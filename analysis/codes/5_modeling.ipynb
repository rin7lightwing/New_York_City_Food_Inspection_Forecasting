{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV # k folds validation using all data as validation set\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns # data visualization library \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchencoder(dftrain,dftest,col,method,targ = 'Target',usetext = False): \n",
    "    '''\n",
    "       dftrain: X_train with target\n",
    "       dftest:X_test with target but should not use its target to encode\n",
    "       method: {'onehot','woe','target','none','label'}\n",
    "       col:{'ZIPCODE','MONTH','CUIZ_TYPE'}\n",
    "       targ: 'Target'\n",
    "       return: encoded X_train and X_Test with target\n",
    "       recommend: woe or target to encode zipcode and cuisine\n",
    "       \n",
    "       '''\n",
    "    #y = dftrain[targ]\n",
    "    #x = dftrain.drop(targ,axis = 1,inplace = True)\n",
    "    if not usetext:\n",
    "        dftrain.drop('Reviews',axis = 1,inplace = True)\n",
    "        dftest.drop('Reviews',axis = 1,inplace = True)\n",
    "        \n",
    "    for i in range(len(col)):\n",
    "            \n",
    "        if method[i] == 'target':\n",
    "            group_target_mean = dftrain.groupby([col[i]])[targ].mean()\n",
    "            dftest[col[i]] = dftest[col[i]].map(group_target_mean)\n",
    "            dftrain[col[i]] = dftrain[col[i]].map(group_target_mean)\n",
    "            \n",
    "        elif method[i] == 'onehot':\n",
    "            \n",
    "            dftrain['unique'] = pd.Series(np.arange(0,len(dftrain)))\n",
    "            dftest['unique'] = pd.Series(np.arange(len(dftrain),len(dftrain)+len(dftest)))\n",
    "            x = pd.concat([dftrain,dftest],axis = 0,ignore_index = True)\n",
    "            df_le = LabelEncoder()\n",
    "            df_labels = df_le.fit_transform(x[col[i]])\n",
    "            x[col[i]+'_LABEL'] = df_labels\n",
    "            df_ohe = OneHotEncoder()\n",
    "            df_feature_arr = df_ohe.fit_transform(x[[col[i]+'_LABEL']]).toarray()\n",
    "            df_feature_labels = list(df_le.classes_)\n",
    "            df_features = pd.DataFrame(df_feature_arr,columns = df_feature_labels)\n",
    "            x = pd.concat([x, df_features], axis=1)\n",
    "            x.drop([col[i]+'_LABEL',col[i]],axis = 1,inplace = True)\n",
    "            dftrain = x[x.unique.isin(dftrain.unique.values)]\n",
    "            dftest = x[x.unique.isin(dftest.unique.values)]\n",
    "            \n",
    "            dftrain.drop('unique',axis = 1,inplace = True)\n",
    "            dftest.drop('unique',axis = 1,inplace = True)\n",
    "            \n",
    "        elif method[i] == 'label':\n",
    "            dftrain['unique'] = pd.Series(np.arange(0,len(dftrain)))\n",
    "            dftest['unique'] = pd.Series(np.arange(len(dftrain),len(dftrain)+len(dftest)))\n",
    "            x = pd.concat([dftrain,dftest],axis = 0,ignore_index = True)\n",
    "            x[col[i]+'_LABEL'] = LabelEncoder().fit_transform(x[col[i]])\n",
    "            dftrain = x[x.unique.isin(dftrain.unique.values)]\n",
    "            dftest = x[x.unique.isin(dftest.unique.values)]\n",
    "            #dftrain.drop(['unique',col[i]],axis = 1,inplace = True)\n",
    "            #dftest.drop(['unique',col[i]],axis = 1,inplace = True)           \n",
    "            \n",
    "    return dftrain, dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfeaturesets(trainx,trainy,method,weights = None, perc = None):\n",
    "    \n",
    "#generate feature sets\n",
    "    if method == 'rfecv':\n",
    "        clf_rf_4 = RandomForestClassifier() \n",
    "        rfecv = RFECV(estimator=clf_rf_4, step=1, cv=5,scoring='roc_auc')   #5-fold cross-validation\n",
    "        rfecv = rfecv.fit(trainx, trainy)\n",
    "        feat = trainx.columns[rfecv.support_].values\n",
    "\n",
    "# print('Optimal number of features :', rfecv.n_features_)\n",
    "# print('Best features :', X_train.columns[rfecv.support_])\n",
    "    elif method == 'lr':\n",
    "        embeded_lr_selector = SelectFromModel(LogisticRegression(C = 0.1,penalty=\"l1\"))\n",
    "        embeded_lr_selector.fit(trainx, trainy)\n",
    "        embeded_lr_support = embeded_lr_selector.get_support()\n",
    "        feat = trainx.loc[:,embeded_lr_support].columns.values\n",
    "# print(str(len(embeded_lr_feature)), 'selected features')\n",
    "# print(embeded_lr_feature)\n",
    "    elif method == 'rf':\n",
    "        embeded_rf_selector = SelectFromModel(RandomForestClassifier(criterion='entropy',oob_score=True))\n",
    "        embeded_rf_selector.fit(trainx, trainy)\n",
    "        embeded_rf_support = embeded_rf_selector.get_support()\n",
    "        feat = trainx.loc[:,embeded_rf_support].columns.values\n",
    "#     print(str(len(embeded_rf_feature)), 'selected features')\n",
    "#     print(embeded_rf_feature)\n",
    "\n",
    "    elif (method == 'fi_rf' or method == 'fi_lgm'):\n",
    "        \n",
    "        \n",
    "        weights = dict(weights)\n",
    "        val = list(weights.values())\n",
    "        l = len(np.where(np.cumsum(val) < perc)[0])\n",
    "        feat = list(weights.keys())[:l]\n",
    "\n",
    "    return feat\n",
    "\n",
    "def getfeatureimportance(X,trained,model,ret = False,pl = False):\n",
    "    #rf:\n",
    "    if model == 'rf':\n",
    "        weights = list(zip( X.columns,trained.feature_importances_ ))\n",
    "        weights.sort(reverse = True,key=lambda x: x[1])\n",
    "        \n",
    "        weights_df = pd.DataFrame(weights[:60],columns = ['feature','weight'])\n",
    "        if pl:\n",
    "            \n",
    "            sns.set_context('talk')\n",
    "            c = sns.barplot(x='weight',y='feature',data = weights_df,palette='Set3')\n",
    "            plt.title(\"Restaurant Failures Feature Importance\"+'_'+model)\n",
    "            plt.rcParams[\"axes.labelsize\"] = 10\n",
    "            plt.xticks(rotation = 90)\n",
    "            plt.xlabel(\"Normalized_Feature_importance\")\n",
    "            plt.ylabel(\"Feature\")\n",
    "            plt.show()\n",
    "        \n",
    "    elif model == 'lgm':\n",
    "        val = trained.feature_importance()\n",
    "        weights = list(zip(X.columns,val/np.sum(val)))\n",
    "        weights.sort(reverse = True,key=lambda x: x[1])\n",
    "        \n",
    "        weights_df = pd.DataFrame(weights[:60],columns = ['feature','weight'])\n",
    "        if pl:\n",
    "            \n",
    "            sns.set_context('talk')\n",
    "            c = sns.barplot(x='weight',y='feature',data = weights_df,palette='Set3')\n",
    "            plt.title(\"Flight Delay Prediction Feature Importance\"+'_'+model)\n",
    "            plt.xticks(rotation = 90)\n",
    "            plt.xlabel(\"Normalized_Feature_importance\")\n",
    "            plt.ylabel(\"Feature\")\n",
    "            plt.show()\n",
    "     \n",
    "    if ret:\n",
    "        return weights\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = pd.read_csv('testset4.csv')\n",
    "Train = pd.read_csv('trainset4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10490, 59)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3694: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Encoding\n",
    "(Train,Test) = batchencoder(Train,Test,col = ['Zipcode','Month','FoodType','LastAction','LastGrade','LastInspProgram','LastInspCat','SubBoro'],method = ['onehot','onehot','onehot','onehot','onehot','onehot','onehot','onehot'],targ = 'Target')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate \n",
    "X_Train = Train.drop('Target',1,inplace = False)\n",
    "Y_Train = Train['Target']\n",
    "X_Test = Test.drop('Target',1,inplace = False)\n",
    "Y_Test = Test['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train.columns.values #should we drop zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.6146\n",
      "[2]\ttraining's binary_logloss: 0.613594\n",
      "[3]\ttraining's binary_logloss: 0.612605\n",
      "[4]\ttraining's binary_logloss: 0.6116\n",
      "[5]\ttraining's binary_logloss: 0.610584\n",
      "[6]\ttraining's binary_logloss: 0.609662\n",
      "[7]\ttraining's binary_logloss: 0.608731\n",
      "[8]\ttraining's binary_logloss: 0.607839\n",
      "[9]\ttraining's binary_logloss: 0.60703\n",
      "[10]\ttraining's binary_logloss: 0.606206\n",
      "[11]\ttraining's binary_logloss: 0.605341\n",
      "[12]\ttraining's binary_logloss: 0.604594\n",
      "[13]\ttraining's binary_logloss: 0.603921\n",
      "[14]\ttraining's binary_logloss: 0.603205\n",
      "[15]\ttraining's binary_logloss: 0.60247\n",
      "[16]\ttraining's binary_logloss: 0.601768\n",
      "[17]\ttraining's binary_logloss: 0.601096\n",
      "[18]\ttraining's binary_logloss: 0.600437\n",
      "[19]\ttraining's binary_logloss: 0.599804\n",
      "[20]\ttraining's binary_logloss: 0.5992\n",
      "[21]\ttraining's binary_logloss: 0.59865\n",
      "[22]\ttraining's binary_logloss: 0.598121\n",
      "[23]\ttraining's binary_logloss: 0.597543\n",
      "[24]\ttraining's binary_logloss: 0.597013\n",
      "[25]\ttraining's binary_logloss: 0.596548\n",
      "[26]\ttraining's binary_logloss: 0.596074\n",
      "[27]\ttraining's binary_logloss: 0.595621\n",
      "[28]\ttraining's binary_logloss: 0.595198\n",
      "[29]\ttraining's binary_logloss: 0.594844\n",
      "[30]\ttraining's binary_logloss: 0.594379\n",
      "[31]\ttraining's binary_logloss: 0.593934\n",
      "[32]\ttraining's binary_logloss: 0.593619\n",
      "[33]\ttraining's binary_logloss: 0.593217\n",
      "[34]\ttraining's binary_logloss: 0.592836\n",
      "[35]\ttraining's binary_logloss: 0.592467\n",
      "[36]\ttraining's binary_logloss: 0.592134\n",
      "[37]\ttraining's binary_logloss: 0.591843\n",
      "[38]\ttraining's binary_logloss: 0.591537\n",
      "[39]\ttraining's binary_logloss: 0.59123\n",
      "[40]\ttraining's binary_logloss: 0.590954\n",
      "[41]\ttraining's binary_logloss: 0.59066\n",
      "[42]\ttraining's binary_logloss: 0.590382\n",
      "[43]\ttraining's binary_logloss: 0.590118\n",
      "[44]\ttraining's binary_logloss: 0.589863\n",
      "[45]\ttraining's binary_logloss: 0.589608\n",
      "[46]\ttraining's binary_logloss: 0.58935\n",
      "[47]\ttraining's binary_logloss: 0.589113\n",
      "[48]\ttraining's binary_logloss: 0.588882\n",
      "[49]\ttraining's binary_logloss: 0.588638\n",
      "[50]\ttraining's binary_logloss: 0.588438\n",
      "[51]\ttraining's binary_logloss: 0.588281\n",
      "[52]\ttraining's binary_logloss: 0.588074\n",
      "[53]\ttraining's binary_logloss: 0.587951\n",
      "[54]\ttraining's binary_logloss: 0.58776\n",
      "[55]\ttraining's binary_logloss: 0.587636\n",
      "[56]\ttraining's binary_logloss: 0.587427\n",
      "[57]\ttraining's binary_logloss: 0.587296\n",
      "[58]\ttraining's binary_logloss: 0.587205\n",
      "[59]\ttraining's binary_logloss: 0.587096\n",
      "[60]\ttraining's binary_logloss: 0.586999\n",
      "[61]\ttraining's binary_logloss: 0.586868\n",
      "[62]\ttraining's binary_logloss: 0.586736\n",
      "[63]\ttraining's binary_logloss: 0.586659\n",
      "[64]\ttraining's binary_logloss: 0.586582\n",
      "[65]\ttraining's binary_logloss: 0.586519\n",
      "[66]\ttraining's binary_logloss: 0.586466\n",
      "[67]\ttraining's binary_logloss: 0.586341\n",
      "[68]\ttraining's binary_logloss: 0.586268\n",
      "[69]\ttraining's binary_logloss: 0.586194\n",
      "[70]\ttraining's binary_logloss: 0.586138\n",
      "[71]\ttraining's binary_logloss: 0.586091\n",
      "[72]\ttraining's binary_logloss: 0.586008\n",
      "[73]\ttraining's binary_logloss: 0.585928\n",
      "[74]\ttraining's binary_logloss: 0.585889\n",
      "[75]\ttraining's binary_logloss: 0.585822\n",
      "[76]\ttraining's binary_logloss: 0.585788\n",
      "[77]\ttraining's binary_logloss: 0.585738\n",
      "[78]\ttraining's binary_logloss: 0.585675\n",
      "[79]\ttraining's binary_logloss: 0.585604\n",
      "[80]\ttraining's binary_logloss: 0.585565\n",
      "[81]\ttraining's binary_logloss: 0.585548\n",
      "[82]\ttraining's binary_logloss: 0.585475\n",
      "[83]\ttraining's binary_logloss: 0.585466\n",
      "[84]\ttraining's binary_logloss: 0.585462\n",
      "[85]\ttraining's binary_logloss: 0.585471\n",
      "[86]\ttraining's binary_logloss: 0.585439\n",
      "[87]\ttraining's binary_logloss: 0.585403\n",
      "[88]\ttraining's binary_logloss: 0.585417\n",
      "[89]\ttraining's binary_logloss: 0.585363\n",
      "[90]\ttraining's binary_logloss: 0.585335\n",
      "[91]\ttraining's binary_logloss: 0.58533\n",
      "[92]\ttraining's binary_logloss: 0.585322\n",
      "[93]\ttraining's binary_logloss: 0.585319\n",
      "[94]\ttraining's binary_logloss: 0.585357\n",
      "[95]\ttraining's binary_logloss: 0.585338\n",
      "[96]\ttraining's binary_logloss: 0.585346\n",
      "[97]\ttraining's binary_logloss: 0.585327\n",
      "[98]\ttraining's binary_logloss: 0.585336\n",
      "[99]\ttraining's binary_logloss: 0.585322\n",
      "[100]\ttraining's binary_logloss: 0.58531\n",
      "[101]\ttraining's binary_logloss: 0.585304\n",
      "[102]\ttraining's binary_logloss: 0.585312\n",
      "[103]\ttraining's binary_logloss: 0.585313\n",
      "[104]\ttraining's binary_logloss: 0.585325\n",
      "[105]\ttraining's binary_logloss: 0.585323\n",
      "[106]\ttraining's binary_logloss: 0.585363\n",
      "[107]\ttraining's binary_logloss: 0.585419\n",
      "[108]\ttraining's binary_logloss: 0.585423\n",
      "[109]\ttraining's binary_logloss: 0.585464\n",
      "[110]\ttraining's binary_logloss: 0.585462\n",
      "[111]\ttraining's binary_logloss: 0.585433\n",
      "[112]\ttraining's binary_logloss: 0.585397\n",
      "[113]\ttraining's binary_logloss: 0.585399\n",
      "[114]\ttraining's binary_logloss: 0.58537\n",
      "[115]\ttraining's binary_logloss: 0.585351\n",
      "[116]\ttraining's binary_logloss: 0.585387\n",
      "[117]\ttraining's binary_logloss: 0.585379\n",
      "[118]\ttraining's binary_logloss: 0.585376\n",
      "[119]\ttraining's binary_logloss: 0.585376\n",
      "[120]\ttraining's binary_logloss: 0.585368\n",
      "[121]\ttraining's binary_logloss: 0.58542\n",
      "[122]\ttraining's binary_logloss: 0.585432\n",
      "[123]\ttraining's binary_logloss: 0.585447\n",
      "[124]\ttraining's binary_logloss: 0.585466\n",
      "[125]\ttraining's binary_logloss: 0.585493\n",
      "[126]\ttraining's binary_logloss: 0.585495\n",
      "[127]\ttraining's binary_logloss: 0.5855\n",
      "[128]\ttraining's binary_logloss: 0.585507\n",
      "[129]\ttraining's binary_logloss: 0.585511\n",
      "[130]\ttraining's binary_logloss: 0.585533\n",
      "[131]\ttraining's binary_logloss: 0.585549\n",
      "[132]\ttraining's binary_logloss: 0.585599\n",
      "[133]\ttraining's binary_logloss: 0.585651\n",
      "[134]\ttraining's binary_logloss: 0.58571\n",
      "[135]\ttraining's binary_logloss: 0.585764\n",
      "[136]\ttraining's binary_logloss: 0.585806\n",
      "[137]\ttraining's binary_logloss: 0.585831\n",
      "[138]\ttraining's binary_logloss: 0.585807\n",
      "[139]\ttraining's binary_logloss: 0.585786\n",
      "[140]\ttraining's binary_logloss: 0.585822\n",
      "[141]\ttraining's binary_logloss: 0.585845\n",
      "[142]\ttraining's binary_logloss: 0.585867\n",
      "[143]\ttraining's binary_logloss: 0.585894\n",
      "[144]\ttraining's binary_logloss: 0.585925\n",
      "[145]\ttraining's binary_logloss: 0.585927\n",
      "[146]\ttraining's binary_logloss: 0.585931\n",
      "[147]\ttraining's binary_logloss: 0.585957\n",
      "[148]\ttraining's binary_logloss: 0.585964\n",
      "[149]\ttraining's binary_logloss: 0.585978\n",
      "[150]\ttraining's binary_logloss: 0.586015\n",
      "[151]\ttraining's binary_logloss: 0.586048\n",
      "[152]\ttraining's binary_logloss: 0.58608\n",
      "[153]\ttraining's binary_logloss: 0.586119\n",
      "[154]\ttraining's binary_logloss: 0.586164\n",
      "[155]\ttraining's binary_logloss: 0.586187\n",
      "[156]\ttraining's binary_logloss: 0.586205\n",
      "[157]\ttraining's binary_logloss: 0.58622\n",
      "[158]\ttraining's binary_logloss: 0.586278\n",
      "[159]\ttraining's binary_logloss: 0.586321\n",
      "[160]\ttraining's binary_logloss: 0.586361\n",
      "[161]\ttraining's binary_logloss: 0.586372\n",
      "[162]\ttraining's binary_logloss: 0.586357\n",
      "[163]\ttraining's binary_logloss: 0.58633\n",
      "[164]\ttraining's binary_logloss: 0.586371\n",
      "[165]\ttraining's binary_logloss: 0.586371\n",
      "[166]\ttraining's binary_logloss: 0.586373\n",
      "[167]\ttraining's binary_logloss: 0.586368\n",
      "[168]\ttraining's binary_logloss: 0.586366\n",
      "[169]\ttraining's binary_logloss: 0.58638\n",
      "[170]\ttraining's binary_logloss: 0.586367\n",
      "[171]\ttraining's binary_logloss: 0.586384\n",
      "[172]\ttraining's binary_logloss: 0.586399\n",
      "[173]\ttraining's binary_logloss: 0.586419\n",
      "[174]\ttraining's binary_logloss: 0.586454\n",
      "[175]\ttraining's binary_logloss: 0.586478\n",
      "[176]\ttraining's binary_logloss: 0.586491\n",
      "[177]\ttraining's binary_logloss: 0.586481\n",
      "[178]\ttraining's binary_logloss: 0.5865\n",
      "[179]\ttraining's binary_logloss: 0.586514\n",
      "[180]\ttraining's binary_logloss: 0.586535\n",
      "[181]\ttraining's binary_logloss: 0.586523\n",
      "[182]\ttraining's binary_logloss: 0.58654\n",
      "[183]\ttraining's binary_logloss: 0.586559\n",
      "[184]\ttraining's binary_logloss: 0.586574\n",
      "[185]\ttraining's binary_logloss: 0.586598\n",
      "[186]\ttraining's binary_logloss: 0.586642\n",
      "[187]\ttraining's binary_logloss: 0.586685\n",
      "[188]\ttraining's binary_logloss: 0.586726\n",
      "[189]\ttraining's binary_logloss: 0.586766\n",
      "[190]\ttraining's binary_logloss: 0.586808\n",
      "[191]\ttraining's binary_logloss: 0.586775\n",
      "[192]\ttraining's binary_logloss: 0.586771\n",
      "[193]\ttraining's binary_logloss: 0.586758\n",
      "[194]\ttraining's binary_logloss: 0.586759\n",
      "[195]\ttraining's binary_logloss: 0.586757\n",
      "[196]\ttraining's binary_logloss: 0.586738\n",
      "[197]\ttraining's binary_logloss: 0.58673\n",
      "[198]\ttraining's binary_logloss: 0.586746\n",
      "[199]\ttraining's binary_logloss: 0.586739\n",
      "[200]\ttraining's binary_logloss: 0.586752\n",
      "[201]\ttraining's binary_logloss: 0.586768\n",
      "[202]\ttraining's binary_logloss: 0.586785\n",
      "[203]\ttraining's binary_logloss: 0.5868\n",
      "[204]\ttraining's binary_logloss: 0.58682\n",
      "[205]\ttraining's binary_logloss: 0.586831\n",
      "[206]\ttraining's binary_logloss: 0.586774\n",
      "[207]\ttraining's binary_logloss: 0.586735\n",
      "[208]\ttraining's binary_logloss: 0.586696\n",
      "[209]\ttraining's binary_logloss: 0.586652\n",
      "[210]\ttraining's binary_logloss: 0.586611\n",
      "[211]\ttraining's binary_logloss: 0.586642\n",
      "[212]\ttraining's binary_logloss: 0.586672\n",
      "[213]\ttraining's binary_logloss: 0.586693\n",
      "[214]\ttraining's binary_logloss: 0.586711\n",
      "[215]\ttraining's binary_logloss: 0.586746\n",
      "[216]\ttraining's binary_logloss: 0.586722\n",
      "[217]\ttraining's binary_logloss: 0.586695\n",
      "[218]\ttraining's binary_logloss: 0.586674\n",
      "[219]\ttraining's binary_logloss: 0.586653\n",
      "[220]\ttraining's binary_logloss: 0.586638\n",
      "[221]\ttraining's binary_logloss: 0.586607\n",
      "[222]\ttraining's binary_logloss: 0.586569\n",
      "[223]\ttraining's binary_logloss: 0.586535\n",
      "[224]\ttraining's binary_logloss: 0.586507\n",
      "[225]\ttraining's binary_logloss: 0.586476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[226]\ttraining's binary_logloss: 0.586463\n",
      "[227]\ttraining's binary_logloss: 0.58643\n",
      "[228]\ttraining's binary_logloss: 0.586405\n",
      "[229]\ttraining's binary_logloss: 0.586377\n",
      "[230]\ttraining's binary_logloss: 0.586343\n",
      "[231]\ttraining's binary_logloss: 0.58635\n",
      "[232]\ttraining's binary_logloss: 0.586351\n",
      "[233]\ttraining's binary_logloss: 0.58635\n",
      "[234]\ttraining's binary_logloss: 0.586352\n",
      "[235]\ttraining's binary_logloss: 0.586357\n",
      "[236]\ttraining's binary_logloss: 0.58632\n",
      "[237]\ttraining's binary_logloss: 0.586293\n",
      "[238]\ttraining's binary_logloss: 0.586265\n",
      "[239]\ttraining's binary_logloss: 0.586218\n",
      "[240]\ttraining's binary_logloss: 0.586191\n",
      "[241]\ttraining's binary_logloss: 0.586186\n",
      "[242]\ttraining's binary_logloss: 0.586157\n",
      "[243]\ttraining's binary_logloss: 0.586139\n",
      "[244]\ttraining's binary_logloss: 0.586129\n",
      "[245]\ttraining's binary_logloss: 0.586102\n",
      "[246]\ttraining's binary_logloss: 0.586029\n",
      "[247]\ttraining's binary_logloss: 0.585967\n",
      "[248]\ttraining's binary_logloss: 0.585891\n",
      "[249]\ttraining's binary_logloss: 0.585818\n",
      "[250]\ttraining's binary_logloss: 0.585748\n",
      "[251]\ttraining's binary_logloss: 0.585689\n",
      "[252]\ttraining's binary_logloss: 0.585632\n",
      "[253]\ttraining's binary_logloss: 0.585588\n",
      "[254]\ttraining's binary_logloss: 0.585543\n",
      "[255]\ttraining's binary_logloss: 0.585484\n",
      "[256]\ttraining's binary_logloss: 0.585464\n",
      "[257]\ttraining's binary_logloss: 0.585442\n",
      "[258]\ttraining's binary_logloss: 0.585418\n",
      "[259]\ttraining's binary_logloss: 0.585396\n",
      "[260]\ttraining's binary_logloss: 0.585377\n",
      "[261]\ttraining's binary_logloss: 0.58536\n",
      "[262]\ttraining's binary_logloss: 0.585335\n",
      "[263]\ttraining's binary_logloss: 0.585312\n",
      "[264]\ttraining's binary_logloss: 0.585319\n",
      "[265]\ttraining's binary_logloss: 0.585298\n",
      "[266]\ttraining's binary_logloss: 0.585302\n",
      "[267]\ttraining's binary_logloss: 0.5853\n",
      "[268]\ttraining's binary_logloss: 0.585305\n",
      "[269]\ttraining's binary_logloss: 0.585298\n",
      "[270]\ttraining's binary_logloss: 0.585298\n",
      "[271]\ttraining's binary_logloss: 0.585269\n",
      "[272]\ttraining's binary_logloss: 0.585223\n",
      "[273]\ttraining's binary_logloss: 0.585209\n",
      "[274]\ttraining's binary_logloss: 0.5852\n",
      "[275]\ttraining's binary_logloss: 0.585174\n",
      "[276]\ttraining's binary_logloss: 0.585114\n",
      "[277]\ttraining's binary_logloss: 0.585064\n",
      "[278]\ttraining's binary_logloss: 0.585017\n",
      "[279]\ttraining's binary_logloss: 0.584972\n",
      "[280]\ttraining's binary_logloss: 0.584916\n",
      "[281]\ttraining's binary_logloss: 0.584898\n",
      "[282]\ttraining's binary_logloss: 0.584873\n",
      "[283]\ttraining's binary_logloss: 0.584859\n",
      "[284]\ttraining's binary_logloss: 0.584851\n",
      "[285]\ttraining's binary_logloss: 0.584839\n",
      "[286]\ttraining's binary_logloss: 0.584809\n",
      "[287]\ttraining's binary_logloss: 0.58475\n",
      "[288]\ttraining's binary_logloss: 0.584703\n",
      "[289]\ttraining's binary_logloss: 0.584649\n",
      "[290]\ttraining's binary_logloss: 0.584594\n",
      "[291]\ttraining's binary_logloss: 0.584508\n",
      "[292]\ttraining's binary_logloss: 0.584429\n",
      "[293]\ttraining's binary_logloss: 0.584357\n",
      "[294]\ttraining's binary_logloss: 0.584287\n",
      "[295]\ttraining's binary_logloss: 0.584213\n",
      "[296]\ttraining's binary_logloss: 0.584173\n",
      "[297]\ttraining's binary_logloss: 0.584132\n",
      "[298]\ttraining's binary_logloss: 0.584095\n",
      "[299]\ttraining's binary_logloss: 0.584064\n",
      "[300]\ttraining's binary_logloss: 0.584039\n",
      "[301]\ttraining's binary_logloss: 0.583982\n",
      "[302]\ttraining's binary_logloss: 0.583941\n",
      "[303]\ttraining's binary_logloss: 0.583895\n",
      "[304]\ttraining's binary_logloss: 0.583833\n",
      "[305]\ttraining's binary_logloss: 0.583773\n",
      "[306]\ttraining's binary_logloss: 0.583727\n",
      "[307]\ttraining's binary_logloss: 0.583674\n",
      "[308]\ttraining's binary_logloss: 0.583625\n",
      "[309]\ttraining's binary_logloss: 0.583579\n",
      "[310]\ttraining's binary_logloss: 0.583522\n",
      "[311]\ttraining's binary_logloss: 0.583461\n",
      "[312]\ttraining's binary_logloss: 0.583411\n",
      "[313]\ttraining's binary_logloss: 0.583326\n",
      "[314]\ttraining's binary_logloss: 0.583268\n",
      "[315]\ttraining's binary_logloss: 0.583209\n",
      "[316]\ttraining's binary_logloss: 0.583157\n",
      "[317]\ttraining's binary_logloss: 0.583105\n",
      "[318]\ttraining's binary_logloss: 0.583057\n",
      "[319]\ttraining's binary_logloss: 0.583009\n",
      "[320]\ttraining's binary_logloss: 0.582958\n",
      "[321]\ttraining's binary_logloss: 0.582925\n",
      "[322]\ttraining's binary_logloss: 0.582856\n",
      "[323]\ttraining's binary_logloss: 0.582783\n",
      "[324]\ttraining's binary_logloss: 0.582746\n",
      "[325]\ttraining's binary_logloss: 0.582681\n",
      "[326]\ttraining's binary_logloss: 0.582606\n",
      "[327]\ttraining's binary_logloss: 0.582534\n",
      "[328]\ttraining's binary_logloss: 0.582462\n",
      "[329]\ttraining's binary_logloss: 0.58239\n",
      "[330]\ttraining's binary_logloss: 0.582315\n",
      "[331]\ttraining's binary_logloss: 0.582246\n",
      "[332]\ttraining's binary_logloss: 0.582184\n",
      "[333]\ttraining's binary_logloss: 0.582123\n",
      "[334]\ttraining's binary_logloss: 0.582069\n",
      "[335]\ttraining's binary_logloss: 0.582016\n",
      "[336]\ttraining's binary_logloss: 0.581988\n",
      "[337]\ttraining's binary_logloss: 0.581954\n",
      "[338]\ttraining's binary_logloss: 0.58192\n",
      "[339]\ttraining's binary_logloss: 0.581888\n",
      "[340]\ttraining's binary_logloss: 0.581858\n",
      "[341]\ttraining's binary_logloss: 0.581811\n",
      "[342]\ttraining's binary_logloss: 0.581762\n",
      "[343]\ttraining's binary_logloss: 0.581698\n",
      "[344]\ttraining's binary_logloss: 0.581647\n",
      "[345]\ttraining's binary_logloss: 0.5816\n",
      "[346]\ttraining's binary_logloss: 0.58152\n",
      "[347]\ttraining's binary_logloss: 0.581443\n",
      "[348]\ttraining's binary_logloss: 0.581375\n",
      "[349]\ttraining's binary_logloss: 0.581304\n",
      "[350]\ttraining's binary_logloss: 0.58124\n",
      "[351]\ttraining's binary_logloss: 0.581213\n",
      "[352]\ttraining's binary_logloss: 0.58118\n",
      "[353]\ttraining's binary_logloss: 0.58115\n",
      "[354]\ttraining's binary_logloss: 0.58112\n",
      "[355]\ttraining's binary_logloss: 0.58109\n",
      "[356]\ttraining's binary_logloss: 0.581026\n",
      "[357]\ttraining's binary_logloss: 0.580961\n",
      "[358]\ttraining's binary_logloss: 0.580912\n",
      "[359]\ttraining's binary_logloss: 0.58085\n",
      "[360]\ttraining's binary_logloss: 0.580789\n",
      "[361]\ttraining's binary_logloss: 0.580718\n",
      "[362]\ttraining's binary_logloss: 0.580654\n",
      "[363]\ttraining's binary_logloss: 0.58059\n",
      "[364]\ttraining's binary_logloss: 0.580521\n",
      "[365]\ttraining's binary_logloss: 0.580454\n",
      "[366]\ttraining's binary_logloss: 0.580392\n",
      "[367]\ttraining's binary_logloss: 0.580332\n",
      "[368]\ttraining's binary_logloss: 0.580282\n",
      "[369]\ttraining's binary_logloss: 0.58022\n",
      "[370]\ttraining's binary_logloss: 0.580164\n",
      "[371]\ttraining's binary_logloss: 0.580089\n",
      "[372]\ttraining's binary_logloss: 0.580017\n",
      "[373]\ttraining's binary_logloss: 0.579944\n",
      "[374]\ttraining's binary_logloss: 0.579868\n",
      "[375]\ttraining's binary_logloss: 0.5798\n",
      "[376]\ttraining's binary_logloss: 0.579741\n",
      "[377]\ttraining's binary_logloss: 0.579672\n",
      "[378]\ttraining's binary_logloss: 0.579606\n",
      "[379]\ttraining's binary_logloss: 0.57954\n",
      "[380]\ttraining's binary_logloss: 0.579485\n",
      "[381]\ttraining's binary_logloss: 0.5794\n",
      "[382]\ttraining's binary_logloss: 0.579302\n",
      "[383]\ttraining's binary_logloss: 0.579207\n",
      "[384]\ttraining's binary_logloss: 0.579115\n",
      "[385]\ttraining's binary_logloss: 0.579019\n",
      "[386]\ttraining's binary_logloss: 0.578947\n",
      "[387]\ttraining's binary_logloss: 0.578865\n",
      "[388]\ttraining's binary_logloss: 0.578804\n",
      "[389]\ttraining's binary_logloss: 0.578724\n",
      "[390]\ttraining's binary_logloss: 0.578657\n",
      "[391]\ttraining's binary_logloss: 0.57857\n",
      "[392]\ttraining's binary_logloss: 0.578479\n",
      "[393]\ttraining's binary_logloss: 0.57839\n",
      "[394]\ttraining's binary_logloss: 0.578311\n",
      "[395]\ttraining's binary_logloss: 0.578234\n",
      "[396]\ttraining's binary_logloss: 0.578191\n",
      "[397]\ttraining's binary_logloss: 0.578152\n",
      "[398]\ttraining's binary_logloss: 0.578112\n",
      "[399]\ttraining's binary_logloss: 0.578077\n",
      "[400]\ttraining's binary_logloss: 0.578014\n",
      "[401]\ttraining's binary_logloss: 0.577937\n",
      "[402]\ttraining's binary_logloss: 0.577862\n",
      "[403]\ttraining's binary_logloss: 0.577789\n",
      "[404]\ttraining's binary_logloss: 0.577716\n",
      "[405]\ttraining's binary_logloss: 0.577646\n",
      "[406]\ttraining's binary_logloss: 0.577563\n",
      "[407]\ttraining's binary_logloss: 0.577528\n",
      "[408]\ttraining's binary_logloss: 0.577486\n",
      "[409]\ttraining's binary_logloss: 0.577411\n",
      "[410]\ttraining's binary_logloss: 0.577373\n",
      "[411]\ttraining's binary_logloss: 0.577285\n",
      "[412]\ttraining's binary_logloss: 0.577222\n",
      "[413]\ttraining's binary_logloss: 0.577142\n",
      "[414]\ttraining's binary_logloss: 0.577059\n",
      "[415]\ttraining's binary_logloss: 0.576977\n",
      "[416]\ttraining's binary_logloss: 0.576915\n",
      "[417]\ttraining's binary_logloss: 0.57684\n",
      "[418]\ttraining's binary_logloss: 0.57676\n",
      "[419]\ttraining's binary_logloss: 0.576689\n",
      "[420]\ttraining's binary_logloss: 0.576613\n",
      "[421]\ttraining's binary_logloss: 0.576571\n",
      "[422]\ttraining's binary_logloss: 0.576514\n",
      "[423]\ttraining's binary_logloss: 0.576459\n",
      "[424]\ttraining's binary_logloss: 0.576404\n",
      "[425]\ttraining's binary_logloss: 0.576354\n",
      "[426]\ttraining's binary_logloss: 0.576288\n",
      "[427]\ttraining's binary_logloss: 0.576224\n",
      "[428]\ttraining's binary_logloss: 0.57616\n",
      "[429]\ttraining's binary_logloss: 0.576093\n",
      "[430]\ttraining's binary_logloss: 0.576029\n",
      "[431]\ttraining's binary_logloss: 0.575967\n",
      "[432]\ttraining's binary_logloss: 0.575905\n",
      "[433]\ttraining's binary_logloss: 0.575832\n",
      "[434]\ttraining's binary_logloss: 0.575757\n",
      "[435]\ttraining's binary_logloss: 0.575687\n",
      "[436]\ttraining's binary_logloss: 0.575609\n",
      "[437]\ttraining's binary_logloss: 0.575559\n",
      "[438]\ttraining's binary_logloss: 0.575481\n",
      "[439]\ttraining's binary_logloss: 0.575433\n",
      "[440]\ttraining's binary_logloss: 0.57536\n",
      "[441]\ttraining's binary_logloss: 0.575309\n",
      "[442]\ttraining's binary_logloss: 0.575235\n",
      "[443]\ttraining's binary_logloss: 0.575162\n",
      "[444]\ttraining's binary_logloss: 0.575094\n",
      "[445]\ttraining's binary_logloss: 0.575024\n",
      "[446]\ttraining's binary_logloss: 0.574924\n",
      "[447]\ttraining's binary_logloss: 0.574831\n",
      "[448]\ttraining's binary_logloss: 0.574721\n",
      "[449]\ttraining's binary_logloss: 0.574629\n",
      "[450]\ttraining's binary_logloss: 0.574535\n",
      "[451]\ttraining's binary_logloss: 0.574453\n",
      "[452]\ttraining's binary_logloss: 0.574374\n",
      "[453]\ttraining's binary_logloss: 0.574296\n",
      "[454]\ttraining's binary_logloss: 0.574227\n",
      "[455]\ttraining's binary_logloss: 0.574159\n",
      "[456]\ttraining's binary_logloss: 0.574101\n",
      "[457]\ttraining's binary_logloss: 0.574016\n",
      "[458]\ttraining's binary_logloss: 0.573959\n",
      "[459]\ttraining's binary_logloss: 0.573877\n",
      "[460]\ttraining's binary_logloss: 0.573821\n",
      "[461]\ttraining's binary_logloss: 0.57375\n",
      "[462]\ttraining's binary_logloss: 0.573678\n",
      "[463]\ttraining's binary_logloss: 0.573609\n",
      "[464]\ttraining's binary_logloss: 0.573528\n",
      "[465]\ttraining's binary_logloss: 0.573459\n",
      "[466]\ttraining's binary_logloss: 0.573382\n",
      "[467]\ttraining's binary_logloss: 0.573307\n",
      "[468]\ttraining's binary_logloss: 0.573242\n",
      "[469]\ttraining's binary_logloss: 0.573178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[470]\ttraining's binary_logloss: 0.573114\n",
      "[471]\ttraining's binary_logloss: 0.573025\n",
      "[472]\ttraining's binary_logloss: 0.572935\n",
      "[473]\ttraining's binary_logloss: 0.572856\n",
      "[474]\ttraining's binary_logloss: 0.572765\n",
      "[475]\ttraining's binary_logloss: 0.572682\n",
      "[476]\ttraining's binary_logloss: 0.572621\n",
      "[477]\ttraining's binary_logloss: 0.572543\n",
      "[478]\ttraining's binary_logloss: 0.572492\n",
      "[479]\ttraining's binary_logloss: 0.57245\n",
      "[480]\ttraining's binary_logloss: 0.572378\n",
      "[481]\ttraining's binary_logloss: 0.572331\n",
      "[482]\ttraining's binary_logloss: 0.572288\n",
      "[483]\ttraining's binary_logloss: 0.572248\n",
      "[484]\ttraining's binary_logloss: 0.572197\n",
      "[485]\ttraining's binary_logloss: 0.572152\n",
      "[486]\ttraining's binary_logloss: 0.572059\n",
      "[487]\ttraining's binary_logloss: 0.571971\n",
      "[488]\ttraining's binary_logloss: 0.57188\n",
      "[489]\ttraining's binary_logloss: 0.571784\n",
      "[490]\ttraining's binary_logloss: 0.571695\n",
      "[491]\ttraining's binary_logloss: 0.571582\n",
      "[492]\ttraining's binary_logloss: 0.571479\n",
      "[493]\ttraining's binary_logloss: 0.571371\n",
      "[494]\ttraining's binary_logloss: 0.571264\n",
      "[495]\ttraining's binary_logloss: 0.571157\n",
      "[496]\ttraining's binary_logloss: 0.571094\n",
      "[497]\ttraining's binary_logloss: 0.571017\n",
      "[498]\ttraining's binary_logloss: 0.570922\n",
      "[499]\ttraining's binary_logloss: 0.57086\n",
      "[500]\ttraining's binary_logloss: 0.570773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py:2267: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Demonstrate on test set\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#smote = SMOTE(ratio='minority')\n",
    "#X_Train, Y_Train = smote.fit_sample(X_Train, Y_Train)\n",
    "\n",
    "ens = [0.1,0.2,0.7]\n",
    "predall_noselect = []\n",
    "trainedall_noselect = []\n",
    "for model in ['lr','rf','lgm']:\n",
    "    (pred,tra) = getprediction(model,X_Train,Y_Train,X_Test)\n",
    "    predall_noselect.append(pred)\n",
    "    trainedall_noselect.append(tra)\n",
    "    plotAUC(Y_Test,pred,model)\n",
    "plotAUC(Y_Test,ens[0]*predall_noselect[0]+ens[1]*predall_noselect[1]+ens[2]*predall_noselect[2],'ensemble')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAUC(truth, pred, lab,other = ''):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(truth, pred)\n",
    "    roc_auc = metrics.roc_auc_score(truth, pred)\n",
    "    c = (np.random.rand(), np.random.rand(), np.random.rand())\n",
    "    plt.plot(fpr, tpr, color=c, label= other+lab+'_'+' (AUC = %0.4f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title('ROC')\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(0.1,-0.6)) \n",
    "    #plt.legend(loc='center left', bbox_to_anchor=(1.2,0.5),ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py:2267: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py:2267: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.rcParams.update({'figure.autolayout':True})\n",
    "getfeatureimportance(X_Train,trainedall_noselect[1],model = 'rf',pl = True)\n",
    "plt.figure(figsize=(10,10))\n",
    "getfeatureimportance(X_Train,trainedall_noselect[2],model = 'lgm',pl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614604\n",
      "[2]\ttraining's binary_logloss: 0.613465\n",
      "[3]\ttraining's binary_logloss: 0.612375\n",
      "[4]\ttraining's binary_logloss: 0.611369\n",
      "[5]\ttraining's binary_logloss: 0.610328\n",
      "[6]\ttraining's binary_logloss: 0.609358\n",
      "[7]\ttraining's binary_logloss: 0.608369\n",
      "[8]\ttraining's binary_logloss: 0.60742\n",
      "[9]\ttraining's binary_logloss: 0.606624\n",
      "[10]\ttraining's binary_logloss: 0.605892\n",
      "[11]\ttraining's binary_logloss: 0.605062\n",
      "[12]\ttraining's binary_logloss: 0.60429\n",
      "[13]\ttraining's binary_logloss: 0.603511\n",
      "[14]\ttraining's binary_logloss: 0.602763\n",
      "[15]\ttraining's binary_logloss: 0.602157\n",
      "[16]\ttraining's binary_logloss: 0.601593\n",
      "[17]\ttraining's binary_logloss: 0.600931\n",
      "[18]\ttraining's binary_logloss: 0.600385\n",
      "[19]\ttraining's binary_logloss: 0.599818\n",
      "[20]\ttraining's binary_logloss: 0.599204\n",
      "[21]\ttraining's binary_logloss: 0.598661\n",
      "[22]\ttraining's binary_logloss: 0.598143\n",
      "[23]\ttraining's binary_logloss: 0.597643\n",
      "[24]\ttraining's binary_logloss: 0.597148\n",
      "[25]\ttraining's binary_logloss: 0.596711\n",
      "[26]\ttraining's binary_logloss: 0.596303\n",
      "[27]\ttraining's binary_logloss: 0.595784\n",
      "[28]\ttraining's binary_logloss: 0.595327\n",
      "[29]\ttraining's binary_logloss: 0.594917\n",
      "[30]\ttraining's binary_logloss: 0.594494\n",
      "[31]\ttraining's binary_logloss: 0.594061\n",
      "[32]\ttraining's binary_logloss: 0.593657\n",
      "[33]\ttraining's binary_logloss: 0.593262\n",
      "[34]\ttraining's binary_logloss: 0.592874\n",
      "[35]\ttraining's binary_logloss: 0.592505\n",
      "[36]\ttraining's binary_logloss: 0.592168\n",
      "[37]\ttraining's binary_logloss: 0.591848\n",
      "[38]\ttraining's binary_logloss: 0.591544\n",
      "[39]\ttraining's binary_logloss: 0.591273\n",
      "[40]\ttraining's binary_logloss: 0.59098\n",
      "[41]\ttraining's binary_logloss: 0.590685\n",
      "[42]\ttraining's binary_logloss: 0.590403\n",
      "[43]\ttraining's binary_logloss: 0.590131\n",
      "[44]\ttraining's binary_logloss: 0.589875\n",
      "[45]\ttraining's binary_logloss: 0.589683\n",
      "[46]\ttraining's binary_logloss: 0.589415\n",
      "[47]\ttraining's binary_logloss: 0.589173\n",
      "[48]\ttraining's binary_logloss: 0.588936\n",
      "[49]\ttraining's binary_logloss: 0.588679\n",
      "[50]\ttraining's binary_logloss: 0.588466\n",
      "[51]\ttraining's binary_logloss: 0.588326\n",
      "[52]\ttraining's binary_logloss: 0.588142\n",
      "[53]\ttraining's binary_logloss: 0.588019\n",
      "[54]\ttraining's binary_logloss: 0.587853\n",
      "[55]\ttraining's binary_logloss: 0.587673\n",
      "[56]\ttraining's binary_logloss: 0.587463\n",
      "[57]\ttraining's binary_logloss: 0.587262\n",
      "[58]\ttraining's binary_logloss: 0.58707\n",
      "[59]\ttraining's binary_logloss: 0.586965\n",
      "[60]\ttraining's binary_logloss: 0.586792\n",
      "[61]\ttraining's binary_logloss: 0.586711\n",
      "[62]\ttraining's binary_logloss: 0.586648\n",
      "[63]\ttraining's binary_logloss: 0.586526\n",
      "[64]\ttraining's binary_logloss: 0.58647\n",
      "[65]\ttraining's binary_logloss: 0.586364\n",
      "[66]\ttraining's binary_logloss: 0.586237\n",
      "[67]\ttraining's binary_logloss: 0.586119\n",
      "[68]\ttraining's binary_logloss: 0.586048\n",
      "[69]\ttraining's binary_logloss: 0.586036\n",
      "[70]\ttraining's binary_logloss: 0.585973\n",
      "[71]\ttraining's binary_logloss: 0.58588\n",
      "[72]\ttraining's binary_logloss: 0.58579\n",
      "[73]\ttraining's binary_logloss: 0.585712\n",
      "[74]\ttraining's binary_logloss: 0.585678\n",
      "[75]\ttraining's binary_logloss: 0.585652\n",
      "[76]\ttraining's binary_logloss: 0.585592\n",
      "[77]\ttraining's binary_logloss: 0.585557\n",
      "[78]\ttraining's binary_logloss: 0.585508\n",
      "[79]\ttraining's binary_logloss: 0.585468\n",
      "[80]\ttraining's binary_logloss: 0.585441\n",
      "[81]\ttraining's binary_logloss: 0.585361\n",
      "[82]\ttraining's binary_logloss: 0.585288\n",
      "[83]\ttraining's binary_logloss: 0.58529\n",
      "[84]\ttraining's binary_logloss: 0.585279\n",
      "[85]\ttraining's binary_logloss: 0.58526\n",
      "[86]\ttraining's binary_logloss: 0.585212\n",
      "[87]\ttraining's binary_logloss: 0.585178\n",
      "[88]\ttraining's binary_logloss: 0.585138\n",
      "[89]\ttraining's binary_logloss: 0.585105\n",
      "[90]\ttraining's binary_logloss: 0.585075\n",
      "[91]\ttraining's binary_logloss: 0.585063\n",
      "[92]\ttraining's binary_logloss: 0.585058\n",
      "[93]\ttraining's binary_logloss: 0.585094\n",
      "[94]\ttraining's binary_logloss: 0.585131\n",
      "[95]\ttraining's binary_logloss: 0.585155\n",
      "[96]\ttraining's binary_logloss: 0.58513\n",
      "[97]\ttraining's binary_logloss: 0.585112\n",
      "[98]\ttraining's binary_logloss: 0.585131\n",
      "[99]\ttraining's binary_logloss: 0.585116\n",
      "[100]\ttraining's binary_logloss: 0.585107\n",
      "[101]\ttraining's binary_logloss: 0.585095\n",
      "[102]\ttraining's binary_logloss: 0.585092\n",
      "[103]\ttraining's binary_logloss: 0.58509\n",
      "[104]\ttraining's binary_logloss: 0.58509\n",
      "[105]\ttraining's binary_logloss: 0.585093\n",
      "[106]\ttraining's binary_logloss: 0.585123\n",
      "[107]\ttraining's binary_logloss: 0.585192\n",
      "[108]\ttraining's binary_logloss: 0.585233\n",
      "[109]\ttraining's binary_logloss: 0.585272\n",
      "[110]\ttraining's binary_logloss: 0.585324\n",
      "[111]\ttraining's binary_logloss: 0.585293\n",
      "[112]\ttraining's binary_logloss: 0.585272\n",
      "[113]\ttraining's binary_logloss: 0.585276\n",
      "[114]\ttraining's binary_logloss: 0.585282\n",
      "[115]\ttraining's binary_logloss: 0.585281\n",
      "[116]\ttraining's binary_logloss: 0.585271\n",
      "[117]\ttraining's binary_logloss: 0.585271\n",
      "[118]\ttraining's binary_logloss: 0.585249\n",
      "[119]\ttraining's binary_logloss: 0.585246\n",
      "[120]\ttraining's binary_logloss: 0.585245\n",
      "[121]\ttraining's binary_logloss: 0.585302\n",
      "[122]\ttraining's binary_logloss: 0.585307\n",
      "[123]\ttraining's binary_logloss: 0.585313\n",
      "[124]\ttraining's binary_logloss: 0.585324\n",
      "[125]\ttraining's binary_logloss: 0.585342\n",
      "[126]\ttraining's binary_logloss: 0.585353\n",
      "[127]\ttraining's binary_logloss: 0.585368\n",
      "[128]\ttraining's binary_logloss: 0.585368\n",
      "[129]\ttraining's binary_logloss: 0.585384\n",
      "[130]\ttraining's binary_logloss: 0.585393\n",
      "[131]\ttraining's binary_logloss: 0.585425\n",
      "[132]\ttraining's binary_logloss: 0.585489\n",
      "[133]\ttraining's binary_logloss: 0.585542\n",
      "[134]\ttraining's binary_logloss: 0.585626\n",
      "[135]\ttraining's binary_logloss: 0.585693\n",
      "[136]\ttraining's binary_logloss: 0.585723\n",
      "[137]\ttraining's binary_logloss: 0.585759\n",
      "[138]\ttraining's binary_logloss: 0.585797\n",
      "[139]\ttraining's binary_logloss: 0.585784\n",
      "[140]\ttraining's binary_logloss: 0.58582\n",
      "[141]\ttraining's binary_logloss: 0.585821\n",
      "[142]\ttraining's binary_logloss: 0.585825\n",
      "[143]\ttraining's binary_logloss: 0.585832\n",
      "[144]\ttraining's binary_logloss: 0.585844\n",
      "[145]\ttraining's binary_logloss: 0.585855\n",
      "[146]\ttraining's binary_logloss: 0.585856\n",
      "[147]\ttraining's binary_logloss: 0.585881\n",
      "[148]\ttraining's binary_logloss: 0.585921\n",
      "[149]\ttraining's binary_logloss: 0.585927\n",
      "[150]\ttraining's binary_logloss: 0.585955\n",
      "[151]\ttraining's binary_logloss: 0.585988\n",
      "[152]\ttraining's binary_logloss: 0.586013\n",
      "[153]\ttraining's binary_logloss: 0.586043\n",
      "[154]\ttraining's binary_logloss: 0.586079\n",
      "[155]\ttraining's binary_logloss: 0.586111\n",
      "[156]\ttraining's binary_logloss: 0.586118\n",
      "[157]\ttraining's binary_logloss: 0.586133\n",
      "[158]\ttraining's binary_logloss: 0.586143\n",
      "[159]\ttraining's binary_logloss: 0.586167\n",
      "[160]\ttraining's binary_logloss: 0.586209\n",
      "[161]\ttraining's binary_logloss: 0.586185\n",
      "[162]\ttraining's binary_logloss: 0.586172\n",
      "[163]\ttraining's binary_logloss: 0.586215\n",
      "[164]\ttraining's binary_logloss: 0.586207\n",
      "[165]\ttraining's binary_logloss: 0.586204\n",
      "[166]\ttraining's binary_logloss: 0.586205\n",
      "[167]\ttraining's binary_logloss: 0.586229\n",
      "[168]\ttraining's binary_logloss: 0.586233\n",
      "[169]\ttraining's binary_logloss: 0.586242\n",
      "[170]\ttraining's binary_logloss: 0.586257\n",
      "[171]\ttraining's binary_logloss: 0.586279\n",
      "[172]\ttraining's binary_logloss: 0.586311\n",
      "[173]\ttraining's binary_logloss: 0.586334\n",
      "[174]\ttraining's binary_logloss: 0.586356\n",
      "[175]\ttraining's binary_logloss: 0.586382\n",
      "[176]\ttraining's binary_logloss: 0.586385\n",
      "[177]\ttraining's binary_logloss: 0.586401\n",
      "[178]\ttraining's binary_logloss: 0.586406\n",
      "[179]\ttraining's binary_logloss: 0.586411\n",
      "[180]\ttraining's binary_logloss: 0.586427\n",
      "[181]\ttraining's binary_logloss: 0.586451\n",
      "[182]\ttraining's binary_logloss: 0.586467\n",
      "[183]\ttraining's binary_logloss: 0.586469\n",
      "[184]\ttraining's binary_logloss: 0.586494\n",
      "[185]\ttraining's binary_logloss: 0.586527\n",
      "[186]\ttraining's binary_logloss: 0.586583\n",
      "[187]\ttraining's binary_logloss: 0.586619\n",
      "[188]\ttraining's binary_logloss: 0.586651\n",
      "[189]\ttraining's binary_logloss: 0.586697\n",
      "[190]\ttraining's binary_logloss: 0.586739\n",
      "[191]\ttraining's binary_logloss: 0.586745\n",
      "[192]\ttraining's binary_logloss: 0.586745\n",
      "[193]\ttraining's binary_logloss: 0.58674\n",
      "[194]\ttraining's binary_logloss: 0.586738\n",
      "[195]\ttraining's binary_logloss: 0.586744\n",
      "[196]\ttraining's binary_logloss: 0.586749\n",
      "[197]\ttraining's binary_logloss: 0.58677\n",
      "[198]\ttraining's binary_logloss: 0.586754\n",
      "[199]\ttraining's binary_logloss: 0.586732\n",
      "[200]\ttraining's binary_logloss: 0.586712\n",
      "[201]\ttraining's binary_logloss: 0.586739\n",
      "[202]\ttraining's binary_logloss: 0.586753\n",
      "[203]\ttraining's binary_logloss: 0.586769\n",
      "[204]\ttraining's binary_logloss: 0.586782\n",
      "[205]\ttraining's binary_logloss: 0.586819\n",
      "[206]\ttraining's binary_logloss: 0.586766\n",
      "[207]\ttraining's binary_logloss: 0.586716\n",
      "[208]\ttraining's binary_logloss: 0.586679\n",
      "[209]\ttraining's binary_logloss: 0.586636\n",
      "[210]\ttraining's binary_logloss: 0.5866\n",
      "[211]\ttraining's binary_logloss: 0.586608\n",
      "[212]\ttraining's binary_logloss: 0.586637\n",
      "[213]\ttraining's binary_logloss: 0.586651\n",
      "[214]\ttraining's binary_logloss: 0.586675\n",
      "[215]\ttraining's binary_logloss: 0.586697\n",
      "[216]\ttraining's binary_logloss: 0.586659\n",
      "[217]\ttraining's binary_logloss: 0.586626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[218]\ttraining's binary_logloss: 0.586606\n",
      "[219]\ttraining's binary_logloss: 0.586564\n",
      "[220]\ttraining's binary_logloss: 0.586541\n",
      "[221]\ttraining's binary_logloss: 0.586504\n",
      "[222]\ttraining's binary_logloss: 0.586471\n",
      "[223]\ttraining's binary_logloss: 0.586438\n",
      "[224]\ttraining's binary_logloss: 0.586402\n",
      "[225]\ttraining's binary_logloss: 0.586389\n",
      "[226]\ttraining's binary_logloss: 0.586375\n",
      "[227]\ttraining's binary_logloss: 0.586352\n",
      "[228]\ttraining's binary_logloss: 0.58631\n",
      "[229]\ttraining's binary_logloss: 0.586289\n",
      "[230]\ttraining's binary_logloss: 0.586267\n",
      "[231]\ttraining's binary_logloss: 0.586266\n",
      "[232]\ttraining's binary_logloss: 0.586242\n",
      "[233]\ttraining's binary_logloss: 0.586241\n",
      "[234]\ttraining's binary_logloss: 0.586242\n",
      "[235]\ttraining's binary_logloss: 0.586241\n",
      "[236]\ttraining's binary_logloss: 0.586204\n",
      "[237]\ttraining's binary_logloss: 0.586163\n",
      "[238]\ttraining's binary_logloss: 0.586133\n",
      "[239]\ttraining's binary_logloss: 0.586114\n",
      "[240]\ttraining's binary_logloss: 0.586085\n",
      "[241]\ttraining's binary_logloss: 0.586074\n",
      "[242]\ttraining's binary_logloss: 0.586069\n",
      "[243]\ttraining's binary_logloss: 0.586066\n",
      "[244]\ttraining's binary_logloss: 0.58606\n",
      "[245]\ttraining's binary_logloss: 0.586055\n",
      "[246]\ttraining's binary_logloss: 0.585994\n",
      "[247]\ttraining's binary_logloss: 0.585927\n",
      "[248]\ttraining's binary_logloss: 0.585855\n",
      "[249]\ttraining's binary_logloss: 0.585786\n",
      "[250]\ttraining's binary_logloss: 0.58573\n",
      "[251]\ttraining's binary_logloss: 0.585661\n",
      "[252]\ttraining's binary_logloss: 0.585619\n",
      "[253]\ttraining's binary_logloss: 0.585537\n",
      "[254]\ttraining's binary_logloss: 0.585498\n",
      "[255]\ttraining's binary_logloss: 0.585442\n",
      "[256]\ttraining's binary_logloss: 0.585411\n",
      "[257]\ttraining's binary_logloss: 0.585386\n",
      "[258]\ttraining's binary_logloss: 0.585362\n",
      "[259]\ttraining's binary_logloss: 0.585315\n",
      "[260]\ttraining's binary_logloss: 0.585299\n",
      "[261]\ttraining's binary_logloss: 0.585308\n",
      "[262]\ttraining's binary_logloss: 0.585317\n",
      "[263]\ttraining's binary_logloss: 0.585326\n",
      "[264]\ttraining's binary_logloss: 0.585337\n",
      "[265]\ttraining's binary_logloss: 0.585305\n",
      "[266]\ttraining's binary_logloss: 0.58531\n",
      "[267]\ttraining's binary_logloss: 0.585305\n",
      "[268]\ttraining's binary_logloss: 0.585287\n",
      "[269]\ttraining's binary_logloss: 0.585289\n",
      "[270]\ttraining's binary_logloss: 0.585279\n",
      "[271]\ttraining's binary_logloss: 0.585247\n",
      "[272]\ttraining's binary_logloss: 0.585217\n",
      "[273]\ttraining's binary_logloss: 0.585191\n",
      "[274]\ttraining's binary_logloss: 0.585181\n",
      "[275]\ttraining's binary_logloss: 0.585154\n",
      "[276]\ttraining's binary_logloss: 0.585096\n",
      "[277]\ttraining's binary_logloss: 0.585046\n",
      "[278]\ttraining's binary_logloss: 0.584999\n",
      "[279]\ttraining's binary_logloss: 0.584952\n",
      "[280]\ttraining's binary_logloss: 0.584916\n",
      "[281]\ttraining's binary_logloss: 0.584897\n",
      "[282]\ttraining's binary_logloss: 0.584893\n",
      "[283]\ttraining's binary_logloss: 0.584863\n",
      "[284]\ttraining's binary_logloss: 0.584839\n",
      "[285]\ttraining's binary_logloss: 0.584822\n",
      "[286]\ttraining's binary_logloss: 0.584773\n",
      "[287]\ttraining's binary_logloss: 0.584708\n",
      "[288]\ttraining's binary_logloss: 0.584661\n",
      "[289]\ttraining's binary_logloss: 0.584612\n",
      "[290]\ttraining's binary_logloss: 0.58455\n",
      "[291]\ttraining's binary_logloss: 0.584485\n",
      "[292]\ttraining's binary_logloss: 0.584402\n",
      "[293]\ttraining's binary_logloss: 0.584327\n",
      "[294]\ttraining's binary_logloss: 0.584251\n",
      "[295]\ttraining's binary_logloss: 0.584175\n",
      "[296]\ttraining's binary_logloss: 0.584134\n",
      "[297]\ttraining's binary_logloss: 0.584099\n",
      "[298]\ttraining's binary_logloss: 0.584063\n",
      "[299]\ttraining's binary_logloss: 0.584027\n",
      "[300]\ttraining's binary_logloss: 0.584004\n",
      "[301]\ttraining's binary_logloss: 0.583958\n",
      "[302]\ttraining's binary_logloss: 0.583918\n",
      "[303]\ttraining's binary_logloss: 0.583873\n",
      "[304]\ttraining's binary_logloss: 0.58383\n",
      "[305]\ttraining's binary_logloss: 0.583779\n",
      "[306]\ttraining's binary_logloss: 0.583725\n",
      "[307]\ttraining's binary_logloss: 0.583668\n",
      "[308]\ttraining's binary_logloss: 0.583605\n",
      "[309]\ttraining's binary_logloss: 0.583558\n",
      "[310]\ttraining's binary_logloss: 0.583504\n",
      "[311]\ttraining's binary_logloss: 0.583441\n",
      "[312]\ttraining's binary_logloss: 0.583375\n",
      "[313]\ttraining's binary_logloss: 0.583316\n",
      "[314]\ttraining's binary_logloss: 0.583264\n",
      "[315]\ttraining's binary_logloss: 0.583213\n",
      "[316]\ttraining's binary_logloss: 0.583178\n",
      "[317]\ttraining's binary_logloss: 0.583127\n",
      "[318]\ttraining's binary_logloss: 0.583076\n",
      "[319]\ttraining's binary_logloss: 0.583027\n",
      "[320]\ttraining's binary_logloss: 0.582971\n",
      "[321]\ttraining's binary_logloss: 0.582916\n",
      "[322]\ttraining's binary_logloss: 0.582874\n",
      "[323]\ttraining's binary_logloss: 0.582829\n",
      "[324]\ttraining's binary_logloss: 0.582768\n",
      "[325]\ttraining's binary_logloss: 0.582727\n",
      "[326]\ttraining's binary_logloss: 0.582652\n",
      "[327]\ttraining's binary_logloss: 0.582579\n",
      "[328]\ttraining's binary_logloss: 0.582508\n",
      "[329]\ttraining's binary_logloss: 0.58242\n",
      "[330]\ttraining's binary_logloss: 0.582344\n",
      "[331]\ttraining's binary_logloss: 0.582291\n",
      "[332]\ttraining's binary_logloss: 0.582236\n",
      "[333]\ttraining's binary_logloss: 0.582192\n",
      "[334]\ttraining's binary_logloss: 0.582136\n",
      "[335]\ttraining's binary_logloss: 0.582077\n",
      "[336]\ttraining's binary_logloss: 0.582046\n",
      "[337]\ttraining's binary_logloss: 0.582019\n",
      "[338]\ttraining's binary_logloss: 0.581989\n",
      "[339]\ttraining's binary_logloss: 0.581956\n",
      "[340]\ttraining's binary_logloss: 0.581928\n",
      "[341]\ttraining's binary_logloss: 0.581877\n",
      "[342]\ttraining's binary_logloss: 0.581828\n",
      "[343]\ttraining's binary_logloss: 0.581781\n",
      "[344]\ttraining's binary_logloss: 0.581739\n",
      "[345]\ttraining's binary_logloss: 0.581692\n",
      "[346]\ttraining's binary_logloss: 0.581619\n",
      "[347]\ttraining's binary_logloss: 0.58155\n",
      "[348]\ttraining's binary_logloss: 0.581484\n",
      "[349]\ttraining's binary_logloss: 0.581417\n",
      "[350]\ttraining's binary_logloss: 0.581344\n",
      "[351]\ttraining's binary_logloss: 0.581309\n",
      "[352]\ttraining's binary_logloss: 0.581275\n",
      "[353]\ttraining's binary_logloss: 0.581243\n",
      "[354]\ttraining's binary_logloss: 0.581215\n",
      "[355]\ttraining's binary_logloss: 0.581185\n",
      "[356]\ttraining's binary_logloss: 0.581139\n",
      "[357]\ttraining's binary_logloss: 0.581066\n",
      "[358]\ttraining's binary_logloss: 0.581022\n",
      "[359]\ttraining's binary_logloss: 0.580958\n",
      "[360]\ttraining's binary_logloss: 0.580897\n",
      "[361]\ttraining's binary_logloss: 0.580824\n",
      "[362]\ttraining's binary_logloss: 0.580755\n",
      "[363]\ttraining's binary_logloss: 0.580685\n",
      "[364]\ttraining's binary_logloss: 0.580617\n",
      "[365]\ttraining's binary_logloss: 0.58055\n",
      "[366]\ttraining's binary_logloss: 0.580503\n",
      "[367]\ttraining's binary_logloss: 0.58045\n",
      "[368]\ttraining's binary_logloss: 0.58039\n",
      "[369]\ttraining's binary_logloss: 0.580331\n",
      "[370]\ttraining's binary_logloss: 0.58027\n",
      "[371]\ttraining's binary_logloss: 0.580192\n",
      "[372]\ttraining's binary_logloss: 0.580117\n",
      "[373]\ttraining's binary_logloss: 0.580039\n",
      "[374]\ttraining's binary_logloss: 0.579963\n",
      "[375]\ttraining's binary_logloss: 0.579891\n",
      "[376]\ttraining's binary_logloss: 0.579828\n",
      "[377]\ttraining's binary_logloss: 0.579759\n",
      "[378]\ttraining's binary_logloss: 0.579694\n",
      "[379]\ttraining's binary_logloss: 0.579636\n",
      "[380]\ttraining's binary_logloss: 0.579571\n",
      "[381]\ttraining's binary_logloss: 0.579475\n",
      "[382]\ttraining's binary_logloss: 0.579389\n",
      "[383]\ttraining's binary_logloss: 0.579304\n",
      "[384]\ttraining's binary_logloss: 0.579211\n",
      "[385]\ttraining's binary_logloss: 0.579127\n",
      "[386]\ttraining's binary_logloss: 0.579057\n",
      "[387]\ttraining's binary_logloss: 0.578979\n",
      "[388]\ttraining's binary_logloss: 0.578912\n",
      "[389]\ttraining's binary_logloss: 0.578836\n",
      "[390]\ttraining's binary_logloss: 0.578751\n",
      "[391]\ttraining's binary_logloss: 0.578662\n",
      "[392]\ttraining's binary_logloss: 0.578578\n",
      "[393]\ttraining's binary_logloss: 0.5785\n",
      "[394]\ttraining's binary_logloss: 0.578424\n",
      "[395]\ttraining's binary_logloss: 0.57833\n",
      "[396]\ttraining's binary_logloss: 0.578286\n",
      "[397]\ttraining's binary_logloss: 0.578242\n",
      "[398]\ttraining's binary_logloss: 0.578202\n",
      "[399]\ttraining's binary_logloss: 0.578163\n",
      "[400]\ttraining's binary_logloss: 0.578116\n",
      "[401]\ttraining's binary_logloss: 0.578038\n",
      "[402]\ttraining's binary_logloss: 0.577962\n",
      "[403]\ttraining's binary_logloss: 0.577892\n",
      "[404]\ttraining's binary_logloss: 0.577818\n",
      "[405]\ttraining's binary_logloss: 0.577741\n",
      "[406]\ttraining's binary_logloss: 0.577686\n",
      "[407]\ttraining's binary_logloss: 0.577645\n",
      "[408]\ttraining's binary_logloss: 0.577587\n",
      "[409]\ttraining's binary_logloss: 0.577505\n",
      "[410]\ttraining's binary_logloss: 0.577419\n",
      "[411]\ttraining's binary_logloss: 0.577336\n",
      "[412]\ttraining's binary_logloss: 0.577256\n",
      "[413]\ttraining's binary_logloss: 0.57717\n",
      "[414]\ttraining's binary_logloss: 0.577086\n",
      "[415]\ttraining's binary_logloss: 0.577018\n",
      "[416]\ttraining's binary_logloss: 0.576936\n",
      "[417]\ttraining's binary_logloss: 0.576862\n",
      "[418]\ttraining's binary_logloss: 0.57679\n",
      "[419]\ttraining's binary_logloss: 0.576712\n",
      "[420]\ttraining's binary_logloss: 0.576641\n",
      "[421]\ttraining's binary_logloss: 0.57659\n",
      "[422]\ttraining's binary_logloss: 0.576541\n",
      "[423]\ttraining's binary_logloss: 0.576497\n",
      "[424]\ttraining's binary_logloss: 0.576446\n",
      "[425]\ttraining's binary_logloss: 0.576393\n",
      "[426]\ttraining's binary_logloss: 0.576325\n",
      "[427]\ttraining's binary_logloss: 0.57626\n",
      "[428]\ttraining's binary_logloss: 0.576197\n",
      "[429]\ttraining's binary_logloss: 0.576135\n",
      "[430]\ttraining's binary_logloss: 0.57607\n",
      "[431]\ttraining's binary_logloss: 0.576007\n",
      "[432]\ttraining's binary_logloss: 0.575939\n",
      "[433]\ttraining's binary_logloss: 0.575865\n",
      "[434]\ttraining's binary_logloss: 0.575791\n",
      "[435]\ttraining's binary_logloss: 0.575725\n",
      "[436]\ttraining's binary_logloss: 0.575654\n",
      "[437]\ttraining's binary_logloss: 0.575597\n",
      "[438]\ttraining's binary_logloss: 0.575528\n",
      "[439]\ttraining's binary_logloss: 0.575473\n",
      "[440]\ttraining's binary_logloss: 0.575417\n",
      "[441]\ttraining's binary_logloss: 0.575352\n",
      "[442]\ttraining's binary_logloss: 0.575298\n",
      "[443]\ttraining's binary_logloss: 0.575232\n",
      "[444]\ttraining's binary_logloss: 0.57516\n",
      "[445]\ttraining's binary_logloss: 0.575093\n",
      "[446]\ttraining's binary_logloss: 0.575008\n",
      "[447]\ttraining's binary_logloss: 0.574914\n",
      "[448]\ttraining's binary_logloss: 0.574829\n",
      "[449]\ttraining's binary_logloss: 0.574734\n",
      "[450]\ttraining's binary_logloss: 0.574625\n",
      "[451]\ttraining's binary_logloss: 0.574526\n",
      "[452]\ttraining's binary_logloss: 0.574431\n",
      "[453]\ttraining's binary_logloss: 0.574334\n",
      "[454]\ttraining's binary_logloss: 0.574249\n",
      "[455]\ttraining's binary_logloss: 0.574168\n",
      "[456]\ttraining's binary_logloss: 0.574101\n",
      "[457]\ttraining's binary_logloss: 0.574008\n",
      "[458]\ttraining's binary_logloss: 0.573918\n",
      "[459]\ttraining's binary_logloss: 0.57383\n",
      "[460]\ttraining's binary_logloss: 0.573763\n",
      "[461]\ttraining's binary_logloss: 0.573684\n",
      "[462]\ttraining's binary_logloss: 0.573604\n",
      "[463]\ttraining's binary_logloss: 0.57353\n",
      "[464]\ttraining's binary_logloss: 0.573451\n",
      "[465]\ttraining's binary_logloss: 0.573375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[466]\ttraining's binary_logloss: 0.573299\n",
      "[467]\ttraining's binary_logloss: 0.573226\n",
      "[468]\ttraining's binary_logloss: 0.573158\n",
      "[469]\ttraining's binary_logloss: 0.573096\n",
      "[470]\ttraining's binary_logloss: 0.573026\n",
      "[471]\ttraining's binary_logloss: 0.572927\n",
      "[472]\ttraining's binary_logloss: 0.57283\n",
      "[473]\ttraining's binary_logloss: 0.572731\n",
      "[474]\ttraining's binary_logloss: 0.572645\n",
      "[475]\ttraining's binary_logloss: 0.572551\n",
      "[476]\ttraining's binary_logloss: 0.572472\n",
      "[477]\ttraining's binary_logloss: 0.572412\n",
      "[478]\ttraining's binary_logloss: 0.572335\n",
      "[479]\ttraining's binary_logloss: 0.572279\n",
      "[480]\ttraining's binary_logloss: 0.57222\n",
      "[481]\ttraining's binary_logloss: 0.572173\n",
      "[482]\ttraining's binary_logloss: 0.572122\n",
      "[483]\ttraining's binary_logloss: 0.572077\n",
      "[484]\ttraining's binary_logloss: 0.572037\n",
      "[485]\ttraining's binary_logloss: 0.572002\n",
      "[486]\ttraining's binary_logloss: 0.571893\n",
      "[487]\ttraining's binary_logloss: 0.571801\n",
      "[488]\ttraining's binary_logloss: 0.57171\n",
      "[489]\ttraining's binary_logloss: 0.571618\n",
      "[490]\ttraining's binary_logloss: 0.571528\n",
      "[491]\ttraining's binary_logloss: 0.571431\n",
      "[492]\ttraining's binary_logloss: 0.571335\n",
      "[493]\ttraining's binary_logloss: 0.57124\n",
      "[494]\ttraining's binary_logloss: 0.571145\n",
      "[495]\ttraining's binary_logloss: 0.571053\n",
      "[496]\ttraining's binary_logloss: 0.57096\n",
      "[497]\ttraining's binary_logloss: 0.570883\n",
      "[498]\ttraining's binary_logloss: 0.570813\n",
      "[499]\ttraining's binary_logloss: 0.570751\n",
      "[500]\ttraining's binary_logloss: 0.57067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614676\n",
      "[2]\ttraining's binary_logloss: 0.61358\n",
      "[3]\ttraining's binary_logloss: 0.612584\n",
      "[4]\ttraining's binary_logloss: 0.611584\n",
      "[5]\ttraining's binary_logloss: 0.610567\n",
      "[6]\ttraining's binary_logloss: 0.609578\n",
      "[7]\ttraining's binary_logloss: 0.608663\n",
      "[8]\ttraining's binary_logloss: 0.607848\n",
      "[9]\ttraining's binary_logloss: 0.607022\n",
      "[10]\ttraining's binary_logloss: 0.606174\n",
      "[11]\ttraining's binary_logloss: 0.6054\n",
      "[12]\ttraining's binary_logloss: 0.604613\n",
      "[13]\ttraining's binary_logloss: 0.603966\n",
      "[14]\ttraining's binary_logloss: 0.603329\n",
      "[15]\ttraining's binary_logloss: 0.60271\n",
      "[16]\ttraining's binary_logloss: 0.602007\n",
      "[17]\ttraining's binary_logloss: 0.601332\n",
      "[18]\ttraining's binary_logloss: 0.600687\n",
      "[19]\ttraining's binary_logloss: 0.600068\n",
      "[20]\ttraining's binary_logloss: 0.599476\n",
      "[21]\ttraining's binary_logloss: 0.598959\n",
      "[22]\ttraining's binary_logloss: 0.598456\n",
      "[23]\ttraining's binary_logloss: 0.597979\n",
      "[24]\ttraining's binary_logloss: 0.597498\n",
      "[25]\ttraining's binary_logloss: 0.597054\n",
      "[26]\ttraining's binary_logloss: 0.596577\n",
      "[27]\ttraining's binary_logloss: 0.596104\n",
      "[28]\ttraining's binary_logloss: 0.595642\n",
      "[29]\ttraining's binary_logloss: 0.595218\n",
      "[30]\ttraining's binary_logloss: 0.594853\n",
      "[31]\ttraining's binary_logloss: 0.594427\n",
      "[32]\ttraining's binary_logloss: 0.594108\n",
      "[33]\ttraining's binary_logloss: 0.593731\n",
      "[34]\ttraining's binary_logloss: 0.593364\n",
      "[35]\ttraining's binary_logloss: 0.593026\n",
      "[36]\ttraining's binary_logloss: 0.592697\n",
      "[37]\ttraining's binary_logloss: 0.592383\n",
      "[38]\ttraining's binary_logloss: 0.592084\n",
      "[39]\ttraining's binary_logloss: 0.591797\n",
      "[40]\ttraining's binary_logloss: 0.591561\n",
      "[41]\ttraining's binary_logloss: 0.591275\n",
      "[42]\ttraining's binary_logloss: 0.591044\n",
      "[43]\ttraining's binary_logloss: 0.590782\n",
      "[44]\ttraining's binary_logloss: 0.590521\n",
      "[45]\ttraining's binary_logloss: 0.590273\n",
      "[46]\ttraining's binary_logloss: 0.590058\n",
      "[47]\ttraining's binary_logloss: 0.589806\n",
      "[48]\ttraining's binary_logloss: 0.589572\n",
      "[49]\ttraining's binary_logloss: 0.589351\n",
      "[50]\ttraining's binary_logloss: 0.589135\n",
      "[51]\ttraining's binary_logloss: 0.588985\n",
      "[52]\ttraining's binary_logloss: 0.588787\n",
      "[53]\ttraining's binary_logloss: 0.588636\n",
      "[54]\ttraining's binary_logloss: 0.588464\n",
      "[55]\ttraining's binary_logloss: 0.588352\n",
      "[56]\ttraining's binary_logloss: 0.588158\n",
      "[57]\ttraining's binary_logloss: 0.58797\n",
      "[58]\ttraining's binary_logloss: 0.587791\n",
      "[59]\ttraining's binary_logloss: 0.587614\n",
      "[60]\ttraining's binary_logloss: 0.587444\n",
      "[61]\ttraining's binary_logloss: 0.587349\n",
      "[62]\ttraining's binary_logloss: 0.58729\n",
      "[63]\ttraining's binary_logloss: 0.587209\n",
      "[64]\ttraining's binary_logloss: 0.587146\n",
      "[65]\ttraining's binary_logloss: 0.587083\n",
      "[66]\ttraining's binary_logloss: 0.587027\n",
      "[67]\ttraining's binary_logloss: 0.586973\n",
      "[68]\ttraining's binary_logloss: 0.586917\n",
      "[69]\ttraining's binary_logloss: 0.586842\n",
      "[70]\ttraining's binary_logloss: 0.586805\n",
      "[71]\ttraining's binary_logloss: 0.586737\n",
      "[72]\ttraining's binary_logloss: 0.586695\n",
      "[73]\ttraining's binary_logloss: 0.586659\n",
      "[74]\ttraining's binary_logloss: 0.586599\n",
      "[75]\ttraining's binary_logloss: 0.586604\n",
      "[76]\ttraining's binary_logloss: 0.586523\n",
      "[77]\ttraining's binary_logloss: 0.586479\n",
      "[78]\ttraining's binary_logloss: 0.586471\n",
      "[79]\ttraining's binary_logloss: 0.586436\n",
      "[80]\ttraining's binary_logloss: 0.58642\n",
      "[81]\ttraining's binary_logloss: 0.586343\n",
      "[82]\ttraining's binary_logloss: 0.58627\n",
      "[83]\ttraining's binary_logloss: 0.586206\n",
      "[84]\ttraining's binary_logloss: 0.586197\n",
      "[85]\ttraining's binary_logloss: 0.586198\n",
      "[86]\ttraining's binary_logloss: 0.586151\n",
      "[87]\ttraining's binary_logloss: 0.58611\n",
      "[88]\ttraining's binary_logloss: 0.586129\n",
      "[89]\ttraining's binary_logloss: 0.586092\n",
      "[90]\ttraining's binary_logloss: 0.586063\n",
      "[91]\ttraining's binary_logloss: 0.586075\n",
      "[92]\ttraining's binary_logloss: 0.586111\n",
      "[93]\ttraining's binary_logloss: 0.58612\n",
      "[94]\ttraining's binary_logloss: 0.58617\n",
      "[95]\ttraining's binary_logloss: 0.586183\n",
      "[96]\ttraining's binary_logloss: 0.586163\n",
      "[97]\ttraining's binary_logloss: 0.586142\n",
      "[98]\ttraining's binary_logloss: 0.586134\n",
      "[99]\ttraining's binary_logloss: 0.586112\n",
      "[100]\ttraining's binary_logloss: 0.586116\n",
      "[101]\ttraining's binary_logloss: 0.586091\n",
      "[102]\ttraining's binary_logloss: 0.58608\n",
      "[103]\ttraining's binary_logloss: 0.586073\n",
      "[104]\ttraining's binary_logloss: 0.586069\n",
      "[105]\ttraining's binary_logloss: 0.586071\n",
      "[106]\ttraining's binary_logloss: 0.58611\n",
      "[107]\ttraining's binary_logloss: 0.586134\n",
      "[108]\ttraining's binary_logloss: 0.586129\n",
      "[109]\ttraining's binary_logloss: 0.586172\n",
      "[110]\ttraining's binary_logloss: 0.586175\n",
      "[111]\ttraining's binary_logloss: 0.58616\n",
      "[112]\ttraining's binary_logloss: 0.58615\n",
      "[113]\ttraining's binary_logloss: 0.58615\n",
      "[114]\ttraining's binary_logloss: 0.586148\n",
      "[115]\ttraining's binary_logloss: 0.58616\n",
      "[116]\ttraining's binary_logloss: 0.586133\n",
      "[117]\ttraining's binary_logloss: 0.586115\n",
      "[118]\ttraining's binary_logloss: 0.586108\n",
      "[119]\ttraining's binary_logloss: 0.586144\n",
      "[120]\ttraining's binary_logloss: 0.586192\n",
      "[121]\ttraining's binary_logloss: 0.586199\n",
      "[122]\ttraining's binary_logloss: 0.586261\n",
      "[123]\ttraining's binary_logloss: 0.586279\n",
      "[124]\ttraining's binary_logloss: 0.586295\n",
      "[125]\ttraining's binary_logloss: 0.586328\n",
      "[126]\ttraining's binary_logloss: 0.586338\n",
      "[127]\ttraining's binary_logloss: 0.586349\n",
      "[128]\ttraining's binary_logloss: 0.586372\n",
      "[129]\ttraining's binary_logloss: 0.586385\n",
      "[130]\ttraining's binary_logloss: 0.586376\n",
      "[131]\ttraining's binary_logloss: 0.58644\n",
      "[132]\ttraining's binary_logloss: 0.586509\n",
      "[133]\ttraining's binary_logloss: 0.586592\n",
      "[134]\ttraining's binary_logloss: 0.586642\n",
      "[135]\ttraining's binary_logloss: 0.586716\n",
      "[136]\ttraining's binary_logloss: 0.586757\n",
      "[137]\ttraining's binary_logloss: 0.5868\n",
      "[138]\ttraining's binary_logloss: 0.586831\n",
      "[139]\ttraining's binary_logloss: 0.586836\n",
      "[140]\ttraining's binary_logloss: 0.586874\n",
      "[141]\ttraining's binary_logloss: 0.58687\n",
      "[142]\ttraining's binary_logloss: 0.586864\n",
      "[143]\ttraining's binary_logloss: 0.586866\n",
      "[144]\ttraining's binary_logloss: 0.586871\n",
      "[145]\ttraining's binary_logloss: 0.586878\n",
      "[146]\ttraining's binary_logloss: 0.586884\n",
      "[147]\ttraining's binary_logloss: 0.586912\n",
      "[148]\ttraining's binary_logloss: 0.586941\n",
      "[149]\ttraining's binary_logloss: 0.586968\n",
      "[150]\ttraining's binary_logloss: 0.586994\n",
      "[151]\ttraining's binary_logloss: 0.587016\n",
      "[152]\ttraining's binary_logloss: 0.587047\n",
      "[153]\ttraining's binary_logloss: 0.587066\n",
      "[154]\ttraining's binary_logloss: 0.58709\n",
      "[155]\ttraining's binary_logloss: 0.587143\n",
      "[156]\ttraining's binary_logloss: 0.587143\n",
      "[157]\ttraining's binary_logloss: 0.587148\n",
      "[158]\ttraining's binary_logloss: 0.587166\n",
      "[159]\ttraining's binary_logloss: 0.587202\n",
      "[160]\ttraining's binary_logloss: 0.58725\n",
      "[161]\ttraining's binary_logloss: 0.587246\n",
      "[162]\ttraining's binary_logloss: 0.587241\n",
      "[163]\ttraining's binary_logloss: 0.587272\n",
      "[164]\ttraining's binary_logloss: 0.587271\n",
      "[165]\ttraining's binary_logloss: 0.587272\n",
      "[166]\ttraining's binary_logloss: 0.587276\n",
      "[167]\ttraining's binary_logloss: 0.587296\n",
      "[168]\ttraining's binary_logloss: 0.587305\n",
      "[169]\ttraining's binary_logloss: 0.587301\n",
      "[170]\ttraining's binary_logloss: 0.587328\n",
      "[171]\ttraining's binary_logloss: 0.587354\n",
      "[172]\ttraining's binary_logloss: 0.587376\n",
      "[173]\ttraining's binary_logloss: 0.587405\n",
      "[174]\ttraining's binary_logloss: 0.587438\n",
      "[175]\ttraining's binary_logloss: 0.587453\n",
      "[176]\ttraining's binary_logloss: 0.587453\n",
      "[177]\ttraining's binary_logloss: 0.587445\n",
      "[178]\ttraining's binary_logloss: 0.587453\n",
      "[179]\ttraining's binary_logloss: 0.587452\n",
      "[180]\ttraining's binary_logloss: 0.587443\n",
      "[181]\ttraining's binary_logloss: 0.587448\n",
      "[182]\ttraining's binary_logloss: 0.587467\n",
      "[183]\ttraining's binary_logloss: 0.587481\n",
      "[184]\ttraining's binary_logloss: 0.5875\n",
      "[185]\ttraining's binary_logloss: 0.587497\n",
      "[186]\ttraining's binary_logloss: 0.587525\n",
      "[187]\ttraining's binary_logloss: 0.587561\n",
      "[188]\ttraining's binary_logloss: 0.587604\n",
      "[189]\ttraining's binary_logloss: 0.587623\n",
      "[190]\ttraining's binary_logloss: 0.587653\n",
      "[191]\ttraining's binary_logloss: 0.587649\n",
      "[192]\ttraining's binary_logloss: 0.587646\n",
      "[193]\ttraining's binary_logloss: 0.587643\n",
      "[194]\ttraining's binary_logloss: 0.587619\n",
      "[195]\ttraining's binary_logloss: 0.587627\n",
      "[196]\ttraining's binary_logloss: 0.587619\n",
      "[197]\ttraining's binary_logloss: 0.587614\n",
      "[198]\ttraining's binary_logloss: 0.587607\n",
      "[199]\ttraining's binary_logloss: 0.587629\n",
      "[200]\ttraining's binary_logloss: 0.587616\n",
      "[201]\ttraining's binary_logloss: 0.587634\n",
      "[202]\ttraining's binary_logloss: 0.587645\n",
      "[203]\ttraining's binary_logloss: 0.587653\n",
      "[204]\ttraining's binary_logloss: 0.587663\n",
      "[205]\ttraining's binary_logloss: 0.587665\n",
      "[206]\ttraining's binary_logloss: 0.587619\n",
      "[207]\ttraining's binary_logloss: 0.587574\n",
      "[208]\ttraining's binary_logloss: 0.587539\n",
      "[209]\ttraining's binary_logloss: 0.587505\n",
      "[210]\ttraining's binary_logloss: 0.587463\n",
      "[211]\ttraining's binary_logloss: 0.587504\n",
      "[212]\ttraining's binary_logloss: 0.587518\n",
      "[213]\ttraining's binary_logloss: 0.587547\n",
      "[214]\ttraining's binary_logloss: 0.587564\n",
      "[215]\ttraining's binary_logloss: 0.587585\n",
      "[216]\ttraining's binary_logloss: 0.58756\n",
      "[217]\ttraining's binary_logloss: 0.587532\n",
      "[218]\ttraining's binary_logloss: 0.587513\n",
      "[219]\ttraining's binary_logloss: 0.587473\n",
      "[220]\ttraining's binary_logloss: 0.587455\n",
      "[221]\ttraining's binary_logloss: 0.587427\n",
      "[222]\ttraining's binary_logloss: 0.587408\n",
      "[223]\ttraining's binary_logloss: 0.587396\n",
      "[224]\ttraining's binary_logloss: 0.587369\n",
      "[225]\ttraining's binary_logloss: 0.587344\n",
      "[226]\ttraining's binary_logloss: 0.587323\n",
      "[227]\ttraining's binary_logloss: 0.587299\n",
      "[228]\ttraining's binary_logloss: 0.587279\n",
      "[229]\ttraining's binary_logloss: 0.58726\n",
      "[230]\ttraining's binary_logloss: 0.587246\n",
      "[231]\ttraining's binary_logloss: 0.587247\n",
      "[232]\ttraining's binary_logloss: 0.58725\n",
      "[233]\ttraining's binary_logloss: 0.587252\n",
      "[234]\ttraining's binary_logloss: 0.587254\n",
      "[235]\ttraining's binary_logloss: 0.587256\n",
      "[236]\ttraining's binary_logloss: 0.587236\n",
      "[237]\ttraining's binary_logloss: 0.587206\n",
      "[238]\ttraining's binary_logloss: 0.587179\n",
      "[239]\ttraining's binary_logloss: 0.587154\n",
      "[240]\ttraining's binary_logloss: 0.587122\n",
      "[241]\ttraining's binary_logloss: 0.587112\n",
      "[242]\ttraining's binary_logloss: 0.587081\n",
      "[243]\ttraining's binary_logloss: 0.58708\n",
      "[244]\ttraining's binary_logloss: 0.58708\n",
      "[245]\ttraining's binary_logloss: 0.587077\n",
      "[246]\ttraining's binary_logloss: 0.587017\n",
      "[247]\ttraining's binary_logloss: 0.586951\n",
      "[248]\ttraining's binary_logloss: 0.586875\n",
      "[249]\ttraining's binary_logloss: 0.586815\n",
      "[250]\ttraining's binary_logloss: 0.586742\n",
      "[251]\ttraining's binary_logloss: 0.586689\n",
      "[252]\ttraining's binary_logloss: 0.586649\n",
      "[253]\ttraining's binary_logloss: 0.586614\n",
      "[254]\ttraining's binary_logloss: 0.586576\n",
      "[255]\ttraining's binary_logloss: 0.586531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256]\ttraining's binary_logloss: 0.586509\n",
      "[257]\ttraining's binary_logloss: 0.586484\n",
      "[258]\ttraining's binary_logloss: 0.586462\n",
      "[259]\ttraining's binary_logloss: 0.58644\n",
      "[260]\ttraining's binary_logloss: 0.58642\n",
      "[261]\ttraining's binary_logloss: 0.586401\n",
      "[262]\ttraining's binary_logloss: 0.586412\n",
      "[263]\ttraining's binary_logloss: 0.586399\n",
      "[264]\ttraining's binary_logloss: 0.586407\n",
      "[265]\ttraining's binary_logloss: 0.586356\n",
      "[266]\ttraining's binary_logloss: 0.586345\n",
      "[267]\ttraining's binary_logloss: 0.586336\n",
      "[268]\ttraining's binary_logloss: 0.586326\n",
      "[269]\ttraining's binary_logloss: 0.586324\n",
      "[270]\ttraining's binary_logloss: 0.586316\n",
      "[271]\ttraining's binary_logloss: 0.586278\n",
      "[272]\ttraining's binary_logloss: 0.586231\n",
      "[273]\ttraining's binary_logloss: 0.586196\n",
      "[274]\ttraining's binary_logloss: 0.586152\n",
      "[275]\ttraining's binary_logloss: 0.586105\n",
      "[276]\ttraining's binary_logloss: 0.586056\n",
      "[277]\ttraining's binary_logloss: 0.586015\n",
      "[278]\ttraining's binary_logloss: 0.585968\n",
      "[279]\ttraining's binary_logloss: 0.585917\n",
      "[280]\ttraining's binary_logloss: 0.585876\n",
      "[281]\ttraining's binary_logloss: 0.585848\n",
      "[282]\ttraining's binary_logloss: 0.585836\n",
      "[283]\ttraining's binary_logloss: 0.585815\n",
      "[284]\ttraining's binary_logloss: 0.585811\n",
      "[285]\ttraining's binary_logloss: 0.585801\n",
      "[286]\ttraining's binary_logloss: 0.585745\n",
      "[287]\ttraining's binary_logloss: 0.585703\n",
      "[288]\ttraining's binary_logloss: 0.585654\n",
      "[289]\ttraining's binary_logloss: 0.585594\n",
      "[290]\ttraining's binary_logloss: 0.585537\n",
      "[291]\ttraining's binary_logloss: 0.585457\n",
      "[292]\ttraining's binary_logloss: 0.585374\n",
      "[293]\ttraining's binary_logloss: 0.585293\n",
      "[294]\ttraining's binary_logloss: 0.585212\n",
      "[295]\ttraining's binary_logloss: 0.585133\n",
      "[296]\ttraining's binary_logloss: 0.585098\n",
      "[297]\ttraining's binary_logloss: 0.5851\n",
      "[298]\ttraining's binary_logloss: 0.585065\n",
      "[299]\ttraining's binary_logloss: 0.585023\n",
      "[300]\ttraining's binary_logloss: 0.584992\n",
      "[301]\ttraining's binary_logloss: 0.584943\n",
      "[302]\ttraining's binary_logloss: 0.584869\n",
      "[303]\ttraining's binary_logloss: 0.584823\n",
      "[304]\ttraining's binary_logloss: 0.584778\n",
      "[305]\ttraining's binary_logloss: 0.584728\n",
      "[306]\ttraining's binary_logloss: 0.584691\n",
      "[307]\ttraining's binary_logloss: 0.584627\n",
      "[308]\ttraining's binary_logloss: 0.584573\n",
      "[309]\ttraining's binary_logloss: 0.58453\n",
      "[310]\ttraining's binary_logloss: 0.584471\n",
      "[311]\ttraining's binary_logloss: 0.584401\n",
      "[312]\ttraining's binary_logloss: 0.584343\n",
      "[313]\ttraining's binary_logloss: 0.584293\n",
      "[314]\ttraining's binary_logloss: 0.584241\n",
      "[315]\ttraining's binary_logloss: 0.584182\n",
      "[316]\ttraining's binary_logloss: 0.584124\n",
      "[317]\ttraining's binary_logloss: 0.584069\n",
      "[318]\ttraining's binary_logloss: 0.584018\n",
      "[319]\ttraining's binary_logloss: 0.58396\n",
      "[320]\ttraining's binary_logloss: 0.583908\n",
      "[321]\ttraining's binary_logloss: 0.58385\n",
      "[322]\ttraining's binary_logloss: 0.583797\n",
      "[323]\ttraining's binary_logloss: 0.583755\n",
      "[324]\ttraining's binary_logloss: 0.583699\n",
      "[325]\ttraining's binary_logloss: 0.583662\n",
      "[326]\ttraining's binary_logloss: 0.583582\n",
      "[327]\ttraining's binary_logloss: 0.583496\n",
      "[328]\ttraining's binary_logloss: 0.583428\n",
      "[329]\ttraining's binary_logloss: 0.583349\n",
      "[330]\ttraining's binary_logloss: 0.58327\n",
      "[331]\ttraining's binary_logloss: 0.583209\n",
      "[332]\ttraining's binary_logloss: 0.583146\n",
      "[333]\ttraining's binary_logloss: 0.583089\n",
      "[334]\ttraining's binary_logloss: 0.58304\n",
      "[335]\ttraining's binary_logloss: 0.58299\n",
      "[336]\ttraining's binary_logloss: 0.582967\n",
      "[337]\ttraining's binary_logloss: 0.582944\n",
      "[338]\ttraining's binary_logloss: 0.582907\n",
      "[339]\ttraining's binary_logloss: 0.582883\n",
      "[340]\ttraining's binary_logloss: 0.582854\n",
      "[341]\ttraining's binary_logloss: 0.582824\n",
      "[342]\ttraining's binary_logloss: 0.582788\n",
      "[343]\ttraining's binary_logloss: 0.582747\n",
      "[344]\ttraining's binary_logloss: 0.582707\n",
      "[345]\ttraining's binary_logloss: 0.582654\n",
      "[346]\ttraining's binary_logloss: 0.582616\n",
      "[347]\ttraining's binary_logloss: 0.582545\n",
      "[348]\ttraining's binary_logloss: 0.582475\n",
      "[349]\ttraining's binary_logloss: 0.582406\n",
      "[350]\ttraining's binary_logloss: 0.582342\n",
      "[351]\ttraining's binary_logloss: 0.582321\n",
      "[352]\ttraining's binary_logloss: 0.582281\n",
      "[353]\ttraining's binary_logloss: 0.582252\n",
      "[354]\ttraining's binary_logloss: 0.582234\n",
      "[355]\ttraining's binary_logloss: 0.582217\n",
      "[356]\ttraining's binary_logloss: 0.582173\n",
      "[357]\ttraining's binary_logloss: 0.582116\n",
      "[358]\ttraining's binary_logloss: 0.582074\n",
      "[359]\ttraining's binary_logloss: 0.582023\n",
      "[360]\ttraining's binary_logloss: 0.581981\n",
      "[361]\ttraining's binary_logloss: 0.581908\n",
      "[362]\ttraining's binary_logloss: 0.581849\n",
      "[363]\ttraining's binary_logloss: 0.581777\n",
      "[364]\ttraining's binary_logloss: 0.581714\n",
      "[365]\ttraining's binary_logloss: 0.581644\n",
      "[366]\ttraining's binary_logloss: 0.581599\n",
      "[367]\ttraining's binary_logloss: 0.581555\n",
      "[368]\ttraining's binary_logloss: 0.581508\n",
      "[369]\ttraining's binary_logloss: 0.581467\n",
      "[370]\ttraining's binary_logloss: 0.581421\n",
      "[371]\ttraining's binary_logloss: 0.581357\n",
      "[372]\ttraining's binary_logloss: 0.581283\n",
      "[373]\ttraining's binary_logloss: 0.58122\n",
      "[374]\ttraining's binary_logloss: 0.581148\n",
      "[375]\ttraining's binary_logloss: 0.581076\n",
      "[376]\ttraining's binary_logloss: 0.580991\n",
      "[377]\ttraining's binary_logloss: 0.580937\n",
      "[378]\ttraining's binary_logloss: 0.580855\n",
      "[379]\ttraining's binary_logloss: 0.580783\n",
      "[380]\ttraining's binary_logloss: 0.580685\n",
      "[381]\ttraining's binary_logloss: 0.580591\n",
      "[382]\ttraining's binary_logloss: 0.580494\n",
      "[383]\ttraining's binary_logloss: 0.580414\n",
      "[384]\ttraining's binary_logloss: 0.58032\n",
      "[385]\ttraining's binary_logloss: 0.580237\n",
      "[386]\ttraining's binary_logloss: 0.580151\n",
      "[387]\ttraining's binary_logloss: 0.580057\n",
      "[388]\ttraining's binary_logloss: 0.579969\n",
      "[389]\ttraining's binary_logloss: 0.579911\n",
      "[390]\ttraining's binary_logloss: 0.579821\n",
      "[391]\ttraining's binary_logloss: 0.579737\n",
      "[392]\ttraining's binary_logloss: 0.579653\n",
      "[393]\ttraining's binary_logloss: 0.57957\n",
      "[394]\ttraining's binary_logloss: 0.579489\n",
      "[395]\ttraining's binary_logloss: 0.579419\n",
      "[396]\ttraining's binary_logloss: 0.579374\n",
      "[397]\ttraining's binary_logloss: 0.579337\n",
      "[398]\ttraining's binary_logloss: 0.579293\n",
      "[399]\ttraining's binary_logloss: 0.579249\n",
      "[400]\ttraining's binary_logloss: 0.579208\n",
      "[401]\ttraining's binary_logloss: 0.579124\n",
      "[402]\ttraining's binary_logloss: 0.579041\n",
      "[403]\ttraining's binary_logloss: 0.578971\n",
      "[404]\ttraining's binary_logloss: 0.578896\n",
      "[405]\ttraining's binary_logloss: 0.578824\n",
      "[406]\ttraining's binary_logloss: 0.578761\n",
      "[407]\ttraining's binary_logloss: 0.57872\n",
      "[408]\ttraining's binary_logloss: 0.578669\n",
      "[409]\ttraining's binary_logloss: 0.57862\n",
      "[410]\ttraining's binary_logloss: 0.578563\n",
      "[411]\ttraining's binary_logloss: 0.578509\n",
      "[412]\ttraining's binary_logloss: 0.578443\n",
      "[413]\ttraining's binary_logloss: 0.57838\n",
      "[414]\ttraining's binary_logloss: 0.578317\n",
      "[415]\ttraining's binary_logloss: 0.578266\n",
      "[416]\ttraining's binary_logloss: 0.578174\n",
      "[417]\ttraining's binary_logloss: 0.578082\n",
      "[418]\ttraining's binary_logloss: 0.578013\n",
      "[419]\ttraining's binary_logloss: 0.577944\n",
      "[420]\ttraining's binary_logloss: 0.577867\n",
      "[421]\ttraining's binary_logloss: 0.577816\n",
      "[422]\ttraining's binary_logloss: 0.577758\n",
      "[423]\ttraining's binary_logloss: 0.577711\n",
      "[424]\ttraining's binary_logloss: 0.577667\n",
      "[425]\ttraining's binary_logloss: 0.577615\n",
      "[426]\ttraining's binary_logloss: 0.57755\n",
      "[427]\ttraining's binary_logloss: 0.577487\n",
      "[428]\ttraining's binary_logloss: 0.577425\n",
      "[429]\ttraining's binary_logloss: 0.577362\n",
      "[430]\ttraining's binary_logloss: 0.577307\n",
      "[431]\ttraining's binary_logloss: 0.577232\n",
      "[432]\ttraining's binary_logloss: 0.577159\n",
      "[433]\ttraining's binary_logloss: 0.577084\n",
      "[434]\ttraining's binary_logloss: 0.577023\n",
      "[435]\ttraining's binary_logloss: 0.576956\n",
      "[436]\ttraining's binary_logloss: 0.576909\n",
      "[437]\ttraining's binary_logloss: 0.576866\n",
      "[438]\ttraining's binary_logloss: 0.576809\n",
      "[439]\ttraining's binary_logloss: 0.576759\n",
      "[440]\ttraining's binary_logloss: 0.576715\n",
      "[441]\ttraining's binary_logloss: 0.576656\n",
      "[442]\ttraining's binary_logloss: 0.576597\n",
      "[443]\ttraining's binary_logloss: 0.576533\n",
      "[444]\ttraining's binary_logloss: 0.57647\n",
      "[445]\ttraining's binary_logloss: 0.576409\n",
      "[446]\ttraining's binary_logloss: 0.576322\n",
      "[447]\ttraining's binary_logloss: 0.576223\n",
      "[448]\ttraining's binary_logloss: 0.576137\n",
      "[449]\ttraining's binary_logloss: 0.576045\n",
      "[450]\ttraining's binary_logloss: 0.575962\n",
      "[451]\ttraining's binary_logloss: 0.575886\n",
      "[452]\ttraining's binary_logloss: 0.57579\n",
      "[453]\ttraining's binary_logloss: 0.575695\n",
      "[454]\ttraining's binary_logloss: 0.575619\n",
      "[455]\ttraining's binary_logloss: 0.575522\n",
      "[456]\ttraining's binary_logloss: 0.575436\n",
      "[457]\ttraining's binary_logloss: 0.575337\n",
      "[458]\ttraining's binary_logloss: 0.575269\n",
      "[459]\ttraining's binary_logloss: 0.575201\n",
      "[460]\ttraining's binary_logloss: 0.575136\n",
      "[461]\ttraining's binary_logloss: 0.575052\n",
      "[462]\ttraining's binary_logloss: 0.574982\n",
      "[463]\ttraining's binary_logloss: 0.574904\n",
      "[464]\ttraining's binary_logloss: 0.574827\n",
      "[465]\ttraining's binary_logloss: 0.574752\n",
      "[466]\ttraining's binary_logloss: 0.574686\n",
      "[467]\ttraining's binary_logloss: 0.574638\n",
      "[468]\ttraining's binary_logloss: 0.574585\n",
      "[469]\ttraining's binary_logloss: 0.574531\n",
      "[470]\ttraining's binary_logloss: 0.574482\n",
      "[471]\ttraining's binary_logloss: 0.574389\n",
      "[472]\ttraining's binary_logloss: 0.57431\n",
      "[473]\ttraining's binary_logloss: 0.574213\n",
      "[474]\ttraining's binary_logloss: 0.574139\n",
      "[475]\ttraining's binary_logloss: 0.574057\n",
      "[476]\ttraining's binary_logloss: 0.573982\n",
      "[477]\ttraining's binary_logloss: 0.573907\n",
      "[478]\ttraining's binary_logloss: 0.573835\n",
      "[479]\ttraining's binary_logloss: 0.573753\n",
      "[480]\ttraining's binary_logloss: 0.573708\n",
      "[481]\ttraining's binary_logloss: 0.573655\n",
      "[482]\ttraining's binary_logloss: 0.573607\n",
      "[483]\ttraining's binary_logloss: 0.573562\n",
      "[484]\ttraining's binary_logloss: 0.573521\n",
      "[485]\ttraining's binary_logloss: 0.57348\n",
      "[486]\ttraining's binary_logloss: 0.573389\n",
      "[487]\ttraining's binary_logloss: 0.573298\n",
      "[488]\ttraining's binary_logloss: 0.573215\n",
      "[489]\ttraining's binary_logloss: 0.573126\n",
      "[490]\ttraining's binary_logloss: 0.573037\n",
      "[491]\ttraining's binary_logloss: 0.572945\n",
      "[492]\ttraining's binary_logloss: 0.572844\n",
      "[493]\ttraining's binary_logloss: 0.572748\n",
      "[494]\ttraining's binary_logloss: 0.572656\n",
      "[495]\ttraining's binary_logloss: 0.572571\n",
      "[496]\ttraining's binary_logloss: 0.572483\n",
      "[497]\ttraining's binary_logloss: 0.572401\n",
      "[498]\ttraining's binary_logloss: 0.572319\n",
      "[499]\ttraining's binary_logloss: 0.572235\n",
      "[500]\ttraining's binary_logloss: 0.572149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614677\n",
      "[2]\ttraining's binary_logloss: 0.613685\n",
      "[3]\ttraining's binary_logloss: 0.612641\n",
      "[4]\ttraining's binary_logloss: 0.611655\n",
      "[5]\ttraining's binary_logloss: 0.610787\n",
      "[6]\ttraining's binary_logloss: 0.609765\n",
      "[7]\ttraining's binary_logloss: 0.608873\n",
      "[8]\ttraining's binary_logloss: 0.608039\n",
      "[9]\ttraining's binary_logloss: 0.607193\n",
      "[10]\ttraining's binary_logloss: 0.606427\n",
      "[11]\ttraining's binary_logloss: 0.605647\n",
      "[12]\ttraining's binary_logloss: 0.60492\n",
      "[13]\ttraining's binary_logloss: 0.604191\n",
      "[14]\ttraining's binary_logloss: 0.603528\n",
      "[15]\ttraining's binary_logloss: 0.602869\n",
      "[16]\ttraining's binary_logloss: 0.60233\n",
      "[17]\ttraining's binary_logloss: 0.601689\n",
      "[18]\ttraining's binary_logloss: 0.601017\n",
      "[19]\ttraining's binary_logloss: 0.60043\n",
      "[20]\ttraining's binary_logloss: 0.599811\n",
      "[21]\ttraining's binary_logloss: 0.599282\n",
      "[22]\ttraining's binary_logloss: 0.598772\n",
      "[23]\ttraining's binary_logloss: 0.598284\n",
      "[24]\ttraining's binary_logloss: 0.597808\n",
      "[25]\ttraining's binary_logloss: 0.597361\n",
      "[26]\ttraining's binary_logloss: 0.596916\n",
      "[27]\ttraining's binary_logloss: 0.596495\n",
      "[28]\ttraining's binary_logloss: 0.596044\n",
      "[29]\ttraining's binary_logloss: 0.5956\n",
      "[30]\ttraining's binary_logloss: 0.595183\n",
      "[31]\ttraining's binary_logloss: 0.594733\n",
      "[32]\ttraining's binary_logloss: 0.594334\n",
      "[33]\ttraining's binary_logloss: 0.593917\n",
      "[34]\ttraining's binary_logloss: 0.593527\n",
      "[35]\ttraining's binary_logloss: 0.59319\n",
      "[36]\ttraining's binary_logloss: 0.592822\n",
      "[37]\ttraining's binary_logloss: 0.592483\n",
      "[38]\ttraining's binary_logloss: 0.592177\n",
      "[39]\ttraining's binary_logloss: 0.591968\n",
      "[40]\ttraining's binary_logloss: 0.591724\n",
      "[41]\ttraining's binary_logloss: 0.591458\n",
      "[42]\ttraining's binary_logloss: 0.591206\n",
      "[43]\ttraining's binary_logloss: 0.591\n",
      "[44]\ttraining's binary_logloss: 0.590767\n",
      "[45]\ttraining's binary_logloss: 0.590558\n",
      "[46]\ttraining's binary_logloss: 0.590266\n",
      "[47]\ttraining's binary_logloss: 0.590006\n",
      "[48]\ttraining's binary_logloss: 0.589764\n",
      "[49]\ttraining's binary_logloss: 0.589503\n",
      "[50]\ttraining's binary_logloss: 0.589282\n",
      "[51]\ttraining's binary_logloss: 0.589109\n",
      "[52]\ttraining's binary_logloss: 0.588984\n",
      "[53]\ttraining's binary_logloss: 0.588825\n",
      "[54]\ttraining's binary_logloss: 0.588705\n",
      "[55]\ttraining's binary_logloss: 0.588564\n",
      "[56]\ttraining's binary_logloss: 0.588459\n",
      "[57]\ttraining's binary_logloss: 0.58826\n",
      "[58]\ttraining's binary_logloss: 0.58814\n",
      "[59]\ttraining's binary_logloss: 0.588025\n",
      "[60]\ttraining's binary_logloss: 0.587855\n",
      "[61]\ttraining's binary_logloss: 0.587768\n",
      "[62]\ttraining's binary_logloss: 0.587635\n",
      "[63]\ttraining's binary_logloss: 0.587573\n",
      "[64]\ttraining's binary_logloss: 0.587528\n",
      "[65]\ttraining's binary_logloss: 0.587413\n",
      "[66]\ttraining's binary_logloss: 0.587361\n",
      "[67]\ttraining's binary_logloss: 0.587307\n",
      "[68]\ttraining's binary_logloss: 0.58724\n",
      "[69]\ttraining's binary_logloss: 0.587162\n",
      "[70]\ttraining's binary_logloss: 0.587116\n",
      "[71]\ttraining's binary_logloss: 0.587038\n",
      "[72]\ttraining's binary_logloss: 0.586999\n",
      "[73]\ttraining's binary_logloss: 0.586946\n",
      "[74]\ttraining's binary_logloss: 0.586941\n",
      "[75]\ttraining's binary_logloss: 0.58694\n",
      "[76]\ttraining's binary_logloss: 0.586854\n",
      "[77]\ttraining's binary_logloss: 0.5868\n",
      "[78]\ttraining's binary_logloss: 0.58675\n",
      "[79]\ttraining's binary_logloss: 0.586699\n",
      "[80]\ttraining's binary_logloss: 0.586632\n",
      "[81]\ttraining's binary_logloss: 0.586552\n",
      "[82]\ttraining's binary_logloss: 0.586477\n",
      "[83]\ttraining's binary_logloss: 0.58644\n",
      "[84]\ttraining's binary_logloss: 0.586378\n",
      "[85]\ttraining's binary_logloss: 0.58632\n",
      "[86]\ttraining's binary_logloss: 0.586256\n",
      "[87]\ttraining's binary_logloss: 0.586201\n",
      "[88]\ttraining's binary_logloss: 0.586148\n",
      "[89]\ttraining's binary_logloss: 0.586108\n",
      "[90]\ttraining's binary_logloss: 0.586108\n",
      "[91]\ttraining's binary_logloss: 0.586099\n",
      "[92]\ttraining's binary_logloss: 0.586111\n",
      "[93]\ttraining's binary_logloss: 0.586084\n",
      "[94]\ttraining's binary_logloss: 0.586145\n",
      "[95]\ttraining's binary_logloss: 0.58615\n",
      "[96]\ttraining's binary_logloss: 0.586133\n",
      "[97]\ttraining's binary_logloss: 0.586121\n",
      "[98]\ttraining's binary_logloss: 0.586118\n",
      "[99]\ttraining's binary_logloss: 0.586113\n",
      "[100]\ttraining's binary_logloss: 0.586118\n",
      "[101]\ttraining's binary_logloss: 0.586125\n",
      "[102]\ttraining's binary_logloss: 0.586112\n",
      "[103]\ttraining's binary_logloss: 0.586154\n",
      "[104]\ttraining's binary_logloss: 0.586163\n",
      "[105]\ttraining's binary_logloss: 0.586165\n",
      "[106]\ttraining's binary_logloss: 0.586197\n",
      "[107]\ttraining's binary_logloss: 0.586226\n",
      "[108]\ttraining's binary_logloss: 0.58622\n",
      "[109]\ttraining's binary_logloss: 0.586224\n",
      "[110]\ttraining's binary_logloss: 0.586229\n",
      "[111]\ttraining's binary_logloss: 0.586197\n",
      "[112]\ttraining's binary_logloss: 0.586172\n",
      "[113]\ttraining's binary_logloss: 0.586149\n",
      "[114]\ttraining's binary_logloss: 0.586125\n",
      "[115]\ttraining's binary_logloss: 0.586119\n",
      "[116]\ttraining's binary_logloss: 0.586158\n",
      "[117]\ttraining's binary_logloss: 0.586154\n",
      "[118]\ttraining's binary_logloss: 0.58615\n",
      "[119]\ttraining's binary_logloss: 0.586146\n",
      "[120]\ttraining's binary_logloss: 0.586189\n",
      "[121]\ttraining's binary_logloss: 0.586246\n",
      "[122]\ttraining's binary_logloss: 0.586255\n",
      "[123]\ttraining's binary_logloss: 0.586267\n",
      "[124]\ttraining's binary_logloss: 0.586323\n",
      "[125]\ttraining's binary_logloss: 0.586393\n",
      "[126]\ttraining's binary_logloss: 0.586416\n",
      "[127]\ttraining's binary_logloss: 0.586416\n",
      "[128]\ttraining's binary_logloss: 0.58642\n",
      "[129]\ttraining's binary_logloss: 0.586455\n",
      "[130]\ttraining's binary_logloss: 0.586467\n",
      "[131]\ttraining's binary_logloss: 0.586531\n",
      "[132]\ttraining's binary_logloss: 0.586556\n",
      "[133]\ttraining's binary_logloss: 0.586627\n",
      "[134]\ttraining's binary_logloss: 0.586691\n",
      "[135]\ttraining's binary_logloss: 0.586766\n",
      "[136]\ttraining's binary_logloss: 0.586787\n",
      "[137]\ttraining's binary_logloss: 0.586771\n",
      "[138]\ttraining's binary_logloss: 0.586759\n",
      "[139]\ttraining's binary_logloss: 0.58675\n",
      "[140]\ttraining's binary_logloss: 0.586744\n",
      "[141]\ttraining's binary_logloss: 0.586752\n",
      "[142]\ttraining's binary_logloss: 0.586766\n",
      "[143]\ttraining's binary_logloss: 0.586799\n",
      "[144]\ttraining's binary_logloss: 0.586811\n",
      "[145]\ttraining's binary_logloss: 0.586825\n",
      "[146]\ttraining's binary_logloss: 0.586849\n",
      "[147]\ttraining's binary_logloss: 0.586893\n",
      "[148]\ttraining's binary_logloss: 0.586929\n",
      "[149]\ttraining's binary_logloss: 0.586938\n",
      "[150]\ttraining's binary_logloss: 0.586975\n",
      "[151]\ttraining's binary_logloss: 0.587009\n",
      "[152]\ttraining's binary_logloss: 0.587043\n",
      "[153]\ttraining's binary_logloss: 0.58707\n",
      "[154]\ttraining's binary_logloss: 0.587086\n",
      "[155]\ttraining's binary_logloss: 0.587133\n",
      "[156]\ttraining's binary_logloss: 0.587144\n",
      "[157]\ttraining's binary_logloss: 0.587143\n",
      "[158]\ttraining's binary_logloss: 0.587166\n",
      "[159]\ttraining's binary_logloss: 0.587201\n",
      "[160]\ttraining's binary_logloss: 0.587217\n",
      "[161]\ttraining's binary_logloss: 0.587207\n",
      "[162]\ttraining's binary_logloss: 0.587194\n",
      "[163]\ttraining's binary_logloss: 0.587187\n",
      "[164]\ttraining's binary_logloss: 0.587177\n",
      "[165]\ttraining's binary_logloss: 0.587178\n",
      "[166]\ttraining's binary_logloss: 0.587188\n",
      "[167]\ttraining's binary_logloss: 0.587175\n",
      "[168]\ttraining's binary_logloss: 0.587216\n",
      "[169]\ttraining's binary_logloss: 0.58725\n",
      "[170]\ttraining's binary_logloss: 0.587265\n",
      "[171]\ttraining's binary_logloss: 0.587319\n",
      "[172]\ttraining's binary_logloss: 0.587339\n",
      "[173]\ttraining's binary_logloss: 0.587369\n",
      "[174]\ttraining's binary_logloss: 0.5874\n",
      "[175]\ttraining's binary_logloss: 0.587456\n",
      "[176]\ttraining's binary_logloss: 0.587489\n",
      "[177]\ttraining's binary_logloss: 0.587473\n",
      "[178]\ttraining's binary_logloss: 0.587497\n",
      "[179]\ttraining's binary_logloss: 0.587497\n",
      "[180]\ttraining's binary_logloss: 0.587528\n",
      "[181]\ttraining's binary_logloss: 0.587513\n",
      "[182]\ttraining's binary_logloss: 0.587516\n",
      "[183]\ttraining's binary_logloss: 0.587509\n",
      "[184]\ttraining's binary_logloss: 0.587516\n",
      "[185]\ttraining's binary_logloss: 0.587493\n",
      "[186]\ttraining's binary_logloss: 0.587529\n",
      "[187]\ttraining's binary_logloss: 0.587549\n",
      "[188]\ttraining's binary_logloss: 0.58757\n",
      "[189]\ttraining's binary_logloss: 0.587613\n",
      "[190]\ttraining's binary_logloss: 0.587639\n",
      "[191]\ttraining's binary_logloss: 0.587632\n",
      "[192]\ttraining's binary_logloss: 0.587628\n",
      "[193]\ttraining's binary_logloss: 0.58762\n",
      "[194]\ttraining's binary_logloss: 0.587584\n",
      "[195]\ttraining's binary_logloss: 0.587588\n",
      "[196]\ttraining's binary_logloss: 0.587588\n",
      "[197]\ttraining's binary_logloss: 0.587586\n",
      "[198]\ttraining's binary_logloss: 0.587585\n",
      "[199]\ttraining's binary_logloss: 0.587589\n",
      "[200]\ttraining's binary_logloss: 0.587583\n",
      "[201]\ttraining's binary_logloss: 0.587603\n",
      "[202]\ttraining's binary_logloss: 0.587623\n",
      "[203]\ttraining's binary_logloss: 0.587644\n",
      "[204]\ttraining's binary_logloss: 0.587669\n",
      "[205]\ttraining's binary_logloss: 0.587691\n",
      "[206]\ttraining's binary_logloss: 0.587652\n",
      "[207]\ttraining's binary_logloss: 0.58761\n",
      "[208]\ttraining's binary_logloss: 0.587588\n",
      "[209]\ttraining's binary_logloss: 0.587545\n",
      "[210]\ttraining's binary_logloss: 0.587505\n",
      "[211]\ttraining's binary_logloss: 0.587544\n",
      "[212]\ttraining's binary_logloss: 0.587572\n",
      "[213]\ttraining's binary_logloss: 0.587611\n",
      "[214]\ttraining's binary_logloss: 0.58765\n",
      "[215]\ttraining's binary_logloss: 0.587686\n",
      "[216]\ttraining's binary_logloss: 0.587635\n",
      "[217]\ttraining's binary_logloss: 0.587598\n",
      "[218]\ttraining's binary_logloss: 0.587557\n",
      "[219]\ttraining's binary_logloss: 0.587535\n",
      "[220]\ttraining's binary_logloss: 0.587511\n",
      "[221]\ttraining's binary_logloss: 0.587498\n",
      "[222]\ttraining's binary_logloss: 0.587488\n",
      "[223]\ttraining's binary_logloss: 0.587467\n",
      "[224]\ttraining's binary_logloss: 0.587459\n",
      "[225]\ttraining's binary_logloss: 0.587451\n",
      "[226]\ttraining's binary_logloss: 0.587424\n",
      "[227]\ttraining's binary_logloss: 0.587403\n",
      "[228]\ttraining's binary_logloss: 0.587379\n",
      "[229]\ttraining's binary_logloss: 0.587365\n",
      "[230]\ttraining's binary_logloss: 0.587325\n",
      "[231]\ttraining's binary_logloss: 0.587323\n",
      "[232]\ttraining's binary_logloss: 0.587323\n",
      "[233]\ttraining's binary_logloss: 0.587325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[234]\ttraining's binary_logloss: 0.587338\n",
      "[235]\ttraining's binary_logloss: 0.587346\n",
      "[236]\ttraining's binary_logloss: 0.587323\n",
      "[237]\ttraining's binary_logloss: 0.587284\n",
      "[238]\ttraining's binary_logloss: 0.587264\n",
      "[239]\ttraining's binary_logloss: 0.58723\n",
      "[240]\ttraining's binary_logloss: 0.587196\n",
      "[241]\ttraining's binary_logloss: 0.587169\n",
      "[242]\ttraining's binary_logloss: 0.58714\n",
      "[243]\ttraining's binary_logloss: 0.587122\n",
      "[244]\ttraining's binary_logloss: 0.587104\n",
      "[245]\ttraining's binary_logloss: 0.587078\n",
      "[246]\ttraining's binary_logloss: 0.587028\n",
      "[247]\ttraining's binary_logloss: 0.586954\n",
      "[248]\ttraining's binary_logloss: 0.586886\n",
      "[249]\ttraining's binary_logloss: 0.586816\n",
      "[250]\ttraining's binary_logloss: 0.586754\n",
      "[251]\ttraining's binary_logloss: 0.586674\n",
      "[252]\ttraining's binary_logloss: 0.586612\n",
      "[253]\ttraining's binary_logloss: 0.586565\n",
      "[254]\ttraining's binary_logloss: 0.586501\n",
      "[255]\ttraining's binary_logloss: 0.586427\n",
      "[256]\ttraining's binary_logloss: 0.586415\n",
      "[257]\ttraining's binary_logloss: 0.586391\n",
      "[258]\ttraining's binary_logloss: 0.586367\n",
      "[259]\ttraining's binary_logloss: 0.586345\n",
      "[260]\ttraining's binary_logloss: 0.586322\n",
      "[261]\ttraining's binary_logloss: 0.586316\n",
      "[262]\ttraining's binary_logloss: 0.586288\n",
      "[263]\ttraining's binary_logloss: 0.586291\n",
      "[264]\ttraining's binary_logloss: 0.5863\n",
      "[265]\ttraining's binary_logloss: 0.586274\n",
      "[266]\ttraining's binary_logloss: 0.58625\n",
      "[267]\ttraining's binary_logloss: 0.586255\n",
      "[268]\ttraining's binary_logloss: 0.586262\n",
      "[269]\ttraining's binary_logloss: 0.586241\n",
      "[270]\ttraining's binary_logloss: 0.586244\n",
      "[271]\ttraining's binary_logloss: 0.58621\n",
      "[272]\ttraining's binary_logloss: 0.586191\n",
      "[273]\ttraining's binary_logloss: 0.586123\n",
      "[274]\ttraining's binary_logloss: 0.586055\n",
      "[275]\ttraining's binary_logloss: 0.586023\n",
      "[276]\ttraining's binary_logloss: 0.585986\n",
      "[277]\ttraining's binary_logloss: 0.585955\n",
      "[278]\ttraining's binary_logloss: 0.585928\n",
      "[279]\ttraining's binary_logloss: 0.585887\n",
      "[280]\ttraining's binary_logloss: 0.585851\n",
      "[281]\ttraining's binary_logloss: 0.585833\n",
      "[282]\ttraining's binary_logloss: 0.585829\n",
      "[283]\ttraining's binary_logloss: 0.585824\n",
      "[284]\ttraining's binary_logloss: 0.585821\n",
      "[285]\ttraining's binary_logloss: 0.585796\n",
      "[286]\ttraining's binary_logloss: 0.585754\n",
      "[287]\ttraining's binary_logloss: 0.585714\n",
      "[288]\ttraining's binary_logloss: 0.585671\n",
      "[289]\ttraining's binary_logloss: 0.585627\n",
      "[290]\ttraining's binary_logloss: 0.585587\n",
      "[291]\ttraining's binary_logloss: 0.585524\n",
      "[292]\ttraining's binary_logloss: 0.585444\n",
      "[293]\ttraining's binary_logloss: 0.585385\n",
      "[294]\ttraining's binary_logloss: 0.585312\n",
      "[295]\ttraining's binary_logloss: 0.585238\n",
      "[296]\ttraining's binary_logloss: 0.585191\n",
      "[297]\ttraining's binary_logloss: 0.585158\n",
      "[298]\ttraining's binary_logloss: 0.585137\n",
      "[299]\ttraining's binary_logloss: 0.585095\n",
      "[300]\ttraining's binary_logloss: 0.585052\n",
      "[301]\ttraining's binary_logloss: 0.585026\n",
      "[302]\ttraining's binary_logloss: 0.584985\n",
      "[303]\ttraining's binary_logloss: 0.584935\n",
      "[304]\ttraining's binary_logloss: 0.584882\n",
      "[305]\ttraining's binary_logloss: 0.584844\n",
      "[306]\ttraining's binary_logloss: 0.584796\n",
      "[307]\ttraining's binary_logloss: 0.58475\n",
      "[308]\ttraining's binary_logloss: 0.584704\n",
      "[309]\ttraining's binary_logloss: 0.584662\n",
      "[310]\ttraining's binary_logloss: 0.584613\n",
      "[311]\ttraining's binary_logloss: 0.584536\n",
      "[312]\ttraining's binary_logloss: 0.584472\n",
      "[313]\ttraining's binary_logloss: 0.584401\n",
      "[314]\ttraining's binary_logloss: 0.584337\n",
      "[315]\ttraining's binary_logloss: 0.584273\n",
      "[316]\ttraining's binary_logloss: 0.584221\n",
      "[317]\ttraining's binary_logloss: 0.58417\n",
      "[318]\ttraining's binary_logloss: 0.584119\n",
      "[319]\ttraining's binary_logloss: 0.584071\n",
      "[320]\ttraining's binary_logloss: 0.58402\n",
      "[321]\ttraining's binary_logloss: 0.583971\n",
      "[322]\ttraining's binary_logloss: 0.583925\n",
      "[323]\ttraining's binary_logloss: 0.583884\n",
      "[324]\ttraining's binary_logloss: 0.583841\n",
      "[325]\ttraining's binary_logloss: 0.583797\n",
      "[326]\ttraining's binary_logloss: 0.583729\n",
      "[327]\ttraining's binary_logloss: 0.583658\n",
      "[328]\ttraining's binary_logloss: 0.583589\n",
      "[329]\ttraining's binary_logloss: 0.583523\n",
      "[330]\ttraining's binary_logloss: 0.583445\n",
      "[331]\ttraining's binary_logloss: 0.583393\n",
      "[332]\ttraining's binary_logloss: 0.583348\n",
      "[333]\ttraining's binary_logloss: 0.583304\n",
      "[334]\ttraining's binary_logloss: 0.583262\n",
      "[335]\ttraining's binary_logloss: 0.583219\n",
      "[336]\ttraining's binary_logloss: 0.583185\n",
      "[337]\ttraining's binary_logloss: 0.583149\n",
      "[338]\ttraining's binary_logloss: 0.583118\n",
      "[339]\ttraining's binary_logloss: 0.583096\n",
      "[340]\ttraining's binary_logloss: 0.583062\n",
      "[341]\ttraining's binary_logloss: 0.583006\n",
      "[342]\ttraining's binary_logloss: 0.582937\n",
      "[343]\ttraining's binary_logloss: 0.582879\n",
      "[344]\ttraining's binary_logloss: 0.582825\n",
      "[345]\ttraining's binary_logloss: 0.582773\n",
      "[346]\ttraining's binary_logloss: 0.58269\n",
      "[347]\ttraining's binary_logloss: 0.582611\n",
      "[348]\ttraining's binary_logloss: 0.582541\n",
      "[349]\ttraining's binary_logloss: 0.582462\n",
      "[350]\ttraining's binary_logloss: 0.582392\n",
      "[351]\ttraining's binary_logloss: 0.582371\n",
      "[352]\ttraining's binary_logloss: 0.58235\n",
      "[353]\ttraining's binary_logloss: 0.582334\n",
      "[354]\ttraining's binary_logloss: 0.582316\n",
      "[355]\ttraining's binary_logloss: 0.582303\n",
      "[356]\ttraining's binary_logloss: 0.582257\n",
      "[357]\ttraining's binary_logloss: 0.582202\n",
      "[358]\ttraining's binary_logloss: 0.582162\n",
      "[359]\ttraining's binary_logloss: 0.582072\n",
      "[360]\ttraining's binary_logloss: 0.582029\n",
      "[361]\ttraining's binary_logloss: 0.581955\n",
      "[362]\ttraining's binary_logloss: 0.581856\n",
      "[363]\ttraining's binary_logloss: 0.581783\n",
      "[364]\ttraining's binary_logloss: 0.581713\n",
      "[365]\ttraining's binary_logloss: 0.581636\n",
      "[366]\ttraining's binary_logloss: 0.581594\n",
      "[367]\ttraining's binary_logloss: 0.581542\n",
      "[368]\ttraining's binary_logloss: 0.581487\n",
      "[369]\ttraining's binary_logloss: 0.581445\n",
      "[370]\ttraining's binary_logloss: 0.5814\n",
      "[371]\ttraining's binary_logloss: 0.58133\n",
      "[372]\ttraining's binary_logloss: 0.581262\n",
      "[373]\ttraining's binary_logloss: 0.581182\n",
      "[374]\ttraining's binary_logloss: 0.581116\n",
      "[375]\ttraining's binary_logloss: 0.581049\n",
      "[376]\ttraining's binary_logloss: 0.580993\n",
      "[377]\ttraining's binary_logloss: 0.580929\n",
      "[378]\ttraining's binary_logloss: 0.580861\n",
      "[379]\ttraining's binary_logloss: 0.580786\n",
      "[380]\ttraining's binary_logloss: 0.580725\n",
      "[381]\ttraining's binary_logloss: 0.58063\n",
      "[382]\ttraining's binary_logloss: 0.580538\n",
      "[383]\ttraining's binary_logloss: 0.580456\n",
      "[384]\ttraining's binary_logloss: 0.580374\n",
      "[385]\ttraining's binary_logloss: 0.580302\n",
      "[386]\ttraining's binary_logloss: 0.580229\n",
      "[387]\ttraining's binary_logloss: 0.580162\n",
      "[388]\ttraining's binary_logloss: 0.580087\n",
      "[389]\ttraining's binary_logloss: 0.580009\n",
      "[390]\ttraining's binary_logloss: 0.579939\n",
      "[391]\ttraining's binary_logloss: 0.579844\n",
      "[392]\ttraining's binary_logloss: 0.579771\n",
      "[393]\ttraining's binary_logloss: 0.579683\n",
      "[394]\ttraining's binary_logloss: 0.579599\n",
      "[395]\ttraining's binary_logloss: 0.579515\n",
      "[396]\ttraining's binary_logloss: 0.579473\n",
      "[397]\ttraining's binary_logloss: 0.579432\n",
      "[398]\ttraining's binary_logloss: 0.57939\n",
      "[399]\ttraining's binary_logloss: 0.579349\n",
      "[400]\ttraining's binary_logloss: 0.57931\n",
      "[401]\ttraining's binary_logloss: 0.579239\n",
      "[402]\ttraining's binary_logloss: 0.579181\n",
      "[403]\ttraining's binary_logloss: 0.579111\n",
      "[404]\ttraining's binary_logloss: 0.579046\n",
      "[405]\ttraining's binary_logloss: 0.57899\n",
      "[406]\ttraining's binary_logloss: 0.578918\n",
      "[407]\ttraining's binary_logloss: 0.578878\n",
      "[408]\ttraining's binary_logloss: 0.578799\n",
      "[409]\ttraining's binary_logloss: 0.578719\n",
      "[410]\ttraining's binary_logloss: 0.578638\n",
      "[411]\ttraining's binary_logloss: 0.578571\n",
      "[412]\ttraining's binary_logloss: 0.578504\n",
      "[413]\ttraining's binary_logloss: 0.57844\n",
      "[414]\ttraining's binary_logloss: 0.578356\n",
      "[415]\ttraining's binary_logloss: 0.578303\n",
      "[416]\ttraining's binary_logloss: 0.578241\n",
      "[417]\ttraining's binary_logloss: 0.578155\n",
      "[418]\ttraining's binary_logloss: 0.578072\n",
      "[419]\ttraining's binary_logloss: 0.577998\n",
      "[420]\ttraining's binary_logloss: 0.57792\n",
      "[421]\ttraining's binary_logloss: 0.577878\n",
      "[422]\ttraining's binary_logloss: 0.577835\n",
      "[423]\ttraining's binary_logloss: 0.577786\n",
      "[424]\ttraining's binary_logloss: 0.57774\n",
      "[425]\ttraining's binary_logloss: 0.577695\n",
      "[426]\ttraining's binary_logloss: 0.577633\n",
      "[427]\ttraining's binary_logloss: 0.577573\n",
      "[428]\ttraining's binary_logloss: 0.577517\n",
      "[429]\ttraining's binary_logloss: 0.577455\n",
      "[430]\ttraining's binary_logloss: 0.577399\n",
      "[431]\ttraining's binary_logloss: 0.577318\n",
      "[432]\ttraining's binary_logloss: 0.577241\n",
      "[433]\ttraining's binary_logloss: 0.577163\n",
      "[434]\ttraining's binary_logloss: 0.577088\n",
      "[435]\ttraining's binary_logloss: 0.577018\n",
      "[436]\ttraining's binary_logloss: 0.57695\n",
      "[437]\ttraining's binary_logloss: 0.576889\n",
      "[438]\ttraining's binary_logloss: 0.576839\n",
      "[439]\ttraining's binary_logloss: 0.576773\n",
      "[440]\ttraining's binary_logloss: 0.576713\n",
      "[441]\ttraining's binary_logloss: 0.576646\n",
      "[442]\ttraining's binary_logloss: 0.576574\n",
      "[443]\ttraining's binary_logloss: 0.576504\n",
      "[444]\ttraining's binary_logloss: 0.576438\n",
      "[445]\ttraining's binary_logloss: 0.576374\n",
      "[446]\ttraining's binary_logloss: 0.576284\n",
      "[447]\ttraining's binary_logloss: 0.576197\n",
      "[448]\ttraining's binary_logloss: 0.576108\n",
      "[449]\ttraining's binary_logloss: 0.576057\n",
      "[450]\ttraining's binary_logloss: 0.575959\n",
      "[451]\ttraining's binary_logloss: 0.575864\n",
      "[452]\ttraining's binary_logloss: 0.575792\n",
      "[453]\ttraining's binary_logloss: 0.575722\n",
      "[454]\ttraining's binary_logloss: 0.575626\n",
      "[455]\ttraining's binary_logloss: 0.575531\n",
      "[456]\ttraining's binary_logloss: 0.575472\n",
      "[457]\ttraining's binary_logloss: 0.575411\n",
      "[458]\ttraining's binary_logloss: 0.575358\n",
      "[459]\ttraining's binary_logloss: 0.5753\n",
      "[460]\ttraining's binary_logloss: 0.575245\n",
      "[461]\ttraining's binary_logloss: 0.575171\n",
      "[462]\ttraining's binary_logloss: 0.575103\n",
      "[463]\ttraining's binary_logloss: 0.575034\n",
      "[464]\ttraining's binary_logloss: 0.574953\n",
      "[465]\ttraining's binary_logloss: 0.574883\n",
      "[466]\ttraining's binary_logloss: 0.574812\n",
      "[467]\ttraining's binary_logloss: 0.574756\n",
      "[468]\ttraining's binary_logloss: 0.574691\n",
      "[469]\ttraining's binary_logloss: 0.574627\n",
      "[470]\ttraining's binary_logloss: 0.574557\n",
      "[471]\ttraining's binary_logloss: 0.574476\n",
      "[472]\ttraining's binary_logloss: 0.574399\n",
      "[473]\ttraining's binary_logloss: 0.574307\n",
      "[474]\ttraining's binary_logloss: 0.574201\n",
      "[475]\ttraining's binary_logloss: 0.5741\n",
      "[476]\ttraining's binary_logloss: 0.574057\n",
      "[477]\ttraining's binary_logloss: 0.573998\n",
      "[478]\ttraining's binary_logloss: 0.573942\n",
      "[479]\ttraining's binary_logloss: 0.573894\n",
      "[480]\ttraining's binary_logloss: 0.573845\n",
      "[481]\ttraining's binary_logloss: 0.573762\n",
      "[482]\ttraining's binary_logloss: 0.573711\n",
      "[483]\ttraining's binary_logloss: 0.573655\n",
      "[484]\ttraining's binary_logloss: 0.573603\n",
      "[485]\ttraining's binary_logloss: 0.573557\n",
      "[486]\ttraining's binary_logloss: 0.573458\n",
      "[487]\ttraining's binary_logloss: 0.573337\n",
      "[488]\ttraining's binary_logloss: 0.573236\n",
      "[489]\ttraining's binary_logloss: 0.573126\n",
      "[490]\ttraining's binary_logloss: 0.573032\n",
      "[491]\ttraining's binary_logloss: 0.572925\n",
      "[492]\ttraining's binary_logloss: 0.572818\n",
      "[493]\ttraining's binary_logloss: 0.572715\n",
      "[494]\ttraining's binary_logloss: 0.572626\n",
      "[495]\ttraining's binary_logloss: 0.572536\n",
      "[496]\ttraining's binary_logloss: 0.572455\n",
      "[497]\ttraining's binary_logloss: 0.572367\n",
      "[498]\ttraining's binary_logloss: 0.572277\n",
      "[499]\ttraining's binary_logloss: 0.572199\n",
      "[500]\ttraining's binary_logloss: 0.572115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614604\n",
      "[2]\ttraining's binary_logloss: 0.613462\n",
      "[3]\ttraining's binary_logloss: 0.612402\n",
      "[4]\ttraining's binary_logloss: 0.611395\n",
      "[5]\ttraining's binary_logloss: 0.610357\n",
      "[6]\ttraining's binary_logloss: 0.609406\n",
      "[7]\ttraining's binary_logloss: 0.608501\n",
      "[8]\ttraining's binary_logloss: 0.607645\n",
      "[9]\ttraining's binary_logloss: 0.606771\n",
      "[10]\ttraining's binary_logloss: 0.605991\n",
      "[11]\ttraining's binary_logloss: 0.605246\n",
      "[12]\ttraining's binary_logloss: 0.604435\n",
      "[13]\ttraining's binary_logloss: 0.603656\n",
      "[14]\ttraining's binary_logloss: 0.602907\n",
      "[15]\ttraining's binary_logloss: 0.6022\n",
      "[16]\ttraining's binary_logloss: 0.601523\n",
      "[17]\ttraining's binary_logloss: 0.600879\n",
      "[18]\ttraining's binary_logloss: 0.600226\n",
      "[19]\ttraining's binary_logloss: 0.599602\n",
      "[20]\ttraining's binary_logloss: 0.599016\n",
      "[21]\ttraining's binary_logloss: 0.598496\n",
      "[22]\ttraining's binary_logloss: 0.597952\n",
      "[23]\ttraining's binary_logloss: 0.597448\n",
      "[24]\ttraining's binary_logloss: 0.596971\n",
      "[25]\ttraining's binary_logloss: 0.596501\n",
      "[26]\ttraining's binary_logloss: 0.595993\n",
      "[27]\ttraining's binary_logloss: 0.595512\n",
      "[28]\ttraining's binary_logloss: 0.595066\n",
      "[29]\ttraining's binary_logloss: 0.594673\n",
      "[30]\ttraining's binary_logloss: 0.594279\n",
      "[31]\ttraining's binary_logloss: 0.593937\n",
      "[32]\ttraining's binary_logloss: 0.593629\n",
      "[33]\ttraining's binary_logloss: 0.593261\n",
      "[34]\ttraining's binary_logloss: 0.592881\n",
      "[35]\ttraining's binary_logloss: 0.592517\n",
      "[36]\ttraining's binary_logloss: 0.592181\n",
      "[37]\ttraining's binary_logloss: 0.591898\n",
      "[38]\ttraining's binary_logloss: 0.591628\n",
      "[39]\ttraining's binary_logloss: 0.591375\n",
      "[40]\ttraining's binary_logloss: 0.591106\n",
      "[41]\ttraining's binary_logloss: 0.59081\n",
      "[42]\ttraining's binary_logloss: 0.590576\n",
      "[43]\ttraining's binary_logloss: 0.590346\n",
      "[44]\ttraining's binary_logloss: 0.590103\n",
      "[45]\ttraining's binary_logloss: 0.589852\n",
      "[46]\ttraining's binary_logloss: 0.589593\n",
      "[47]\ttraining's binary_logloss: 0.589354\n",
      "[48]\ttraining's binary_logloss: 0.589159\n",
      "[49]\ttraining's binary_logloss: 0.588931\n",
      "[50]\ttraining's binary_logloss: 0.588688\n",
      "[51]\ttraining's binary_logloss: 0.588489\n",
      "[52]\ttraining's binary_logloss: 0.588292\n",
      "[53]\ttraining's binary_logloss: 0.588137\n",
      "[54]\ttraining's binary_logloss: 0.588011\n",
      "[55]\ttraining's binary_logloss: 0.587853\n",
      "[56]\ttraining's binary_logloss: 0.587725\n",
      "[57]\ttraining's binary_logloss: 0.587523\n",
      "[58]\ttraining's binary_logloss: 0.587341\n",
      "[59]\ttraining's binary_logloss: 0.587153\n",
      "[60]\ttraining's binary_logloss: 0.586975\n",
      "[61]\ttraining's binary_logloss: 0.586878\n",
      "[62]\ttraining's binary_logloss: 0.586804\n",
      "[63]\ttraining's binary_logloss: 0.586679\n",
      "[64]\ttraining's binary_logloss: 0.586561\n",
      "[65]\ttraining's binary_logloss: 0.586541\n",
      "[66]\ttraining's binary_logloss: 0.586471\n",
      "[67]\ttraining's binary_logloss: 0.58641\n",
      "[68]\ttraining's binary_logloss: 0.586334\n",
      "[69]\ttraining's binary_logloss: 0.586266\n",
      "[70]\ttraining's binary_logloss: 0.586217\n",
      "[71]\ttraining's binary_logloss: 0.586118\n",
      "[72]\ttraining's binary_logloss: 0.586076\n",
      "[73]\ttraining's binary_logloss: 0.585993\n",
      "[74]\ttraining's binary_logloss: 0.58593\n",
      "[75]\ttraining's binary_logloss: 0.585862\n",
      "[76]\ttraining's binary_logloss: 0.585775\n",
      "[77]\ttraining's binary_logloss: 0.585786\n",
      "[78]\ttraining's binary_logloss: 0.585749\n",
      "[79]\ttraining's binary_logloss: 0.585701\n",
      "[80]\ttraining's binary_logloss: 0.58567\n",
      "[81]\ttraining's binary_logloss: 0.585588\n",
      "[82]\ttraining's binary_logloss: 0.585513\n",
      "[83]\ttraining's binary_logloss: 0.585443\n",
      "[84]\ttraining's binary_logloss: 0.585388\n",
      "[85]\ttraining's binary_logloss: 0.58533\n",
      "[86]\ttraining's binary_logloss: 0.585284\n",
      "[87]\ttraining's binary_logloss: 0.585248\n",
      "[88]\ttraining's binary_logloss: 0.585169\n",
      "[89]\ttraining's binary_logloss: 0.58513\n",
      "[90]\ttraining's binary_logloss: 0.585079\n",
      "[91]\ttraining's binary_logloss: 0.585071\n",
      "[92]\ttraining's binary_logloss: 0.585101\n",
      "[93]\ttraining's binary_logloss: 0.585152\n",
      "[94]\ttraining's binary_logloss: 0.58518\n",
      "[95]\ttraining's binary_logloss: 0.585187\n",
      "[96]\ttraining's binary_logloss: 0.585162\n",
      "[97]\ttraining's binary_logloss: 0.585139\n",
      "[98]\ttraining's binary_logloss: 0.585133\n",
      "[99]\ttraining's binary_logloss: 0.585121\n",
      "[100]\ttraining's binary_logloss: 0.585123\n",
      "[101]\ttraining's binary_logloss: 0.585143\n",
      "[102]\ttraining's binary_logloss: 0.585133\n",
      "[103]\ttraining's binary_logloss: 0.585133\n",
      "[104]\ttraining's binary_logloss: 0.585134\n",
      "[105]\ttraining's binary_logloss: 0.585153\n",
      "[106]\ttraining's binary_logloss: 0.585185\n",
      "[107]\ttraining's binary_logloss: 0.585218\n",
      "[108]\ttraining's binary_logloss: 0.585213\n",
      "[109]\ttraining's binary_logloss: 0.585253\n",
      "[110]\ttraining's binary_logloss: 0.5853\n",
      "[111]\ttraining's binary_logloss: 0.585275\n",
      "[112]\ttraining's binary_logloss: 0.585237\n",
      "[113]\ttraining's binary_logloss: 0.585229\n",
      "[114]\ttraining's binary_logloss: 0.585214\n",
      "[115]\ttraining's binary_logloss: 0.585213\n",
      "[116]\ttraining's binary_logloss: 0.585206\n",
      "[117]\ttraining's binary_logloss: 0.585247\n",
      "[118]\ttraining's binary_logloss: 0.585243\n",
      "[119]\ttraining's binary_logloss: 0.585242\n",
      "[120]\ttraining's binary_logloss: 0.585246\n",
      "[121]\ttraining's binary_logloss: 0.585252\n",
      "[122]\ttraining's binary_logloss: 0.585314\n",
      "[123]\ttraining's binary_logloss: 0.585368\n",
      "[124]\ttraining's binary_logloss: 0.585397\n",
      "[125]\ttraining's binary_logloss: 0.585417\n",
      "[126]\ttraining's binary_logloss: 0.585412\n",
      "[127]\ttraining's binary_logloss: 0.585414\n",
      "[128]\ttraining's binary_logloss: 0.585411\n",
      "[129]\ttraining's binary_logloss: 0.585418\n",
      "[130]\ttraining's binary_logloss: 0.585428\n",
      "[131]\ttraining's binary_logloss: 0.585449\n",
      "[132]\ttraining's binary_logloss: 0.585474\n",
      "[133]\ttraining's binary_logloss: 0.58551\n",
      "[134]\ttraining's binary_logloss: 0.585564\n",
      "[135]\ttraining's binary_logloss: 0.58561\n",
      "[136]\ttraining's binary_logloss: 0.585646\n",
      "[137]\ttraining's binary_logloss: 0.585669\n",
      "[138]\ttraining's binary_logloss: 0.585717\n",
      "[139]\ttraining's binary_logloss: 0.585711\n",
      "[140]\ttraining's binary_logloss: 0.585737\n",
      "[141]\ttraining's binary_logloss: 0.585744\n",
      "[142]\ttraining's binary_logloss: 0.585754\n",
      "[143]\ttraining's binary_logloss: 0.585792\n",
      "[144]\ttraining's binary_logloss: 0.585798\n",
      "[145]\ttraining's binary_logloss: 0.585821\n",
      "[146]\ttraining's binary_logloss: 0.585848\n",
      "[147]\ttraining's binary_logloss: 0.585907\n",
      "[148]\ttraining's binary_logloss: 0.585909\n",
      "[149]\ttraining's binary_logloss: 0.58594\n",
      "[150]\ttraining's binary_logloss: 0.585973\n",
      "[151]\ttraining's binary_logloss: 0.586007\n",
      "[152]\ttraining's binary_logloss: 0.586037\n",
      "[153]\ttraining's binary_logloss: 0.586059\n",
      "[154]\ttraining's binary_logloss: 0.586077\n",
      "[155]\ttraining's binary_logloss: 0.586088\n",
      "[156]\ttraining's binary_logloss: 0.586119\n",
      "[157]\ttraining's binary_logloss: 0.586141\n",
      "[158]\ttraining's binary_logloss: 0.586147\n",
      "[159]\ttraining's binary_logloss: 0.586186\n",
      "[160]\ttraining's binary_logloss: 0.586194\n",
      "[161]\ttraining's binary_logloss: 0.586176\n",
      "[162]\ttraining's binary_logloss: 0.586165\n",
      "[163]\ttraining's binary_logloss: 0.586158\n",
      "[164]\ttraining's binary_logloss: 0.58615\n",
      "[165]\ttraining's binary_logloss: 0.586155\n",
      "[166]\ttraining's binary_logloss: 0.586194\n",
      "[167]\ttraining's binary_logloss: 0.586209\n",
      "[168]\ttraining's binary_logloss: 0.586252\n",
      "[169]\ttraining's binary_logloss: 0.586246\n",
      "[170]\ttraining's binary_logloss: 0.586252\n",
      "[171]\ttraining's binary_logloss: 0.586269\n",
      "[172]\ttraining's binary_logloss: 0.58629\n",
      "[173]\ttraining's binary_logloss: 0.586319\n",
      "[174]\ttraining's binary_logloss: 0.586345\n",
      "[175]\ttraining's binary_logloss: 0.586366\n",
      "[176]\ttraining's binary_logloss: 0.586342\n",
      "[177]\ttraining's binary_logloss: 0.586363\n",
      "[178]\ttraining's binary_logloss: 0.586364\n",
      "[179]\ttraining's binary_logloss: 0.586387\n",
      "[180]\ttraining's binary_logloss: 0.586392\n",
      "[181]\ttraining's binary_logloss: 0.586395\n",
      "[182]\ttraining's binary_logloss: 0.586417\n",
      "[183]\ttraining's binary_logloss: 0.586416\n",
      "[184]\ttraining's binary_logloss: 0.586423\n",
      "[185]\ttraining's binary_logloss: 0.586436\n",
      "[186]\ttraining's binary_logloss: 0.586475\n",
      "[187]\ttraining's binary_logloss: 0.586495\n",
      "[188]\ttraining's binary_logloss: 0.586516\n",
      "[189]\ttraining's binary_logloss: 0.586548\n",
      "[190]\ttraining's binary_logloss: 0.586569\n",
      "[191]\ttraining's binary_logloss: 0.586556\n",
      "[192]\ttraining's binary_logloss: 0.586557\n",
      "[193]\ttraining's binary_logloss: 0.586561\n",
      "[194]\ttraining's binary_logloss: 0.586549\n",
      "[195]\ttraining's binary_logloss: 0.586555\n",
      "[196]\ttraining's binary_logloss: 0.586553\n",
      "[197]\ttraining's binary_logloss: 0.586564\n",
      "[198]\ttraining's binary_logloss: 0.586571\n",
      "[199]\ttraining's binary_logloss: 0.58658\n",
      "[200]\ttraining's binary_logloss: 0.586588\n",
      "[201]\ttraining's binary_logloss: 0.586612\n",
      "[202]\ttraining's binary_logloss: 0.586632\n",
      "[203]\ttraining's binary_logloss: 0.586668\n",
      "[204]\ttraining's binary_logloss: 0.586685\n",
      "[205]\ttraining's binary_logloss: 0.586707\n",
      "[206]\ttraining's binary_logloss: 0.58669\n",
      "[207]\ttraining's binary_logloss: 0.586651\n",
      "[208]\ttraining's binary_logloss: 0.586613\n",
      "[209]\ttraining's binary_logloss: 0.586569\n",
      "[210]\ttraining's binary_logloss: 0.586525\n",
      "[211]\ttraining's binary_logloss: 0.586555\n",
      "[212]\ttraining's binary_logloss: 0.586555\n",
      "[213]\ttraining's binary_logloss: 0.586582\n",
      "[214]\ttraining's binary_logloss: 0.58661\n",
      "[215]\ttraining's binary_logloss: 0.586641\n",
      "[216]\ttraining's binary_logloss: 0.586616\n",
      "[217]\ttraining's binary_logloss: 0.586581\n",
      "[218]\ttraining's binary_logloss: 0.586547\n",
      "[219]\ttraining's binary_logloss: 0.586525\n",
      "[220]\ttraining's binary_logloss: 0.586496\n",
      "[221]\ttraining's binary_logloss: 0.586458\n",
      "[222]\ttraining's binary_logloss: 0.586438\n",
      "[223]\ttraining's binary_logloss: 0.586401\n",
      "[224]\ttraining's binary_logloss: 0.586372\n",
      "[225]\ttraining's binary_logloss: 0.586344\n",
      "[226]\ttraining's binary_logloss: 0.586321\n",
      "[227]\ttraining's binary_logloss: 0.586296\n",
      "[228]\ttraining's binary_logloss: 0.586252\n",
      "[229]\ttraining's binary_logloss: 0.586226\n",
      "[230]\ttraining's binary_logloss: 0.586196\n",
      "[231]\ttraining's binary_logloss: 0.586195\n",
      "[232]\ttraining's binary_logloss: 0.586197\n",
      "[233]\ttraining's binary_logloss: 0.586194\n",
      "[234]\ttraining's binary_logloss: 0.586193\n",
      "[235]\ttraining's binary_logloss: 0.586194\n",
      "[236]\ttraining's binary_logloss: 0.586153\n",
      "[237]\ttraining's binary_logloss: 0.586115\n",
      "[238]\ttraining's binary_logloss: 0.58607\n",
      "[239]\ttraining's binary_logloss: 0.586029\n",
      "[240]\ttraining's binary_logloss: 0.585991\n",
      "[241]\ttraining's binary_logloss: 0.585981\n",
      "[242]\ttraining's binary_logloss: 0.585976\n",
      "[243]\ttraining's binary_logloss: 0.585961\n",
      "[244]\ttraining's binary_logloss: 0.585964\n",
      "[245]\ttraining's binary_logloss: 0.585959\n",
      "[246]\ttraining's binary_logloss: 0.585886\n",
      "[247]\ttraining's binary_logloss: 0.585809\n",
      "[248]\ttraining's binary_logloss: 0.58574\n",
      "[249]\ttraining's binary_logloss: 0.585682\n",
      "[250]\ttraining's binary_logloss: 0.585617\n",
      "[251]\ttraining's binary_logloss: 0.585575\n",
      "[252]\ttraining's binary_logloss: 0.585539\n",
      "[253]\ttraining's binary_logloss: 0.585507\n",
      "[254]\ttraining's binary_logloss: 0.585453\n",
      "[255]\ttraining's binary_logloss: 0.585401\n",
      "[256]\ttraining's binary_logloss: 0.585381\n",
      "[257]\ttraining's binary_logloss: 0.585361\n",
      "[258]\ttraining's binary_logloss: 0.585326\n",
      "[259]\ttraining's binary_logloss: 0.585296\n",
      "[260]\ttraining's binary_logloss: 0.585281\n",
      "[261]\ttraining's binary_logloss: 0.585255\n",
      "[262]\ttraining's binary_logloss: 0.585233\n",
      "[263]\ttraining's binary_logloss: 0.585217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[264]\ttraining's binary_logloss: 0.585225\n",
      "[265]\ttraining's binary_logloss: 0.585195\n",
      "[266]\ttraining's binary_logloss: 0.585195\n",
      "[267]\ttraining's binary_logloss: 0.585198\n",
      "[268]\ttraining's binary_logloss: 0.585203\n",
      "[269]\ttraining's binary_logloss: 0.585197\n",
      "[270]\ttraining's binary_logloss: 0.585175\n",
      "[271]\ttraining's binary_logloss: 0.585115\n",
      "[272]\ttraining's binary_logloss: 0.585088\n",
      "[273]\ttraining's binary_logloss: 0.585063\n",
      "[274]\ttraining's binary_logloss: 0.585051\n",
      "[275]\ttraining's binary_logloss: 0.585022\n",
      "[276]\ttraining's binary_logloss: 0.584976\n",
      "[277]\ttraining's binary_logloss: 0.584927\n",
      "[278]\ttraining's binary_logloss: 0.584881\n",
      "[279]\ttraining's binary_logloss: 0.584835\n",
      "[280]\ttraining's binary_logloss: 0.58479\n",
      "[281]\ttraining's binary_logloss: 0.584762\n",
      "[282]\ttraining's binary_logloss: 0.58475\n",
      "[283]\ttraining's binary_logloss: 0.584745\n",
      "[284]\ttraining's binary_logloss: 0.584723\n",
      "[285]\ttraining's binary_logloss: 0.584709\n",
      "[286]\ttraining's binary_logloss: 0.584659\n",
      "[287]\ttraining's binary_logloss: 0.584607\n",
      "[288]\ttraining's binary_logloss: 0.584548\n",
      "[289]\ttraining's binary_logloss: 0.584502\n",
      "[290]\ttraining's binary_logloss: 0.584445\n",
      "[291]\ttraining's binary_logloss: 0.584372\n",
      "[292]\ttraining's binary_logloss: 0.584291\n",
      "[293]\ttraining's binary_logloss: 0.584211\n",
      "[294]\ttraining's binary_logloss: 0.584125\n",
      "[295]\ttraining's binary_logloss: 0.584043\n",
      "[296]\ttraining's binary_logloss: 0.584011\n",
      "[297]\ttraining's binary_logloss: 0.583983\n",
      "[298]\ttraining's binary_logloss: 0.583957\n",
      "[299]\ttraining's binary_logloss: 0.583919\n",
      "[300]\ttraining's binary_logloss: 0.583883\n",
      "[301]\ttraining's binary_logloss: 0.583838\n",
      "[302]\ttraining's binary_logloss: 0.583771\n",
      "[303]\ttraining's binary_logloss: 0.583713\n",
      "[304]\ttraining's binary_logloss: 0.583691\n",
      "[305]\ttraining's binary_logloss: 0.583606\n",
      "[306]\ttraining's binary_logloss: 0.583557\n",
      "[307]\ttraining's binary_logloss: 0.583496\n",
      "[308]\ttraining's binary_logloss: 0.583453\n",
      "[309]\ttraining's binary_logloss: 0.583395\n",
      "[310]\ttraining's binary_logloss: 0.583341\n",
      "[311]\ttraining's binary_logloss: 0.583257\n",
      "[312]\ttraining's binary_logloss: 0.5832\n",
      "[313]\ttraining's binary_logloss: 0.583143\n",
      "[314]\ttraining's binary_logloss: 0.583087\n",
      "[315]\ttraining's binary_logloss: 0.583004\n",
      "[316]\ttraining's binary_logloss: 0.582952\n",
      "[317]\ttraining's binary_logloss: 0.582896\n",
      "[318]\ttraining's binary_logloss: 0.582842\n",
      "[319]\ttraining's binary_logloss: 0.582791\n",
      "[320]\ttraining's binary_logloss: 0.582742\n",
      "[321]\ttraining's binary_logloss: 0.582696\n",
      "[322]\ttraining's binary_logloss: 0.582637\n",
      "[323]\ttraining's binary_logloss: 0.582577\n",
      "[324]\ttraining's binary_logloss: 0.582525\n",
      "[325]\ttraining's binary_logloss: 0.582472\n",
      "[326]\ttraining's binary_logloss: 0.582403\n",
      "[327]\ttraining's binary_logloss: 0.582332\n",
      "[328]\ttraining's binary_logloss: 0.582265\n",
      "[329]\ttraining's binary_logloss: 0.582191\n",
      "[330]\ttraining's binary_logloss: 0.582109\n",
      "[331]\ttraining's binary_logloss: 0.582067\n",
      "[332]\ttraining's binary_logloss: 0.582015\n",
      "[333]\ttraining's binary_logloss: 0.581971\n",
      "[334]\ttraining's binary_logloss: 0.581929\n",
      "[335]\ttraining's binary_logloss: 0.581882\n",
      "[336]\ttraining's binary_logloss: 0.581851\n",
      "[337]\ttraining's binary_logloss: 0.581805\n",
      "[338]\ttraining's binary_logloss: 0.581762\n",
      "[339]\ttraining's binary_logloss: 0.581731\n",
      "[340]\ttraining's binary_logloss: 0.581703\n",
      "[341]\ttraining's binary_logloss: 0.581637\n",
      "[342]\ttraining's binary_logloss: 0.581593\n",
      "[343]\ttraining's binary_logloss: 0.581547\n",
      "[344]\ttraining's binary_logloss: 0.581505\n",
      "[345]\ttraining's binary_logloss: 0.581461\n",
      "[346]\ttraining's binary_logloss: 0.581387\n",
      "[347]\ttraining's binary_logloss: 0.581313\n",
      "[348]\ttraining's binary_logloss: 0.581246\n",
      "[349]\ttraining's binary_logloss: 0.581178\n",
      "[350]\ttraining's binary_logloss: 0.581111\n",
      "[351]\ttraining's binary_logloss: 0.581082\n",
      "[352]\ttraining's binary_logloss: 0.581049\n",
      "[353]\ttraining's binary_logloss: 0.58102\n",
      "[354]\ttraining's binary_logloss: 0.581\n",
      "[355]\ttraining's binary_logloss: 0.580973\n",
      "[356]\ttraining's binary_logloss: 0.580919\n",
      "[357]\ttraining's binary_logloss: 0.580857\n",
      "[358]\ttraining's binary_logloss: 0.580811\n",
      "[359]\ttraining's binary_logloss: 0.580761\n",
      "[360]\ttraining's binary_logloss: 0.580716\n",
      "[361]\ttraining's binary_logloss: 0.580637\n",
      "[362]\ttraining's binary_logloss: 0.580566\n",
      "[363]\ttraining's binary_logloss: 0.580496\n",
      "[364]\ttraining's binary_logloss: 0.58044\n",
      "[365]\ttraining's binary_logloss: 0.580371\n",
      "[366]\ttraining's binary_logloss: 0.580305\n",
      "[367]\ttraining's binary_logloss: 0.58025\n",
      "[368]\ttraining's binary_logloss: 0.580195\n",
      "[369]\ttraining's binary_logloss: 0.580125\n",
      "[370]\ttraining's binary_logloss: 0.580065\n",
      "[371]\ttraining's binary_logloss: 0.579993\n",
      "[372]\ttraining's binary_logloss: 0.579912\n",
      "[373]\ttraining's binary_logloss: 0.579836\n",
      "[374]\ttraining's binary_logloss: 0.579778\n",
      "[375]\ttraining's binary_logloss: 0.579707\n",
      "[376]\ttraining's binary_logloss: 0.579631\n",
      "[377]\ttraining's binary_logloss: 0.579577\n",
      "[378]\ttraining's binary_logloss: 0.579508\n",
      "[379]\ttraining's binary_logloss: 0.579451\n",
      "[380]\ttraining's binary_logloss: 0.579396\n",
      "[381]\ttraining's binary_logloss: 0.579301\n",
      "[382]\ttraining's binary_logloss: 0.57922\n",
      "[383]\ttraining's binary_logloss: 0.579137\n",
      "[384]\ttraining's binary_logloss: 0.579058\n",
      "[385]\ttraining's binary_logloss: 0.578966\n",
      "[386]\ttraining's binary_logloss: 0.578894\n",
      "[387]\ttraining's binary_logloss: 0.578838\n",
      "[388]\ttraining's binary_logloss: 0.578754\n",
      "[389]\ttraining's binary_logloss: 0.578687\n",
      "[390]\ttraining's binary_logloss: 0.5786\n",
      "[391]\ttraining's binary_logloss: 0.578509\n",
      "[392]\ttraining's binary_logloss: 0.578418\n",
      "[393]\ttraining's binary_logloss: 0.57833\n",
      "[394]\ttraining's binary_logloss: 0.578247\n",
      "[395]\ttraining's binary_logloss: 0.578163\n",
      "[396]\ttraining's binary_logloss: 0.578121\n",
      "[397]\ttraining's binary_logloss: 0.578082\n",
      "[398]\ttraining's binary_logloss: 0.578039\n",
      "[399]\ttraining's binary_logloss: 0.578\n",
      "[400]\ttraining's binary_logloss: 0.577964\n",
      "[401]\ttraining's binary_logloss: 0.577886\n",
      "[402]\ttraining's binary_logloss: 0.577813\n",
      "[403]\ttraining's binary_logloss: 0.577749\n",
      "[404]\ttraining's binary_logloss: 0.577678\n",
      "[405]\ttraining's binary_logloss: 0.577605\n",
      "[406]\ttraining's binary_logloss: 0.577514\n",
      "[407]\ttraining's binary_logloss: 0.577434\n",
      "[408]\ttraining's binary_logloss: 0.577357\n",
      "[409]\ttraining's binary_logloss: 0.577317\n",
      "[410]\ttraining's binary_logloss: 0.577237\n",
      "[411]\ttraining's binary_logloss: 0.57715\n",
      "[412]\ttraining's binary_logloss: 0.577081\n",
      "[413]\ttraining's binary_logloss: 0.576999\n",
      "[414]\ttraining's binary_logloss: 0.576917\n",
      "[415]\ttraining's binary_logloss: 0.576831\n",
      "[416]\ttraining's binary_logloss: 0.57674\n",
      "[417]\ttraining's binary_logloss: 0.576666\n",
      "[418]\ttraining's binary_logloss: 0.576598\n",
      "[419]\ttraining's binary_logloss: 0.57651\n",
      "[420]\ttraining's binary_logloss: 0.576442\n",
      "[421]\ttraining's binary_logloss: 0.57639\n",
      "[422]\ttraining's binary_logloss: 0.576339\n",
      "[423]\ttraining's binary_logloss: 0.576284\n",
      "[424]\ttraining's binary_logloss: 0.576234\n",
      "[425]\ttraining's binary_logloss: 0.57619\n",
      "[426]\ttraining's binary_logloss: 0.576132\n",
      "[427]\ttraining's binary_logloss: 0.576076\n",
      "[428]\ttraining's binary_logloss: 0.576016\n",
      "[429]\ttraining's binary_logloss: 0.575958\n",
      "[430]\ttraining's binary_logloss: 0.575896\n",
      "[431]\ttraining's binary_logloss: 0.575832\n",
      "[432]\ttraining's binary_logloss: 0.575757\n",
      "[433]\ttraining's binary_logloss: 0.57568\n",
      "[434]\ttraining's binary_logloss: 0.575612\n",
      "[435]\ttraining's binary_logloss: 0.575543\n",
      "[436]\ttraining's binary_logloss: 0.575499\n",
      "[437]\ttraining's binary_logloss: 0.575431\n",
      "[438]\ttraining's binary_logloss: 0.575376\n",
      "[439]\ttraining's binary_logloss: 0.57531\n",
      "[440]\ttraining's binary_logloss: 0.575252\n",
      "[441]\ttraining's binary_logloss: 0.575189\n",
      "[442]\ttraining's binary_logloss: 0.575118\n",
      "[443]\ttraining's binary_logloss: 0.575056\n",
      "[444]\ttraining's binary_logloss: 0.574986\n",
      "[445]\ttraining's binary_logloss: 0.574919\n",
      "[446]\ttraining's binary_logloss: 0.574809\n",
      "[447]\ttraining's binary_logloss: 0.57471\n",
      "[448]\ttraining's binary_logloss: 0.574615\n",
      "[449]\ttraining's binary_logloss: 0.574521\n",
      "[450]\ttraining's binary_logloss: 0.574427\n",
      "[451]\ttraining's binary_logloss: 0.574333\n",
      "[452]\ttraining's binary_logloss: 0.57425\n",
      "[453]\ttraining's binary_logloss: 0.574165\n",
      "[454]\ttraining's binary_logloss: 0.57409\n",
      "[455]\ttraining's binary_logloss: 0.574014\n",
      "[456]\ttraining's binary_logloss: 0.573949\n",
      "[457]\ttraining's binary_logloss: 0.573851\n",
      "[458]\ttraining's binary_logloss: 0.573766\n",
      "[459]\ttraining's binary_logloss: 0.5737\n",
      "[460]\ttraining's binary_logloss: 0.573643\n",
      "[461]\ttraining's binary_logloss: 0.573564\n",
      "[462]\ttraining's binary_logloss: 0.573486\n",
      "[463]\ttraining's binary_logloss: 0.573408\n",
      "[464]\ttraining's binary_logloss: 0.573335\n",
      "[465]\ttraining's binary_logloss: 0.573262\n",
      "[466]\ttraining's binary_logloss: 0.57319\n",
      "[467]\ttraining's binary_logloss: 0.573114\n",
      "[468]\ttraining's binary_logloss: 0.573043\n",
      "[469]\ttraining's binary_logloss: 0.57297\n",
      "[470]\ttraining's binary_logloss: 0.572902\n",
      "[471]\ttraining's binary_logloss: 0.572818\n",
      "[472]\ttraining's binary_logloss: 0.57272\n",
      "[473]\ttraining's binary_logloss: 0.572625\n",
      "[474]\ttraining's binary_logloss: 0.57253\n",
      "[475]\ttraining's binary_logloss: 0.572433\n",
      "[476]\ttraining's binary_logloss: 0.572386\n",
      "[477]\ttraining's binary_logloss: 0.572342\n",
      "[478]\ttraining's binary_logloss: 0.572252\n",
      "[479]\ttraining's binary_logloss: 0.572205\n",
      "[480]\ttraining's binary_logloss: 0.572115\n",
      "[481]\ttraining's binary_logloss: 0.572061\n",
      "[482]\ttraining's binary_logloss: 0.572019\n",
      "[483]\ttraining's binary_logloss: 0.571976\n",
      "[484]\ttraining's binary_logloss: 0.57193\n",
      "[485]\ttraining's binary_logloss: 0.571887\n",
      "[486]\ttraining's binary_logloss: 0.571797\n",
      "[487]\ttraining's binary_logloss: 0.571713\n",
      "[488]\ttraining's binary_logloss: 0.571622\n",
      "[489]\ttraining's binary_logloss: 0.571511\n",
      "[490]\ttraining's binary_logloss: 0.571418\n",
      "[491]\ttraining's binary_logloss: 0.571317\n",
      "[492]\ttraining's binary_logloss: 0.571223\n",
      "[493]\ttraining's binary_logloss: 0.571134\n",
      "[494]\ttraining's binary_logloss: 0.571035\n",
      "[495]\ttraining's binary_logloss: 0.570933\n",
      "[496]\ttraining's binary_logloss: 0.570861\n",
      "[497]\ttraining's binary_logloss: 0.57079\n",
      "[498]\ttraining's binary_logloss: 0.570723\n",
      "[499]\ttraining's binary_logloss: 0.570659\n",
      "[500]\ttraining's binary_logloss: 0.570579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614721\n",
      "[2]\ttraining's binary_logloss: 0.613575\n",
      "[3]\ttraining's binary_logloss: 0.612596\n",
      "[4]\ttraining's binary_logloss: 0.611666\n",
      "[5]\ttraining's binary_logloss: 0.610606\n",
      "[6]\ttraining's binary_logloss: 0.609718\n",
      "[7]\ttraining's binary_logloss: 0.608737\n",
      "[8]\ttraining's binary_logloss: 0.607816\n",
      "[9]\ttraining's binary_logloss: 0.606951\n",
      "[10]\ttraining's binary_logloss: 0.606099\n",
      "[11]\ttraining's binary_logloss: 0.605331\n",
      "[12]\ttraining's binary_logloss: 0.604524\n",
      "[13]\ttraining's binary_logloss: 0.603858\n",
      "[14]\ttraining's binary_logloss: 0.603123\n",
      "[15]\ttraining's binary_logloss: 0.602471\n",
      "[16]\ttraining's binary_logloss: 0.601759\n",
      "[17]\ttraining's binary_logloss: 0.601075\n",
      "[18]\ttraining's binary_logloss: 0.600424\n",
      "[19]\ttraining's binary_logloss: 0.599796\n",
      "[20]\ttraining's binary_logloss: 0.599283\n",
      "[21]\ttraining's binary_logloss: 0.598739\n",
      "[22]\ttraining's binary_logloss: 0.598261\n",
      "[23]\ttraining's binary_logloss: 0.597754\n",
      "[24]\ttraining's binary_logloss: 0.597257\n",
      "[25]\ttraining's binary_logloss: 0.596822\n",
      "[26]\ttraining's binary_logloss: 0.596333\n",
      "[27]\ttraining's binary_logloss: 0.595855\n",
      "[28]\ttraining's binary_logloss: 0.595423\n",
      "[29]\ttraining's binary_logloss: 0.595062\n",
      "[30]\ttraining's binary_logloss: 0.594617\n",
      "[31]\ttraining's binary_logloss: 0.594184\n",
      "[32]\ttraining's binary_logloss: 0.593784\n",
      "[33]\ttraining's binary_logloss: 0.593411\n",
      "[34]\ttraining's binary_logloss: 0.5931\n",
      "[35]\ttraining's binary_logloss: 0.592797\n",
      "[36]\ttraining's binary_logloss: 0.592503\n",
      "[37]\ttraining's binary_logloss: 0.59218\n",
      "[38]\ttraining's binary_logloss: 0.591874\n",
      "[39]\ttraining's binary_logloss: 0.591583\n",
      "[40]\ttraining's binary_logloss: 0.591345\n",
      "[41]\ttraining's binary_logloss: 0.591069\n",
      "[42]\ttraining's binary_logloss: 0.590811\n",
      "[43]\ttraining's binary_logloss: 0.590555\n",
      "[44]\ttraining's binary_logloss: 0.590296\n",
      "[45]\ttraining's binary_logloss: 0.590051\n",
      "[46]\ttraining's binary_logloss: 0.58979\n",
      "[47]\ttraining's binary_logloss: 0.589538\n",
      "[48]\ttraining's binary_logloss: 0.58936\n",
      "[49]\ttraining's binary_logloss: 0.589186\n",
      "[50]\ttraining's binary_logloss: 0.589003\n",
      "[51]\ttraining's binary_logloss: 0.588834\n",
      "[52]\ttraining's binary_logloss: 0.588675\n",
      "[53]\ttraining's binary_logloss: 0.588489\n",
      "[54]\ttraining's binary_logloss: 0.588314\n",
      "[55]\ttraining's binary_logloss: 0.588182\n",
      "[56]\ttraining's binary_logloss: 0.587973\n",
      "[57]\ttraining's binary_logloss: 0.587778\n",
      "[58]\ttraining's binary_logloss: 0.587592\n",
      "[59]\ttraining's binary_logloss: 0.587417\n",
      "[60]\ttraining's binary_logloss: 0.587239\n",
      "[61]\ttraining's binary_logloss: 0.587144\n",
      "[62]\ttraining's binary_logloss: 0.587071\n",
      "[63]\ttraining's binary_logloss: 0.586988\n",
      "[64]\ttraining's binary_logloss: 0.586913\n",
      "[65]\ttraining's binary_logloss: 0.58686\n",
      "[66]\ttraining's binary_logloss: 0.586776\n",
      "[67]\ttraining's binary_logloss: 0.586703\n",
      "[68]\ttraining's binary_logloss: 0.586634\n",
      "[69]\ttraining's binary_logloss: 0.586598\n",
      "[70]\ttraining's binary_logloss: 0.586536\n",
      "[71]\ttraining's binary_logloss: 0.586449\n",
      "[72]\ttraining's binary_logloss: 0.586363\n",
      "[73]\ttraining's binary_logloss: 0.586284\n",
      "[74]\ttraining's binary_logloss: 0.58624\n",
      "[75]\ttraining's binary_logloss: 0.586159\n",
      "[76]\ttraining's binary_logloss: 0.586095\n",
      "[77]\ttraining's binary_logloss: 0.586052\n",
      "[78]\ttraining's binary_logloss: 0.585997\n",
      "[79]\ttraining's binary_logloss: 0.585948\n",
      "[80]\ttraining's binary_logloss: 0.585904\n",
      "[81]\ttraining's binary_logloss: 0.585808\n",
      "[82]\ttraining's binary_logloss: 0.585785\n",
      "[83]\ttraining's binary_logloss: 0.585768\n",
      "[84]\ttraining's binary_logloss: 0.585683\n",
      "[85]\ttraining's binary_logloss: 0.585605\n",
      "[86]\ttraining's binary_logloss: 0.585554\n",
      "[87]\ttraining's binary_logloss: 0.585501\n",
      "[88]\ttraining's binary_logloss: 0.585508\n",
      "[89]\ttraining's binary_logloss: 0.58546\n",
      "[90]\ttraining's binary_logloss: 0.585424\n",
      "[91]\ttraining's binary_logloss: 0.585431\n",
      "[92]\ttraining's binary_logloss: 0.585399\n",
      "[93]\ttraining's binary_logloss: 0.585375\n",
      "[94]\ttraining's binary_logloss: 0.585424\n",
      "[95]\ttraining's binary_logloss: 0.585455\n",
      "[96]\ttraining's binary_logloss: 0.585444\n",
      "[97]\ttraining's binary_logloss: 0.585441\n",
      "[98]\ttraining's binary_logloss: 0.585422\n",
      "[99]\ttraining's binary_logloss: 0.585422\n",
      "[100]\ttraining's binary_logloss: 0.585416\n",
      "[101]\ttraining's binary_logloss: 0.585428\n",
      "[102]\ttraining's binary_logloss: 0.585416\n",
      "[103]\ttraining's binary_logloss: 0.585422\n",
      "[104]\ttraining's binary_logloss: 0.585425\n",
      "[105]\ttraining's binary_logloss: 0.585419\n",
      "[106]\ttraining's binary_logloss: 0.585458\n",
      "[107]\ttraining's binary_logloss: 0.585492\n",
      "[108]\ttraining's binary_logloss: 0.585537\n",
      "[109]\ttraining's binary_logloss: 0.58553\n",
      "[110]\ttraining's binary_logloss: 0.585577\n",
      "[111]\ttraining's binary_logloss: 0.585523\n",
      "[112]\ttraining's binary_logloss: 0.585493\n",
      "[113]\ttraining's binary_logloss: 0.585469\n",
      "[114]\ttraining's binary_logloss: 0.585449\n",
      "[115]\ttraining's binary_logloss: 0.585478\n",
      "[116]\ttraining's binary_logloss: 0.585464\n",
      "[117]\ttraining's binary_logloss: 0.585441\n",
      "[118]\ttraining's binary_logloss: 0.585487\n",
      "[119]\ttraining's binary_logloss: 0.585461\n",
      "[120]\ttraining's binary_logloss: 0.585441\n",
      "[121]\ttraining's binary_logloss: 0.585457\n",
      "[122]\ttraining's binary_logloss: 0.58546\n",
      "[123]\ttraining's binary_logloss: 0.585484\n",
      "[124]\ttraining's binary_logloss: 0.585559\n",
      "[125]\ttraining's binary_logloss: 0.585565\n",
      "[126]\ttraining's binary_logloss: 0.585569\n",
      "[127]\ttraining's binary_logloss: 0.585572\n",
      "[128]\ttraining's binary_logloss: 0.585555\n",
      "[129]\ttraining's binary_logloss: 0.585566\n",
      "[130]\ttraining's binary_logloss: 0.585573\n",
      "[131]\ttraining's binary_logloss: 0.585628\n",
      "[132]\ttraining's binary_logloss: 0.585703\n",
      "[133]\ttraining's binary_logloss: 0.585732\n",
      "[134]\ttraining's binary_logloss: 0.585791\n",
      "[135]\ttraining's binary_logloss: 0.585851\n",
      "[136]\ttraining's binary_logloss: 0.585883\n",
      "[137]\ttraining's binary_logloss: 0.585926\n",
      "[138]\ttraining's binary_logloss: 0.585914\n",
      "[139]\ttraining's binary_logloss: 0.585937\n",
      "[140]\ttraining's binary_logloss: 0.585975\n",
      "[141]\ttraining's binary_logloss: 0.585975\n",
      "[142]\ttraining's binary_logloss: 0.585978\n",
      "[143]\ttraining's binary_logloss: 0.585984\n",
      "[144]\ttraining's binary_logloss: 0.586026\n",
      "[145]\ttraining's binary_logloss: 0.586047\n",
      "[146]\ttraining's binary_logloss: 0.586053\n",
      "[147]\ttraining's binary_logloss: 0.586083\n",
      "[148]\ttraining's binary_logloss: 0.586095\n",
      "[149]\ttraining's binary_logloss: 0.586133\n",
      "[150]\ttraining's binary_logloss: 0.586145\n",
      "[151]\ttraining's binary_logloss: 0.58618\n",
      "[152]\ttraining's binary_logloss: 0.586213\n",
      "[153]\ttraining's binary_logloss: 0.586235\n",
      "[154]\ttraining's binary_logloss: 0.586268\n",
      "[155]\ttraining's binary_logloss: 0.5863\n",
      "[156]\ttraining's binary_logloss: 0.586302\n",
      "[157]\ttraining's binary_logloss: 0.586306\n",
      "[158]\ttraining's binary_logloss: 0.586316\n",
      "[159]\ttraining's binary_logloss: 0.58633\n",
      "[160]\ttraining's binary_logloss: 0.586348\n",
      "[161]\ttraining's binary_logloss: 0.586322\n",
      "[162]\ttraining's binary_logloss: 0.586337\n",
      "[163]\ttraining's binary_logloss: 0.586318\n",
      "[164]\ttraining's binary_logloss: 0.586316\n",
      "[165]\ttraining's binary_logloss: 0.586313\n",
      "[166]\ttraining's binary_logloss: 0.586309\n",
      "[167]\ttraining's binary_logloss: 0.586344\n",
      "[168]\ttraining's binary_logloss: 0.586365\n",
      "[169]\ttraining's binary_logloss: 0.586363\n",
      "[170]\ttraining's binary_logloss: 0.586371\n",
      "[171]\ttraining's binary_logloss: 0.586391\n",
      "[172]\ttraining's binary_logloss: 0.586415\n",
      "[173]\ttraining's binary_logloss: 0.586431\n",
      "[174]\ttraining's binary_logloss: 0.586454\n",
      "[175]\ttraining's binary_logloss: 0.586472\n",
      "[176]\ttraining's binary_logloss: 0.586444\n",
      "[177]\ttraining's binary_logloss: 0.586423\n",
      "[178]\ttraining's binary_logloss: 0.586411\n",
      "[179]\ttraining's binary_logloss: 0.586408\n",
      "[180]\ttraining's binary_logloss: 0.586373\n",
      "[181]\ttraining's binary_logloss: 0.586378\n",
      "[182]\ttraining's binary_logloss: 0.586413\n",
      "[183]\ttraining's binary_logloss: 0.58642\n",
      "[184]\ttraining's binary_logloss: 0.586439\n",
      "[185]\ttraining's binary_logloss: 0.586462\n",
      "[186]\ttraining's binary_logloss: 0.586506\n",
      "[187]\ttraining's binary_logloss: 0.586548\n",
      "[188]\ttraining's binary_logloss: 0.586587\n",
      "[189]\ttraining's binary_logloss: 0.586624\n",
      "[190]\ttraining's binary_logloss: 0.586673\n",
      "[191]\ttraining's binary_logloss: 0.586656\n",
      "[192]\ttraining's binary_logloss: 0.586654\n",
      "[193]\ttraining's binary_logloss: 0.586638\n",
      "[194]\ttraining's binary_logloss: 0.586643\n",
      "[195]\ttraining's binary_logloss: 0.586636\n",
      "[196]\ttraining's binary_logloss: 0.586625\n",
      "[197]\ttraining's binary_logloss: 0.586651\n",
      "[198]\ttraining's binary_logloss: 0.586663\n",
      "[199]\ttraining's binary_logloss: 0.586683\n",
      "[200]\ttraining's binary_logloss: 0.586705\n",
      "[201]\ttraining's binary_logloss: 0.586722\n",
      "[202]\ttraining's binary_logloss: 0.586741\n",
      "[203]\ttraining's binary_logloss: 0.586765\n",
      "[204]\ttraining's binary_logloss: 0.586787\n",
      "[205]\ttraining's binary_logloss: 0.58682\n",
      "[206]\ttraining's binary_logloss: 0.586784\n",
      "[207]\ttraining's binary_logloss: 0.586716\n",
      "[208]\ttraining's binary_logloss: 0.586651\n",
      "[209]\ttraining's binary_logloss: 0.586612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[210]\ttraining's binary_logloss: 0.586586\n",
      "[211]\ttraining's binary_logloss: 0.586615\n",
      "[212]\ttraining's binary_logloss: 0.586621\n",
      "[213]\ttraining's binary_logloss: 0.58664\n",
      "[214]\ttraining's binary_logloss: 0.586647\n",
      "[215]\ttraining's binary_logloss: 0.586677\n",
      "[216]\ttraining's binary_logloss: 0.586656\n",
      "[217]\ttraining's binary_logloss: 0.586628\n",
      "[218]\ttraining's binary_logloss: 0.586611\n",
      "[219]\ttraining's binary_logloss: 0.586594\n",
      "[220]\ttraining's binary_logloss: 0.586572\n",
      "[221]\ttraining's binary_logloss: 0.586533\n",
      "[222]\ttraining's binary_logloss: 0.586493\n",
      "[223]\ttraining's binary_logloss: 0.586458\n",
      "[224]\ttraining's binary_logloss: 0.586439\n",
      "[225]\ttraining's binary_logloss: 0.58641\n",
      "[226]\ttraining's binary_logloss: 0.586403\n",
      "[227]\ttraining's binary_logloss: 0.586377\n",
      "[228]\ttraining's binary_logloss: 0.586348\n",
      "[229]\ttraining's binary_logloss: 0.586322\n",
      "[230]\ttraining's binary_logloss: 0.586298\n",
      "[231]\ttraining's binary_logloss: 0.586299\n",
      "[232]\ttraining's binary_logloss: 0.586298\n",
      "[233]\ttraining's binary_logloss: 0.586304\n",
      "[234]\ttraining's binary_logloss: 0.586311\n",
      "[235]\ttraining's binary_logloss: 0.586311\n",
      "[236]\ttraining's binary_logloss: 0.586269\n",
      "[237]\ttraining's binary_logloss: 0.586225\n",
      "[238]\ttraining's binary_logloss: 0.586183\n",
      "[239]\ttraining's binary_logloss: 0.586152\n",
      "[240]\ttraining's binary_logloss: 0.586112\n",
      "[241]\ttraining's binary_logloss: 0.586098\n",
      "[242]\ttraining's binary_logloss: 0.586086\n",
      "[243]\ttraining's binary_logloss: 0.586076\n",
      "[244]\ttraining's binary_logloss: 0.58605\n",
      "[245]\ttraining's binary_logloss: 0.586046\n",
      "[246]\ttraining's binary_logloss: 0.58598\n",
      "[247]\ttraining's binary_logloss: 0.585915\n",
      "[248]\ttraining's binary_logloss: 0.585853\n",
      "[249]\ttraining's binary_logloss: 0.585783\n",
      "[250]\ttraining's binary_logloss: 0.585718\n",
      "[251]\ttraining's binary_logloss: 0.585678\n",
      "[252]\ttraining's binary_logloss: 0.585623\n",
      "[253]\ttraining's binary_logloss: 0.58557\n",
      "[254]\ttraining's binary_logloss: 0.585509\n",
      "[255]\ttraining's binary_logloss: 0.585459\n",
      "[256]\ttraining's binary_logloss: 0.585443\n",
      "[257]\ttraining's binary_logloss: 0.585425\n",
      "[258]\ttraining's binary_logloss: 0.585406\n",
      "[259]\ttraining's binary_logloss: 0.585376\n",
      "[260]\ttraining's binary_logloss: 0.585356\n",
      "[261]\ttraining's binary_logloss: 0.585363\n",
      "[262]\ttraining's binary_logloss: 0.585341\n",
      "[263]\ttraining's binary_logloss: 0.585324\n",
      "[264]\ttraining's binary_logloss: 0.585299\n",
      "[265]\ttraining's binary_logloss: 0.585271\n",
      "[266]\ttraining's binary_logloss: 0.585267\n",
      "[267]\ttraining's binary_logloss: 0.585256\n",
      "[268]\ttraining's binary_logloss: 0.585264\n",
      "[269]\ttraining's binary_logloss: 0.585253\n",
      "[270]\ttraining's binary_logloss: 0.58526\n",
      "[271]\ttraining's binary_logloss: 0.585234\n",
      "[272]\ttraining's binary_logloss: 0.58523\n",
      "[273]\ttraining's binary_logloss: 0.5852\n",
      "[274]\ttraining's binary_logloss: 0.585172\n",
      "[275]\ttraining's binary_logloss: 0.58517\n",
      "[276]\ttraining's binary_logloss: 0.585125\n",
      "[277]\ttraining's binary_logloss: 0.585075\n",
      "[278]\ttraining's binary_logloss: 0.585028\n",
      "[279]\ttraining's binary_logloss: 0.584988\n",
      "[280]\ttraining's binary_logloss: 0.584943\n",
      "[281]\ttraining's binary_logloss: 0.584915\n",
      "[282]\ttraining's binary_logloss: 0.584887\n",
      "[283]\ttraining's binary_logloss: 0.584859\n",
      "[284]\ttraining's binary_logloss: 0.584828\n",
      "[285]\ttraining's binary_logloss: 0.584808\n",
      "[286]\ttraining's binary_logloss: 0.584752\n",
      "[287]\ttraining's binary_logloss: 0.584705\n",
      "[288]\ttraining's binary_logloss: 0.584664\n",
      "[289]\ttraining's binary_logloss: 0.584609\n",
      "[290]\ttraining's binary_logloss: 0.584547\n",
      "[291]\ttraining's binary_logloss: 0.584466\n",
      "[292]\ttraining's binary_logloss: 0.584383\n",
      "[293]\ttraining's binary_logloss: 0.584305\n",
      "[294]\ttraining's binary_logloss: 0.58423\n",
      "[295]\ttraining's binary_logloss: 0.584154\n",
      "[296]\ttraining's binary_logloss: 0.584113\n",
      "[297]\ttraining's binary_logloss: 0.584083\n",
      "[298]\ttraining's binary_logloss: 0.584044\n",
      "[299]\ttraining's binary_logloss: 0.584008\n",
      "[300]\ttraining's binary_logloss: 0.58397\n",
      "[301]\ttraining's binary_logloss: 0.583915\n",
      "[302]\ttraining's binary_logloss: 0.583868\n",
      "[303]\ttraining's binary_logloss: 0.583812\n",
      "[304]\ttraining's binary_logloss: 0.583745\n",
      "[305]\ttraining's binary_logloss: 0.583694\n",
      "[306]\ttraining's binary_logloss: 0.583639\n",
      "[307]\ttraining's binary_logloss: 0.583591\n",
      "[308]\ttraining's binary_logloss: 0.583546\n",
      "[309]\ttraining's binary_logloss: 0.583505\n",
      "[310]\ttraining's binary_logloss: 0.583463\n",
      "[311]\ttraining's binary_logloss: 0.583412\n",
      "[312]\ttraining's binary_logloss: 0.583351\n",
      "[313]\ttraining's binary_logloss: 0.583283\n",
      "[314]\ttraining's binary_logloss: 0.583223\n",
      "[315]\ttraining's binary_logloss: 0.583176\n",
      "[316]\ttraining's binary_logloss: 0.583123\n",
      "[317]\ttraining's binary_logloss: 0.583071\n",
      "[318]\ttraining's binary_logloss: 0.58302\n",
      "[319]\ttraining's binary_logloss: 0.582977\n",
      "[320]\ttraining's binary_logloss: 0.582933\n",
      "[321]\ttraining's binary_logloss: 0.582869\n",
      "[322]\ttraining's binary_logloss: 0.582812\n",
      "[323]\ttraining's binary_logloss: 0.582748\n",
      "[324]\ttraining's binary_logloss: 0.582689\n",
      "[325]\ttraining's binary_logloss: 0.582631\n",
      "[326]\ttraining's binary_logloss: 0.582547\n",
      "[327]\ttraining's binary_logloss: 0.582476\n",
      "[328]\ttraining's binary_logloss: 0.582393\n",
      "[329]\ttraining's binary_logloss: 0.582318\n",
      "[330]\ttraining's binary_logloss: 0.582246\n",
      "[331]\ttraining's binary_logloss: 0.582186\n",
      "[332]\ttraining's binary_logloss: 0.582131\n",
      "[333]\ttraining's binary_logloss: 0.582071\n",
      "[334]\ttraining's binary_logloss: 0.582011\n",
      "[335]\ttraining's binary_logloss: 0.581961\n",
      "[336]\ttraining's binary_logloss: 0.581926\n",
      "[337]\ttraining's binary_logloss: 0.581892\n",
      "[338]\ttraining's binary_logloss: 0.581861\n",
      "[339]\ttraining's binary_logloss: 0.581834\n",
      "[340]\ttraining's binary_logloss: 0.581806\n",
      "[341]\ttraining's binary_logloss: 0.581765\n",
      "[342]\ttraining's binary_logloss: 0.581712\n",
      "[343]\ttraining's binary_logloss: 0.581668\n",
      "[344]\ttraining's binary_logloss: 0.581624\n",
      "[345]\ttraining's binary_logloss: 0.58157\n",
      "[346]\ttraining's binary_logloss: 0.581493\n",
      "[347]\ttraining's binary_logloss: 0.581424\n",
      "[348]\ttraining's binary_logloss: 0.581364\n",
      "[349]\ttraining's binary_logloss: 0.581289\n",
      "[350]\ttraining's binary_logloss: 0.581226\n",
      "[351]\ttraining's binary_logloss: 0.58119\n",
      "[352]\ttraining's binary_logloss: 0.58115\n",
      "[353]\ttraining's binary_logloss: 0.581112\n",
      "[354]\ttraining's binary_logloss: 0.581091\n",
      "[355]\ttraining's binary_logloss: 0.581057\n",
      "[356]\ttraining's binary_logloss: 0.581012\n",
      "[357]\ttraining's binary_logloss: 0.580955\n",
      "[358]\ttraining's binary_logloss: 0.580907\n",
      "[359]\ttraining's binary_logloss: 0.58085\n",
      "[360]\ttraining's binary_logloss: 0.580806\n",
      "[361]\ttraining's binary_logloss: 0.580733\n",
      "[362]\ttraining's binary_logloss: 0.580659\n",
      "[363]\ttraining's binary_logloss: 0.580589\n",
      "[364]\ttraining's binary_logloss: 0.580512\n",
      "[365]\ttraining's binary_logloss: 0.580439\n",
      "[366]\ttraining's binary_logloss: 0.580373\n",
      "[367]\ttraining's binary_logloss: 0.580319\n",
      "[368]\ttraining's binary_logloss: 0.580272\n",
      "[369]\ttraining's binary_logloss: 0.58022\n",
      "[370]\ttraining's binary_logloss: 0.580171\n",
      "[371]\ttraining's binary_logloss: 0.58011\n",
      "[372]\ttraining's binary_logloss: 0.580035\n",
      "[373]\ttraining's binary_logloss: 0.579974\n",
      "[374]\ttraining's binary_logloss: 0.579893\n",
      "[375]\ttraining's binary_logloss: 0.579825\n",
      "[376]\ttraining's binary_logloss: 0.579757\n",
      "[377]\ttraining's binary_logloss: 0.57969\n",
      "[378]\ttraining's binary_logloss: 0.579632\n",
      "[379]\ttraining's binary_logloss: 0.579577\n",
      "[380]\ttraining's binary_logloss: 0.579524\n",
      "[381]\ttraining's binary_logloss: 0.579432\n",
      "[382]\ttraining's binary_logloss: 0.579337\n",
      "[383]\ttraining's binary_logloss: 0.579258\n",
      "[384]\ttraining's binary_logloss: 0.579178\n",
      "[385]\ttraining's binary_logloss: 0.579096\n",
      "[386]\ttraining's binary_logloss: 0.579026\n",
      "[387]\ttraining's binary_logloss: 0.578961\n",
      "[388]\ttraining's binary_logloss: 0.578871\n",
      "[389]\ttraining's binary_logloss: 0.578802\n",
      "[390]\ttraining's binary_logloss: 0.578716\n",
      "[391]\ttraining's binary_logloss: 0.578639\n",
      "[392]\ttraining's binary_logloss: 0.578546\n",
      "[393]\ttraining's binary_logloss: 0.578467\n",
      "[394]\ttraining's binary_logloss: 0.578384\n",
      "[395]\ttraining's binary_logloss: 0.578302\n",
      "[396]\ttraining's binary_logloss: 0.578261\n",
      "[397]\ttraining's binary_logloss: 0.578215\n",
      "[398]\ttraining's binary_logloss: 0.578168\n",
      "[399]\ttraining's binary_logloss: 0.578128\n",
      "[400]\ttraining's binary_logloss: 0.578084\n",
      "[401]\ttraining's binary_logloss: 0.577998\n",
      "[402]\ttraining's binary_logloss: 0.577927\n",
      "[403]\ttraining's binary_logloss: 0.577858\n",
      "[404]\ttraining's binary_logloss: 0.577794\n",
      "[405]\ttraining's binary_logloss: 0.577724\n",
      "[406]\ttraining's binary_logloss: 0.577672\n",
      "[407]\ttraining's binary_logloss: 0.577634\n",
      "[408]\ttraining's binary_logloss: 0.577552\n",
      "[409]\ttraining's binary_logloss: 0.577475\n",
      "[410]\ttraining's binary_logloss: 0.577391\n",
      "[411]\ttraining's binary_logloss: 0.577307\n",
      "[412]\ttraining's binary_logloss: 0.577227\n",
      "[413]\ttraining's binary_logloss: 0.577148\n",
      "[414]\ttraining's binary_logloss: 0.577081\n",
      "[415]\ttraining's binary_logloss: 0.577009\n",
      "[416]\ttraining's binary_logloss: 0.576921\n",
      "[417]\ttraining's binary_logloss: 0.576839\n",
      "[418]\ttraining's binary_logloss: 0.576758\n",
      "[419]\ttraining's binary_logloss: 0.576673\n",
      "[420]\ttraining's binary_logloss: 0.576606\n",
      "[421]\ttraining's binary_logloss: 0.576556\n",
      "[422]\ttraining's binary_logloss: 0.5765\n",
      "[423]\ttraining's binary_logloss: 0.576448\n",
      "[424]\ttraining's binary_logloss: 0.576404\n",
      "[425]\ttraining's binary_logloss: 0.576355\n",
      "[426]\ttraining's binary_logloss: 0.576298\n",
      "[427]\ttraining's binary_logloss: 0.576241\n",
      "[428]\ttraining's binary_logloss: 0.576204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[429]\ttraining's binary_logloss: 0.576142\n",
      "[430]\ttraining's binary_logloss: 0.576081\n",
      "[431]\ttraining's binary_logloss: 0.576009\n",
      "[432]\ttraining's binary_logloss: 0.575933\n",
      "[433]\ttraining's binary_logloss: 0.575867\n",
      "[434]\ttraining's binary_logloss: 0.575796\n",
      "[435]\ttraining's binary_logloss: 0.575721\n",
      "[436]\ttraining's binary_logloss: 0.575659\n",
      "[437]\ttraining's binary_logloss: 0.575598\n",
      "[438]\ttraining's binary_logloss: 0.575547\n",
      "[439]\ttraining's binary_logloss: 0.575481\n",
      "[440]\ttraining's binary_logloss: 0.575417\n",
      "[441]\ttraining's binary_logloss: 0.575344\n",
      "[442]\ttraining's binary_logloss: 0.575269\n",
      "[443]\ttraining's binary_logloss: 0.575196\n",
      "[444]\ttraining's binary_logloss: 0.575133\n",
      "[445]\ttraining's binary_logloss: 0.575066\n",
      "[446]\ttraining's binary_logloss: 0.574975\n",
      "[447]\ttraining's binary_logloss: 0.574885\n",
      "[448]\ttraining's binary_logloss: 0.574779\n",
      "[449]\ttraining's binary_logloss: 0.574679\n",
      "[450]\ttraining's binary_logloss: 0.574589\n",
      "[451]\ttraining's binary_logloss: 0.57451\n",
      "[452]\ttraining's binary_logloss: 0.57443\n",
      "[453]\ttraining's binary_logloss: 0.574353\n",
      "[454]\ttraining's binary_logloss: 0.574277\n",
      "[455]\ttraining's binary_logloss: 0.574193\n",
      "[456]\ttraining's binary_logloss: 0.5741\n",
      "[457]\ttraining's binary_logloss: 0.57401\n",
      "[458]\ttraining's binary_logloss: 0.573948\n",
      "[459]\ttraining's binary_logloss: 0.573863\n",
      "[460]\ttraining's binary_logloss: 0.573804\n",
      "[461]\ttraining's binary_logloss: 0.573731\n",
      "[462]\ttraining's binary_logloss: 0.57366\n",
      "[463]\ttraining's binary_logloss: 0.573584\n",
      "[464]\ttraining's binary_logloss: 0.573515\n",
      "[465]\ttraining's binary_logloss: 0.573441\n",
      "[466]\ttraining's binary_logloss: 0.573366\n",
      "[467]\ttraining's binary_logloss: 0.573298\n",
      "[468]\ttraining's binary_logloss: 0.573237\n",
      "[469]\ttraining's binary_logloss: 0.573161\n",
      "[470]\ttraining's binary_logloss: 0.573102\n",
      "[471]\ttraining's binary_logloss: 0.573003\n",
      "[472]\ttraining's binary_logloss: 0.572911\n",
      "[473]\ttraining's binary_logloss: 0.572812\n",
      "[474]\ttraining's binary_logloss: 0.572715\n",
      "[475]\ttraining's binary_logloss: 0.572621\n",
      "[476]\ttraining's binary_logloss: 0.572537\n",
      "[477]\ttraining's binary_logloss: 0.572457\n",
      "[478]\ttraining's binary_logloss: 0.572394\n",
      "[479]\ttraining's binary_logloss: 0.572316\n",
      "[480]\ttraining's binary_logloss: 0.572257\n",
      "[481]\ttraining's binary_logloss: 0.57221\n",
      "[482]\ttraining's binary_logloss: 0.572161\n",
      "[483]\ttraining's binary_logloss: 0.572121\n",
      "[484]\ttraining's binary_logloss: 0.572078\n",
      "[485]\ttraining's binary_logloss: 0.572037\n",
      "[486]\ttraining's binary_logloss: 0.571941\n",
      "[487]\ttraining's binary_logloss: 0.571845\n",
      "[488]\ttraining's binary_logloss: 0.57177\n",
      "[489]\ttraining's binary_logloss: 0.571692\n",
      "[490]\ttraining's binary_logloss: 0.571603\n",
      "[491]\ttraining's binary_logloss: 0.571502\n",
      "[492]\ttraining's binary_logloss: 0.571404\n",
      "[493]\ttraining's binary_logloss: 0.571303\n",
      "[494]\ttraining's binary_logloss: 0.571205\n",
      "[495]\ttraining's binary_logloss: 0.571108\n",
      "[496]\ttraining's binary_logloss: 0.571034\n",
      "[497]\ttraining's binary_logloss: 0.570952\n",
      "[498]\ttraining's binary_logloss: 0.570874\n",
      "[499]\ttraining's binary_logloss: 0.570794\n",
      "[500]\ttraining's binary_logloss: 0.570707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py:2267: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "percent = 0.95\n",
    "ens = [0.2,0.3,0.5]\n",
    "for met in ['rfecv','lr','rf','fi_rf','fi_lgm']:\n",
    "    if met in ['rfecv','lr','rf']:\n",
    "        feat = getfeaturesets(X_Train,Y_Train,method  = met)\n",
    "    elif met == 'fi_rf':\n",
    "        feat = getfeaturesets(X_Train,Y_Train,method  = 'fi_rf',\n",
    "                              weights = getfeatureimportance(X_Train,trainedall_noselect[1],'rf',ret = True),perc = percent)\n",
    "    elif met == 'fi_lgm':\n",
    "        feat = getfeaturesets(X_Train,Y_Train,method  = 'fi_rf',\n",
    "                              weights = getfeatureimportance(X_Train,trainedall_noselect[2],'lgm',ret = True),perc = percent)\n",
    "    \n",
    "    X_featTrain = X_Train[feat]\n",
    "    X_featTest = X_Test[feat]\n",
    "    predall_select = []\n",
    "    trainedall_select = []\n",
    "    for model in ['lr','rf','lgm']:\n",
    "        (pred,tra) = getprediction(model,X_featTrain,Y_Train,X_featTest)\n",
    "        predall_select.append(pred)\n",
    "        trainedall_select.append(tra)\n",
    "        plotAUC(Y_Test,pred,model,other = met)\n",
    "    plotAUC(Y_Test,ens[0]*predall_select[0]+ens[1]*predall_select[1]+ens[2]*predall_select[2],'ensemble',other = met)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation to find best parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#lightgbm\n",
    "#num_of_leave\n",
    "#min_data_in_leave 20\n",
    "\n",
    "#rf\n",
    "#n_estimators=1200, max_features='sqrt'\n",
    "\n",
    "#testRF(X_Train,Y_Train,X_Test,Y_Test, nestimator, maxfeat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features_values = [0.2,'sqrt']\n",
    "n_estimators_values = [600,750,900,1050,1200,1350,1500,1650]\n",
    "\n",
    "res = dict()\n",
    "for s in max_features_values:\n",
    "    res[s] = list()\n",
    "\n",
    "#Now train and get results for each option\n",
    "for s in max_features_values:\n",
    "    for l in n_estimators_values:\n",
    "        res[s].append(testRF(X_Train,Y_Train,X_Test,Y_Test, l, s))  \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614787\n",
      "[2]\ttraining's binary_logloss: 0.613724\n",
      "[3]\ttraining's binary_logloss: 0.612709\n",
      "[4]\ttraining's binary_logloss: 0.611737\n",
      "[5]\ttraining's binary_logloss: 0.610853\n",
      "[6]\ttraining's binary_logloss: 0.609993\n",
      "[7]\ttraining's binary_logloss: 0.609191\n",
      "[8]\ttraining's binary_logloss: 0.608402\n",
      "[9]\ttraining's binary_logloss: 0.607647\n",
      "[10]\ttraining's binary_logloss: 0.606854\n",
      "[11]\ttraining's binary_logloss: 0.606073\n",
      "[12]\ttraining's binary_logloss: 0.605323\n",
      "[13]\ttraining's binary_logloss: 0.604662\n",
      "[14]\ttraining's binary_logloss: 0.603961\n",
      "[15]\ttraining's binary_logloss: 0.603282\n",
      "[16]\ttraining's binary_logloss: 0.602686\n",
      "[17]\ttraining's binary_logloss: 0.602075\n",
      "[18]\ttraining's binary_logloss: 0.60146\n",
      "[19]\ttraining's binary_logloss: 0.600892\n",
      "[20]\ttraining's binary_logloss: 0.600326\n",
      "[21]\ttraining's binary_logloss: 0.5998\n",
      "[22]\ttraining's binary_logloss: 0.599349\n",
      "[23]\ttraining's binary_logloss: 0.598867\n",
      "[24]\ttraining's binary_logloss: 0.5984\n",
      "[25]\ttraining's binary_logloss: 0.597963\n",
      "[26]\ttraining's binary_logloss: 0.59754\n",
      "[27]\ttraining's binary_logloss: 0.597132\n",
      "[28]\ttraining's binary_logloss: 0.596767\n",
      "[29]\ttraining's binary_logloss: 0.596398\n",
      "[30]\ttraining's binary_logloss: 0.59607\n",
      "[31]\ttraining's binary_logloss: 0.595793\n",
      "[32]\ttraining's binary_logloss: 0.595439\n",
      "[33]\ttraining's binary_logloss: 0.595193\n",
      "[34]\ttraining's binary_logloss: 0.594925\n",
      "[35]\ttraining's binary_logloss: 0.594604\n",
      "[36]\ttraining's binary_logloss: 0.594313\n",
      "[37]\ttraining's binary_logloss: 0.594037\n",
      "[38]\ttraining's binary_logloss: 0.593763\n",
      "[39]\ttraining's binary_logloss: 0.593517\n",
      "[40]\ttraining's binary_logloss: 0.593267\n",
      "[41]\ttraining's binary_logloss: 0.593007\n",
      "[42]\ttraining's binary_logloss: 0.592762\n",
      "[43]\ttraining's binary_logloss: 0.592528\n",
      "[44]\ttraining's binary_logloss: 0.592333\n",
      "[45]\ttraining's binary_logloss: 0.592125\n",
      "[46]\ttraining's binary_logloss: 0.591895\n",
      "[47]\ttraining's binary_logloss: 0.591678\n",
      "[48]\ttraining's binary_logloss: 0.591475\n",
      "[49]\ttraining's binary_logloss: 0.591245\n",
      "[50]\ttraining's binary_logloss: 0.591014\n",
      "[51]\ttraining's binary_logloss: 0.590818\n",
      "[52]\ttraining's binary_logloss: 0.590637\n",
      "[53]\ttraining's binary_logloss: 0.590472\n",
      "[54]\ttraining's binary_logloss: 0.590357\n",
      "[55]\ttraining's binary_logloss: 0.590202\n",
      "[56]\ttraining's binary_logloss: 0.590103\n",
      "[57]\ttraining's binary_logloss: 0.589938\n",
      "[58]\ttraining's binary_logloss: 0.589773\n",
      "[59]\ttraining's binary_logloss: 0.589698\n",
      "[60]\ttraining's binary_logloss: 0.589545\n",
      "[61]\ttraining's binary_logloss: 0.589493\n",
      "[62]\ttraining's binary_logloss: 0.589448\n",
      "[63]\ttraining's binary_logloss: 0.589422\n",
      "[64]\ttraining's binary_logloss: 0.58938\n",
      "[65]\ttraining's binary_logloss: 0.589343\n",
      "[66]\ttraining's binary_logloss: 0.589268\n",
      "[67]\ttraining's binary_logloss: 0.589218\n",
      "[68]\ttraining's binary_logloss: 0.589169\n",
      "[69]\ttraining's binary_logloss: 0.589118\n",
      "[70]\ttraining's binary_logloss: 0.589084\n",
      "[71]\ttraining's binary_logloss: 0.589063\n",
      "[72]\ttraining's binary_logloss: 0.589069\n",
      "[73]\ttraining's binary_logloss: 0.589007\n",
      "[74]\ttraining's binary_logloss: 0.58896\n",
      "[75]\ttraining's binary_logloss: 0.588916\n",
      "[76]\ttraining's binary_logloss: 0.588861\n",
      "[77]\ttraining's binary_logloss: 0.588826\n",
      "[78]\ttraining's binary_logloss: 0.588795\n",
      "[79]\ttraining's binary_logloss: 0.588793\n",
      "[80]\ttraining's binary_logloss: 0.58874\n",
      "[81]\ttraining's binary_logloss: 0.588659\n",
      "[82]\ttraining's binary_logloss: 0.588672\n",
      "[83]\ttraining's binary_logloss: 0.588629\n",
      "[84]\ttraining's binary_logloss: 0.588561\n",
      "[85]\ttraining's binary_logloss: 0.588577\n",
      "[86]\ttraining's binary_logloss: 0.588605\n",
      "[87]\ttraining's binary_logloss: 0.588566\n",
      "[88]\ttraining's binary_logloss: 0.588537\n",
      "[89]\ttraining's binary_logloss: 0.588501\n",
      "[90]\ttraining's binary_logloss: 0.588472\n",
      "[91]\ttraining's binary_logloss: 0.58845\n",
      "[92]\ttraining's binary_logloss: 0.588433\n",
      "[93]\ttraining's binary_logloss: 0.588424\n",
      "[94]\ttraining's binary_logloss: 0.588417\n",
      "[95]\ttraining's binary_logloss: 0.588468\n",
      "[96]\ttraining's binary_logloss: 0.58849\n",
      "[97]\ttraining's binary_logloss: 0.588494\n",
      "[98]\ttraining's binary_logloss: 0.588514\n",
      "[99]\ttraining's binary_logloss: 0.588532\n",
      "[100]\ttraining's binary_logloss: 0.58856\n",
      "[101]\ttraining's binary_logloss: 0.58857\n",
      "[102]\ttraining's binary_logloss: 0.588621\n",
      "[103]\ttraining's binary_logloss: 0.588675\n",
      "[104]\ttraining's binary_logloss: 0.588701\n",
      "[105]\ttraining's binary_logloss: 0.588759\n",
      "[106]\ttraining's binary_logloss: 0.58882\n",
      "[107]\ttraining's binary_logloss: 0.588816\n",
      "[108]\ttraining's binary_logloss: 0.588886\n",
      "[109]\ttraining's binary_logloss: 0.588959\n",
      "[110]\ttraining's binary_logloss: 0.588959\n",
      "[111]\ttraining's binary_logloss: 0.588965\n",
      "[112]\ttraining's binary_logloss: 0.589001\n",
      "[113]\ttraining's binary_logloss: 0.588995\n",
      "[114]\ttraining's binary_logloss: 0.588993\n",
      "[115]\ttraining's binary_logloss: 0.58901\n",
      "[116]\ttraining's binary_logloss: 0.588988\n",
      "[117]\ttraining's binary_logloss: 0.589024\n",
      "[118]\ttraining's binary_logloss: 0.589018\n",
      "[119]\ttraining's binary_logloss: 0.589017\n",
      "[120]\ttraining's binary_logloss: 0.589063\n",
      "[121]\ttraining's binary_logloss: 0.589076\n",
      "[122]\ttraining's binary_logloss: 0.589093\n",
      "[123]\ttraining's binary_logloss: 0.589116\n",
      "[124]\ttraining's binary_logloss: 0.589141\n",
      "[125]\ttraining's binary_logloss: 0.589167\n",
      "[126]\ttraining's binary_logloss: 0.589193\n",
      "[127]\ttraining's binary_logloss: 0.589191\n",
      "[128]\ttraining's binary_logloss: 0.589216\n",
      "[129]\ttraining's binary_logloss: 0.589242\n",
      "[130]\ttraining's binary_logloss: 0.589274\n",
      "[131]\ttraining's binary_logloss: 0.589331\n",
      "[132]\ttraining's binary_logloss: 0.589387\n",
      "[133]\ttraining's binary_logloss: 0.58946\n",
      "[134]\ttraining's binary_logloss: 0.589537\n",
      "[135]\ttraining's binary_logloss: 0.589617\n",
      "[136]\ttraining's binary_logloss: 0.589672\n",
      "[137]\ttraining's binary_logloss: 0.589731\n",
      "[138]\ttraining's binary_logloss: 0.589791\n",
      "[139]\ttraining's binary_logloss: 0.58984\n",
      "[140]\ttraining's binary_logloss: 0.589904\n",
      "[141]\ttraining's binary_logloss: 0.589943\n",
      "[142]\ttraining's binary_logloss: 0.58996\n",
      "[143]\ttraining's binary_logloss: 0.590003\n",
      "[144]\ttraining's binary_logloss: 0.590035\n",
      "[145]\ttraining's binary_logloss: 0.590069\n",
      "[146]\ttraining's binary_logloss: 0.590111\n",
      "[147]\ttraining's binary_logloss: 0.590163\n",
      "[148]\ttraining's binary_logloss: 0.590195\n",
      "[149]\ttraining's binary_logloss: 0.590242\n",
      "[150]\ttraining's binary_logloss: 0.590286\n",
      "[151]\ttraining's binary_logloss: 0.590336\n",
      "[152]\ttraining's binary_logloss: 0.590388\n",
      "[153]\ttraining's binary_logloss: 0.590415\n",
      "[154]\ttraining's binary_logloss: 0.590465\n",
      "[155]\ttraining's binary_logloss: 0.590503\n",
      "[156]\ttraining's binary_logloss: 0.590548\n",
      "[157]\ttraining's binary_logloss: 0.590598\n",
      "[158]\ttraining's binary_logloss: 0.590615\n",
      "[159]\ttraining's binary_logloss: 0.590655\n",
      "[160]\ttraining's binary_logloss: 0.590699\n",
      "[161]\ttraining's binary_logloss: 0.590695\n",
      "[162]\ttraining's binary_logloss: 0.590693\n",
      "[163]\ttraining's binary_logloss: 0.590734\n",
      "[164]\ttraining's binary_logloss: 0.590736\n",
      "[165]\ttraining's binary_logloss: 0.590744\n",
      "[166]\ttraining's binary_logloss: 0.590764\n",
      "[167]\ttraining's binary_logloss: 0.590814\n",
      "[168]\ttraining's binary_logloss: 0.590873\n",
      "[169]\ttraining's binary_logloss: 0.590902\n",
      "[170]\ttraining's binary_logloss: 0.59091\n",
      "[171]\ttraining's binary_logloss: 0.590951\n",
      "[172]\ttraining's binary_logloss: 0.590975\n",
      "[173]\ttraining's binary_logloss: 0.591003\n",
      "[174]\ttraining's binary_logloss: 0.591036\n",
      "[175]\ttraining's binary_logloss: 0.591102\n",
      "[176]\ttraining's binary_logloss: 0.591109\n",
      "[177]\ttraining's binary_logloss: 0.591115\n",
      "[178]\ttraining's binary_logloss: 0.591126\n",
      "[179]\ttraining's binary_logloss: 0.591159\n",
      "[180]\ttraining's binary_logloss: 0.591161\n",
      "[181]\ttraining's binary_logloss: 0.591183\n",
      "[182]\ttraining's binary_logloss: 0.591208\n",
      "[183]\ttraining's binary_logloss: 0.591222\n",
      "[184]\ttraining's binary_logloss: 0.591255\n",
      "[185]\ttraining's binary_logloss: 0.591284\n",
      "[186]\ttraining's binary_logloss: 0.591344\n",
      "[187]\ttraining's binary_logloss: 0.591405\n",
      "[188]\ttraining's binary_logloss: 0.591467\n",
      "[189]\ttraining's binary_logloss: 0.591498\n",
      "[190]\ttraining's binary_logloss: 0.591555\n",
      "[191]\ttraining's binary_logloss: 0.59157\n",
      "[192]\ttraining's binary_logloss: 0.591565\n",
      "[193]\ttraining's binary_logloss: 0.591581\n",
      "[194]\ttraining's binary_logloss: 0.591599\n",
      "[195]\ttraining's binary_logloss: 0.591619\n",
      "[196]\ttraining's binary_logloss: 0.591639\n",
      "[197]\ttraining's binary_logloss: 0.591628\n",
      "[198]\ttraining's binary_logloss: 0.591648\n",
      "[199]\ttraining's binary_logloss: 0.59167\n",
      "[200]\ttraining's binary_logloss: 0.591671\n",
      "[201]\ttraining's binary_logloss: 0.591705\n",
      "[202]\ttraining's binary_logloss: 0.591727\n",
      "[203]\ttraining's binary_logloss: 0.591752\n",
      "[204]\ttraining's binary_logloss: 0.591781\n",
      "[205]\ttraining's binary_logloss: 0.591805\n",
      "[206]\ttraining's binary_logloss: 0.591786\n",
      "[207]\ttraining's binary_logloss: 0.591748\n",
      "[208]\ttraining's binary_logloss: 0.591723\n",
      "[209]\ttraining's binary_logloss: 0.591708\n",
      "[210]\ttraining's binary_logloss: 0.591656\n",
      "[211]\ttraining's binary_logloss: 0.591675\n",
      "[212]\ttraining's binary_logloss: 0.591693\n",
      "[213]\ttraining's binary_logloss: 0.591715\n",
      "[214]\ttraining's binary_logloss: 0.591738\n",
      "[215]\ttraining's binary_logloss: 0.591772\n",
      "[216]\ttraining's binary_logloss: 0.591756\n",
      "[217]\ttraining's binary_logloss: 0.591733\n",
      "[218]\ttraining's binary_logloss: 0.59172\n",
      "[219]\ttraining's binary_logloss: 0.591687\n",
      "[220]\ttraining's binary_logloss: 0.591666\n",
      "[221]\ttraining's binary_logloss: 0.591641\n",
      "[222]\ttraining's binary_logloss: 0.591634\n",
      "[223]\ttraining's binary_logloss: 0.591612\n",
      "[224]\ttraining's binary_logloss: 0.591593\n",
      "[225]\ttraining's binary_logloss: 0.591585\n",
      "[226]\ttraining's binary_logloss: 0.591574\n",
      "[227]\ttraining's binary_logloss: 0.591558\n",
      "[228]\ttraining's binary_logloss: 0.591544\n",
      "[229]\ttraining's binary_logloss: 0.591535\n",
      "[230]\ttraining's binary_logloss: 0.591508\n",
      "[231]\ttraining's binary_logloss: 0.591521\n",
      "[232]\ttraining's binary_logloss: 0.591536\n",
      "[233]\ttraining's binary_logloss: 0.591532\n",
      "[234]\ttraining's binary_logloss: 0.591548\n",
      "[235]\ttraining's binary_logloss: 0.591557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[236]\ttraining's binary_logloss: 0.591538\n",
      "[237]\ttraining's binary_logloss: 0.591518\n",
      "[238]\ttraining's binary_logloss: 0.591496\n",
      "[239]\ttraining's binary_logloss: 0.591474\n",
      "[240]\ttraining's binary_logloss: 0.591444\n",
      "[241]\ttraining's binary_logloss: 0.591423\n",
      "[242]\ttraining's binary_logloss: 0.591424\n",
      "[243]\ttraining's binary_logloss: 0.591425\n",
      "[244]\ttraining's binary_logloss: 0.591433\n",
      "[245]\ttraining's binary_logloss: 0.591441\n",
      "[246]\ttraining's binary_logloss: 0.591397\n",
      "[247]\ttraining's binary_logloss: 0.591335\n",
      "[248]\ttraining's binary_logloss: 0.591275\n",
      "[249]\ttraining's binary_logloss: 0.591222\n",
      "[250]\ttraining's binary_logloss: 0.591163\n",
      "[251]\ttraining's binary_logloss: 0.591117\n",
      "[252]\ttraining's binary_logloss: 0.591093\n",
      "[253]\ttraining's binary_logloss: 0.591037\n",
      "[254]\ttraining's binary_logloss: 0.590996\n",
      "[255]\ttraining's binary_logloss: 0.590949\n",
      "[256]\ttraining's binary_logloss: 0.590946\n",
      "[257]\ttraining's binary_logloss: 0.590946\n",
      "[258]\ttraining's binary_logloss: 0.590937\n",
      "[259]\ttraining's binary_logloss: 0.590915\n",
      "[260]\ttraining's binary_logloss: 0.590896\n",
      "[261]\ttraining's binary_logloss: 0.590908\n",
      "[262]\ttraining's binary_logloss: 0.590926\n",
      "[263]\ttraining's binary_logloss: 0.590931\n",
      "[264]\ttraining's binary_logloss: 0.590949\n",
      "[265]\ttraining's binary_logloss: 0.590957\n",
      "[266]\ttraining's binary_logloss: 0.59096\n",
      "[267]\ttraining's binary_logloss: 0.590971\n",
      "[268]\ttraining's binary_logloss: 0.590984\n",
      "[269]\ttraining's binary_logloss: 0.590997\n",
      "[270]\ttraining's binary_logloss: 0.590999\n",
      "[271]\ttraining's binary_logloss: 0.591008\n",
      "[272]\ttraining's binary_logloss: 0.590989\n",
      "[273]\ttraining's binary_logloss: 0.590999\n",
      "[274]\ttraining's binary_logloss: 0.590982\n",
      "[275]\ttraining's binary_logloss: 0.590996\n",
      "[276]\ttraining's binary_logloss: 0.590959\n",
      "[277]\ttraining's binary_logloss: 0.590923\n",
      "[278]\ttraining's binary_logloss: 0.590887\n",
      "[279]\ttraining's binary_logloss: 0.590859\n",
      "[280]\ttraining's binary_logloss: 0.590825\n",
      "[281]\ttraining's binary_logloss: 0.59082\n",
      "[282]\ttraining's binary_logloss: 0.590808\n",
      "[283]\ttraining's binary_logloss: 0.590797\n",
      "[284]\ttraining's binary_logloss: 0.590792\n",
      "[285]\ttraining's binary_logloss: 0.590783\n",
      "[286]\ttraining's binary_logloss: 0.590731\n",
      "[287]\ttraining's binary_logloss: 0.590684\n",
      "[288]\ttraining's binary_logloss: 0.590647\n",
      "[289]\ttraining's binary_logloss: 0.590604\n",
      "[290]\ttraining's binary_logloss: 0.59056\n",
      "[291]\ttraining's binary_logloss: 0.59049\n",
      "[292]\ttraining's binary_logloss: 0.590426\n",
      "[293]\ttraining's binary_logloss: 0.590368\n",
      "[294]\ttraining's binary_logloss: 0.590313\n",
      "[295]\ttraining's binary_logloss: 0.59024\n",
      "[296]\ttraining's binary_logloss: 0.590211\n",
      "[297]\ttraining's binary_logloss: 0.590184\n",
      "[298]\ttraining's binary_logloss: 0.590156\n",
      "[299]\ttraining's binary_logloss: 0.590139\n",
      "[300]\ttraining's binary_logloss: 0.590113\n",
      "[301]\ttraining's binary_logloss: 0.590068\n",
      "[302]\ttraining's binary_logloss: 0.590033\n",
      "[303]\ttraining's binary_logloss: 0.589991\n",
      "[304]\ttraining's binary_logloss: 0.589971\n",
      "[305]\ttraining's binary_logloss: 0.589929\n",
      "[306]\ttraining's binary_logloss: 0.58989\n",
      "[307]\ttraining's binary_logloss: 0.589852\n",
      "[308]\ttraining's binary_logloss: 0.589815\n",
      "[309]\ttraining's binary_logloss: 0.589775\n",
      "[310]\ttraining's binary_logloss: 0.589738\n",
      "[311]\ttraining's binary_logloss: 0.5897\n",
      "[312]\ttraining's binary_logloss: 0.58966\n",
      "[313]\ttraining's binary_logloss: 0.589624\n",
      "[314]\ttraining's binary_logloss: 0.589578\n",
      "[315]\ttraining's binary_logloss: 0.589536\n",
      "[316]\ttraining's binary_logloss: 0.589495\n",
      "[317]\ttraining's binary_logloss: 0.589452\n",
      "[318]\ttraining's binary_logloss: 0.589419\n",
      "[319]\ttraining's binary_logloss: 0.589374\n",
      "[320]\ttraining's binary_logloss: 0.589338\n",
      "[321]\ttraining's binary_logloss: 0.589282\n",
      "[322]\ttraining's binary_logloss: 0.589247\n",
      "[323]\ttraining's binary_logloss: 0.589201\n",
      "[324]\ttraining's binary_logloss: 0.589149\n",
      "[325]\ttraining's binary_logloss: 0.589112\n",
      "[326]\ttraining's binary_logloss: 0.58905\n",
      "[327]\ttraining's binary_logloss: 0.588997\n",
      "[328]\ttraining's binary_logloss: 0.588933\n",
      "[329]\ttraining's binary_logloss: 0.588868\n",
      "[330]\ttraining's binary_logloss: 0.588799\n",
      "[331]\ttraining's binary_logloss: 0.58876\n",
      "[332]\ttraining's binary_logloss: 0.588705\n",
      "[333]\ttraining's binary_logloss: 0.588657\n",
      "[334]\ttraining's binary_logloss: 0.588618\n",
      "[335]\ttraining's binary_logloss: 0.588572\n",
      "[336]\ttraining's binary_logloss: 0.588556\n",
      "[337]\ttraining's binary_logloss: 0.588532\n",
      "[338]\ttraining's binary_logloss: 0.58852\n",
      "[339]\ttraining's binary_logloss: 0.588499\n",
      "[340]\ttraining's binary_logloss: 0.588491\n",
      "[341]\ttraining's binary_logloss: 0.588454\n",
      "[342]\ttraining's binary_logloss: 0.588418\n",
      "[343]\ttraining's binary_logloss: 0.588381\n",
      "[344]\ttraining's binary_logloss: 0.588336\n",
      "[345]\ttraining's binary_logloss: 0.588301\n",
      "[346]\ttraining's binary_logloss: 0.588236\n",
      "[347]\ttraining's binary_logloss: 0.588169\n",
      "[348]\ttraining's binary_logloss: 0.588108\n",
      "[349]\ttraining's binary_logloss: 0.588048\n",
      "[350]\ttraining's binary_logloss: 0.58799\n",
      "[351]\ttraining's binary_logloss: 0.587965\n",
      "[352]\ttraining's binary_logloss: 0.587943\n",
      "[353]\ttraining's binary_logloss: 0.587922\n",
      "[354]\ttraining's binary_logloss: 0.5879\n",
      "[355]\ttraining's binary_logloss: 0.58788\n",
      "[356]\ttraining's binary_logloss: 0.587831\n",
      "[357]\ttraining's binary_logloss: 0.587782\n",
      "[358]\ttraining's binary_logloss: 0.587734\n",
      "[359]\ttraining's binary_logloss: 0.587695\n",
      "[360]\ttraining's binary_logloss: 0.587646\n",
      "[361]\ttraining's binary_logloss: 0.587583\n",
      "[362]\ttraining's binary_logloss: 0.58751\n",
      "[363]\ttraining's binary_logloss: 0.587453\n",
      "[364]\ttraining's binary_logloss: 0.587374\n",
      "[365]\ttraining's binary_logloss: 0.587306\n",
      "[366]\ttraining's binary_logloss: 0.587255\n",
      "[367]\ttraining's binary_logloss: 0.587208\n",
      "[368]\ttraining's binary_logloss: 0.587156\n",
      "[369]\ttraining's binary_logloss: 0.587112\n",
      "[370]\ttraining's binary_logloss: 0.587067\n",
      "[371]\ttraining's binary_logloss: 0.587006\n",
      "[372]\ttraining's binary_logloss: 0.586947\n",
      "[373]\ttraining's binary_logloss: 0.586884\n",
      "[374]\ttraining's binary_logloss: 0.586822\n",
      "[375]\ttraining's binary_logloss: 0.586761\n",
      "[376]\ttraining's binary_logloss: 0.586707\n",
      "[377]\ttraining's binary_logloss: 0.586657\n",
      "[378]\ttraining's binary_logloss: 0.586604\n",
      "[379]\ttraining's binary_logloss: 0.586558\n",
      "[380]\ttraining's binary_logloss: 0.586494\n",
      "[381]\ttraining's binary_logloss: 0.586409\n",
      "[382]\ttraining's binary_logloss: 0.586325\n",
      "[383]\ttraining's binary_logloss: 0.586248\n",
      "[384]\ttraining's binary_logloss: 0.58618\n",
      "[385]\ttraining's binary_logloss: 0.586099\n",
      "[386]\ttraining's binary_logloss: 0.586034\n",
      "[387]\ttraining's binary_logloss: 0.585977\n",
      "[388]\ttraining's binary_logloss: 0.585919\n",
      "[389]\ttraining's binary_logloss: 0.585862\n",
      "[390]\ttraining's binary_logloss: 0.585804\n",
      "[391]\ttraining's binary_logloss: 0.585732\n",
      "[392]\ttraining's binary_logloss: 0.585659\n",
      "[393]\ttraining's binary_logloss: 0.585584\n",
      "[394]\ttraining's binary_logloss: 0.585512\n",
      "[395]\ttraining's binary_logloss: 0.585435\n",
      "[396]\ttraining's binary_logloss: 0.585376\n",
      "[397]\ttraining's binary_logloss: 0.585342\n",
      "[398]\ttraining's binary_logloss: 0.585299\n",
      "[399]\ttraining's binary_logloss: 0.585259\n",
      "[400]\ttraining's binary_logloss: 0.585222\n",
      "[401]\ttraining's binary_logloss: 0.585168\n",
      "[402]\ttraining's binary_logloss: 0.585117\n",
      "[403]\ttraining's binary_logloss: 0.58506\n",
      "[404]\ttraining's binary_logloss: 0.58499\n",
      "[405]\ttraining's binary_logloss: 0.584935\n",
      "[406]\ttraining's binary_logloss: 0.584862\n",
      "[407]\ttraining's binary_logloss: 0.584796\n",
      "[408]\ttraining's binary_logloss: 0.584732\n",
      "[409]\ttraining's binary_logloss: 0.584669\n",
      "[410]\ttraining's binary_logloss: 0.584631\n",
      "[411]\ttraining's binary_logloss: 0.584557\n",
      "[412]\ttraining's binary_logloss: 0.584509\n",
      "[413]\ttraining's binary_logloss: 0.584439\n",
      "[414]\ttraining's binary_logloss: 0.58439\n",
      "[415]\ttraining's binary_logloss: 0.58434\n",
      "[416]\ttraining's binary_logloss: 0.584273\n",
      "[417]\ttraining's binary_logloss: 0.584208\n",
      "[418]\ttraining's binary_logloss: 0.584144\n",
      "[419]\ttraining's binary_logloss: 0.584086\n",
      "[420]\ttraining's binary_logloss: 0.584025\n",
      "[421]\ttraining's binary_logloss: 0.583986\n",
      "[422]\ttraining's binary_logloss: 0.583947\n",
      "[423]\ttraining's binary_logloss: 0.583905\n",
      "[424]\ttraining's binary_logloss: 0.583872\n",
      "[425]\ttraining's binary_logloss: 0.583832\n",
      "[426]\ttraining's binary_logloss: 0.583776\n",
      "[427]\ttraining's binary_logloss: 0.583716\n",
      "[428]\ttraining's binary_logloss: 0.583691\n",
      "[429]\ttraining's binary_logloss: 0.583631\n",
      "[430]\ttraining's binary_logloss: 0.583581\n",
      "[431]\ttraining's binary_logloss: 0.583518\n",
      "[432]\ttraining's binary_logloss: 0.583452\n",
      "[433]\ttraining's binary_logloss: 0.583389\n",
      "[434]\ttraining's binary_logloss: 0.583331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[435]\ttraining's binary_logloss: 0.583272\n",
      "[436]\ttraining's binary_logloss: 0.583223\n",
      "[437]\ttraining's binary_logloss: 0.583164\n",
      "[438]\ttraining's binary_logloss: 0.583123\n",
      "[439]\ttraining's binary_logloss: 0.583079\n",
      "[440]\ttraining's binary_logloss: 0.583036\n",
      "[441]\ttraining's binary_logloss: 0.582986\n",
      "[442]\ttraining's binary_logloss: 0.582926\n",
      "[443]\ttraining's binary_logloss: 0.582871\n",
      "[444]\ttraining's binary_logloss: 0.582818\n",
      "[445]\ttraining's binary_logloss: 0.582771\n",
      "[446]\ttraining's binary_logloss: 0.582678\n",
      "[447]\ttraining's binary_logloss: 0.582588\n",
      "[448]\ttraining's binary_logloss: 0.582502\n",
      "[449]\ttraining's binary_logloss: 0.582414\n",
      "[450]\ttraining's binary_logloss: 0.582338\n",
      "[451]\ttraining's binary_logloss: 0.58227\n",
      "[452]\ttraining's binary_logloss: 0.5822\n",
      "[453]\ttraining's binary_logloss: 0.582138\n",
      "[454]\ttraining's binary_logloss: 0.582083\n",
      "[455]\ttraining's binary_logloss: 0.582023\n",
      "[456]\ttraining's binary_logloss: 0.581958\n",
      "[457]\ttraining's binary_logloss: 0.581902\n",
      "[458]\ttraining's binary_logloss: 0.581827\n",
      "[459]\ttraining's binary_logloss: 0.581767\n",
      "[460]\ttraining's binary_logloss: 0.581723\n",
      "[461]\ttraining's binary_logloss: 0.581661\n",
      "[462]\ttraining's binary_logloss: 0.581595\n",
      "[463]\ttraining's binary_logloss: 0.581526\n",
      "[464]\ttraining's binary_logloss: 0.581459\n",
      "[465]\ttraining's binary_logloss: 0.581393\n",
      "[466]\ttraining's binary_logloss: 0.58133\n",
      "[467]\ttraining's binary_logloss: 0.581273\n",
      "[468]\ttraining's binary_logloss: 0.581217\n",
      "[469]\ttraining's binary_logloss: 0.581163\n",
      "[470]\ttraining's binary_logloss: 0.581111\n",
      "[471]\ttraining's binary_logloss: 0.581026\n",
      "[472]\ttraining's binary_logloss: 0.580952\n",
      "[473]\ttraining's binary_logloss: 0.58087\n",
      "[474]\ttraining's binary_logloss: 0.580789\n",
      "[475]\ttraining's binary_logloss: 0.580714\n",
      "[476]\ttraining's binary_logloss: 0.580653\n",
      "[477]\ttraining's binary_logloss: 0.580588\n",
      "[478]\ttraining's binary_logloss: 0.580534\n",
      "[479]\ttraining's binary_logloss: 0.580467\n",
      "[480]\ttraining's binary_logloss: 0.58043\n",
      "[481]\ttraining's binary_logloss: 0.580395\n",
      "[482]\ttraining's binary_logloss: 0.580355\n",
      "[483]\ttraining's binary_logloss: 0.580309\n",
      "[484]\ttraining's binary_logloss: 0.580281\n",
      "[485]\ttraining's binary_logloss: 0.580237\n",
      "[486]\ttraining's binary_logloss: 0.58015\n",
      "[487]\ttraining's binary_logloss: 0.580067\n",
      "[488]\ttraining's binary_logloss: 0.579978\n",
      "[489]\ttraining's binary_logloss: 0.579894\n",
      "[490]\ttraining's binary_logloss: 0.579827\n",
      "[491]\ttraining's binary_logloss: 0.579736\n",
      "[492]\ttraining's binary_logloss: 0.579632\n",
      "[493]\ttraining's binary_logloss: 0.579538\n",
      "[494]\ttraining's binary_logloss: 0.579439\n",
      "[495]\ttraining's binary_logloss: 0.579342\n",
      "[496]\ttraining's binary_logloss: 0.579285\n",
      "[497]\ttraining's binary_logloss: 0.579227\n",
      "[498]\ttraining's binary_logloss: 0.57917\n",
      "[499]\ttraining's binary_logloss: 0.579114\n",
      "[500]\ttraining's binary_logloss: 0.579066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614441\n",
      "[2]\ttraining's binary_logloss: 0.61311\n",
      "[3]\ttraining's binary_logloss: 0.611812\n",
      "[4]\ttraining's binary_logloss: 0.610567\n",
      "[5]\ttraining's binary_logloss: 0.609378\n",
      "[6]\ttraining's binary_logloss: 0.608204\n",
      "[7]\ttraining's binary_logloss: 0.607092\n",
      "[8]\ttraining's binary_logloss: 0.606031\n",
      "[9]\ttraining's binary_logloss: 0.604997\n",
      "[10]\ttraining's binary_logloss: 0.604\n",
      "[11]\ttraining's binary_logloss: 0.60306\n",
      "[12]\ttraining's binary_logloss: 0.602115\n",
      "[13]\ttraining's binary_logloss: 0.601214\n",
      "[14]\ttraining's binary_logloss: 0.600346\n",
      "[15]\ttraining's binary_logloss: 0.599514\n",
      "[16]\ttraining's binary_logloss: 0.598748\n",
      "[17]\ttraining's binary_logloss: 0.597942\n",
      "[18]\ttraining's binary_logloss: 0.597168\n",
      "[19]\ttraining's binary_logloss: 0.596424\n",
      "[20]\ttraining's binary_logloss: 0.595668\n",
      "[21]\ttraining's binary_logloss: 0.595003\n",
      "[22]\ttraining's binary_logloss: 0.594404\n",
      "[23]\ttraining's binary_logloss: 0.593773\n",
      "[24]\ttraining's binary_logloss: 0.59319\n",
      "[25]\ttraining's binary_logloss: 0.592648\n",
      "[26]\ttraining's binary_logloss: 0.592094\n",
      "[27]\ttraining's binary_logloss: 0.591434\n",
      "[28]\ttraining's binary_logloss: 0.590928\n",
      "[29]\ttraining's binary_logloss: 0.590312\n",
      "[30]\ttraining's binary_logloss: 0.589811\n",
      "[31]\ttraining's binary_logloss: 0.58934\n",
      "[32]\ttraining's binary_logloss: 0.588784\n",
      "[33]\ttraining's binary_logloss: 0.588342\n",
      "[34]\ttraining's binary_logloss: 0.587865\n",
      "[35]\ttraining's binary_logloss: 0.587352\n",
      "[36]\ttraining's binary_logloss: 0.586908\n",
      "[37]\ttraining's binary_logloss: 0.586497\n",
      "[38]\ttraining's binary_logloss: 0.586091\n",
      "[39]\ttraining's binary_logloss: 0.585685\n",
      "[40]\ttraining's binary_logloss: 0.585301\n",
      "[41]\ttraining's binary_logloss: 0.584938\n",
      "[42]\ttraining's binary_logloss: 0.584611\n",
      "[43]\ttraining's binary_logloss: 0.584229\n",
      "[44]\ttraining's binary_logloss: 0.58393\n",
      "[45]\ttraining's binary_logloss: 0.583587\n",
      "[46]\ttraining's binary_logloss: 0.583235\n",
      "[47]\ttraining's binary_logloss: 0.582899\n",
      "[48]\ttraining's binary_logloss: 0.582572\n",
      "[49]\ttraining's binary_logloss: 0.582262\n",
      "[50]\ttraining's binary_logloss: 0.581956\n",
      "[51]\ttraining's binary_logloss: 0.581638\n",
      "[52]\ttraining's binary_logloss: 0.581336\n",
      "[53]\ttraining's binary_logloss: 0.581047\n",
      "[54]\ttraining's binary_logloss: 0.580772\n",
      "[55]\ttraining's binary_logloss: 0.580508\n",
      "[56]\ttraining's binary_logloss: 0.580302\n",
      "[57]\ttraining's binary_logloss: 0.580028\n",
      "[58]\ttraining's binary_logloss: 0.579735\n",
      "[59]\ttraining's binary_logloss: 0.579546\n",
      "[60]\ttraining's binary_logloss: 0.579281\n",
      "[61]\ttraining's binary_logloss: 0.579121\n",
      "[62]\ttraining's binary_logloss: 0.578966\n",
      "[63]\ttraining's binary_logloss: 0.578808\n",
      "[64]\ttraining's binary_logloss: 0.578657\n",
      "[65]\ttraining's binary_logloss: 0.578511\n",
      "[66]\ttraining's binary_logloss: 0.578306\n",
      "[67]\ttraining's binary_logloss: 0.578158\n",
      "[68]\ttraining's binary_logloss: 0.578027\n",
      "[69]\ttraining's binary_logloss: 0.577854\n",
      "[70]\ttraining's binary_logloss: 0.577713\n",
      "[71]\ttraining's binary_logloss: 0.577577\n",
      "[72]\ttraining's binary_logloss: 0.577467\n",
      "[73]\ttraining's binary_logloss: 0.577297\n",
      "[74]\ttraining's binary_logloss: 0.577137\n",
      "[75]\ttraining's binary_logloss: 0.576987\n",
      "[76]\ttraining's binary_logloss: 0.576863\n",
      "[77]\ttraining's binary_logloss: 0.576764\n",
      "[78]\ttraining's binary_logloss: 0.576675\n",
      "[79]\ttraining's binary_logloss: 0.576565\n",
      "[80]\ttraining's binary_logloss: 0.576436\n",
      "[81]\ttraining's binary_logloss: 0.576298\n",
      "[82]\ttraining's binary_logloss: 0.576194\n",
      "[83]\ttraining's binary_logloss: 0.576058\n",
      "[84]\ttraining's binary_logloss: 0.57593\n",
      "[85]\ttraining's binary_logloss: 0.575835\n",
      "[86]\ttraining's binary_logloss: 0.575753\n",
      "[87]\ttraining's binary_logloss: 0.575653\n",
      "[88]\ttraining's binary_logloss: 0.575534\n",
      "[89]\ttraining's binary_logloss: 0.575423\n",
      "[90]\ttraining's binary_logloss: 0.575333\n",
      "[91]\ttraining's binary_logloss: 0.575245\n",
      "[92]\ttraining's binary_logloss: 0.575163\n",
      "[93]\ttraining's binary_logloss: 0.57509\n",
      "[94]\ttraining's binary_logloss: 0.575019\n",
      "[95]\ttraining's binary_logloss: 0.575003\n",
      "[96]\ttraining's binary_logloss: 0.57493\n",
      "[97]\ttraining's binary_logloss: 0.57485\n",
      "[98]\ttraining's binary_logloss: 0.574762\n",
      "[99]\ttraining's binary_logloss: 0.574697\n",
      "[100]\ttraining's binary_logloss: 0.57464\n",
      "[101]\ttraining's binary_logloss: 0.574547\n",
      "[102]\ttraining's binary_logloss: 0.574481\n",
      "[103]\ttraining's binary_logloss: 0.574414\n",
      "[104]\ttraining's binary_logloss: 0.574305\n",
      "[105]\ttraining's binary_logloss: 0.574246\n",
      "[106]\ttraining's binary_logloss: 0.57422\n",
      "[107]\ttraining's binary_logloss: 0.574181\n",
      "[108]\ttraining's binary_logloss: 0.574151\n",
      "[109]\ttraining's binary_logloss: 0.574124\n",
      "[110]\ttraining's binary_logloss: 0.574045\n",
      "[111]\ttraining's binary_logloss: 0.573978\n",
      "[112]\ttraining's binary_logloss: 0.573922\n",
      "[113]\ttraining's binary_logloss: 0.573817\n",
      "[114]\ttraining's binary_logloss: 0.573712\n",
      "[115]\ttraining's binary_logloss: 0.573621\n",
      "[116]\ttraining's binary_logloss: 0.573527\n",
      "[117]\ttraining's binary_logloss: 0.573465\n",
      "[118]\ttraining's binary_logloss: 0.573379\n",
      "[119]\ttraining's binary_logloss: 0.573305\n",
      "[120]\ttraining's binary_logloss: 0.573274\n",
      "[121]\ttraining's binary_logloss: 0.573211\n",
      "[122]\ttraining's binary_logloss: 0.573162\n",
      "[123]\ttraining's binary_logloss: 0.573121\n",
      "[124]\ttraining's binary_logloss: 0.573062\n",
      "[125]\ttraining's binary_logloss: 0.573063\n",
      "[126]\ttraining's binary_logloss: 0.573005\n",
      "[127]\ttraining's binary_logloss: 0.572927\n",
      "[128]\ttraining's binary_logloss: 0.572856\n",
      "[129]\ttraining's binary_logloss: 0.572805\n",
      "[130]\ttraining's binary_logloss: 0.572748\n",
      "[131]\ttraining's binary_logloss: 0.572725\n",
      "[132]\ttraining's binary_logloss: 0.572712\n",
      "[133]\ttraining's binary_logloss: 0.572704\n",
      "[134]\ttraining's binary_logloss: 0.572709\n",
      "[135]\ttraining's binary_logloss: 0.572715\n",
      "[136]\ttraining's binary_logloss: 0.572702\n",
      "[137]\ttraining's binary_logloss: 0.57268\n",
      "[138]\ttraining's binary_logloss: 0.57265\n",
      "[139]\ttraining's binary_logloss: 0.572625\n",
      "[140]\ttraining's binary_logloss: 0.572572\n",
      "[141]\ttraining's binary_logloss: 0.572534\n",
      "[142]\ttraining's binary_logloss: 0.57251\n",
      "[143]\ttraining's binary_logloss: 0.572472\n",
      "[144]\ttraining's binary_logloss: 0.572421\n",
      "[145]\ttraining's binary_logloss: 0.572389\n",
      "[146]\ttraining's binary_logloss: 0.572363\n",
      "[147]\ttraining's binary_logloss: 0.57233\n",
      "[148]\ttraining's binary_logloss: 0.572283\n",
      "[149]\ttraining's binary_logloss: 0.572242\n",
      "[150]\ttraining's binary_logloss: 0.572187\n",
      "[151]\ttraining's binary_logloss: 0.572146\n",
      "[152]\ttraining's binary_logloss: 0.572107\n",
      "[153]\ttraining's binary_logloss: 0.572046\n",
      "[154]\ttraining's binary_logloss: 0.572021\n",
      "[155]\ttraining's binary_logloss: 0.571996\n",
      "[156]\ttraining's binary_logloss: 0.57197\n",
      "[157]\ttraining's binary_logloss: 0.571943\n",
      "[158]\ttraining's binary_logloss: 0.571884\n",
      "[159]\ttraining's binary_logloss: 0.571883\n",
      "[160]\ttraining's binary_logloss: 0.571845\n",
      "[161]\ttraining's binary_logloss: 0.571754\n",
      "[162]\ttraining's binary_logloss: 0.571676\n",
      "[163]\ttraining's binary_logloss: 0.571616\n",
      "[164]\ttraining's binary_logloss: 0.571534\n",
      "[165]\ttraining's binary_logloss: 0.571455\n",
      "[166]\ttraining's binary_logloss: 0.571391\n",
      "[167]\ttraining's binary_logloss: 0.571375\n",
      "[168]\ttraining's binary_logloss: 0.57135\n",
      "[169]\ttraining's binary_logloss: 0.571305\n",
      "[170]\ttraining's binary_logloss: 0.571217\n",
      "[171]\ttraining's binary_logloss: 0.571192\n",
      "[172]\ttraining's binary_logloss: 0.571157\n",
      "[173]\ttraining's binary_logloss: 0.571128\n",
      "[174]\ttraining's binary_logloss: 0.571104\n",
      "[175]\ttraining's binary_logloss: 0.571084\n",
      "[176]\ttraining's binary_logloss: 0.571035\n",
      "[177]\ttraining's binary_logloss: 0.570984\n",
      "[178]\ttraining's binary_logloss: 0.570929\n",
      "[179]\ttraining's binary_logloss: 0.570892\n",
      "[180]\ttraining's binary_logloss: 0.570825\n",
      "[181]\ttraining's binary_logloss: 0.570772\n",
      "[182]\ttraining's binary_logloss: 0.570713\n",
      "[183]\ttraining's binary_logloss: 0.570627\n",
      "[184]\ttraining's binary_logloss: 0.570562\n",
      "[185]\ttraining's binary_logloss: 0.57049\n",
      "[186]\ttraining's binary_logloss: 0.570449\n",
      "[187]\ttraining's binary_logloss: 0.57041\n",
      "[188]\ttraining's binary_logloss: 0.570372\n",
      "[189]\ttraining's binary_logloss: 0.570323\n",
      "[190]\ttraining's binary_logloss: 0.570289\n",
      "[191]\ttraining's binary_logloss: 0.570228\n",
      "[192]\ttraining's binary_logloss: 0.570158\n",
      "[193]\ttraining's binary_logloss: 0.570107\n",
      "[194]\ttraining's binary_logloss: 0.570044\n",
      "[195]\ttraining's binary_logloss: 0.569998\n",
      "[196]\ttraining's binary_logloss: 0.569925\n",
      "[197]\ttraining's binary_logloss: 0.569844\n",
      "[198]\ttraining's binary_logloss: 0.569782\n",
      "[199]\ttraining's binary_logloss: 0.569726\n",
      "[200]\ttraining's binary_logloss: 0.569649\n",
      "[201]\ttraining's binary_logloss: 0.569621\n",
      "[202]\ttraining's binary_logloss: 0.569583\n",
      "[203]\ttraining's binary_logloss: 0.569551\n",
      "[204]\ttraining's binary_logloss: 0.569504\n",
      "[205]\ttraining's binary_logloss: 0.569475\n",
      "[206]\ttraining's binary_logloss: 0.569402\n",
      "[207]\ttraining's binary_logloss: 0.569308\n",
      "[208]\ttraining's binary_logloss: 0.569213\n",
      "[209]\ttraining's binary_logloss: 0.569138\n",
      "[210]\ttraining's binary_logloss: 0.569051\n",
      "[211]\ttraining's binary_logloss: 0.569015\n",
      "[212]\ttraining's binary_logloss: 0.568957\n",
      "[213]\ttraining's binary_logloss: 0.568913\n",
      "[214]\ttraining's binary_logloss: 0.568881\n",
      "[215]\ttraining's binary_logloss: 0.56885\n",
      "[216]\ttraining's binary_logloss: 0.568771\n",
      "[217]\ttraining's binary_logloss: 0.56867\n",
      "[218]\ttraining's binary_logloss: 0.568581\n",
      "[219]\ttraining's binary_logloss: 0.568514\n",
      "[220]\ttraining's binary_logloss: 0.568432\n",
      "[221]\ttraining's binary_logloss: 0.568339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[222]\ttraining's binary_logloss: 0.568264\n",
      "[223]\ttraining's binary_logloss: 0.568183\n",
      "[224]\ttraining's binary_logloss: 0.568094\n",
      "[225]\ttraining's binary_logloss: 0.568017\n",
      "[226]\ttraining's binary_logloss: 0.567924\n",
      "[227]\ttraining's binary_logloss: 0.567833\n",
      "[228]\ttraining's binary_logloss: 0.567731\n",
      "[229]\ttraining's binary_logloss: 0.567632\n",
      "[230]\ttraining's binary_logloss: 0.567544\n",
      "[231]\ttraining's binary_logloss: 0.567465\n",
      "[232]\ttraining's binary_logloss: 0.567401\n",
      "[233]\ttraining's binary_logloss: 0.567339\n",
      "[234]\ttraining's binary_logloss: 0.56726\n",
      "[235]\ttraining's binary_logloss: 0.567186\n",
      "[236]\ttraining's binary_logloss: 0.567084\n",
      "[237]\ttraining's binary_logloss: 0.566991\n",
      "[238]\ttraining's binary_logloss: 0.5669\n",
      "[239]\ttraining's binary_logloss: 0.566802\n",
      "[240]\ttraining's binary_logloss: 0.566703\n",
      "[241]\ttraining's binary_logloss: 0.566631\n",
      "[242]\ttraining's binary_logloss: 0.566545\n",
      "[243]\ttraining's binary_logloss: 0.566468\n",
      "[244]\ttraining's binary_logloss: 0.566427\n",
      "[245]\ttraining's binary_logloss: 0.566374\n",
      "[246]\ttraining's binary_logloss: 0.566241\n",
      "[247]\ttraining's binary_logloss: 0.566118\n",
      "[248]\ttraining's binary_logloss: 0.566001\n",
      "[249]\ttraining's binary_logloss: 0.565888\n",
      "[250]\ttraining's binary_logloss: 0.565782\n",
      "[251]\ttraining's binary_logloss: 0.565661\n",
      "[252]\ttraining's binary_logloss: 0.56556\n",
      "[253]\ttraining's binary_logloss: 0.565436\n",
      "[254]\ttraining's binary_logloss: 0.565319\n",
      "[255]\ttraining's binary_logloss: 0.565195\n",
      "[256]\ttraining's binary_logloss: 0.565126\n",
      "[257]\ttraining's binary_logloss: 0.565059\n",
      "[258]\ttraining's binary_logloss: 0.564991\n",
      "[259]\ttraining's binary_logloss: 0.564926\n",
      "[260]\ttraining's binary_logloss: 0.564863\n",
      "[261]\ttraining's binary_logloss: 0.564802\n",
      "[262]\ttraining's binary_logloss: 0.56475\n",
      "[263]\ttraining's binary_logloss: 0.564707\n",
      "[264]\ttraining's binary_logloss: 0.564615\n",
      "[265]\ttraining's binary_logloss: 0.564568\n",
      "[266]\ttraining's binary_logloss: 0.56452\n",
      "[267]\ttraining's binary_logloss: 0.564469\n",
      "[268]\ttraining's binary_logloss: 0.564426\n",
      "[269]\ttraining's binary_logloss: 0.564389\n",
      "[270]\ttraining's binary_logloss: 0.56433\n",
      "[271]\ttraining's binary_logloss: 0.564247\n",
      "[272]\ttraining's binary_logloss: 0.564157\n",
      "[273]\ttraining's binary_logloss: 0.564086\n",
      "[274]\ttraining's binary_logloss: 0.564021\n",
      "[275]\ttraining's binary_logloss: 0.56393\n",
      "[276]\ttraining's binary_logloss: 0.563832\n",
      "[277]\ttraining's binary_logloss: 0.563738\n",
      "[278]\ttraining's binary_logloss: 0.563645\n",
      "[279]\ttraining's binary_logloss: 0.563564\n",
      "[280]\ttraining's binary_logloss: 0.563476\n",
      "[281]\ttraining's binary_logloss: 0.563423\n",
      "[282]\ttraining's binary_logloss: 0.563361\n",
      "[283]\ttraining's binary_logloss: 0.563299\n",
      "[284]\ttraining's binary_logloss: 0.563237\n",
      "[285]\ttraining's binary_logloss: 0.563184\n",
      "[286]\ttraining's binary_logloss: 0.563072\n",
      "[287]\ttraining's binary_logloss: 0.562963\n",
      "[288]\ttraining's binary_logloss: 0.56285\n",
      "[289]\ttraining's binary_logloss: 0.562757\n",
      "[290]\ttraining's binary_logloss: 0.562643\n",
      "[291]\ttraining's binary_logloss: 0.562507\n",
      "[292]\ttraining's binary_logloss: 0.562381\n",
      "[293]\ttraining's binary_logloss: 0.562267\n",
      "[294]\ttraining's binary_logloss: 0.562139\n",
      "[295]\ttraining's binary_logloss: 0.562011\n",
      "[296]\ttraining's binary_logloss: 0.561924\n",
      "[297]\ttraining's binary_logloss: 0.561824\n",
      "[298]\ttraining's binary_logloss: 0.561725\n",
      "[299]\ttraining's binary_logloss: 0.561653\n",
      "[300]\ttraining's binary_logloss: 0.561566\n",
      "[301]\ttraining's binary_logloss: 0.56144\n",
      "[302]\ttraining's binary_logloss: 0.561325\n",
      "[303]\ttraining's binary_logloss: 0.56123\n",
      "[304]\ttraining's binary_logloss: 0.561136\n",
      "[305]\ttraining's binary_logloss: 0.561035\n",
      "[306]\ttraining's binary_logloss: 0.560929\n",
      "[307]\ttraining's binary_logloss: 0.560825\n",
      "[308]\ttraining's binary_logloss: 0.560727\n",
      "[309]\ttraining's binary_logloss: 0.560627\n",
      "[310]\ttraining's binary_logloss: 0.560533\n",
      "[311]\ttraining's binary_logloss: 0.560428\n",
      "[312]\ttraining's binary_logloss: 0.560324\n",
      "[313]\ttraining's binary_logloss: 0.56023\n",
      "[314]\ttraining's binary_logloss: 0.560123\n",
      "[315]\ttraining's binary_logloss: 0.560014\n",
      "[316]\ttraining's binary_logloss: 0.5599\n",
      "[317]\ttraining's binary_logloss: 0.559797\n",
      "[318]\ttraining's binary_logloss: 0.559705\n",
      "[319]\ttraining's binary_logloss: 0.559607\n",
      "[320]\ttraining's binary_logloss: 0.559515\n",
      "[321]\ttraining's binary_logloss: 0.559434\n",
      "[322]\ttraining's binary_logloss: 0.559352\n",
      "[323]\ttraining's binary_logloss: 0.55925\n",
      "[324]\ttraining's binary_logloss: 0.559125\n",
      "[325]\ttraining's binary_logloss: 0.559044\n",
      "[326]\ttraining's binary_logloss: 0.558914\n",
      "[327]\ttraining's binary_logloss: 0.558779\n",
      "[328]\ttraining's binary_logloss: 0.558658\n",
      "[329]\ttraining's binary_logloss: 0.558518\n",
      "[330]\ttraining's binary_logloss: 0.558385\n",
      "[331]\ttraining's binary_logloss: 0.558283\n",
      "[332]\ttraining's binary_logloss: 0.558193\n",
      "[333]\ttraining's binary_logloss: 0.55808\n",
      "[334]\ttraining's binary_logloss: 0.557993\n",
      "[335]\ttraining's binary_logloss: 0.557887\n",
      "[336]\ttraining's binary_logloss: 0.557804\n",
      "[337]\ttraining's binary_logloss: 0.557708\n",
      "[338]\ttraining's binary_logloss: 0.557628\n",
      "[339]\ttraining's binary_logloss: 0.557521\n",
      "[340]\ttraining's binary_logloss: 0.557457\n",
      "[341]\ttraining's binary_logloss: 0.557368\n",
      "[342]\ttraining's binary_logloss: 0.557265\n",
      "[343]\ttraining's binary_logloss: 0.55717\n",
      "[344]\ttraining's binary_logloss: 0.557074\n",
      "[345]\ttraining's binary_logloss: 0.556996\n",
      "[346]\ttraining's binary_logloss: 0.556866\n",
      "[347]\ttraining's binary_logloss: 0.556743\n",
      "[348]\ttraining's binary_logloss: 0.556623\n",
      "[349]\ttraining's binary_logloss: 0.556503\n",
      "[350]\ttraining's binary_logloss: 0.556373\n",
      "[351]\ttraining's binary_logloss: 0.556298\n",
      "[352]\ttraining's binary_logloss: 0.556225\n",
      "[353]\ttraining's binary_logloss: 0.556139\n",
      "[354]\ttraining's binary_logloss: 0.556061\n",
      "[355]\ttraining's binary_logloss: 0.555976\n",
      "[356]\ttraining's binary_logloss: 0.55586\n",
      "[357]\ttraining's binary_logloss: 0.555764\n",
      "[358]\ttraining's binary_logloss: 0.555657\n",
      "[359]\ttraining's binary_logloss: 0.555554\n",
      "[360]\ttraining's binary_logloss: 0.555463\n",
      "[361]\ttraining's binary_logloss: 0.555345\n",
      "[362]\ttraining's binary_logloss: 0.555224\n",
      "[363]\ttraining's binary_logloss: 0.555093\n",
      "[364]\ttraining's binary_logloss: 0.554985\n",
      "[365]\ttraining's binary_logloss: 0.554887\n",
      "[366]\ttraining's binary_logloss: 0.554779\n",
      "[367]\ttraining's binary_logloss: 0.554671\n",
      "[368]\ttraining's binary_logloss: 0.554568\n",
      "[369]\ttraining's binary_logloss: 0.554443\n",
      "[370]\ttraining's binary_logloss: 0.554337\n",
      "[371]\ttraining's binary_logloss: 0.554222\n",
      "[372]\ttraining's binary_logloss: 0.554126\n",
      "[373]\ttraining's binary_logloss: 0.554016\n",
      "[374]\ttraining's binary_logloss: 0.553899\n",
      "[375]\ttraining's binary_logloss: 0.553778\n",
      "[376]\ttraining's binary_logloss: 0.553673\n",
      "[377]\ttraining's binary_logloss: 0.553563\n",
      "[378]\ttraining's binary_logloss: 0.553461\n",
      "[379]\ttraining's binary_logloss: 0.553361\n",
      "[380]\ttraining's binary_logloss: 0.553216\n",
      "[381]\ttraining's binary_logloss: 0.553079\n",
      "[382]\ttraining's binary_logloss: 0.552944\n",
      "[383]\ttraining's binary_logloss: 0.552813\n",
      "[384]\ttraining's binary_logloss: 0.552692\n",
      "[385]\ttraining's binary_logloss: 0.552567\n",
      "[386]\ttraining's binary_logloss: 0.55244\n",
      "[387]\ttraining's binary_logloss: 0.552294\n",
      "[388]\ttraining's binary_logloss: 0.552167\n",
      "[389]\ttraining's binary_logloss: 0.552044\n",
      "[390]\ttraining's binary_logloss: 0.551897\n",
      "[391]\ttraining's binary_logloss: 0.55176\n",
      "[392]\ttraining's binary_logloss: 0.551626\n",
      "[393]\ttraining's binary_logloss: 0.551492\n",
      "[394]\ttraining's binary_logloss: 0.551342\n",
      "[395]\ttraining's binary_logloss: 0.551207\n",
      "[396]\ttraining's binary_logloss: 0.551112\n",
      "[397]\ttraining's binary_logloss: 0.55102\n",
      "[398]\ttraining's binary_logloss: 0.550938\n",
      "[399]\ttraining's binary_logloss: 0.550853\n",
      "[400]\ttraining's binary_logloss: 0.550763\n",
      "[401]\ttraining's binary_logloss: 0.550633\n",
      "[402]\ttraining's binary_logloss: 0.550518\n",
      "[403]\ttraining's binary_logloss: 0.550396\n",
      "[404]\ttraining's binary_logloss: 0.550277\n",
      "[405]\ttraining's binary_logloss: 0.550152\n",
      "[406]\ttraining's binary_logloss: 0.550069\n",
      "[407]\ttraining's binary_logloss: 0.549969\n",
      "[408]\ttraining's binary_logloss: 0.549889\n",
      "[409]\ttraining's binary_logloss: 0.549804\n",
      "[410]\ttraining's binary_logloss: 0.549672\n",
      "[411]\ttraining's binary_logloss: 0.549541\n",
      "[412]\ttraining's binary_logloss: 0.549418\n",
      "[413]\ttraining's binary_logloss: 0.549283\n",
      "[414]\ttraining's binary_logloss: 0.549162\n",
      "[415]\ttraining's binary_logloss: 0.549057\n",
      "[416]\ttraining's binary_logloss: 0.548936\n",
      "[417]\ttraining's binary_logloss: 0.548819\n",
      "[418]\ttraining's binary_logloss: 0.54871\n",
      "[419]\ttraining's binary_logloss: 0.548603\n",
      "[420]\ttraining's binary_logloss: 0.548487\n",
      "[421]\ttraining's binary_logloss: 0.548392\n",
      "[422]\ttraining's binary_logloss: 0.548299\n",
      "[423]\ttraining's binary_logloss: 0.548197\n",
      "[424]\ttraining's binary_logloss: 0.548107\n",
      "[425]\ttraining's binary_logloss: 0.548009\n",
      "[426]\ttraining's binary_logloss: 0.547895\n",
      "[427]\ttraining's binary_logloss: 0.547792\n",
      "[428]\ttraining's binary_logloss: 0.54772\n",
      "[429]\ttraining's binary_logloss: 0.547594\n",
      "[430]\ttraining's binary_logloss: 0.547485\n",
      "[431]\ttraining's binary_logloss: 0.547377\n",
      "[432]\ttraining's binary_logloss: 0.547242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[433]\ttraining's binary_logloss: 0.547129\n",
      "[434]\ttraining's binary_logloss: 0.547018\n",
      "[435]\ttraining's binary_logloss: 0.546909\n",
      "[436]\ttraining's binary_logloss: 0.546808\n",
      "[437]\ttraining's binary_logloss: 0.546703\n",
      "[438]\ttraining's binary_logloss: 0.546605\n",
      "[439]\ttraining's binary_logloss: 0.546483\n",
      "[440]\ttraining's binary_logloss: 0.546407\n",
      "[441]\ttraining's binary_logloss: 0.546294\n",
      "[442]\ttraining's binary_logloss: 0.546169\n",
      "[443]\ttraining's binary_logloss: 0.54603\n",
      "[444]\ttraining's binary_logloss: 0.545922\n",
      "[445]\ttraining's binary_logloss: 0.545793\n",
      "[446]\ttraining's binary_logloss: 0.545641\n",
      "[447]\ttraining's binary_logloss: 0.54549\n",
      "[448]\ttraining's binary_logloss: 0.54534\n",
      "[449]\ttraining's binary_logloss: 0.545188\n",
      "[450]\ttraining's binary_logloss: 0.545043\n",
      "[451]\ttraining's binary_logloss: 0.544893\n",
      "[452]\ttraining's binary_logloss: 0.544743\n",
      "[453]\ttraining's binary_logloss: 0.544611\n",
      "[454]\ttraining's binary_logloss: 0.544494\n",
      "[455]\ttraining's binary_logloss: 0.544348\n",
      "[456]\ttraining's binary_logloss: 0.544253\n",
      "[457]\ttraining's binary_logloss: 0.544145\n",
      "[458]\ttraining's binary_logloss: 0.544049\n",
      "[459]\ttraining's binary_logloss: 0.543964\n",
      "[460]\ttraining's binary_logloss: 0.543876\n",
      "[461]\ttraining's binary_logloss: 0.543762\n",
      "[462]\ttraining's binary_logloss: 0.543637\n",
      "[463]\ttraining's binary_logloss: 0.543523\n",
      "[464]\ttraining's binary_logloss: 0.543419\n",
      "[465]\ttraining's binary_logloss: 0.54329\n",
      "[466]\ttraining's binary_logloss: 0.543155\n",
      "[467]\ttraining's binary_logloss: 0.543048\n",
      "[468]\ttraining's binary_logloss: 0.542942\n",
      "[469]\ttraining's binary_logloss: 0.542837\n",
      "[470]\ttraining's binary_logloss: 0.542714\n",
      "[471]\ttraining's binary_logloss: 0.542575\n",
      "[472]\ttraining's binary_logloss: 0.542445\n",
      "[473]\ttraining's binary_logloss: 0.542308\n",
      "[474]\ttraining's binary_logloss: 0.542173\n",
      "[475]\ttraining's binary_logloss: 0.542041\n",
      "[476]\ttraining's binary_logloss: 0.541963\n",
      "[477]\ttraining's binary_logloss: 0.541865\n",
      "[478]\ttraining's binary_logloss: 0.541784\n",
      "[479]\ttraining's binary_logloss: 0.541641\n",
      "[480]\ttraining's binary_logloss: 0.541548\n",
      "[481]\ttraining's binary_logloss: 0.541474\n",
      "[482]\ttraining's binary_logloss: 0.541393\n",
      "[483]\ttraining's binary_logloss: 0.54128\n",
      "[484]\ttraining's binary_logloss: 0.541199\n",
      "[485]\ttraining's binary_logloss: 0.541123\n",
      "[486]\ttraining's binary_logloss: 0.540993\n",
      "[487]\ttraining's binary_logloss: 0.540862\n",
      "[488]\ttraining's binary_logloss: 0.540731\n",
      "[489]\ttraining's binary_logloss: 0.540626\n",
      "[490]\ttraining's binary_logloss: 0.540515\n",
      "[491]\ttraining's binary_logloss: 0.540396\n",
      "[492]\ttraining's binary_logloss: 0.54025\n",
      "[493]\ttraining's binary_logloss: 0.540119\n",
      "[494]\ttraining's binary_logloss: 0.54\n",
      "[495]\ttraining's binary_logloss: 0.539862\n",
      "[496]\ttraining's binary_logloss: 0.539717\n",
      "[497]\ttraining's binary_logloss: 0.539566\n",
      "[498]\ttraining's binary_logloss: 0.539444\n",
      "[499]\ttraining's binary_logloss: 0.539309\n",
      "[500]\ttraining's binary_logloss: 0.539173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614302\n",
      "[2]\ttraining's binary_logloss: 0.612831\n",
      "[3]\ttraining's binary_logloss: 0.611385\n",
      "[4]\ttraining's binary_logloss: 0.60998\n",
      "[5]\ttraining's binary_logloss: 0.608641\n",
      "[6]\ttraining's binary_logloss: 0.60731\n",
      "[7]\ttraining's binary_logloss: 0.606048\n",
      "[8]\ttraining's binary_logloss: 0.604823\n",
      "[9]\ttraining's binary_logloss: 0.603623\n",
      "[10]\ttraining's binary_logloss: 0.602499\n",
      "[11]\ttraining's binary_logloss: 0.601412\n",
      "[12]\ttraining's binary_logloss: 0.600319\n",
      "[13]\ttraining's binary_logloss: 0.599297\n",
      "[14]\ttraining's binary_logloss: 0.59831\n",
      "[15]\ttraining's binary_logloss: 0.597315\n",
      "[16]\ttraining's binary_logloss: 0.596384\n",
      "[17]\ttraining's binary_logloss: 0.595465\n",
      "[18]\ttraining's binary_logloss: 0.594581\n",
      "[19]\ttraining's binary_logloss: 0.593718\n",
      "[20]\ttraining's binary_logloss: 0.592841\n",
      "[21]\ttraining's binary_logloss: 0.592074\n",
      "[22]\ttraining's binary_logloss: 0.591367\n",
      "[23]\ttraining's binary_logloss: 0.590619\n",
      "[24]\ttraining's binary_logloss: 0.589927\n",
      "[25]\ttraining's binary_logloss: 0.589276\n",
      "[26]\ttraining's binary_logloss: 0.588588\n",
      "[27]\ttraining's binary_logloss: 0.587847\n",
      "[28]\ttraining's binary_logloss: 0.587168\n",
      "[29]\ttraining's binary_logloss: 0.586477\n",
      "[30]\ttraining's binary_logloss: 0.585854\n",
      "[31]\ttraining's binary_logloss: 0.585242\n",
      "[32]\ttraining's binary_logloss: 0.584579\n",
      "[33]\ttraining's binary_logloss: 0.584012\n",
      "[34]\ttraining's binary_logloss: 0.583458\n",
      "[35]\ttraining's binary_logloss: 0.582781\n",
      "[36]\ttraining's binary_logloss: 0.582203\n",
      "[37]\ttraining's binary_logloss: 0.581646\n",
      "[38]\ttraining's binary_logloss: 0.581094\n",
      "[39]\ttraining's binary_logloss: 0.580566\n",
      "[40]\ttraining's binary_logloss: 0.580038\n",
      "[41]\ttraining's binary_logloss: 0.579582\n",
      "[42]\ttraining's binary_logloss: 0.579161\n",
      "[43]\ttraining's binary_logloss: 0.578717\n",
      "[44]\ttraining's binary_logloss: 0.578282\n",
      "[45]\ttraining's binary_logloss: 0.577878\n",
      "[46]\ttraining's binary_logloss: 0.577405\n",
      "[47]\ttraining's binary_logloss: 0.576959\n",
      "[48]\ttraining's binary_logloss: 0.576492\n",
      "[49]\ttraining's binary_logloss: 0.57607\n",
      "[50]\ttraining's binary_logloss: 0.575668\n",
      "[51]\ttraining's binary_logloss: 0.575243\n",
      "[52]\ttraining's binary_logloss: 0.57483\n",
      "[53]\ttraining's binary_logloss: 0.574444\n",
      "[54]\ttraining's binary_logloss: 0.574095\n",
      "[55]\ttraining's binary_logloss: 0.573736\n",
      "[56]\ttraining's binary_logloss: 0.573439\n",
      "[57]\ttraining's binary_logloss: 0.573063\n",
      "[58]\ttraining's binary_logloss: 0.572686\n",
      "[59]\ttraining's binary_logloss: 0.572426\n",
      "[60]\ttraining's binary_logloss: 0.572083\n",
      "[61]\ttraining's binary_logloss: 0.571795\n",
      "[62]\ttraining's binary_logloss: 0.571547\n",
      "[63]\ttraining's binary_logloss: 0.571247\n",
      "[64]\ttraining's binary_logloss: 0.570989\n",
      "[65]\ttraining's binary_logloss: 0.570725\n",
      "[66]\ttraining's binary_logloss: 0.570428\n",
      "[67]\ttraining's binary_logloss: 0.570172\n",
      "[68]\ttraining's binary_logloss: 0.569911\n",
      "[69]\ttraining's binary_logloss: 0.569655\n",
      "[70]\ttraining's binary_logloss: 0.569436\n",
      "[71]\ttraining's binary_logloss: 0.569187\n",
      "[72]\ttraining's binary_logloss: 0.568986\n",
      "[73]\ttraining's binary_logloss: 0.568713\n",
      "[74]\ttraining's binary_logloss: 0.568441\n",
      "[75]\ttraining's binary_logloss: 0.568185\n",
      "[76]\ttraining's binary_logloss: 0.567976\n",
      "[77]\ttraining's binary_logloss: 0.567798\n",
      "[78]\ttraining's binary_logloss: 0.56763\n",
      "[79]\ttraining's binary_logloss: 0.567419\n",
      "[80]\ttraining's binary_logloss: 0.567215\n",
      "[81]\ttraining's binary_logloss: 0.566994\n",
      "[82]\ttraining's binary_logloss: 0.566833\n",
      "[83]\ttraining's binary_logloss: 0.566599\n",
      "[84]\ttraining's binary_logloss: 0.566384\n",
      "[85]\ttraining's binary_logloss: 0.566196\n",
      "[86]\ttraining's binary_logloss: 0.566008\n",
      "[87]\ttraining's binary_logloss: 0.565824\n",
      "[88]\ttraining's binary_logloss: 0.565608\n",
      "[89]\ttraining's binary_logloss: 0.565398\n",
      "[90]\ttraining's binary_logloss: 0.565215\n",
      "[91]\ttraining's binary_logloss: 0.565037\n",
      "[92]\ttraining's binary_logloss: 0.564874\n",
      "[93]\ttraining's binary_logloss: 0.564728\n",
      "[94]\ttraining's binary_logloss: 0.564609\n",
      "[95]\ttraining's binary_logloss: 0.564492\n",
      "[96]\ttraining's binary_logloss: 0.564309\n",
      "[97]\ttraining's binary_logloss: 0.564139\n",
      "[98]\ttraining's binary_logloss: 0.563983\n",
      "[99]\ttraining's binary_logloss: 0.563838\n",
      "[100]\ttraining's binary_logloss: 0.563686\n",
      "[101]\ttraining's binary_logloss: 0.563536\n",
      "[102]\ttraining's binary_logloss: 0.563429\n",
      "[103]\ttraining's binary_logloss: 0.563261\n",
      "[104]\ttraining's binary_logloss: 0.563113\n",
      "[105]\ttraining's binary_logloss: 0.562958\n",
      "[106]\ttraining's binary_logloss: 0.562828\n",
      "[107]\ttraining's binary_logloss: 0.56269\n",
      "[108]\ttraining's binary_logloss: 0.562561\n",
      "[109]\ttraining's binary_logloss: 0.562444\n",
      "[110]\ttraining's binary_logloss: 0.562311\n",
      "[111]\ttraining's binary_logloss: 0.562165\n",
      "[112]\ttraining's binary_logloss: 0.562023\n",
      "[113]\ttraining's binary_logloss: 0.561832\n",
      "[114]\ttraining's binary_logloss: 0.561646\n",
      "[115]\ttraining's binary_logloss: 0.561489\n",
      "[116]\ttraining's binary_logloss: 0.561342\n",
      "[117]\ttraining's binary_logloss: 0.561198\n",
      "[118]\ttraining's binary_logloss: 0.561045\n",
      "[119]\ttraining's binary_logloss: 0.560888\n",
      "[120]\ttraining's binary_logloss: 0.560768\n",
      "[121]\ttraining's binary_logloss: 0.560635\n",
      "[122]\ttraining's binary_logloss: 0.56051\n",
      "[123]\ttraining's binary_logloss: 0.560403\n",
      "[124]\ttraining's binary_logloss: 0.560275\n",
      "[125]\ttraining's binary_logloss: 0.560189\n",
      "[126]\ttraining's binary_logloss: 0.560068\n",
      "[127]\ttraining's binary_logloss: 0.559899\n",
      "[128]\ttraining's binary_logloss: 0.559755\n",
      "[129]\ttraining's binary_logloss: 0.559629\n",
      "[130]\ttraining's binary_logloss: 0.559504\n",
      "[131]\ttraining's binary_logloss: 0.559413\n",
      "[132]\ttraining's binary_logloss: 0.559324\n",
      "[133]\ttraining's binary_logloss: 0.559218\n",
      "[134]\ttraining's binary_logloss: 0.559147\n",
      "[135]\ttraining's binary_logloss: 0.559051\n",
      "[136]\ttraining's binary_logloss: 0.558938\n",
      "[137]\ttraining's binary_logloss: 0.558818\n",
      "[138]\ttraining's binary_logloss: 0.558709\n",
      "[139]\ttraining's binary_logloss: 0.558619\n",
      "[140]\ttraining's binary_logloss: 0.558514\n",
      "[141]\ttraining's binary_logloss: 0.558412\n",
      "[142]\ttraining's binary_logloss: 0.558309\n",
      "[143]\ttraining's binary_logloss: 0.558219\n",
      "[144]\ttraining's binary_logloss: 0.558121\n",
      "[145]\ttraining's binary_logloss: 0.558018\n",
      "[146]\ttraining's binary_logloss: 0.557901\n",
      "[147]\ttraining's binary_logloss: 0.557771\n",
      "[148]\ttraining's binary_logloss: 0.557639\n",
      "[149]\ttraining's binary_logloss: 0.557516\n",
      "[150]\ttraining's binary_logloss: 0.557386\n",
      "[151]\ttraining's binary_logloss: 0.557264\n",
      "[152]\ttraining's binary_logloss: 0.557156\n",
      "[153]\ttraining's binary_logloss: 0.557018\n",
      "[154]\ttraining's binary_logloss: 0.55691\n",
      "[155]\ttraining's binary_logloss: 0.556786\n",
      "[156]\ttraining's binary_logloss: 0.556674\n",
      "[157]\ttraining's binary_logloss: 0.556557\n",
      "[158]\ttraining's binary_logloss: 0.556427\n",
      "[159]\ttraining's binary_logloss: 0.556294\n",
      "[160]\ttraining's binary_logloss: 0.556159\n",
      "[161]\ttraining's binary_logloss: 0.55601\n",
      "[162]\ttraining's binary_logloss: 0.555866\n",
      "[163]\ttraining's binary_logloss: 0.555737\n",
      "[164]\ttraining's binary_logloss: 0.555592\n",
      "[165]\ttraining's binary_logloss: 0.555446\n",
      "[166]\ttraining's binary_logloss: 0.555319\n",
      "[167]\ttraining's binary_logloss: 0.555234\n",
      "[168]\ttraining's binary_logloss: 0.555129\n",
      "[169]\ttraining's binary_logloss: 0.555016\n",
      "[170]\ttraining's binary_logloss: 0.554849\n",
      "[171]\ttraining's binary_logloss: 0.55473\n",
      "[172]\ttraining's binary_logloss: 0.554624\n",
      "[173]\ttraining's binary_logloss: 0.554504\n",
      "[174]\ttraining's binary_logloss: 0.554404\n",
      "[175]\ttraining's binary_logloss: 0.554308\n",
      "[176]\ttraining's binary_logloss: 0.5542\n",
      "[177]\ttraining's binary_logloss: 0.554092\n",
      "[178]\ttraining's binary_logloss: 0.553962\n",
      "[179]\ttraining's binary_logloss: 0.553862\n",
      "[180]\ttraining's binary_logloss: 0.553742\n",
      "[181]\ttraining's binary_logloss: 0.553621\n",
      "[182]\ttraining's binary_logloss: 0.553495\n",
      "[183]\ttraining's binary_logloss: 0.553368\n",
      "[184]\ttraining's binary_logloss: 0.553225\n",
      "[185]\ttraining's binary_logloss: 0.553062\n",
      "[186]\ttraining's binary_logloss: 0.552944\n",
      "[187]\ttraining's binary_logloss: 0.552833\n",
      "[188]\ttraining's binary_logloss: 0.552729\n",
      "[189]\ttraining's binary_logloss: 0.552637\n",
      "[190]\ttraining's binary_logloss: 0.552531\n",
      "[191]\ttraining's binary_logloss: 0.552401\n",
      "[192]\ttraining's binary_logloss: 0.552277\n",
      "[193]\ttraining's binary_logloss: 0.552145\n",
      "[194]\ttraining's binary_logloss: 0.552033\n",
      "[195]\ttraining's binary_logloss: 0.551907\n",
      "[196]\ttraining's binary_logloss: 0.551754\n",
      "[197]\ttraining's binary_logloss: 0.551622\n",
      "[198]\ttraining's binary_logloss: 0.551492\n",
      "[199]\ttraining's binary_logloss: 0.551369\n",
      "[200]\ttraining's binary_logloss: 0.551256\n",
      "[201]\ttraining's binary_logloss: 0.551161\n",
      "[202]\ttraining's binary_logloss: 0.551066\n",
      "[203]\ttraining's binary_logloss: 0.55098\n",
      "[204]\ttraining's binary_logloss: 0.550881\n",
      "[205]\ttraining's binary_logloss: 0.550781\n",
      "[206]\ttraining's binary_logloss: 0.550622\n",
      "[207]\ttraining's binary_logloss: 0.550455\n",
      "[208]\ttraining's binary_logloss: 0.550289\n",
      "[209]\ttraining's binary_logloss: 0.550143\n",
      "[210]\ttraining's binary_logloss: 0.549986\n",
      "[211]\ttraining's binary_logloss: 0.549891\n",
      "[212]\ttraining's binary_logloss: 0.549756\n",
      "[213]\ttraining's binary_logloss: 0.549651\n",
      "[214]\ttraining's binary_logloss: 0.549564\n",
      "[215]\ttraining's binary_logloss: 0.549478\n",
      "[216]\ttraining's binary_logloss: 0.549328\n",
      "[217]\ttraining's binary_logloss: 0.549166\n",
      "[218]\ttraining's binary_logloss: 0.549011\n",
      "[219]\ttraining's binary_logloss: 0.548837\n",
      "[220]\ttraining's binary_logloss: 0.548676\n",
      "[221]\ttraining's binary_logloss: 0.548499\n",
      "[222]\ttraining's binary_logloss: 0.548352\n",
      "[223]\ttraining's binary_logloss: 0.548195\n",
      "[224]\ttraining's binary_logloss: 0.548048\n",
      "[225]\ttraining's binary_logloss: 0.547907\n",
      "[226]\ttraining's binary_logloss: 0.547727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[227]\ttraining's binary_logloss: 0.547557\n",
      "[228]\ttraining's binary_logloss: 0.547387\n",
      "[229]\ttraining's binary_logloss: 0.547215\n",
      "[230]\ttraining's binary_logloss: 0.547044\n",
      "[231]\ttraining's binary_logloss: 0.546913\n",
      "[232]\ttraining's binary_logloss: 0.546781\n",
      "[233]\ttraining's binary_logloss: 0.546653\n",
      "[234]\ttraining's binary_logloss: 0.546482\n",
      "[235]\ttraining's binary_logloss: 0.546366\n",
      "[236]\ttraining's binary_logloss: 0.546187\n",
      "[237]\ttraining's binary_logloss: 0.546019\n",
      "[238]\ttraining's binary_logloss: 0.545879\n",
      "[239]\ttraining's binary_logloss: 0.545725\n",
      "[240]\ttraining's binary_logloss: 0.545566\n",
      "[241]\ttraining's binary_logloss: 0.54543\n",
      "[242]\ttraining's binary_logloss: 0.545296\n",
      "[243]\ttraining's binary_logloss: 0.545171\n",
      "[244]\ttraining's binary_logloss: 0.545074\n",
      "[245]\ttraining's binary_logloss: 0.54495\n",
      "[246]\ttraining's binary_logloss: 0.544745\n",
      "[247]\ttraining's binary_logloss: 0.544575\n",
      "[248]\ttraining's binary_logloss: 0.544379\n",
      "[249]\ttraining's binary_logloss: 0.544183\n",
      "[250]\ttraining's binary_logloss: 0.543994\n",
      "[251]\ttraining's binary_logloss: 0.543841\n",
      "[252]\ttraining's binary_logloss: 0.543706\n",
      "[253]\ttraining's binary_logloss: 0.543517\n",
      "[254]\ttraining's binary_logloss: 0.543373\n",
      "[255]\ttraining's binary_logloss: 0.543185\n",
      "[256]\ttraining's binary_logloss: 0.543059\n",
      "[257]\ttraining's binary_logloss: 0.54293\n",
      "[258]\ttraining's binary_logloss: 0.542816\n",
      "[259]\ttraining's binary_logloss: 0.542697\n",
      "[260]\ttraining's binary_logloss: 0.542583\n",
      "[261]\ttraining's binary_logloss: 0.542487\n",
      "[262]\ttraining's binary_logloss: 0.542382\n",
      "[263]\ttraining's binary_logloss: 0.542245\n",
      "[264]\ttraining's binary_logloss: 0.5421\n",
      "[265]\ttraining's binary_logloss: 0.541988\n",
      "[266]\ttraining's binary_logloss: 0.541889\n",
      "[267]\ttraining's binary_logloss: 0.541765\n",
      "[268]\ttraining's binary_logloss: 0.54166\n",
      "[269]\ttraining's binary_logloss: 0.541573\n",
      "[270]\ttraining's binary_logloss: 0.541454\n",
      "[271]\ttraining's binary_logloss: 0.541283\n",
      "[272]\ttraining's binary_logloss: 0.541128\n",
      "[273]\ttraining's binary_logloss: 0.54098\n",
      "[274]\ttraining's binary_logloss: 0.540823\n",
      "[275]\ttraining's binary_logloss: 0.540698\n",
      "[276]\ttraining's binary_logloss: 0.540553\n",
      "[277]\ttraining's binary_logloss: 0.540413\n",
      "[278]\ttraining's binary_logloss: 0.540269\n",
      "[279]\ttraining's binary_logloss: 0.540144\n",
      "[280]\ttraining's binary_logloss: 0.540006\n",
      "[281]\ttraining's binary_logloss: 0.539873\n",
      "[282]\ttraining's binary_logloss: 0.539757\n",
      "[283]\ttraining's binary_logloss: 0.53964\n",
      "[284]\ttraining's binary_logloss: 0.53953\n",
      "[285]\ttraining's binary_logloss: 0.539414\n",
      "[286]\ttraining's binary_logloss: 0.539243\n",
      "[287]\ttraining's binary_logloss: 0.539062\n",
      "[288]\ttraining's binary_logloss: 0.538895\n",
      "[289]\ttraining's binary_logloss: 0.538742\n",
      "[290]\ttraining's binary_logloss: 0.538566\n",
      "[291]\ttraining's binary_logloss: 0.538369\n",
      "[292]\ttraining's binary_logloss: 0.538184\n",
      "[293]\ttraining's binary_logloss: 0.53798\n",
      "[294]\ttraining's binary_logloss: 0.537788\n",
      "[295]\ttraining's binary_logloss: 0.537623\n",
      "[296]\ttraining's binary_logloss: 0.537485\n",
      "[297]\ttraining's binary_logloss: 0.537331\n",
      "[298]\ttraining's binary_logloss: 0.537174\n",
      "[299]\ttraining's binary_logloss: 0.537054\n",
      "[300]\ttraining's binary_logloss: 0.536923\n",
      "[301]\ttraining's binary_logloss: 0.536746\n",
      "[302]\ttraining's binary_logloss: 0.536561\n",
      "[303]\ttraining's binary_logloss: 0.53641\n",
      "[304]\ttraining's binary_logloss: 0.536247\n",
      "[305]\ttraining's binary_logloss: 0.536096\n",
      "[306]\ttraining's binary_logloss: 0.535919\n",
      "[307]\ttraining's binary_logloss: 0.535758\n",
      "[308]\ttraining's binary_logloss: 0.535606\n",
      "[309]\ttraining's binary_logloss: 0.535461\n",
      "[310]\ttraining's binary_logloss: 0.535306\n",
      "[311]\ttraining's binary_logloss: 0.535139\n",
      "[312]\ttraining's binary_logloss: 0.534973\n",
      "[313]\ttraining's binary_logloss: 0.53481\n",
      "[314]\ttraining's binary_logloss: 0.534652\n",
      "[315]\ttraining's binary_logloss: 0.534487\n",
      "[316]\ttraining's binary_logloss: 0.534319\n",
      "[317]\ttraining's binary_logloss: 0.534167\n",
      "[318]\ttraining's binary_logloss: 0.53402\n",
      "[319]\ttraining's binary_logloss: 0.533869\n",
      "[320]\ttraining's binary_logloss: 0.53372\n",
      "[321]\ttraining's binary_logloss: 0.533597\n",
      "[322]\ttraining's binary_logloss: 0.533492\n",
      "[323]\ttraining's binary_logloss: 0.533334\n",
      "[324]\ttraining's binary_logloss: 0.53318\n",
      "[325]\ttraining's binary_logloss: 0.533062\n",
      "[326]\ttraining's binary_logloss: 0.532874\n",
      "[327]\ttraining's binary_logloss: 0.532689\n",
      "[328]\ttraining's binary_logloss: 0.53251\n",
      "[329]\ttraining's binary_logloss: 0.532335\n",
      "[330]\ttraining's binary_logloss: 0.532158\n",
      "[331]\ttraining's binary_logloss: 0.532009\n",
      "[332]\ttraining's binary_logloss: 0.531861\n",
      "[333]\ttraining's binary_logloss: 0.531727\n",
      "[334]\ttraining's binary_logloss: 0.531595\n",
      "[335]\ttraining's binary_logloss: 0.531474\n",
      "[336]\ttraining's binary_logloss: 0.531324\n",
      "[337]\ttraining's binary_logloss: 0.531178\n",
      "[338]\ttraining's binary_logloss: 0.531023\n",
      "[339]\ttraining's binary_logloss: 0.530866\n",
      "[340]\ttraining's binary_logloss: 0.530776\n",
      "[341]\ttraining's binary_logloss: 0.530629\n",
      "[342]\ttraining's binary_logloss: 0.53051\n",
      "[343]\ttraining's binary_logloss: 0.530398\n",
      "[344]\ttraining's binary_logloss: 0.530252\n",
      "[345]\ttraining's binary_logloss: 0.53012\n",
      "[346]\ttraining's binary_logloss: 0.529941\n",
      "[347]\ttraining's binary_logloss: 0.529753\n",
      "[348]\ttraining's binary_logloss: 0.529575\n",
      "[349]\ttraining's binary_logloss: 0.529399\n",
      "[350]\ttraining's binary_logloss: 0.52923\n",
      "[351]\ttraining's binary_logloss: 0.529095\n",
      "[352]\ttraining's binary_logloss: 0.528968\n",
      "[353]\ttraining's binary_logloss: 0.528842\n",
      "[354]\ttraining's binary_logloss: 0.528707\n",
      "[355]\ttraining's binary_logloss: 0.528587\n",
      "[356]\ttraining's binary_logloss: 0.52844\n",
      "[357]\ttraining's binary_logloss: 0.5283\n",
      "[358]\ttraining's binary_logloss: 0.528165\n",
      "[359]\ttraining's binary_logloss: 0.528022\n",
      "[360]\ttraining's binary_logloss: 0.527893\n",
      "[361]\ttraining's binary_logloss: 0.527753\n",
      "[362]\ttraining's binary_logloss: 0.527578\n",
      "[363]\ttraining's binary_logloss: 0.527383\n",
      "[364]\ttraining's binary_logloss: 0.527203\n",
      "[365]\ttraining's binary_logloss: 0.52704\n",
      "[366]\ttraining's binary_logloss: 0.526867\n",
      "[367]\ttraining's binary_logloss: 0.526694\n",
      "[368]\ttraining's binary_logloss: 0.526543\n",
      "[369]\ttraining's binary_logloss: 0.526374\n",
      "[370]\ttraining's binary_logloss: 0.526214\n",
      "[371]\ttraining's binary_logloss: 0.526036\n",
      "[372]\ttraining's binary_logloss: 0.52587\n",
      "[373]\ttraining's binary_logloss: 0.525693\n",
      "[374]\ttraining's binary_logloss: 0.525509\n",
      "[375]\ttraining's binary_logloss: 0.525332\n",
      "[376]\ttraining's binary_logloss: 0.525175\n",
      "[377]\ttraining's binary_logloss: 0.525032\n",
      "[378]\ttraining's binary_logloss: 0.52488\n",
      "[379]\ttraining's binary_logloss: 0.524749\n",
      "[380]\ttraining's binary_logloss: 0.524565\n",
      "[381]\ttraining's binary_logloss: 0.52439\n",
      "[382]\ttraining's binary_logloss: 0.524223\n",
      "[383]\ttraining's binary_logloss: 0.524039\n",
      "[384]\ttraining's binary_logloss: 0.523876\n",
      "[385]\ttraining's binary_logloss: 0.523705\n",
      "[386]\ttraining's binary_logloss: 0.523529\n",
      "[387]\ttraining's binary_logloss: 0.523357\n",
      "[388]\ttraining's binary_logloss: 0.523195\n",
      "[389]\ttraining's binary_logloss: 0.523002\n",
      "[390]\ttraining's binary_logloss: 0.522838\n",
      "[391]\ttraining's binary_logloss: 0.522643\n",
      "[392]\ttraining's binary_logloss: 0.522456\n",
      "[393]\ttraining's binary_logloss: 0.522288\n",
      "[394]\ttraining's binary_logloss: 0.522105\n",
      "[395]\ttraining's binary_logloss: 0.521929\n",
      "[396]\ttraining's binary_logloss: 0.521794\n",
      "[397]\ttraining's binary_logloss: 0.521665\n",
      "[398]\ttraining's binary_logloss: 0.521537\n",
      "[399]\ttraining's binary_logloss: 0.52141\n",
      "[400]\ttraining's binary_logloss: 0.521271\n",
      "[401]\ttraining's binary_logloss: 0.521093\n",
      "[402]\ttraining's binary_logloss: 0.520926\n",
      "[403]\ttraining's binary_logloss: 0.520753\n",
      "[404]\ttraining's binary_logloss: 0.520592\n",
      "[405]\ttraining's binary_logloss: 0.520421\n",
      "[406]\ttraining's binary_logloss: 0.5203\n",
      "[407]\ttraining's binary_logloss: 0.520151\n",
      "[408]\ttraining's binary_logloss: 0.520041\n",
      "[409]\ttraining's binary_logloss: 0.519882\n",
      "[410]\ttraining's binary_logloss: 0.519787\n",
      "[411]\ttraining's binary_logloss: 0.519634\n",
      "[412]\ttraining's binary_logloss: 0.5195\n",
      "[413]\ttraining's binary_logloss: 0.519358\n",
      "[414]\ttraining's binary_logloss: 0.519197\n",
      "[415]\ttraining's binary_logloss: 0.519064\n",
      "[416]\ttraining's binary_logloss: 0.5189\n",
      "[417]\ttraining's binary_logloss: 0.518725\n",
      "[418]\ttraining's binary_logloss: 0.518565\n",
      "[419]\ttraining's binary_logloss: 0.518407\n",
      "[420]\ttraining's binary_logloss: 0.518244\n",
      "[421]\ttraining's binary_logloss: 0.518098\n",
      "[422]\ttraining's binary_logloss: 0.517972\n",
      "[423]\ttraining's binary_logloss: 0.517811\n",
      "[424]\ttraining's binary_logloss: 0.517691\n",
      "[425]\ttraining's binary_logloss: 0.517552\n",
      "[426]\ttraining's binary_logloss: 0.517391\n",
      "[427]\ttraining's binary_logloss: 0.517232\n",
      "[428]\ttraining's binary_logloss: 0.517119\n",
      "[429]\ttraining's binary_logloss: 0.51698\n",
      "[430]\ttraining's binary_logloss: 0.516811\n",
      "[431]\ttraining's binary_logloss: 0.516658\n",
      "[432]\ttraining's binary_logloss: 0.516513\n",
      "[433]\ttraining's binary_logloss: 0.516344\n",
      "[434]\ttraining's binary_logloss: 0.516178\n",
      "[435]\ttraining's binary_logloss: 0.516017\n",
      "[436]\ttraining's binary_logloss: 0.515875\n",
      "[437]\ttraining's binary_logloss: 0.515729\n",
      "[438]\ttraining's binary_logloss: 0.51559\n",
      "[439]\ttraining's binary_logloss: 0.515452\n",
      "[440]\ttraining's binary_logloss: 0.515315\n",
      "[441]\ttraining's binary_logloss: 0.515144\n",
      "[442]\ttraining's binary_logloss: 0.514957\n",
      "[443]\ttraining's binary_logloss: 0.514789\n",
      "[444]\ttraining's binary_logloss: 0.514621\n",
      "[445]\ttraining's binary_logloss: 0.514446\n",
      "[446]\ttraining's binary_logloss: 0.514254\n",
      "[447]\ttraining's binary_logloss: 0.514037\n",
      "[448]\ttraining's binary_logloss: 0.513836\n",
      "[449]\ttraining's binary_logloss: 0.513627\n",
      "[450]\ttraining's binary_logloss: 0.51344\n",
      "[451]\ttraining's binary_logloss: 0.51324\n",
      "[452]\ttraining's binary_logloss: 0.513029\n",
      "[453]\ttraining's binary_logloss: 0.512851\n",
      "[454]\ttraining's binary_logloss: 0.51269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[455]\ttraining's binary_logloss: 0.512507\n",
      "[456]\ttraining's binary_logloss: 0.512368\n",
      "[457]\ttraining's binary_logloss: 0.512227\n",
      "[458]\ttraining's binary_logloss: 0.512089\n",
      "[459]\ttraining's binary_logloss: 0.511946\n",
      "[460]\ttraining's binary_logloss: 0.511813\n",
      "[461]\ttraining's binary_logloss: 0.511661\n",
      "[462]\ttraining's binary_logloss: 0.511496\n",
      "[463]\ttraining's binary_logloss: 0.511355\n",
      "[464]\ttraining's binary_logloss: 0.511197\n",
      "[465]\ttraining's binary_logloss: 0.511033\n",
      "[466]\ttraining's binary_logloss: 0.510852\n",
      "[467]\ttraining's binary_logloss: 0.510691\n",
      "[468]\ttraining's binary_logloss: 0.510536\n",
      "[469]\ttraining's binary_logloss: 0.510364\n",
      "[470]\ttraining's binary_logloss: 0.510199\n",
      "[471]\ttraining's binary_logloss: 0.510027\n",
      "[472]\ttraining's binary_logloss: 0.50986\n",
      "[473]\ttraining's binary_logloss: 0.509678\n",
      "[474]\ttraining's binary_logloss: 0.509512\n",
      "[475]\ttraining's binary_logloss: 0.509339\n",
      "[476]\ttraining's binary_logloss: 0.509205\n",
      "[477]\ttraining's binary_logloss: 0.509059\n",
      "[478]\ttraining's binary_logloss: 0.50892\n",
      "[479]\ttraining's binary_logloss: 0.508779\n",
      "[480]\ttraining's binary_logloss: 0.508643\n",
      "[481]\ttraining's binary_logloss: 0.508525\n",
      "[482]\ttraining's binary_logloss: 0.508416\n",
      "[483]\ttraining's binary_logloss: 0.508265\n",
      "[484]\ttraining's binary_logloss: 0.508148\n",
      "[485]\ttraining's binary_logloss: 0.508006\n",
      "[486]\ttraining's binary_logloss: 0.507822\n",
      "[487]\ttraining's binary_logloss: 0.507651\n",
      "[488]\ttraining's binary_logloss: 0.507472\n",
      "[489]\ttraining's binary_logloss: 0.507285\n",
      "[490]\ttraining's binary_logloss: 0.507098\n",
      "[491]\ttraining's binary_logloss: 0.506942\n",
      "[492]\ttraining's binary_logloss: 0.506752\n",
      "[493]\ttraining's binary_logloss: 0.506577\n",
      "[494]\ttraining's binary_logloss: 0.506395\n",
      "[495]\ttraining's binary_logloss: 0.506215\n",
      "[496]\ttraining's binary_logloss: 0.506019\n",
      "[497]\ttraining's binary_logloss: 0.505829\n",
      "[498]\ttraining's binary_logloss: 0.505643\n",
      "[499]\ttraining's binary_logloss: 0.505465\n",
      "[500]\ttraining's binary_logloss: 0.505288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614173\n",
      "[2]\ttraining's binary_logloss: 0.612578\n",
      "[3]\ttraining's binary_logloss: 0.611014\n",
      "[4]\ttraining's binary_logloss: 0.60949\n",
      "[5]\ttraining's binary_logloss: 0.608035\n",
      "[6]\ttraining's binary_logloss: 0.606571\n",
      "[7]\ttraining's binary_logloss: 0.605185\n",
      "[8]\ttraining's binary_logloss: 0.603844\n",
      "[9]\ttraining's binary_logloss: 0.602511\n",
      "[10]\ttraining's binary_logloss: 0.601275\n",
      "[11]\ttraining's binary_logloss: 0.600055\n",
      "[12]\ttraining's binary_logloss: 0.598843\n",
      "[13]\ttraining's binary_logloss: 0.597707\n",
      "[14]\ttraining's binary_logloss: 0.596591\n",
      "[15]\ttraining's binary_logloss: 0.595475\n",
      "[16]\ttraining's binary_logloss: 0.594419\n",
      "[17]\ttraining's binary_logloss: 0.593396\n",
      "[18]\ttraining's binary_logloss: 0.592403\n",
      "[19]\ttraining's binary_logloss: 0.591434\n",
      "[20]\ttraining's binary_logloss: 0.590459\n",
      "[21]\ttraining's binary_logloss: 0.589579\n",
      "[22]\ttraining's binary_logloss: 0.588746\n",
      "[23]\ttraining's binary_logloss: 0.587907\n",
      "[24]\ttraining's binary_logloss: 0.587122\n",
      "[25]\ttraining's binary_logloss: 0.58636\n",
      "[26]\ttraining's binary_logloss: 0.585566\n",
      "[27]\ttraining's binary_logloss: 0.584732\n",
      "[28]\ttraining's binary_logloss: 0.583994\n",
      "[29]\ttraining's binary_logloss: 0.583178\n",
      "[30]\ttraining's binary_logloss: 0.582465\n",
      "[31]\ttraining's binary_logloss: 0.581739\n",
      "[32]\ttraining's binary_logloss: 0.58098\n",
      "[33]\ttraining's binary_logloss: 0.580303\n",
      "[34]\ttraining's binary_logloss: 0.579612\n",
      "[35]\ttraining's binary_logloss: 0.578906\n",
      "[36]\ttraining's binary_logloss: 0.578198\n",
      "[37]\ttraining's binary_logloss: 0.577535\n",
      "[38]\ttraining's binary_logloss: 0.576861\n",
      "[39]\ttraining's binary_logloss: 0.5762\n",
      "[40]\ttraining's binary_logloss: 0.575564\n",
      "[41]\ttraining's binary_logloss: 0.575008\n",
      "[42]\ttraining's binary_logloss: 0.574469\n",
      "[43]\ttraining's binary_logloss: 0.573899\n",
      "[44]\ttraining's binary_logloss: 0.573423\n",
      "[45]\ttraining's binary_logloss: 0.572889\n",
      "[46]\ttraining's binary_logloss: 0.572314\n",
      "[47]\ttraining's binary_logloss: 0.571738\n",
      "[48]\ttraining's binary_logloss: 0.571184\n",
      "[49]\ttraining's binary_logloss: 0.570644\n",
      "[50]\ttraining's binary_logloss: 0.570152\n",
      "[51]\ttraining's binary_logloss: 0.569667\n",
      "[52]\ttraining's binary_logloss: 0.56921\n",
      "[53]\ttraining's binary_logloss: 0.568781\n",
      "[54]\ttraining's binary_logloss: 0.568317\n",
      "[55]\ttraining's binary_logloss: 0.567869\n",
      "[56]\ttraining's binary_logloss: 0.567468\n",
      "[57]\ttraining's binary_logloss: 0.567014\n",
      "[58]\ttraining's binary_logloss: 0.566556\n",
      "[59]\ttraining's binary_logloss: 0.566208\n",
      "[60]\ttraining's binary_logloss: 0.565781\n",
      "[61]\ttraining's binary_logloss: 0.565407\n",
      "[62]\ttraining's binary_logloss: 0.565059\n",
      "[63]\ttraining's binary_logloss: 0.56466\n",
      "[64]\ttraining's binary_logloss: 0.564277\n",
      "[65]\ttraining's binary_logloss: 0.563919\n",
      "[66]\ttraining's binary_logloss: 0.56353\n",
      "[67]\ttraining's binary_logloss: 0.563193\n",
      "[68]\ttraining's binary_logloss: 0.562807\n",
      "[69]\ttraining's binary_logloss: 0.562479\n",
      "[70]\ttraining's binary_logloss: 0.562106\n",
      "[71]\ttraining's binary_logloss: 0.56176\n",
      "[72]\ttraining's binary_logloss: 0.56146\n",
      "[73]\ttraining's binary_logloss: 0.561096\n",
      "[74]\ttraining's binary_logloss: 0.560739\n",
      "[75]\ttraining's binary_logloss: 0.560389\n",
      "[76]\ttraining's binary_logloss: 0.560107\n",
      "[77]\ttraining's binary_logloss: 0.559857\n",
      "[78]\ttraining's binary_logloss: 0.559609\n",
      "[79]\ttraining's binary_logloss: 0.55931\n",
      "[80]\ttraining's binary_logloss: 0.559015\n",
      "[81]\ttraining's binary_logloss: 0.558714\n",
      "[82]\ttraining's binary_logloss: 0.558474\n",
      "[83]\ttraining's binary_logloss: 0.558176\n",
      "[84]\ttraining's binary_logloss: 0.55789\n",
      "[85]\ttraining's binary_logloss: 0.557655\n",
      "[86]\ttraining's binary_logloss: 0.557395\n",
      "[87]\ttraining's binary_logloss: 0.557127\n",
      "[88]\ttraining's binary_logloss: 0.556828\n",
      "[89]\ttraining's binary_logloss: 0.55653\n",
      "[90]\ttraining's binary_logloss: 0.556283\n",
      "[91]\ttraining's binary_logloss: 0.556047\n",
      "[92]\ttraining's binary_logloss: 0.555806\n",
      "[93]\ttraining's binary_logloss: 0.555583\n",
      "[94]\ttraining's binary_logloss: 0.555407\n",
      "[95]\ttraining's binary_logloss: 0.555221\n",
      "[96]\ttraining's binary_logloss: 0.554963\n",
      "[97]\ttraining's binary_logloss: 0.554716\n",
      "[98]\ttraining's binary_logloss: 0.554473\n",
      "[99]\ttraining's binary_logloss: 0.554257\n",
      "[100]\ttraining's binary_logloss: 0.554021\n",
      "[101]\ttraining's binary_logloss: 0.553804\n",
      "[102]\ttraining's binary_logloss: 0.553609\n",
      "[103]\ttraining's binary_logloss: 0.553374\n",
      "[104]\ttraining's binary_logloss: 0.553168\n",
      "[105]\ttraining's binary_logloss: 0.552928\n",
      "[106]\ttraining's binary_logloss: 0.552727\n",
      "[107]\ttraining's binary_logloss: 0.552518\n",
      "[108]\ttraining's binary_logloss: 0.552313\n",
      "[109]\ttraining's binary_logloss: 0.552139\n",
      "[110]\ttraining's binary_logloss: 0.551946\n",
      "[111]\ttraining's binary_logloss: 0.551723\n",
      "[112]\ttraining's binary_logloss: 0.551481\n",
      "[113]\ttraining's binary_logloss: 0.551216\n",
      "[114]\ttraining's binary_logloss: 0.550958\n",
      "[115]\ttraining's binary_logloss: 0.550714\n",
      "[116]\ttraining's binary_logloss: 0.550449\n",
      "[117]\ttraining's binary_logloss: 0.550254\n",
      "[118]\ttraining's binary_logloss: 0.55001\n",
      "[119]\ttraining's binary_logloss: 0.549791\n",
      "[120]\ttraining's binary_logloss: 0.54958\n",
      "[121]\ttraining's binary_logloss: 0.549378\n",
      "[122]\ttraining's binary_logloss: 0.549182\n",
      "[123]\ttraining's binary_logloss: 0.549005\n",
      "[124]\ttraining's binary_logloss: 0.548803\n",
      "[125]\ttraining's binary_logloss: 0.548633\n",
      "[126]\ttraining's binary_logloss: 0.548434\n",
      "[127]\ttraining's binary_logloss: 0.548178\n",
      "[128]\ttraining's binary_logloss: 0.547969\n",
      "[129]\ttraining's binary_logloss: 0.547768\n",
      "[130]\ttraining's binary_logloss: 0.547548\n",
      "[131]\ttraining's binary_logloss: 0.547378\n",
      "[132]\ttraining's binary_logloss: 0.54721\n",
      "[133]\ttraining's binary_logloss: 0.547057\n",
      "[134]\ttraining's binary_logloss: 0.546913\n",
      "[135]\ttraining's binary_logloss: 0.546746\n",
      "[136]\ttraining's binary_logloss: 0.546562\n",
      "[137]\ttraining's binary_logloss: 0.546371\n",
      "[138]\ttraining's binary_logloss: 0.546159\n",
      "[139]\ttraining's binary_logloss: 0.54599\n",
      "[140]\ttraining's binary_logloss: 0.545821\n",
      "[141]\ttraining's binary_logloss: 0.545632\n",
      "[142]\ttraining's binary_logloss: 0.54546\n",
      "[143]\ttraining's binary_logloss: 0.545288\n",
      "[144]\ttraining's binary_logloss: 0.545114\n",
      "[145]\ttraining's binary_logloss: 0.544949\n",
      "[146]\ttraining's binary_logloss: 0.544785\n",
      "[147]\ttraining's binary_logloss: 0.544624\n",
      "[148]\ttraining's binary_logloss: 0.544435\n",
      "[149]\ttraining's binary_logloss: 0.544248\n",
      "[150]\ttraining's binary_logloss: 0.544053\n",
      "[151]\ttraining's binary_logloss: 0.543879\n",
      "[152]\ttraining's binary_logloss: 0.543706\n",
      "[153]\ttraining's binary_logloss: 0.543542\n",
      "[154]\ttraining's binary_logloss: 0.543356\n",
      "[155]\ttraining's binary_logloss: 0.543143\n",
      "[156]\ttraining's binary_logloss: 0.542969\n",
      "[157]\ttraining's binary_logloss: 0.542766\n",
      "[158]\ttraining's binary_logloss: 0.542551\n",
      "[159]\ttraining's binary_logloss: 0.542366\n",
      "[160]\ttraining's binary_logloss: 0.542163\n",
      "[161]\ttraining's binary_logloss: 0.54195\n",
      "[162]\ttraining's binary_logloss: 0.541745\n",
      "[163]\ttraining's binary_logloss: 0.541529\n",
      "[164]\ttraining's binary_logloss: 0.541335\n",
      "[165]\ttraining's binary_logloss: 0.54114\n",
      "[166]\ttraining's binary_logloss: 0.54095\n",
      "[167]\ttraining's binary_logloss: 0.540794\n",
      "[168]\ttraining's binary_logloss: 0.540577\n",
      "[169]\ttraining's binary_logloss: 0.540384\n",
      "[170]\ttraining's binary_logloss: 0.540138\n",
      "[171]\ttraining's binary_logloss: 0.539957\n",
      "[172]\ttraining's binary_logloss: 0.539782\n",
      "[173]\ttraining's binary_logloss: 0.539598\n",
      "[174]\ttraining's binary_logloss: 0.539452\n",
      "[175]\ttraining's binary_logloss: 0.53929\n",
      "[176]\ttraining's binary_logloss: 0.53913\n",
      "[177]\ttraining's binary_logloss: 0.538965\n",
      "[178]\ttraining's binary_logloss: 0.53877\n",
      "[179]\ttraining's binary_logloss: 0.538614\n",
      "[180]\ttraining's binary_logloss: 0.538433\n",
      "[181]\ttraining's binary_logloss: 0.538214\n",
      "[182]\ttraining's binary_logloss: 0.537997\n",
      "[183]\ttraining's binary_logloss: 0.537778\n",
      "[184]\ttraining's binary_logloss: 0.537575\n",
      "[185]\ttraining's binary_logloss: 0.537359\n",
      "[186]\ttraining's binary_logloss: 0.537184\n",
      "[187]\ttraining's binary_logloss: 0.537001\n",
      "[188]\ttraining's binary_logloss: 0.536828\n",
      "[189]\ttraining's binary_logloss: 0.536681\n",
      "[190]\ttraining's binary_logloss: 0.536509\n",
      "[191]\ttraining's binary_logloss: 0.536324\n",
      "[192]\ttraining's binary_logloss: 0.536122\n",
      "[193]\ttraining's binary_logloss: 0.535954\n",
      "[194]\ttraining's binary_logloss: 0.535748\n",
      "[195]\ttraining's binary_logloss: 0.535559\n",
      "[196]\ttraining's binary_logloss: 0.535356\n",
      "[197]\ttraining's binary_logloss: 0.535161\n",
      "[198]\ttraining's binary_logloss: 0.534962\n",
      "[199]\ttraining's binary_logloss: 0.534751\n",
      "[200]\ttraining's binary_logloss: 0.534585\n",
      "[201]\ttraining's binary_logloss: 0.534427\n",
      "[202]\ttraining's binary_logloss: 0.53428\n",
      "[203]\ttraining's binary_logloss: 0.534159\n",
      "[204]\ttraining's binary_logloss: 0.533985\n",
      "[205]\ttraining's binary_logloss: 0.533819\n",
      "[206]\ttraining's binary_logloss: 0.53365\n",
      "[207]\ttraining's binary_logloss: 0.533431\n",
      "[208]\ttraining's binary_logloss: 0.533208\n",
      "[209]\ttraining's binary_logloss: 0.532997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[210]\ttraining's binary_logloss: 0.532783\n",
      "[211]\ttraining's binary_logloss: 0.532599\n",
      "[212]\ttraining's binary_logloss: 0.532404\n",
      "[213]\ttraining's binary_logloss: 0.532222\n",
      "[214]\ttraining's binary_logloss: 0.532046\n",
      "[215]\ttraining's binary_logloss: 0.531883\n",
      "[216]\ttraining's binary_logloss: 0.53168\n",
      "[217]\ttraining's binary_logloss: 0.531456\n",
      "[218]\ttraining's binary_logloss: 0.531225\n",
      "[219]\ttraining's binary_logloss: 0.531\n",
      "[220]\ttraining's binary_logloss: 0.530775\n",
      "[221]\ttraining's binary_logloss: 0.530534\n",
      "[222]\ttraining's binary_logloss: 0.530363\n",
      "[223]\ttraining's binary_logloss: 0.53016\n",
      "[224]\ttraining's binary_logloss: 0.529923\n",
      "[225]\ttraining's binary_logloss: 0.529737\n",
      "[226]\ttraining's binary_logloss: 0.529495\n",
      "[227]\ttraining's binary_logloss: 0.529252\n",
      "[228]\ttraining's binary_logloss: 0.529014\n",
      "[229]\ttraining's binary_logloss: 0.528789\n",
      "[230]\ttraining's binary_logloss: 0.528561\n",
      "[231]\ttraining's binary_logloss: 0.528354\n",
      "[232]\ttraining's binary_logloss: 0.52814\n",
      "[233]\ttraining's binary_logloss: 0.527921\n",
      "[234]\ttraining's binary_logloss: 0.527712\n",
      "[235]\ttraining's binary_logloss: 0.527498\n",
      "[236]\ttraining's binary_logloss: 0.527256\n",
      "[237]\ttraining's binary_logloss: 0.527017\n",
      "[238]\ttraining's binary_logloss: 0.526832\n",
      "[239]\ttraining's binary_logloss: 0.526608\n",
      "[240]\ttraining's binary_logloss: 0.526372\n",
      "[241]\ttraining's binary_logloss: 0.52618\n",
      "[242]\ttraining's binary_logloss: 0.526036\n",
      "[243]\ttraining's binary_logloss: 0.525852\n",
      "[244]\ttraining's binary_logloss: 0.525645\n",
      "[245]\ttraining's binary_logloss: 0.525488\n",
      "[246]\ttraining's binary_logloss: 0.525204\n",
      "[247]\ttraining's binary_logloss: 0.524983\n",
      "[248]\ttraining's binary_logloss: 0.524759\n",
      "[249]\ttraining's binary_logloss: 0.524496\n",
      "[250]\ttraining's binary_logloss: 0.524245\n",
      "[251]\ttraining's binary_logloss: 0.524032\n",
      "[252]\ttraining's binary_logloss: 0.523845\n",
      "[253]\ttraining's binary_logloss: 0.523635\n",
      "[254]\ttraining's binary_logloss: 0.523424\n",
      "[255]\ttraining's binary_logloss: 0.523182\n",
      "[256]\ttraining's binary_logloss: 0.523009\n",
      "[257]\ttraining's binary_logloss: 0.522828\n",
      "[258]\ttraining's binary_logloss: 0.522599\n",
      "[259]\ttraining's binary_logloss: 0.522376\n",
      "[260]\ttraining's binary_logloss: 0.522159\n",
      "[261]\ttraining's binary_logloss: 0.522002\n",
      "[262]\ttraining's binary_logloss: 0.52185\n",
      "[263]\ttraining's binary_logloss: 0.521653\n",
      "[264]\ttraining's binary_logloss: 0.521454\n",
      "[265]\ttraining's binary_logloss: 0.521262\n",
      "[266]\ttraining's binary_logloss: 0.521116\n",
      "[267]\ttraining's binary_logloss: 0.520959\n",
      "[268]\ttraining's binary_logloss: 0.520796\n",
      "[269]\ttraining's binary_logloss: 0.520644\n",
      "[270]\ttraining's binary_logloss: 0.520475\n",
      "[271]\ttraining's binary_logloss: 0.520308\n",
      "[272]\ttraining's binary_logloss: 0.520142\n",
      "[273]\ttraining's binary_logloss: 0.519966\n",
      "[274]\ttraining's binary_logloss: 0.519798\n",
      "[275]\ttraining's binary_logloss: 0.519635\n",
      "[276]\ttraining's binary_logloss: 0.519433\n",
      "[277]\ttraining's binary_logloss: 0.519237\n",
      "[278]\ttraining's binary_logloss: 0.51904\n",
      "[279]\ttraining's binary_logloss: 0.518877\n",
      "[280]\ttraining's binary_logloss: 0.518688\n",
      "[281]\ttraining's binary_logloss: 0.518502\n",
      "[282]\ttraining's binary_logloss: 0.518345\n",
      "[283]\ttraining's binary_logloss: 0.518158\n",
      "[284]\ttraining's binary_logloss: 0.518003\n",
      "[285]\ttraining's binary_logloss: 0.517833\n",
      "[286]\ttraining's binary_logloss: 0.517624\n",
      "[287]\ttraining's binary_logloss: 0.5174\n",
      "[288]\ttraining's binary_logloss: 0.517172\n",
      "[289]\ttraining's binary_logloss: 0.516969\n",
      "[290]\ttraining's binary_logloss: 0.516748\n",
      "[291]\ttraining's binary_logloss: 0.516488\n",
      "[292]\ttraining's binary_logloss: 0.516272\n",
      "[293]\ttraining's binary_logloss: 0.516035\n",
      "[294]\ttraining's binary_logloss: 0.515797\n",
      "[295]\ttraining's binary_logloss: 0.515569\n",
      "[296]\ttraining's binary_logloss: 0.515366\n",
      "[297]\ttraining's binary_logloss: 0.515137\n",
      "[298]\ttraining's binary_logloss: 0.514955\n",
      "[299]\ttraining's binary_logloss: 0.514777\n",
      "[300]\ttraining's binary_logloss: 0.514572\n",
      "[301]\ttraining's binary_logloss: 0.514355\n",
      "[302]\ttraining's binary_logloss: 0.514128\n",
      "[303]\ttraining's binary_logloss: 0.513895\n",
      "[304]\ttraining's binary_logloss: 0.513673\n",
      "[305]\ttraining's binary_logloss: 0.513463\n",
      "[306]\ttraining's binary_logloss: 0.51327\n",
      "[307]\ttraining's binary_logloss: 0.513078\n",
      "[308]\ttraining's binary_logloss: 0.512883\n",
      "[309]\ttraining's binary_logloss: 0.512699\n",
      "[310]\ttraining's binary_logloss: 0.512513\n",
      "[311]\ttraining's binary_logloss: 0.512309\n",
      "[312]\ttraining's binary_logloss: 0.512089\n",
      "[313]\ttraining's binary_logloss: 0.511868\n",
      "[314]\ttraining's binary_logloss: 0.511673\n",
      "[315]\ttraining's binary_logloss: 0.511466\n",
      "[316]\ttraining's binary_logloss: 0.511263\n",
      "[317]\ttraining's binary_logloss: 0.511069\n",
      "[318]\ttraining's binary_logloss: 0.510879\n",
      "[319]\ttraining's binary_logloss: 0.510681\n",
      "[320]\ttraining's binary_logloss: 0.510497\n",
      "[321]\ttraining's binary_logloss: 0.510334\n",
      "[322]\ttraining's binary_logloss: 0.510188\n",
      "[323]\ttraining's binary_logloss: 0.509971\n",
      "[324]\ttraining's binary_logloss: 0.509767\n",
      "[325]\ttraining's binary_logloss: 0.509608\n",
      "[326]\ttraining's binary_logloss: 0.509373\n",
      "[327]\ttraining's binary_logloss: 0.509142\n",
      "[328]\ttraining's binary_logloss: 0.508906\n",
      "[329]\ttraining's binary_logloss: 0.508662\n",
      "[330]\ttraining's binary_logloss: 0.508431\n",
      "[331]\ttraining's binary_logloss: 0.508237\n",
      "[332]\ttraining's binary_logloss: 0.508046\n",
      "[333]\ttraining's binary_logloss: 0.507861\n",
      "[334]\ttraining's binary_logloss: 0.507685\n",
      "[335]\ttraining's binary_logloss: 0.507503\n",
      "[336]\ttraining's binary_logloss: 0.507316\n",
      "[337]\ttraining's binary_logloss: 0.507121\n",
      "[338]\ttraining's binary_logloss: 0.506941\n",
      "[339]\ttraining's binary_logloss: 0.506725\n",
      "[340]\ttraining's binary_logloss: 0.506593\n",
      "[341]\ttraining's binary_logloss: 0.506411\n",
      "[342]\ttraining's binary_logloss: 0.506258\n",
      "[343]\ttraining's binary_logloss: 0.506078\n",
      "[344]\ttraining's binary_logloss: 0.505883\n",
      "[345]\ttraining's binary_logloss: 0.505704\n",
      "[346]\ttraining's binary_logloss: 0.505493\n",
      "[347]\ttraining's binary_logloss: 0.505256\n",
      "[348]\ttraining's binary_logloss: 0.505026\n",
      "[349]\ttraining's binary_logloss: 0.504806\n",
      "[350]\ttraining's binary_logloss: 0.50458\n",
      "[351]\ttraining's binary_logloss: 0.504391\n",
      "[352]\ttraining's binary_logloss: 0.504198\n",
      "[353]\ttraining's binary_logloss: 0.504017\n",
      "[354]\ttraining's binary_logloss: 0.503813\n",
      "[355]\ttraining's binary_logloss: 0.503655\n",
      "[356]\ttraining's binary_logloss: 0.503447\n",
      "[357]\ttraining's binary_logloss: 0.503258\n",
      "[358]\ttraining's binary_logloss: 0.503071\n",
      "[359]\ttraining's binary_logloss: 0.502889\n",
      "[360]\ttraining's binary_logloss: 0.502717\n",
      "[361]\ttraining's binary_logloss: 0.502499\n",
      "[362]\ttraining's binary_logloss: 0.502292\n",
      "[363]\ttraining's binary_logloss: 0.502038\n",
      "[364]\ttraining's binary_logloss: 0.501839\n",
      "[365]\ttraining's binary_logloss: 0.501652\n",
      "[366]\ttraining's binary_logloss: 0.501411\n",
      "[367]\ttraining's binary_logloss: 0.501193\n",
      "[368]\ttraining's binary_logloss: 0.501002\n",
      "[369]\ttraining's binary_logloss: 0.50079\n",
      "[370]\ttraining's binary_logloss: 0.500572\n",
      "[371]\ttraining's binary_logloss: 0.500356\n",
      "[372]\ttraining's binary_logloss: 0.500128\n",
      "[373]\ttraining's binary_logloss: 0.49992\n",
      "[374]\ttraining's binary_logloss: 0.499697\n",
      "[375]\ttraining's binary_logloss: 0.49949\n",
      "[376]\ttraining's binary_logloss: 0.499296\n",
      "[377]\ttraining's binary_logloss: 0.499106\n",
      "[378]\ttraining's binary_logloss: 0.498923\n",
      "[379]\ttraining's binary_logloss: 0.498753\n",
      "[380]\ttraining's binary_logloss: 0.498555\n",
      "[381]\ttraining's binary_logloss: 0.498363\n",
      "[382]\ttraining's binary_logloss: 0.498146\n",
      "[383]\ttraining's binary_logloss: 0.497936\n",
      "[384]\ttraining's binary_logloss: 0.497731\n",
      "[385]\ttraining's binary_logloss: 0.497522\n",
      "[386]\ttraining's binary_logloss: 0.497325\n",
      "[387]\ttraining's binary_logloss: 0.497086\n",
      "[388]\ttraining's binary_logloss: 0.496869\n",
      "[389]\ttraining's binary_logloss: 0.496607\n",
      "[390]\ttraining's binary_logloss: 0.496373\n",
      "[391]\ttraining's binary_logloss: 0.49614\n",
      "[392]\ttraining's binary_logloss: 0.495905\n",
      "[393]\ttraining's binary_logloss: 0.495676\n",
      "[394]\ttraining's binary_logloss: 0.495445\n",
      "[395]\ttraining's binary_logloss: 0.495225\n",
      "[396]\ttraining's binary_logloss: 0.49506\n",
      "[397]\ttraining's binary_logloss: 0.494891\n",
      "[398]\ttraining's binary_logloss: 0.494727\n",
      "[399]\ttraining's binary_logloss: 0.494572\n",
      "[400]\ttraining's binary_logloss: 0.494415\n",
      "[401]\ttraining's binary_logloss: 0.494204\n",
      "[402]\ttraining's binary_logloss: 0.493993\n",
      "[403]\ttraining's binary_logloss: 0.493785\n",
      "[404]\ttraining's binary_logloss: 0.493583\n",
      "[405]\ttraining's binary_logloss: 0.493377\n",
      "[406]\ttraining's binary_logloss: 0.493195\n",
      "[407]\ttraining's binary_logloss: 0.492992\n",
      "[408]\ttraining's binary_logloss: 0.492844\n",
      "[409]\ttraining's binary_logloss: 0.492692\n",
      "[410]\ttraining's binary_logloss: 0.492542\n",
      "[411]\ttraining's binary_logloss: 0.492348\n",
      "[412]\ttraining's binary_logloss: 0.492163\n",
      "[413]\ttraining's binary_logloss: 0.49199\n",
      "[414]\ttraining's binary_logloss: 0.491815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[415]\ttraining's binary_logloss: 0.491612\n",
      "[416]\ttraining's binary_logloss: 0.491406\n",
      "[417]\ttraining's binary_logloss: 0.491198\n",
      "[418]\ttraining's binary_logloss: 0.490999\n",
      "[419]\ttraining's binary_logloss: 0.490814\n",
      "[420]\ttraining's binary_logloss: 0.490632\n",
      "[421]\ttraining's binary_logloss: 0.49044\n",
      "[422]\ttraining's binary_logloss: 0.490261\n",
      "[423]\ttraining's binary_logloss: 0.490043\n",
      "[424]\ttraining's binary_logloss: 0.489868\n",
      "[425]\ttraining's binary_logloss: 0.489678\n",
      "[426]\ttraining's binary_logloss: 0.489512\n",
      "[427]\ttraining's binary_logloss: 0.489283\n",
      "[428]\ttraining's binary_logloss: 0.489126\n",
      "[429]\ttraining's binary_logloss: 0.488956\n",
      "[430]\ttraining's binary_logloss: 0.488753\n",
      "[431]\ttraining's binary_logloss: 0.488522\n",
      "[432]\ttraining's binary_logloss: 0.488321\n",
      "[433]\ttraining's binary_logloss: 0.488127\n",
      "[434]\ttraining's binary_logloss: 0.487935\n",
      "[435]\ttraining's binary_logloss: 0.487736\n",
      "[436]\ttraining's binary_logloss: 0.487561\n",
      "[437]\ttraining's binary_logloss: 0.487362\n",
      "[438]\ttraining's binary_logloss: 0.487156\n",
      "[439]\ttraining's binary_logloss: 0.486965\n",
      "[440]\ttraining's binary_logloss: 0.486781\n",
      "[441]\ttraining's binary_logloss: 0.486549\n",
      "[442]\ttraining's binary_logloss: 0.486329\n",
      "[443]\ttraining's binary_logloss: 0.486136\n",
      "[444]\ttraining's binary_logloss: 0.485951\n",
      "[445]\ttraining's binary_logloss: 0.485775\n",
      "[446]\ttraining's binary_logloss: 0.485551\n",
      "[447]\ttraining's binary_logloss: 0.485333\n",
      "[448]\ttraining's binary_logloss: 0.485095\n",
      "[449]\ttraining's binary_logloss: 0.48486\n",
      "[450]\ttraining's binary_logloss: 0.484642\n",
      "[451]\ttraining's binary_logloss: 0.484396\n",
      "[452]\ttraining's binary_logloss: 0.48414\n",
      "[453]\ttraining's binary_logloss: 0.483918\n",
      "[454]\ttraining's binary_logloss: 0.483718\n",
      "[455]\ttraining's binary_logloss: 0.483487\n",
      "[456]\ttraining's binary_logloss: 0.483286\n",
      "[457]\ttraining's binary_logloss: 0.483115\n",
      "[458]\ttraining's binary_logloss: 0.482935\n",
      "[459]\ttraining's binary_logloss: 0.482747\n",
      "[460]\ttraining's binary_logloss: 0.482577\n",
      "[461]\ttraining's binary_logloss: 0.482367\n",
      "[462]\ttraining's binary_logloss: 0.482164\n",
      "[463]\ttraining's binary_logloss: 0.481953\n",
      "[464]\ttraining's binary_logloss: 0.481725\n",
      "[465]\ttraining's binary_logloss: 0.48152\n",
      "[466]\ttraining's binary_logloss: 0.481301\n",
      "[467]\ttraining's binary_logloss: 0.481063\n",
      "[468]\ttraining's binary_logloss: 0.480841\n",
      "[469]\ttraining's binary_logloss: 0.48063\n",
      "[470]\ttraining's binary_logloss: 0.480424\n",
      "[471]\ttraining's binary_logloss: 0.480225\n",
      "[472]\ttraining's binary_logloss: 0.480044\n",
      "[473]\ttraining's binary_logloss: 0.479857\n",
      "[474]\ttraining's binary_logloss: 0.479664\n",
      "[475]\ttraining's binary_logloss: 0.479468\n",
      "[476]\ttraining's binary_logloss: 0.479301\n",
      "[477]\ttraining's binary_logloss: 0.479136\n",
      "[478]\ttraining's binary_logloss: 0.478954\n",
      "[479]\ttraining's binary_logloss: 0.478816\n",
      "[480]\ttraining's binary_logloss: 0.478625\n",
      "[481]\ttraining's binary_logloss: 0.478436\n",
      "[482]\ttraining's binary_logloss: 0.478253\n",
      "[483]\ttraining's binary_logloss: 0.478114\n",
      "[484]\ttraining's binary_logloss: 0.477936\n",
      "[485]\ttraining's binary_logloss: 0.477737\n",
      "[486]\ttraining's binary_logloss: 0.477532\n",
      "[487]\ttraining's binary_logloss: 0.477328\n",
      "[488]\ttraining's binary_logloss: 0.477105\n",
      "[489]\ttraining's binary_logloss: 0.476919\n",
      "[490]\ttraining's binary_logloss: 0.476705\n",
      "[491]\ttraining's binary_logloss: 0.476508\n",
      "[492]\ttraining's binary_logloss: 0.476278\n",
      "[493]\ttraining's binary_logloss: 0.476051\n",
      "[494]\ttraining's binary_logloss: 0.475831\n",
      "[495]\ttraining's binary_logloss: 0.475622\n",
      "[496]\ttraining's binary_logloss: 0.475381\n",
      "[497]\ttraining's binary_logloss: 0.475148\n",
      "[498]\ttraining's binary_logloss: 0.474933\n",
      "[499]\ttraining's binary_logloss: 0.474715\n",
      "[500]\ttraining's binary_logloss: 0.474502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614697\n",
      "[2]\ttraining's binary_logloss: 0.613765\n",
      "[3]\ttraining's binary_logloss: 0.612858\n",
      "[4]\ttraining's binary_logloss: 0.611944\n",
      "[5]\ttraining's binary_logloss: 0.611012\n",
      "[6]\ttraining's binary_logloss: 0.610177\n",
      "[7]\ttraining's binary_logloss: 0.609357\n",
      "[8]\ttraining's binary_logloss: 0.608572\n",
      "[9]\ttraining's binary_logloss: 0.607822\n",
      "[10]\ttraining's binary_logloss: 0.607103\n",
      "[11]\ttraining's binary_logloss: 0.606306\n",
      "[12]\ttraining's binary_logloss: 0.605594\n",
      "[13]\ttraining's binary_logloss: 0.604975\n",
      "[14]\ttraining's binary_logloss: 0.604325\n",
      "[15]\ttraining's binary_logloss: 0.603641\n",
      "[16]\ttraining's binary_logloss: 0.602985\n",
      "[17]\ttraining's binary_logloss: 0.602353\n",
      "[18]\ttraining's binary_logloss: 0.601745\n",
      "[19]\ttraining's binary_logloss: 0.601166\n",
      "[20]\ttraining's binary_logloss: 0.600614\n",
      "[21]\ttraining's binary_logloss: 0.60008\n",
      "[22]\ttraining's binary_logloss: 0.599575\n",
      "[23]\ttraining's binary_logloss: 0.599065\n",
      "[24]\ttraining's binary_logloss: 0.598542\n",
      "[25]\ttraining's binary_logloss: 0.598099\n",
      "[26]\ttraining's binary_logloss: 0.597646\n",
      "[27]\ttraining's binary_logloss: 0.597244\n",
      "[28]\ttraining's binary_logloss: 0.596865\n",
      "[29]\ttraining's binary_logloss: 0.596561\n",
      "[30]\ttraining's binary_logloss: 0.596182\n",
      "[31]\ttraining's binary_logloss: 0.595789\n",
      "[32]\ttraining's binary_logloss: 0.595519\n",
      "[33]\ttraining's binary_logloss: 0.595165\n",
      "[34]\ttraining's binary_logloss: 0.594839\n",
      "[35]\ttraining's binary_logloss: 0.594513\n",
      "[36]\ttraining's binary_logloss: 0.59422\n",
      "[37]\ttraining's binary_logloss: 0.593961\n",
      "[38]\ttraining's binary_logloss: 0.593695\n",
      "[39]\ttraining's binary_logloss: 0.593434\n",
      "[40]\ttraining's binary_logloss: 0.593197\n",
      "[41]\ttraining's binary_logloss: 0.592937\n",
      "[42]\ttraining's binary_logloss: 0.592691\n",
      "[43]\ttraining's binary_logloss: 0.592459\n",
      "[44]\ttraining's binary_logloss: 0.592249\n",
      "[45]\ttraining's binary_logloss: 0.592035\n",
      "[46]\ttraining's binary_logloss: 0.591804\n",
      "[47]\ttraining's binary_logloss: 0.591585\n",
      "[48]\ttraining's binary_logloss: 0.591383\n",
      "[49]\ttraining's binary_logloss: 0.591198\n",
      "[50]\ttraining's binary_logloss: 0.591019\n",
      "[51]\ttraining's binary_logloss: 0.590902\n",
      "[52]\ttraining's binary_logloss: 0.590722\n",
      "[53]\ttraining's binary_logloss: 0.59057\n",
      "[54]\ttraining's binary_logloss: 0.590399\n",
      "[55]\ttraining's binary_logloss: 0.590297\n",
      "[56]\ttraining's binary_logloss: 0.590102\n",
      "[57]\ttraining's binary_logloss: 0.589991\n",
      "[58]\ttraining's binary_logloss: 0.589918\n",
      "[59]\ttraining's binary_logloss: 0.589823\n",
      "[60]\ttraining's binary_logloss: 0.589748\n",
      "[61]\ttraining's binary_logloss: 0.58963\n",
      "[62]\ttraining's binary_logloss: 0.589518\n",
      "[63]\ttraining's binary_logloss: 0.589462\n",
      "[64]\ttraining's binary_logloss: 0.589405\n",
      "[65]\ttraining's binary_logloss: 0.589372\n",
      "[66]\ttraining's binary_logloss: 0.589344\n",
      "[67]\ttraining's binary_logloss: 0.589241\n",
      "[68]\ttraining's binary_logloss: 0.589204\n",
      "[69]\ttraining's binary_logloss: 0.589151\n",
      "[70]\ttraining's binary_logloss: 0.589126\n",
      "[71]\ttraining's binary_logloss: 0.589099\n",
      "[72]\ttraining's binary_logloss: 0.58904\n",
      "[73]\ttraining's binary_logloss: 0.588986\n",
      "[74]\ttraining's binary_logloss: 0.588961\n",
      "[75]\ttraining's binary_logloss: 0.58892\n",
      "[76]\ttraining's binary_logloss: 0.588888\n",
      "[77]\ttraining's binary_logloss: 0.588892\n",
      "[78]\ttraining's binary_logloss: 0.588831\n",
      "[79]\ttraining's binary_logloss: 0.588773\n",
      "[80]\ttraining's binary_logloss: 0.588742\n",
      "[81]\ttraining's binary_logloss: 0.588698\n",
      "[82]\ttraining's binary_logloss: 0.58863\n",
      "[83]\ttraining's binary_logloss: 0.588564\n",
      "[84]\ttraining's binary_logloss: 0.588586\n",
      "[85]\ttraining's binary_logloss: 0.588535\n",
      "[86]\ttraining's binary_logloss: 0.588516\n",
      "[87]\ttraining's binary_logloss: 0.588503\n",
      "[88]\ttraining's binary_logloss: 0.58853\n",
      "[89]\ttraining's binary_logloss: 0.588487\n",
      "[90]\ttraining's binary_logloss: 0.588484\n",
      "[91]\ttraining's binary_logloss: 0.588456\n",
      "[92]\ttraining's binary_logloss: 0.588443\n",
      "[93]\ttraining's binary_logloss: 0.58849\n",
      "[94]\ttraining's binary_logloss: 0.588548\n",
      "[95]\ttraining's binary_logloss: 0.588546\n",
      "[96]\ttraining's binary_logloss: 0.58858\n",
      "[97]\ttraining's binary_logloss: 0.588572\n",
      "[98]\ttraining's binary_logloss: 0.588596\n",
      "[99]\ttraining's binary_logloss: 0.588599\n",
      "[100]\ttraining's binary_logloss: 0.588598\n",
      "[101]\ttraining's binary_logloss: 0.588617\n",
      "[102]\ttraining's binary_logloss: 0.588649\n",
      "[103]\ttraining's binary_logloss: 0.588675\n",
      "[104]\ttraining's binary_logloss: 0.588696\n",
      "[105]\ttraining's binary_logloss: 0.588727\n",
      "[106]\ttraining's binary_logloss: 0.588785\n",
      "[107]\ttraining's binary_logloss: 0.588859\n",
      "[108]\ttraining's binary_logloss: 0.588921\n",
      "[109]\ttraining's binary_logloss: 0.588986\n",
      "[110]\ttraining's binary_logloss: 0.589053\n",
      "[111]\ttraining's binary_logloss: 0.589048\n",
      "[112]\ttraining's binary_logloss: 0.589016\n",
      "[113]\ttraining's binary_logloss: 0.589052\n",
      "[114]\ttraining's binary_logloss: 0.589022\n",
      "[115]\ttraining's binary_logloss: 0.589026\n",
      "[116]\ttraining's binary_logloss: 0.589085\n",
      "[117]\ttraining's binary_logloss: 0.589093\n",
      "[118]\ttraining's binary_logloss: 0.589105\n",
      "[119]\ttraining's binary_logloss: 0.589096\n",
      "[120]\ttraining's binary_logloss: 0.589114\n",
      "[121]\ttraining's binary_logloss: 0.589181\n",
      "[122]\ttraining's binary_logloss: 0.589205\n",
      "[123]\ttraining's binary_logloss: 0.589231\n",
      "[124]\ttraining's binary_logloss: 0.589317\n",
      "[125]\ttraining's binary_logloss: 0.589409\n",
      "[126]\ttraining's binary_logloss: 0.58943\n",
      "[127]\ttraining's binary_logloss: 0.589454\n",
      "[128]\ttraining's binary_logloss: 0.589483\n",
      "[129]\ttraining's binary_logloss: 0.589505\n",
      "[130]\ttraining's binary_logloss: 0.589541\n",
      "[131]\ttraining's binary_logloss: 0.58959\n",
      "[132]\ttraining's binary_logloss: 0.589662\n",
      "[133]\ttraining's binary_logloss: 0.589743\n",
      "[134]\ttraining's binary_logloss: 0.589823\n",
      "[135]\ttraining's binary_logloss: 0.589902\n",
      "[136]\ttraining's binary_logloss: 0.589894\n",
      "[137]\ttraining's binary_logloss: 0.589929\n",
      "[138]\ttraining's binary_logloss: 0.589922\n",
      "[139]\ttraining's binary_logloss: 0.589918\n",
      "[140]\ttraining's binary_logloss: 0.589971\n",
      "[141]\ttraining's binary_logloss: 0.589982\n",
      "[142]\ttraining's binary_logloss: 0.589995\n",
      "[143]\ttraining's binary_logloss: 0.590011\n",
      "[144]\ttraining's binary_logloss: 0.590035\n",
      "[145]\ttraining's binary_logloss: 0.590055\n",
      "[146]\ttraining's binary_logloss: 0.590078\n",
      "[147]\ttraining's binary_logloss: 0.590132\n",
      "[148]\ttraining's binary_logloss: 0.590157\n",
      "[149]\ttraining's binary_logloss: 0.590184\n",
      "[150]\ttraining's binary_logloss: 0.590214\n",
      "[151]\ttraining's binary_logloss: 0.590267\n",
      "[152]\ttraining's binary_logloss: 0.590317\n",
      "[153]\ttraining's binary_logloss: 0.590378\n",
      "[154]\ttraining's binary_logloss: 0.590419\n",
      "[155]\ttraining's binary_logloss: 0.590455\n",
      "[156]\ttraining's binary_logloss: 0.590474\n",
      "[157]\ttraining's binary_logloss: 0.590497\n",
      "[158]\ttraining's binary_logloss: 0.590515\n",
      "[159]\ttraining's binary_logloss: 0.59058\n",
      "[160]\ttraining's binary_logloss: 0.590619\n",
      "[161]\ttraining's binary_logloss: 0.590653\n",
      "[162]\ttraining's binary_logloss: 0.590657\n",
      "[163]\ttraining's binary_logloss: 0.590657\n",
      "[164]\ttraining's binary_logloss: 0.590709\n",
      "[165]\ttraining's binary_logloss: 0.590717\n",
      "[166]\ttraining's binary_logloss: 0.590743\n",
      "[167]\ttraining's binary_logloss: 0.590766\n",
      "[168]\ttraining's binary_logloss: 0.5908\n",
      "[169]\ttraining's binary_logloss: 0.590844\n",
      "[170]\ttraining's binary_logloss: 0.590853\n",
      "[171]\ttraining's binary_logloss: 0.590884\n",
      "[172]\ttraining's binary_logloss: 0.590915\n",
      "[173]\ttraining's binary_logloss: 0.590946\n",
      "[174]\ttraining's binary_logloss: 0.590991\n",
      "[175]\ttraining's binary_logloss: 0.591026\n",
      "[176]\ttraining's binary_logloss: 0.591062\n",
      "[177]\ttraining's binary_logloss: 0.591065\n",
      "[178]\ttraining's binary_logloss: 0.591091\n",
      "[179]\ttraining's binary_logloss: 0.591123\n",
      "[180]\ttraining's binary_logloss: 0.591161\n",
      "[181]\ttraining's binary_logloss: 0.591165\n",
      "[182]\ttraining's binary_logloss: 0.591193\n",
      "[183]\ttraining's binary_logloss: 0.591231\n",
      "[184]\ttraining's binary_logloss: 0.591254\n",
      "[185]\ttraining's binary_logloss: 0.59129\n",
      "[186]\ttraining's binary_logloss: 0.591352\n",
      "[187]\ttraining's binary_logloss: 0.591418\n",
      "[188]\ttraining's binary_logloss: 0.591486\n",
      "[189]\ttraining's binary_logloss: 0.59153\n",
      "[190]\ttraining's binary_logloss: 0.591593\n",
      "[191]\ttraining's binary_logloss: 0.591593\n",
      "[192]\ttraining's binary_logloss: 0.591606\n",
      "[193]\ttraining's binary_logloss: 0.591613\n",
      "[194]\ttraining's binary_logloss: 0.591632\n",
      "[195]\ttraining's binary_logloss: 0.591649\n",
      "[196]\ttraining's binary_logloss: 0.591644\n",
      "[197]\ttraining's binary_logloss: 0.591646\n",
      "[198]\ttraining's binary_logloss: 0.591666\n",
      "[199]\ttraining's binary_logloss: 0.591671\n",
      "[200]\ttraining's binary_logloss: 0.591681\n",
      "[201]\ttraining's binary_logloss: 0.591708\n",
      "[202]\ttraining's binary_logloss: 0.591733\n",
      "[203]\ttraining's binary_logloss: 0.591766\n",
      "[204]\ttraining's binary_logloss: 0.591795\n",
      "[205]\ttraining's binary_logloss: 0.591824\n",
      "[206]\ttraining's binary_logloss: 0.591786\n",
      "[207]\ttraining's binary_logloss: 0.591761\n",
      "[208]\ttraining's binary_logloss: 0.591738\n",
      "[209]\ttraining's binary_logloss: 0.591709\n",
      "[210]\ttraining's binary_logloss: 0.591674\n",
      "[211]\ttraining's binary_logloss: 0.591717\n",
      "[212]\ttraining's binary_logloss: 0.591753\n",
      "[213]\ttraining's binary_logloss: 0.59179\n",
      "[214]\ttraining's binary_logloss: 0.591811\n",
      "[215]\ttraining's binary_logloss: 0.591851\n",
      "[216]\ttraining's binary_logloss: 0.591835\n",
      "[217]\ttraining's binary_logloss: 0.591825\n",
      "[218]\ttraining's binary_logloss: 0.591813\n",
      "[219]\ttraining's binary_logloss: 0.591803\n",
      "[220]\ttraining's binary_logloss: 0.591791\n",
      "[221]\ttraining's binary_logloss: 0.591777\n",
      "[222]\ttraining's binary_logloss: 0.59176\n",
      "[223]\ttraining's binary_logloss: 0.591747\n",
      "[224]\ttraining's binary_logloss: 0.591734\n",
      "[225]\ttraining's binary_logloss: 0.591722\n",
      "[226]\ttraining's binary_logloss: 0.591721\n",
      "[227]\ttraining's binary_logloss: 0.591692\n",
      "[228]\ttraining's binary_logloss: 0.591674\n",
      "[229]\ttraining's binary_logloss: 0.591657\n",
      "[230]\ttraining's binary_logloss: 0.591644\n",
      "[231]\ttraining's binary_logloss: 0.591661\n",
      "[232]\ttraining's binary_logloss: 0.591675\n",
      "[233]\ttraining's binary_logloss: 0.59169\n",
      "[234]\ttraining's binary_logloss: 0.591705\n",
      "[235]\ttraining's binary_logloss: 0.591725\n",
      "[236]\ttraining's binary_logloss: 0.591703\n",
      "[237]\ttraining's binary_logloss: 0.591689\n",
      "[238]\ttraining's binary_logloss: 0.591673\n",
      "[239]\ttraining's binary_logloss: 0.591639\n",
      "[240]\ttraining's binary_logloss: 0.591613\n",
      "[241]\ttraining's binary_logloss: 0.591615\n",
      "[242]\ttraining's binary_logloss: 0.591596\n",
      "[243]\ttraining's binary_logloss: 0.591589\n",
      "[244]\ttraining's binary_logloss: 0.59159\n",
      "[245]\ttraining's binary_logloss: 0.591577\n",
      "[246]\ttraining's binary_logloss: 0.591516\n",
      "[247]\ttraining's binary_logloss: 0.59147\n",
      "[248]\ttraining's binary_logloss: 0.591404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[249]\ttraining's binary_logloss: 0.591346\n",
      "[250]\ttraining's binary_logloss: 0.591294\n",
      "[251]\ttraining's binary_logloss: 0.591234\n",
      "[252]\ttraining's binary_logloss: 0.591188\n",
      "[253]\ttraining's binary_logloss: 0.591136\n",
      "[254]\ttraining's binary_logloss: 0.59108\n",
      "[255]\ttraining's binary_logloss: 0.591039\n",
      "[256]\ttraining's binary_logloss: 0.591025\n",
      "[257]\ttraining's binary_logloss: 0.591013\n",
      "[258]\ttraining's binary_logloss: 0.591006\n",
      "[259]\ttraining's binary_logloss: 0.591007\n",
      "[260]\ttraining's binary_logloss: 0.591003\n",
      "[261]\ttraining's binary_logloss: 0.591026\n",
      "[262]\ttraining's binary_logloss: 0.591043\n",
      "[263]\ttraining's binary_logloss: 0.591023\n",
      "[264]\ttraining's binary_logloss: 0.591044\n",
      "[265]\ttraining's binary_logloss: 0.591062\n",
      "[266]\ttraining's binary_logloss: 0.591072\n",
      "[267]\ttraining's binary_logloss: 0.591078\n",
      "[268]\ttraining's binary_logloss: 0.591089\n",
      "[269]\ttraining's binary_logloss: 0.591097\n",
      "[270]\ttraining's binary_logloss: 0.591108\n",
      "[271]\ttraining's binary_logloss: 0.591086\n",
      "[272]\ttraining's binary_logloss: 0.591068\n",
      "[273]\ttraining's binary_logloss: 0.591077\n",
      "[274]\ttraining's binary_logloss: 0.591087\n",
      "[275]\ttraining's binary_logloss: 0.591098\n",
      "[276]\ttraining's binary_logloss: 0.591053\n",
      "[277]\ttraining's binary_logloss: 0.591012\n",
      "[278]\ttraining's binary_logloss: 0.590973\n",
      "[279]\ttraining's binary_logloss: 0.590935\n",
      "[280]\ttraining's binary_logloss: 0.590894\n",
      "[281]\ttraining's binary_logloss: 0.590881\n",
      "[282]\ttraining's binary_logloss: 0.590869\n",
      "[283]\ttraining's binary_logloss: 0.590859\n",
      "[284]\ttraining's binary_logloss: 0.590865\n",
      "[285]\ttraining's binary_logloss: 0.590861\n",
      "[286]\ttraining's binary_logloss: 0.590851\n",
      "[287]\ttraining's binary_logloss: 0.590805\n",
      "[288]\ttraining's binary_logloss: 0.59077\n",
      "[289]\ttraining's binary_logloss: 0.590722\n",
      "[290]\ttraining's binary_logloss: 0.590685\n",
      "[291]\ttraining's binary_logloss: 0.590617\n",
      "[292]\ttraining's binary_logloss: 0.590551\n",
      "[293]\ttraining's binary_logloss: 0.590489\n",
      "[294]\ttraining's binary_logloss: 0.59043\n",
      "[295]\ttraining's binary_logloss: 0.59037\n",
      "[296]\ttraining's binary_logloss: 0.590343\n",
      "[297]\ttraining's binary_logloss: 0.590316\n",
      "[298]\ttraining's binary_logloss: 0.590295\n",
      "[299]\ttraining's binary_logloss: 0.590278\n",
      "[300]\ttraining's binary_logloss: 0.590267\n",
      "[301]\ttraining's binary_logloss: 0.590221\n",
      "[302]\ttraining's binary_logloss: 0.590187\n",
      "[303]\ttraining's binary_logloss: 0.590158\n",
      "[304]\ttraining's binary_logloss: 0.5901\n",
      "[305]\ttraining's binary_logloss: 0.590058\n",
      "[306]\ttraining's binary_logloss: 0.590018\n",
      "[307]\ttraining's binary_logloss: 0.589982\n",
      "[308]\ttraining's binary_logloss: 0.589944\n",
      "[309]\ttraining's binary_logloss: 0.589905\n",
      "[310]\ttraining's binary_logloss: 0.589869\n",
      "[311]\ttraining's binary_logloss: 0.589816\n",
      "[312]\ttraining's binary_logloss: 0.589767\n",
      "[313]\ttraining's binary_logloss: 0.589686\n",
      "[314]\ttraining's binary_logloss: 0.589636\n",
      "[315]\ttraining's binary_logloss: 0.589587\n",
      "[316]\ttraining's binary_logloss: 0.589543\n",
      "[317]\ttraining's binary_logloss: 0.589498\n",
      "[318]\ttraining's binary_logloss: 0.589464\n",
      "[319]\ttraining's binary_logloss: 0.589432\n",
      "[320]\ttraining's binary_logloss: 0.589391\n",
      "[321]\ttraining's binary_logloss: 0.589346\n",
      "[322]\ttraining's binary_logloss: 0.589294\n",
      "[323]\ttraining's binary_logloss: 0.58924\n",
      "[324]\ttraining's binary_logloss: 0.589203\n",
      "[325]\ttraining's binary_logloss: 0.589154\n",
      "[326]\ttraining's binary_logloss: 0.589084\n",
      "[327]\ttraining's binary_logloss: 0.589019\n",
      "[328]\ttraining's binary_logloss: 0.588959\n",
      "[329]\ttraining's binary_logloss: 0.588896\n",
      "[330]\ttraining's binary_logloss: 0.588834\n",
      "[331]\ttraining's binary_logloss: 0.588778\n",
      "[332]\ttraining's binary_logloss: 0.58873\n",
      "[333]\ttraining's binary_logloss: 0.588677\n",
      "[334]\ttraining's binary_logloss: 0.588641\n",
      "[335]\ttraining's binary_logloss: 0.588592\n",
      "[336]\ttraining's binary_logloss: 0.588576\n",
      "[337]\ttraining's binary_logloss: 0.58856\n",
      "[338]\ttraining's binary_logloss: 0.588543\n",
      "[339]\ttraining's binary_logloss: 0.588528\n",
      "[340]\ttraining's binary_logloss: 0.588509\n",
      "[341]\ttraining's binary_logloss: 0.588471\n",
      "[342]\ttraining's binary_logloss: 0.588433\n",
      "[343]\ttraining's binary_logloss: 0.588393\n",
      "[344]\ttraining's binary_logloss: 0.58836\n",
      "[345]\ttraining's binary_logloss: 0.588323\n",
      "[346]\ttraining's binary_logloss: 0.588256\n",
      "[347]\ttraining's binary_logloss: 0.58819\n",
      "[348]\ttraining's binary_logloss: 0.588124\n",
      "[349]\ttraining's binary_logloss: 0.58806\n",
      "[350]\ttraining's binary_logloss: 0.588003\n",
      "[351]\ttraining's binary_logloss: 0.587985\n",
      "[352]\ttraining's binary_logloss: 0.587962\n",
      "[353]\ttraining's binary_logloss: 0.587945\n",
      "[354]\ttraining's binary_logloss: 0.587923\n",
      "[355]\ttraining's binary_logloss: 0.587903\n",
      "[356]\ttraining's binary_logloss: 0.587855\n",
      "[357]\ttraining's binary_logloss: 0.587812\n",
      "[358]\ttraining's binary_logloss: 0.587774\n",
      "[359]\ttraining's binary_logloss: 0.58773\n",
      "[360]\ttraining's binary_logloss: 0.587687\n",
      "[361]\ttraining's binary_logloss: 0.587626\n",
      "[362]\ttraining's binary_logloss: 0.587568\n",
      "[363]\ttraining's binary_logloss: 0.58751\n",
      "[364]\ttraining's binary_logloss: 0.587451\n",
      "[365]\ttraining's binary_logloss: 0.587395\n",
      "[366]\ttraining's binary_logloss: 0.58735\n",
      "[367]\ttraining's binary_logloss: 0.587301\n",
      "[368]\ttraining's binary_logloss: 0.587252\n",
      "[369]\ttraining's binary_logloss: 0.58721\n",
      "[370]\ttraining's binary_logloss: 0.587162\n",
      "[371]\ttraining's binary_logloss: 0.587097\n",
      "[372]\ttraining's binary_logloss: 0.587034\n",
      "[373]\ttraining's binary_logloss: 0.586976\n",
      "[374]\ttraining's binary_logloss: 0.586915\n",
      "[375]\ttraining's binary_logloss: 0.586855\n",
      "[376]\ttraining's binary_logloss: 0.586804\n",
      "[377]\ttraining's binary_logloss: 0.586751\n",
      "[378]\ttraining's binary_logloss: 0.5867\n",
      "[379]\ttraining's binary_logloss: 0.586649\n",
      "[380]\ttraining's binary_logloss: 0.586603\n",
      "[381]\ttraining's binary_logloss: 0.586529\n",
      "[382]\ttraining's binary_logloss: 0.586444\n",
      "[383]\ttraining's binary_logloss: 0.58636\n",
      "[384]\ttraining's binary_logloss: 0.586278\n",
      "[385]\ttraining's binary_logloss: 0.586193\n",
      "[386]\ttraining's binary_logloss: 0.586135\n",
      "[387]\ttraining's binary_logloss: 0.586082\n",
      "[388]\ttraining's binary_logloss: 0.586025\n",
      "[389]\ttraining's binary_logloss: 0.58597\n",
      "[390]\ttraining's binary_logloss: 0.585916\n",
      "[391]\ttraining's binary_logloss: 0.585836\n",
      "[392]\ttraining's binary_logloss: 0.585762\n",
      "[393]\ttraining's binary_logloss: 0.585684\n",
      "[394]\ttraining's binary_logloss: 0.585604\n",
      "[395]\ttraining's binary_logloss: 0.585528\n",
      "[396]\ttraining's binary_logloss: 0.585491\n",
      "[397]\ttraining's binary_logloss: 0.585452\n",
      "[398]\ttraining's binary_logloss: 0.585417\n",
      "[399]\ttraining's binary_logloss: 0.58539\n",
      "[400]\ttraining's binary_logloss: 0.585362\n",
      "[401]\ttraining's binary_logloss: 0.585306\n",
      "[402]\ttraining's binary_logloss: 0.585256\n",
      "[403]\ttraining's binary_logloss: 0.585202\n",
      "[404]\ttraining's binary_logloss: 0.585154\n",
      "[405]\ttraining's binary_logloss: 0.585106\n",
      "[406]\ttraining's binary_logloss: 0.585034\n",
      "[407]\ttraining's binary_logloss: 0.584994\n",
      "[408]\ttraining's binary_logloss: 0.584963\n",
      "[409]\ttraining's binary_logloss: 0.584895\n",
      "[410]\ttraining's binary_logloss: 0.58487\n",
      "[411]\ttraining's binary_logloss: 0.584797\n",
      "[412]\ttraining's binary_logloss: 0.584743\n",
      "[413]\ttraining's binary_logloss: 0.584673\n",
      "[414]\ttraining's binary_logloss: 0.58461\n",
      "[415]\ttraining's binary_logloss: 0.58456\n",
      "[416]\ttraining's binary_logloss: 0.584512\n",
      "[417]\ttraining's binary_logloss: 0.58445\n",
      "[418]\ttraining's binary_logloss: 0.58438\n",
      "[419]\ttraining's binary_logloss: 0.584314\n",
      "[420]\ttraining's binary_logloss: 0.584256\n",
      "[421]\ttraining's binary_logloss: 0.584217\n",
      "[422]\ttraining's binary_logloss: 0.584175\n",
      "[423]\ttraining's binary_logloss: 0.584133\n",
      "[424]\ttraining's binary_logloss: 0.584095\n",
      "[425]\ttraining's binary_logloss: 0.584058\n",
      "[426]\ttraining's binary_logloss: 0.584012\n",
      "[427]\ttraining's binary_logloss: 0.583952\n",
      "[428]\ttraining's binary_logloss: 0.583902\n",
      "[429]\ttraining's binary_logloss: 0.583854\n",
      "[430]\ttraining's binary_logloss: 0.583808\n",
      "[431]\ttraining's binary_logloss: 0.583759\n",
      "[432]\ttraining's binary_logloss: 0.583707\n",
      "[433]\ttraining's binary_logloss: 0.583644\n",
      "[434]\ttraining's binary_logloss: 0.58358\n",
      "[435]\ttraining's binary_logloss: 0.583525\n",
      "[436]\ttraining's binary_logloss: 0.583457\n",
      "[437]\ttraining's binary_logloss: 0.583394\n",
      "[438]\ttraining's binary_logloss: 0.583333\n",
      "[439]\ttraining's binary_logloss: 0.583291\n",
      "[440]\ttraining's binary_logloss: 0.583225\n",
      "[441]\ttraining's binary_logloss: 0.583179\n",
      "[442]\ttraining's binary_logloss: 0.58312\n",
      "[443]\ttraining's binary_logloss: 0.583061\n",
      "[444]\ttraining's binary_logloss: 0.583012\n",
      "[445]\ttraining's binary_logloss: 0.582955\n",
      "[446]\ttraining's binary_logloss: 0.582878\n",
      "[447]\ttraining's binary_logloss: 0.582799\n",
      "[448]\ttraining's binary_logloss: 0.582715\n",
      "[449]\ttraining's binary_logloss: 0.582624\n",
      "[450]\ttraining's binary_logloss: 0.582538\n",
      "[451]\ttraining's binary_logloss: 0.582465\n",
      "[452]\ttraining's binary_logloss: 0.582395\n",
      "[453]\ttraining's binary_logloss: 0.582326\n",
      "[454]\ttraining's binary_logloss: 0.582259\n",
      "[455]\ttraining's binary_logloss: 0.5822\n",
      "[456]\ttraining's binary_logloss: 0.582154\n",
      "[457]\ttraining's binary_logloss: 0.582108\n",
      "[458]\ttraining's binary_logloss: 0.582063\n",
      "[459]\ttraining's binary_logloss: 0.582017\n",
      "[460]\ttraining's binary_logloss: 0.581975\n",
      "[461]\ttraining's binary_logloss: 0.581911\n",
      "[462]\ttraining's binary_logloss: 0.58185\n",
      "[463]\ttraining's binary_logloss: 0.58178\n",
      "[464]\ttraining's binary_logloss: 0.581709\n",
      "[465]\ttraining's binary_logloss: 0.581648\n",
      "[466]\ttraining's binary_logloss: 0.581591\n",
      "[467]\ttraining's binary_logloss: 0.581536\n",
      "[468]\ttraining's binary_logloss: 0.581482\n",
      "[469]\ttraining's binary_logloss: 0.581432\n",
      "[470]\ttraining's binary_logloss: 0.581381\n",
      "[471]\ttraining's binary_logloss: 0.581298\n",
      "[472]\ttraining's binary_logloss: 0.58123\n",
      "[473]\ttraining's binary_logloss: 0.581163\n",
      "[474]\ttraining's binary_logloss: 0.581081\n",
      "[475]\ttraining's binary_logloss: 0.58101\n",
      "[476]\ttraining's binary_logloss: 0.580967\n",
      "[477]\ttraining's binary_logloss: 0.580901\n",
      "[478]\ttraining's binary_logloss: 0.580857\n",
      "[479]\ttraining's binary_logloss: 0.580798\n",
      "[480]\ttraining's binary_logloss: 0.580757\n",
      "[481]\ttraining's binary_logloss: 0.580717\n",
      "[482]\ttraining's binary_logloss: 0.580681\n",
      "[483]\ttraining's binary_logloss: 0.580651\n",
      "[484]\ttraining's binary_logloss: 0.580615\n",
      "[485]\ttraining's binary_logloss: 0.580581\n",
      "[486]\ttraining's binary_logloss: 0.580497\n",
      "[487]\ttraining's binary_logloss: 0.580422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[488]\ttraining's binary_logloss: 0.580336\n",
      "[489]\ttraining's binary_logloss: 0.580254\n",
      "[490]\ttraining's binary_logloss: 0.580174\n",
      "[491]\ttraining's binary_logloss: 0.58007\n",
      "[492]\ttraining's binary_logloss: 0.579986\n",
      "[493]\ttraining's binary_logloss: 0.579901\n",
      "[494]\ttraining's binary_logloss: 0.579803\n",
      "[495]\ttraining's binary_logloss: 0.579721\n",
      "[496]\ttraining's binary_logloss: 0.579657\n",
      "[497]\ttraining's binary_logloss: 0.579601\n",
      "[498]\ttraining's binary_logloss: 0.579528\n",
      "[499]\ttraining's binary_logloss: 0.579455\n",
      "[500]\ttraining's binary_logloss: 0.579384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614399\n",
      "[2]\ttraining's binary_logloss: 0.613184\n",
      "[3]\ttraining's binary_logloss: 0.611976\n",
      "[4]\ttraining's binary_logloss: 0.61075\n",
      "[5]\ttraining's binary_logloss: 0.609543\n",
      "[6]\ttraining's binary_logloss: 0.608394\n",
      "[7]\ttraining's binary_logloss: 0.607259\n",
      "[8]\ttraining's binary_logloss: 0.60618\n",
      "[9]\ttraining's binary_logloss: 0.605143\n",
      "[10]\ttraining's binary_logloss: 0.604154\n",
      "[11]\ttraining's binary_logloss: 0.603194\n",
      "[12]\ttraining's binary_logloss: 0.602335\n",
      "[13]\ttraining's binary_logloss: 0.601475\n",
      "[14]\ttraining's binary_logloss: 0.600682\n",
      "[15]\ttraining's binary_logloss: 0.599855\n",
      "[16]\ttraining's binary_logloss: 0.59903\n",
      "[17]\ttraining's binary_logloss: 0.598234\n",
      "[18]\ttraining's binary_logloss: 0.597455\n",
      "[19]\ttraining's binary_logloss: 0.596694\n",
      "[20]\ttraining's binary_logloss: 0.595965\n",
      "[21]\ttraining's binary_logloss: 0.595294\n",
      "[22]\ttraining's binary_logloss: 0.594649\n",
      "[23]\ttraining's binary_logloss: 0.593992\n",
      "[24]\ttraining's binary_logloss: 0.593347\n",
      "[25]\ttraining's binary_logloss: 0.592785\n",
      "[26]\ttraining's binary_logloss: 0.592158\n",
      "[27]\ttraining's binary_logloss: 0.591544\n",
      "[28]\ttraining's binary_logloss: 0.591004\n",
      "[29]\ttraining's binary_logloss: 0.59046\n",
      "[30]\ttraining's binary_logloss: 0.589919\n",
      "[31]\ttraining's binary_logloss: 0.589367\n",
      "[32]\ttraining's binary_logloss: 0.588899\n",
      "[33]\ttraining's binary_logloss: 0.588382\n",
      "[34]\ttraining's binary_logloss: 0.587855\n",
      "[35]\ttraining's binary_logloss: 0.587352\n",
      "[36]\ttraining's binary_logloss: 0.586912\n",
      "[37]\ttraining's binary_logloss: 0.586517\n",
      "[38]\ttraining's binary_logloss: 0.586102\n",
      "[39]\ttraining's binary_logloss: 0.585696\n",
      "[40]\ttraining's binary_logloss: 0.585307\n",
      "[41]\ttraining's binary_logloss: 0.584936\n",
      "[42]\ttraining's binary_logloss: 0.584539\n",
      "[43]\ttraining's binary_logloss: 0.584161\n",
      "[44]\ttraining's binary_logloss: 0.583853\n",
      "[45]\ttraining's binary_logloss: 0.583507\n",
      "[46]\ttraining's binary_logloss: 0.583158\n",
      "[47]\ttraining's binary_logloss: 0.582835\n",
      "[48]\ttraining's binary_logloss: 0.582518\n",
      "[49]\ttraining's binary_logloss: 0.582193\n",
      "[50]\ttraining's binary_logloss: 0.581899\n",
      "[51]\ttraining's binary_logloss: 0.581636\n",
      "[52]\ttraining's binary_logloss: 0.581338\n",
      "[53]\ttraining's binary_logloss: 0.581149\n",
      "[54]\ttraining's binary_logloss: 0.580904\n",
      "[55]\ttraining's binary_logloss: 0.580681\n",
      "[56]\ttraining's binary_logloss: 0.580383\n",
      "[57]\ttraining's binary_logloss: 0.58016\n",
      "[58]\ttraining's binary_logloss: 0.579981\n",
      "[59]\ttraining's binary_logloss: 0.579776\n",
      "[60]\ttraining's binary_logloss: 0.5796\n",
      "[61]\ttraining's binary_logloss: 0.579393\n",
      "[62]\ttraining's binary_logloss: 0.579173\n",
      "[63]\ttraining's binary_logloss: 0.57901\n",
      "[64]\ttraining's binary_logloss: 0.578815\n",
      "[65]\ttraining's binary_logloss: 0.578662\n",
      "[66]\ttraining's binary_logloss: 0.578519\n",
      "[67]\ttraining's binary_logloss: 0.578353\n",
      "[68]\ttraining's binary_logloss: 0.578218\n",
      "[69]\ttraining's binary_logloss: 0.578044\n",
      "[70]\ttraining's binary_logloss: 0.577895\n",
      "[71]\ttraining's binary_logloss: 0.57776\n",
      "[72]\ttraining's binary_logloss: 0.577598\n",
      "[73]\ttraining's binary_logloss: 0.577435\n",
      "[74]\ttraining's binary_logloss: 0.577273\n",
      "[75]\ttraining's binary_logloss: 0.577132\n",
      "[76]\ttraining's binary_logloss: 0.577046\n",
      "[77]\ttraining's binary_logloss: 0.57692\n",
      "[78]\ttraining's binary_logloss: 0.576786\n",
      "[79]\ttraining's binary_logloss: 0.576658\n",
      "[80]\ttraining's binary_logloss: 0.576554\n",
      "[81]\ttraining's binary_logloss: 0.576464\n",
      "[82]\ttraining's binary_logloss: 0.576332\n",
      "[83]\ttraining's binary_logloss: 0.57624\n",
      "[84]\ttraining's binary_logloss: 0.576161\n",
      "[85]\ttraining's binary_logloss: 0.576086\n",
      "[86]\ttraining's binary_logloss: 0.575981\n",
      "[87]\ttraining's binary_logloss: 0.57587\n",
      "[88]\ttraining's binary_logloss: 0.575817\n",
      "[89]\ttraining's binary_logloss: 0.575704\n",
      "[90]\ttraining's binary_logloss: 0.575609\n",
      "[91]\ttraining's binary_logloss: 0.575538\n",
      "[92]\ttraining's binary_logloss: 0.575463\n",
      "[93]\ttraining's binary_logloss: 0.575396\n",
      "[94]\ttraining's binary_logloss: 0.575345\n",
      "[95]\ttraining's binary_logloss: 0.575318\n",
      "[96]\ttraining's binary_logloss: 0.575265\n",
      "[97]\ttraining's binary_logloss: 0.575181\n",
      "[98]\ttraining's binary_logloss: 0.575117\n",
      "[99]\ttraining's binary_logloss: 0.575032\n",
      "[100]\ttraining's binary_logloss: 0.574953\n",
      "[101]\ttraining's binary_logloss: 0.574877\n",
      "[102]\ttraining's binary_logloss: 0.574815\n",
      "[103]\ttraining's binary_logloss: 0.574736\n",
      "[104]\ttraining's binary_logloss: 0.574675\n",
      "[105]\ttraining's binary_logloss: 0.574583\n",
      "[106]\ttraining's binary_logloss: 0.574537\n",
      "[107]\ttraining's binary_logloss: 0.574517\n",
      "[108]\ttraining's binary_logloss: 0.574473\n",
      "[109]\ttraining's binary_logloss: 0.574448\n",
      "[110]\ttraining's binary_logloss: 0.574414\n",
      "[111]\ttraining's binary_logloss: 0.574316\n",
      "[112]\ttraining's binary_logloss: 0.574206\n",
      "[113]\ttraining's binary_logloss: 0.574143\n",
      "[114]\ttraining's binary_logloss: 0.574042\n",
      "[115]\ttraining's binary_logloss: 0.573934\n",
      "[116]\ttraining's binary_logloss: 0.573896\n",
      "[117]\ttraining's binary_logloss: 0.57382\n",
      "[118]\ttraining's binary_logloss: 0.573752\n",
      "[119]\ttraining's binary_logloss: 0.573671\n",
      "[120]\ttraining's binary_logloss: 0.573614\n",
      "[121]\ttraining's binary_logloss: 0.573626\n",
      "[122]\ttraining's binary_logloss: 0.573629\n",
      "[123]\ttraining's binary_logloss: 0.573638\n",
      "[124]\ttraining's binary_logloss: 0.573594\n",
      "[125]\ttraining's binary_logloss: 0.5736\n",
      "[126]\ttraining's binary_logloss: 0.57355\n",
      "[127]\ttraining's binary_logloss: 0.5735\n",
      "[128]\ttraining's binary_logloss: 0.573452\n",
      "[129]\ttraining's binary_logloss: 0.573393\n",
      "[130]\ttraining's binary_logloss: 0.573353\n",
      "[131]\ttraining's binary_logloss: 0.573291\n",
      "[132]\ttraining's binary_logloss: 0.573285\n",
      "[133]\ttraining's binary_logloss: 0.573276\n",
      "[134]\ttraining's binary_logloss: 0.573263\n",
      "[135]\ttraining's binary_logloss: 0.573261\n",
      "[136]\ttraining's binary_logloss: 0.573244\n",
      "[137]\ttraining's binary_logloss: 0.573202\n",
      "[138]\ttraining's binary_logloss: 0.573165\n",
      "[139]\ttraining's binary_logloss: 0.573099\n",
      "[140]\ttraining's binary_logloss: 0.573058\n",
      "[141]\ttraining's binary_logloss: 0.57301\n",
      "[142]\ttraining's binary_logloss: 0.572964\n",
      "[143]\ttraining's binary_logloss: 0.572934\n",
      "[144]\ttraining's binary_logloss: 0.572905\n",
      "[145]\ttraining's binary_logloss: 0.57287\n",
      "[146]\ttraining's binary_logloss: 0.572821\n",
      "[147]\ttraining's binary_logloss: 0.572776\n",
      "[148]\ttraining's binary_logloss: 0.572741\n",
      "[149]\ttraining's binary_logloss: 0.572691\n",
      "[150]\ttraining's binary_logloss: 0.572649\n",
      "[151]\ttraining's binary_logloss: 0.572643\n",
      "[152]\ttraining's binary_logloss: 0.572597\n",
      "[153]\ttraining's binary_logloss: 0.572575\n",
      "[154]\ttraining's binary_logloss: 0.572534\n",
      "[155]\ttraining's binary_logloss: 0.572506\n",
      "[156]\ttraining's binary_logloss: 0.572451\n",
      "[157]\ttraining's binary_logloss: 0.57239\n",
      "[158]\ttraining's binary_logloss: 0.572382\n",
      "[159]\ttraining's binary_logloss: 0.572352\n",
      "[160]\ttraining's binary_logloss: 0.572319\n",
      "[161]\ttraining's binary_logloss: 0.572272\n",
      "[162]\ttraining's binary_logloss: 0.572192\n",
      "[163]\ttraining's binary_logloss: 0.572115\n",
      "[164]\ttraining's binary_logloss: 0.572111\n",
      "[165]\ttraining's binary_logloss: 0.572051\n",
      "[166]\ttraining's binary_logloss: 0.571969\n",
      "[167]\ttraining's binary_logloss: 0.571882\n",
      "[168]\ttraining's binary_logloss: 0.571793\n",
      "[169]\ttraining's binary_logloss: 0.571747\n",
      "[170]\ttraining's binary_logloss: 0.571664\n",
      "[171]\ttraining's binary_logloss: 0.571632\n",
      "[172]\ttraining's binary_logloss: 0.571585\n",
      "[173]\ttraining's binary_logloss: 0.571544\n",
      "[174]\ttraining's binary_logloss: 0.571516\n",
      "[175]\ttraining's binary_logloss: 0.571477\n",
      "[176]\ttraining's binary_logloss: 0.571426\n",
      "[177]\ttraining's binary_logloss: 0.571352\n",
      "[178]\ttraining's binary_logloss: 0.571302\n",
      "[179]\ttraining's binary_logloss: 0.571242\n",
      "[180]\ttraining's binary_logloss: 0.571181\n",
      "[181]\ttraining's binary_logloss: 0.57112\n",
      "[182]\ttraining's binary_logloss: 0.571051\n",
      "[183]\ttraining's binary_logloss: 0.570971\n",
      "[184]\ttraining's binary_logloss: 0.570901\n",
      "[185]\ttraining's binary_logloss: 0.570837\n",
      "[186]\ttraining's binary_logloss: 0.57083\n",
      "[187]\ttraining's binary_logloss: 0.570789\n",
      "[188]\ttraining's binary_logloss: 0.570775\n",
      "[189]\ttraining's binary_logloss: 0.570734\n",
      "[190]\ttraining's binary_logloss: 0.570689\n",
      "[191]\ttraining's binary_logloss: 0.570628\n",
      "[192]\ttraining's binary_logloss: 0.57056\n",
      "[193]\ttraining's binary_logloss: 0.5705\n",
      "[194]\ttraining's binary_logloss: 0.570439\n",
      "[195]\ttraining's binary_logloss: 0.570388\n",
      "[196]\ttraining's binary_logloss: 0.570332\n",
      "[197]\ttraining's binary_logloss: 0.570292\n",
      "[198]\ttraining's binary_logloss: 0.570251\n",
      "[199]\ttraining's binary_logloss: 0.570217\n",
      "[200]\ttraining's binary_logloss: 0.570145\n",
      "[201]\ttraining's binary_logloss: 0.570111\n",
      "[202]\ttraining's binary_logloss: 0.570083\n",
      "[203]\ttraining's binary_logloss: 0.570047\n",
      "[204]\ttraining's binary_logloss: 0.570017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[205]\ttraining's binary_logloss: 0.569989\n",
      "[206]\ttraining's binary_logloss: 0.569881\n",
      "[207]\ttraining's binary_logloss: 0.569789\n",
      "[208]\ttraining's binary_logloss: 0.569694\n",
      "[209]\ttraining's binary_logloss: 0.5696\n",
      "[210]\ttraining's binary_logloss: 0.569515\n",
      "[211]\ttraining's binary_logloss: 0.569485\n",
      "[212]\ttraining's binary_logloss: 0.569444\n",
      "[213]\ttraining's binary_logloss: 0.569415\n",
      "[214]\ttraining's binary_logloss: 0.569376\n",
      "[215]\ttraining's binary_logloss: 0.569355\n",
      "[216]\ttraining's binary_logloss: 0.569274\n",
      "[217]\ttraining's binary_logloss: 0.569197\n",
      "[218]\ttraining's binary_logloss: 0.569127\n",
      "[219]\ttraining's binary_logloss: 0.569051\n",
      "[220]\ttraining's binary_logloss: 0.568979\n",
      "[221]\ttraining's binary_logloss: 0.568905\n",
      "[222]\ttraining's binary_logloss: 0.568837\n",
      "[223]\ttraining's binary_logloss: 0.568763\n",
      "[224]\ttraining's binary_logloss: 0.568697\n",
      "[225]\ttraining's binary_logloss: 0.568635\n",
      "[226]\ttraining's binary_logloss: 0.568566\n",
      "[227]\ttraining's binary_logloss: 0.568462\n",
      "[228]\ttraining's binary_logloss: 0.568359\n",
      "[229]\ttraining's binary_logloss: 0.56826\n",
      "[230]\ttraining's binary_logloss: 0.568163\n",
      "[231]\ttraining's binary_logloss: 0.568104\n",
      "[232]\ttraining's binary_logloss: 0.568034\n",
      "[233]\ttraining's binary_logloss: 0.567989\n",
      "[234]\ttraining's binary_logloss: 0.567929\n",
      "[235]\ttraining's binary_logloss: 0.567874\n",
      "[236]\ttraining's binary_logloss: 0.567763\n",
      "[237]\ttraining's binary_logloss: 0.567673\n",
      "[238]\ttraining's binary_logloss: 0.567589\n",
      "[239]\ttraining's binary_logloss: 0.567521\n",
      "[240]\ttraining's binary_logloss: 0.567437\n",
      "[241]\ttraining's binary_logloss: 0.56736\n",
      "[242]\ttraining's binary_logloss: 0.567278\n",
      "[243]\ttraining's binary_logloss: 0.567215\n",
      "[244]\ttraining's binary_logloss: 0.567151\n",
      "[245]\ttraining's binary_logloss: 0.56707\n",
      "[246]\ttraining's binary_logloss: 0.56694\n",
      "[247]\ttraining's binary_logloss: 0.566823\n",
      "[248]\ttraining's binary_logloss: 0.566702\n",
      "[249]\ttraining's binary_logloss: 0.566577\n",
      "[250]\ttraining's binary_logloss: 0.566452\n",
      "[251]\ttraining's binary_logloss: 0.566345\n",
      "[252]\ttraining's binary_logloss: 0.566232\n",
      "[253]\ttraining's binary_logloss: 0.566133\n",
      "[254]\ttraining's binary_logloss: 0.566037\n",
      "[255]\ttraining's binary_logloss: 0.565905\n",
      "[256]\ttraining's binary_logloss: 0.565834\n",
      "[257]\ttraining's binary_logloss: 0.565776\n",
      "[258]\ttraining's binary_logloss: 0.565719\n",
      "[259]\ttraining's binary_logloss: 0.565656\n",
      "[260]\ttraining's binary_logloss: 0.565599\n",
      "[261]\ttraining's binary_logloss: 0.565537\n",
      "[262]\ttraining's binary_logloss: 0.565461\n",
      "[263]\ttraining's binary_logloss: 0.565389\n",
      "[264]\ttraining's binary_logloss: 0.565324\n",
      "[265]\ttraining's binary_logloss: 0.565261\n",
      "[266]\ttraining's binary_logloss: 0.565209\n",
      "[267]\ttraining's binary_logloss: 0.565168\n",
      "[268]\ttraining's binary_logloss: 0.565126\n",
      "[269]\ttraining's binary_logloss: 0.565079\n",
      "[270]\ttraining's binary_logloss: 0.565037\n",
      "[271]\ttraining's binary_logloss: 0.564937\n",
      "[272]\ttraining's binary_logloss: 0.564842\n",
      "[273]\ttraining's binary_logloss: 0.564757\n",
      "[274]\ttraining's binary_logloss: 0.56469\n",
      "[275]\ttraining's binary_logloss: 0.564575\n",
      "[276]\ttraining's binary_logloss: 0.564486\n",
      "[277]\ttraining's binary_logloss: 0.564393\n",
      "[278]\ttraining's binary_logloss: 0.564306\n",
      "[279]\ttraining's binary_logloss: 0.564198\n",
      "[280]\ttraining's binary_logloss: 0.564088\n",
      "[281]\ttraining's binary_logloss: 0.564032\n",
      "[282]\ttraining's binary_logloss: 0.563951\n",
      "[283]\ttraining's binary_logloss: 0.563886\n",
      "[284]\ttraining's binary_logloss: 0.563834\n",
      "[285]\ttraining's binary_logloss: 0.563765\n",
      "[286]\ttraining's binary_logloss: 0.563689\n",
      "[287]\ttraining's binary_logloss: 0.563566\n",
      "[288]\ttraining's binary_logloss: 0.563467\n",
      "[289]\ttraining's binary_logloss: 0.563358\n",
      "[290]\ttraining's binary_logloss: 0.563257\n",
      "[291]\ttraining's binary_logloss: 0.563134\n",
      "[292]\ttraining's binary_logloss: 0.563012\n",
      "[293]\ttraining's binary_logloss: 0.562887\n",
      "[294]\ttraining's binary_logloss: 0.562794\n",
      "[295]\ttraining's binary_logloss: 0.562668\n",
      "[296]\ttraining's binary_logloss: 0.562583\n",
      "[297]\ttraining's binary_logloss: 0.562491\n",
      "[298]\ttraining's binary_logloss: 0.5624\n",
      "[299]\ttraining's binary_logloss: 0.562307\n",
      "[300]\ttraining's binary_logloss: 0.562232\n",
      "[301]\ttraining's binary_logloss: 0.562126\n",
      "[302]\ttraining's binary_logloss: 0.562042\n",
      "[303]\ttraining's binary_logloss: 0.561955\n",
      "[304]\ttraining's binary_logloss: 0.56184\n",
      "[305]\ttraining's binary_logloss: 0.561714\n",
      "[306]\ttraining's binary_logloss: 0.561619\n",
      "[307]\ttraining's binary_logloss: 0.561529\n",
      "[308]\ttraining's binary_logloss: 0.561437\n",
      "[309]\ttraining's binary_logloss: 0.561336\n",
      "[310]\ttraining's binary_logloss: 0.56123\n",
      "[311]\ttraining's binary_logloss: 0.561108\n",
      "[312]\ttraining's binary_logloss: 0.561004\n",
      "[313]\ttraining's binary_logloss: 0.560852\n",
      "[314]\ttraining's binary_logloss: 0.56074\n",
      "[315]\ttraining's binary_logloss: 0.560639\n",
      "[316]\ttraining's binary_logloss: 0.560533\n",
      "[317]\ttraining's binary_logloss: 0.560435\n",
      "[318]\ttraining's binary_logloss: 0.560356\n",
      "[319]\ttraining's binary_logloss: 0.560274\n",
      "[320]\ttraining's binary_logloss: 0.560166\n",
      "[321]\ttraining's binary_logloss: 0.560087\n",
      "[322]\ttraining's binary_logloss: 0.559982\n",
      "[323]\ttraining's binary_logloss: 0.559912\n",
      "[324]\ttraining's binary_logloss: 0.559833\n",
      "[325]\ttraining's binary_logloss: 0.559725\n",
      "[326]\ttraining's binary_logloss: 0.559576\n",
      "[327]\ttraining's binary_logloss: 0.559434\n",
      "[328]\ttraining's binary_logloss: 0.559299\n",
      "[329]\ttraining's binary_logloss: 0.559163\n",
      "[330]\ttraining's binary_logloss: 0.55903\n",
      "[331]\ttraining's binary_logloss: 0.55892\n",
      "[332]\ttraining's binary_logloss: 0.558822\n",
      "[333]\ttraining's binary_logloss: 0.558724\n",
      "[334]\ttraining's binary_logloss: 0.558647\n",
      "[335]\ttraining's binary_logloss: 0.558561\n",
      "[336]\ttraining's binary_logloss: 0.558479\n",
      "[337]\ttraining's binary_logloss: 0.558383\n",
      "[338]\ttraining's binary_logloss: 0.558299\n",
      "[339]\ttraining's binary_logloss: 0.558209\n",
      "[340]\ttraining's binary_logloss: 0.55814\n",
      "[341]\ttraining's binary_logloss: 0.558045\n",
      "[342]\ttraining's binary_logloss: 0.557956\n",
      "[343]\ttraining's binary_logloss: 0.557881\n",
      "[344]\ttraining's binary_logloss: 0.557796\n",
      "[345]\ttraining's binary_logloss: 0.557699\n",
      "[346]\ttraining's binary_logloss: 0.557576\n",
      "[347]\ttraining's binary_logloss: 0.557453\n",
      "[348]\ttraining's binary_logloss: 0.557339\n",
      "[349]\ttraining's binary_logloss: 0.557226\n",
      "[350]\ttraining's binary_logloss: 0.557092\n",
      "[351]\ttraining's binary_logloss: 0.55703\n",
      "[352]\ttraining's binary_logloss: 0.55695\n",
      "[353]\ttraining's binary_logloss: 0.556868\n",
      "[354]\ttraining's binary_logloss: 0.556785\n",
      "[355]\ttraining's binary_logloss: 0.556705\n",
      "[356]\ttraining's binary_logloss: 0.556619\n",
      "[357]\ttraining's binary_logloss: 0.556516\n",
      "[358]\ttraining's binary_logloss: 0.55643\n",
      "[359]\ttraining's binary_logloss: 0.556334\n",
      "[360]\ttraining's binary_logloss: 0.55624\n",
      "[361]\ttraining's binary_logloss: 0.556116\n",
      "[362]\ttraining's binary_logloss: 0.556009\n",
      "[363]\ttraining's binary_logloss: 0.555911\n",
      "[364]\ttraining's binary_logloss: 0.555804\n",
      "[365]\ttraining's binary_logloss: 0.555667\n",
      "[366]\ttraining's binary_logloss: 0.555558\n",
      "[367]\ttraining's binary_logloss: 0.555453\n",
      "[368]\ttraining's binary_logloss: 0.555354\n",
      "[369]\ttraining's binary_logloss: 0.555255\n",
      "[370]\ttraining's binary_logloss: 0.555152\n",
      "[371]\ttraining's binary_logloss: 0.555041\n",
      "[372]\ttraining's binary_logloss: 0.554927\n",
      "[373]\ttraining's binary_logloss: 0.554815\n",
      "[374]\ttraining's binary_logloss: 0.554703\n",
      "[375]\ttraining's binary_logloss: 0.554591\n",
      "[376]\ttraining's binary_logloss: 0.554489\n",
      "[377]\ttraining's binary_logloss: 0.55438\n",
      "[378]\ttraining's binary_logloss: 0.554276\n",
      "[379]\ttraining's binary_logloss: 0.554175\n",
      "[380]\ttraining's binary_logloss: 0.554077\n",
      "[381]\ttraining's binary_logloss: 0.553948\n",
      "[382]\ttraining's binary_logloss: 0.553835\n",
      "[383]\ttraining's binary_logloss: 0.553705\n",
      "[384]\ttraining's binary_logloss: 0.553582\n",
      "[385]\ttraining's binary_logloss: 0.553446\n",
      "[386]\ttraining's binary_logloss: 0.553335\n",
      "[387]\ttraining's binary_logloss: 0.553225\n",
      "[388]\ttraining's binary_logloss: 0.553122\n",
      "[389]\ttraining's binary_logloss: 0.553013\n",
      "[390]\ttraining's binary_logloss: 0.552911\n",
      "[391]\ttraining's binary_logloss: 0.552776\n",
      "[392]\ttraining's binary_logloss: 0.552646\n",
      "[393]\ttraining's binary_logloss: 0.552523\n",
      "[394]\ttraining's binary_logloss: 0.552403\n",
      "[395]\ttraining's binary_logloss: 0.552267\n",
      "[396]\ttraining's binary_logloss: 0.552179\n",
      "[397]\ttraining's binary_logloss: 0.552097\n",
      "[398]\ttraining's binary_logloss: 0.552015\n",
      "[399]\ttraining's binary_logloss: 0.551946\n",
      "[400]\ttraining's binary_logloss: 0.551842\n",
      "[401]\ttraining's binary_logloss: 0.551727\n",
      "[402]\ttraining's binary_logloss: 0.551605\n",
      "[403]\ttraining's binary_logloss: 0.551484\n",
      "[404]\ttraining's binary_logloss: 0.551367\n",
      "[405]\ttraining's binary_logloss: 0.551255\n",
      "[406]\ttraining's binary_logloss: 0.551117\n",
      "[407]\ttraining's binary_logloss: 0.551032\n",
      "[408]\ttraining's binary_logloss: 0.550948\n",
      "[409]\ttraining's binary_logloss: 0.550816\n",
      "[410]\ttraining's binary_logloss: 0.550737\n",
      "[411]\ttraining's binary_logloss: 0.550628\n",
      "[412]\ttraining's binary_logloss: 0.550528\n",
      "[413]\ttraining's binary_logloss: 0.550421\n",
      "[414]\ttraining's binary_logloss: 0.550319\n",
      "[415]\ttraining's binary_logloss: 0.550214\n",
      "[416]\ttraining's binary_logloss: 0.550116\n",
      "[417]\ttraining's binary_logloss: 0.549993\n",
      "[418]\ttraining's binary_logloss: 0.549874\n",
      "[419]\ttraining's binary_logloss: 0.549751\n",
      "[420]\ttraining's binary_logloss: 0.549632\n",
      "[421]\ttraining's binary_logloss: 0.54952\n",
      "[422]\ttraining's binary_logloss: 0.549427\n",
      "[423]\ttraining's binary_logloss: 0.54933\n",
      "[424]\ttraining's binary_logloss: 0.549222\n",
      "[425]\ttraining's binary_logloss: 0.549111\n",
      "[426]\ttraining's binary_logloss: 0.548997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[427]\ttraining's binary_logloss: 0.548888\n",
      "[428]\ttraining's binary_logloss: 0.548789\n",
      "[429]\ttraining's binary_logloss: 0.548684\n",
      "[430]\ttraining's binary_logloss: 0.54861\n",
      "[431]\ttraining's binary_logloss: 0.548496\n",
      "[432]\ttraining's binary_logloss: 0.548397\n",
      "[433]\ttraining's binary_logloss: 0.54829\n",
      "[434]\ttraining's binary_logloss: 0.548185\n",
      "[435]\ttraining's binary_logloss: 0.548082\n",
      "[436]\ttraining's binary_logloss: 0.547959\n",
      "[437]\ttraining's binary_logloss: 0.547846\n",
      "[438]\ttraining's binary_logloss: 0.547727\n",
      "[439]\ttraining's binary_logloss: 0.54762\n",
      "[440]\ttraining's binary_logloss: 0.547503\n",
      "[441]\ttraining's binary_logloss: 0.547393\n",
      "[442]\ttraining's binary_logloss: 0.547283\n",
      "[443]\ttraining's binary_logloss: 0.547162\n",
      "[444]\ttraining's binary_logloss: 0.547048\n",
      "[445]\ttraining's binary_logloss: 0.546936\n",
      "[446]\ttraining's binary_logloss: 0.546776\n",
      "[447]\ttraining's binary_logloss: 0.546637\n",
      "[448]\ttraining's binary_logloss: 0.546484\n",
      "[449]\ttraining's binary_logloss: 0.546335\n",
      "[450]\ttraining's binary_logloss: 0.546194\n",
      "[451]\ttraining's binary_logloss: 0.546059\n",
      "[452]\ttraining's binary_logloss: 0.545929\n",
      "[453]\ttraining's binary_logloss: 0.545804\n",
      "[454]\ttraining's binary_logloss: 0.545677\n",
      "[455]\ttraining's binary_logloss: 0.545559\n",
      "[456]\ttraining's binary_logloss: 0.545456\n",
      "[457]\ttraining's binary_logloss: 0.54535\n",
      "[458]\ttraining's binary_logloss: 0.545254\n",
      "[459]\ttraining's binary_logloss: 0.545129\n",
      "[460]\ttraining's binary_logloss: 0.545047\n",
      "[461]\ttraining's binary_logloss: 0.544934\n",
      "[462]\ttraining's binary_logloss: 0.544825\n",
      "[463]\ttraining's binary_logloss: 0.544721\n",
      "[464]\ttraining's binary_logloss: 0.544612\n",
      "[465]\ttraining's binary_logloss: 0.544497\n",
      "[466]\ttraining's binary_logloss: 0.544376\n",
      "[467]\ttraining's binary_logloss: 0.544259\n",
      "[468]\ttraining's binary_logloss: 0.544142\n",
      "[469]\ttraining's binary_logloss: 0.544036\n",
      "[470]\ttraining's binary_logloss: 0.543928\n",
      "[471]\ttraining's binary_logloss: 0.543804\n",
      "[472]\ttraining's binary_logloss: 0.543687\n",
      "[473]\ttraining's binary_logloss: 0.543554\n",
      "[474]\ttraining's binary_logloss: 0.543416\n",
      "[475]\ttraining's binary_logloss: 0.543299\n",
      "[476]\ttraining's binary_logloss: 0.543191\n",
      "[477]\ttraining's binary_logloss: 0.543087\n",
      "[478]\ttraining's binary_logloss: 0.543\n",
      "[479]\ttraining's binary_logloss: 0.542898\n",
      "[480]\ttraining's binary_logloss: 0.542811\n",
      "[481]\ttraining's binary_logloss: 0.542731\n",
      "[482]\ttraining's binary_logloss: 0.542659\n",
      "[483]\ttraining's binary_logloss: 0.542576\n",
      "[484]\ttraining's binary_logloss: 0.542498\n",
      "[485]\ttraining's binary_logloss: 0.54241\n",
      "[486]\ttraining's binary_logloss: 0.542281\n",
      "[487]\ttraining's binary_logloss: 0.542149\n",
      "[488]\ttraining's binary_logloss: 0.542009\n",
      "[489]\ttraining's binary_logloss: 0.541881\n",
      "[490]\ttraining's binary_logloss: 0.541745\n",
      "[491]\ttraining's binary_logloss: 0.54163\n",
      "[492]\ttraining's binary_logloss: 0.541501\n",
      "[493]\ttraining's binary_logloss: 0.541387\n",
      "[494]\ttraining's binary_logloss: 0.541254\n",
      "[495]\ttraining's binary_logloss: 0.541126\n",
      "[496]\ttraining's binary_logloss: 0.540994\n",
      "[497]\ttraining's binary_logloss: 0.540868\n",
      "[498]\ttraining's binary_logloss: 0.540771\n",
      "[499]\ttraining's binary_logloss: 0.540645\n",
      "[500]\ttraining's binary_logloss: 0.540527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614248\n",
      "[2]\ttraining's binary_logloss: 0.612857\n",
      "[3]\ttraining's binary_logloss: 0.611508\n",
      "[4]\ttraining's binary_logloss: 0.61015\n",
      "[5]\ttraining's binary_logloss: 0.608807\n",
      "[6]\ttraining's binary_logloss: 0.607496\n",
      "[7]\ttraining's binary_logloss: 0.606207\n",
      "[8]\ttraining's binary_logloss: 0.60498\n",
      "[9]\ttraining's binary_logloss: 0.603786\n",
      "[10]\ttraining's binary_logloss: 0.602645\n",
      "[11]\ttraining's binary_logloss: 0.60151\n",
      "[12]\ttraining's binary_logloss: 0.600467\n",
      "[13]\ttraining's binary_logloss: 0.599447\n",
      "[14]\ttraining's binary_logloss: 0.598472\n",
      "[15]\ttraining's binary_logloss: 0.597495\n",
      "[16]\ttraining's binary_logloss: 0.596542\n",
      "[17]\ttraining's binary_logloss: 0.595618\n",
      "[18]\ttraining's binary_logloss: 0.594708\n",
      "[19]\ttraining's binary_logloss: 0.593835\n",
      "[20]\ttraining's binary_logloss: 0.592993\n",
      "[21]\ttraining's binary_logloss: 0.592218\n",
      "[22]\ttraining's binary_logloss: 0.591466\n",
      "[23]\ttraining's binary_logloss: 0.590664\n",
      "[24]\ttraining's binary_logloss: 0.58991\n",
      "[25]\ttraining's binary_logloss: 0.589241\n",
      "[26]\ttraining's binary_logloss: 0.588491\n",
      "[27]\ttraining's binary_logloss: 0.58776\n",
      "[28]\ttraining's binary_logloss: 0.587106\n",
      "[29]\ttraining's binary_logloss: 0.586465\n",
      "[30]\ttraining's binary_logloss: 0.58578\n",
      "[31]\ttraining's binary_logloss: 0.58509\n",
      "[32]\ttraining's binary_logloss: 0.584513\n",
      "[33]\ttraining's binary_logloss: 0.583877\n",
      "[34]\ttraining's binary_logloss: 0.583242\n",
      "[35]\ttraining's binary_logloss: 0.582628\n",
      "[36]\ttraining's binary_logloss: 0.58205\n",
      "[37]\ttraining's binary_logloss: 0.581534\n",
      "[38]\ttraining's binary_logloss: 0.581017\n",
      "[39]\ttraining's binary_logloss: 0.580494\n",
      "[40]\ttraining's binary_logloss: 0.579989\n",
      "[41]\ttraining's binary_logloss: 0.579523\n",
      "[42]\ttraining's binary_logloss: 0.579081\n",
      "[43]\ttraining's binary_logloss: 0.578607\n",
      "[44]\ttraining's binary_logloss: 0.578205\n",
      "[45]\ttraining's binary_logloss: 0.57777\n",
      "[46]\ttraining's binary_logloss: 0.577318\n",
      "[47]\ttraining's binary_logloss: 0.576888\n",
      "[48]\ttraining's binary_logloss: 0.576447\n",
      "[49]\ttraining's binary_logloss: 0.576014\n",
      "[50]\ttraining's binary_logloss: 0.575603\n",
      "[51]\ttraining's binary_logloss: 0.57525\n",
      "[52]\ttraining's binary_logloss: 0.57488\n",
      "[53]\ttraining's binary_logloss: 0.574591\n",
      "[54]\ttraining's binary_logloss: 0.574227\n",
      "[55]\ttraining's binary_logloss: 0.573916\n",
      "[56]\ttraining's binary_logloss: 0.573526\n",
      "[57]\ttraining's binary_logloss: 0.573217\n",
      "[58]\ttraining's binary_logloss: 0.572925\n",
      "[59]\ttraining's binary_logloss: 0.572635\n",
      "[60]\ttraining's binary_logloss: 0.572388\n",
      "[61]\ttraining's binary_logloss: 0.572096\n",
      "[62]\ttraining's binary_logloss: 0.571784\n",
      "[63]\ttraining's binary_logloss: 0.571526\n",
      "[64]\ttraining's binary_logloss: 0.571248\n",
      "[65]\ttraining's binary_logloss: 0.571\n",
      "[66]\ttraining's binary_logloss: 0.570751\n",
      "[67]\ttraining's binary_logloss: 0.570493\n",
      "[68]\ttraining's binary_logloss: 0.570246\n",
      "[69]\ttraining's binary_logloss: 0.570035\n",
      "[70]\ttraining's binary_logloss: 0.569761\n",
      "[71]\ttraining's binary_logloss: 0.569502\n",
      "[72]\ttraining's binary_logloss: 0.569233\n",
      "[73]\ttraining's binary_logloss: 0.568978\n",
      "[74]\ttraining's binary_logloss: 0.568736\n",
      "[75]\ttraining's binary_logloss: 0.568485\n",
      "[76]\ttraining's binary_logloss: 0.568323\n",
      "[77]\ttraining's binary_logloss: 0.56813\n",
      "[78]\ttraining's binary_logloss: 0.567914\n",
      "[79]\ttraining's binary_logloss: 0.567695\n",
      "[80]\ttraining's binary_logloss: 0.567485\n",
      "[81]\ttraining's binary_logloss: 0.567299\n",
      "[82]\ttraining's binary_logloss: 0.567066\n",
      "[83]\ttraining's binary_logloss: 0.56689\n",
      "[84]\ttraining's binary_logloss: 0.566729\n",
      "[85]\ttraining's binary_logloss: 0.56656\n",
      "[86]\ttraining's binary_logloss: 0.566361\n",
      "[87]\ttraining's binary_logloss: 0.566153\n",
      "[88]\ttraining's binary_logloss: 0.566015\n",
      "[89]\ttraining's binary_logloss: 0.565801\n",
      "[90]\ttraining's binary_logloss: 0.565628\n",
      "[91]\ttraining's binary_logloss: 0.565474\n",
      "[92]\ttraining's binary_logloss: 0.565318\n",
      "[93]\ttraining's binary_logloss: 0.565172\n",
      "[94]\ttraining's binary_logloss: 0.565048\n",
      "[95]\ttraining's binary_logloss: 0.564942\n",
      "[96]\ttraining's binary_logloss: 0.564837\n",
      "[97]\ttraining's binary_logloss: 0.564672\n",
      "[98]\ttraining's binary_logloss: 0.564546\n",
      "[99]\ttraining's binary_logloss: 0.564387\n",
      "[100]\ttraining's binary_logloss: 0.564232\n",
      "[101]\ttraining's binary_logloss: 0.564059\n",
      "[102]\ttraining's binary_logloss: 0.563893\n",
      "[103]\ttraining's binary_logloss: 0.563724\n",
      "[104]\ttraining's binary_logloss: 0.563578\n",
      "[105]\ttraining's binary_logloss: 0.563401\n",
      "[106]\ttraining's binary_logloss: 0.563259\n",
      "[107]\ttraining's binary_logloss: 0.563144\n",
      "[108]\ttraining's binary_logloss: 0.563026\n",
      "[109]\ttraining's binary_logloss: 0.562915\n",
      "[110]\ttraining's binary_logloss: 0.562814\n",
      "[111]\ttraining's binary_logloss: 0.562633\n",
      "[112]\ttraining's binary_logloss: 0.562445\n",
      "[113]\ttraining's binary_logloss: 0.562286\n",
      "[114]\ttraining's binary_logloss: 0.562103\n",
      "[115]\ttraining's binary_logloss: 0.561918\n",
      "[116]\ttraining's binary_logloss: 0.5618\n",
      "[117]\ttraining's binary_logloss: 0.561662\n",
      "[118]\ttraining's binary_logloss: 0.561516\n",
      "[119]\ttraining's binary_logloss: 0.561367\n",
      "[120]\ttraining's binary_logloss: 0.561251\n",
      "[121]\ttraining's binary_logloss: 0.561176\n",
      "[122]\ttraining's binary_logloss: 0.561088\n",
      "[123]\ttraining's binary_logloss: 0.561009\n",
      "[124]\ttraining's binary_logloss: 0.560933\n",
      "[125]\ttraining's binary_logloss: 0.560865\n",
      "[126]\ttraining's binary_logloss: 0.56072\n",
      "[127]\ttraining's binary_logloss: 0.560588\n",
      "[128]\ttraining's binary_logloss: 0.560455\n",
      "[129]\ttraining's binary_logloss: 0.560334\n",
      "[130]\ttraining's binary_logloss: 0.560226\n",
      "[131]\ttraining's binary_logloss: 0.560097\n",
      "[132]\ttraining's binary_logloss: 0.559969\n",
      "[133]\ttraining's binary_logloss: 0.55988\n",
      "[134]\ttraining's binary_logloss: 0.559785\n",
      "[135]\ttraining's binary_logloss: 0.559703\n",
      "[136]\ttraining's binary_logloss: 0.559587\n",
      "[137]\ttraining's binary_logloss: 0.559477\n",
      "[138]\ttraining's binary_logloss: 0.559357\n",
      "[139]\ttraining's binary_logloss: 0.559238\n",
      "[140]\ttraining's binary_logloss: 0.559132\n",
      "[141]\ttraining's binary_logloss: 0.559015\n",
      "[142]\ttraining's binary_logloss: 0.558901\n",
      "[143]\ttraining's binary_logloss: 0.558793\n",
      "[144]\ttraining's binary_logloss: 0.558703\n",
      "[145]\ttraining's binary_logloss: 0.558571\n",
      "[146]\ttraining's binary_logloss: 0.558454\n",
      "[147]\ttraining's binary_logloss: 0.55834\n",
      "[148]\ttraining's binary_logloss: 0.558226\n",
      "[149]\ttraining's binary_logloss: 0.558116\n",
      "[150]\ttraining's binary_logloss: 0.558014\n",
      "[151]\ttraining's binary_logloss: 0.557918\n",
      "[152]\ttraining's binary_logloss: 0.557813\n",
      "[153]\ttraining's binary_logloss: 0.557743\n",
      "[154]\ttraining's binary_logloss: 0.557615\n",
      "[155]\ttraining's binary_logloss: 0.55752\n",
      "[156]\ttraining's binary_logloss: 0.557374\n",
      "[157]\ttraining's binary_logloss: 0.557239\n",
      "[158]\ttraining's binary_logloss: 0.557152\n",
      "[159]\ttraining's binary_logloss: 0.557048\n",
      "[160]\ttraining's binary_logloss: 0.556947\n",
      "[161]\ttraining's binary_logloss: 0.556835\n",
      "[162]\ttraining's binary_logloss: 0.556688\n",
      "[163]\ttraining's binary_logloss: 0.556542\n",
      "[164]\ttraining's binary_logloss: 0.556472\n",
      "[165]\ttraining's binary_logloss: 0.556363\n",
      "[166]\ttraining's binary_logloss: 0.556217\n",
      "[167]\ttraining's binary_logloss: 0.556066\n",
      "[168]\ttraining's binary_logloss: 0.555891\n",
      "[169]\ttraining's binary_logloss: 0.555781\n",
      "[170]\ttraining's binary_logloss: 0.555632\n",
      "[171]\ttraining's binary_logloss: 0.555528\n",
      "[172]\ttraining's binary_logloss: 0.555408\n",
      "[173]\ttraining's binary_logloss: 0.555302\n",
      "[174]\ttraining's binary_logloss: 0.555202\n",
      "[175]\ttraining's binary_logloss: 0.555084\n",
      "[176]\ttraining's binary_logloss: 0.554963\n",
      "[177]\ttraining's binary_logloss: 0.554833\n",
      "[178]\ttraining's binary_logloss: 0.554716\n",
      "[179]\ttraining's binary_logloss: 0.554602\n",
      "[180]\ttraining's binary_logloss: 0.554491\n",
      "[181]\ttraining's binary_logloss: 0.554363\n",
      "[182]\ttraining's binary_logloss: 0.554246\n",
      "[183]\ttraining's binary_logloss: 0.554127\n",
      "[184]\ttraining's binary_logloss: 0.553968\n",
      "[185]\ttraining's binary_logloss: 0.553849\n",
      "[186]\ttraining's binary_logloss: 0.553762\n",
      "[187]\ttraining's binary_logloss: 0.553654\n",
      "[188]\ttraining's binary_logloss: 0.553586\n",
      "[189]\ttraining's binary_logloss: 0.553469\n",
      "[190]\ttraining's binary_logloss: 0.553374\n",
      "[191]\ttraining's binary_logloss: 0.553249\n",
      "[192]\ttraining's binary_logloss: 0.553106\n",
      "[193]\ttraining's binary_logloss: 0.552987\n",
      "[194]\ttraining's binary_logloss: 0.552851\n",
      "[195]\ttraining's binary_logloss: 0.552708\n",
      "[196]\ttraining's binary_logloss: 0.552592\n",
      "[197]\ttraining's binary_logloss: 0.55248\n",
      "[198]\ttraining's binary_logloss: 0.552368\n",
      "[199]\ttraining's binary_logloss: 0.552254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's binary_logloss: 0.552129\n",
      "[201]\ttraining's binary_logloss: 0.55205\n",
      "[202]\ttraining's binary_logloss: 0.551933\n",
      "[203]\ttraining's binary_logloss: 0.551822\n",
      "[204]\ttraining's binary_logloss: 0.551735\n",
      "[205]\ttraining's binary_logloss: 0.55163\n",
      "[206]\ttraining's binary_logloss: 0.551465\n",
      "[207]\ttraining's binary_logloss: 0.551316\n",
      "[208]\ttraining's binary_logloss: 0.551179\n",
      "[209]\ttraining's binary_logloss: 0.551036\n",
      "[210]\ttraining's binary_logloss: 0.550895\n",
      "[211]\ttraining's binary_logloss: 0.55079\n",
      "[212]\ttraining's binary_logloss: 0.550687\n",
      "[213]\ttraining's binary_logloss: 0.550573\n",
      "[214]\ttraining's binary_logloss: 0.550482\n",
      "[215]\ttraining's binary_logloss: 0.550397\n",
      "[216]\ttraining's binary_logloss: 0.550253\n",
      "[217]\ttraining's binary_logloss: 0.550103\n",
      "[218]\ttraining's binary_logloss: 0.549965\n",
      "[219]\ttraining's binary_logloss: 0.549822\n",
      "[220]\ttraining's binary_logloss: 0.549693\n",
      "[221]\ttraining's binary_logloss: 0.549535\n",
      "[222]\ttraining's binary_logloss: 0.549395\n",
      "[223]\ttraining's binary_logloss: 0.549254\n",
      "[224]\ttraining's binary_logloss: 0.549112\n",
      "[225]\ttraining's binary_logloss: 0.548979\n",
      "[226]\ttraining's binary_logloss: 0.548821\n",
      "[227]\ttraining's binary_logloss: 0.548641\n",
      "[228]\ttraining's binary_logloss: 0.548472\n",
      "[229]\ttraining's binary_logloss: 0.548301\n",
      "[230]\ttraining's binary_logloss: 0.548142\n",
      "[231]\ttraining's binary_logloss: 0.548029\n",
      "[232]\ttraining's binary_logloss: 0.547914\n",
      "[233]\ttraining's binary_logloss: 0.54781\n",
      "[234]\ttraining's binary_logloss: 0.54771\n",
      "[235]\ttraining's binary_logloss: 0.547597\n",
      "[236]\ttraining's binary_logloss: 0.547422\n",
      "[237]\ttraining's binary_logloss: 0.547286\n",
      "[238]\ttraining's binary_logloss: 0.547162\n",
      "[239]\ttraining's binary_logloss: 0.547042\n",
      "[240]\ttraining's binary_logloss: 0.546917\n",
      "[241]\ttraining's binary_logloss: 0.546785\n",
      "[242]\ttraining's binary_logloss: 0.54663\n",
      "[243]\ttraining's binary_logloss: 0.546506\n",
      "[244]\ttraining's binary_logloss: 0.546394\n",
      "[245]\ttraining's binary_logloss: 0.546256\n",
      "[246]\ttraining's binary_logloss: 0.546055\n",
      "[247]\ttraining's binary_logloss: 0.545863\n",
      "[248]\ttraining's binary_logloss: 0.545671\n",
      "[249]\ttraining's binary_logloss: 0.545484\n",
      "[250]\ttraining's binary_logloss: 0.545309\n",
      "[251]\ttraining's binary_logloss: 0.545147\n",
      "[252]\ttraining's binary_logloss: 0.544989\n",
      "[253]\ttraining's binary_logloss: 0.544852\n",
      "[254]\ttraining's binary_logloss: 0.544715\n",
      "[255]\ttraining's binary_logloss: 0.544523\n",
      "[256]\ttraining's binary_logloss: 0.544396\n",
      "[257]\ttraining's binary_logloss: 0.544277\n",
      "[258]\ttraining's binary_logloss: 0.544159\n",
      "[259]\ttraining's binary_logloss: 0.544039\n",
      "[260]\ttraining's binary_logloss: 0.543921\n",
      "[261]\ttraining's binary_logloss: 0.543796\n",
      "[262]\ttraining's binary_logloss: 0.543656\n",
      "[263]\ttraining's binary_logloss: 0.543519\n",
      "[264]\ttraining's binary_logloss: 0.543376\n",
      "[265]\ttraining's binary_logloss: 0.543252\n",
      "[266]\ttraining's binary_logloss: 0.543118\n",
      "[267]\ttraining's binary_logloss: 0.543032\n",
      "[268]\ttraining's binary_logloss: 0.542912\n",
      "[269]\ttraining's binary_logloss: 0.542809\n",
      "[270]\ttraining's binary_logloss: 0.542692\n",
      "[271]\ttraining's binary_logloss: 0.542562\n",
      "[272]\ttraining's binary_logloss: 0.542436\n",
      "[273]\ttraining's binary_logloss: 0.54234\n",
      "[274]\ttraining's binary_logloss: 0.542234\n",
      "[275]\ttraining's binary_logloss: 0.542057\n",
      "[276]\ttraining's binary_logloss: 0.541915\n",
      "[277]\ttraining's binary_logloss: 0.541773\n",
      "[278]\ttraining's binary_logloss: 0.541643\n",
      "[279]\ttraining's binary_logloss: 0.541506\n",
      "[280]\ttraining's binary_logloss: 0.541358\n",
      "[281]\ttraining's binary_logloss: 0.541241\n",
      "[282]\ttraining's binary_logloss: 0.541104\n",
      "[283]\ttraining's binary_logloss: 0.540986\n",
      "[284]\ttraining's binary_logloss: 0.540876\n",
      "[285]\ttraining's binary_logloss: 0.540762\n",
      "[286]\ttraining's binary_logloss: 0.540623\n",
      "[287]\ttraining's binary_logloss: 0.540435\n",
      "[288]\ttraining's binary_logloss: 0.540266\n",
      "[289]\ttraining's binary_logloss: 0.54009\n",
      "[290]\ttraining's binary_logloss: 0.539922\n",
      "[291]\ttraining's binary_logloss: 0.539743\n",
      "[292]\ttraining's binary_logloss: 0.539566\n",
      "[293]\ttraining's binary_logloss: 0.539391\n",
      "[294]\ttraining's binary_logloss: 0.53923\n",
      "[295]\ttraining's binary_logloss: 0.53905\n",
      "[296]\ttraining's binary_logloss: 0.538901\n",
      "[297]\ttraining's binary_logloss: 0.538751\n",
      "[298]\ttraining's binary_logloss: 0.538596\n",
      "[299]\ttraining's binary_logloss: 0.538459\n",
      "[300]\ttraining's binary_logloss: 0.538327\n",
      "[301]\ttraining's binary_logloss: 0.538179\n",
      "[302]\ttraining's binary_logloss: 0.538048\n",
      "[303]\ttraining's binary_logloss: 0.537906\n",
      "[304]\ttraining's binary_logloss: 0.537739\n",
      "[305]\ttraining's binary_logloss: 0.537565\n",
      "[306]\ttraining's binary_logloss: 0.537399\n",
      "[307]\ttraining's binary_logloss: 0.537257\n",
      "[308]\ttraining's binary_logloss: 0.537097\n",
      "[309]\ttraining's binary_logloss: 0.536938\n",
      "[310]\ttraining's binary_logloss: 0.536752\n",
      "[311]\ttraining's binary_logloss: 0.536589\n",
      "[312]\ttraining's binary_logloss: 0.536428\n",
      "[313]\ttraining's binary_logloss: 0.536224\n",
      "[314]\ttraining's binary_logloss: 0.536064\n",
      "[315]\ttraining's binary_logloss: 0.535902\n",
      "[316]\ttraining's binary_logloss: 0.535732\n",
      "[317]\ttraining's binary_logloss: 0.53558\n",
      "[318]\ttraining's binary_logloss: 0.535456\n",
      "[319]\ttraining's binary_logloss: 0.535309\n",
      "[320]\ttraining's binary_logloss: 0.535162\n",
      "[321]\ttraining's binary_logloss: 0.535051\n",
      "[322]\ttraining's binary_logloss: 0.534891\n",
      "[323]\ttraining's binary_logloss: 0.534733\n",
      "[324]\ttraining's binary_logloss: 0.534608\n",
      "[325]\ttraining's binary_logloss: 0.534458\n",
      "[326]\ttraining's binary_logloss: 0.534261\n",
      "[327]\ttraining's binary_logloss: 0.534058\n",
      "[328]\ttraining's binary_logloss: 0.533862\n",
      "[329]\ttraining's binary_logloss: 0.533671\n",
      "[330]\ttraining's binary_logloss: 0.533482\n",
      "[331]\ttraining's binary_logloss: 0.533333\n",
      "[332]\ttraining's binary_logloss: 0.53319\n",
      "[333]\ttraining's binary_logloss: 0.533042\n",
      "[334]\ttraining's binary_logloss: 0.532893\n",
      "[335]\ttraining's binary_logloss: 0.532768\n",
      "[336]\ttraining's binary_logloss: 0.532669\n",
      "[337]\ttraining's binary_logloss: 0.532513\n",
      "[338]\ttraining's binary_logloss: 0.532373\n",
      "[339]\ttraining's binary_logloss: 0.532224\n",
      "[340]\ttraining's binary_logloss: 0.532093\n",
      "[341]\ttraining's binary_logloss: 0.531953\n",
      "[342]\ttraining's binary_logloss: 0.531841\n",
      "[343]\ttraining's binary_logloss: 0.531723\n",
      "[344]\ttraining's binary_logloss: 0.531594\n",
      "[345]\ttraining's binary_logloss: 0.53147\n",
      "[346]\ttraining's binary_logloss: 0.531278\n",
      "[347]\ttraining's binary_logloss: 0.531108\n",
      "[348]\ttraining's binary_logloss: 0.530924\n",
      "[349]\ttraining's binary_logloss: 0.530761\n",
      "[350]\ttraining's binary_logloss: 0.530596\n",
      "[351]\ttraining's binary_logloss: 0.530483\n",
      "[352]\ttraining's binary_logloss: 0.530353\n",
      "[353]\ttraining's binary_logloss: 0.530212\n",
      "[354]\ttraining's binary_logloss: 0.530086\n",
      "[355]\ttraining's binary_logloss: 0.529975\n",
      "[356]\ttraining's binary_logloss: 0.529841\n",
      "[357]\ttraining's binary_logloss: 0.529685\n",
      "[358]\ttraining's binary_logloss: 0.52952\n",
      "[359]\ttraining's binary_logloss: 0.529365\n",
      "[360]\ttraining's binary_logloss: 0.529223\n",
      "[361]\ttraining's binary_logloss: 0.529057\n",
      "[362]\ttraining's binary_logloss: 0.528896\n",
      "[363]\ttraining's binary_logloss: 0.528717\n",
      "[364]\ttraining's binary_logloss: 0.528567\n",
      "[365]\ttraining's binary_logloss: 0.528379\n",
      "[366]\ttraining's binary_logloss: 0.528213\n",
      "[367]\ttraining's binary_logloss: 0.528066\n",
      "[368]\ttraining's binary_logloss: 0.527906\n",
      "[369]\ttraining's binary_logloss: 0.527739\n",
      "[370]\ttraining's binary_logloss: 0.527594\n",
      "[371]\ttraining's binary_logloss: 0.52742\n",
      "[372]\ttraining's binary_logloss: 0.527233\n",
      "[373]\ttraining's binary_logloss: 0.527065\n",
      "[374]\ttraining's binary_logloss: 0.526916\n",
      "[375]\ttraining's binary_logloss: 0.526739\n",
      "[376]\ttraining's binary_logloss: 0.526594\n",
      "[377]\ttraining's binary_logloss: 0.526428\n",
      "[378]\ttraining's binary_logloss: 0.526273\n",
      "[379]\ttraining's binary_logloss: 0.526131\n",
      "[380]\ttraining's binary_logloss: 0.525975\n",
      "[381]\ttraining's binary_logloss: 0.525786\n",
      "[382]\ttraining's binary_logloss: 0.525629\n",
      "[383]\ttraining's binary_logloss: 0.525475\n",
      "[384]\ttraining's binary_logloss: 0.525319\n",
      "[385]\ttraining's binary_logloss: 0.525164\n",
      "[386]\ttraining's binary_logloss: 0.52499\n",
      "[387]\ttraining's binary_logloss: 0.524827\n",
      "[388]\ttraining's binary_logloss: 0.524665\n",
      "[389]\ttraining's binary_logloss: 0.524475\n",
      "[390]\ttraining's binary_logloss: 0.524315\n",
      "[391]\ttraining's binary_logloss: 0.52413\n",
      "[392]\ttraining's binary_logloss: 0.523942\n",
      "[393]\ttraining's binary_logloss: 0.523771\n",
      "[394]\ttraining's binary_logloss: 0.523592\n",
      "[395]\ttraining's binary_logloss: 0.523438\n",
      "[396]\ttraining's binary_logloss: 0.52331\n",
      "[397]\ttraining's binary_logloss: 0.523186\n",
      "[398]\ttraining's binary_logloss: 0.523051\n",
      "[399]\ttraining's binary_logloss: 0.52294\n",
      "[400]\ttraining's binary_logloss: 0.522815\n",
      "[401]\ttraining's binary_logloss: 0.522646\n",
      "[402]\ttraining's binary_logloss: 0.522477\n",
      "[403]\ttraining's binary_logloss: 0.522308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[404]\ttraining's binary_logloss: 0.522148\n",
      "[405]\ttraining's binary_logloss: 0.521996\n",
      "[406]\ttraining's binary_logloss: 0.521864\n",
      "[407]\ttraining's binary_logloss: 0.521735\n",
      "[408]\ttraining's binary_logloss: 0.521609\n",
      "[409]\ttraining's binary_logloss: 0.521472\n",
      "[410]\ttraining's binary_logloss: 0.521348\n",
      "[411]\ttraining's binary_logloss: 0.521214\n",
      "[412]\ttraining's binary_logloss: 0.521084\n",
      "[413]\ttraining's binary_logloss: 0.520942\n",
      "[414]\ttraining's binary_logloss: 0.520797\n",
      "[415]\ttraining's binary_logloss: 0.520659\n",
      "[416]\ttraining's binary_logloss: 0.520504\n",
      "[417]\ttraining's binary_logloss: 0.520336\n",
      "[418]\ttraining's binary_logloss: 0.520159\n",
      "[419]\ttraining's binary_logloss: 0.520003\n",
      "[420]\ttraining's binary_logloss: 0.519839\n",
      "[421]\ttraining's binary_logloss: 0.519697\n",
      "[422]\ttraining's binary_logloss: 0.519554\n",
      "[423]\ttraining's binary_logloss: 0.519387\n",
      "[424]\ttraining's binary_logloss: 0.51924\n",
      "[425]\ttraining's binary_logloss: 0.51909\n",
      "[426]\ttraining's binary_logloss: 0.51893\n",
      "[427]\ttraining's binary_logloss: 0.518776\n",
      "[428]\ttraining's binary_logloss: 0.518635\n",
      "[429]\ttraining's binary_logloss: 0.518487\n",
      "[430]\ttraining's binary_logloss: 0.518376\n",
      "[431]\ttraining's binary_logloss: 0.518223\n",
      "[432]\ttraining's binary_logloss: 0.518086\n",
      "[433]\ttraining's binary_logloss: 0.517942\n",
      "[434]\ttraining's binary_logloss: 0.517795\n",
      "[435]\ttraining's binary_logloss: 0.517651\n",
      "[436]\ttraining's binary_logloss: 0.517511\n",
      "[437]\ttraining's binary_logloss: 0.517355\n",
      "[438]\ttraining's binary_logloss: 0.517227\n",
      "[439]\ttraining's binary_logloss: 0.517056\n",
      "[440]\ttraining's binary_logloss: 0.51689\n",
      "[441]\ttraining's binary_logloss: 0.516702\n",
      "[442]\ttraining's binary_logloss: 0.516535\n",
      "[443]\ttraining's binary_logloss: 0.516389\n",
      "[444]\ttraining's binary_logloss: 0.516206\n",
      "[445]\ttraining's binary_logloss: 0.51606\n",
      "[446]\ttraining's binary_logloss: 0.515871\n",
      "[447]\ttraining's binary_logloss: 0.51568\n",
      "[448]\ttraining's binary_logloss: 0.515502\n",
      "[449]\ttraining's binary_logloss: 0.515318\n",
      "[450]\ttraining's binary_logloss: 0.515136\n",
      "[451]\ttraining's binary_logloss: 0.514927\n",
      "[452]\ttraining's binary_logloss: 0.51474\n",
      "[453]\ttraining's binary_logloss: 0.514543\n",
      "[454]\ttraining's binary_logloss: 0.51435\n",
      "[455]\ttraining's binary_logloss: 0.51417\n",
      "[456]\ttraining's binary_logloss: 0.513975\n",
      "[457]\ttraining's binary_logloss: 0.513788\n",
      "[458]\ttraining's binary_logloss: 0.513628\n",
      "[459]\ttraining's binary_logloss: 0.513497\n",
      "[460]\ttraining's binary_logloss: 0.513317\n",
      "[461]\ttraining's binary_logloss: 0.513125\n",
      "[462]\ttraining's binary_logloss: 0.512955\n",
      "[463]\ttraining's binary_logloss: 0.512779\n",
      "[464]\ttraining's binary_logloss: 0.512618\n",
      "[465]\ttraining's binary_logloss: 0.512446\n",
      "[466]\ttraining's binary_logloss: 0.512278\n",
      "[467]\ttraining's binary_logloss: 0.5121\n",
      "[468]\ttraining's binary_logloss: 0.51192\n",
      "[469]\ttraining's binary_logloss: 0.511738\n",
      "[470]\ttraining's binary_logloss: 0.511573\n",
      "[471]\ttraining's binary_logloss: 0.511398\n",
      "[472]\ttraining's binary_logloss: 0.511233\n",
      "[473]\ttraining's binary_logloss: 0.51107\n",
      "[474]\ttraining's binary_logloss: 0.510916\n",
      "[475]\ttraining's binary_logloss: 0.510771\n",
      "[476]\ttraining's binary_logloss: 0.510625\n",
      "[477]\ttraining's binary_logloss: 0.510454\n",
      "[478]\ttraining's binary_logloss: 0.510303\n",
      "[479]\ttraining's binary_logloss: 0.510158\n",
      "[480]\ttraining's binary_logloss: 0.51\n",
      "[481]\ttraining's binary_logloss: 0.509874\n",
      "[482]\ttraining's binary_logloss: 0.509741\n",
      "[483]\ttraining's binary_logloss: 0.509596\n",
      "[484]\ttraining's binary_logloss: 0.509459\n",
      "[485]\ttraining's binary_logloss: 0.509334\n",
      "[486]\ttraining's binary_logloss: 0.509139\n",
      "[487]\ttraining's binary_logloss: 0.508967\n",
      "[488]\ttraining's binary_logloss: 0.508773\n",
      "[489]\ttraining's binary_logloss: 0.508589\n",
      "[490]\ttraining's binary_logloss: 0.508398\n",
      "[491]\ttraining's binary_logloss: 0.508227\n",
      "[492]\ttraining's binary_logloss: 0.508052\n",
      "[493]\ttraining's binary_logloss: 0.50788\n",
      "[494]\ttraining's binary_logloss: 0.507706\n",
      "[495]\ttraining's binary_logloss: 0.507533\n",
      "[496]\ttraining's binary_logloss: 0.507397\n",
      "[497]\ttraining's binary_logloss: 0.507247\n",
      "[498]\ttraining's binary_logloss: 0.507092\n",
      "[499]\ttraining's binary_logloss: 0.506917\n",
      "[500]\ttraining's binary_logloss: 0.506773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614122\n",
      "[2]\ttraining's binary_logloss: 0.612598\n",
      "[3]\ttraining's binary_logloss: 0.61113\n",
      "[4]\ttraining's binary_logloss: 0.609643\n",
      "[5]\ttraining's binary_logloss: 0.608182\n",
      "[6]\ttraining's binary_logloss: 0.606746\n",
      "[7]\ttraining's binary_logloss: 0.605329\n",
      "[8]\ttraining's binary_logloss: 0.60399\n",
      "[9]\ttraining's binary_logloss: 0.60269\n",
      "[10]\ttraining's binary_logloss: 0.601425\n",
      "[11]\ttraining's binary_logloss: 0.600203\n",
      "[12]\ttraining's binary_logloss: 0.599047\n",
      "[13]\ttraining's binary_logloss: 0.597918\n",
      "[14]\ttraining's binary_logloss: 0.596859\n",
      "[15]\ttraining's binary_logloss: 0.595756\n",
      "[16]\ttraining's binary_logloss: 0.594676\n",
      "[17]\ttraining's binary_logloss: 0.593651\n",
      "[18]\ttraining's binary_logloss: 0.592633\n",
      "[19]\ttraining's binary_logloss: 0.59166\n",
      "[20]\ttraining's binary_logloss: 0.590716\n",
      "[21]\ttraining's binary_logloss: 0.589823\n",
      "[22]\ttraining's binary_logloss: 0.588967\n",
      "[23]\ttraining's binary_logloss: 0.588058\n",
      "[24]\ttraining's binary_logloss: 0.58719\n",
      "[25]\ttraining's binary_logloss: 0.586419\n",
      "[26]\ttraining's binary_logloss: 0.585572\n",
      "[27]\ttraining's binary_logloss: 0.584752\n",
      "[28]\ttraining's binary_logloss: 0.584003\n",
      "[29]\ttraining's binary_logloss: 0.583264\n",
      "[30]\ttraining's binary_logloss: 0.582506\n",
      "[31]\ttraining's binary_logloss: 0.581732\n",
      "[32]\ttraining's binary_logloss: 0.581046\n",
      "[33]\ttraining's binary_logloss: 0.58033\n",
      "[34]\ttraining's binary_logloss: 0.57959\n",
      "[35]\ttraining's binary_logloss: 0.578876\n",
      "[36]\ttraining's binary_logloss: 0.578185\n",
      "[37]\ttraining's binary_logloss: 0.577572\n",
      "[38]\ttraining's binary_logloss: 0.576936\n",
      "[39]\ttraining's binary_logloss: 0.576315\n",
      "[40]\ttraining's binary_logloss: 0.5757\n",
      "[41]\ttraining's binary_logloss: 0.575104\n",
      "[42]\ttraining's binary_logloss: 0.574563\n",
      "[43]\ttraining's binary_logloss: 0.573998\n",
      "[44]\ttraining's binary_logloss: 0.573467\n",
      "[45]\ttraining's binary_logloss: 0.572971\n",
      "[46]\ttraining's binary_logloss: 0.572392\n",
      "[47]\ttraining's binary_logloss: 0.571888\n",
      "[48]\ttraining's binary_logloss: 0.571346\n",
      "[49]\ttraining's binary_logloss: 0.57079\n",
      "[50]\ttraining's binary_logloss: 0.570248\n",
      "[51]\ttraining's binary_logloss: 0.569785\n",
      "[52]\ttraining's binary_logloss: 0.569351\n",
      "[53]\ttraining's binary_logloss: 0.568944\n",
      "[54]\ttraining's binary_logloss: 0.568454\n",
      "[55]\ttraining's binary_logloss: 0.568058\n",
      "[56]\ttraining's binary_logloss: 0.56759\n",
      "[57]\ttraining's binary_logloss: 0.567196\n",
      "[58]\ttraining's binary_logloss: 0.566831\n",
      "[59]\ttraining's binary_logloss: 0.566464\n",
      "[60]\ttraining's binary_logloss: 0.566128\n",
      "[61]\ttraining's binary_logloss: 0.565749\n",
      "[62]\ttraining's binary_logloss: 0.56537\n",
      "[63]\ttraining's binary_logloss: 0.56504\n",
      "[64]\ttraining's binary_logloss: 0.564677\n",
      "[65]\ttraining's binary_logloss: 0.56434\n",
      "[66]\ttraining's binary_logloss: 0.563997\n",
      "[67]\ttraining's binary_logloss: 0.563656\n",
      "[68]\ttraining's binary_logloss: 0.56334\n",
      "[69]\ttraining's binary_logloss: 0.562981\n",
      "[70]\ttraining's binary_logloss: 0.562656\n",
      "[71]\ttraining's binary_logloss: 0.5623\n",
      "[72]\ttraining's binary_logloss: 0.561948\n",
      "[73]\ttraining's binary_logloss: 0.561624\n",
      "[74]\ttraining's binary_logloss: 0.56131\n",
      "[75]\ttraining's binary_logloss: 0.56097\n",
      "[76]\ttraining's binary_logloss: 0.560728\n",
      "[77]\ttraining's binary_logloss: 0.560431\n",
      "[78]\ttraining's binary_logloss: 0.560132\n",
      "[79]\ttraining's binary_logloss: 0.559848\n",
      "[80]\ttraining's binary_logloss: 0.55956\n",
      "[81]\ttraining's binary_logloss: 0.559303\n",
      "[82]\ttraining's binary_logloss: 0.558996\n",
      "[83]\ttraining's binary_logloss: 0.558739\n",
      "[84]\ttraining's binary_logloss: 0.558502\n",
      "[85]\ttraining's binary_logloss: 0.558268\n",
      "[86]\ttraining's binary_logloss: 0.557994\n",
      "[87]\ttraining's binary_logloss: 0.557707\n",
      "[88]\ttraining's binary_logloss: 0.557489\n",
      "[89]\ttraining's binary_logloss: 0.557209\n",
      "[90]\ttraining's binary_logloss: 0.556956\n",
      "[91]\ttraining's binary_logloss: 0.556723\n",
      "[92]\ttraining's binary_logloss: 0.556495\n",
      "[93]\ttraining's binary_logloss: 0.556269\n",
      "[94]\ttraining's binary_logloss: 0.556083\n",
      "[95]\ttraining's binary_logloss: 0.555841\n",
      "[96]\ttraining's binary_logloss: 0.55565\n",
      "[97]\ttraining's binary_logloss: 0.555411\n",
      "[98]\ttraining's binary_logloss: 0.555203\n",
      "[99]\ttraining's binary_logloss: 0.55497\n",
      "[100]\ttraining's binary_logloss: 0.554753\n",
      "[101]\ttraining's binary_logloss: 0.554499\n",
      "[102]\ttraining's binary_logloss: 0.554262\n",
      "[103]\ttraining's binary_logloss: 0.554032\n",
      "[104]\ttraining's binary_logloss: 0.553813\n",
      "[105]\ttraining's binary_logloss: 0.553563\n",
      "[106]\ttraining's binary_logloss: 0.553355\n",
      "[107]\ttraining's binary_logloss: 0.553168\n",
      "[108]\ttraining's binary_logloss: 0.552973\n",
      "[109]\ttraining's binary_logloss: 0.552785\n",
      "[110]\ttraining's binary_logloss: 0.5526\n",
      "[111]\ttraining's binary_logloss: 0.552347\n",
      "[112]\ttraining's binary_logloss: 0.552114\n",
      "[113]\ttraining's binary_logloss: 0.551909\n",
      "[114]\ttraining's binary_logloss: 0.551708\n",
      "[115]\ttraining's binary_logloss: 0.551459\n",
      "[116]\ttraining's binary_logloss: 0.551264\n",
      "[117]\ttraining's binary_logloss: 0.551063\n",
      "[118]\ttraining's binary_logloss: 0.550845\n",
      "[119]\ttraining's binary_logloss: 0.550643\n",
      "[120]\ttraining's binary_logloss: 0.55042\n",
      "[121]\ttraining's binary_logloss: 0.550281\n",
      "[122]\ttraining's binary_logloss: 0.550121\n",
      "[123]\ttraining's binary_logloss: 0.549971\n",
      "[124]\ttraining's binary_logloss: 0.549817\n",
      "[125]\ttraining's binary_logloss: 0.549652\n",
      "[126]\ttraining's binary_logloss: 0.549435\n",
      "[127]\ttraining's binary_logloss: 0.549234\n",
      "[128]\ttraining's binary_logloss: 0.549023\n",
      "[129]\ttraining's binary_logloss: 0.548805\n",
      "[130]\ttraining's binary_logloss: 0.548603\n",
      "[131]\ttraining's binary_logloss: 0.548417\n",
      "[132]\ttraining's binary_logloss: 0.548247\n",
      "[133]\ttraining's binary_logloss: 0.548095\n",
      "[134]\ttraining's binary_logloss: 0.547944\n",
      "[135]\ttraining's binary_logloss: 0.547813\n",
      "[136]\ttraining's binary_logloss: 0.547628\n",
      "[137]\ttraining's binary_logloss: 0.547455\n",
      "[138]\ttraining's binary_logloss: 0.547269\n",
      "[139]\ttraining's binary_logloss: 0.547069\n",
      "[140]\ttraining's binary_logloss: 0.546897\n",
      "[141]\ttraining's binary_logloss: 0.546728\n",
      "[142]\ttraining's binary_logloss: 0.546545\n",
      "[143]\ttraining's binary_logloss: 0.546353\n",
      "[144]\ttraining's binary_logloss: 0.546178\n",
      "[145]\ttraining's binary_logloss: 0.545968\n",
      "[146]\ttraining's binary_logloss: 0.545797\n",
      "[147]\ttraining's binary_logloss: 0.545596\n",
      "[148]\ttraining's binary_logloss: 0.545433\n",
      "[149]\ttraining's binary_logloss: 0.545271\n",
      "[150]\ttraining's binary_logloss: 0.545121\n",
      "[151]\ttraining's binary_logloss: 0.544986\n",
      "[152]\ttraining's binary_logloss: 0.544821\n",
      "[153]\ttraining's binary_logloss: 0.544688\n",
      "[154]\ttraining's binary_logloss: 0.544501\n",
      "[155]\ttraining's binary_logloss: 0.544337\n",
      "[156]\ttraining's binary_logloss: 0.544127\n",
      "[157]\ttraining's binary_logloss: 0.543935\n",
      "[158]\ttraining's binary_logloss: 0.543788\n",
      "[159]\ttraining's binary_logloss: 0.543635\n",
      "[160]\ttraining's binary_logloss: 0.543463\n",
      "[161]\ttraining's binary_logloss: 0.543308\n",
      "[162]\ttraining's binary_logloss: 0.543118\n",
      "[163]\ttraining's binary_logloss: 0.542916\n",
      "[164]\ttraining's binary_logloss: 0.542781\n",
      "[165]\ttraining's binary_logloss: 0.542596\n",
      "[166]\ttraining's binary_logloss: 0.54238\n",
      "[167]\ttraining's binary_logloss: 0.542175\n",
      "[168]\ttraining's binary_logloss: 0.541939\n",
      "[169]\ttraining's binary_logloss: 0.541771\n",
      "[170]\ttraining's binary_logloss: 0.541545\n",
      "[171]\ttraining's binary_logloss: 0.541368\n",
      "[172]\ttraining's binary_logloss: 0.541184\n",
      "[173]\ttraining's binary_logloss: 0.541031\n",
      "[174]\ttraining's binary_logloss: 0.540859\n",
      "[175]\ttraining's binary_logloss: 0.540691\n",
      "[176]\ttraining's binary_logloss: 0.54052\n",
      "[177]\ttraining's binary_logloss: 0.54033\n",
      "[178]\ttraining's binary_logloss: 0.540126\n",
      "[179]\ttraining's binary_logloss: 0.539933\n",
      "[180]\ttraining's binary_logloss: 0.539734\n",
      "[181]\ttraining's binary_logloss: 0.539549\n",
      "[182]\ttraining's binary_logloss: 0.539327\n",
      "[183]\ttraining's binary_logloss: 0.539144\n",
      "[184]\ttraining's binary_logloss: 0.538979\n",
      "[185]\ttraining's binary_logloss: 0.538795\n",
      "[186]\ttraining's binary_logloss: 0.538637\n",
      "[187]\ttraining's binary_logloss: 0.538462\n",
      "[188]\ttraining's binary_logloss: 0.538308\n",
      "[189]\ttraining's binary_logloss: 0.538132\n",
      "[190]\ttraining's binary_logloss: 0.537965\n",
      "[191]\ttraining's binary_logloss: 0.537775\n",
      "[192]\ttraining's binary_logloss: 0.537583\n",
      "[193]\ttraining's binary_logloss: 0.537409\n",
      "[194]\ttraining's binary_logloss: 0.537242\n",
      "[195]\ttraining's binary_logloss: 0.537053\n",
      "[196]\ttraining's binary_logloss: 0.536887\n",
      "[197]\ttraining's binary_logloss: 0.536709\n",
      "[198]\ttraining's binary_logloss: 0.536545\n",
      "[199]\ttraining's binary_logloss: 0.536367\n",
      "[200]\ttraining's binary_logloss: 0.536169\n",
      "[201]\ttraining's binary_logloss: 0.53603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[202]\ttraining's binary_logloss: 0.535842\n",
      "[203]\ttraining's binary_logloss: 0.535654\n",
      "[204]\ttraining's binary_logloss: 0.53549\n",
      "[205]\ttraining's binary_logloss: 0.535318\n",
      "[206]\ttraining's binary_logloss: 0.535113\n",
      "[207]\ttraining's binary_logloss: 0.534897\n",
      "[208]\ttraining's binary_logloss: 0.534668\n",
      "[209]\ttraining's binary_logloss: 0.534469\n",
      "[210]\ttraining's binary_logloss: 0.534295\n",
      "[211]\ttraining's binary_logloss: 0.53411\n",
      "[212]\ttraining's binary_logloss: 0.533928\n",
      "[213]\ttraining's binary_logloss: 0.533767\n",
      "[214]\ttraining's binary_logloss: 0.533614\n",
      "[215]\ttraining's binary_logloss: 0.533451\n",
      "[216]\ttraining's binary_logloss: 0.533241\n",
      "[217]\ttraining's binary_logloss: 0.533049\n",
      "[218]\ttraining's binary_logloss: 0.532844\n",
      "[219]\ttraining's binary_logloss: 0.532642\n",
      "[220]\ttraining's binary_logloss: 0.532464\n",
      "[221]\ttraining's binary_logloss: 0.532255\n",
      "[222]\ttraining's binary_logloss: 0.532037\n",
      "[223]\ttraining's binary_logloss: 0.531828\n",
      "[224]\ttraining's binary_logloss: 0.531637\n",
      "[225]\ttraining's binary_logloss: 0.531434\n",
      "[226]\ttraining's binary_logloss: 0.531219\n",
      "[227]\ttraining's binary_logloss: 0.530978\n",
      "[228]\ttraining's binary_logloss: 0.530748\n",
      "[229]\ttraining's binary_logloss: 0.530521\n",
      "[230]\ttraining's binary_logloss: 0.530324\n",
      "[231]\ttraining's binary_logloss: 0.530151\n",
      "[232]\ttraining's binary_logloss: 0.52999\n",
      "[233]\ttraining's binary_logloss: 0.529833\n",
      "[234]\ttraining's binary_logloss: 0.529666\n",
      "[235]\ttraining's binary_logloss: 0.529482\n",
      "[236]\ttraining's binary_logloss: 0.529244\n",
      "[237]\ttraining's binary_logloss: 0.529046\n",
      "[238]\ttraining's binary_logloss: 0.528867\n",
      "[239]\ttraining's binary_logloss: 0.52868\n",
      "[240]\ttraining's binary_logloss: 0.528513\n",
      "[241]\ttraining's binary_logloss: 0.528324\n",
      "[242]\ttraining's binary_logloss: 0.528109\n",
      "[243]\ttraining's binary_logloss: 0.527932\n",
      "[244]\ttraining's binary_logloss: 0.527727\n",
      "[245]\ttraining's binary_logloss: 0.527543\n",
      "[246]\ttraining's binary_logloss: 0.527278\n",
      "[247]\ttraining's binary_logloss: 0.527034\n",
      "[248]\ttraining's binary_logloss: 0.526773\n",
      "[249]\ttraining's binary_logloss: 0.526568\n",
      "[250]\ttraining's binary_logloss: 0.526362\n",
      "[251]\ttraining's binary_logloss: 0.526155\n",
      "[252]\ttraining's binary_logloss: 0.525914\n",
      "[253]\ttraining's binary_logloss: 0.525719\n",
      "[254]\ttraining's binary_logloss: 0.52551\n",
      "[255]\ttraining's binary_logloss: 0.525261\n",
      "[256]\ttraining's binary_logloss: 0.525077\n",
      "[257]\ttraining's binary_logloss: 0.52488\n",
      "[258]\ttraining's binary_logloss: 0.524712\n",
      "[259]\ttraining's binary_logloss: 0.524524\n",
      "[260]\ttraining's binary_logloss: 0.524361\n",
      "[261]\ttraining's binary_logloss: 0.524185\n",
      "[262]\ttraining's binary_logloss: 0.524001\n",
      "[263]\ttraining's binary_logloss: 0.52382\n",
      "[264]\ttraining's binary_logloss: 0.523635\n",
      "[265]\ttraining's binary_logloss: 0.523459\n",
      "[266]\ttraining's binary_logloss: 0.523249\n",
      "[267]\ttraining's binary_logloss: 0.523064\n",
      "[268]\ttraining's binary_logloss: 0.522885\n",
      "[269]\ttraining's binary_logloss: 0.522703\n",
      "[270]\ttraining's binary_logloss: 0.522535\n",
      "[271]\ttraining's binary_logloss: 0.522344\n",
      "[272]\ttraining's binary_logloss: 0.522133\n",
      "[273]\ttraining's binary_logloss: 0.521931\n",
      "[274]\ttraining's binary_logloss: 0.521776\n",
      "[275]\ttraining's binary_logloss: 0.521544\n",
      "[276]\ttraining's binary_logloss: 0.521356\n",
      "[277]\ttraining's binary_logloss: 0.521162\n",
      "[278]\ttraining's binary_logloss: 0.520989\n",
      "[279]\ttraining's binary_logloss: 0.520799\n",
      "[280]\ttraining's binary_logloss: 0.520624\n",
      "[281]\ttraining's binary_logloss: 0.520463\n",
      "[282]\ttraining's binary_logloss: 0.52026\n",
      "[283]\ttraining's binary_logloss: 0.520087\n",
      "[284]\ttraining's binary_logloss: 0.519924\n",
      "[285]\ttraining's binary_logloss: 0.519762\n",
      "[286]\ttraining's binary_logloss: 0.519568\n",
      "[287]\ttraining's binary_logloss: 0.519344\n",
      "[288]\ttraining's binary_logloss: 0.519114\n",
      "[289]\ttraining's binary_logloss: 0.518895\n",
      "[290]\ttraining's binary_logloss: 0.518672\n",
      "[291]\ttraining's binary_logloss: 0.518451\n",
      "[292]\ttraining's binary_logloss: 0.51823\n",
      "[293]\ttraining's binary_logloss: 0.518013\n",
      "[294]\ttraining's binary_logloss: 0.517784\n",
      "[295]\ttraining's binary_logloss: 0.517523\n",
      "[296]\ttraining's binary_logloss: 0.517341\n",
      "[297]\ttraining's binary_logloss: 0.517148\n",
      "[298]\ttraining's binary_logloss: 0.51693\n",
      "[299]\ttraining's binary_logloss: 0.516752\n",
      "[300]\ttraining's binary_logloss: 0.516574\n",
      "[301]\ttraining's binary_logloss: 0.516367\n",
      "[302]\ttraining's binary_logloss: 0.516179\n",
      "[303]\ttraining's binary_logloss: 0.516011\n",
      "[304]\ttraining's binary_logloss: 0.515788\n",
      "[305]\ttraining's binary_logloss: 0.515572\n",
      "[306]\ttraining's binary_logloss: 0.515372\n",
      "[307]\ttraining's binary_logloss: 0.515162\n",
      "[308]\ttraining's binary_logloss: 0.514956\n",
      "[309]\ttraining's binary_logloss: 0.514735\n",
      "[310]\ttraining's binary_logloss: 0.514542\n",
      "[311]\ttraining's binary_logloss: 0.514359\n",
      "[312]\ttraining's binary_logloss: 0.514134\n",
      "[313]\ttraining's binary_logloss: 0.513882\n",
      "[314]\ttraining's binary_logloss: 0.513664\n",
      "[315]\ttraining's binary_logloss: 0.513465\n",
      "[316]\ttraining's binary_logloss: 0.51327\n",
      "[317]\ttraining's binary_logloss: 0.513084\n",
      "[318]\ttraining's binary_logloss: 0.512912\n",
      "[319]\ttraining's binary_logloss: 0.512728\n",
      "[320]\ttraining's binary_logloss: 0.512514\n",
      "[321]\ttraining's binary_logloss: 0.512347\n",
      "[322]\ttraining's binary_logloss: 0.512163\n",
      "[323]\ttraining's binary_logloss: 0.511993\n",
      "[324]\ttraining's binary_logloss: 0.511794\n",
      "[325]\ttraining's binary_logloss: 0.511588\n",
      "[326]\ttraining's binary_logloss: 0.511337\n",
      "[327]\ttraining's binary_logloss: 0.511086\n",
      "[328]\ttraining's binary_logloss: 0.510862\n",
      "[329]\ttraining's binary_logloss: 0.510644\n",
      "[330]\ttraining's binary_logloss: 0.510413\n",
      "[331]\ttraining's binary_logloss: 0.510209\n",
      "[332]\ttraining's binary_logloss: 0.510011\n",
      "[333]\ttraining's binary_logloss: 0.509826\n",
      "[334]\ttraining's binary_logloss: 0.509643\n",
      "[335]\ttraining's binary_logloss: 0.509456\n",
      "[336]\ttraining's binary_logloss: 0.509271\n",
      "[337]\ttraining's binary_logloss: 0.509069\n",
      "[338]\ttraining's binary_logloss: 0.508896\n",
      "[339]\ttraining's binary_logloss: 0.508708\n",
      "[340]\ttraining's binary_logloss: 0.508531\n",
      "[341]\ttraining's binary_logloss: 0.508371\n",
      "[342]\ttraining's binary_logloss: 0.508199\n",
      "[343]\ttraining's binary_logloss: 0.508034\n",
      "[344]\ttraining's binary_logloss: 0.507871\n",
      "[345]\ttraining's binary_logloss: 0.507688\n",
      "[346]\ttraining's binary_logloss: 0.507449\n",
      "[347]\ttraining's binary_logloss: 0.50722\n",
      "[348]\ttraining's binary_logloss: 0.507001\n",
      "[349]\ttraining's binary_logloss: 0.506792\n",
      "[350]\ttraining's binary_logloss: 0.506578\n",
      "[351]\ttraining's binary_logloss: 0.50642\n",
      "[352]\ttraining's binary_logloss: 0.50625\n",
      "[353]\ttraining's binary_logloss: 0.506086\n",
      "[354]\ttraining's binary_logloss: 0.505927\n",
      "[355]\ttraining's binary_logloss: 0.50577\n",
      "[356]\ttraining's binary_logloss: 0.505601\n",
      "[357]\ttraining's binary_logloss: 0.505406\n",
      "[358]\ttraining's binary_logloss: 0.505186\n",
      "[359]\ttraining's binary_logloss: 0.504982\n",
      "[360]\ttraining's binary_logloss: 0.504799\n",
      "[361]\ttraining's binary_logloss: 0.504584\n",
      "[362]\ttraining's binary_logloss: 0.504375\n",
      "[363]\ttraining's binary_logloss: 0.504153\n",
      "[364]\ttraining's binary_logloss: 0.503949\n",
      "[365]\ttraining's binary_logloss: 0.503706\n",
      "[366]\ttraining's binary_logloss: 0.503489\n",
      "[367]\ttraining's binary_logloss: 0.503274\n",
      "[368]\ttraining's binary_logloss: 0.503074\n",
      "[369]\ttraining's binary_logloss: 0.502864\n",
      "[370]\ttraining's binary_logloss: 0.502652\n",
      "[371]\ttraining's binary_logloss: 0.502421\n",
      "[372]\ttraining's binary_logloss: 0.502196\n",
      "[373]\ttraining's binary_logloss: 0.50193\n",
      "[374]\ttraining's binary_logloss: 0.501721\n",
      "[375]\ttraining's binary_logloss: 0.501487\n",
      "[376]\ttraining's binary_logloss: 0.501287\n",
      "[377]\ttraining's binary_logloss: 0.501085\n",
      "[378]\ttraining's binary_logloss: 0.500893\n",
      "[379]\ttraining's binary_logloss: 0.500686\n",
      "[380]\ttraining's binary_logloss: 0.500493\n",
      "[381]\ttraining's binary_logloss: 0.50027\n",
      "[382]\ttraining's binary_logloss: 0.50005\n",
      "[383]\ttraining's binary_logloss: 0.499839\n",
      "[384]\ttraining's binary_logloss: 0.499648\n",
      "[385]\ttraining's binary_logloss: 0.499434\n",
      "[386]\ttraining's binary_logloss: 0.499195\n",
      "[387]\ttraining's binary_logloss: 0.49897\n",
      "[388]\ttraining's binary_logloss: 0.498761\n",
      "[389]\ttraining's binary_logloss: 0.498533\n",
      "[390]\ttraining's binary_logloss: 0.49831\n",
      "[391]\ttraining's binary_logloss: 0.498092\n",
      "[392]\ttraining's binary_logloss: 0.497872\n",
      "[393]\ttraining's binary_logloss: 0.497647\n",
      "[394]\ttraining's binary_logloss: 0.49742\n",
      "[395]\ttraining's binary_logloss: 0.497193\n",
      "[396]\ttraining's binary_logloss: 0.497021\n",
      "[397]\ttraining's binary_logloss: 0.496843\n",
      "[398]\ttraining's binary_logloss: 0.496666\n",
      "[399]\ttraining's binary_logloss: 0.496489\n",
      "[400]\ttraining's binary_logloss: 0.496297\n",
      "[401]\ttraining's binary_logloss: 0.496083\n",
      "[402]\ttraining's binary_logloss: 0.495877\n",
      "[403]\ttraining's binary_logloss: 0.49567\n",
      "[404]\ttraining's binary_logloss: 0.495489\n",
      "[405]\ttraining's binary_logloss: 0.495292\n",
      "[406]\ttraining's binary_logloss: 0.495107\n",
      "[407]\ttraining's binary_logloss: 0.494927\n",
      "[408]\ttraining's binary_logloss: 0.494756\n",
      "[409]\ttraining's binary_logloss: 0.494569\n",
      "[410]\ttraining's binary_logloss: 0.494395\n",
      "[411]\ttraining's binary_logloss: 0.494186\n",
      "[412]\ttraining's binary_logloss: 0.494013\n",
      "[413]\ttraining's binary_logloss: 0.493812\n",
      "[414]\ttraining's binary_logloss: 0.493618\n",
      "[415]\ttraining's binary_logloss: 0.49343\n",
      "[416]\ttraining's binary_logloss: 0.49323\n",
      "[417]\ttraining's binary_logloss: 0.493033\n",
      "[418]\ttraining's binary_logloss: 0.492858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[419]\ttraining's binary_logloss: 0.492659\n",
      "[420]\ttraining's binary_logloss: 0.492473\n",
      "[421]\ttraining's binary_logloss: 0.492308\n",
      "[422]\ttraining's binary_logloss: 0.492102\n",
      "[423]\ttraining's binary_logloss: 0.49195\n",
      "[424]\ttraining's binary_logloss: 0.491799\n",
      "[425]\ttraining's binary_logloss: 0.491635\n",
      "[426]\ttraining's binary_logloss: 0.491465\n",
      "[427]\ttraining's binary_logloss: 0.491314\n",
      "[428]\ttraining's binary_logloss: 0.491176\n",
      "[429]\ttraining's binary_logloss: 0.491034\n",
      "[430]\ttraining's binary_logloss: 0.490875\n",
      "[431]\ttraining's binary_logloss: 0.490697\n",
      "[432]\ttraining's binary_logloss: 0.490516\n",
      "[433]\ttraining's binary_logloss: 0.490326\n",
      "[434]\ttraining's binary_logloss: 0.490124\n",
      "[435]\ttraining's binary_logloss: 0.489944\n",
      "[436]\ttraining's binary_logloss: 0.489749\n",
      "[437]\ttraining's binary_logloss: 0.489536\n",
      "[438]\ttraining's binary_logloss: 0.48938\n",
      "[439]\ttraining's binary_logloss: 0.489182\n",
      "[440]\ttraining's binary_logloss: 0.489011\n",
      "[441]\ttraining's binary_logloss: 0.488827\n",
      "[442]\ttraining's binary_logloss: 0.488624\n",
      "[443]\ttraining's binary_logloss: 0.488417\n",
      "[444]\ttraining's binary_logloss: 0.488191\n",
      "[445]\ttraining's binary_logloss: 0.487985\n",
      "[446]\ttraining's binary_logloss: 0.487734\n",
      "[447]\ttraining's binary_logloss: 0.48751\n",
      "[448]\ttraining's binary_logloss: 0.487261\n",
      "[449]\ttraining's binary_logloss: 0.487028\n",
      "[450]\ttraining's binary_logloss: 0.486802\n",
      "[451]\ttraining's binary_logloss: 0.486535\n",
      "[452]\ttraining's binary_logloss: 0.486283\n",
      "[453]\ttraining's binary_logloss: 0.486053\n",
      "[454]\ttraining's binary_logloss: 0.485805\n",
      "[455]\ttraining's binary_logloss: 0.485607\n",
      "[456]\ttraining's binary_logloss: 0.485379\n",
      "[457]\ttraining's binary_logloss: 0.485215\n",
      "[458]\ttraining's binary_logloss: 0.485042\n",
      "[459]\ttraining's binary_logloss: 0.484843\n",
      "[460]\ttraining's binary_logloss: 0.484679\n",
      "[461]\ttraining's binary_logloss: 0.484475\n",
      "[462]\ttraining's binary_logloss: 0.484284\n",
      "[463]\ttraining's binary_logloss: 0.484088\n",
      "[464]\ttraining's binary_logloss: 0.483907\n",
      "[465]\ttraining's binary_logloss: 0.483723\n",
      "[466]\ttraining's binary_logloss: 0.483505\n",
      "[467]\ttraining's binary_logloss: 0.483263\n",
      "[468]\ttraining's binary_logloss: 0.483046\n",
      "[469]\ttraining's binary_logloss: 0.482807\n",
      "[470]\ttraining's binary_logloss: 0.482596\n",
      "[471]\ttraining's binary_logloss: 0.482392\n",
      "[472]\ttraining's binary_logloss: 0.482193\n",
      "[473]\ttraining's binary_logloss: 0.482\n",
      "[474]\ttraining's binary_logloss: 0.481816\n",
      "[475]\ttraining's binary_logloss: 0.48163\n",
      "[476]\ttraining's binary_logloss: 0.481416\n",
      "[477]\ttraining's binary_logloss: 0.481243\n",
      "[478]\ttraining's binary_logloss: 0.481065\n",
      "[479]\ttraining's binary_logloss: 0.48088\n",
      "[480]\ttraining's binary_logloss: 0.48069\n",
      "[481]\ttraining's binary_logloss: 0.480513\n",
      "[482]\ttraining's binary_logloss: 0.480352\n",
      "[483]\ttraining's binary_logloss: 0.480146\n",
      "[484]\ttraining's binary_logloss: 0.479958\n",
      "[485]\ttraining's binary_logloss: 0.479802\n",
      "[486]\ttraining's binary_logloss: 0.479551\n",
      "[487]\ttraining's binary_logloss: 0.479344\n",
      "[488]\ttraining's binary_logloss: 0.479141\n",
      "[489]\ttraining's binary_logloss: 0.478918\n",
      "[490]\ttraining's binary_logloss: 0.478706\n",
      "[491]\ttraining's binary_logloss: 0.478504\n",
      "[492]\ttraining's binary_logloss: 0.478306\n",
      "[493]\ttraining's binary_logloss: 0.478116\n",
      "[494]\ttraining's binary_logloss: 0.47793\n",
      "[495]\ttraining's binary_logloss: 0.477746\n",
      "[496]\ttraining's binary_logloss: 0.477579\n",
      "[497]\ttraining's binary_logloss: 0.477403\n",
      "[498]\ttraining's binary_logloss: 0.477181\n",
      "[499]\ttraining's binary_logloss: 0.47698\n",
      "[500]\ttraining's binary_logloss: 0.476757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614697\n",
      "[2]\ttraining's binary_logloss: 0.61365\n",
      "[3]\ttraining's binary_logloss: 0.612776\n",
      "[4]\ttraining's binary_logloss: 0.611906\n",
      "[5]\ttraining's binary_logloss: 0.61117\n",
      "[6]\ttraining's binary_logloss: 0.610319\n",
      "[7]\ttraining's binary_logloss: 0.609487\n",
      "[8]\ttraining's binary_logloss: 0.608698\n",
      "[9]\ttraining's binary_logloss: 0.607871\n",
      "[10]\ttraining's binary_logloss: 0.607132\n",
      "[11]\ttraining's binary_logloss: 0.606401\n",
      "[12]\ttraining's binary_logloss: 0.605642\n",
      "[13]\ttraining's binary_logloss: 0.604923\n",
      "[14]\ttraining's binary_logloss: 0.604228\n",
      "[15]\ttraining's binary_logloss: 0.603614\n",
      "[16]\ttraining's binary_logloss: 0.603019\n",
      "[17]\ttraining's binary_logloss: 0.602401\n",
      "[18]\ttraining's binary_logloss: 0.601813\n",
      "[19]\ttraining's binary_logloss: 0.601209\n",
      "[20]\ttraining's binary_logloss: 0.600749\n",
      "[21]\ttraining's binary_logloss: 0.600288\n",
      "[22]\ttraining's binary_logloss: 0.599895\n",
      "[23]\ttraining's binary_logloss: 0.599421\n",
      "[24]\ttraining's binary_logloss: 0.598977\n",
      "[25]\ttraining's binary_logloss: 0.598552\n",
      "[26]\ttraining's binary_logloss: 0.598121\n",
      "[27]\ttraining's binary_logloss: 0.597708\n",
      "[28]\ttraining's binary_logloss: 0.597299\n",
      "[29]\ttraining's binary_logloss: 0.596913\n",
      "[30]\ttraining's binary_logloss: 0.59655\n",
      "[31]\ttraining's binary_logloss: 0.596164\n",
      "[32]\ttraining's binary_logloss: 0.595797\n",
      "[33]\ttraining's binary_logloss: 0.595439\n",
      "[34]\ttraining's binary_logloss: 0.595093\n",
      "[35]\ttraining's binary_logloss: 0.594778\n",
      "[36]\ttraining's binary_logloss: 0.594524\n",
      "[37]\ttraining's binary_logloss: 0.594207\n",
      "[38]\ttraining's binary_logloss: 0.593953\n",
      "[39]\ttraining's binary_logloss: 0.593691\n",
      "[40]\ttraining's binary_logloss: 0.593444\n",
      "[41]\ttraining's binary_logloss: 0.593182\n",
      "[42]\ttraining's binary_logloss: 0.592941\n",
      "[43]\ttraining's binary_logloss: 0.592707\n",
      "[44]\ttraining's binary_logloss: 0.592526\n",
      "[45]\ttraining's binary_logloss: 0.592318\n",
      "[46]\ttraining's binary_logloss: 0.592147\n",
      "[47]\ttraining's binary_logloss: 0.591977\n",
      "[48]\ttraining's binary_logloss: 0.591767\n",
      "[49]\ttraining's binary_logloss: 0.591568\n",
      "[50]\ttraining's binary_logloss: 0.591436\n",
      "[51]\ttraining's binary_logloss: 0.591263\n",
      "[52]\ttraining's binary_logloss: 0.591113\n",
      "[53]\ttraining's binary_logloss: 0.590951\n",
      "[54]\ttraining's binary_logloss: 0.590828\n",
      "[55]\ttraining's binary_logloss: 0.590658\n",
      "[56]\ttraining's binary_logloss: 0.590466\n",
      "[57]\ttraining's binary_logloss: 0.590283\n",
      "[58]\ttraining's binary_logloss: 0.590116\n",
      "[59]\ttraining's binary_logloss: 0.59002\n",
      "[60]\ttraining's binary_logloss: 0.589865\n",
      "[61]\ttraining's binary_logloss: 0.589797\n",
      "[62]\ttraining's binary_logloss: 0.589688\n",
      "[63]\ttraining's binary_logloss: 0.589628\n",
      "[64]\ttraining's binary_logloss: 0.589583\n",
      "[65]\ttraining's binary_logloss: 0.589544\n",
      "[66]\ttraining's binary_logloss: 0.589485\n",
      "[67]\ttraining's binary_logloss: 0.589382\n",
      "[68]\ttraining's binary_logloss: 0.589347\n",
      "[69]\ttraining's binary_logloss: 0.589286\n",
      "[70]\ttraining's binary_logloss: 0.589261\n",
      "[71]\ttraining's binary_logloss: 0.58919\n",
      "[72]\ttraining's binary_logloss: 0.589126\n",
      "[73]\ttraining's binary_logloss: 0.589074\n",
      "[74]\ttraining's binary_logloss: 0.589052\n",
      "[75]\ttraining's binary_logloss: 0.588992\n",
      "[76]\ttraining's binary_logloss: 0.588982\n",
      "[77]\ttraining's binary_logloss: 0.589019\n",
      "[78]\ttraining's binary_logloss: 0.589028\n",
      "[79]\ttraining's binary_logloss: 0.588965\n",
      "[80]\ttraining's binary_logloss: 0.588954\n",
      "[81]\ttraining's binary_logloss: 0.589\n",
      "[82]\ttraining's binary_logloss: 0.588999\n",
      "[83]\ttraining's binary_logloss: 0.588926\n",
      "[84]\ttraining's binary_logloss: 0.588931\n",
      "[85]\ttraining's binary_logloss: 0.588869\n",
      "[86]\ttraining's binary_logloss: 0.588888\n",
      "[87]\ttraining's binary_logloss: 0.588853\n",
      "[88]\ttraining's binary_logloss: 0.588821\n",
      "[89]\ttraining's binary_logloss: 0.588794\n",
      "[90]\ttraining's binary_logloss: 0.588772\n",
      "[91]\ttraining's binary_logloss: 0.588802\n",
      "[92]\ttraining's binary_logloss: 0.588836\n",
      "[93]\ttraining's binary_logloss: 0.588854\n",
      "[94]\ttraining's binary_logloss: 0.588838\n",
      "[95]\ttraining's binary_logloss: 0.588893\n",
      "[96]\ttraining's binary_logloss: 0.588885\n",
      "[97]\ttraining's binary_logloss: 0.588881\n",
      "[98]\ttraining's binary_logloss: 0.588892\n",
      "[99]\ttraining's binary_logloss: 0.588897\n",
      "[100]\ttraining's binary_logloss: 0.588918\n",
      "[101]\ttraining's binary_logloss: 0.588918\n",
      "[102]\ttraining's binary_logloss: 0.588933\n",
      "[103]\ttraining's binary_logloss: 0.588953\n",
      "[104]\ttraining's binary_logloss: 0.588973\n",
      "[105]\ttraining's binary_logloss: 0.588981\n",
      "[106]\ttraining's binary_logloss: 0.589037\n",
      "[107]\ttraining's binary_logloss: 0.589095\n",
      "[108]\ttraining's binary_logloss: 0.589093\n",
      "[109]\ttraining's binary_logloss: 0.589161\n",
      "[110]\ttraining's binary_logloss: 0.589165\n",
      "[111]\ttraining's binary_logloss: 0.58917\n",
      "[112]\ttraining's binary_logloss: 0.589167\n",
      "[113]\ttraining's binary_logloss: 0.589169\n",
      "[114]\ttraining's binary_logloss: 0.589212\n",
      "[115]\ttraining's binary_logloss: 0.589218\n",
      "[116]\ttraining's binary_logloss: 0.589218\n",
      "[117]\ttraining's binary_logloss: 0.589198\n",
      "[118]\ttraining's binary_logloss: 0.589208\n",
      "[119]\ttraining's binary_logloss: 0.589248\n",
      "[120]\ttraining's binary_logloss: 0.58929\n",
      "[121]\ttraining's binary_logloss: 0.589302\n",
      "[122]\ttraining's binary_logloss: 0.589321\n",
      "[123]\ttraining's binary_logloss: 0.589341\n",
      "[124]\ttraining's binary_logloss: 0.589377\n",
      "[125]\ttraining's binary_logloss: 0.589402\n",
      "[126]\ttraining's binary_logloss: 0.589423\n",
      "[127]\ttraining's binary_logloss: 0.589447\n",
      "[128]\ttraining's binary_logloss: 0.589474\n",
      "[129]\ttraining's binary_logloss: 0.589476\n",
      "[130]\ttraining's binary_logloss: 0.589513\n",
      "[131]\ttraining's binary_logloss: 0.589591\n",
      "[132]\ttraining's binary_logloss: 0.589622\n",
      "[133]\ttraining's binary_logloss: 0.589703\n",
      "[134]\ttraining's binary_logloss: 0.589746\n",
      "[135]\ttraining's binary_logloss: 0.589829\n",
      "[136]\ttraining's binary_logloss: 0.589889\n",
      "[137]\ttraining's binary_logloss: 0.589935\n",
      "[138]\ttraining's binary_logloss: 0.589949\n",
      "[139]\ttraining's binary_logloss: 0.590008\n",
      "[140]\ttraining's binary_logloss: 0.590069\n",
      "[141]\ttraining's binary_logloss: 0.590091\n",
      "[142]\ttraining's binary_logloss: 0.59011\n",
      "[143]\ttraining's binary_logloss: 0.590147\n",
      "[144]\ttraining's binary_logloss: 0.590147\n",
      "[145]\ttraining's binary_logloss: 0.590225\n",
      "[146]\ttraining's binary_logloss: 0.59027\n",
      "[147]\ttraining's binary_logloss: 0.590297\n",
      "[148]\ttraining's binary_logloss: 0.590328\n",
      "[149]\ttraining's binary_logloss: 0.590356\n",
      "[150]\ttraining's binary_logloss: 0.590401\n",
      "[151]\ttraining's binary_logloss: 0.590463\n",
      "[152]\ttraining's binary_logloss: 0.590523\n",
      "[153]\ttraining's binary_logloss: 0.590573\n",
      "[154]\ttraining's binary_logloss: 0.59063\n",
      "[155]\ttraining's binary_logloss: 0.590659\n",
      "[156]\ttraining's binary_logloss: 0.590688\n",
      "[157]\ttraining's binary_logloss: 0.590704\n",
      "[158]\ttraining's binary_logloss: 0.59074\n",
      "[159]\ttraining's binary_logloss: 0.590779\n",
      "[160]\ttraining's binary_logloss: 0.590807\n",
      "[161]\ttraining's binary_logloss: 0.590846\n",
      "[162]\ttraining's binary_logloss: 0.590837\n",
      "[163]\ttraining's binary_logloss: 0.590837\n",
      "[164]\ttraining's binary_logloss: 0.590833\n",
      "[165]\ttraining's binary_logloss: 0.590868\n",
      "[166]\ttraining's binary_logloss: 0.590886\n",
      "[167]\ttraining's binary_logloss: 0.590925\n",
      "[168]\ttraining's binary_logloss: 0.590958\n",
      "[169]\ttraining's binary_logloss: 0.590989\n",
      "[170]\ttraining's binary_logloss: 0.591036\n",
      "[171]\ttraining's binary_logloss: 0.591065\n",
      "[172]\ttraining's binary_logloss: 0.591105\n",
      "[173]\ttraining's binary_logloss: 0.59113\n",
      "[174]\ttraining's binary_logloss: 0.591158\n",
      "[175]\ttraining's binary_logloss: 0.591182\n",
      "[176]\ttraining's binary_logloss: 0.591179\n",
      "[177]\ttraining's binary_logloss: 0.591189\n",
      "[178]\ttraining's binary_logloss: 0.591198\n",
      "[179]\ttraining's binary_logloss: 0.591207\n",
      "[180]\ttraining's binary_logloss: 0.591216\n",
      "[181]\ttraining's binary_logloss: 0.591238\n",
      "[182]\ttraining's binary_logloss: 0.591262\n",
      "[183]\ttraining's binary_logloss: 0.591305\n",
      "[184]\ttraining's binary_logloss: 0.591326\n",
      "[185]\ttraining's binary_logloss: 0.591363\n",
      "[186]\ttraining's binary_logloss: 0.591428\n",
      "[187]\ttraining's binary_logloss: 0.591487\n",
      "[188]\ttraining's binary_logloss: 0.591549\n",
      "[189]\ttraining's binary_logloss: 0.59161\n",
      "[190]\ttraining's binary_logloss: 0.591655\n",
      "[191]\ttraining's binary_logloss: 0.591673\n",
      "[192]\ttraining's binary_logloss: 0.591692\n",
      "[193]\ttraining's binary_logloss: 0.591693\n",
      "[194]\ttraining's binary_logloss: 0.591712\n",
      "[195]\ttraining's binary_logloss: 0.591705\n",
      "[196]\ttraining's binary_logloss: 0.591723\n",
      "[197]\ttraining's binary_logloss: 0.59175\n",
      "[198]\ttraining's binary_logloss: 0.59177\n",
      "[199]\ttraining's binary_logloss: 0.591782\n",
      "[200]\ttraining's binary_logloss: 0.591796\n",
      "[201]\ttraining's binary_logloss: 0.591839\n",
      "[202]\ttraining's binary_logloss: 0.591861\n",
      "[203]\ttraining's binary_logloss: 0.591896\n",
      "[204]\ttraining's binary_logloss: 0.591946\n",
      "[205]\ttraining's binary_logloss: 0.591969\n",
      "[206]\ttraining's binary_logloss: 0.591957\n",
      "[207]\ttraining's binary_logloss: 0.59192\n",
      "[208]\ttraining's binary_logloss: 0.591892\n",
      "[209]\ttraining's binary_logloss: 0.591859\n",
      "[210]\ttraining's binary_logloss: 0.591833\n",
      "[211]\ttraining's binary_logloss: 0.591871\n",
      "[212]\ttraining's binary_logloss: 0.591908\n",
      "[213]\ttraining's binary_logloss: 0.591929\n",
      "[214]\ttraining's binary_logloss: 0.591966\n",
      "[215]\ttraining's binary_logloss: 0.591988\n",
      "[216]\ttraining's binary_logloss: 0.591965\n",
      "[217]\ttraining's binary_logloss: 0.591944\n",
      "[218]\ttraining's binary_logloss: 0.591931\n",
      "[219]\ttraining's binary_logloss: 0.591919\n",
      "[220]\ttraining's binary_logloss: 0.5919\n",
      "[221]\ttraining's binary_logloss: 0.591892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[222]\ttraining's binary_logloss: 0.59188\n",
      "[223]\ttraining's binary_logloss: 0.591874\n",
      "[224]\ttraining's binary_logloss: 0.591864\n",
      "[225]\ttraining's binary_logloss: 0.591855\n",
      "[226]\ttraining's binary_logloss: 0.591841\n",
      "[227]\ttraining's binary_logloss: 0.591828\n",
      "[228]\ttraining's binary_logloss: 0.591815\n",
      "[229]\ttraining's binary_logloss: 0.591818\n",
      "[230]\ttraining's binary_logloss: 0.591796\n",
      "[231]\ttraining's binary_logloss: 0.591809\n",
      "[232]\ttraining's binary_logloss: 0.591822\n",
      "[233]\ttraining's binary_logloss: 0.591839\n",
      "[234]\ttraining's binary_logloss: 0.591832\n",
      "[235]\ttraining's binary_logloss: 0.591827\n",
      "[236]\ttraining's binary_logloss: 0.591834\n",
      "[237]\ttraining's binary_logloss: 0.591805\n",
      "[238]\ttraining's binary_logloss: 0.591789\n",
      "[239]\ttraining's binary_logloss: 0.591767\n",
      "[240]\ttraining's binary_logloss: 0.591746\n",
      "[241]\ttraining's binary_logloss: 0.591742\n",
      "[242]\ttraining's binary_logloss: 0.591739\n",
      "[243]\ttraining's binary_logloss: 0.591749\n",
      "[244]\ttraining's binary_logloss: 0.591755\n",
      "[245]\ttraining's binary_logloss: 0.591764\n",
      "[246]\ttraining's binary_logloss: 0.591718\n",
      "[247]\ttraining's binary_logloss: 0.591657\n",
      "[248]\ttraining's binary_logloss: 0.591599\n",
      "[249]\ttraining's binary_logloss: 0.591542\n",
      "[250]\ttraining's binary_logloss: 0.59149\n",
      "[251]\ttraining's binary_logloss: 0.591446\n",
      "[252]\ttraining's binary_logloss: 0.591405\n",
      "[253]\ttraining's binary_logloss: 0.591378\n",
      "[254]\ttraining's binary_logloss: 0.591357\n",
      "[255]\ttraining's binary_logloss: 0.591314\n",
      "[256]\ttraining's binary_logloss: 0.591299\n",
      "[257]\ttraining's binary_logloss: 0.591297\n",
      "[258]\ttraining's binary_logloss: 0.591262\n",
      "[259]\ttraining's binary_logloss: 0.591243\n",
      "[260]\ttraining's binary_logloss: 0.591213\n",
      "[261]\ttraining's binary_logloss: 0.591234\n",
      "[262]\ttraining's binary_logloss: 0.591225\n",
      "[263]\ttraining's binary_logloss: 0.591215\n",
      "[264]\ttraining's binary_logloss: 0.591237\n",
      "[265]\ttraining's binary_logloss: 0.591247\n",
      "[266]\ttraining's binary_logloss: 0.591251\n",
      "[267]\ttraining's binary_logloss: 0.591258\n",
      "[268]\ttraining's binary_logloss: 0.591273\n",
      "[269]\ttraining's binary_logloss: 0.591283\n",
      "[270]\ttraining's binary_logloss: 0.591298\n",
      "[271]\ttraining's binary_logloss: 0.591281\n",
      "[272]\ttraining's binary_logloss: 0.591283\n",
      "[273]\ttraining's binary_logloss: 0.59129\n",
      "[274]\ttraining's binary_logloss: 0.591274\n",
      "[275]\ttraining's binary_logloss: 0.591257\n",
      "[276]\ttraining's binary_logloss: 0.591215\n",
      "[277]\ttraining's binary_logloss: 0.591179\n",
      "[278]\ttraining's binary_logloss: 0.591163\n",
      "[279]\ttraining's binary_logloss: 0.591153\n",
      "[280]\ttraining's binary_logloss: 0.591139\n",
      "[281]\ttraining's binary_logloss: 0.591118\n",
      "[282]\ttraining's binary_logloss: 0.59112\n",
      "[283]\ttraining's binary_logloss: 0.59111\n",
      "[284]\ttraining's binary_logloss: 0.5911\n",
      "[285]\ttraining's binary_logloss: 0.591093\n",
      "[286]\ttraining's binary_logloss: 0.59105\n",
      "[287]\ttraining's binary_logloss: 0.591014\n",
      "[288]\ttraining's binary_logloss: 0.590997\n",
      "[289]\ttraining's binary_logloss: 0.590949\n",
      "[290]\ttraining's binary_logloss: 0.590928\n",
      "[291]\ttraining's binary_logloss: 0.590867\n",
      "[292]\ttraining's binary_logloss: 0.590808\n",
      "[293]\ttraining's binary_logloss: 0.590745\n",
      "[294]\ttraining's binary_logloss: 0.590691\n",
      "[295]\ttraining's binary_logloss: 0.59062\n",
      "[296]\ttraining's binary_logloss: 0.590591\n",
      "[297]\ttraining's binary_logloss: 0.590562\n",
      "[298]\ttraining's binary_logloss: 0.590535\n",
      "[299]\ttraining's binary_logloss: 0.590508\n",
      "[300]\ttraining's binary_logloss: 0.590481\n",
      "[301]\ttraining's binary_logloss: 0.590432\n",
      "[302]\ttraining's binary_logloss: 0.590386\n",
      "[303]\ttraining's binary_logloss: 0.590354\n",
      "[304]\ttraining's binary_logloss: 0.590309\n",
      "[305]\ttraining's binary_logloss: 0.590263\n",
      "[306]\ttraining's binary_logloss: 0.590223\n",
      "[307]\ttraining's binary_logloss: 0.590185\n",
      "[308]\ttraining's binary_logloss: 0.590155\n",
      "[309]\ttraining's binary_logloss: 0.59012\n",
      "[310]\ttraining's binary_logloss: 0.590089\n",
      "[311]\ttraining's binary_logloss: 0.590046\n",
      "[312]\ttraining's binary_logloss: 0.590001\n",
      "[313]\ttraining's binary_logloss: 0.589925\n",
      "[314]\ttraining's binary_logloss: 0.589884\n",
      "[315]\ttraining's binary_logloss: 0.589844\n",
      "[316]\ttraining's binary_logloss: 0.5898\n",
      "[317]\ttraining's binary_logloss: 0.589761\n",
      "[318]\ttraining's binary_logloss: 0.58972\n",
      "[319]\ttraining's binary_logloss: 0.589676\n",
      "[320]\ttraining's binary_logloss: 0.589641\n",
      "[321]\ttraining's binary_logloss: 0.589607\n",
      "[322]\ttraining's binary_logloss: 0.58957\n",
      "[323]\ttraining's binary_logloss: 0.589534\n",
      "[324]\ttraining's binary_logloss: 0.589489\n",
      "[325]\ttraining's binary_logloss: 0.589453\n",
      "[326]\ttraining's binary_logloss: 0.589388\n",
      "[327]\ttraining's binary_logloss: 0.589325\n",
      "[328]\ttraining's binary_logloss: 0.589271\n",
      "[329]\ttraining's binary_logloss: 0.58921\n",
      "[330]\ttraining's binary_logloss: 0.589163\n",
      "[331]\ttraining's binary_logloss: 0.589109\n",
      "[332]\ttraining's binary_logloss: 0.589061\n",
      "[333]\ttraining's binary_logloss: 0.58901\n",
      "[334]\ttraining's binary_logloss: 0.588963\n",
      "[335]\ttraining's binary_logloss: 0.58892\n",
      "[336]\ttraining's binary_logloss: 0.588901\n",
      "[337]\ttraining's binary_logloss: 0.588886\n",
      "[338]\ttraining's binary_logloss: 0.588873\n",
      "[339]\ttraining's binary_logloss: 0.588852\n",
      "[340]\ttraining's binary_logloss: 0.588829\n",
      "[341]\ttraining's binary_logloss: 0.588792\n",
      "[342]\ttraining's binary_logloss: 0.588757\n",
      "[343]\ttraining's binary_logloss: 0.588725\n",
      "[344]\ttraining's binary_logloss: 0.588693\n",
      "[345]\ttraining's binary_logloss: 0.588659\n",
      "[346]\ttraining's binary_logloss: 0.588598\n",
      "[347]\ttraining's binary_logloss: 0.588544\n",
      "[348]\ttraining's binary_logloss: 0.588475\n",
      "[349]\ttraining's binary_logloss: 0.588415\n",
      "[350]\ttraining's binary_logloss: 0.588348\n",
      "[351]\ttraining's binary_logloss: 0.588324\n",
      "[352]\ttraining's binary_logloss: 0.58831\n",
      "[353]\ttraining's binary_logloss: 0.588294\n",
      "[354]\ttraining's binary_logloss: 0.588282\n",
      "[355]\ttraining's binary_logloss: 0.588263\n",
      "[356]\ttraining's binary_logloss: 0.588217\n",
      "[357]\ttraining's binary_logloss: 0.588168\n",
      "[358]\ttraining's binary_logloss: 0.588122\n",
      "[359]\ttraining's binary_logloss: 0.588073\n",
      "[360]\ttraining's binary_logloss: 0.588029\n",
      "[361]\ttraining's binary_logloss: 0.587966\n",
      "[362]\ttraining's binary_logloss: 0.587902\n",
      "[363]\ttraining's binary_logloss: 0.587828\n",
      "[364]\ttraining's binary_logloss: 0.587769\n",
      "[365]\ttraining's binary_logloss: 0.587697\n",
      "[366]\ttraining's binary_logloss: 0.58765\n",
      "[367]\ttraining's binary_logloss: 0.587608\n",
      "[368]\ttraining's binary_logloss: 0.587554\n",
      "[369]\ttraining's binary_logloss: 0.58751\n",
      "[370]\ttraining's binary_logloss: 0.587463\n",
      "[371]\ttraining's binary_logloss: 0.587397\n",
      "[372]\ttraining's binary_logloss: 0.587335\n",
      "[373]\ttraining's binary_logloss: 0.587275\n",
      "[374]\ttraining's binary_logloss: 0.587209\n",
      "[375]\ttraining's binary_logloss: 0.587157\n",
      "[376]\ttraining's binary_logloss: 0.587107\n",
      "[377]\ttraining's binary_logloss: 0.587056\n",
      "[378]\ttraining's binary_logloss: 0.587009\n",
      "[379]\ttraining's binary_logloss: 0.586962\n",
      "[380]\ttraining's binary_logloss: 0.586916\n",
      "[381]\ttraining's binary_logloss: 0.586839\n",
      "[382]\ttraining's binary_logloss: 0.586751\n",
      "[383]\ttraining's binary_logloss: 0.586671\n",
      "[384]\ttraining's binary_logloss: 0.586584\n",
      "[385]\ttraining's binary_logloss: 0.5865\n",
      "[386]\ttraining's binary_logloss: 0.586422\n",
      "[387]\ttraining's binary_logloss: 0.58635\n",
      "[388]\ttraining's binary_logloss: 0.586275\n",
      "[389]\ttraining's binary_logloss: 0.586205\n",
      "[390]\ttraining's binary_logloss: 0.586134\n",
      "[391]\ttraining's binary_logloss: 0.586068\n",
      "[392]\ttraining's binary_logloss: 0.585997\n",
      "[393]\ttraining's binary_logloss: 0.585934\n",
      "[394]\ttraining's binary_logloss: 0.585867\n",
      "[395]\ttraining's binary_logloss: 0.585791\n",
      "[396]\ttraining's binary_logloss: 0.585758\n",
      "[397]\ttraining's binary_logloss: 0.585725\n",
      "[398]\ttraining's binary_logloss: 0.585673\n",
      "[399]\ttraining's binary_logloss: 0.58564\n",
      "[400]\ttraining's binary_logloss: 0.585587\n",
      "[401]\ttraining's binary_logloss: 0.585541\n",
      "[402]\ttraining's binary_logloss: 0.585484\n",
      "[403]\ttraining's binary_logloss: 0.585428\n",
      "[404]\ttraining's binary_logloss: 0.58538\n",
      "[405]\ttraining's binary_logloss: 0.585333\n",
      "[406]\ttraining's binary_logloss: 0.585266\n",
      "[407]\ttraining's binary_logloss: 0.585197\n",
      "[408]\ttraining's binary_logloss: 0.585131\n",
      "[409]\ttraining's binary_logloss: 0.585097\n",
      "[410]\ttraining's binary_logloss: 0.585066\n",
      "[411]\ttraining's binary_logloss: 0.584997\n",
      "[412]\ttraining's binary_logloss: 0.584931\n",
      "[413]\ttraining's binary_logloss: 0.584865\n",
      "[414]\ttraining's binary_logloss: 0.5848\n",
      "[415]\ttraining's binary_logloss: 0.584733\n",
      "[416]\ttraining's binary_logloss: 0.584676\n",
      "[417]\ttraining's binary_logloss: 0.584616\n",
      "[418]\ttraining's binary_logloss: 0.584568\n",
      "[419]\ttraining's binary_logloss: 0.584509\n",
      "[420]\ttraining's binary_logloss: 0.584448\n",
      "[421]\ttraining's binary_logloss: 0.584409\n",
      "[422]\ttraining's binary_logloss: 0.584373\n",
      "[423]\ttraining's binary_logloss: 0.584331\n",
      "[424]\ttraining's binary_logloss: 0.584292\n",
      "[425]\ttraining's binary_logloss: 0.584248\n",
      "[426]\ttraining's binary_logloss: 0.584187\n",
      "[427]\ttraining's binary_logloss: 0.584138\n",
      "[428]\ttraining's binary_logloss: 0.584092\n",
      "[429]\ttraining's binary_logloss: 0.58405\n",
      "[430]\ttraining's binary_logloss: 0.584004\n",
      "[431]\ttraining's binary_logloss: 0.583938\n",
      "[432]\ttraining's binary_logloss: 0.583873\n",
      "[433]\ttraining's binary_logloss: 0.583804\n",
      "[434]\ttraining's binary_logloss: 0.583742\n",
      "[435]\ttraining's binary_logloss: 0.583682\n",
      "[436]\ttraining's binary_logloss: 0.583624\n",
      "[437]\ttraining's binary_logloss: 0.583566\n",
      "[438]\ttraining's binary_logloss: 0.58351\n",
      "[439]\ttraining's binary_logloss: 0.58347\n",
      "[440]\ttraining's binary_logloss: 0.583433\n",
      "[441]\ttraining's binary_logloss: 0.583383\n",
      "[442]\ttraining's binary_logloss: 0.583327\n",
      "[443]\ttraining's binary_logloss: 0.583279\n",
      "[444]\ttraining's binary_logloss: 0.583228\n",
      "[445]\ttraining's binary_logloss: 0.583182\n",
      "[446]\ttraining's binary_logloss: 0.583085\n",
      "[447]\ttraining's binary_logloss: 0.582998\n",
      "[448]\ttraining's binary_logloss: 0.582905\n",
      "[449]\ttraining's binary_logloss: 0.582822\n",
      "[450]\ttraining's binary_logloss: 0.582745\n",
      "[451]\ttraining's binary_logloss: 0.582674\n",
      "[452]\ttraining's binary_logloss: 0.582604\n",
      "[453]\ttraining's binary_logloss: 0.582536\n",
      "[454]\ttraining's binary_logloss: 0.58247\n",
      "[455]\ttraining's binary_logloss: 0.582397\n",
      "[456]\ttraining's binary_logloss: 0.582324\n",
      "[457]\ttraining's binary_logloss: 0.58227\n",
      "[458]\ttraining's binary_logloss: 0.582194\n",
      "[459]\ttraining's binary_logloss: 0.58214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[460]\ttraining's binary_logloss: 0.582085\n",
      "[461]\ttraining's binary_logloss: 0.58202\n",
      "[462]\ttraining's binary_logloss: 0.581957\n",
      "[463]\ttraining's binary_logloss: 0.581895\n",
      "[464]\ttraining's binary_logloss: 0.581834\n",
      "[465]\ttraining's binary_logloss: 0.581776\n",
      "[466]\ttraining's binary_logloss: 0.581718\n",
      "[467]\ttraining's binary_logloss: 0.581659\n",
      "[468]\ttraining's binary_logloss: 0.581601\n",
      "[469]\ttraining's binary_logloss: 0.58155\n",
      "[470]\ttraining's binary_logloss: 0.581499\n",
      "[471]\ttraining's binary_logloss: 0.581416\n",
      "[472]\ttraining's binary_logloss: 0.581336\n",
      "[473]\ttraining's binary_logloss: 0.581257\n",
      "[474]\ttraining's binary_logloss: 0.58118\n",
      "[475]\ttraining's binary_logloss: 0.581105\n",
      "[476]\ttraining's binary_logloss: 0.581034\n",
      "[477]\ttraining's binary_logloss: 0.580982\n",
      "[478]\ttraining's binary_logloss: 0.58094\n",
      "[479]\ttraining's binary_logloss: 0.580907\n",
      "[480]\ttraining's binary_logloss: 0.58088\n",
      "[481]\ttraining's binary_logloss: 0.580852\n",
      "[482]\ttraining's binary_logloss: 0.580808\n",
      "[483]\ttraining's binary_logloss: 0.580779\n",
      "[484]\ttraining's binary_logloss: 0.580745\n",
      "[485]\ttraining's binary_logloss: 0.580713\n",
      "[486]\ttraining's binary_logloss: 0.580637\n",
      "[487]\ttraining's binary_logloss: 0.580558\n",
      "[488]\ttraining's binary_logloss: 0.580483\n",
      "[489]\ttraining's binary_logloss: 0.580398\n",
      "[490]\ttraining's binary_logloss: 0.580312\n",
      "[491]\ttraining's binary_logloss: 0.580226\n",
      "[492]\ttraining's binary_logloss: 0.580141\n",
      "[493]\ttraining's binary_logloss: 0.580057\n",
      "[494]\ttraining's binary_logloss: 0.579979\n",
      "[495]\ttraining's binary_logloss: 0.579899\n",
      "[496]\ttraining's binary_logloss: 0.579839\n",
      "[497]\ttraining's binary_logloss: 0.579781\n",
      "[498]\ttraining's binary_logloss: 0.579724\n",
      "[499]\ttraining's binary_logloss: 0.579668\n",
      "[500]\ttraining's binary_logloss: 0.579602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614407\n",
      "[2]\ttraining's binary_logloss: 0.613077\n",
      "[3]\ttraining's binary_logloss: 0.611914\n",
      "[4]\ttraining's binary_logloss: 0.610788\n",
      "[5]\ttraining's binary_logloss: 0.609783\n",
      "[6]\ttraining's binary_logloss: 0.608564\n",
      "[7]\ttraining's binary_logloss: 0.607422\n",
      "[8]\ttraining's binary_logloss: 0.606367\n",
      "[9]\ttraining's binary_logloss: 0.605378\n",
      "[10]\ttraining's binary_logloss: 0.604372\n",
      "[11]\ttraining's binary_logloss: 0.603446\n",
      "[12]\ttraining's binary_logloss: 0.602508\n",
      "[13]\ttraining's binary_logloss: 0.601629\n",
      "[14]\ttraining's binary_logloss: 0.600757\n",
      "[15]\ttraining's binary_logloss: 0.599996\n",
      "[16]\ttraining's binary_logloss: 0.599196\n",
      "[17]\ttraining's binary_logloss: 0.598403\n",
      "[18]\ttraining's binary_logloss: 0.597633\n",
      "[19]\ttraining's binary_logloss: 0.596878\n",
      "[20]\ttraining's binary_logloss: 0.596249\n",
      "[21]\ttraining's binary_logloss: 0.595585\n",
      "[22]\ttraining's binary_logloss: 0.59499\n",
      "[23]\ttraining's binary_logloss: 0.594381\n",
      "[24]\ttraining's binary_logloss: 0.593807\n",
      "[25]\ttraining's binary_logloss: 0.593268\n",
      "[26]\ttraining's binary_logloss: 0.592625\n",
      "[27]\ttraining's binary_logloss: 0.592017\n",
      "[28]\ttraining's binary_logloss: 0.591404\n",
      "[29]\ttraining's binary_logloss: 0.590832\n",
      "[30]\ttraining's binary_logloss: 0.590295\n",
      "[31]\ttraining's binary_logloss: 0.589779\n",
      "[32]\ttraining's binary_logloss: 0.589233\n",
      "[33]\ttraining's binary_logloss: 0.588701\n",
      "[34]\ttraining's binary_logloss: 0.58817\n",
      "[35]\ttraining's binary_logloss: 0.587677\n",
      "[36]\ttraining's binary_logloss: 0.587283\n",
      "[37]\ttraining's binary_logloss: 0.586836\n",
      "[38]\ttraining's binary_logloss: 0.586439\n",
      "[39]\ttraining's binary_logloss: 0.586036\n",
      "[40]\ttraining's binary_logloss: 0.585644\n",
      "[41]\ttraining's binary_logloss: 0.58529\n",
      "[42]\ttraining's binary_logloss: 0.58489\n",
      "[43]\ttraining's binary_logloss: 0.5845\n",
      "[44]\ttraining's binary_logloss: 0.584181\n",
      "[45]\ttraining's binary_logloss: 0.58382\n",
      "[46]\ttraining's binary_logloss: 0.583502\n",
      "[47]\ttraining's binary_logloss: 0.583183\n",
      "[48]\ttraining's binary_logloss: 0.582831\n",
      "[49]\ttraining's binary_logloss: 0.582514\n",
      "[50]\ttraining's binary_logloss: 0.582236\n",
      "[51]\ttraining's binary_logloss: 0.581938\n",
      "[52]\ttraining's binary_logloss: 0.581683\n",
      "[53]\ttraining's binary_logloss: 0.58144\n",
      "[54]\ttraining's binary_logloss: 0.581178\n",
      "[55]\ttraining's binary_logloss: 0.580929\n",
      "[56]\ttraining's binary_logloss: 0.580639\n",
      "[57]\ttraining's binary_logloss: 0.58036\n",
      "[58]\ttraining's binary_logloss: 0.580104\n",
      "[59]\ttraining's binary_logloss: 0.579899\n",
      "[60]\ttraining's binary_logloss: 0.579648\n",
      "[61]\ttraining's binary_logloss: 0.579436\n",
      "[62]\ttraining's binary_logloss: 0.579224\n",
      "[63]\ttraining's binary_logloss: 0.579068\n",
      "[64]\ttraining's binary_logloss: 0.578918\n",
      "[65]\ttraining's binary_logloss: 0.578757\n",
      "[66]\ttraining's binary_logloss: 0.578591\n",
      "[67]\ttraining's binary_logloss: 0.578424\n",
      "[68]\ttraining's binary_logloss: 0.578281\n",
      "[69]\ttraining's binary_logloss: 0.578097\n",
      "[70]\ttraining's binary_logloss: 0.577971\n",
      "[71]\ttraining's binary_logloss: 0.57778\n",
      "[72]\ttraining's binary_logloss: 0.577625\n",
      "[73]\ttraining's binary_logloss: 0.577475\n",
      "[74]\ttraining's binary_logloss: 0.577357\n",
      "[75]\ttraining's binary_logloss: 0.577244\n",
      "[76]\ttraining's binary_logloss: 0.577121\n",
      "[77]\ttraining's binary_logloss: 0.577064\n",
      "[78]\ttraining's binary_logloss: 0.576982\n",
      "[79]\ttraining's binary_logloss: 0.576874\n",
      "[80]\ttraining's binary_logloss: 0.576786\n",
      "[81]\ttraining's binary_logloss: 0.576738\n",
      "[82]\ttraining's binary_logloss: 0.576617\n",
      "[83]\ttraining's binary_logloss: 0.576491\n",
      "[84]\ttraining's binary_logloss: 0.576382\n",
      "[85]\ttraining's binary_logloss: 0.576255\n",
      "[86]\ttraining's binary_logloss: 0.576163\n",
      "[87]\ttraining's binary_logloss: 0.576037\n",
      "[88]\ttraining's binary_logloss: 0.575916\n",
      "[89]\ttraining's binary_logloss: 0.575818\n",
      "[90]\ttraining's binary_logloss: 0.57571\n",
      "[91]\ttraining's binary_logloss: 0.575651\n",
      "[92]\ttraining's binary_logloss: 0.575605\n",
      "[93]\ttraining's binary_logloss: 0.575512\n",
      "[94]\ttraining's binary_logloss: 0.575441\n",
      "[95]\ttraining's binary_logloss: 0.575371\n",
      "[96]\ttraining's binary_logloss: 0.575286\n",
      "[97]\ttraining's binary_logloss: 0.575195\n",
      "[98]\ttraining's binary_logloss: 0.575114\n",
      "[99]\ttraining's binary_logloss: 0.575039\n",
      "[100]\ttraining's binary_logloss: 0.574967\n",
      "[101]\ttraining's binary_logloss: 0.574847\n",
      "[102]\ttraining's binary_logloss: 0.574771\n",
      "[103]\ttraining's binary_logloss: 0.574718\n",
      "[104]\ttraining's binary_logloss: 0.574602\n",
      "[105]\ttraining's binary_logloss: 0.574508\n",
      "[106]\ttraining's binary_logloss: 0.574463\n",
      "[107]\ttraining's binary_logloss: 0.57444\n",
      "[108]\ttraining's binary_logloss: 0.574403\n",
      "[109]\ttraining's binary_logloss: 0.57438\n",
      "[110]\ttraining's binary_logloss: 0.574374\n",
      "[111]\ttraining's binary_logloss: 0.574301\n",
      "[112]\ttraining's binary_logloss: 0.574192\n",
      "[113]\ttraining's binary_logloss: 0.574102\n",
      "[114]\ttraining's binary_logloss: 0.574041\n",
      "[115]\ttraining's binary_logloss: 0.573954\n",
      "[116]\ttraining's binary_logloss: 0.573878\n",
      "[117]\ttraining's binary_logloss: 0.573803\n",
      "[118]\ttraining's binary_logloss: 0.573741\n",
      "[119]\ttraining's binary_logloss: 0.573712\n",
      "[120]\ttraining's binary_logloss: 0.573685\n",
      "[121]\ttraining's binary_logloss: 0.573621\n",
      "[122]\ttraining's binary_logloss: 0.573568\n",
      "[123]\ttraining's binary_logloss: 0.573516\n",
      "[124]\ttraining's binary_logloss: 0.573484\n",
      "[125]\ttraining's binary_logloss: 0.573437\n",
      "[126]\ttraining's binary_logloss: 0.573363\n",
      "[127]\ttraining's binary_logloss: 0.573301\n",
      "[128]\ttraining's binary_logloss: 0.573241\n",
      "[129]\ttraining's binary_logloss: 0.573162\n",
      "[130]\ttraining's binary_logloss: 0.573118\n",
      "[131]\ttraining's binary_logloss: 0.573117\n",
      "[132]\ttraining's binary_logloss: 0.573056\n",
      "[133]\ttraining's binary_logloss: 0.573059\n",
      "[134]\ttraining's binary_logloss: 0.573034\n",
      "[135]\ttraining's binary_logloss: 0.573036\n",
      "[136]\ttraining's binary_logloss: 0.573005\n",
      "[137]\ttraining's binary_logloss: 0.57298\n",
      "[138]\ttraining's binary_logloss: 0.572921\n",
      "[139]\ttraining's binary_logloss: 0.572908\n",
      "[140]\ttraining's binary_logloss: 0.572873\n",
      "[141]\ttraining's binary_logloss: 0.572827\n",
      "[142]\ttraining's binary_logloss: 0.572802\n",
      "[143]\ttraining's binary_logloss: 0.572768\n",
      "[144]\ttraining's binary_logloss: 0.572724\n",
      "[145]\ttraining's binary_logloss: 0.572716\n",
      "[146]\ttraining's binary_logloss: 0.572679\n",
      "[147]\ttraining's binary_logloss: 0.57264\n",
      "[148]\ttraining's binary_logloss: 0.572585\n",
      "[149]\ttraining's binary_logloss: 0.572568\n",
      "[150]\ttraining's binary_logloss: 0.572552\n",
      "[151]\ttraining's binary_logloss: 0.572519\n",
      "[152]\ttraining's binary_logloss: 0.572498\n",
      "[153]\ttraining's binary_logloss: 0.57246\n",
      "[154]\ttraining's binary_logloss: 0.572437\n",
      "[155]\ttraining's binary_logloss: 0.572384\n",
      "[156]\ttraining's binary_logloss: 0.572338\n",
      "[157]\ttraining's binary_logloss: 0.572275\n",
      "[158]\ttraining's binary_logloss: 0.572252\n",
      "[159]\ttraining's binary_logloss: 0.572221\n",
      "[160]\ttraining's binary_logloss: 0.572165\n",
      "[161]\ttraining's binary_logloss: 0.57212\n",
      "[162]\ttraining's binary_logloss: 0.572042\n",
      "[163]\ttraining's binary_logloss: 0.571969\n",
      "[164]\ttraining's binary_logloss: 0.571897\n",
      "[165]\ttraining's binary_logloss: 0.571874\n",
      "[166]\ttraining's binary_logloss: 0.571778\n",
      "[167]\ttraining's binary_logloss: 0.571739\n",
      "[168]\ttraining's binary_logloss: 0.571665\n",
      "[169]\ttraining's binary_logloss: 0.5716\n",
      "[170]\ttraining's binary_logloss: 0.571565\n",
      "[171]\ttraining's binary_logloss: 0.571519\n",
      "[172]\ttraining's binary_logloss: 0.571491\n",
      "[173]\ttraining's binary_logloss: 0.571448\n",
      "[174]\ttraining's binary_logloss: 0.571427\n",
      "[175]\ttraining's binary_logloss: 0.571391\n",
      "[176]\ttraining's binary_logloss: 0.571332\n",
      "[177]\ttraining's binary_logloss: 0.57127\n",
      "[178]\ttraining's binary_logloss: 0.571215\n",
      "[179]\ttraining's binary_logloss: 0.571169\n",
      "[180]\ttraining's binary_logloss: 0.571117\n",
      "[181]\ttraining's binary_logloss: 0.571066\n",
      "[182]\ttraining's binary_logloss: 0.570992\n",
      "[183]\ttraining's binary_logloss: 0.570948\n",
      "[184]\ttraining's binary_logloss: 0.570873\n",
      "[185]\ttraining's binary_logloss: 0.570799\n",
      "[186]\ttraining's binary_logloss: 0.570782\n",
      "[187]\ttraining's binary_logloss: 0.570765\n",
      "[188]\ttraining's binary_logloss: 0.570727\n",
      "[189]\ttraining's binary_logloss: 0.570717\n",
      "[190]\ttraining's binary_logloss: 0.570713\n",
      "[191]\ttraining's binary_logloss: 0.570664\n",
      "[192]\ttraining's binary_logloss: 0.570615\n",
      "[193]\ttraining's binary_logloss: 0.570538\n",
      "[194]\ttraining's binary_logloss: 0.570484\n",
      "[195]\ttraining's binary_logloss: 0.570414\n",
      "[196]\ttraining's binary_logloss: 0.570366\n",
      "[197]\ttraining's binary_logloss: 0.570328\n",
      "[198]\ttraining's binary_logloss: 0.570279\n",
      "[199]\ttraining's binary_logloss: 0.570225\n",
      "[200]\ttraining's binary_logloss: 0.570159\n",
      "[201]\ttraining's binary_logloss: 0.570127\n",
      "[202]\ttraining's binary_logloss: 0.570103\n",
      "[203]\ttraining's binary_logloss: 0.570064\n",
      "[204]\ttraining's binary_logloss: 0.570059\n",
      "[205]\ttraining's binary_logloss: 0.57002\n",
      "[206]\ttraining's binary_logloss: 0.569947\n",
      "[207]\ttraining's binary_logloss: 0.569858\n",
      "[208]\ttraining's binary_logloss: 0.569765\n",
      "[209]\ttraining's binary_logloss: 0.56967\n",
      "[210]\ttraining's binary_logloss: 0.569583\n",
      "[211]\ttraining's binary_logloss: 0.569543\n",
      "[212]\ttraining's binary_logloss: 0.569516\n",
      "[213]\ttraining's binary_logloss: 0.569479\n",
      "[214]\ttraining's binary_logloss: 0.569457\n",
      "[215]\ttraining's binary_logloss: 0.569428\n",
      "[216]\ttraining's binary_logloss: 0.569342\n",
      "[217]\ttraining's binary_logloss: 0.569268\n",
      "[218]\ttraining's binary_logloss: 0.569182\n",
      "[219]\ttraining's binary_logloss: 0.569108\n",
      "[220]\ttraining's binary_logloss: 0.569031\n",
      "[221]\ttraining's binary_logloss: 0.568973\n",
      "[222]\ttraining's binary_logloss: 0.568876\n",
      "[223]\ttraining's binary_logloss: 0.568812\n",
      "[224]\ttraining's binary_logloss: 0.568706\n",
      "[225]\ttraining's binary_logloss: 0.568646\n",
      "[226]\ttraining's binary_logloss: 0.568539\n",
      "[227]\ttraining's binary_logloss: 0.56844\n",
      "[228]\ttraining's binary_logloss: 0.568357\n",
      "[229]\ttraining's binary_logloss: 0.568299\n",
      "[230]\ttraining's binary_logloss: 0.568198\n",
      "[231]\ttraining's binary_logloss: 0.568156\n",
      "[232]\ttraining's binary_logloss: 0.568095\n",
      "[233]\ttraining's binary_logloss: 0.568041\n",
      "[234]\ttraining's binary_logloss: 0.567976\n",
      "[235]\ttraining's binary_logloss: 0.567899\n",
      "[236]\ttraining's binary_logloss: 0.567831\n",
      "[237]\ttraining's binary_logloss: 0.567732\n",
      "[238]\ttraining's binary_logloss: 0.567642\n",
      "[239]\ttraining's binary_logloss: 0.567556\n",
      "[240]\ttraining's binary_logloss: 0.567464\n",
      "[241]\ttraining's binary_logloss: 0.567391\n",
      "[242]\ttraining's binary_logloss: 0.567342\n",
      "[243]\ttraining's binary_logloss: 0.567292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[244]\ttraining's binary_logloss: 0.567242\n",
      "[245]\ttraining's binary_logloss: 0.567176\n",
      "[246]\ttraining's binary_logloss: 0.567033\n",
      "[247]\ttraining's binary_logloss: 0.566916\n",
      "[248]\ttraining's binary_logloss: 0.566787\n",
      "[249]\ttraining's binary_logloss: 0.566674\n",
      "[250]\ttraining's binary_logloss: 0.566565\n",
      "[251]\ttraining's binary_logloss: 0.566435\n",
      "[252]\ttraining's binary_logloss: 0.566358\n",
      "[253]\ttraining's binary_logloss: 0.566286\n",
      "[254]\ttraining's binary_logloss: 0.566157\n",
      "[255]\ttraining's binary_logloss: 0.566034\n",
      "[256]\ttraining's binary_logloss: 0.565959\n",
      "[257]\ttraining's binary_logloss: 0.565884\n",
      "[258]\ttraining's binary_logloss: 0.565804\n",
      "[259]\ttraining's binary_logloss: 0.565731\n",
      "[260]\ttraining's binary_logloss: 0.565649\n",
      "[261]\ttraining's binary_logloss: 0.565568\n",
      "[262]\ttraining's binary_logloss: 0.5655\n",
      "[263]\ttraining's binary_logloss: 0.56544\n",
      "[264]\ttraining's binary_logloss: 0.565361\n",
      "[265]\ttraining's binary_logloss: 0.565291\n",
      "[266]\ttraining's binary_logloss: 0.565239\n",
      "[267]\ttraining's binary_logloss: 0.565192\n",
      "[268]\ttraining's binary_logloss: 0.565157\n",
      "[269]\ttraining's binary_logloss: 0.56512\n",
      "[270]\ttraining's binary_logloss: 0.565085\n",
      "[271]\ttraining's binary_logloss: 0.565041\n",
      "[272]\ttraining's binary_logloss: 0.564971\n",
      "[273]\ttraining's binary_logloss: 0.564888\n",
      "[274]\ttraining's binary_logloss: 0.564813\n",
      "[275]\ttraining's binary_logloss: 0.564761\n",
      "[276]\ttraining's binary_logloss: 0.564685\n",
      "[277]\ttraining's binary_logloss: 0.564611\n",
      "[278]\ttraining's binary_logloss: 0.564543\n",
      "[279]\ttraining's binary_logloss: 0.564473\n",
      "[280]\ttraining's binary_logloss: 0.564405\n",
      "[281]\ttraining's binary_logloss: 0.564345\n",
      "[282]\ttraining's binary_logloss: 0.564303\n",
      "[283]\ttraining's binary_logloss: 0.564235\n",
      "[284]\ttraining's binary_logloss: 0.56418\n",
      "[285]\ttraining's binary_logloss: 0.56413\n",
      "[286]\ttraining's binary_logloss: 0.564033\n",
      "[287]\ttraining's binary_logloss: 0.563935\n",
      "[288]\ttraining's binary_logloss: 0.563872\n",
      "[289]\ttraining's binary_logloss: 0.563771\n",
      "[290]\ttraining's binary_logloss: 0.563682\n",
      "[291]\ttraining's binary_logloss: 0.563541\n",
      "[292]\ttraining's binary_logloss: 0.563407\n",
      "[293]\ttraining's binary_logloss: 0.563278\n",
      "[294]\ttraining's binary_logloss: 0.563177\n",
      "[295]\ttraining's binary_logloss: 0.563043\n",
      "[296]\ttraining's binary_logloss: 0.562952\n",
      "[297]\ttraining's binary_logloss: 0.562862\n",
      "[298]\ttraining's binary_logloss: 0.562774\n",
      "[299]\ttraining's binary_logloss: 0.562688\n",
      "[300]\ttraining's binary_logloss: 0.562605\n",
      "[301]\ttraining's binary_logloss: 0.562494\n",
      "[302]\ttraining's binary_logloss: 0.562395\n",
      "[303]\ttraining's binary_logloss: 0.562316\n",
      "[304]\ttraining's binary_logloss: 0.562206\n",
      "[305]\ttraining's binary_logloss: 0.562117\n",
      "[306]\ttraining's binary_logloss: 0.562015\n",
      "[307]\ttraining's binary_logloss: 0.561918\n",
      "[308]\ttraining's binary_logloss: 0.561826\n",
      "[309]\ttraining's binary_logloss: 0.561742\n",
      "[310]\ttraining's binary_logloss: 0.561639\n",
      "[311]\ttraining's binary_logloss: 0.561532\n",
      "[312]\ttraining's binary_logloss: 0.561433\n",
      "[313]\ttraining's binary_logloss: 0.561289\n",
      "[314]\ttraining's binary_logloss: 0.561184\n",
      "[315]\ttraining's binary_logloss: 0.561068\n",
      "[316]\ttraining's binary_logloss: 0.560971\n",
      "[317]\ttraining's binary_logloss: 0.560863\n",
      "[318]\ttraining's binary_logloss: 0.560766\n",
      "[319]\ttraining's binary_logloss: 0.560661\n",
      "[320]\ttraining's binary_logloss: 0.560546\n",
      "[321]\ttraining's binary_logloss: 0.560469\n",
      "[322]\ttraining's binary_logloss: 0.560383\n",
      "[323]\ttraining's binary_logloss: 0.560296\n",
      "[324]\ttraining's binary_logloss: 0.560209\n",
      "[325]\ttraining's binary_logloss: 0.560127\n",
      "[326]\ttraining's binary_logloss: 0.559991\n",
      "[327]\ttraining's binary_logloss: 0.559854\n",
      "[328]\ttraining's binary_logloss: 0.559755\n",
      "[329]\ttraining's binary_logloss: 0.559635\n",
      "[330]\ttraining's binary_logloss: 0.559532\n",
      "[331]\ttraining's binary_logloss: 0.559441\n",
      "[332]\ttraining's binary_logloss: 0.559344\n",
      "[333]\ttraining's binary_logloss: 0.559257\n",
      "[334]\ttraining's binary_logloss: 0.559163\n",
      "[335]\ttraining's binary_logloss: 0.559078\n",
      "[336]\ttraining's binary_logloss: 0.559006\n",
      "[337]\ttraining's binary_logloss: 0.558935\n",
      "[338]\ttraining's binary_logloss: 0.558863\n",
      "[339]\ttraining's binary_logloss: 0.558789\n",
      "[340]\ttraining's binary_logloss: 0.55871\n",
      "[341]\ttraining's binary_logloss: 0.558635\n",
      "[342]\ttraining's binary_logloss: 0.558554\n",
      "[343]\ttraining's binary_logloss: 0.558491\n",
      "[344]\ttraining's binary_logloss: 0.558413\n",
      "[345]\ttraining's binary_logloss: 0.558356\n",
      "[346]\ttraining's binary_logloss: 0.558232\n",
      "[347]\ttraining's binary_logloss: 0.55811\n",
      "[348]\ttraining's binary_logloss: 0.557995\n",
      "[349]\ttraining's binary_logloss: 0.557867\n",
      "[350]\ttraining's binary_logloss: 0.557743\n",
      "[351]\ttraining's binary_logloss: 0.557658\n",
      "[352]\ttraining's binary_logloss: 0.557586\n",
      "[353]\ttraining's binary_logloss: 0.557518\n",
      "[354]\ttraining's binary_logloss: 0.557448\n",
      "[355]\ttraining's binary_logloss: 0.557369\n",
      "[356]\ttraining's binary_logloss: 0.557268\n",
      "[357]\ttraining's binary_logloss: 0.557164\n",
      "[358]\ttraining's binary_logloss: 0.557067\n",
      "[359]\ttraining's binary_logloss: 0.556984\n",
      "[360]\ttraining's binary_logloss: 0.556894\n",
      "[361]\ttraining's binary_logloss: 0.556782\n",
      "[362]\ttraining's binary_logloss: 0.556687\n",
      "[363]\ttraining's binary_logloss: 0.556547\n",
      "[364]\ttraining's binary_logloss: 0.556448\n",
      "[365]\ttraining's binary_logloss: 0.556321\n",
      "[366]\ttraining's binary_logloss: 0.556216\n",
      "[367]\ttraining's binary_logloss: 0.556117\n",
      "[368]\ttraining's binary_logloss: 0.556017\n",
      "[369]\ttraining's binary_logloss: 0.555919\n",
      "[370]\ttraining's binary_logloss: 0.555821\n",
      "[371]\ttraining's binary_logloss: 0.555723\n",
      "[372]\ttraining's binary_logloss: 0.555626\n",
      "[373]\ttraining's binary_logloss: 0.555532\n",
      "[374]\ttraining's binary_logloss: 0.555435\n",
      "[375]\ttraining's binary_logloss: 0.555317\n",
      "[376]\ttraining's binary_logloss: 0.555215\n",
      "[377]\ttraining's binary_logloss: 0.555109\n",
      "[378]\ttraining's binary_logloss: 0.555013\n",
      "[379]\ttraining's binary_logloss: 0.55491\n",
      "[380]\ttraining's binary_logloss: 0.554811\n",
      "[381]\ttraining's binary_logloss: 0.554667\n",
      "[382]\ttraining's binary_logloss: 0.554547\n",
      "[383]\ttraining's binary_logloss: 0.554426\n",
      "[384]\ttraining's binary_logloss: 0.554306\n",
      "[385]\ttraining's binary_logloss: 0.554187\n",
      "[386]\ttraining's binary_logloss: 0.554061\n",
      "[387]\ttraining's binary_logloss: 0.553939\n",
      "[388]\ttraining's binary_logloss: 0.553828\n",
      "[389]\ttraining's binary_logloss: 0.553699\n",
      "[390]\ttraining's binary_logloss: 0.553586\n",
      "[391]\ttraining's binary_logloss: 0.553456\n",
      "[392]\ttraining's binary_logloss: 0.55333\n",
      "[393]\ttraining's binary_logloss: 0.553202\n",
      "[394]\ttraining's binary_logloss: 0.553075\n",
      "[395]\ttraining's binary_logloss: 0.552946\n",
      "[396]\ttraining's binary_logloss: 0.552869\n",
      "[397]\ttraining's binary_logloss: 0.552794\n",
      "[398]\ttraining's binary_logloss: 0.552725\n",
      "[399]\ttraining's binary_logloss: 0.552647\n",
      "[400]\ttraining's binary_logloss: 0.552574\n",
      "[401]\ttraining's binary_logloss: 0.55247\n",
      "[402]\ttraining's binary_logloss: 0.55235\n",
      "[403]\ttraining's binary_logloss: 0.552232\n",
      "[404]\ttraining's binary_logloss: 0.552122\n",
      "[405]\ttraining's binary_logloss: 0.552011\n",
      "[406]\ttraining's binary_logloss: 0.551914\n",
      "[407]\ttraining's binary_logloss: 0.551817\n",
      "[408]\ttraining's binary_logloss: 0.551728\n",
      "[409]\ttraining's binary_logloss: 0.551635\n",
      "[410]\ttraining's binary_logloss: 0.551542\n",
      "[411]\ttraining's binary_logloss: 0.55143\n",
      "[412]\ttraining's binary_logloss: 0.551332\n",
      "[413]\ttraining's binary_logloss: 0.551229\n",
      "[414]\ttraining's binary_logloss: 0.551121\n",
      "[415]\ttraining's binary_logloss: 0.551023\n",
      "[416]\ttraining's binary_logloss: 0.550923\n",
      "[417]\ttraining's binary_logloss: 0.550824\n",
      "[418]\ttraining's binary_logloss: 0.550714\n",
      "[419]\ttraining's binary_logloss: 0.550612\n",
      "[420]\ttraining's binary_logloss: 0.550495\n",
      "[421]\ttraining's binary_logloss: 0.550392\n",
      "[422]\ttraining's binary_logloss: 0.550301\n",
      "[423]\ttraining's binary_logloss: 0.550209\n",
      "[424]\ttraining's binary_logloss: 0.550119\n",
      "[425]\ttraining's binary_logloss: 0.550013\n",
      "[426]\ttraining's binary_logloss: 0.549901\n",
      "[427]\ttraining's binary_logloss: 0.5498\n",
      "[428]\ttraining's binary_logloss: 0.549707\n",
      "[429]\ttraining's binary_logloss: 0.549602\n",
      "[430]\ttraining's binary_logloss: 0.549504\n",
      "[431]\ttraining's binary_logloss: 0.549399\n",
      "[432]\ttraining's binary_logloss: 0.549297\n",
      "[433]\ttraining's binary_logloss: 0.549179\n",
      "[434]\ttraining's binary_logloss: 0.54908\n",
      "[435]\ttraining's binary_logloss: 0.548967\n",
      "[436]\ttraining's binary_logloss: 0.548855\n",
      "[437]\ttraining's binary_logloss: 0.548754\n",
      "[438]\ttraining's binary_logloss: 0.548669\n",
      "[439]\ttraining's binary_logloss: 0.548578\n",
      "[440]\ttraining's binary_logloss: 0.548479\n",
      "[441]\ttraining's binary_logloss: 0.548366\n",
      "[442]\ttraining's binary_logloss: 0.548261\n",
      "[443]\ttraining's binary_logloss: 0.548147\n",
      "[444]\ttraining's binary_logloss: 0.548038\n",
      "[445]\ttraining's binary_logloss: 0.547922\n",
      "[446]\ttraining's binary_logloss: 0.547775\n",
      "[447]\ttraining's binary_logloss: 0.54763\n",
      "[448]\ttraining's binary_logloss: 0.547495\n",
      "[449]\ttraining's binary_logloss: 0.547351\n",
      "[450]\ttraining's binary_logloss: 0.547209\n",
      "[451]\ttraining's binary_logloss: 0.547099\n",
      "[452]\ttraining's binary_logloss: 0.546967\n",
      "[453]\ttraining's binary_logloss: 0.546842\n",
      "[454]\ttraining's binary_logloss: 0.546721\n",
      "[455]\ttraining's binary_logloss: 0.546577\n",
      "[456]\ttraining's binary_logloss: 0.546425\n",
      "[457]\ttraining's binary_logloss: 0.546286\n",
      "[458]\ttraining's binary_logloss: 0.546145\n",
      "[459]\ttraining's binary_logloss: 0.546028\n",
      "[460]\ttraining's binary_logloss: 0.545931\n",
      "[461]\ttraining's binary_logloss: 0.545815\n",
      "[462]\ttraining's binary_logloss: 0.545712\n",
      "[463]\ttraining's binary_logloss: 0.545611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[464]\ttraining's binary_logloss: 0.545507\n",
      "[465]\ttraining's binary_logloss: 0.545415\n",
      "[466]\ttraining's binary_logloss: 0.545296\n",
      "[467]\ttraining's binary_logloss: 0.545182\n",
      "[468]\ttraining's binary_logloss: 0.545076\n",
      "[469]\ttraining's binary_logloss: 0.544961\n",
      "[470]\ttraining's binary_logloss: 0.544855\n",
      "[471]\ttraining's binary_logloss: 0.544729\n",
      "[472]\ttraining's binary_logloss: 0.544604\n",
      "[473]\ttraining's binary_logloss: 0.544498\n",
      "[474]\ttraining's binary_logloss: 0.544395\n",
      "[475]\ttraining's binary_logloss: 0.544286\n",
      "[476]\ttraining's binary_logloss: 0.544199\n",
      "[477]\ttraining's binary_logloss: 0.544124\n",
      "[478]\ttraining's binary_logloss: 0.544041\n",
      "[479]\ttraining's binary_logloss: 0.543949\n",
      "[480]\ttraining's binary_logloss: 0.543853\n",
      "[481]\ttraining's binary_logloss: 0.543776\n",
      "[482]\ttraining's binary_logloss: 0.543683\n",
      "[483]\ttraining's binary_logloss: 0.543606\n",
      "[484]\ttraining's binary_logloss: 0.543516\n",
      "[485]\ttraining's binary_logloss: 0.543439\n",
      "[486]\ttraining's binary_logloss: 0.543298\n",
      "[487]\ttraining's binary_logloss: 0.543164\n",
      "[488]\ttraining's binary_logloss: 0.543034\n",
      "[489]\ttraining's binary_logloss: 0.542908\n",
      "[490]\ttraining's binary_logloss: 0.54278\n",
      "[491]\ttraining's binary_logloss: 0.542653\n",
      "[492]\ttraining's binary_logloss: 0.542533\n",
      "[493]\ttraining's binary_logloss: 0.54241\n",
      "[494]\ttraining's binary_logloss: 0.542286\n",
      "[495]\ttraining's binary_logloss: 0.542169\n",
      "[496]\ttraining's binary_logloss: 0.54204\n",
      "[497]\ttraining's binary_logloss: 0.541912\n",
      "[498]\ttraining's binary_logloss: 0.541788\n",
      "[499]\ttraining's binary_logloss: 0.541689\n",
      "[500]\ttraining's binary_logloss: 0.541563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614261\n",
      "[2]\ttraining's binary_logloss: 0.612796\n",
      "[3]\ttraining's binary_logloss: 0.611476\n",
      "[4]\ttraining's binary_logloss: 0.610184\n",
      "[5]\ttraining's binary_logloss: 0.609034\n",
      "[6]\ttraining's binary_logloss: 0.607665\n",
      "[7]\ttraining's binary_logloss: 0.606377\n",
      "[8]\ttraining's binary_logloss: 0.605192\n",
      "[9]\ttraining's binary_logloss: 0.60414\n",
      "[10]\ttraining's binary_logloss: 0.602988\n",
      "[11]\ttraining's binary_logloss: 0.60191\n",
      "[12]\ttraining's binary_logloss: 0.600823\n",
      "[13]\ttraining's binary_logloss: 0.599788\n",
      "[14]\ttraining's binary_logloss: 0.598802\n",
      "[15]\ttraining's binary_logloss: 0.597896\n",
      "[16]\ttraining's binary_logloss: 0.596967\n",
      "[17]\ttraining's binary_logloss: 0.596068\n",
      "[18]\ttraining's binary_logloss: 0.595137\n",
      "[19]\ttraining's binary_logloss: 0.594266\n",
      "[20]\ttraining's binary_logloss: 0.593477\n",
      "[21]\ttraining's binary_logloss: 0.592693\n",
      "[22]\ttraining's binary_logloss: 0.59198\n",
      "[23]\ttraining's binary_logloss: 0.591264\n",
      "[24]\ttraining's binary_logloss: 0.590586\n",
      "[25]\ttraining's binary_logloss: 0.589947\n",
      "[26]\ttraining's binary_logloss: 0.589196\n",
      "[27]\ttraining's binary_logloss: 0.58849\n",
      "[28]\ttraining's binary_logloss: 0.587761\n",
      "[29]\ttraining's binary_logloss: 0.587078\n",
      "[30]\ttraining's binary_logloss: 0.586427\n",
      "[31]\ttraining's binary_logloss: 0.585772\n",
      "[32]\ttraining's binary_logloss: 0.585127\n",
      "[33]\ttraining's binary_logloss: 0.584562\n",
      "[34]\ttraining's binary_logloss: 0.58391\n",
      "[35]\ttraining's binary_logloss: 0.583289\n",
      "[36]\ttraining's binary_logloss: 0.582778\n",
      "[37]\ttraining's binary_logloss: 0.582219\n",
      "[38]\ttraining's binary_logloss: 0.581691\n",
      "[39]\ttraining's binary_logloss: 0.581144\n",
      "[40]\ttraining's binary_logloss: 0.580642\n",
      "[41]\ttraining's binary_logloss: 0.58018\n",
      "[42]\ttraining's binary_logloss: 0.579682\n",
      "[43]\ttraining's binary_logloss: 0.57921\n",
      "[44]\ttraining's binary_logloss: 0.578797\n",
      "[45]\ttraining's binary_logloss: 0.578359\n",
      "[46]\ttraining's binary_logloss: 0.57793\n",
      "[47]\ttraining's binary_logloss: 0.577481\n",
      "[48]\ttraining's binary_logloss: 0.57703\n",
      "[49]\ttraining's binary_logloss: 0.576582\n",
      "[50]\ttraining's binary_logloss: 0.576205\n",
      "[51]\ttraining's binary_logloss: 0.575836\n",
      "[52]\ttraining's binary_logloss: 0.57546\n",
      "[53]\ttraining's binary_logloss: 0.575116\n",
      "[54]\ttraining's binary_logloss: 0.574762\n",
      "[55]\ttraining's binary_logloss: 0.574374\n",
      "[56]\ttraining's binary_logloss: 0.574\n",
      "[57]\ttraining's binary_logloss: 0.573627\n",
      "[58]\ttraining's binary_logloss: 0.573287\n",
      "[59]\ttraining's binary_logloss: 0.572979\n",
      "[60]\ttraining's binary_logloss: 0.572634\n",
      "[61]\ttraining's binary_logloss: 0.572329\n",
      "[62]\ttraining's binary_logloss: 0.572033\n",
      "[63]\ttraining's binary_logloss: 0.571743\n",
      "[64]\ttraining's binary_logloss: 0.571474\n",
      "[65]\ttraining's binary_logloss: 0.571205\n",
      "[66]\ttraining's binary_logloss: 0.570934\n",
      "[67]\ttraining's binary_logloss: 0.570672\n",
      "[68]\ttraining's binary_logloss: 0.570374\n",
      "[69]\ttraining's binary_logloss: 0.570164\n",
      "[70]\ttraining's binary_logloss: 0.569896\n",
      "[71]\ttraining's binary_logloss: 0.569603\n",
      "[72]\ttraining's binary_logloss: 0.569396\n",
      "[73]\ttraining's binary_logloss: 0.569163\n",
      "[74]\ttraining's binary_logloss: 0.568951\n",
      "[75]\ttraining's binary_logloss: 0.568746\n",
      "[76]\ttraining's binary_logloss: 0.56855\n",
      "[77]\ttraining's binary_logloss: 0.568411\n",
      "[78]\ttraining's binary_logloss: 0.568239\n",
      "[79]\ttraining's binary_logloss: 0.568044\n",
      "[80]\ttraining's binary_logloss: 0.567885\n",
      "[81]\ttraining's binary_logloss: 0.56775\n",
      "[82]\ttraining's binary_logloss: 0.567547\n",
      "[83]\ttraining's binary_logloss: 0.567347\n",
      "[84]\ttraining's binary_logloss: 0.56715\n",
      "[85]\ttraining's binary_logloss: 0.566948\n",
      "[86]\ttraining's binary_logloss: 0.566778\n",
      "[87]\ttraining's binary_logloss: 0.566572\n",
      "[88]\ttraining's binary_logloss: 0.566364\n",
      "[89]\ttraining's binary_logloss: 0.566185\n",
      "[90]\ttraining's binary_logloss: 0.565979\n",
      "[91]\ttraining's binary_logloss: 0.565809\n",
      "[92]\ttraining's binary_logloss: 0.565689\n",
      "[93]\ttraining's binary_logloss: 0.565525\n",
      "[94]\ttraining's binary_logloss: 0.565383\n",
      "[95]\ttraining's binary_logloss: 0.565236\n",
      "[96]\ttraining's binary_logloss: 0.565081\n",
      "[97]\ttraining's binary_logloss: 0.564925\n",
      "[98]\ttraining's binary_logloss: 0.564763\n",
      "[99]\ttraining's binary_logloss: 0.564612\n",
      "[100]\ttraining's binary_logloss: 0.564459\n",
      "[101]\ttraining's binary_logloss: 0.564256\n",
      "[102]\ttraining's binary_logloss: 0.564137\n",
      "[103]\ttraining's binary_logloss: 0.563972\n",
      "[104]\ttraining's binary_logloss: 0.563825\n",
      "[105]\ttraining's binary_logloss: 0.563676\n",
      "[106]\ttraining's binary_logloss: 0.56355\n",
      "[107]\ttraining's binary_logloss: 0.563428\n",
      "[108]\ttraining's binary_logloss: 0.563307\n",
      "[109]\ttraining's binary_logloss: 0.563198\n",
      "[110]\ttraining's binary_logloss: 0.563119\n",
      "[111]\ttraining's binary_logloss: 0.562966\n",
      "[112]\ttraining's binary_logloss: 0.562781\n",
      "[113]\ttraining's binary_logloss: 0.562624\n",
      "[114]\ttraining's binary_logloss: 0.562476\n",
      "[115]\ttraining's binary_logloss: 0.5623\n",
      "[116]\ttraining's binary_logloss: 0.562146\n",
      "[117]\ttraining's binary_logloss: 0.561994\n",
      "[118]\ttraining's binary_logloss: 0.561855\n",
      "[119]\ttraining's binary_logloss: 0.561761\n",
      "[120]\ttraining's binary_logloss: 0.56165\n",
      "[121]\ttraining's binary_logloss: 0.561504\n",
      "[122]\ttraining's binary_logloss: 0.561368\n",
      "[123]\ttraining's binary_logloss: 0.56123\n",
      "[124]\ttraining's binary_logloss: 0.561129\n",
      "[125]\ttraining's binary_logloss: 0.561013\n",
      "[126]\ttraining's binary_logloss: 0.560862\n",
      "[127]\ttraining's binary_logloss: 0.560718\n",
      "[128]\ttraining's binary_logloss: 0.560591\n",
      "[129]\ttraining's binary_logloss: 0.56044\n",
      "[130]\ttraining's binary_logloss: 0.560296\n",
      "[131]\ttraining's binary_logloss: 0.560221\n",
      "[132]\ttraining's binary_logloss: 0.560098\n",
      "[133]\ttraining's binary_logloss: 0.560021\n",
      "[134]\ttraining's binary_logloss: 0.559916\n",
      "[135]\ttraining's binary_logloss: 0.55984\n",
      "[136]\ttraining's binary_logloss: 0.559727\n",
      "[137]\ttraining's binary_logloss: 0.559629\n",
      "[138]\ttraining's binary_logloss: 0.559489\n",
      "[139]\ttraining's binary_logloss: 0.559387\n",
      "[140]\ttraining's binary_logloss: 0.559266\n",
      "[141]\ttraining's binary_logloss: 0.559163\n",
      "[142]\ttraining's binary_logloss: 0.559063\n",
      "[143]\ttraining's binary_logloss: 0.558965\n",
      "[144]\ttraining's binary_logloss: 0.558856\n",
      "[145]\ttraining's binary_logloss: 0.558774\n",
      "[146]\ttraining's binary_logloss: 0.558661\n",
      "[147]\ttraining's binary_logloss: 0.55856\n",
      "[148]\ttraining's binary_logloss: 0.558426\n",
      "[149]\ttraining's binary_logloss: 0.55834\n",
      "[150]\ttraining's binary_logloss: 0.558261\n",
      "[151]\ttraining's binary_logloss: 0.558169\n",
      "[152]\ttraining's binary_logloss: 0.558074\n",
      "[153]\ttraining's binary_logloss: 0.557938\n",
      "[154]\ttraining's binary_logloss: 0.557803\n",
      "[155]\ttraining's binary_logloss: 0.5577\n",
      "[156]\ttraining's binary_logloss: 0.557599\n",
      "[157]\ttraining's binary_logloss: 0.557457\n",
      "[158]\ttraining's binary_logloss: 0.557344\n",
      "[159]\ttraining's binary_logloss: 0.557245\n",
      "[160]\ttraining's binary_logloss: 0.557111\n",
      "[161]\ttraining's binary_logloss: 0.557011\n",
      "[162]\ttraining's binary_logloss: 0.55687\n",
      "[163]\ttraining's binary_logloss: 0.556728\n",
      "[164]\ttraining's binary_logloss: 0.556594\n",
      "[165]\ttraining's binary_logloss: 0.556504\n",
      "[166]\ttraining's binary_logloss: 0.556331\n",
      "[167]\ttraining's binary_logloss: 0.556196\n",
      "[168]\ttraining's binary_logloss: 0.556071\n",
      "[169]\ttraining's binary_logloss: 0.555942\n",
      "[170]\ttraining's binary_logloss: 0.555829\n",
      "[171]\ttraining's binary_logloss: 0.555715\n",
      "[172]\ttraining's binary_logloss: 0.555607\n",
      "[173]\ttraining's binary_logloss: 0.555509\n",
      "[174]\ttraining's binary_logloss: 0.555419\n",
      "[175]\ttraining's binary_logloss: 0.555332\n",
      "[176]\ttraining's binary_logloss: 0.555212\n",
      "[177]\ttraining's binary_logloss: 0.555084\n",
      "[178]\ttraining's binary_logloss: 0.554968\n",
      "[179]\ttraining's binary_logloss: 0.554855\n",
      "[180]\ttraining's binary_logloss: 0.554723\n",
      "[181]\ttraining's binary_logloss: 0.554615\n",
      "[182]\ttraining's binary_logloss: 0.554471\n",
      "[183]\ttraining's binary_logloss: 0.554359\n",
      "[184]\ttraining's binary_logloss: 0.554213\n",
      "[185]\ttraining's binary_logloss: 0.554064\n",
      "[186]\ttraining's binary_logloss: 0.553988\n",
      "[187]\ttraining's binary_logloss: 0.5539\n",
      "[188]\ttraining's binary_logloss: 0.553796\n",
      "[189]\ttraining's binary_logloss: 0.553684\n",
      "[190]\ttraining's binary_logloss: 0.553619\n",
      "[191]\ttraining's binary_logloss: 0.553522\n",
      "[192]\ttraining's binary_logloss: 0.553414\n",
      "[193]\ttraining's binary_logloss: 0.553275\n",
      "[194]\ttraining's binary_logloss: 0.553175\n",
      "[195]\ttraining's binary_logloss: 0.553033\n",
      "[196]\ttraining's binary_logloss: 0.552906\n",
      "[197]\ttraining's binary_logloss: 0.55279\n",
      "[198]\ttraining's binary_logloss: 0.552677\n",
      "[199]\ttraining's binary_logloss: 0.552549\n",
      "[200]\ttraining's binary_logloss: 0.552447\n",
      "[201]\ttraining's binary_logloss: 0.552346\n",
      "[202]\ttraining's binary_logloss: 0.552226\n",
      "[203]\ttraining's binary_logloss: 0.552115\n",
      "[204]\ttraining's binary_logloss: 0.552024\n",
      "[205]\ttraining's binary_logloss: 0.551923\n",
      "[206]\ttraining's binary_logloss: 0.551806\n",
      "[207]\ttraining's binary_logloss: 0.551651\n",
      "[208]\ttraining's binary_logloss: 0.551514\n",
      "[209]\ttraining's binary_logloss: 0.551367\n",
      "[210]\ttraining's binary_logloss: 0.55122\n",
      "[211]\ttraining's binary_logloss: 0.551125\n",
      "[212]\ttraining's binary_logloss: 0.551022\n",
      "[213]\ttraining's binary_logloss: 0.550919\n",
      "[214]\ttraining's binary_logloss: 0.550827\n",
      "[215]\ttraining's binary_logloss: 0.550732\n",
      "[216]\ttraining's binary_logloss: 0.550586\n",
      "[217]\ttraining's binary_logloss: 0.550444\n",
      "[218]\ttraining's binary_logloss: 0.550294\n",
      "[219]\ttraining's binary_logloss: 0.550158\n",
      "[220]\ttraining's binary_logloss: 0.550019\n",
      "[221]\ttraining's binary_logloss: 0.549878\n",
      "[222]\ttraining's binary_logloss: 0.549736\n",
      "[223]\ttraining's binary_logloss: 0.549608\n",
      "[224]\ttraining's binary_logloss: 0.54946\n",
      "[225]\ttraining's binary_logloss: 0.549321\n",
      "[226]\ttraining's binary_logloss: 0.54915\n",
      "[227]\ttraining's binary_logloss: 0.548987\n",
      "[228]\ttraining's binary_logloss: 0.548821\n",
      "[229]\ttraining's binary_logloss: 0.548665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[230]\ttraining's binary_logloss: 0.548505\n",
      "[231]\ttraining's binary_logloss: 0.548409\n",
      "[232]\ttraining's binary_logloss: 0.548288\n",
      "[233]\ttraining's binary_logloss: 0.548183\n",
      "[234]\ttraining's binary_logloss: 0.548049\n",
      "[235]\ttraining's binary_logloss: 0.547907\n",
      "[236]\ttraining's binary_logloss: 0.547779\n",
      "[237]\ttraining's binary_logloss: 0.547634\n",
      "[238]\ttraining's binary_logloss: 0.547472\n",
      "[239]\ttraining's binary_logloss: 0.547318\n",
      "[240]\ttraining's binary_logloss: 0.547178\n",
      "[241]\ttraining's binary_logloss: 0.547051\n",
      "[242]\ttraining's binary_logloss: 0.546946\n",
      "[243]\ttraining's binary_logloss: 0.546844\n",
      "[244]\ttraining's binary_logloss: 0.546725\n",
      "[245]\ttraining's binary_logloss: 0.546597\n",
      "[246]\ttraining's binary_logloss: 0.546393\n",
      "[247]\ttraining's binary_logloss: 0.546197\n",
      "[248]\ttraining's binary_logloss: 0.546005\n",
      "[249]\ttraining's binary_logloss: 0.545825\n",
      "[250]\ttraining's binary_logloss: 0.545648\n",
      "[251]\ttraining's binary_logloss: 0.545475\n",
      "[252]\ttraining's binary_logloss: 0.545331\n",
      "[253]\ttraining's binary_logloss: 0.545157\n",
      "[254]\ttraining's binary_logloss: 0.545004\n",
      "[255]\ttraining's binary_logloss: 0.544839\n",
      "[256]\ttraining's binary_logloss: 0.544711\n",
      "[257]\ttraining's binary_logloss: 0.544575\n",
      "[258]\ttraining's binary_logloss: 0.544455\n",
      "[259]\ttraining's binary_logloss: 0.544318\n",
      "[260]\ttraining's binary_logloss: 0.544178\n",
      "[261]\ttraining's binary_logloss: 0.54405\n",
      "[262]\ttraining's binary_logloss: 0.543921\n",
      "[263]\ttraining's binary_logloss: 0.543808\n",
      "[264]\ttraining's binary_logloss: 0.543687\n",
      "[265]\ttraining's binary_logloss: 0.543564\n",
      "[266]\ttraining's binary_logloss: 0.54346\n",
      "[267]\ttraining's binary_logloss: 0.543351\n",
      "[268]\ttraining's binary_logloss: 0.543274\n",
      "[269]\ttraining's binary_logloss: 0.543193\n",
      "[270]\ttraining's binary_logloss: 0.543081\n",
      "[271]\ttraining's binary_logloss: 0.542953\n",
      "[272]\ttraining's binary_logloss: 0.542846\n",
      "[273]\ttraining's binary_logloss: 0.54273\n",
      "[274]\ttraining's binary_logloss: 0.542625\n",
      "[275]\ttraining's binary_logloss: 0.542512\n",
      "[276]\ttraining's binary_logloss: 0.542386\n",
      "[277]\ttraining's binary_logloss: 0.542266\n",
      "[278]\ttraining's binary_logloss: 0.54213\n",
      "[279]\ttraining's binary_logloss: 0.542011\n",
      "[280]\ttraining's binary_logloss: 0.541884\n",
      "[281]\ttraining's binary_logloss: 0.541773\n",
      "[282]\ttraining's binary_logloss: 0.541683\n",
      "[283]\ttraining's binary_logloss: 0.541578\n",
      "[284]\ttraining's binary_logloss: 0.541473\n",
      "[285]\ttraining's binary_logloss: 0.541372\n",
      "[286]\ttraining's binary_logloss: 0.541208\n",
      "[287]\ttraining's binary_logloss: 0.541049\n",
      "[288]\ttraining's binary_logloss: 0.540936\n",
      "[289]\ttraining's binary_logloss: 0.540769\n",
      "[290]\ttraining's binary_logloss: 0.540634\n",
      "[291]\ttraining's binary_logloss: 0.540441\n",
      "[292]\ttraining's binary_logloss: 0.540248\n",
      "[293]\ttraining's binary_logloss: 0.540078\n",
      "[294]\ttraining's binary_logloss: 0.539899\n",
      "[295]\ttraining's binary_logloss: 0.539731\n",
      "[296]\ttraining's binary_logloss: 0.539579\n",
      "[297]\ttraining's binary_logloss: 0.539429\n",
      "[298]\ttraining's binary_logloss: 0.539297\n",
      "[299]\ttraining's binary_logloss: 0.539154\n",
      "[300]\ttraining's binary_logloss: 0.539017\n",
      "[301]\ttraining's binary_logloss: 0.538851\n",
      "[302]\ttraining's binary_logloss: 0.538696\n",
      "[303]\ttraining's binary_logloss: 0.538528\n",
      "[304]\ttraining's binary_logloss: 0.538367\n",
      "[305]\ttraining's binary_logloss: 0.538215\n",
      "[306]\ttraining's binary_logloss: 0.538071\n",
      "[307]\ttraining's binary_logloss: 0.537889\n",
      "[308]\ttraining's binary_logloss: 0.537758\n",
      "[309]\ttraining's binary_logloss: 0.537627\n",
      "[310]\ttraining's binary_logloss: 0.537472\n",
      "[311]\ttraining's binary_logloss: 0.537307\n",
      "[312]\ttraining's binary_logloss: 0.53716\n",
      "[313]\ttraining's binary_logloss: 0.536956\n",
      "[314]\ttraining's binary_logloss: 0.536796\n",
      "[315]\ttraining's binary_logloss: 0.536635\n",
      "[316]\ttraining's binary_logloss: 0.536491\n",
      "[317]\ttraining's binary_logloss: 0.536325\n",
      "[318]\ttraining's binary_logloss: 0.536164\n",
      "[319]\ttraining's binary_logloss: 0.536004\n",
      "[320]\ttraining's binary_logloss: 0.535841\n",
      "[321]\ttraining's binary_logloss: 0.535739\n",
      "[322]\ttraining's binary_logloss: 0.535595\n",
      "[323]\ttraining's binary_logloss: 0.535463\n",
      "[324]\ttraining's binary_logloss: 0.535332\n",
      "[325]\ttraining's binary_logloss: 0.53517\n",
      "[326]\ttraining's binary_logloss: 0.534988\n",
      "[327]\ttraining's binary_logloss: 0.534808\n",
      "[328]\ttraining's binary_logloss: 0.534657\n",
      "[329]\ttraining's binary_logloss: 0.534488\n",
      "[330]\ttraining's binary_logloss: 0.534331\n",
      "[331]\ttraining's binary_logloss: 0.534198\n",
      "[332]\ttraining's binary_logloss: 0.534055\n",
      "[333]\ttraining's binary_logloss: 0.533919\n",
      "[334]\ttraining's binary_logloss: 0.533777\n",
      "[335]\ttraining's binary_logloss: 0.533637\n",
      "[336]\ttraining's binary_logloss: 0.533507\n",
      "[337]\ttraining's binary_logloss: 0.533376\n",
      "[338]\ttraining's binary_logloss: 0.533246\n",
      "[339]\ttraining's binary_logloss: 0.533112\n",
      "[340]\ttraining's binary_logloss: 0.532973\n",
      "[341]\ttraining's binary_logloss: 0.532833\n",
      "[342]\ttraining's binary_logloss: 0.532709\n",
      "[343]\ttraining's binary_logloss: 0.53258\n",
      "[344]\ttraining's binary_logloss: 0.532449\n",
      "[345]\ttraining's binary_logloss: 0.532342\n",
      "[346]\ttraining's binary_logloss: 0.532171\n",
      "[347]\ttraining's binary_logloss: 0.531991\n",
      "[348]\ttraining's binary_logloss: 0.531829\n",
      "[349]\ttraining's binary_logloss: 0.531655\n",
      "[350]\ttraining's binary_logloss: 0.531493\n",
      "[351]\ttraining's binary_logloss: 0.531353\n",
      "[352]\ttraining's binary_logloss: 0.531226\n",
      "[353]\ttraining's binary_logloss: 0.53109\n",
      "[354]\ttraining's binary_logloss: 0.530975\n",
      "[355]\ttraining's binary_logloss: 0.530841\n",
      "[356]\ttraining's binary_logloss: 0.53068\n",
      "[357]\ttraining's binary_logloss: 0.530519\n",
      "[358]\ttraining's binary_logloss: 0.530368\n",
      "[359]\ttraining's binary_logloss: 0.530216\n",
      "[360]\ttraining's binary_logloss: 0.530071\n",
      "[361]\ttraining's binary_logloss: 0.529915\n",
      "[362]\ttraining's binary_logloss: 0.529791\n",
      "[363]\ttraining's binary_logloss: 0.529596\n",
      "[364]\ttraining's binary_logloss: 0.529453\n",
      "[365]\ttraining's binary_logloss: 0.529275\n",
      "[366]\ttraining's binary_logloss: 0.529118\n",
      "[367]\ttraining's binary_logloss: 0.528961\n",
      "[368]\ttraining's binary_logloss: 0.528815\n",
      "[369]\ttraining's binary_logloss: 0.528654\n",
      "[370]\ttraining's binary_logloss: 0.528504\n",
      "[371]\ttraining's binary_logloss: 0.528342\n",
      "[372]\ttraining's binary_logloss: 0.528182\n",
      "[373]\ttraining's binary_logloss: 0.528018\n",
      "[374]\ttraining's binary_logloss: 0.527886\n",
      "[375]\ttraining's binary_logloss: 0.527686\n",
      "[376]\ttraining's binary_logloss: 0.52753\n",
      "[377]\ttraining's binary_logloss: 0.527366\n",
      "[378]\ttraining's binary_logloss: 0.527216\n",
      "[379]\ttraining's binary_logloss: 0.527052\n",
      "[380]\ttraining's binary_logloss: 0.526892\n",
      "[381]\ttraining's binary_logloss: 0.526692\n",
      "[382]\ttraining's binary_logloss: 0.526511\n",
      "[383]\ttraining's binary_logloss: 0.526346\n",
      "[384]\ttraining's binary_logloss: 0.52619\n",
      "[385]\ttraining's binary_logloss: 0.526034\n",
      "[386]\ttraining's binary_logloss: 0.52586\n",
      "[387]\ttraining's binary_logloss: 0.525682\n",
      "[388]\ttraining's binary_logloss: 0.525497\n",
      "[389]\ttraining's binary_logloss: 0.525328\n",
      "[390]\ttraining's binary_logloss: 0.525149\n",
      "[391]\ttraining's binary_logloss: 0.524955\n",
      "[392]\ttraining's binary_logloss: 0.524782\n",
      "[393]\ttraining's binary_logloss: 0.524606\n",
      "[394]\ttraining's binary_logloss: 0.524439\n",
      "[395]\ttraining's binary_logloss: 0.524267\n",
      "[396]\ttraining's binary_logloss: 0.52413\n",
      "[397]\ttraining's binary_logloss: 0.524009\n",
      "[398]\ttraining's binary_logloss: 0.523891\n",
      "[399]\ttraining's binary_logloss: 0.52377\n",
      "[400]\ttraining's binary_logloss: 0.523649\n",
      "[401]\ttraining's binary_logloss: 0.523479\n",
      "[402]\ttraining's binary_logloss: 0.523316\n",
      "[403]\ttraining's binary_logloss: 0.523165\n",
      "[404]\ttraining's binary_logloss: 0.52301\n",
      "[405]\ttraining's binary_logloss: 0.522873\n",
      "[406]\ttraining's binary_logloss: 0.522733\n",
      "[407]\ttraining's binary_logloss: 0.522601\n",
      "[408]\ttraining's binary_logloss: 0.522457\n",
      "[409]\ttraining's binary_logloss: 0.522328\n",
      "[410]\ttraining's binary_logloss: 0.522198\n",
      "[411]\ttraining's binary_logloss: 0.522051\n",
      "[412]\ttraining's binary_logloss: 0.521912\n",
      "[413]\ttraining's binary_logloss: 0.521763\n",
      "[414]\ttraining's binary_logloss: 0.5216\n",
      "[415]\ttraining's binary_logloss: 0.521466\n",
      "[416]\ttraining's binary_logloss: 0.52131\n",
      "[417]\ttraining's binary_logloss: 0.521157\n",
      "[418]\ttraining's binary_logloss: 0.521016\n",
      "[419]\ttraining's binary_logloss: 0.520868\n",
      "[420]\ttraining's binary_logloss: 0.52071\n",
      "[421]\ttraining's binary_logloss: 0.520561\n",
      "[422]\ttraining's binary_logloss: 0.520404\n",
      "[423]\ttraining's binary_logloss: 0.520249\n",
      "[424]\ttraining's binary_logloss: 0.520118\n",
      "[425]\ttraining's binary_logloss: 0.519973\n",
      "[426]\ttraining's binary_logloss: 0.519808\n",
      "[427]\ttraining's binary_logloss: 0.519655\n",
      "[428]\ttraining's binary_logloss: 0.519515\n",
      "[429]\ttraining's binary_logloss: 0.519356\n",
      "[430]\ttraining's binary_logloss: 0.519202\n",
      "[431]\ttraining's binary_logloss: 0.519049\n",
      "[432]\ttraining's binary_logloss: 0.518913\n",
      "[433]\ttraining's binary_logloss: 0.51876\n",
      "[434]\ttraining's binary_logloss: 0.51863\n",
      "[435]\ttraining's binary_logloss: 0.518467\n",
      "[436]\ttraining's binary_logloss: 0.518346\n",
      "[437]\ttraining's binary_logloss: 0.518226\n",
      "[438]\ttraining's binary_logloss: 0.518088\n",
      "[439]\ttraining's binary_logloss: 0.517962\n",
      "[440]\ttraining's binary_logloss: 0.517836\n",
      "[441]\ttraining's binary_logloss: 0.51767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[442]\ttraining's binary_logloss: 0.517532\n",
      "[443]\ttraining's binary_logloss: 0.517379\n",
      "[444]\ttraining's binary_logloss: 0.51724\n",
      "[445]\ttraining's binary_logloss: 0.517082\n",
      "[446]\ttraining's binary_logloss: 0.516889\n",
      "[447]\ttraining's binary_logloss: 0.516699\n",
      "[448]\ttraining's binary_logloss: 0.516513\n",
      "[449]\ttraining's binary_logloss: 0.516331\n",
      "[450]\ttraining's binary_logloss: 0.516154\n",
      "[451]\ttraining's binary_logloss: 0.515944\n",
      "[452]\ttraining's binary_logloss: 0.515736\n",
      "[453]\ttraining's binary_logloss: 0.515535\n",
      "[454]\ttraining's binary_logloss: 0.515325\n",
      "[455]\ttraining's binary_logloss: 0.515134\n",
      "[456]\ttraining's binary_logloss: 0.514942\n",
      "[457]\ttraining's binary_logloss: 0.514749\n",
      "[458]\ttraining's binary_logloss: 0.514549\n",
      "[459]\ttraining's binary_logloss: 0.514397\n",
      "[460]\ttraining's binary_logloss: 0.51426\n",
      "[461]\ttraining's binary_logloss: 0.514097\n",
      "[462]\ttraining's binary_logloss: 0.51394\n",
      "[463]\ttraining's binary_logloss: 0.51376\n",
      "[464]\ttraining's binary_logloss: 0.513607\n",
      "[465]\ttraining's binary_logloss: 0.51343\n",
      "[466]\ttraining's binary_logloss: 0.513256\n",
      "[467]\ttraining's binary_logloss: 0.513087\n",
      "[468]\ttraining's binary_logloss: 0.512905\n",
      "[469]\ttraining's binary_logloss: 0.512749\n",
      "[470]\ttraining's binary_logloss: 0.512589\n",
      "[471]\ttraining's binary_logloss: 0.512441\n",
      "[472]\ttraining's binary_logloss: 0.512297\n",
      "[473]\ttraining's binary_logloss: 0.512157\n",
      "[474]\ttraining's binary_logloss: 0.512011\n",
      "[475]\ttraining's binary_logloss: 0.511873\n",
      "[476]\ttraining's binary_logloss: 0.511722\n",
      "[477]\ttraining's binary_logloss: 0.511581\n",
      "[478]\ttraining's binary_logloss: 0.511447\n",
      "[479]\ttraining's binary_logloss: 0.511293\n",
      "[480]\ttraining's binary_logloss: 0.511149\n",
      "[481]\ttraining's binary_logloss: 0.511029\n",
      "[482]\ttraining's binary_logloss: 0.510875\n",
      "[483]\ttraining's binary_logloss: 0.510757\n",
      "[484]\ttraining's binary_logloss: 0.510639\n",
      "[485]\ttraining's binary_logloss: 0.51052\n",
      "[486]\ttraining's binary_logloss: 0.510324\n",
      "[487]\ttraining's binary_logloss: 0.510145\n",
      "[488]\ttraining's binary_logloss: 0.509953\n",
      "[489]\ttraining's binary_logloss: 0.509777\n",
      "[490]\ttraining's binary_logloss: 0.509598\n",
      "[491]\ttraining's binary_logloss: 0.509434\n",
      "[492]\ttraining's binary_logloss: 0.509268\n",
      "[493]\ttraining's binary_logloss: 0.509116\n",
      "[494]\ttraining's binary_logloss: 0.508966\n",
      "[495]\ttraining's binary_logloss: 0.508812\n",
      "[496]\ttraining's binary_logloss: 0.508612\n",
      "[497]\ttraining's binary_logloss: 0.508434\n",
      "[498]\ttraining's binary_logloss: 0.508279\n",
      "[499]\ttraining's binary_logloss: 0.508139\n",
      "[500]\ttraining's binary_logloss: 0.507985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614135\n",
      "[2]\ttraining's binary_logloss: 0.612552\n",
      "[3]\ttraining's binary_logloss: 0.611104\n",
      "[4]\ttraining's binary_logloss: 0.609686\n",
      "[5]\ttraining's binary_logloss: 0.6084\n",
      "[6]\ttraining's binary_logloss: 0.606927\n",
      "[7]\ttraining's binary_logloss: 0.605523\n",
      "[8]\ttraining's binary_logloss: 0.604194\n",
      "[9]\ttraining's binary_logloss: 0.603018\n",
      "[10]\ttraining's binary_logloss: 0.601754\n",
      "[11]\ttraining's binary_logloss: 0.600573\n",
      "[12]\ttraining's binary_logloss: 0.599366\n",
      "[13]\ttraining's binary_logloss: 0.598205\n",
      "[14]\ttraining's binary_logloss: 0.597096\n",
      "[15]\ttraining's binary_logloss: 0.596067\n",
      "[16]\ttraining's binary_logloss: 0.595019\n",
      "[17]\ttraining's binary_logloss: 0.594004\n",
      "[18]\ttraining's binary_logloss: 0.592974\n",
      "[19]\ttraining's binary_logloss: 0.592009\n",
      "[20]\ttraining's binary_logloss: 0.5911\n",
      "[21]\ttraining's binary_logloss: 0.590223\n",
      "[22]\ttraining's binary_logloss: 0.58941\n",
      "[23]\ttraining's binary_logloss: 0.588599\n",
      "[24]\ttraining's binary_logloss: 0.587816\n",
      "[25]\ttraining's binary_logloss: 0.587063\n",
      "[26]\ttraining's binary_logloss: 0.586216\n",
      "[27]\ttraining's binary_logloss: 0.585406\n",
      "[28]\ttraining's binary_logloss: 0.584594\n",
      "[29]\ttraining's binary_logloss: 0.58383\n",
      "[30]\ttraining's binary_logloss: 0.58306\n",
      "[31]\ttraining's binary_logloss: 0.582331\n",
      "[32]\ttraining's binary_logloss: 0.581584\n",
      "[33]\ttraining's binary_logloss: 0.580848\n",
      "[34]\ttraining's binary_logloss: 0.580099\n",
      "[35]\ttraining's binary_logloss: 0.579396\n",
      "[36]\ttraining's binary_logloss: 0.578781\n",
      "[37]\ttraining's binary_logloss: 0.578118\n",
      "[38]\ttraining's binary_logloss: 0.577491\n",
      "[39]\ttraining's binary_logloss: 0.576836\n",
      "[40]\ttraining's binary_logloss: 0.576244\n",
      "[41]\ttraining's binary_logloss: 0.57568\n",
      "[42]\ttraining's binary_logloss: 0.575099\n",
      "[43]\ttraining's binary_logloss: 0.574533\n",
      "[44]\ttraining's binary_logloss: 0.574024\n",
      "[45]\ttraining's binary_logloss: 0.573492\n",
      "[46]\ttraining's binary_logloss: 0.572975\n",
      "[47]\ttraining's binary_logloss: 0.572431\n",
      "[48]\ttraining's binary_logloss: 0.571874\n",
      "[49]\ttraining's binary_logloss: 0.571353\n",
      "[50]\ttraining's binary_logloss: 0.570854\n",
      "[51]\ttraining's binary_logloss: 0.570392\n",
      "[52]\ttraining's binary_logloss: 0.569924\n",
      "[53]\ttraining's binary_logloss: 0.569463\n",
      "[54]\ttraining's binary_logloss: 0.569027\n",
      "[55]\ttraining's binary_logloss: 0.568575\n",
      "[56]\ttraining's binary_logloss: 0.56813\n",
      "[57]\ttraining's binary_logloss: 0.567687\n",
      "[58]\ttraining's binary_logloss: 0.567258\n",
      "[59]\ttraining's binary_logloss: 0.566866\n",
      "[60]\ttraining's binary_logloss: 0.566436\n",
      "[61]\ttraining's binary_logloss: 0.566063\n",
      "[62]\ttraining's binary_logloss: 0.565682\n",
      "[63]\ttraining's binary_logloss: 0.565305\n",
      "[64]\ttraining's binary_logloss: 0.56497\n",
      "[65]\ttraining's binary_logloss: 0.564643\n",
      "[66]\ttraining's binary_logloss: 0.564307\n",
      "[67]\ttraining's binary_logloss: 0.563967\n",
      "[68]\ttraining's binary_logloss: 0.56365\n",
      "[69]\ttraining's binary_logloss: 0.563337\n",
      "[70]\ttraining's binary_logloss: 0.563028\n",
      "[71]\ttraining's binary_logloss: 0.562655\n",
      "[72]\ttraining's binary_logloss: 0.562338\n",
      "[73]\ttraining's binary_logloss: 0.562031\n",
      "[74]\ttraining's binary_logloss: 0.561742\n",
      "[75]\ttraining's binary_logloss: 0.56144\n",
      "[76]\ttraining's binary_logloss: 0.561168\n",
      "[77]\ttraining's binary_logloss: 0.560942\n",
      "[78]\ttraining's binary_logloss: 0.560696\n",
      "[79]\ttraining's binary_logloss: 0.560425\n",
      "[80]\ttraining's binary_logloss: 0.560195\n",
      "[81]\ttraining's binary_logloss: 0.559978\n",
      "[82]\ttraining's binary_logloss: 0.559683\n",
      "[83]\ttraining's binary_logloss: 0.559437\n",
      "[84]\ttraining's binary_logloss: 0.55915\n",
      "[85]\ttraining's binary_logloss: 0.558878\n",
      "[86]\ttraining's binary_logloss: 0.558635\n",
      "[87]\ttraining's binary_logloss: 0.558346\n",
      "[88]\ttraining's binary_logloss: 0.558077\n",
      "[89]\ttraining's binary_logloss: 0.557816\n",
      "[90]\ttraining's binary_logloss: 0.557518\n",
      "[91]\ttraining's binary_logloss: 0.557288\n",
      "[92]\ttraining's binary_logloss: 0.557064\n",
      "[93]\ttraining's binary_logloss: 0.556842\n",
      "[94]\ttraining's binary_logloss: 0.55662\n",
      "[95]\ttraining's binary_logloss: 0.556395\n",
      "[96]\ttraining's binary_logloss: 0.556157\n",
      "[97]\ttraining's binary_logloss: 0.555935\n",
      "[98]\ttraining's binary_logloss: 0.555715\n",
      "[99]\ttraining's binary_logloss: 0.555475\n",
      "[100]\ttraining's binary_logloss: 0.555247\n",
      "[101]\ttraining's binary_logloss: 0.554956\n",
      "[102]\ttraining's binary_logloss: 0.554747\n",
      "[103]\ttraining's binary_logloss: 0.554537\n",
      "[104]\ttraining's binary_logloss: 0.554323\n",
      "[105]\ttraining's binary_logloss: 0.554104\n",
      "[106]\ttraining's binary_logloss: 0.55391\n",
      "[107]\ttraining's binary_logloss: 0.553716\n",
      "[108]\ttraining's binary_logloss: 0.553536\n",
      "[109]\ttraining's binary_logloss: 0.553349\n",
      "[110]\ttraining's binary_logloss: 0.55321\n",
      "[111]\ttraining's binary_logloss: 0.552981\n",
      "[112]\ttraining's binary_logloss: 0.552722\n",
      "[113]\ttraining's binary_logloss: 0.552502\n",
      "[114]\ttraining's binary_logloss: 0.552267\n",
      "[115]\ttraining's binary_logloss: 0.552046\n",
      "[116]\ttraining's binary_logloss: 0.551817\n",
      "[117]\ttraining's binary_logloss: 0.551584\n",
      "[118]\ttraining's binary_logloss: 0.551361\n",
      "[119]\ttraining's binary_logloss: 0.551194\n",
      "[120]\ttraining's binary_logloss: 0.551029\n",
      "[121]\ttraining's binary_logloss: 0.550826\n",
      "[122]\ttraining's binary_logloss: 0.550628\n",
      "[123]\ttraining's binary_logloss: 0.550426\n",
      "[124]\ttraining's binary_logloss: 0.550241\n",
      "[125]\ttraining's binary_logloss: 0.550052\n",
      "[126]\ttraining's binary_logloss: 0.549827\n",
      "[127]\ttraining's binary_logloss: 0.549626\n",
      "[128]\ttraining's binary_logloss: 0.549421\n",
      "[129]\ttraining's binary_logloss: 0.549246\n",
      "[130]\ttraining's binary_logloss: 0.549034\n",
      "[131]\ttraining's binary_logloss: 0.548879\n",
      "[132]\ttraining's binary_logloss: 0.54871\n",
      "[133]\ttraining's binary_logloss: 0.54856\n",
      "[134]\ttraining's binary_logloss: 0.5484\n",
      "[135]\ttraining's binary_logloss: 0.548267\n",
      "[136]\ttraining's binary_logloss: 0.548078\n",
      "[137]\ttraining's binary_logloss: 0.547906\n",
      "[138]\ttraining's binary_logloss: 0.547713\n",
      "[139]\ttraining's binary_logloss: 0.547541\n",
      "[140]\ttraining's binary_logloss: 0.547372\n",
      "[141]\ttraining's binary_logloss: 0.547207\n",
      "[142]\ttraining's binary_logloss: 0.547036\n",
      "[143]\ttraining's binary_logloss: 0.546854\n",
      "[144]\ttraining's binary_logloss: 0.546673\n",
      "[145]\ttraining's binary_logloss: 0.546503\n",
      "[146]\ttraining's binary_logloss: 0.546323\n",
      "[147]\ttraining's binary_logloss: 0.546154\n",
      "[148]\ttraining's binary_logloss: 0.545957\n",
      "[149]\ttraining's binary_logloss: 0.545786\n",
      "[150]\ttraining's binary_logloss: 0.545647\n",
      "[151]\ttraining's binary_logloss: 0.545474\n",
      "[152]\ttraining's binary_logloss: 0.545305\n",
      "[153]\ttraining's binary_logloss: 0.545119\n",
      "[154]\ttraining's binary_logloss: 0.544936\n",
      "[155]\ttraining's binary_logloss: 0.544776\n",
      "[156]\ttraining's binary_logloss: 0.544605\n",
      "[157]\ttraining's binary_logloss: 0.544397\n",
      "[158]\ttraining's binary_logloss: 0.544234\n",
      "[159]\ttraining's binary_logloss: 0.544069\n",
      "[160]\ttraining's binary_logloss: 0.543909\n",
      "[161]\ttraining's binary_logloss: 0.543732\n",
      "[162]\ttraining's binary_logloss: 0.543538\n",
      "[163]\ttraining's binary_logloss: 0.543356\n",
      "[164]\ttraining's binary_logloss: 0.543156\n",
      "[165]\ttraining's binary_logloss: 0.543002\n",
      "[166]\ttraining's binary_logloss: 0.542785\n",
      "[167]\ttraining's binary_logloss: 0.542596\n",
      "[168]\ttraining's binary_logloss: 0.542434\n",
      "[169]\ttraining's binary_logloss: 0.542228\n",
      "[170]\ttraining's binary_logloss: 0.542052\n",
      "[171]\ttraining's binary_logloss: 0.541886\n",
      "[172]\ttraining's binary_logloss: 0.541732\n",
      "[173]\ttraining's binary_logloss: 0.541558\n",
      "[174]\ttraining's binary_logloss: 0.541398\n",
      "[175]\ttraining's binary_logloss: 0.541234\n",
      "[176]\ttraining's binary_logloss: 0.541059\n",
      "[177]\ttraining's binary_logloss: 0.540891\n",
      "[178]\ttraining's binary_logloss: 0.540703\n",
      "[179]\ttraining's binary_logloss: 0.540531\n",
      "[180]\ttraining's binary_logloss: 0.540333\n",
      "[181]\ttraining's binary_logloss: 0.540159\n",
      "[182]\ttraining's binary_logloss: 0.539973\n",
      "[183]\ttraining's binary_logloss: 0.539794\n",
      "[184]\ttraining's binary_logloss: 0.539597\n",
      "[185]\ttraining's binary_logloss: 0.539403\n",
      "[186]\ttraining's binary_logloss: 0.539282\n",
      "[187]\ttraining's binary_logloss: 0.539145\n",
      "[188]\ttraining's binary_logloss: 0.538977\n",
      "[189]\ttraining's binary_logloss: 0.53885\n",
      "[190]\ttraining's binary_logloss: 0.538722\n",
      "[191]\ttraining's binary_logloss: 0.538562\n",
      "[192]\ttraining's binary_logloss: 0.538389\n",
      "[193]\ttraining's binary_logloss: 0.538211\n",
      "[194]\ttraining's binary_logloss: 0.538045\n",
      "[195]\ttraining's binary_logloss: 0.537867\n",
      "[196]\ttraining's binary_logloss: 0.537693\n",
      "[197]\ttraining's binary_logloss: 0.537522\n",
      "[198]\ttraining's binary_logloss: 0.537369\n",
      "[199]\ttraining's binary_logloss: 0.537199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's binary_logloss: 0.537027\n",
      "[201]\ttraining's binary_logloss: 0.536867\n",
      "[202]\ttraining's binary_logloss: 0.53674\n",
      "[203]\ttraining's binary_logloss: 0.536555\n",
      "[204]\ttraining's binary_logloss: 0.536401\n",
      "[205]\ttraining's binary_logloss: 0.536242\n",
      "[206]\ttraining's binary_logloss: 0.536051\n",
      "[207]\ttraining's binary_logloss: 0.535842\n",
      "[208]\ttraining's binary_logloss: 0.535649\n",
      "[209]\ttraining's binary_logloss: 0.535463\n",
      "[210]\ttraining's binary_logloss: 0.535265\n",
      "[211]\ttraining's binary_logloss: 0.535094\n",
      "[212]\ttraining's binary_logloss: 0.534947\n",
      "[213]\ttraining's binary_logloss: 0.534782\n",
      "[214]\ttraining's binary_logloss: 0.534652\n",
      "[215]\ttraining's binary_logloss: 0.534489\n",
      "[216]\ttraining's binary_logloss: 0.534307\n",
      "[217]\ttraining's binary_logloss: 0.534115\n",
      "[218]\ttraining's binary_logloss: 0.533922\n",
      "[219]\ttraining's binary_logloss: 0.533734\n",
      "[220]\ttraining's binary_logloss: 0.533538\n",
      "[221]\ttraining's binary_logloss: 0.53335\n",
      "[222]\ttraining's binary_logloss: 0.533132\n",
      "[223]\ttraining's binary_logloss: 0.532955\n",
      "[224]\ttraining's binary_logloss: 0.532751\n",
      "[225]\ttraining's binary_logloss: 0.532558\n",
      "[226]\ttraining's binary_logloss: 0.532319\n",
      "[227]\ttraining's binary_logloss: 0.532095\n",
      "[228]\ttraining's binary_logloss: 0.53187\n",
      "[229]\ttraining's binary_logloss: 0.531652\n",
      "[230]\ttraining's binary_logloss: 0.531425\n",
      "[231]\ttraining's binary_logloss: 0.531279\n",
      "[232]\ttraining's binary_logloss: 0.531134\n",
      "[233]\ttraining's binary_logloss: 0.530969\n",
      "[234]\ttraining's binary_logloss: 0.530786\n",
      "[235]\ttraining's binary_logloss: 0.530641\n",
      "[236]\ttraining's binary_logloss: 0.530447\n",
      "[237]\ttraining's binary_logloss: 0.530238\n",
      "[238]\ttraining's binary_logloss: 0.53001\n",
      "[239]\ttraining's binary_logloss: 0.529804\n",
      "[240]\ttraining's binary_logloss: 0.529604\n",
      "[241]\ttraining's binary_logloss: 0.529407\n",
      "[242]\ttraining's binary_logloss: 0.529214\n",
      "[243]\ttraining's binary_logloss: 0.529039\n",
      "[244]\ttraining's binary_logloss: 0.52889\n",
      "[245]\ttraining's binary_logloss: 0.52871\n",
      "[246]\ttraining's binary_logloss: 0.528468\n",
      "[247]\ttraining's binary_logloss: 0.528222\n",
      "[248]\ttraining's binary_logloss: 0.527969\n",
      "[249]\ttraining's binary_logloss: 0.527758\n",
      "[250]\ttraining's binary_logloss: 0.527542\n",
      "[251]\ttraining's binary_logloss: 0.527328\n",
      "[252]\ttraining's binary_logloss: 0.527086\n",
      "[253]\ttraining's binary_logloss: 0.526877\n",
      "[254]\ttraining's binary_logloss: 0.526675\n",
      "[255]\ttraining's binary_logloss: 0.526455\n",
      "[256]\ttraining's binary_logloss: 0.526281\n",
      "[257]\ttraining's binary_logloss: 0.526105\n",
      "[258]\ttraining's binary_logloss: 0.525919\n",
      "[259]\ttraining's binary_logloss: 0.525745\n",
      "[260]\ttraining's binary_logloss: 0.525555\n",
      "[261]\ttraining's binary_logloss: 0.525371\n",
      "[262]\ttraining's binary_logloss: 0.525168\n",
      "[263]\ttraining's binary_logloss: 0.524972\n",
      "[264]\ttraining's binary_logloss: 0.524763\n",
      "[265]\ttraining's binary_logloss: 0.524575\n",
      "[266]\ttraining's binary_logloss: 0.524422\n",
      "[267]\ttraining's binary_logloss: 0.524262\n",
      "[268]\ttraining's binary_logloss: 0.524124\n",
      "[269]\ttraining's binary_logloss: 0.523989\n",
      "[270]\ttraining's binary_logloss: 0.52383\n",
      "[271]\ttraining's binary_logloss: 0.523697\n",
      "[272]\ttraining's binary_logloss: 0.523564\n",
      "[273]\ttraining's binary_logloss: 0.523393\n",
      "[274]\ttraining's binary_logloss: 0.52319\n",
      "[275]\ttraining's binary_logloss: 0.523036\n",
      "[276]\ttraining's binary_logloss: 0.522858\n",
      "[277]\ttraining's binary_logloss: 0.522681\n",
      "[278]\ttraining's binary_logloss: 0.522485\n",
      "[279]\ttraining's binary_logloss: 0.522303\n",
      "[280]\ttraining's binary_logloss: 0.522108\n",
      "[281]\ttraining's binary_logloss: 0.52194\n",
      "[282]\ttraining's binary_logloss: 0.521792\n",
      "[283]\ttraining's binary_logloss: 0.521651\n",
      "[284]\ttraining's binary_logloss: 0.521511\n",
      "[285]\ttraining's binary_logloss: 0.521357\n",
      "[286]\ttraining's binary_logloss: 0.521143\n",
      "[287]\ttraining's binary_logloss: 0.520931\n",
      "[288]\ttraining's binary_logloss: 0.520776\n",
      "[289]\ttraining's binary_logloss: 0.520554\n",
      "[290]\ttraining's binary_logloss: 0.520347\n",
      "[291]\ttraining's binary_logloss: 0.520126\n",
      "[292]\ttraining's binary_logloss: 0.519904\n",
      "[293]\ttraining's binary_logloss: 0.519687\n",
      "[294]\ttraining's binary_logloss: 0.519491\n",
      "[295]\ttraining's binary_logloss: 0.519284\n",
      "[296]\ttraining's binary_logloss: 0.519083\n",
      "[297]\ttraining's binary_logloss: 0.518879\n",
      "[298]\ttraining's binary_logloss: 0.518694\n",
      "[299]\ttraining's binary_logloss: 0.518506\n",
      "[300]\ttraining's binary_logloss: 0.518337\n",
      "[301]\ttraining's binary_logloss: 0.518106\n",
      "[302]\ttraining's binary_logloss: 0.517914\n",
      "[303]\ttraining's binary_logloss: 0.517688\n",
      "[304]\ttraining's binary_logloss: 0.517479\n",
      "[305]\ttraining's binary_logloss: 0.517297\n",
      "[306]\ttraining's binary_logloss: 0.517084\n",
      "[307]\ttraining's binary_logloss: 0.516887\n",
      "[308]\ttraining's binary_logloss: 0.516706\n",
      "[309]\ttraining's binary_logloss: 0.516506\n",
      "[310]\ttraining's binary_logloss: 0.516318\n",
      "[311]\ttraining's binary_logloss: 0.516098\n",
      "[312]\ttraining's binary_logloss: 0.515894\n",
      "[313]\ttraining's binary_logloss: 0.515649\n",
      "[314]\ttraining's binary_logloss: 0.515444\n",
      "[315]\ttraining's binary_logloss: 0.515236\n",
      "[316]\ttraining's binary_logloss: 0.515043\n",
      "[317]\ttraining's binary_logloss: 0.514849\n",
      "[318]\ttraining's binary_logloss: 0.514629\n",
      "[319]\ttraining's binary_logloss: 0.514425\n",
      "[320]\ttraining's binary_logloss: 0.514191\n",
      "[321]\ttraining's binary_logloss: 0.51401\n",
      "[322]\ttraining's binary_logloss: 0.513832\n",
      "[323]\ttraining's binary_logloss: 0.513669\n",
      "[324]\ttraining's binary_logloss: 0.513503\n",
      "[325]\ttraining's binary_logloss: 0.513319\n",
      "[326]\ttraining's binary_logloss: 0.513093\n",
      "[327]\ttraining's binary_logloss: 0.512827\n",
      "[328]\ttraining's binary_logloss: 0.512633\n",
      "[329]\ttraining's binary_logloss: 0.512436\n",
      "[330]\ttraining's binary_logloss: 0.512221\n",
      "[331]\ttraining's binary_logloss: 0.512041\n",
      "[332]\ttraining's binary_logloss: 0.511862\n",
      "[333]\ttraining's binary_logloss: 0.51167\n",
      "[334]\ttraining's binary_logloss: 0.511487\n",
      "[335]\ttraining's binary_logloss: 0.511323\n",
      "[336]\ttraining's binary_logloss: 0.51114\n",
      "[337]\ttraining's binary_logloss: 0.510961\n",
      "[338]\ttraining's binary_logloss: 0.510764\n",
      "[339]\ttraining's binary_logloss: 0.510596\n",
      "[340]\ttraining's binary_logloss: 0.510414\n",
      "[341]\ttraining's binary_logloss: 0.510229\n",
      "[342]\ttraining's binary_logloss: 0.510075\n",
      "[343]\ttraining's binary_logloss: 0.509904\n",
      "[344]\ttraining's binary_logloss: 0.509738\n",
      "[345]\ttraining's binary_logloss: 0.509569\n",
      "[346]\ttraining's binary_logloss: 0.509335\n",
      "[347]\ttraining's binary_logloss: 0.509104\n",
      "[348]\ttraining's binary_logloss: 0.5089\n",
      "[349]\ttraining's binary_logloss: 0.508678\n",
      "[350]\ttraining's binary_logloss: 0.508465\n",
      "[351]\ttraining's binary_logloss: 0.508289\n",
      "[352]\ttraining's binary_logloss: 0.508114\n",
      "[353]\ttraining's binary_logloss: 0.507959\n",
      "[354]\ttraining's binary_logloss: 0.507792\n",
      "[355]\ttraining's binary_logloss: 0.50763\n",
      "[356]\ttraining's binary_logloss: 0.507438\n",
      "[357]\ttraining's binary_logloss: 0.507227\n",
      "[358]\ttraining's binary_logloss: 0.507017\n",
      "[359]\ttraining's binary_logloss: 0.506837\n",
      "[360]\ttraining's binary_logloss: 0.506629\n",
      "[361]\ttraining's binary_logloss: 0.506397\n",
      "[362]\ttraining's binary_logloss: 0.50621\n",
      "[363]\ttraining's binary_logloss: 0.506015\n",
      "[364]\ttraining's binary_logloss: 0.505838\n",
      "[365]\ttraining's binary_logloss: 0.505621\n",
      "[366]\ttraining's binary_logloss: 0.505397\n",
      "[367]\ttraining's binary_logloss: 0.505192\n",
      "[368]\ttraining's binary_logloss: 0.50499\n",
      "[369]\ttraining's binary_logloss: 0.504782\n",
      "[370]\ttraining's binary_logloss: 0.504586\n",
      "[371]\ttraining's binary_logloss: 0.504378\n",
      "[372]\ttraining's binary_logloss: 0.504111\n",
      "[373]\ttraining's binary_logloss: 0.503878\n",
      "[374]\ttraining's binary_logloss: 0.503665\n",
      "[375]\ttraining's binary_logloss: 0.503431\n",
      "[376]\ttraining's binary_logloss: 0.503244\n",
      "[377]\ttraining's binary_logloss: 0.503014\n",
      "[378]\ttraining's binary_logloss: 0.502824\n",
      "[379]\ttraining's binary_logloss: 0.502631\n",
      "[380]\ttraining's binary_logloss: 0.502416\n",
      "[381]\ttraining's binary_logloss: 0.50221\n",
      "[382]\ttraining's binary_logloss: 0.501989\n",
      "[383]\ttraining's binary_logloss: 0.501778\n",
      "[384]\ttraining's binary_logloss: 0.501582\n",
      "[385]\ttraining's binary_logloss: 0.501386\n",
      "[386]\ttraining's binary_logloss: 0.501172\n",
      "[387]\ttraining's binary_logloss: 0.50092\n",
      "[388]\ttraining's binary_logloss: 0.500699\n",
      "[389]\ttraining's binary_logloss: 0.500497\n",
      "[390]\ttraining's binary_logloss: 0.500277\n",
      "[391]\ttraining's binary_logloss: 0.500059\n",
      "[392]\ttraining's binary_logloss: 0.499838\n",
      "[393]\ttraining's binary_logloss: 0.499628\n",
      "[394]\ttraining's binary_logloss: 0.499417\n",
      "[395]\ttraining's binary_logloss: 0.499211\n",
      "[396]\ttraining's binary_logloss: 0.499022\n",
      "[397]\ttraining's binary_logloss: 0.498836\n",
      "[398]\ttraining's binary_logloss: 0.498651\n",
      "[399]\ttraining's binary_logloss: 0.498457\n",
      "[400]\ttraining's binary_logloss: 0.498278\n",
      "[401]\ttraining's binary_logloss: 0.498056\n",
      "[402]\ttraining's binary_logloss: 0.497858\n",
      "[403]\ttraining's binary_logloss: 0.49766\n",
      "[404]\ttraining's binary_logloss: 0.497455\n",
      "[405]\ttraining's binary_logloss: 0.497264\n",
      "[406]\ttraining's binary_logloss: 0.49708\n",
      "[407]\ttraining's binary_logloss: 0.496887\n",
      "[408]\ttraining's binary_logloss: 0.496714\n",
      "[409]\ttraining's binary_logloss: 0.496557\n",
      "[410]\ttraining's binary_logloss: 0.496385\n",
      "[411]\ttraining's binary_logloss: 0.496208\n",
      "[412]\ttraining's binary_logloss: 0.496027\n",
      "[413]\ttraining's binary_logloss: 0.495845\n",
      "[414]\ttraining's binary_logloss: 0.49563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[415]\ttraining's binary_logloss: 0.495468\n",
      "[416]\ttraining's binary_logloss: 0.495278\n",
      "[417]\ttraining's binary_logloss: 0.495107\n",
      "[418]\ttraining's binary_logloss: 0.494943\n",
      "[419]\ttraining's binary_logloss: 0.494736\n",
      "[420]\ttraining's binary_logloss: 0.494557\n",
      "[421]\ttraining's binary_logloss: 0.494354\n",
      "[422]\ttraining's binary_logloss: 0.494179\n",
      "[423]\ttraining's binary_logloss: 0.494\n",
      "[424]\ttraining's binary_logloss: 0.49386\n",
      "[425]\ttraining's binary_logloss: 0.49369\n",
      "[426]\ttraining's binary_logloss: 0.493486\n",
      "[427]\ttraining's binary_logloss: 0.493293\n",
      "[428]\ttraining's binary_logloss: 0.493111\n",
      "[429]\ttraining's binary_logloss: 0.492886\n",
      "[430]\ttraining's binary_logloss: 0.492689\n",
      "[431]\ttraining's binary_logloss: 0.492494\n",
      "[432]\ttraining's binary_logloss: 0.492306\n",
      "[433]\ttraining's binary_logloss: 0.492116\n",
      "[434]\ttraining's binary_logloss: 0.491927\n",
      "[435]\ttraining's binary_logloss: 0.49173\n",
      "[436]\ttraining's binary_logloss: 0.491557\n",
      "[437]\ttraining's binary_logloss: 0.491384\n",
      "[438]\ttraining's binary_logloss: 0.49121\n",
      "[439]\ttraining's binary_logloss: 0.491045\n",
      "[440]\ttraining's binary_logloss: 0.490881\n",
      "[441]\ttraining's binary_logloss: 0.490697\n",
      "[442]\ttraining's binary_logloss: 0.490511\n",
      "[443]\ttraining's binary_logloss: 0.490311\n",
      "[444]\ttraining's binary_logloss: 0.490122\n",
      "[445]\ttraining's binary_logloss: 0.489922\n",
      "[446]\ttraining's binary_logloss: 0.489705\n",
      "[447]\ttraining's binary_logloss: 0.489482\n",
      "[448]\ttraining's binary_logloss: 0.489247\n",
      "[449]\ttraining's binary_logloss: 0.489036\n",
      "[450]\ttraining's binary_logloss: 0.488787\n",
      "[451]\ttraining's binary_logloss: 0.488529\n",
      "[452]\ttraining's binary_logloss: 0.488284\n",
      "[453]\ttraining's binary_logloss: 0.488033\n",
      "[454]\ttraining's binary_logloss: 0.487796\n",
      "[455]\ttraining's binary_logloss: 0.487567\n",
      "[456]\ttraining's binary_logloss: 0.487415\n",
      "[457]\ttraining's binary_logloss: 0.487221\n",
      "[458]\ttraining's binary_logloss: 0.487063\n",
      "[459]\ttraining's binary_logloss: 0.486903\n",
      "[460]\ttraining's binary_logloss: 0.486749\n",
      "[461]\ttraining's binary_logloss: 0.486539\n",
      "[462]\ttraining's binary_logloss: 0.486337\n",
      "[463]\ttraining's binary_logloss: 0.486137\n",
      "[464]\ttraining's binary_logloss: 0.485949\n",
      "[465]\ttraining's binary_logloss: 0.485721\n",
      "[466]\ttraining's binary_logloss: 0.485513\n",
      "[467]\ttraining's binary_logloss: 0.485294\n",
      "[468]\ttraining's binary_logloss: 0.485084\n",
      "[469]\ttraining's binary_logloss: 0.484862\n",
      "[470]\ttraining's binary_logloss: 0.484647\n",
      "[471]\ttraining's binary_logloss: 0.484462\n",
      "[472]\ttraining's binary_logloss: 0.484271\n",
      "[473]\ttraining's binary_logloss: 0.484082\n",
      "[474]\ttraining's binary_logloss: 0.483906\n",
      "[475]\ttraining's binary_logloss: 0.483717\n",
      "[476]\ttraining's binary_logloss: 0.483525\n",
      "[477]\ttraining's binary_logloss: 0.483342\n",
      "[478]\ttraining's binary_logloss: 0.48316\n",
      "[479]\ttraining's binary_logloss: 0.482977\n",
      "[480]\ttraining's binary_logloss: 0.482805\n",
      "[481]\ttraining's binary_logloss: 0.482615\n",
      "[482]\ttraining's binary_logloss: 0.482418\n",
      "[483]\ttraining's binary_logloss: 0.482231\n",
      "[484]\ttraining's binary_logloss: 0.482018\n",
      "[485]\ttraining's binary_logloss: 0.48181\n",
      "[486]\ttraining's binary_logloss: 0.481578\n",
      "[487]\ttraining's binary_logloss: 0.481382\n",
      "[488]\ttraining's binary_logloss: 0.481166\n",
      "[489]\ttraining's binary_logloss: 0.480965\n",
      "[490]\ttraining's binary_logloss: 0.480768\n",
      "[491]\ttraining's binary_logloss: 0.480574\n",
      "[492]\ttraining's binary_logloss: 0.48039\n",
      "[493]\ttraining's binary_logloss: 0.480187\n",
      "[494]\ttraining's binary_logloss: 0.479972\n",
      "[495]\ttraining's binary_logloss: 0.47979\n",
      "[496]\ttraining's binary_logloss: 0.479547\n",
      "[497]\ttraining's binary_logloss: 0.479351\n",
      "[498]\ttraining's binary_logloss: 0.479171\n",
      "[499]\ttraining's binary_logloss: 0.478982\n",
      "[500]\ttraining's binary_logloss: 0.478797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614726\n",
      "[2]\ttraining's binary_logloss: 0.61378\n",
      "[3]\ttraining's binary_logloss: 0.61288\n",
      "[4]\ttraining's binary_logloss: 0.612112\n",
      "[5]\ttraining's binary_logloss: 0.611156\n",
      "[6]\ttraining's binary_logloss: 0.610293\n",
      "[7]\ttraining's binary_logloss: 0.609467\n",
      "[8]\ttraining's binary_logloss: 0.608674\n",
      "[9]\ttraining's binary_logloss: 0.607937\n",
      "[10]\ttraining's binary_logloss: 0.607211\n",
      "[11]\ttraining's binary_logloss: 0.606419\n",
      "[12]\ttraining's binary_logloss: 0.605793\n",
      "[13]\ttraining's binary_logloss: 0.605108\n",
      "[14]\ttraining's binary_logloss: 0.604396\n",
      "[15]\ttraining's binary_logloss: 0.603708\n",
      "[16]\ttraining's binary_logloss: 0.603059\n",
      "[17]\ttraining's binary_logloss: 0.602439\n",
      "[18]\ttraining's binary_logloss: 0.601851\n",
      "[19]\ttraining's binary_logloss: 0.601247\n",
      "[20]\ttraining's binary_logloss: 0.60067\n",
      "[21]\ttraining's binary_logloss: 0.600144\n",
      "[22]\ttraining's binary_logloss: 0.599662\n",
      "[23]\ttraining's binary_logloss: 0.599137\n",
      "[24]\ttraining's binary_logloss: 0.598689\n",
      "[25]\ttraining's binary_logloss: 0.598254\n",
      "[26]\ttraining's binary_logloss: 0.597922\n",
      "[27]\ttraining's binary_logloss: 0.597509\n",
      "[28]\ttraining's binary_logloss: 0.597129\n",
      "[29]\ttraining's binary_logloss: 0.596727\n",
      "[30]\ttraining's binary_logloss: 0.596378\n",
      "[31]\ttraining's binary_logloss: 0.595995\n",
      "[32]\ttraining's binary_logloss: 0.595624\n",
      "[33]\ttraining's binary_logloss: 0.595273\n",
      "[34]\ttraining's binary_logloss: 0.594931\n",
      "[35]\ttraining's binary_logloss: 0.594598\n",
      "[36]\ttraining's binary_logloss: 0.594303\n",
      "[37]\ttraining's binary_logloss: 0.594054\n",
      "[38]\ttraining's binary_logloss: 0.593789\n",
      "[39]\ttraining's binary_logloss: 0.593537\n",
      "[40]\ttraining's binary_logloss: 0.593278\n",
      "[41]\ttraining's binary_logloss: 0.593016\n",
      "[42]\ttraining's binary_logloss: 0.592868\n",
      "[43]\ttraining's binary_logloss: 0.592642\n",
      "[44]\ttraining's binary_logloss: 0.592411\n",
      "[45]\ttraining's binary_logloss: 0.592194\n",
      "[46]\ttraining's binary_logloss: 0.59197\n",
      "[47]\ttraining's binary_logloss: 0.591756\n",
      "[48]\ttraining's binary_logloss: 0.591555\n",
      "[49]\ttraining's binary_logloss: 0.591366\n",
      "[50]\ttraining's binary_logloss: 0.591189\n",
      "[51]\ttraining's binary_logloss: 0.591025\n",
      "[52]\ttraining's binary_logloss: 0.590869\n",
      "[53]\ttraining's binary_logloss: 0.590726\n",
      "[54]\ttraining's binary_logloss: 0.590558\n",
      "[55]\ttraining's binary_logloss: 0.590412\n",
      "[56]\ttraining's binary_logloss: 0.59026\n",
      "[57]\ttraining's binary_logloss: 0.590077\n",
      "[58]\ttraining's binary_logloss: 0.5899\n",
      "[59]\ttraining's binary_logloss: 0.589734\n",
      "[60]\ttraining's binary_logloss: 0.589574\n",
      "[61]\ttraining's binary_logloss: 0.589461\n",
      "[62]\ttraining's binary_logloss: 0.589397\n",
      "[63]\ttraining's binary_logloss: 0.589305\n",
      "[64]\ttraining's binary_logloss: 0.589251\n",
      "[65]\ttraining's binary_logloss: 0.589225\n",
      "[66]\ttraining's binary_logloss: 0.5892\n",
      "[67]\ttraining's binary_logloss: 0.589187\n",
      "[68]\ttraining's binary_logloss: 0.589136\n",
      "[69]\ttraining's binary_logloss: 0.589045\n",
      "[70]\ttraining's binary_logloss: 0.589052\n",
      "[71]\ttraining's binary_logloss: 0.588984\n",
      "[72]\ttraining's binary_logloss: 0.588923\n",
      "[73]\ttraining's binary_logloss: 0.588931\n",
      "[74]\ttraining's binary_logloss: 0.588883\n",
      "[75]\ttraining's binary_logloss: 0.588883\n",
      "[76]\ttraining's binary_logloss: 0.588839\n",
      "[77]\ttraining's binary_logloss: 0.588801\n",
      "[78]\ttraining's binary_logloss: 0.588778\n",
      "[79]\ttraining's binary_logloss: 0.588743\n",
      "[80]\ttraining's binary_logloss: 0.58872\n",
      "[81]\ttraining's binary_logloss: 0.588728\n",
      "[82]\ttraining's binary_logloss: 0.588663\n",
      "[83]\ttraining's binary_logloss: 0.58868\n",
      "[84]\ttraining's binary_logloss: 0.588704\n",
      "[85]\ttraining's binary_logloss: 0.588735\n",
      "[86]\ttraining's binary_logloss: 0.588752\n",
      "[87]\ttraining's binary_logloss: 0.588752\n",
      "[88]\ttraining's binary_logloss: 0.588738\n",
      "[89]\ttraining's binary_logloss: 0.588717\n",
      "[90]\ttraining's binary_logloss: 0.588666\n",
      "[91]\ttraining's binary_logloss: 0.588646\n",
      "[92]\ttraining's binary_logloss: 0.588714\n",
      "[93]\ttraining's binary_logloss: 0.588701\n",
      "[94]\ttraining's binary_logloss: 0.588696\n",
      "[95]\ttraining's binary_logloss: 0.588729\n",
      "[96]\ttraining's binary_logloss: 0.588716\n",
      "[97]\ttraining's binary_logloss: 0.588713\n",
      "[98]\ttraining's binary_logloss: 0.588724\n",
      "[99]\ttraining's binary_logloss: 0.588737\n",
      "[100]\ttraining's binary_logloss: 0.588756\n",
      "[101]\ttraining's binary_logloss: 0.588752\n",
      "[102]\ttraining's binary_logloss: 0.588759\n",
      "[103]\ttraining's binary_logloss: 0.588776\n",
      "[104]\ttraining's binary_logloss: 0.588788\n",
      "[105]\ttraining's binary_logloss: 0.588801\n",
      "[106]\ttraining's binary_logloss: 0.588864\n",
      "[107]\ttraining's binary_logloss: 0.588865\n",
      "[108]\ttraining's binary_logloss: 0.588871\n",
      "[109]\ttraining's binary_logloss: 0.588932\n",
      "[110]\ttraining's binary_logloss: 0.588987\n",
      "[111]\ttraining's binary_logloss: 0.589024\n",
      "[112]\ttraining's binary_logloss: 0.589065\n",
      "[113]\ttraining's binary_logloss: 0.589083\n",
      "[114]\ttraining's binary_logloss: 0.589087\n",
      "[115]\ttraining's binary_logloss: 0.589094\n",
      "[116]\ttraining's binary_logloss: 0.5891\n",
      "[117]\ttraining's binary_logloss: 0.589104\n",
      "[118]\ttraining's binary_logloss: 0.589114\n",
      "[119]\ttraining's binary_logloss: 0.589127\n",
      "[120]\ttraining's binary_logloss: 0.589144\n",
      "[121]\ttraining's binary_logloss: 0.58916\n",
      "[122]\ttraining's binary_logloss: 0.589182\n",
      "[123]\ttraining's binary_logloss: 0.589212\n",
      "[124]\ttraining's binary_logloss: 0.589301\n",
      "[125]\ttraining's binary_logloss: 0.589391\n",
      "[126]\ttraining's binary_logloss: 0.589397\n",
      "[127]\ttraining's binary_logloss: 0.589423\n",
      "[128]\ttraining's binary_logloss: 0.58946\n",
      "[129]\ttraining's binary_logloss: 0.589495\n",
      "[130]\ttraining's binary_logloss: 0.589503\n",
      "[131]\ttraining's binary_logloss: 0.589586\n",
      "[132]\ttraining's binary_logloss: 0.589668\n",
      "[133]\ttraining's binary_logloss: 0.589755\n",
      "[134]\ttraining's binary_logloss: 0.589815\n",
      "[135]\ttraining's binary_logloss: 0.589881\n",
      "[136]\ttraining's binary_logloss: 0.589874\n",
      "[137]\ttraining's binary_logloss: 0.58994\n",
      "[138]\ttraining's binary_logloss: 0.59001\n",
      "[139]\ttraining's binary_logloss: 0.590013\n",
      "[140]\ttraining's binary_logloss: 0.590029\n",
      "[141]\ttraining's binary_logloss: 0.590082\n",
      "[142]\ttraining's binary_logloss: 0.590097\n",
      "[143]\ttraining's binary_logloss: 0.590147\n",
      "[144]\ttraining's binary_logloss: 0.590159\n",
      "[145]\ttraining's binary_logloss: 0.590178\n",
      "[146]\ttraining's binary_logloss: 0.590219\n",
      "[147]\ttraining's binary_logloss: 0.590254\n",
      "[148]\ttraining's binary_logloss: 0.590314\n",
      "[149]\ttraining's binary_logloss: 0.590351\n",
      "[150]\ttraining's binary_logloss: 0.590393\n",
      "[151]\ttraining's binary_logloss: 0.59044\n",
      "[152]\ttraining's binary_logloss: 0.590494\n",
      "[153]\ttraining's binary_logloss: 0.590542\n",
      "[154]\ttraining's binary_logloss: 0.59059\n",
      "[155]\ttraining's binary_logloss: 0.590665\n",
      "[156]\ttraining's binary_logloss: 0.590715\n",
      "[157]\ttraining's binary_logloss: 0.590732\n",
      "[158]\ttraining's binary_logloss: 0.590751\n",
      "[159]\ttraining's binary_logloss: 0.590808\n",
      "[160]\ttraining's binary_logloss: 0.590853\n",
      "[161]\ttraining's binary_logloss: 0.590893\n",
      "[162]\ttraining's binary_logloss: 0.590886\n",
      "[163]\ttraining's binary_logloss: 0.590876\n",
      "[164]\ttraining's binary_logloss: 0.590873\n",
      "[165]\ttraining's binary_logloss: 0.590869\n",
      "[166]\ttraining's binary_logloss: 0.590916\n",
      "[167]\ttraining's binary_logloss: 0.590958\n",
      "[168]\ttraining's binary_logloss: 0.59098\n",
      "[169]\ttraining's binary_logloss: 0.591018\n",
      "[170]\ttraining's binary_logloss: 0.591077\n",
      "[171]\ttraining's binary_logloss: 0.591094\n",
      "[172]\ttraining's binary_logloss: 0.591125\n",
      "[173]\ttraining's binary_logloss: 0.591151\n",
      "[174]\ttraining's binary_logloss: 0.591188\n",
      "[175]\ttraining's binary_logloss: 0.591219\n",
      "[176]\ttraining's binary_logloss: 0.591234\n",
      "[177]\ttraining's binary_logloss: 0.591242\n",
      "[178]\ttraining's binary_logloss: 0.591256\n",
      "[179]\ttraining's binary_logloss: 0.591297\n",
      "[180]\ttraining's binary_logloss: 0.591314\n",
      "[181]\ttraining's binary_logloss: 0.591331\n",
      "[182]\ttraining's binary_logloss: 0.591358\n",
      "[183]\ttraining's binary_logloss: 0.591384\n",
      "[184]\ttraining's binary_logloss: 0.591414\n",
      "[185]\ttraining's binary_logloss: 0.591402\n",
      "[186]\ttraining's binary_logloss: 0.591466\n",
      "[187]\ttraining's binary_logloss: 0.591534\n",
      "[188]\ttraining's binary_logloss: 0.591603\n",
      "[189]\ttraining's binary_logloss: 0.591668\n",
      "[190]\ttraining's binary_logloss: 0.591712\n",
      "[191]\ttraining's binary_logloss: 0.591738\n",
      "[192]\ttraining's binary_logloss: 0.591762\n",
      "[193]\ttraining's binary_logloss: 0.59177\n",
      "[194]\ttraining's binary_logloss: 0.591767\n",
      "[195]\ttraining's binary_logloss: 0.591793\n",
      "[196]\ttraining's binary_logloss: 0.591824\n",
      "[197]\ttraining's binary_logloss: 0.591831\n",
      "[198]\ttraining's binary_logloss: 0.591846\n",
      "[199]\ttraining's binary_logloss: 0.591862\n",
      "[200]\ttraining's binary_logloss: 0.591876\n",
      "[201]\ttraining's binary_logloss: 0.591918\n",
      "[202]\ttraining's binary_logloss: 0.591939\n",
      "[203]\ttraining's binary_logloss: 0.591972\n",
      "[204]\ttraining's binary_logloss: 0.591996\n",
      "[205]\ttraining's binary_logloss: 0.592017\n",
      "[206]\ttraining's binary_logloss: 0.591995\n",
      "[207]\ttraining's binary_logloss: 0.591962\n",
      "[208]\ttraining's binary_logloss: 0.591933\n",
      "[209]\ttraining's binary_logloss: 0.591903\n",
      "[210]\ttraining's binary_logloss: 0.591875\n",
      "[211]\ttraining's binary_logloss: 0.591916\n",
      "[212]\ttraining's binary_logloss: 0.591958\n",
      "[213]\ttraining's binary_logloss: 0.591998\n",
      "[214]\ttraining's binary_logloss: 0.592042\n",
      "[215]\ttraining's binary_logloss: 0.592066\n",
      "[216]\ttraining's binary_logloss: 0.592063\n",
      "[217]\ttraining's binary_logloss: 0.592048\n",
      "[218]\ttraining's binary_logloss: 0.592037\n",
      "[219]\ttraining's binary_logloss: 0.592029\n",
      "[220]\ttraining's binary_logloss: 0.59203\n",
      "[221]\ttraining's binary_logloss: 0.592008\n",
      "[222]\ttraining's binary_logloss: 0.591998\n",
      "[223]\ttraining's binary_logloss: 0.591989\n",
      "[224]\ttraining's binary_logloss: 0.591976\n",
      "[225]\ttraining's binary_logloss: 0.591969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[226]\ttraining's binary_logloss: 0.591947\n",
      "[227]\ttraining's binary_logloss: 0.591929\n",
      "[228]\ttraining's binary_logloss: 0.591914\n",
      "[229]\ttraining's binary_logloss: 0.591893\n",
      "[230]\ttraining's binary_logloss: 0.591888\n",
      "[231]\ttraining's binary_logloss: 0.591873\n",
      "[232]\ttraining's binary_logloss: 0.591886\n",
      "[233]\ttraining's binary_logloss: 0.591898\n",
      "[234]\ttraining's binary_logloss: 0.591913\n",
      "[235]\ttraining's binary_logloss: 0.591932\n",
      "[236]\ttraining's binary_logloss: 0.591901\n",
      "[237]\ttraining's binary_logloss: 0.591886\n",
      "[238]\ttraining's binary_logloss: 0.591858\n",
      "[239]\ttraining's binary_logloss: 0.591837\n",
      "[240]\ttraining's binary_logloss: 0.591832\n",
      "[241]\ttraining's binary_logloss: 0.59184\n",
      "[242]\ttraining's binary_logloss: 0.591849\n",
      "[243]\ttraining's binary_logloss: 0.591851\n",
      "[244]\ttraining's binary_logloss: 0.591843\n",
      "[245]\ttraining's binary_logloss: 0.591827\n",
      "[246]\ttraining's binary_logloss: 0.591784\n",
      "[247]\ttraining's binary_logloss: 0.591721\n",
      "[248]\ttraining's binary_logloss: 0.591663\n",
      "[249]\ttraining's binary_logloss: 0.591602\n",
      "[250]\ttraining's binary_logloss: 0.591549\n",
      "[251]\ttraining's binary_logloss: 0.591493\n",
      "[252]\ttraining's binary_logloss: 0.591471\n",
      "[253]\ttraining's binary_logloss: 0.591442\n",
      "[254]\ttraining's binary_logloss: 0.591387\n",
      "[255]\ttraining's binary_logloss: 0.591361\n",
      "[256]\ttraining's binary_logloss: 0.591348\n",
      "[257]\ttraining's binary_logloss: 0.591331\n",
      "[258]\ttraining's binary_logloss: 0.591319\n",
      "[259]\ttraining's binary_logloss: 0.591316\n",
      "[260]\ttraining's binary_logloss: 0.591282\n",
      "[261]\ttraining's binary_logloss: 0.5913\n",
      "[262]\ttraining's binary_logloss: 0.591317\n",
      "[263]\ttraining's binary_logloss: 0.591342\n",
      "[264]\ttraining's binary_logloss: 0.591327\n",
      "[265]\ttraining's binary_logloss: 0.591344\n",
      "[266]\ttraining's binary_logloss: 0.59135\n",
      "[267]\ttraining's binary_logloss: 0.591344\n",
      "[268]\ttraining's binary_logloss: 0.591362\n",
      "[269]\ttraining's binary_logloss: 0.591355\n",
      "[270]\ttraining's binary_logloss: 0.591373\n",
      "[271]\ttraining's binary_logloss: 0.591329\n",
      "[272]\ttraining's binary_logloss: 0.591313\n",
      "[273]\ttraining's binary_logloss: 0.591299\n",
      "[274]\ttraining's binary_logloss: 0.591309\n",
      "[275]\ttraining's binary_logloss: 0.591314\n",
      "[276]\ttraining's binary_logloss: 0.591279\n",
      "[277]\ttraining's binary_logloss: 0.591266\n",
      "[278]\ttraining's binary_logloss: 0.591231\n",
      "[279]\ttraining's binary_logloss: 0.591198\n",
      "[280]\ttraining's binary_logloss: 0.591165\n",
      "[281]\ttraining's binary_logloss: 0.591155\n",
      "[282]\ttraining's binary_logloss: 0.591145\n",
      "[283]\ttraining's binary_logloss: 0.591148\n",
      "[284]\ttraining's binary_logloss: 0.591138\n",
      "[285]\ttraining's binary_logloss: 0.591151\n",
      "[286]\ttraining's binary_logloss: 0.591111\n",
      "[287]\ttraining's binary_logloss: 0.591067\n",
      "[288]\ttraining's binary_logloss: 0.59103\n",
      "[289]\ttraining's binary_logloss: 0.59098\n",
      "[290]\ttraining's binary_logloss: 0.590937\n",
      "[291]\ttraining's binary_logloss: 0.590877\n",
      "[292]\ttraining's binary_logloss: 0.590815\n",
      "[293]\ttraining's binary_logloss: 0.590757\n",
      "[294]\ttraining's binary_logloss: 0.590703\n",
      "[295]\ttraining's binary_logloss: 0.590638\n",
      "[296]\ttraining's binary_logloss: 0.59062\n",
      "[297]\ttraining's binary_logloss: 0.590604\n",
      "[298]\ttraining's binary_logloss: 0.590582\n",
      "[299]\ttraining's binary_logloss: 0.590561\n",
      "[300]\ttraining's binary_logloss: 0.590543\n",
      "[301]\ttraining's binary_logloss: 0.59049\n",
      "[302]\ttraining's binary_logloss: 0.590438\n",
      "[303]\ttraining's binary_logloss: 0.590416\n",
      "[304]\ttraining's binary_logloss: 0.590369\n",
      "[305]\ttraining's binary_logloss: 0.590322\n",
      "[306]\ttraining's binary_logloss: 0.590286\n",
      "[307]\ttraining's binary_logloss: 0.590251\n",
      "[308]\ttraining's binary_logloss: 0.59022\n",
      "[309]\ttraining's binary_logloss: 0.590181\n",
      "[310]\ttraining's binary_logloss: 0.590148\n",
      "[311]\ttraining's binary_logloss: 0.590087\n",
      "[312]\ttraining's binary_logloss: 0.590026\n",
      "[313]\ttraining's binary_logloss: 0.589966\n",
      "[314]\ttraining's binary_logloss: 0.58992\n",
      "[315]\ttraining's binary_logloss: 0.589864\n",
      "[316]\ttraining's binary_logloss: 0.589817\n",
      "[317]\ttraining's binary_logloss: 0.589775\n",
      "[318]\ttraining's binary_logloss: 0.589735\n",
      "[319]\ttraining's binary_logloss: 0.589693\n",
      "[320]\ttraining's binary_logloss: 0.589654\n",
      "[321]\ttraining's binary_logloss: 0.589622\n",
      "[322]\ttraining's binary_logloss: 0.589572\n",
      "[323]\ttraining's binary_logloss: 0.589546\n",
      "[324]\ttraining's binary_logloss: 0.589497\n",
      "[325]\ttraining's binary_logloss: 0.589474\n",
      "[326]\ttraining's binary_logloss: 0.589414\n",
      "[327]\ttraining's binary_logloss: 0.589351\n",
      "[328]\ttraining's binary_logloss: 0.589292\n",
      "[329]\ttraining's binary_logloss: 0.589229\n",
      "[330]\ttraining's binary_logloss: 0.589172\n",
      "[331]\ttraining's binary_logloss: 0.589125\n",
      "[332]\ttraining's binary_logloss: 0.58907\n",
      "[333]\ttraining's binary_logloss: 0.589013\n",
      "[334]\ttraining's binary_logloss: 0.588964\n",
      "[335]\ttraining's binary_logloss: 0.588919\n",
      "[336]\ttraining's binary_logloss: 0.588898\n",
      "[337]\ttraining's binary_logloss: 0.588879\n",
      "[338]\ttraining's binary_logloss: 0.588857\n",
      "[339]\ttraining's binary_logloss: 0.588847\n",
      "[340]\ttraining's binary_logloss: 0.588828\n",
      "[341]\ttraining's binary_logloss: 0.588781\n",
      "[342]\ttraining's binary_logloss: 0.58875\n",
      "[343]\ttraining's binary_logloss: 0.588722\n",
      "[344]\ttraining's binary_logloss: 0.588685\n",
      "[345]\ttraining's binary_logloss: 0.588648\n",
      "[346]\ttraining's binary_logloss: 0.588602\n",
      "[347]\ttraining's binary_logloss: 0.588542\n",
      "[348]\ttraining's binary_logloss: 0.588482\n",
      "[349]\ttraining's binary_logloss: 0.588424\n",
      "[350]\ttraining's binary_logloss: 0.588372\n",
      "[351]\ttraining's binary_logloss: 0.588359\n",
      "[352]\ttraining's binary_logloss: 0.588352\n",
      "[353]\ttraining's binary_logloss: 0.588345\n",
      "[354]\ttraining's binary_logloss: 0.588334\n",
      "[355]\ttraining's binary_logloss: 0.588324\n",
      "[356]\ttraining's binary_logloss: 0.588284\n",
      "[357]\ttraining's binary_logloss: 0.588246\n",
      "[358]\ttraining's binary_logloss: 0.588207\n",
      "[359]\ttraining's binary_logloss: 0.588159\n",
      "[360]\ttraining's binary_logloss: 0.588112\n",
      "[361]\ttraining's binary_logloss: 0.58805\n",
      "[362]\ttraining's binary_logloss: 0.587977\n",
      "[363]\ttraining's binary_logloss: 0.587906\n",
      "[364]\ttraining's binary_logloss: 0.587849\n",
      "[365]\ttraining's binary_logloss: 0.587783\n",
      "[366]\ttraining's binary_logloss: 0.587743\n",
      "[367]\ttraining's binary_logloss: 0.58769\n",
      "[368]\ttraining's binary_logloss: 0.587644\n",
      "[369]\ttraining's binary_logloss: 0.587593\n",
      "[370]\ttraining's binary_logloss: 0.587549\n",
      "[371]\ttraining's binary_logloss: 0.587488\n",
      "[372]\ttraining's binary_logloss: 0.587424\n",
      "[373]\ttraining's binary_logloss: 0.587361\n",
      "[374]\ttraining's binary_logloss: 0.587298\n",
      "[375]\ttraining's binary_logloss: 0.587247\n",
      "[376]\ttraining's binary_logloss: 0.587198\n",
      "[377]\ttraining's binary_logloss: 0.587136\n",
      "[378]\ttraining's binary_logloss: 0.587087\n",
      "[379]\ttraining's binary_logloss: 0.587036\n",
      "[380]\ttraining's binary_logloss: 0.586989\n",
      "[381]\ttraining's binary_logloss: 0.586905\n",
      "[382]\ttraining's binary_logloss: 0.586822\n",
      "[383]\ttraining's binary_logloss: 0.586744\n",
      "[384]\ttraining's binary_logloss: 0.586671\n",
      "[385]\ttraining's binary_logloss: 0.5866\n",
      "[386]\ttraining's binary_logloss: 0.586526\n",
      "[387]\ttraining's binary_logloss: 0.586479\n",
      "[388]\ttraining's binary_logloss: 0.586411\n",
      "[389]\ttraining's binary_logloss: 0.586358\n",
      "[390]\ttraining's binary_logloss: 0.5863\n",
      "[391]\ttraining's binary_logloss: 0.586229\n",
      "[392]\ttraining's binary_logloss: 0.58615\n",
      "[393]\ttraining's binary_logloss: 0.58608\n",
      "[394]\ttraining's binary_logloss: 0.586016\n",
      "[395]\ttraining's binary_logloss: 0.585945\n",
      "[396]\ttraining's binary_logloss: 0.585888\n",
      "[397]\ttraining's binary_logloss: 0.585853\n",
      "[398]\ttraining's binary_logloss: 0.585798\n",
      "[399]\ttraining's binary_logloss: 0.585754\n",
      "[400]\ttraining's binary_logloss: 0.585705\n",
      "[401]\ttraining's binary_logloss: 0.585655\n",
      "[402]\ttraining's binary_logloss: 0.585612\n",
      "[403]\ttraining's binary_logloss: 0.585578\n",
      "[404]\ttraining's binary_logloss: 0.585537\n",
      "[405]\ttraining's binary_logloss: 0.585498\n",
      "[406]\ttraining's binary_logloss: 0.585458\n",
      "[407]\ttraining's binary_logloss: 0.585427\n",
      "[408]\ttraining's binary_logloss: 0.585366\n",
      "[409]\ttraining's binary_logloss: 0.585286\n",
      "[410]\ttraining's binary_logloss: 0.585256\n",
      "[411]\ttraining's binary_logloss: 0.585194\n",
      "[412]\ttraining's binary_logloss: 0.585128\n",
      "[413]\ttraining's binary_logloss: 0.585067\n",
      "[414]\ttraining's binary_logloss: 0.585008\n",
      "[415]\ttraining's binary_logloss: 0.58495\n",
      "[416]\ttraining's binary_logloss: 0.584882\n",
      "[417]\ttraining's binary_logloss: 0.584827\n",
      "[418]\ttraining's binary_logloss: 0.584781\n",
      "[419]\ttraining's binary_logloss: 0.584722\n",
      "[420]\ttraining's binary_logloss: 0.584673\n",
      "[421]\ttraining's binary_logloss: 0.584639\n",
      "[422]\ttraining's binary_logloss: 0.584597\n",
      "[423]\ttraining's binary_logloss: 0.584562\n",
      "[424]\ttraining's binary_logloss: 0.584526\n",
      "[425]\ttraining's binary_logloss: 0.584487\n",
      "[426]\ttraining's binary_logloss: 0.584443\n",
      "[427]\ttraining's binary_logloss: 0.584383\n",
      "[428]\ttraining's binary_logloss: 0.584332\n",
      "[429]\ttraining's binary_logloss: 0.584278\n",
      "[430]\ttraining's binary_logloss: 0.584228\n",
      "[431]\ttraining's binary_logloss: 0.584167\n",
      "[432]\ttraining's binary_logloss: 0.584107\n",
      "[433]\ttraining's binary_logloss: 0.584041\n",
      "[434]\ttraining's binary_logloss: 0.583979\n",
      "[435]\ttraining's binary_logloss: 0.583915\n",
      "[436]\ttraining's binary_logloss: 0.583874\n",
      "[437]\ttraining's binary_logloss: 0.583827\n",
      "[438]\ttraining's binary_logloss: 0.583769\n",
      "[439]\ttraining's binary_logloss: 0.583731\n",
      "[440]\ttraining's binary_logloss: 0.583697\n",
      "[441]\ttraining's binary_logloss: 0.583641\n",
      "[442]\ttraining's binary_logloss: 0.583587\n",
      "[443]\ttraining's binary_logloss: 0.583535\n",
      "[444]\ttraining's binary_logloss: 0.583483\n",
      "[445]\ttraining's binary_logloss: 0.583426\n",
      "[446]\ttraining's binary_logloss: 0.583342\n",
      "[447]\ttraining's binary_logloss: 0.583258\n",
      "[448]\ttraining's binary_logloss: 0.583182\n",
      "[449]\ttraining's binary_logloss: 0.583107\n",
      "[450]\ttraining's binary_logloss: 0.583035\n",
      "[451]\ttraining's binary_logloss: 0.582969\n",
      "[452]\ttraining's binary_logloss: 0.582892\n",
      "[453]\ttraining's binary_logloss: 0.582827\n",
      "[454]\ttraining's binary_logloss: 0.582759\n",
      "[455]\ttraining's binary_logloss: 0.582693\n",
      "[456]\ttraining's binary_logloss: 0.582637\n",
      "[457]\ttraining's binary_logloss: 0.582582\n",
      "[458]\ttraining's binary_logloss: 0.582536\n",
      "[459]\ttraining's binary_logloss: 0.582465\n",
      "[460]\ttraining's binary_logloss: 0.58242\n",
      "[461]\ttraining's binary_logloss: 0.582361\n",
      "[462]\ttraining's binary_logloss: 0.582296\n",
      "[463]\ttraining's binary_logloss: 0.582234\n",
      "[464]\ttraining's binary_logloss: 0.582171\n",
      "[465]\ttraining's binary_logloss: 0.58211\n",
      "[466]\ttraining's binary_logloss: 0.58207\n",
      "[467]\ttraining's binary_logloss: 0.582014\n",
      "[468]\ttraining's binary_logloss: 0.58197\n",
      "[469]\ttraining's binary_logloss: 0.581931\n",
      "[470]\ttraining's binary_logloss: 0.581878\n",
      "[471]\ttraining's binary_logloss: 0.581795\n",
      "[472]\ttraining's binary_logloss: 0.581706\n",
      "[473]\ttraining's binary_logloss: 0.581628\n",
      "[474]\ttraining's binary_logloss: 0.581561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[475]\ttraining's binary_logloss: 0.581489\n",
      "[476]\ttraining's binary_logloss: 0.581436\n",
      "[477]\ttraining's binary_logloss: 0.581393\n",
      "[478]\ttraining's binary_logloss: 0.58133\n",
      "[479]\ttraining's binary_logloss: 0.581255\n",
      "[480]\ttraining's binary_logloss: 0.581209\n",
      "[481]\ttraining's binary_logloss: 0.581183\n",
      "[482]\ttraining's binary_logloss: 0.581157\n",
      "[483]\ttraining's binary_logloss: 0.581125\n",
      "[484]\ttraining's binary_logloss: 0.581095\n",
      "[485]\ttraining's binary_logloss: 0.58107\n",
      "[486]\ttraining's binary_logloss: 0.580994\n",
      "[487]\ttraining's binary_logloss: 0.580921\n",
      "[488]\ttraining's binary_logloss: 0.580843\n",
      "[489]\ttraining's binary_logloss: 0.58077\n",
      "[490]\ttraining's binary_logloss: 0.580686\n",
      "[491]\ttraining's binary_logloss: 0.580585\n",
      "[492]\ttraining's binary_logloss: 0.580487\n",
      "[493]\ttraining's binary_logloss: 0.580391\n",
      "[494]\ttraining's binary_logloss: 0.580309\n",
      "[495]\ttraining's binary_logloss: 0.580216\n",
      "[496]\ttraining's binary_logloss: 0.580138\n",
      "[497]\ttraining's binary_logloss: 0.580062\n",
      "[498]\ttraining's binary_logloss: 0.579997\n",
      "[499]\ttraining's binary_logloss: 0.579929\n",
      "[500]\ttraining's binary_logloss: 0.579856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614426\n",
      "[2]\ttraining's binary_logloss: 0.613176\n",
      "[3]\ttraining's binary_logloss: 0.612007\n",
      "[4]\ttraining's binary_logloss: 0.610984\n",
      "[5]\ttraining's binary_logloss: 0.609778\n",
      "[6]\ttraining's binary_logloss: 0.608699\n",
      "[7]\ttraining's binary_logloss: 0.60767\n",
      "[8]\ttraining's binary_logloss: 0.60656\n",
      "[9]\ttraining's binary_logloss: 0.605604\n",
      "[10]\ttraining's binary_logloss: 0.604582\n",
      "[11]\ttraining's binary_logloss: 0.603629\n",
      "[12]\ttraining's binary_logloss: 0.602772\n",
      "[13]\ttraining's binary_logloss: 0.601937\n",
      "[14]\ttraining's binary_logloss: 0.601041\n",
      "[15]\ttraining's binary_logloss: 0.600177\n",
      "[16]\ttraining's binary_logloss: 0.599338\n",
      "[17]\ttraining's binary_logloss: 0.598521\n",
      "[18]\ttraining's binary_logloss: 0.597771\n",
      "[19]\ttraining's binary_logloss: 0.597011\n",
      "[20]\ttraining's binary_logloss: 0.596309\n",
      "[21]\ttraining's binary_logloss: 0.595661\n",
      "[22]\ttraining's binary_logloss: 0.595056\n",
      "[23]\ttraining's binary_logloss: 0.594378\n",
      "[24]\ttraining's binary_logloss: 0.593816\n",
      "[25]\ttraining's binary_logloss: 0.593257\n",
      "[26]\ttraining's binary_logloss: 0.592758\n",
      "[27]\ttraining's binary_logloss: 0.592135\n",
      "[28]\ttraining's binary_logloss: 0.591606\n",
      "[29]\ttraining's binary_logloss: 0.591018\n",
      "[30]\ttraining's binary_logloss: 0.590424\n",
      "[31]\ttraining's binary_logloss: 0.589886\n",
      "[32]\ttraining's binary_logloss: 0.589339\n",
      "[33]\ttraining's binary_logloss: 0.588845\n",
      "[34]\ttraining's binary_logloss: 0.588348\n",
      "[35]\ttraining's binary_logloss: 0.587798\n",
      "[36]\ttraining's binary_logloss: 0.587363\n",
      "[37]\ttraining's binary_logloss: 0.586971\n",
      "[38]\ttraining's binary_logloss: 0.586562\n",
      "[39]\ttraining's binary_logloss: 0.586157\n",
      "[40]\ttraining's binary_logloss: 0.585758\n",
      "[41]\ttraining's binary_logloss: 0.585352\n",
      "[42]\ttraining's binary_logloss: 0.585074\n",
      "[43]\ttraining's binary_logloss: 0.584753\n",
      "[44]\ttraining's binary_logloss: 0.584385\n",
      "[45]\ttraining's binary_logloss: 0.584019\n",
      "[46]\ttraining's binary_logloss: 0.583669\n",
      "[47]\ttraining's binary_logloss: 0.583329\n",
      "[48]\ttraining's binary_logloss: 0.583005\n",
      "[49]\ttraining's binary_logloss: 0.58267\n",
      "[50]\ttraining's binary_logloss: 0.582351\n",
      "[51]\ttraining's binary_logloss: 0.582089\n",
      "[52]\ttraining's binary_logloss: 0.581828\n",
      "[53]\ttraining's binary_logloss: 0.581561\n",
      "[54]\ttraining's binary_logloss: 0.581314\n",
      "[55]\ttraining's binary_logloss: 0.581063\n",
      "[56]\ttraining's binary_logloss: 0.580814\n",
      "[57]\ttraining's binary_logloss: 0.580525\n",
      "[58]\ttraining's binary_logloss: 0.580255\n",
      "[59]\ttraining's binary_logloss: 0.579985\n",
      "[60]\ttraining's binary_logloss: 0.579726\n",
      "[61]\ttraining's binary_logloss: 0.579519\n",
      "[62]\ttraining's binary_logloss: 0.579353\n",
      "[63]\ttraining's binary_logloss: 0.579167\n",
      "[64]\ttraining's binary_logloss: 0.578974\n",
      "[65]\ttraining's binary_logloss: 0.578847\n",
      "[66]\ttraining's binary_logloss: 0.578708\n",
      "[67]\ttraining's binary_logloss: 0.57857\n",
      "[68]\ttraining's binary_logloss: 0.57839\n",
      "[69]\ttraining's binary_logloss: 0.578232\n",
      "[70]\ttraining's binary_logloss: 0.578051\n",
      "[71]\ttraining's binary_logloss: 0.577863\n",
      "[72]\ttraining's binary_logloss: 0.57769\n",
      "[73]\ttraining's binary_logloss: 0.577593\n",
      "[74]\ttraining's binary_logloss: 0.577427\n",
      "[75]\ttraining's binary_logloss: 0.5773\n",
      "[76]\ttraining's binary_logloss: 0.577183\n",
      "[77]\ttraining's binary_logloss: 0.577077\n",
      "[78]\ttraining's binary_logloss: 0.576994\n",
      "[79]\ttraining's binary_logloss: 0.576863\n",
      "[80]\ttraining's binary_logloss: 0.576772\n",
      "[81]\ttraining's binary_logloss: 0.576683\n",
      "[82]\ttraining's binary_logloss: 0.576561\n",
      "[83]\ttraining's binary_logloss: 0.576466\n",
      "[84]\ttraining's binary_logloss: 0.576378\n",
      "[85]\ttraining's binary_logloss: 0.576301\n",
      "[86]\ttraining's binary_logloss: 0.576213\n",
      "[87]\ttraining's binary_logloss: 0.576112\n",
      "[88]\ttraining's binary_logloss: 0.576013\n",
      "[89]\ttraining's binary_logloss: 0.575901\n",
      "[90]\ttraining's binary_logloss: 0.57579\n",
      "[91]\ttraining's binary_logloss: 0.575688\n",
      "[92]\ttraining's binary_logloss: 0.575672\n",
      "[93]\ttraining's binary_logloss: 0.575611\n",
      "[94]\ttraining's binary_logloss: 0.575554\n",
      "[95]\ttraining's binary_logloss: 0.575525\n",
      "[96]\ttraining's binary_logloss: 0.575442\n",
      "[97]\ttraining's binary_logloss: 0.575351\n",
      "[98]\ttraining's binary_logloss: 0.575262\n",
      "[99]\ttraining's binary_logloss: 0.575205\n",
      "[100]\ttraining's binary_logloss: 0.575125\n",
      "[101]\ttraining's binary_logloss: 0.575037\n",
      "[102]\ttraining's binary_logloss: 0.574951\n",
      "[103]\ttraining's binary_logloss: 0.574875\n",
      "[104]\ttraining's binary_logloss: 0.574788\n",
      "[105]\ttraining's binary_logloss: 0.5747\n",
      "[106]\ttraining's binary_logloss: 0.574673\n",
      "[107]\ttraining's binary_logloss: 0.574651\n",
      "[108]\ttraining's binary_logloss: 0.574568\n",
      "[109]\ttraining's binary_logloss: 0.57455\n",
      "[110]\ttraining's binary_logloss: 0.57449\n",
      "[111]\ttraining's binary_logloss: 0.574401\n",
      "[112]\ttraining's binary_logloss: 0.574341\n",
      "[113]\ttraining's binary_logloss: 0.574255\n",
      "[114]\ttraining's binary_logloss: 0.574146\n",
      "[115]\ttraining's binary_logloss: 0.574047\n",
      "[116]\ttraining's binary_logloss: 0.573962\n",
      "[117]\ttraining's binary_logloss: 0.573891\n",
      "[118]\ttraining's binary_logloss: 0.573815\n",
      "[119]\ttraining's binary_logloss: 0.573766\n",
      "[120]\ttraining's binary_logloss: 0.573706\n",
      "[121]\ttraining's binary_logloss: 0.573664\n",
      "[122]\ttraining's binary_logloss: 0.573617\n",
      "[123]\ttraining's binary_logloss: 0.573613\n",
      "[124]\ttraining's binary_logloss: 0.573604\n",
      "[125]\ttraining's binary_logloss: 0.57361\n",
      "[126]\ttraining's binary_logloss: 0.573546\n",
      "[127]\ttraining's binary_logloss: 0.573492\n",
      "[128]\ttraining's binary_logloss: 0.573449\n",
      "[129]\ttraining's binary_logloss: 0.573394\n",
      "[130]\ttraining's binary_logloss: 0.573316\n",
      "[131]\ttraining's binary_logloss: 0.573318\n",
      "[132]\ttraining's binary_logloss: 0.573277\n",
      "[133]\ttraining's binary_logloss: 0.573244\n",
      "[134]\ttraining's binary_logloss: 0.573202\n",
      "[135]\ttraining's binary_logloss: 0.573196\n",
      "[136]\ttraining's binary_logloss: 0.573132\n",
      "[137]\ttraining's binary_logloss: 0.573115\n",
      "[138]\ttraining's binary_logloss: 0.5731\n",
      "[139]\ttraining's binary_logloss: 0.573082\n",
      "[140]\ttraining's binary_logloss: 0.573037\n",
      "[141]\ttraining's binary_logloss: 0.573004\n",
      "[142]\ttraining's binary_logloss: 0.573007\n",
      "[143]\ttraining's binary_logloss: 0.572959\n",
      "[144]\ttraining's binary_logloss: 0.572934\n",
      "[145]\ttraining's binary_logloss: 0.572934\n",
      "[146]\ttraining's binary_logloss: 0.572887\n",
      "[147]\ttraining's binary_logloss: 0.572825\n",
      "[148]\ttraining's binary_logloss: 0.572812\n",
      "[149]\ttraining's binary_logloss: 0.572755\n",
      "[150]\ttraining's binary_logloss: 0.572738\n",
      "[151]\ttraining's binary_logloss: 0.572713\n",
      "[152]\ttraining's binary_logloss: 0.572693\n",
      "[153]\ttraining's binary_logloss: 0.572679\n",
      "[154]\ttraining's binary_logloss: 0.572643\n",
      "[155]\ttraining's binary_logloss: 0.572616\n",
      "[156]\ttraining's binary_logloss: 0.572577\n",
      "[157]\ttraining's binary_logloss: 0.572555\n",
      "[158]\ttraining's binary_logloss: 0.572515\n",
      "[159]\ttraining's binary_logloss: 0.572444\n",
      "[160]\ttraining's binary_logloss: 0.572405\n",
      "[161]\ttraining's binary_logloss: 0.572365\n",
      "[162]\ttraining's binary_logloss: 0.572297\n",
      "[163]\ttraining's binary_logloss: 0.572232\n",
      "[164]\ttraining's binary_logloss: 0.572157\n",
      "[165]\ttraining's binary_logloss: 0.572102\n",
      "[166]\ttraining's binary_logloss: 0.572043\n",
      "[167]\ttraining's binary_logloss: 0.571993\n",
      "[168]\ttraining's binary_logloss: 0.57194\n",
      "[169]\ttraining's binary_logloss: 0.571882\n",
      "[170]\ttraining's binary_logloss: 0.571849\n",
      "[171]\ttraining's binary_logloss: 0.57183\n",
      "[172]\ttraining's binary_logloss: 0.5718\n",
      "[173]\ttraining's binary_logloss: 0.571772\n",
      "[174]\ttraining's binary_logloss: 0.571744\n",
      "[175]\ttraining's binary_logloss: 0.571708\n",
      "[176]\ttraining's binary_logloss: 0.571679\n",
      "[177]\ttraining's binary_logloss: 0.571634\n",
      "[178]\ttraining's binary_logloss: 0.57159\n",
      "[179]\ttraining's binary_logloss: 0.571558\n",
      "[180]\ttraining's binary_logloss: 0.571532\n",
      "[181]\ttraining's binary_logloss: 0.571491\n",
      "[182]\ttraining's binary_logloss: 0.571448\n",
      "[183]\ttraining's binary_logloss: 0.571407\n",
      "[184]\ttraining's binary_logloss: 0.571349\n",
      "[185]\ttraining's binary_logloss: 0.571293\n",
      "[186]\ttraining's binary_logloss: 0.571254\n",
      "[187]\ttraining's binary_logloss: 0.571219\n",
      "[188]\ttraining's binary_logloss: 0.571211\n",
      "[189]\ttraining's binary_logloss: 0.571196\n",
      "[190]\ttraining's binary_logloss: 0.571171\n",
      "[191]\ttraining's binary_logloss: 0.571127\n",
      "[192]\ttraining's binary_logloss: 0.571072\n",
      "[193]\ttraining's binary_logloss: 0.571004\n",
      "[194]\ttraining's binary_logloss: 0.570941\n",
      "[195]\ttraining's binary_logloss: 0.570883\n",
      "[196]\ttraining's binary_logloss: 0.570846\n",
      "[197]\ttraining's binary_logloss: 0.570814\n",
      "[198]\ttraining's binary_logloss: 0.570775\n",
      "[199]\ttraining's binary_logloss: 0.570718\n",
      "[200]\ttraining's binary_logloss: 0.570679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[201]\ttraining's binary_logloss: 0.570644\n",
      "[202]\ttraining's binary_logloss: 0.570609\n",
      "[203]\ttraining's binary_logloss: 0.570577\n",
      "[204]\ttraining's binary_logloss: 0.570545\n",
      "[205]\ttraining's binary_logloss: 0.570515\n",
      "[206]\ttraining's binary_logloss: 0.570423\n",
      "[207]\ttraining's binary_logloss: 0.570326\n",
      "[208]\ttraining's binary_logloss: 0.570259\n",
      "[209]\ttraining's binary_logloss: 0.57016\n",
      "[210]\ttraining's binary_logloss: 0.570092\n",
      "[211]\ttraining's binary_logloss: 0.570046\n",
      "[212]\ttraining's binary_logloss: 0.570003\n",
      "[213]\ttraining's binary_logloss: 0.569975\n",
      "[214]\ttraining's binary_logloss: 0.569947\n",
      "[215]\ttraining's binary_logloss: 0.569912\n",
      "[216]\ttraining's binary_logloss: 0.56984\n",
      "[217]\ttraining's binary_logloss: 0.569757\n",
      "[218]\ttraining's binary_logloss: 0.569694\n",
      "[219]\ttraining's binary_logloss: 0.569614\n",
      "[220]\ttraining's binary_logloss: 0.569523\n",
      "[221]\ttraining's binary_logloss: 0.569443\n",
      "[222]\ttraining's binary_logloss: 0.569362\n",
      "[223]\ttraining's binary_logloss: 0.569284\n",
      "[224]\ttraining's binary_logloss: 0.569214\n",
      "[225]\ttraining's binary_logloss: 0.569157\n",
      "[226]\ttraining's binary_logloss: 0.569051\n",
      "[227]\ttraining's binary_logloss: 0.568947\n",
      "[228]\ttraining's binary_logloss: 0.568873\n",
      "[229]\ttraining's binary_logloss: 0.568779\n",
      "[230]\ttraining's binary_logloss: 0.568707\n",
      "[231]\ttraining's binary_logloss: 0.56864\n",
      "[232]\ttraining's binary_logloss: 0.568587\n",
      "[233]\ttraining's binary_logloss: 0.568531\n",
      "[234]\ttraining's binary_logloss: 0.568481\n",
      "[235]\ttraining's binary_logloss: 0.568455\n",
      "[236]\ttraining's binary_logloss: 0.568362\n",
      "[237]\ttraining's binary_logloss: 0.568249\n",
      "[238]\ttraining's binary_logloss: 0.568137\n",
      "[239]\ttraining's binary_logloss: 0.568044\n",
      "[240]\ttraining's binary_logloss: 0.567969\n",
      "[241]\ttraining's binary_logloss: 0.567915\n",
      "[242]\ttraining's binary_logloss: 0.567865\n",
      "[243]\ttraining's binary_logloss: 0.567767\n",
      "[244]\ttraining's binary_logloss: 0.567694\n",
      "[245]\ttraining's binary_logloss: 0.567615\n",
      "[246]\ttraining's binary_logloss: 0.567509\n",
      "[247]\ttraining's binary_logloss: 0.567398\n",
      "[248]\ttraining's binary_logloss: 0.567263\n",
      "[249]\ttraining's binary_logloss: 0.567155\n",
      "[250]\ttraining's binary_logloss: 0.567038\n",
      "[251]\ttraining's binary_logloss: 0.56693\n",
      "[252]\ttraining's binary_logloss: 0.566853\n",
      "[253]\ttraining's binary_logloss: 0.56676\n",
      "[254]\ttraining's binary_logloss: 0.566667\n",
      "[255]\ttraining's binary_logloss: 0.566561\n",
      "[256]\ttraining's binary_logloss: 0.566496\n",
      "[257]\ttraining's binary_logloss: 0.566431\n",
      "[258]\ttraining's binary_logloss: 0.566354\n",
      "[259]\ttraining's binary_logloss: 0.566292\n",
      "[260]\ttraining's binary_logloss: 0.566225\n",
      "[261]\ttraining's binary_logloss: 0.566147\n",
      "[262]\ttraining's binary_logloss: 0.566092\n",
      "[263]\ttraining's binary_logloss: 0.566035\n",
      "[264]\ttraining's binary_logloss: 0.565971\n",
      "[265]\ttraining's binary_logloss: 0.565921\n",
      "[266]\ttraining's binary_logloss: 0.565881\n",
      "[267]\ttraining's binary_logloss: 0.565849\n",
      "[268]\ttraining's binary_logloss: 0.565824\n",
      "[269]\ttraining's binary_logloss: 0.565784\n",
      "[270]\ttraining's binary_logloss: 0.565748\n",
      "[271]\ttraining's binary_logloss: 0.565631\n",
      "[272]\ttraining's binary_logloss: 0.565537\n",
      "[273]\ttraining's binary_logloss: 0.565449\n",
      "[274]\ttraining's binary_logloss: 0.56537\n",
      "[275]\ttraining's binary_logloss: 0.565293\n",
      "[276]\ttraining's binary_logloss: 0.565207\n",
      "[277]\ttraining's binary_logloss: 0.565125\n",
      "[278]\ttraining's binary_logloss: 0.565044\n",
      "[279]\ttraining's binary_logloss: 0.564962\n",
      "[280]\ttraining's binary_logloss: 0.564879\n",
      "[281]\ttraining's binary_logloss: 0.564823\n",
      "[282]\ttraining's binary_logloss: 0.564783\n",
      "[283]\ttraining's binary_logloss: 0.564736\n",
      "[284]\ttraining's binary_logloss: 0.564684\n",
      "[285]\ttraining's binary_logloss: 0.56464\n",
      "[286]\ttraining's binary_logloss: 0.564538\n",
      "[287]\ttraining's binary_logloss: 0.564437\n",
      "[288]\ttraining's binary_logloss: 0.564325\n",
      "[289]\ttraining's binary_logloss: 0.564241\n",
      "[290]\ttraining's binary_logloss: 0.564144\n",
      "[291]\ttraining's binary_logloss: 0.564048\n",
      "[292]\ttraining's binary_logloss: 0.56395\n",
      "[293]\ttraining's binary_logloss: 0.563822\n",
      "[294]\ttraining's binary_logloss: 0.563722\n",
      "[295]\ttraining's binary_logloss: 0.563606\n",
      "[296]\ttraining's binary_logloss: 0.563529\n",
      "[297]\ttraining's binary_logloss: 0.563466\n",
      "[298]\ttraining's binary_logloss: 0.563377\n",
      "[299]\ttraining's binary_logloss: 0.563289\n",
      "[300]\ttraining's binary_logloss: 0.56321\n",
      "[301]\ttraining's binary_logloss: 0.563106\n",
      "[302]\ttraining's binary_logloss: 0.563\n",
      "[303]\ttraining's binary_logloss: 0.562889\n",
      "[304]\ttraining's binary_logloss: 0.562784\n",
      "[305]\ttraining's binary_logloss: 0.562692\n",
      "[306]\ttraining's binary_logloss: 0.562604\n",
      "[307]\ttraining's binary_logloss: 0.562494\n",
      "[308]\ttraining's binary_logloss: 0.562384\n",
      "[309]\ttraining's binary_logloss: 0.562272\n",
      "[310]\ttraining's binary_logloss: 0.562167\n",
      "[311]\ttraining's binary_logloss: 0.562054\n",
      "[312]\ttraining's binary_logloss: 0.561943\n",
      "[313]\ttraining's binary_logloss: 0.561844\n",
      "[314]\ttraining's binary_logloss: 0.561741\n",
      "[315]\ttraining's binary_logloss: 0.561633\n",
      "[316]\ttraining's binary_logloss: 0.561537\n",
      "[317]\ttraining's binary_logloss: 0.561435\n",
      "[318]\ttraining's binary_logloss: 0.561342\n",
      "[319]\ttraining's binary_logloss: 0.561255\n",
      "[320]\ttraining's binary_logloss: 0.561167\n",
      "[321]\ttraining's binary_logloss: 0.561065\n",
      "[322]\ttraining's binary_logloss: 0.560971\n",
      "[323]\ttraining's binary_logloss: 0.560879\n",
      "[324]\ttraining's binary_logloss: 0.560786\n",
      "[325]\ttraining's binary_logloss: 0.560695\n",
      "[326]\ttraining's binary_logloss: 0.560557\n",
      "[327]\ttraining's binary_logloss: 0.560432\n",
      "[328]\ttraining's binary_logloss: 0.560323\n",
      "[329]\ttraining's binary_logloss: 0.560194\n",
      "[330]\ttraining's binary_logloss: 0.560067\n",
      "[331]\ttraining's binary_logloss: 0.55996\n",
      "[332]\ttraining's binary_logloss: 0.559863\n",
      "[333]\ttraining's binary_logloss: 0.559755\n",
      "[334]\ttraining's binary_logloss: 0.559668\n",
      "[335]\ttraining's binary_logloss: 0.559571\n",
      "[336]\ttraining's binary_logloss: 0.559507\n",
      "[337]\ttraining's binary_logloss: 0.559441\n",
      "[338]\ttraining's binary_logloss: 0.559376\n",
      "[339]\ttraining's binary_logloss: 0.559311\n",
      "[340]\ttraining's binary_logloss: 0.559236\n",
      "[341]\ttraining's binary_logloss: 0.55914\n",
      "[342]\ttraining's binary_logloss: 0.559079\n",
      "[343]\ttraining's binary_logloss: 0.559017\n",
      "[344]\ttraining's binary_logloss: 0.558944\n",
      "[345]\ttraining's binary_logloss: 0.558869\n",
      "[346]\ttraining's binary_logloss: 0.558753\n",
      "[347]\ttraining's binary_logloss: 0.558632\n",
      "[348]\ttraining's binary_logloss: 0.558517\n",
      "[349]\ttraining's binary_logloss: 0.558418\n",
      "[350]\ttraining's binary_logloss: 0.558299\n",
      "[351]\ttraining's binary_logloss: 0.558228\n",
      "[352]\ttraining's binary_logloss: 0.558144\n",
      "[353]\ttraining's binary_logloss: 0.558082\n",
      "[354]\ttraining's binary_logloss: 0.558004\n",
      "[355]\ttraining's binary_logloss: 0.55794\n",
      "[356]\ttraining's binary_logloss: 0.557829\n",
      "[357]\ttraining's binary_logloss: 0.557717\n",
      "[358]\ttraining's binary_logloss: 0.557605\n",
      "[359]\ttraining's binary_logloss: 0.557488\n",
      "[360]\ttraining's binary_logloss: 0.557387\n",
      "[361]\ttraining's binary_logloss: 0.557267\n",
      "[362]\ttraining's binary_logloss: 0.557156\n",
      "[363]\ttraining's binary_logloss: 0.557038\n",
      "[364]\ttraining's binary_logloss: 0.556941\n",
      "[365]\ttraining's binary_logloss: 0.556832\n",
      "[366]\ttraining's binary_logloss: 0.556751\n",
      "[367]\ttraining's binary_logloss: 0.556656\n",
      "[368]\ttraining's binary_logloss: 0.556569\n",
      "[369]\ttraining's binary_logloss: 0.556479\n",
      "[370]\ttraining's binary_logloss: 0.556382\n",
      "[371]\ttraining's binary_logloss: 0.556282\n",
      "[372]\ttraining's binary_logloss: 0.556176\n",
      "[373]\ttraining's binary_logloss: 0.556051\n",
      "[374]\ttraining's binary_logloss: 0.55593\n",
      "[375]\ttraining's binary_logloss: 0.555828\n",
      "[376]\ttraining's binary_logloss: 0.555735\n",
      "[377]\ttraining's binary_logloss: 0.555627\n",
      "[378]\ttraining's binary_logloss: 0.55553\n",
      "[379]\ttraining's binary_logloss: 0.555424\n",
      "[380]\ttraining's binary_logloss: 0.555321\n",
      "[381]\ttraining's binary_logloss: 0.555186\n",
      "[382]\ttraining's binary_logloss: 0.555054\n",
      "[383]\ttraining's binary_logloss: 0.55491\n",
      "[384]\ttraining's binary_logloss: 0.554794\n",
      "[385]\ttraining's binary_logloss: 0.554678\n",
      "[386]\ttraining's binary_logloss: 0.554549\n",
      "[387]\ttraining's binary_logloss: 0.554428\n",
      "[388]\ttraining's binary_logloss: 0.554284\n",
      "[389]\ttraining's binary_logloss: 0.554163\n",
      "[390]\ttraining's binary_logloss: 0.554023\n",
      "[391]\ttraining's binary_logloss: 0.553888\n",
      "[392]\ttraining's binary_logloss: 0.553767\n",
      "[393]\ttraining's binary_logloss: 0.55363\n",
      "[394]\ttraining's binary_logloss: 0.553506\n",
      "[395]\ttraining's binary_logloss: 0.553384\n",
      "[396]\ttraining's binary_logloss: 0.553311\n",
      "[397]\ttraining's binary_logloss: 0.553205\n",
      "[398]\ttraining's binary_logloss: 0.553136\n",
      "[399]\ttraining's binary_logloss: 0.553063\n",
      "[400]\ttraining's binary_logloss: 0.552986\n",
      "[401]\ttraining's binary_logloss: 0.552871\n",
      "[402]\ttraining's binary_logloss: 0.552767\n",
      "[403]\ttraining's binary_logloss: 0.55265\n",
      "[404]\ttraining's binary_logloss: 0.552529\n",
      "[405]\ttraining's binary_logloss: 0.552426\n",
      "[406]\ttraining's binary_logloss: 0.552332\n",
      "[407]\ttraining's binary_logloss: 0.552226\n",
      "[408]\ttraining's binary_logloss: 0.552128\n",
      "[409]\ttraining's binary_logloss: 0.552023\n",
      "[410]\ttraining's binary_logloss: 0.55191\n",
      "[411]\ttraining's binary_logloss: 0.5518\n",
      "[412]\ttraining's binary_logloss: 0.551677\n",
      "[413]\ttraining's binary_logloss: 0.551572\n",
      "[414]\ttraining's binary_logloss: 0.551466\n",
      "[415]\ttraining's binary_logloss: 0.551348\n",
      "[416]\ttraining's binary_logloss: 0.551238\n",
      "[417]\ttraining's binary_logloss: 0.55113\n",
      "[418]\ttraining's binary_logloss: 0.551033\n",
      "[419]\ttraining's binary_logloss: 0.550946\n",
      "[420]\ttraining's binary_logloss: 0.550852\n",
      "[421]\ttraining's binary_logloss: 0.550747\n",
      "[422]\ttraining's binary_logloss: 0.55064\n",
      "[423]\ttraining's binary_logloss: 0.550547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[424]\ttraining's binary_logloss: 0.550457\n",
      "[425]\ttraining's binary_logloss: 0.550368\n",
      "[426]\ttraining's binary_logloss: 0.550263\n",
      "[427]\ttraining's binary_logloss: 0.550169\n",
      "[428]\ttraining's binary_logloss: 0.550076\n",
      "[429]\ttraining's binary_logloss: 0.549988\n",
      "[430]\ttraining's binary_logloss: 0.549873\n",
      "[431]\ttraining's binary_logloss: 0.549751\n",
      "[432]\ttraining's binary_logloss: 0.549647\n",
      "[433]\ttraining's binary_logloss: 0.549518\n",
      "[434]\ttraining's binary_logloss: 0.549407\n",
      "[435]\ttraining's binary_logloss: 0.549305\n",
      "[436]\ttraining's binary_logloss: 0.549215\n",
      "[437]\ttraining's binary_logloss: 0.549126\n",
      "[438]\ttraining's binary_logloss: 0.549034\n",
      "[439]\ttraining's binary_logloss: 0.54896\n",
      "[440]\ttraining's binary_logloss: 0.548873\n",
      "[441]\ttraining's binary_logloss: 0.548754\n",
      "[442]\ttraining's binary_logloss: 0.548652\n",
      "[443]\ttraining's binary_logloss: 0.548549\n",
      "[444]\ttraining's binary_logloss: 0.548439\n",
      "[445]\ttraining's binary_logloss: 0.548336\n",
      "[446]\ttraining's binary_logloss: 0.548186\n",
      "[447]\ttraining's binary_logloss: 0.548042\n",
      "[448]\ttraining's binary_logloss: 0.547906\n",
      "[449]\ttraining's binary_logloss: 0.547772\n",
      "[450]\ttraining's binary_logloss: 0.547631\n",
      "[451]\ttraining's binary_logloss: 0.547521\n",
      "[452]\ttraining's binary_logloss: 0.547374\n",
      "[453]\ttraining's binary_logloss: 0.547237\n",
      "[454]\ttraining's binary_logloss: 0.547098\n",
      "[455]\ttraining's binary_logloss: 0.546959\n",
      "[456]\ttraining's binary_logloss: 0.546834\n",
      "[457]\ttraining's binary_logloss: 0.546714\n",
      "[458]\ttraining's binary_logloss: 0.546593\n",
      "[459]\ttraining's binary_logloss: 0.546475\n",
      "[460]\ttraining's binary_logloss: 0.546383\n",
      "[461]\ttraining's binary_logloss: 0.546265\n",
      "[462]\ttraining's binary_logloss: 0.546138\n",
      "[463]\ttraining's binary_logloss: 0.546014\n",
      "[464]\ttraining's binary_logloss: 0.545902\n",
      "[465]\ttraining's binary_logloss: 0.545781\n",
      "[466]\ttraining's binary_logloss: 0.545672\n",
      "[467]\ttraining's binary_logloss: 0.545574\n",
      "[468]\ttraining's binary_logloss: 0.545484\n",
      "[469]\ttraining's binary_logloss: 0.545373\n",
      "[470]\ttraining's binary_logloss: 0.54527\n",
      "[471]\ttraining's binary_logloss: 0.545135\n",
      "[472]\ttraining's binary_logloss: 0.545\n",
      "[473]\ttraining's binary_logloss: 0.54488\n",
      "[474]\ttraining's binary_logloss: 0.544757\n",
      "[475]\ttraining's binary_logloss: 0.544627\n",
      "[476]\ttraining's binary_logloss: 0.544532\n",
      "[477]\ttraining's binary_logloss: 0.544441\n",
      "[478]\ttraining's binary_logloss: 0.544327\n",
      "[479]\ttraining's binary_logloss: 0.54422\n",
      "[480]\ttraining's binary_logloss: 0.544131\n",
      "[481]\ttraining's binary_logloss: 0.54403\n",
      "[482]\ttraining's binary_logloss: 0.543945\n",
      "[483]\ttraining's binary_logloss: 0.543862\n",
      "[484]\ttraining's binary_logloss: 0.54378\n",
      "[485]\ttraining's binary_logloss: 0.543705\n",
      "[486]\ttraining's binary_logloss: 0.543565\n",
      "[487]\ttraining's binary_logloss: 0.543418\n",
      "[488]\ttraining's binary_logloss: 0.543283\n",
      "[489]\ttraining's binary_logloss: 0.543144\n",
      "[490]\ttraining's binary_logloss: 0.542995\n",
      "[491]\ttraining's binary_logloss: 0.542874\n",
      "[492]\ttraining's binary_logloss: 0.542753\n",
      "[493]\ttraining's binary_logloss: 0.542635\n",
      "[494]\ttraining's binary_logloss: 0.542509\n",
      "[495]\ttraining's binary_logloss: 0.542392\n",
      "[496]\ttraining's binary_logloss: 0.542277\n",
      "[497]\ttraining's binary_logloss: 0.542166\n",
      "[498]\ttraining's binary_logloss: 0.542059\n",
      "[499]\ttraining's binary_logloss: 0.541922\n",
      "[500]\ttraining's binary_logloss: 0.541807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614282\n",
      "[2]\ttraining's binary_logloss: 0.612887\n",
      "[3]\ttraining's binary_logloss: 0.611577\n",
      "[4]\ttraining's binary_logloss: 0.610386\n",
      "[5]\ttraining's binary_logloss: 0.609057\n",
      "[6]\ttraining's binary_logloss: 0.607843\n",
      "[7]\ttraining's binary_logloss: 0.606674\n",
      "[8]\ttraining's binary_logloss: 0.605408\n",
      "[9]\ttraining's binary_logloss: 0.604301\n",
      "[10]\ttraining's binary_logloss: 0.603142\n",
      "[11]\ttraining's binary_logloss: 0.602004\n",
      "[12]\ttraining's binary_logloss: 0.601024\n",
      "[13]\ttraining's binary_logloss: 0.600048\n",
      "[14]\ttraining's binary_logloss: 0.599011\n",
      "[15]\ttraining's binary_logloss: 0.59803\n",
      "[16]\ttraining's binary_logloss: 0.597093\n",
      "[17]\ttraining's binary_logloss: 0.596164\n",
      "[18]\ttraining's binary_logloss: 0.595304\n",
      "[19]\ttraining's binary_logloss: 0.594433\n",
      "[20]\ttraining's binary_logloss: 0.593614\n",
      "[21]\ttraining's binary_logloss: 0.592855\n",
      "[22]\ttraining's binary_logloss: 0.592142\n",
      "[23]\ttraining's binary_logloss: 0.59133\n",
      "[24]\ttraining's binary_logloss: 0.590656\n",
      "[25]\ttraining's binary_logloss: 0.589996\n",
      "[26]\ttraining's binary_logloss: 0.589372\n",
      "[27]\ttraining's binary_logloss: 0.588648\n",
      "[28]\ttraining's binary_logloss: 0.587987\n",
      "[29]\ttraining's binary_logloss: 0.5873\n",
      "[30]\ttraining's binary_logloss: 0.586628\n",
      "[31]\ttraining's binary_logloss: 0.585967\n",
      "[32]\ttraining's binary_logloss: 0.585307\n",
      "[33]\ttraining's binary_logloss: 0.584704\n",
      "[34]\ttraining's binary_logloss: 0.584098\n",
      "[35]\ttraining's binary_logloss: 0.583449\n",
      "[36]\ttraining's binary_logloss: 0.582885\n",
      "[37]\ttraining's binary_logloss: 0.582354\n",
      "[38]\ttraining's binary_logloss: 0.581835\n",
      "[39]\ttraining's binary_logloss: 0.581312\n",
      "[40]\ttraining's binary_logloss: 0.580814\n",
      "[41]\ttraining's binary_logloss: 0.580324\n",
      "[42]\ttraining's binary_logloss: 0.579949\n",
      "[43]\ttraining's binary_logloss: 0.579532\n",
      "[44]\ttraining's binary_logloss: 0.579075\n",
      "[45]\ttraining's binary_logloss: 0.578659\n",
      "[46]\ttraining's binary_logloss: 0.578176\n",
      "[47]\ttraining's binary_logloss: 0.577716\n",
      "[48]\ttraining's binary_logloss: 0.577241\n",
      "[49]\ttraining's binary_logloss: 0.576807\n",
      "[50]\ttraining's binary_logloss: 0.576414\n",
      "[51]\ttraining's binary_logloss: 0.576055\n",
      "[52]\ttraining's binary_logloss: 0.575705\n",
      "[53]\ttraining's binary_logloss: 0.575355\n",
      "[54]\ttraining's binary_logloss: 0.574994\n",
      "[55]\ttraining's binary_logloss: 0.574653\n",
      "[56]\ttraining's binary_logloss: 0.574322\n",
      "[57]\ttraining's binary_logloss: 0.573949\n",
      "[58]\ttraining's binary_logloss: 0.573599\n",
      "[59]\ttraining's binary_logloss: 0.573242\n",
      "[60]\ttraining's binary_logloss: 0.57289\n",
      "[61]\ttraining's binary_logloss: 0.572593\n",
      "[62]\ttraining's binary_logloss: 0.572344\n",
      "[63]\ttraining's binary_logloss: 0.572079\n",
      "[64]\ttraining's binary_logloss: 0.571808\n",
      "[65]\ttraining's binary_logloss: 0.571563\n",
      "[66]\ttraining's binary_logloss: 0.57132\n",
      "[67]\ttraining's binary_logloss: 0.571076\n",
      "[68]\ttraining's binary_logloss: 0.570826\n",
      "[69]\ttraining's binary_logloss: 0.570589\n",
      "[70]\ttraining's binary_logloss: 0.57031\n",
      "[71]\ttraining's binary_logloss: 0.570061\n",
      "[72]\ttraining's binary_logloss: 0.569811\n",
      "[73]\ttraining's binary_logloss: 0.569625\n",
      "[74]\ttraining's binary_logloss: 0.569354\n",
      "[75]\ttraining's binary_logloss: 0.569125\n",
      "[76]\ttraining's binary_logloss: 0.568925\n",
      "[77]\ttraining's binary_logloss: 0.568723\n",
      "[78]\ttraining's binary_logloss: 0.568553\n",
      "[79]\ttraining's binary_logloss: 0.568381\n",
      "[80]\ttraining's binary_logloss: 0.568204\n",
      "[81]\ttraining's binary_logloss: 0.568027\n",
      "[82]\ttraining's binary_logloss: 0.567822\n",
      "[83]\ttraining's binary_logloss: 0.567646\n",
      "[84]\ttraining's binary_logloss: 0.567469\n",
      "[85]\ttraining's binary_logloss: 0.567312\n",
      "[86]\ttraining's binary_logloss: 0.567126\n",
      "[87]\ttraining's binary_logloss: 0.566941\n",
      "[88]\ttraining's binary_logloss: 0.566748\n",
      "[89]\ttraining's binary_logloss: 0.566537\n",
      "[90]\ttraining's binary_logloss: 0.566335\n",
      "[91]\ttraining's binary_logloss: 0.566152\n",
      "[92]\ttraining's binary_logloss: 0.566054\n",
      "[93]\ttraining's binary_logloss: 0.565903\n",
      "[94]\ttraining's binary_logloss: 0.565772\n",
      "[95]\ttraining's binary_logloss: 0.565653\n",
      "[96]\ttraining's binary_logloss: 0.565497\n",
      "[97]\ttraining's binary_logloss: 0.565324\n",
      "[98]\ttraining's binary_logloss: 0.56515\n",
      "[99]\ttraining's binary_logloss: 0.565003\n",
      "[100]\ttraining's binary_logloss: 0.564855\n",
      "[101]\ttraining's binary_logloss: 0.564689\n",
      "[102]\ttraining's binary_logloss: 0.564531\n",
      "[103]\ttraining's binary_logloss: 0.564375\n",
      "[104]\ttraining's binary_logloss: 0.564225\n",
      "[105]\ttraining's binary_logloss: 0.564057\n",
      "[106]\ttraining's binary_logloss: 0.563973\n",
      "[107]\ttraining's binary_logloss: 0.563841\n",
      "[108]\ttraining's binary_logloss: 0.56371\n",
      "[109]\ttraining's binary_logloss: 0.563588\n",
      "[110]\ttraining's binary_logloss: 0.563481\n",
      "[111]\ttraining's binary_logloss: 0.563312\n",
      "[112]\ttraining's binary_logloss: 0.563194\n",
      "[113]\ttraining's binary_logloss: 0.563023\n",
      "[114]\ttraining's binary_logloss: 0.562844\n",
      "[115]\ttraining's binary_logloss: 0.562713\n",
      "[116]\ttraining's binary_logloss: 0.562557\n",
      "[117]\ttraining's binary_logloss: 0.562406\n",
      "[118]\ttraining's binary_logloss: 0.56226\n",
      "[119]\ttraining's binary_logloss: 0.562123\n",
      "[120]\ttraining's binary_logloss: 0.561983\n",
      "[121]\ttraining's binary_logloss: 0.561859\n",
      "[122]\ttraining's binary_logloss: 0.561746\n",
      "[123]\ttraining's binary_logloss: 0.561622\n",
      "[124]\ttraining's binary_logloss: 0.561508\n",
      "[125]\ttraining's binary_logloss: 0.561405\n",
      "[126]\ttraining's binary_logloss: 0.56125\n",
      "[127]\ttraining's binary_logloss: 0.561105\n",
      "[128]\ttraining's binary_logloss: 0.56098\n",
      "[129]\ttraining's binary_logloss: 0.560845\n",
      "[130]\ttraining's binary_logloss: 0.560714\n",
      "[131]\ttraining's binary_logloss: 0.560639\n",
      "[132]\ttraining's binary_logloss: 0.560526\n",
      "[133]\ttraining's binary_logloss: 0.56042\n",
      "[134]\ttraining's binary_logloss: 0.560305\n",
      "[135]\ttraining's binary_logloss: 0.560203\n",
      "[136]\ttraining's binary_logloss: 0.560104\n",
      "[137]\ttraining's binary_logloss: 0.560022\n",
      "[138]\ttraining's binary_logloss: 0.559918\n",
      "[139]\ttraining's binary_logloss: 0.559827\n",
      "[140]\ttraining's binary_logloss: 0.559748\n",
      "[141]\ttraining's binary_logloss: 0.559617\n",
      "[142]\ttraining's binary_logloss: 0.559504\n",
      "[143]\ttraining's binary_logloss: 0.559415\n",
      "[144]\ttraining's binary_logloss: 0.559299\n",
      "[145]\ttraining's binary_logloss: 0.559195\n",
      "[146]\ttraining's binary_logloss: 0.559078\n",
      "[147]\ttraining's binary_logloss: 0.558947\n",
      "[148]\ttraining's binary_logloss: 0.558848\n",
      "[149]\ttraining's binary_logloss: 0.558723\n",
      "[150]\ttraining's binary_logloss: 0.558634\n",
      "[151]\ttraining's binary_logloss: 0.558522\n",
      "[152]\ttraining's binary_logloss: 0.558433\n",
      "[153]\ttraining's binary_logloss: 0.558337\n",
      "[154]\ttraining's binary_logloss: 0.558247\n",
      "[155]\ttraining's binary_logloss: 0.558135\n",
      "[156]\ttraining's binary_logloss: 0.558047\n",
      "[157]\ttraining's binary_logloss: 0.557944\n",
      "[158]\ttraining's binary_logloss: 0.557808\n",
      "[159]\ttraining's binary_logloss: 0.557685\n",
      "[160]\ttraining's binary_logloss: 0.557574\n",
      "[161]\ttraining's binary_logloss: 0.557467\n",
      "[162]\ttraining's binary_logloss: 0.557344\n",
      "[163]\ttraining's binary_logloss: 0.557216\n",
      "[164]\ttraining's binary_logloss: 0.557075\n",
      "[165]\ttraining's binary_logloss: 0.556966\n",
      "[166]\ttraining's binary_logloss: 0.556832\n",
      "[167]\ttraining's binary_logloss: 0.556698\n",
      "[168]\ttraining's binary_logloss: 0.556565\n",
      "[169]\ttraining's binary_logloss: 0.556439\n",
      "[170]\ttraining's binary_logloss: 0.556361\n",
      "[171]\ttraining's binary_logloss: 0.556268\n",
      "[172]\ttraining's binary_logloss: 0.556181\n",
      "[173]\ttraining's binary_logloss: 0.556082\n",
      "[174]\ttraining's binary_logloss: 0.555995\n",
      "[175]\ttraining's binary_logloss: 0.555899\n",
      "[176]\ttraining's binary_logloss: 0.55579\n",
      "[177]\ttraining's binary_logloss: 0.555677\n",
      "[178]\ttraining's binary_logloss: 0.555562\n",
      "[179]\ttraining's binary_logloss: 0.555475\n",
      "[180]\ttraining's binary_logloss: 0.555385\n",
      "[181]\ttraining's binary_logloss: 0.555248\n",
      "[182]\ttraining's binary_logloss: 0.555131\n",
      "[183]\ttraining's binary_logloss: 0.555016\n",
      "[184]\ttraining's binary_logloss: 0.554866\n",
      "[185]\ttraining's binary_logloss: 0.554754\n",
      "[186]\ttraining's binary_logloss: 0.554665\n",
      "[187]\ttraining's binary_logloss: 0.554573\n",
      "[188]\ttraining's binary_logloss: 0.55447\n",
      "[189]\ttraining's binary_logloss: 0.554389\n",
      "[190]\ttraining's binary_logloss: 0.554306\n",
      "[191]\ttraining's binary_logloss: 0.554202\n",
      "[192]\ttraining's binary_logloss: 0.554086\n",
      "[193]\ttraining's binary_logloss: 0.553953\n",
      "[194]\ttraining's binary_logloss: 0.553831\n",
      "[195]\ttraining's binary_logloss: 0.553722\n",
      "[196]\ttraining's binary_logloss: 0.553623\n",
      "[197]\ttraining's binary_logloss: 0.553513\n",
      "[198]\ttraining's binary_logloss: 0.553407\n",
      "[199]\ttraining's binary_logloss: 0.553297\n",
      "[200]\ttraining's binary_logloss: 0.55321\n",
      "[201]\ttraining's binary_logloss: 0.553127\n",
      "[202]\ttraining's binary_logloss: 0.55303\n",
      "[203]\ttraining's binary_logloss: 0.552959\n",
      "[204]\ttraining's binary_logloss: 0.552849\n",
      "[205]\ttraining's binary_logloss: 0.552744\n",
      "[206]\ttraining's binary_logloss: 0.552592\n",
      "[207]\ttraining's binary_logloss: 0.552433\n",
      "[208]\ttraining's binary_logloss: 0.552259\n",
      "[209]\ttraining's binary_logloss: 0.552116\n",
      "[210]\ttraining's binary_logloss: 0.551994\n",
      "[211]\ttraining's binary_logloss: 0.551889\n",
      "[212]\ttraining's binary_logloss: 0.55179\n",
      "[213]\ttraining's binary_logloss: 0.551692\n",
      "[214]\ttraining's binary_logloss: 0.551599\n",
      "[215]\ttraining's binary_logloss: 0.551515\n",
      "[216]\ttraining's binary_logloss: 0.551396\n",
      "[217]\ttraining's binary_logloss: 0.551257\n",
      "[218]\ttraining's binary_logloss: 0.551123\n",
      "[219]\ttraining's binary_logloss: 0.550991\n",
      "[220]\ttraining's binary_logloss: 0.550861\n",
      "[221]\ttraining's binary_logloss: 0.550742\n",
      "[222]\ttraining's binary_logloss: 0.550597\n",
      "[223]\ttraining's binary_logloss: 0.550442\n",
      "[224]\ttraining's binary_logloss: 0.550324\n",
      "[225]\ttraining's binary_logloss: 0.550179\n",
      "[226]\ttraining's binary_logloss: 0.550038\n",
      "[227]\ttraining's binary_logloss: 0.549878\n",
      "[228]\ttraining's binary_logloss: 0.549748\n",
      "[229]\ttraining's binary_logloss: 0.549586\n",
      "[230]\ttraining's binary_logloss: 0.549428\n",
      "[231]\ttraining's binary_logloss: 0.549319\n",
      "[232]\ttraining's binary_logloss: 0.54921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[233]\ttraining's binary_logloss: 0.549096\n",
      "[234]\ttraining's binary_logloss: 0.548988\n",
      "[235]\ttraining's binary_logloss: 0.548897\n",
      "[236]\ttraining's binary_logloss: 0.548748\n",
      "[237]\ttraining's binary_logloss: 0.548578\n",
      "[238]\ttraining's binary_logloss: 0.548397\n",
      "[239]\ttraining's binary_logloss: 0.548218\n",
      "[240]\ttraining's binary_logloss: 0.548053\n",
      "[241]\ttraining's binary_logloss: 0.547938\n",
      "[242]\ttraining's binary_logloss: 0.547817\n",
      "[243]\ttraining's binary_logloss: 0.547673\n",
      "[244]\ttraining's binary_logloss: 0.547549\n",
      "[245]\ttraining's binary_logloss: 0.547402\n",
      "[246]\ttraining's binary_logloss: 0.547247\n",
      "[247]\ttraining's binary_logloss: 0.547106\n",
      "[248]\ttraining's binary_logloss: 0.546905\n",
      "[249]\ttraining's binary_logloss: 0.546715\n",
      "[250]\ttraining's binary_logloss: 0.54654\n",
      "[251]\ttraining's binary_logloss: 0.546365\n",
      "[252]\ttraining's binary_logloss: 0.546228\n",
      "[253]\ttraining's binary_logloss: 0.54607\n",
      "[254]\ttraining's binary_logloss: 0.545942\n",
      "[255]\ttraining's binary_logloss: 0.545817\n",
      "[256]\ttraining's binary_logloss: 0.545699\n",
      "[257]\ttraining's binary_logloss: 0.545561\n",
      "[258]\ttraining's binary_logloss: 0.545438\n",
      "[259]\ttraining's binary_logloss: 0.545283\n",
      "[260]\ttraining's binary_logloss: 0.545164\n",
      "[261]\ttraining's binary_logloss: 0.54506\n",
      "[262]\ttraining's binary_logloss: 0.544951\n",
      "[263]\ttraining's binary_logloss: 0.544852\n",
      "[264]\ttraining's binary_logloss: 0.544725\n",
      "[265]\ttraining's binary_logloss: 0.544605\n",
      "[266]\ttraining's binary_logloss: 0.544516\n",
      "[267]\ttraining's binary_logloss: 0.544397\n",
      "[268]\ttraining's binary_logloss: 0.544301\n",
      "[269]\ttraining's binary_logloss: 0.544205\n",
      "[270]\ttraining's binary_logloss: 0.54409\n",
      "[271]\ttraining's binary_logloss: 0.543933\n",
      "[272]\ttraining's binary_logloss: 0.543787\n",
      "[273]\ttraining's binary_logloss: 0.543644\n",
      "[274]\ttraining's binary_logloss: 0.543506\n",
      "[275]\ttraining's binary_logloss: 0.543347\n",
      "[276]\ttraining's binary_logloss: 0.543204\n",
      "[277]\ttraining's binary_logloss: 0.54309\n",
      "[278]\ttraining's binary_logloss: 0.54296\n",
      "[279]\ttraining's binary_logloss: 0.542818\n",
      "[280]\ttraining's binary_logloss: 0.542687\n",
      "[281]\ttraining's binary_logloss: 0.542582\n",
      "[282]\ttraining's binary_logloss: 0.542451\n",
      "[283]\ttraining's binary_logloss: 0.542347\n",
      "[284]\ttraining's binary_logloss: 0.542257\n",
      "[285]\ttraining's binary_logloss: 0.542142\n",
      "[286]\ttraining's binary_logloss: 0.541979\n",
      "[287]\ttraining's binary_logloss: 0.541818\n",
      "[288]\ttraining's binary_logloss: 0.541664\n",
      "[289]\ttraining's binary_logloss: 0.541534\n",
      "[290]\ttraining's binary_logloss: 0.541413\n",
      "[291]\ttraining's binary_logloss: 0.541235\n",
      "[292]\ttraining's binary_logloss: 0.541044\n",
      "[293]\ttraining's binary_logloss: 0.540874\n",
      "[294]\ttraining's binary_logloss: 0.540713\n",
      "[295]\ttraining's binary_logloss: 0.540527\n",
      "[296]\ttraining's binary_logloss: 0.540393\n",
      "[297]\ttraining's binary_logloss: 0.540265\n",
      "[298]\ttraining's binary_logloss: 0.540128\n",
      "[299]\ttraining's binary_logloss: 0.54\n",
      "[300]\ttraining's binary_logloss: 0.539859\n",
      "[301]\ttraining's binary_logloss: 0.539706\n",
      "[302]\ttraining's binary_logloss: 0.539565\n",
      "[303]\ttraining's binary_logloss: 0.539404\n",
      "[304]\ttraining's binary_logloss: 0.539256\n",
      "[305]\ttraining's binary_logloss: 0.539105\n",
      "[306]\ttraining's binary_logloss: 0.538975\n",
      "[307]\ttraining's binary_logloss: 0.538845\n",
      "[308]\ttraining's binary_logloss: 0.538713\n",
      "[309]\ttraining's binary_logloss: 0.538549\n",
      "[310]\ttraining's binary_logloss: 0.538396\n",
      "[311]\ttraining's binary_logloss: 0.538223\n",
      "[312]\ttraining's binary_logloss: 0.538067\n",
      "[313]\ttraining's binary_logloss: 0.537903\n",
      "[314]\ttraining's binary_logloss: 0.537761\n",
      "[315]\ttraining's binary_logloss: 0.537604\n",
      "[316]\ttraining's binary_logloss: 0.537444\n",
      "[317]\ttraining's binary_logloss: 0.53727\n",
      "[318]\ttraining's binary_logloss: 0.537137\n",
      "[319]\ttraining's binary_logloss: 0.536981\n",
      "[320]\ttraining's binary_logloss: 0.536821\n",
      "[321]\ttraining's binary_logloss: 0.536706\n",
      "[322]\ttraining's binary_logloss: 0.536578\n",
      "[323]\ttraining's binary_logloss: 0.536436\n",
      "[324]\ttraining's binary_logloss: 0.536277\n",
      "[325]\ttraining's binary_logloss: 0.53617\n",
      "[326]\ttraining's binary_logloss: 0.535985\n",
      "[327]\ttraining's binary_logloss: 0.535804\n",
      "[328]\ttraining's binary_logloss: 0.535653\n",
      "[329]\ttraining's binary_logloss: 0.53551\n",
      "[330]\ttraining's binary_logloss: 0.535357\n",
      "[331]\ttraining's binary_logloss: 0.535218\n",
      "[332]\ttraining's binary_logloss: 0.535065\n",
      "[333]\ttraining's binary_logloss: 0.534913\n",
      "[334]\ttraining's binary_logloss: 0.534764\n",
      "[335]\ttraining's binary_logloss: 0.534601\n",
      "[336]\ttraining's binary_logloss: 0.534461\n",
      "[337]\ttraining's binary_logloss: 0.534329\n",
      "[338]\ttraining's binary_logloss: 0.534209\n",
      "[339]\ttraining's binary_logloss: 0.534089\n",
      "[340]\ttraining's binary_logloss: 0.533965\n",
      "[341]\ttraining's binary_logloss: 0.533841\n",
      "[342]\ttraining's binary_logloss: 0.533727\n",
      "[343]\ttraining's binary_logloss: 0.533615\n",
      "[344]\ttraining's binary_logloss: 0.533499\n",
      "[345]\ttraining's binary_logloss: 0.533402\n",
      "[346]\ttraining's binary_logloss: 0.533248\n",
      "[347]\ttraining's binary_logloss: 0.533071\n",
      "[348]\ttraining's binary_logloss: 0.532898\n",
      "[349]\ttraining's binary_logloss: 0.532749\n",
      "[350]\ttraining's binary_logloss: 0.532578\n",
      "[351]\ttraining's binary_logloss: 0.532456\n",
      "[352]\ttraining's binary_logloss: 0.532354\n",
      "[353]\ttraining's binary_logloss: 0.532253\n",
      "[354]\ttraining's binary_logloss: 0.532137\n",
      "[355]\ttraining's binary_logloss: 0.532034\n",
      "[356]\ttraining's binary_logloss: 0.531863\n",
      "[357]\ttraining's binary_logloss: 0.531701\n",
      "[358]\ttraining's binary_logloss: 0.531544\n",
      "[359]\ttraining's binary_logloss: 0.531392\n",
      "[360]\ttraining's binary_logloss: 0.531254\n",
      "[361]\ttraining's binary_logloss: 0.531092\n",
      "[362]\ttraining's binary_logloss: 0.530953\n",
      "[363]\ttraining's binary_logloss: 0.530758\n",
      "[364]\ttraining's binary_logloss: 0.530597\n",
      "[365]\ttraining's binary_logloss: 0.530443\n",
      "[366]\ttraining's binary_logloss: 0.530308\n",
      "[367]\ttraining's binary_logloss: 0.530168\n",
      "[368]\ttraining's binary_logloss: 0.530028\n",
      "[369]\ttraining's binary_logloss: 0.52989\n",
      "[370]\ttraining's binary_logloss: 0.529741\n",
      "[371]\ttraining's binary_logloss: 0.529583\n",
      "[372]\ttraining's binary_logloss: 0.529395\n",
      "[373]\ttraining's binary_logloss: 0.529199\n",
      "[374]\ttraining's binary_logloss: 0.529024\n",
      "[375]\ttraining's binary_logloss: 0.52887\n",
      "[376]\ttraining's binary_logloss: 0.528735\n",
      "[377]\ttraining's binary_logloss: 0.52856\n",
      "[378]\ttraining's binary_logloss: 0.52841\n",
      "[379]\ttraining's binary_logloss: 0.528278\n",
      "[380]\ttraining's binary_logloss: 0.528145\n",
      "[381]\ttraining's binary_logloss: 0.527985\n",
      "[382]\ttraining's binary_logloss: 0.527827\n",
      "[383]\ttraining's binary_logloss: 0.527648\n",
      "[384]\ttraining's binary_logloss: 0.527495\n",
      "[385]\ttraining's binary_logloss: 0.527337\n",
      "[386]\ttraining's binary_logloss: 0.527163\n",
      "[387]\ttraining's binary_logloss: 0.527007\n",
      "[388]\ttraining's binary_logloss: 0.526838\n",
      "[389]\ttraining's binary_logloss: 0.526671\n",
      "[390]\ttraining's binary_logloss: 0.526514\n",
      "[391]\ttraining's binary_logloss: 0.52633\n",
      "[392]\ttraining's binary_logloss: 0.526124\n",
      "[393]\ttraining's binary_logloss: 0.525949\n",
      "[394]\ttraining's binary_logloss: 0.52577\n",
      "[395]\ttraining's binary_logloss: 0.525597\n",
      "[396]\ttraining's binary_logloss: 0.525453\n",
      "[397]\ttraining's binary_logloss: 0.525317\n",
      "[398]\ttraining's binary_logloss: 0.525196\n",
      "[399]\ttraining's binary_logloss: 0.525055\n",
      "[400]\ttraining's binary_logloss: 0.524915\n",
      "[401]\ttraining's binary_logloss: 0.524773\n",
      "[402]\ttraining's binary_logloss: 0.524625\n",
      "[403]\ttraining's binary_logloss: 0.524468\n",
      "[404]\ttraining's binary_logloss: 0.524314\n",
      "[405]\ttraining's binary_logloss: 0.524181\n",
      "[406]\ttraining's binary_logloss: 0.524032\n",
      "[407]\ttraining's binary_logloss: 0.523884\n",
      "[408]\ttraining's binary_logloss: 0.523729\n",
      "[409]\ttraining's binary_logloss: 0.523568\n",
      "[410]\ttraining's binary_logloss: 0.52339\n",
      "[411]\ttraining's binary_logloss: 0.523245\n",
      "[412]\ttraining's binary_logloss: 0.52311\n",
      "[413]\ttraining's binary_logloss: 0.522913\n",
      "[414]\ttraining's binary_logloss: 0.522758\n",
      "[415]\ttraining's binary_logloss: 0.522588\n",
      "[416]\ttraining's binary_logloss: 0.522448\n",
      "[417]\ttraining's binary_logloss: 0.522299\n",
      "[418]\ttraining's binary_logloss: 0.522131\n",
      "[419]\ttraining's binary_logloss: 0.521997\n",
      "[420]\ttraining's binary_logloss: 0.521865\n",
      "[421]\ttraining's binary_logloss: 0.521703\n",
      "[422]\ttraining's binary_logloss: 0.52155\n",
      "[423]\ttraining's binary_logloss: 0.521406\n",
      "[424]\ttraining's binary_logloss: 0.521254\n",
      "[425]\ttraining's binary_logloss: 0.521123\n",
      "[426]\ttraining's binary_logloss: 0.520978\n",
      "[427]\ttraining's binary_logloss: 0.520839\n",
      "[428]\ttraining's binary_logloss: 0.520706\n",
      "[429]\ttraining's binary_logloss: 0.520574\n",
      "[430]\ttraining's binary_logloss: 0.52044\n",
      "[431]\ttraining's binary_logloss: 0.520286\n",
      "[432]\ttraining's binary_logloss: 0.520143\n",
      "[433]\ttraining's binary_logloss: 0.519982\n",
      "[434]\ttraining's binary_logloss: 0.519837\n",
      "[435]\ttraining's binary_logloss: 0.519685\n",
      "[436]\ttraining's binary_logloss: 0.519549\n",
      "[437]\ttraining's binary_logloss: 0.519393\n",
      "[438]\ttraining's binary_logloss: 0.519241\n",
      "[439]\ttraining's binary_logloss: 0.519092\n",
      "[440]\ttraining's binary_logloss: 0.518941\n",
      "[441]\ttraining's binary_logloss: 0.518787\n",
      "[442]\ttraining's binary_logloss: 0.518653\n",
      "[443]\ttraining's binary_logloss: 0.518504\n",
      "[444]\ttraining's binary_logloss: 0.518343\n",
      "[445]\ttraining's binary_logloss: 0.518196\n",
      "[446]\ttraining's binary_logloss: 0.518006\n",
      "[447]\ttraining's binary_logloss: 0.5178\n",
      "[448]\ttraining's binary_logloss: 0.517611\n",
      "[449]\ttraining's binary_logloss: 0.517431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[450]\ttraining's binary_logloss: 0.517243\n",
      "[451]\ttraining's binary_logloss: 0.517098\n",
      "[452]\ttraining's binary_logloss: 0.516908\n",
      "[453]\ttraining's binary_logloss: 0.516708\n",
      "[454]\ttraining's binary_logloss: 0.516514\n",
      "[455]\ttraining's binary_logloss: 0.516366\n",
      "[456]\ttraining's binary_logloss: 0.516207\n",
      "[457]\ttraining's binary_logloss: 0.516074\n",
      "[458]\ttraining's binary_logloss: 0.515913\n",
      "[459]\ttraining's binary_logloss: 0.51575\n",
      "[460]\ttraining's binary_logloss: 0.515587\n",
      "[461]\ttraining's binary_logloss: 0.515445\n",
      "[462]\ttraining's binary_logloss: 0.515276\n",
      "[463]\ttraining's binary_logloss: 0.515121\n",
      "[464]\ttraining's binary_logloss: 0.514972\n",
      "[465]\ttraining's binary_logloss: 0.514799\n",
      "[466]\ttraining's binary_logloss: 0.514658\n",
      "[467]\ttraining's binary_logloss: 0.514496\n",
      "[468]\ttraining's binary_logloss: 0.514334\n",
      "[469]\ttraining's binary_logloss: 0.514196\n",
      "[470]\ttraining's binary_logloss: 0.51406\n",
      "[471]\ttraining's binary_logloss: 0.513893\n",
      "[472]\ttraining's binary_logloss: 0.513748\n",
      "[473]\ttraining's binary_logloss: 0.513566\n",
      "[474]\ttraining's binary_logloss: 0.513424\n",
      "[475]\ttraining's binary_logloss: 0.513258\n",
      "[476]\ttraining's binary_logloss: 0.513117\n",
      "[477]\ttraining's binary_logloss: 0.512981\n",
      "[478]\ttraining's binary_logloss: 0.512847\n",
      "[479]\ttraining's binary_logloss: 0.512701\n",
      "[480]\ttraining's binary_logloss: 0.512542\n",
      "[481]\ttraining's binary_logloss: 0.512401\n",
      "[482]\ttraining's binary_logloss: 0.512247\n",
      "[483]\ttraining's binary_logloss: 0.512114\n",
      "[484]\ttraining's binary_logloss: 0.51199\n",
      "[485]\ttraining's binary_logloss: 0.511872\n",
      "[486]\ttraining's binary_logloss: 0.511715\n",
      "[487]\ttraining's binary_logloss: 0.51154\n",
      "[488]\ttraining's binary_logloss: 0.511363\n",
      "[489]\ttraining's binary_logloss: 0.511188\n",
      "[490]\ttraining's binary_logloss: 0.51099\n",
      "[491]\ttraining's binary_logloss: 0.510826\n",
      "[492]\ttraining's binary_logloss: 0.510671\n",
      "[493]\ttraining's binary_logloss: 0.510516\n",
      "[494]\ttraining's binary_logloss: 0.510361\n",
      "[495]\ttraining's binary_logloss: 0.510199\n",
      "[496]\ttraining's binary_logloss: 0.510031\n",
      "[497]\ttraining's binary_logloss: 0.509873\n",
      "[498]\ttraining's binary_logloss: 0.509734\n",
      "[499]\ttraining's binary_logloss: 0.509585\n",
      "[500]\ttraining's binary_logloss: 0.509423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614176\n",
      "[2]\ttraining's binary_logloss: 0.612677\n",
      "[3]\ttraining's binary_logloss: 0.611261\n",
      "[4]\ttraining's binary_logloss: 0.609946\n",
      "[5]\ttraining's binary_logloss: 0.608497\n",
      "[6]\ttraining's binary_logloss: 0.607152\n",
      "[7]\ttraining's binary_logloss: 0.605873\n",
      "[8]\ttraining's binary_logloss: 0.604491\n",
      "[9]\ttraining's binary_logloss: 0.603263\n",
      "[10]\ttraining's binary_logloss: 0.602003\n",
      "[11]\ttraining's binary_logloss: 0.600783\n",
      "[12]\ttraining's binary_logloss: 0.599697\n",
      "[13]\ttraining's binary_logloss: 0.598593\n",
      "[14]\ttraining's binary_logloss: 0.597437\n",
      "[15]\ttraining's binary_logloss: 0.59632\n",
      "[16]\ttraining's binary_logloss: 0.595287\n",
      "[17]\ttraining's binary_logloss: 0.594262\n",
      "[18]\ttraining's binary_logloss: 0.593297\n",
      "[19]\ttraining's binary_logloss: 0.592335\n",
      "[20]\ttraining's binary_logloss: 0.591444\n",
      "[21]\ttraining's binary_logloss: 0.590578\n",
      "[22]\ttraining's binary_logloss: 0.589762\n",
      "[23]\ttraining's binary_logloss: 0.58889\n",
      "[24]\ttraining's binary_logloss: 0.588119\n",
      "[25]\ttraining's binary_logloss: 0.58737\n",
      "[26]\ttraining's binary_logloss: 0.58662\n",
      "[27]\ttraining's binary_logloss: 0.585815\n",
      "[28]\ttraining's binary_logloss: 0.585044\n",
      "[29]\ttraining's binary_logloss: 0.584262\n",
      "[30]\ttraining's binary_logloss: 0.583513\n",
      "[31]\ttraining's binary_logloss: 0.582766\n",
      "[32]\ttraining's binary_logloss: 0.582011\n",
      "[33]\ttraining's binary_logloss: 0.581311\n",
      "[34]\ttraining's binary_logloss: 0.580572\n",
      "[35]\ttraining's binary_logloss: 0.579846\n",
      "[36]\ttraining's binary_logloss: 0.579195\n",
      "[37]\ttraining's binary_logloss: 0.578572\n",
      "[38]\ttraining's binary_logloss: 0.577968\n",
      "[39]\ttraining's binary_logloss: 0.577359\n",
      "[40]\ttraining's binary_logloss: 0.576769\n",
      "[41]\ttraining's binary_logloss: 0.576192\n",
      "[42]\ttraining's binary_logloss: 0.575732\n",
      "[43]\ttraining's binary_logloss: 0.57524\n",
      "[44]\ttraining's binary_logloss: 0.574698\n",
      "[45]\ttraining's binary_logloss: 0.574152\n",
      "[46]\ttraining's binary_logloss: 0.573573\n",
      "[47]\ttraining's binary_logloss: 0.57299\n",
      "[48]\ttraining's binary_logloss: 0.572412\n",
      "[49]\ttraining's binary_logloss: 0.571856\n",
      "[50]\ttraining's binary_logloss: 0.571317\n",
      "[51]\ttraining's binary_logloss: 0.570859\n",
      "[52]\ttraining's binary_logloss: 0.570423\n",
      "[53]\ttraining's binary_logloss: 0.569991\n",
      "[54]\ttraining's binary_logloss: 0.569572\n",
      "[55]\ttraining's binary_logloss: 0.569151\n",
      "[56]\ttraining's binary_logloss: 0.568755\n",
      "[57]\ttraining's binary_logloss: 0.568295\n",
      "[58]\ttraining's binary_logloss: 0.567866\n",
      "[59]\ttraining's binary_logloss: 0.56743\n",
      "[60]\ttraining's binary_logloss: 0.567007\n",
      "[61]\ttraining's binary_logloss: 0.566629\n",
      "[62]\ttraining's binary_logloss: 0.566304\n",
      "[63]\ttraining's binary_logloss: 0.565976\n",
      "[64]\ttraining's binary_logloss: 0.565615\n",
      "[65]\ttraining's binary_logloss: 0.565284\n",
      "[66]\ttraining's binary_logloss: 0.564972\n",
      "[67]\ttraining's binary_logloss: 0.564637\n",
      "[68]\ttraining's binary_logloss: 0.564316\n",
      "[69]\ttraining's binary_logloss: 0.563923\n",
      "[70]\ttraining's binary_logloss: 0.563604\n",
      "[71]\ttraining's binary_logloss: 0.563249\n",
      "[72]\ttraining's binary_logloss: 0.56292\n",
      "[73]\ttraining's binary_logloss: 0.56267\n",
      "[74]\ttraining's binary_logloss: 0.56236\n",
      "[75]\ttraining's binary_logloss: 0.562047\n",
      "[76]\ttraining's binary_logloss: 0.561765\n",
      "[77]\ttraining's binary_logloss: 0.561473\n",
      "[78]\ttraining's binary_logloss: 0.561211\n",
      "[79]\ttraining's binary_logloss: 0.56094\n",
      "[80]\ttraining's binary_logloss: 0.560673\n",
      "[81]\ttraining's binary_logloss: 0.560427\n",
      "[82]\ttraining's binary_logloss: 0.560165\n",
      "[83]\ttraining's binary_logloss: 0.559904\n",
      "[84]\ttraining's binary_logloss: 0.559667\n",
      "[85]\ttraining's binary_logloss: 0.559429\n",
      "[86]\ttraining's binary_logloss: 0.559161\n",
      "[87]\ttraining's binary_logloss: 0.558907\n",
      "[88]\ttraining's binary_logloss: 0.558639\n",
      "[89]\ttraining's binary_logloss: 0.558364\n",
      "[90]\ttraining's binary_logloss: 0.558087\n",
      "[91]\ttraining's binary_logloss: 0.557837\n",
      "[92]\ttraining's binary_logloss: 0.557676\n",
      "[93]\ttraining's binary_logloss: 0.55746\n",
      "[94]\ttraining's binary_logloss: 0.557252\n",
      "[95]\ttraining's binary_logloss: 0.557075\n",
      "[96]\ttraining's binary_logloss: 0.556839\n",
      "[97]\ttraining's binary_logloss: 0.556574\n",
      "[98]\ttraining's binary_logloss: 0.556335\n",
      "[99]\ttraining's binary_logloss: 0.556127\n",
      "[100]\ttraining's binary_logloss: 0.555918\n",
      "[101]\ttraining's binary_logloss: 0.555674\n",
      "[102]\ttraining's binary_logloss: 0.555414\n",
      "[103]\ttraining's binary_logloss: 0.555186\n",
      "[104]\ttraining's binary_logloss: 0.554952\n",
      "[105]\ttraining's binary_logloss: 0.554698\n",
      "[106]\ttraining's binary_logloss: 0.5545\n",
      "[107]\ttraining's binary_logloss: 0.5543\n",
      "[108]\ttraining's binary_logloss: 0.554106\n",
      "[109]\ttraining's binary_logloss: 0.553924\n",
      "[110]\ttraining's binary_logloss: 0.553737\n",
      "[111]\ttraining's binary_logloss: 0.553496\n",
      "[112]\ttraining's binary_logloss: 0.553308\n",
      "[113]\ttraining's binary_logloss: 0.553059\n",
      "[114]\ttraining's binary_logloss: 0.552806\n",
      "[115]\ttraining's binary_logloss: 0.552577\n",
      "[116]\ttraining's binary_logloss: 0.552352\n",
      "[117]\ttraining's binary_logloss: 0.552137\n",
      "[118]\ttraining's binary_logloss: 0.551915\n",
      "[119]\ttraining's binary_logloss: 0.551691\n",
      "[120]\ttraining's binary_logloss: 0.55148\n",
      "[121]\ttraining's binary_logloss: 0.551345\n",
      "[122]\ttraining's binary_logloss: 0.551146\n",
      "[123]\ttraining's binary_logloss: 0.551003\n",
      "[124]\ttraining's binary_logloss: 0.550888\n",
      "[125]\ttraining's binary_logloss: 0.55075\n",
      "[126]\ttraining's binary_logloss: 0.550534\n",
      "[127]\ttraining's binary_logloss: 0.550318\n",
      "[128]\ttraining's binary_logloss: 0.550119\n",
      "[129]\ttraining's binary_logloss: 0.549901\n",
      "[130]\ttraining's binary_logloss: 0.549693\n",
      "[131]\ttraining's binary_logloss: 0.549559\n",
      "[132]\ttraining's binary_logloss: 0.549404\n",
      "[133]\ttraining's binary_logloss: 0.549236\n",
      "[134]\ttraining's binary_logloss: 0.549073\n",
      "[135]\ttraining's binary_logloss: 0.548914\n",
      "[136]\ttraining's binary_logloss: 0.548692\n",
      "[137]\ttraining's binary_logloss: 0.548555\n",
      "[138]\ttraining's binary_logloss: 0.548373\n",
      "[139]\ttraining's binary_logloss: 0.54823\n",
      "[140]\ttraining's binary_logloss: 0.548053\n",
      "[141]\ttraining's binary_logloss: 0.547843\n",
      "[142]\ttraining's binary_logloss: 0.547684\n",
      "[143]\ttraining's binary_logloss: 0.547535\n",
      "[144]\ttraining's binary_logloss: 0.54735\n",
      "[145]\ttraining's binary_logloss: 0.547192\n",
      "[146]\ttraining's binary_logloss: 0.547031\n",
      "[147]\ttraining's binary_logloss: 0.546859\n",
      "[148]\ttraining's binary_logloss: 0.546706\n",
      "[149]\ttraining's binary_logloss: 0.546539\n",
      "[150]\ttraining's binary_logloss: 0.546389\n",
      "[151]\ttraining's binary_logloss: 0.546217\n",
      "[152]\ttraining's binary_logloss: 0.546056\n",
      "[153]\ttraining's binary_logloss: 0.545878\n",
      "[154]\ttraining's binary_logloss: 0.545728\n",
      "[155]\ttraining's binary_logloss: 0.545572\n",
      "[156]\ttraining's binary_logloss: 0.545384\n",
      "[157]\ttraining's binary_logloss: 0.545232\n",
      "[158]\ttraining's binary_logloss: 0.545056\n",
      "[159]\ttraining's binary_logloss: 0.544854\n",
      "[160]\ttraining's binary_logloss: 0.544693\n",
      "[161]\ttraining's binary_logloss: 0.544515\n",
      "[162]\ttraining's binary_logloss: 0.544328\n",
      "[163]\ttraining's binary_logloss: 0.54415\n",
      "[164]\ttraining's binary_logloss: 0.543949\n",
      "[165]\ttraining's binary_logloss: 0.543779\n",
      "[166]\ttraining's binary_logloss: 0.543586\n",
      "[167]\ttraining's binary_logloss: 0.543412\n",
      "[168]\ttraining's binary_logloss: 0.543243\n",
      "[169]\ttraining's binary_logloss: 0.543063\n",
      "[170]\ttraining's binary_logloss: 0.54292\n",
      "[171]\ttraining's binary_logloss: 0.542776\n",
      "[172]\ttraining's binary_logloss: 0.542624\n",
      "[173]\ttraining's binary_logloss: 0.542474\n",
      "[174]\ttraining's binary_logloss: 0.542306\n",
      "[175]\ttraining's binary_logloss: 0.542155\n",
      "[176]\ttraining's binary_logloss: 0.541976\n",
      "[177]\ttraining's binary_logloss: 0.541806\n",
      "[178]\ttraining's binary_logloss: 0.541628\n",
      "[179]\ttraining's binary_logloss: 0.541486\n",
      "[180]\ttraining's binary_logloss: 0.541342\n",
      "[181]\ttraining's binary_logloss: 0.541165\n",
      "[182]\ttraining's binary_logloss: 0.541002\n",
      "[183]\ttraining's binary_logloss: 0.540831\n",
      "[184]\ttraining's binary_logloss: 0.540662\n",
      "[185]\ttraining's binary_logloss: 0.540495\n",
      "[186]\ttraining's binary_logloss: 0.540341\n",
      "[187]\ttraining's binary_logloss: 0.540195\n",
      "[188]\ttraining's binary_logloss: 0.540021\n",
      "[189]\ttraining's binary_logloss: 0.539891\n",
      "[190]\ttraining's binary_logloss: 0.539731\n",
      "[191]\ttraining's binary_logloss: 0.53954\n",
      "[192]\ttraining's binary_logloss: 0.539377\n",
      "[193]\ttraining's binary_logloss: 0.539196\n",
      "[194]\ttraining's binary_logloss: 0.539022\n",
      "[195]\ttraining's binary_logloss: 0.538859\n",
      "[196]\ttraining's binary_logloss: 0.538689\n",
      "[197]\ttraining's binary_logloss: 0.538535\n",
      "[198]\ttraining's binary_logloss: 0.538364\n",
      "[199]\ttraining's binary_logloss: 0.538194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's binary_logloss: 0.538016\n",
      "[201]\ttraining's binary_logloss: 0.537857\n",
      "[202]\ttraining's binary_logloss: 0.537693\n",
      "[203]\ttraining's binary_logloss: 0.537522\n",
      "[204]\ttraining's binary_logloss: 0.53735\n",
      "[205]\ttraining's binary_logloss: 0.537186\n",
      "[206]\ttraining's binary_logloss: 0.53698\n",
      "[207]\ttraining's binary_logloss: 0.536773\n",
      "[208]\ttraining's binary_logloss: 0.536545\n",
      "[209]\ttraining's binary_logloss: 0.53632\n",
      "[210]\ttraining's binary_logloss: 0.536149\n",
      "[211]\ttraining's binary_logloss: 0.53599\n",
      "[212]\ttraining's binary_logloss: 0.535829\n",
      "[213]\ttraining's binary_logloss: 0.535683\n",
      "[214]\ttraining's binary_logloss: 0.535531\n",
      "[215]\ttraining's binary_logloss: 0.535402\n",
      "[216]\ttraining's binary_logloss: 0.535222\n",
      "[217]\ttraining's binary_logloss: 0.535023\n",
      "[218]\ttraining's binary_logloss: 0.534841\n",
      "[219]\ttraining's binary_logloss: 0.534655\n",
      "[220]\ttraining's binary_logloss: 0.534466\n",
      "[221]\ttraining's binary_logloss: 0.534294\n",
      "[222]\ttraining's binary_logloss: 0.534125\n",
      "[223]\ttraining's binary_logloss: 0.533957\n",
      "[224]\ttraining's binary_logloss: 0.533788\n",
      "[225]\ttraining's binary_logloss: 0.533631\n",
      "[226]\ttraining's binary_logloss: 0.533446\n",
      "[227]\ttraining's binary_logloss: 0.533229\n",
      "[228]\ttraining's binary_logloss: 0.533038\n",
      "[229]\ttraining's binary_logloss: 0.532818\n",
      "[230]\ttraining's binary_logloss: 0.532634\n",
      "[231]\ttraining's binary_logloss: 0.532451\n",
      "[232]\ttraining's binary_logloss: 0.532295\n",
      "[233]\ttraining's binary_logloss: 0.532139\n",
      "[234]\ttraining's binary_logloss: 0.531975\n",
      "[235]\ttraining's binary_logloss: 0.531837\n",
      "[236]\ttraining's binary_logloss: 0.531634\n",
      "[237]\ttraining's binary_logloss: 0.531405\n",
      "[238]\ttraining's binary_logloss: 0.531175\n",
      "[239]\ttraining's binary_logloss: 0.530952\n",
      "[240]\ttraining's binary_logloss: 0.530749\n",
      "[241]\ttraining's binary_logloss: 0.530586\n",
      "[242]\ttraining's binary_logloss: 0.530404\n",
      "[243]\ttraining's binary_logloss: 0.530222\n",
      "[244]\ttraining's binary_logloss: 0.530039\n",
      "[245]\ttraining's binary_logloss: 0.529854\n",
      "[246]\ttraining's binary_logloss: 0.529668\n",
      "[247]\ttraining's binary_logloss: 0.529484\n",
      "[248]\ttraining's binary_logloss: 0.529233\n",
      "[249]\ttraining's binary_logloss: 0.528994\n",
      "[250]\ttraining's binary_logloss: 0.528765\n",
      "[251]\ttraining's binary_logloss: 0.528539\n",
      "[252]\ttraining's binary_logloss: 0.52832\n",
      "[253]\ttraining's binary_logloss: 0.528126\n",
      "[254]\ttraining's binary_logloss: 0.527928\n",
      "[255]\ttraining's binary_logloss: 0.527731\n",
      "[256]\ttraining's binary_logloss: 0.527556\n",
      "[257]\ttraining's binary_logloss: 0.527395\n",
      "[258]\ttraining's binary_logloss: 0.527228\n",
      "[259]\ttraining's binary_logloss: 0.527027\n",
      "[260]\ttraining's binary_logloss: 0.526843\n",
      "[261]\ttraining's binary_logloss: 0.526693\n",
      "[262]\ttraining's binary_logloss: 0.526563\n",
      "[263]\ttraining's binary_logloss: 0.526413\n",
      "[264]\ttraining's binary_logloss: 0.526216\n",
      "[265]\ttraining's binary_logloss: 0.526051\n",
      "[266]\ttraining's binary_logloss: 0.525889\n",
      "[267]\ttraining's binary_logloss: 0.525729\n",
      "[268]\ttraining's binary_logloss: 0.525589\n",
      "[269]\ttraining's binary_logloss: 0.525439\n",
      "[270]\ttraining's binary_logloss: 0.525272\n",
      "[271]\ttraining's binary_logloss: 0.525068\n",
      "[272]\ttraining's binary_logloss: 0.524927\n",
      "[273]\ttraining's binary_logloss: 0.524735\n",
      "[274]\ttraining's binary_logloss: 0.524557\n",
      "[275]\ttraining's binary_logloss: 0.524392\n",
      "[276]\ttraining's binary_logloss: 0.524194\n",
      "[277]\ttraining's binary_logloss: 0.524026\n",
      "[278]\ttraining's binary_logloss: 0.523858\n",
      "[279]\ttraining's binary_logloss: 0.523676\n",
      "[280]\ttraining's binary_logloss: 0.523505\n",
      "[281]\ttraining's binary_logloss: 0.523342\n",
      "[282]\ttraining's binary_logloss: 0.523201\n",
      "[283]\ttraining's binary_logloss: 0.523054\n",
      "[284]\ttraining's binary_logloss: 0.522885\n",
      "[285]\ttraining's binary_logloss: 0.522729\n",
      "[286]\ttraining's binary_logloss: 0.522509\n",
      "[287]\ttraining's binary_logloss: 0.522276\n",
      "[288]\ttraining's binary_logloss: 0.522058\n",
      "[289]\ttraining's binary_logloss: 0.521877\n",
      "[290]\ttraining's binary_logloss: 0.521681\n",
      "[291]\ttraining's binary_logloss: 0.521473\n",
      "[292]\ttraining's binary_logloss: 0.521213\n",
      "[293]\ttraining's binary_logloss: 0.520986\n",
      "[294]\ttraining's binary_logloss: 0.520768\n",
      "[295]\ttraining's binary_logloss: 0.520546\n",
      "[296]\ttraining's binary_logloss: 0.520358\n",
      "[297]\ttraining's binary_logloss: 0.520195\n",
      "[298]\ttraining's binary_logloss: 0.520012\n",
      "[299]\ttraining's binary_logloss: 0.519839\n",
      "[300]\ttraining's binary_logloss: 0.519645\n",
      "[301]\ttraining's binary_logloss: 0.519446\n",
      "[302]\ttraining's binary_logloss: 0.519282\n",
      "[303]\ttraining's binary_logloss: 0.519081\n",
      "[304]\ttraining's binary_logloss: 0.518898\n",
      "[305]\ttraining's binary_logloss: 0.518752\n",
      "[306]\ttraining's binary_logloss: 0.518579\n",
      "[307]\ttraining's binary_logloss: 0.518395\n",
      "[308]\ttraining's binary_logloss: 0.518206\n",
      "[309]\ttraining's binary_logloss: 0.518018\n",
      "[310]\ttraining's binary_logloss: 0.517825\n",
      "[311]\ttraining's binary_logloss: 0.517615\n",
      "[312]\ttraining's binary_logloss: 0.51741\n",
      "[313]\ttraining's binary_logloss: 0.517203\n",
      "[314]\ttraining's binary_logloss: 0.516994\n",
      "[315]\ttraining's binary_logloss: 0.516765\n",
      "[316]\ttraining's binary_logloss: 0.51657\n",
      "[317]\ttraining's binary_logloss: 0.516342\n",
      "[318]\ttraining's binary_logloss: 0.516162\n",
      "[319]\ttraining's binary_logloss: 0.515956\n",
      "[320]\ttraining's binary_logloss: 0.515743\n",
      "[321]\ttraining's binary_logloss: 0.515558\n",
      "[322]\ttraining's binary_logloss: 0.515379\n",
      "[323]\ttraining's binary_logloss: 0.515209\n",
      "[324]\ttraining's binary_logloss: 0.515009\n",
      "[325]\ttraining's binary_logloss: 0.514852\n",
      "[326]\ttraining's binary_logloss: 0.514622\n",
      "[327]\ttraining's binary_logloss: 0.514405\n",
      "[328]\ttraining's binary_logloss: 0.514204\n",
      "[329]\ttraining's binary_logloss: 0.51399\n",
      "[330]\ttraining's binary_logloss: 0.513766\n",
      "[331]\ttraining's binary_logloss: 0.513583\n",
      "[332]\ttraining's binary_logloss: 0.513385\n",
      "[333]\ttraining's binary_logloss: 0.513183\n",
      "[334]\ttraining's binary_logloss: 0.512978\n",
      "[335]\ttraining's binary_logloss: 0.512788\n",
      "[336]\ttraining's binary_logloss: 0.512602\n",
      "[337]\ttraining's binary_logloss: 0.512451\n",
      "[338]\ttraining's binary_logloss: 0.512244\n",
      "[339]\ttraining's binary_logloss: 0.512044\n",
      "[340]\ttraining's binary_logloss: 0.511869\n",
      "[341]\ttraining's binary_logloss: 0.511724\n",
      "[342]\ttraining's binary_logloss: 0.511568\n",
      "[343]\ttraining's binary_logloss: 0.511411\n",
      "[344]\ttraining's binary_logloss: 0.511261\n",
      "[345]\ttraining's binary_logloss: 0.511112\n",
      "[346]\ttraining's binary_logloss: 0.510918\n",
      "[347]\ttraining's binary_logloss: 0.510706\n",
      "[348]\ttraining's binary_logloss: 0.510501\n",
      "[349]\ttraining's binary_logloss: 0.510302\n",
      "[350]\ttraining's binary_logloss: 0.510098\n",
      "[351]\ttraining's binary_logloss: 0.509935\n",
      "[352]\ttraining's binary_logloss: 0.509781\n",
      "[353]\ttraining's binary_logloss: 0.509607\n",
      "[354]\ttraining's binary_logloss: 0.509451\n",
      "[355]\ttraining's binary_logloss: 0.509293\n",
      "[356]\ttraining's binary_logloss: 0.509094\n",
      "[357]\ttraining's binary_logloss: 0.508915\n",
      "[358]\ttraining's binary_logloss: 0.508719\n",
      "[359]\ttraining's binary_logloss: 0.50852\n",
      "[360]\ttraining's binary_logloss: 0.508332\n",
      "[361]\ttraining's binary_logloss: 0.508137\n",
      "[362]\ttraining's binary_logloss: 0.507943\n",
      "[363]\ttraining's binary_logloss: 0.507727\n",
      "[364]\ttraining's binary_logloss: 0.507554\n",
      "[365]\ttraining's binary_logloss: 0.507353\n",
      "[366]\ttraining's binary_logloss: 0.507154\n",
      "[367]\ttraining's binary_logloss: 0.506973\n",
      "[368]\ttraining's binary_logloss: 0.506789\n",
      "[369]\ttraining's binary_logloss: 0.506592\n",
      "[370]\ttraining's binary_logloss: 0.506419\n",
      "[371]\ttraining's binary_logloss: 0.506208\n",
      "[372]\ttraining's binary_logloss: 0.505992\n",
      "[373]\ttraining's binary_logloss: 0.505789\n",
      "[374]\ttraining's binary_logloss: 0.505568\n",
      "[375]\ttraining's binary_logloss: 0.505371\n",
      "[376]\ttraining's binary_logloss: 0.50518\n",
      "[377]\ttraining's binary_logloss: 0.504956\n",
      "[378]\ttraining's binary_logloss: 0.504765\n",
      "[379]\ttraining's binary_logloss: 0.504587\n",
      "[380]\ttraining's binary_logloss: 0.504399\n",
      "[381]\ttraining's binary_logloss: 0.504205\n",
      "[382]\ttraining's binary_logloss: 0.50401\n",
      "[383]\ttraining's binary_logloss: 0.503774\n",
      "[384]\ttraining's binary_logloss: 0.50359\n",
      "[385]\ttraining's binary_logloss: 0.503379\n",
      "[386]\ttraining's binary_logloss: 0.503162\n",
      "[387]\ttraining's binary_logloss: 0.502957\n",
      "[388]\ttraining's binary_logloss: 0.502754\n",
      "[389]\ttraining's binary_logloss: 0.502565\n",
      "[390]\ttraining's binary_logloss: 0.502369\n",
      "[391]\ttraining's binary_logloss: 0.50216\n",
      "[392]\ttraining's binary_logloss: 0.501938\n",
      "[393]\ttraining's binary_logloss: 0.501733\n",
      "[394]\ttraining's binary_logloss: 0.501523\n",
      "[395]\ttraining's binary_logloss: 0.501297\n",
      "[396]\ttraining's binary_logloss: 0.501109\n",
      "[397]\ttraining's binary_logloss: 0.500939\n",
      "[398]\ttraining's binary_logloss: 0.50075\n",
      "[399]\ttraining's binary_logloss: 0.500562\n",
      "[400]\ttraining's binary_logloss: 0.500367\n",
      "[401]\ttraining's binary_logloss: 0.500181\n",
      "[402]\ttraining's binary_logloss: 0.499991\n",
      "[403]\ttraining's binary_logloss: 0.499776\n",
      "[404]\ttraining's binary_logloss: 0.499586\n",
      "[405]\ttraining's binary_logloss: 0.499375\n",
      "[406]\ttraining's binary_logloss: 0.49918\n",
      "[407]\ttraining's binary_logloss: 0.498983\n",
      "[408]\ttraining's binary_logloss: 0.498764\n",
      "[409]\ttraining's binary_logloss: 0.498549\n",
      "[410]\ttraining's binary_logloss: 0.498327\n",
      "[411]\ttraining's binary_logloss: 0.498123\n",
      "[412]\ttraining's binary_logloss: 0.49796\n",
      "[413]\ttraining's binary_logloss: 0.497752\n",
      "[414]\ttraining's binary_logloss: 0.497564\n",
      "[415]\ttraining's binary_logloss: 0.497388\n",
      "[416]\ttraining's binary_logloss: 0.497179\n",
      "[417]\ttraining's binary_logloss: 0.49699\n",
      "[418]\ttraining's binary_logloss: 0.496783\n",
      "[419]\ttraining's binary_logloss: 0.496599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[420]\ttraining's binary_logloss: 0.496412\n",
      "[421]\ttraining's binary_logloss: 0.496212\n",
      "[422]\ttraining's binary_logloss: 0.496052\n",
      "[423]\ttraining's binary_logloss: 0.495877\n",
      "[424]\ttraining's binary_logloss: 0.495683\n",
      "[425]\ttraining's binary_logloss: 0.495528\n",
      "[426]\ttraining's binary_logloss: 0.495366\n",
      "[427]\ttraining's binary_logloss: 0.495181\n",
      "[428]\ttraining's binary_logloss: 0.494988\n",
      "[429]\ttraining's binary_logloss: 0.49485\n",
      "[430]\ttraining's binary_logloss: 0.494691\n",
      "[431]\ttraining's binary_logloss: 0.494489\n",
      "[432]\ttraining's binary_logloss: 0.494319\n",
      "[433]\ttraining's binary_logloss: 0.494129\n",
      "[434]\ttraining's binary_logloss: 0.493948\n",
      "[435]\ttraining's binary_logloss: 0.493764\n",
      "[436]\ttraining's binary_logloss: 0.493612\n",
      "[437]\ttraining's binary_logloss: 0.493423\n",
      "[438]\ttraining's binary_logloss: 0.493262\n",
      "[439]\ttraining's binary_logloss: 0.493082\n",
      "[440]\ttraining's binary_logloss: 0.492935\n",
      "[441]\ttraining's binary_logloss: 0.492741\n",
      "[442]\ttraining's binary_logloss: 0.492558\n",
      "[443]\ttraining's binary_logloss: 0.492374\n",
      "[444]\ttraining's binary_logloss: 0.492198\n",
      "[445]\ttraining's binary_logloss: 0.492003\n",
      "[446]\ttraining's binary_logloss: 0.491772\n",
      "[447]\ttraining's binary_logloss: 0.49153\n",
      "[448]\ttraining's binary_logloss: 0.49129\n",
      "[449]\ttraining's binary_logloss: 0.491061\n",
      "[450]\ttraining's binary_logloss: 0.490842\n",
      "[451]\ttraining's binary_logloss: 0.490659\n",
      "[452]\ttraining's binary_logloss: 0.490407\n",
      "[453]\ttraining's binary_logloss: 0.490164\n",
      "[454]\ttraining's binary_logloss: 0.489982\n",
      "[455]\ttraining's binary_logloss: 0.489745\n",
      "[456]\ttraining's binary_logloss: 0.489545\n",
      "[457]\ttraining's binary_logloss: 0.48935\n",
      "[458]\ttraining's binary_logloss: 0.489169\n",
      "[459]\ttraining's binary_logloss: 0.489016\n",
      "[460]\ttraining's binary_logloss: 0.488872\n",
      "[461]\ttraining's binary_logloss: 0.488692\n",
      "[462]\ttraining's binary_logloss: 0.488496\n",
      "[463]\ttraining's binary_logloss: 0.48832\n",
      "[464]\ttraining's binary_logloss: 0.488112\n",
      "[465]\ttraining's binary_logloss: 0.48793\n",
      "[466]\ttraining's binary_logloss: 0.487733\n",
      "[467]\ttraining's binary_logloss: 0.48754\n",
      "[468]\ttraining's binary_logloss: 0.487353\n",
      "[469]\ttraining's binary_logloss: 0.487151\n",
      "[470]\ttraining's binary_logloss: 0.486963\n",
      "[471]\ttraining's binary_logloss: 0.486773\n",
      "[472]\ttraining's binary_logloss: 0.486535\n",
      "[473]\ttraining's binary_logloss: 0.486309\n",
      "[474]\ttraining's binary_logloss: 0.486107\n",
      "[475]\ttraining's binary_logloss: 0.485906\n",
      "[476]\ttraining's binary_logloss: 0.485734\n",
      "[477]\ttraining's binary_logloss: 0.485546\n",
      "[478]\ttraining's binary_logloss: 0.485346\n",
      "[479]\ttraining's binary_logloss: 0.48515\n",
      "[480]\ttraining's binary_logloss: 0.484959\n",
      "[481]\ttraining's binary_logloss: 0.484788\n",
      "[482]\ttraining's binary_logloss: 0.484622\n",
      "[483]\ttraining's binary_logloss: 0.484454\n",
      "[484]\ttraining's binary_logloss: 0.484278\n",
      "[485]\ttraining's binary_logloss: 0.484137\n",
      "[486]\ttraining's binary_logloss: 0.483892\n",
      "[487]\ttraining's binary_logloss: 0.483661\n",
      "[488]\ttraining's binary_logloss: 0.483426\n",
      "[489]\ttraining's binary_logloss: 0.483228\n",
      "[490]\ttraining's binary_logloss: 0.483003\n",
      "[491]\ttraining's binary_logloss: 0.482809\n",
      "[492]\ttraining's binary_logloss: 0.482619\n",
      "[493]\ttraining's binary_logloss: 0.482438\n",
      "[494]\ttraining's binary_logloss: 0.482242\n",
      "[495]\ttraining's binary_logloss: 0.482049\n",
      "[496]\ttraining's binary_logloss: 0.481825\n",
      "[497]\ttraining's binary_logloss: 0.481644\n",
      "[498]\ttraining's binary_logloss: 0.481446\n",
      "[499]\ttraining's binary_logloss: 0.481228\n",
      "[500]\ttraining's binary_logloss: 0.48101\n"
     ]
    }
   ],
   "source": [
    "leavenumber_values = [10,20,30,40]\n",
    "min_data_in_leave_values = [10,20,30,40]\n",
    "\n",
    "res2 = dict()\n",
    "for s2 in min_data_in_leave_values:\n",
    "    res2[s2] = list()\n",
    "\n",
    "#Now train and get results for each option\n",
    "for s2 in min_data_in_leave_values:\n",
    "    for l2 in leavenumber_values:\n",
    "        res2[s2].append(testLGM(X_Train,Y_Train,X_Test,Y_Test, l2, s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Holdout Accuracy by Hyperparameters')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py:2267: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVwAAAEVCAYAAACsQV2IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXmcU9X1wL8nyezDMDsMMDLsiAsiiFqXutQWlyqK4v7T1qoVtVXrrlWrVGvr1qpVce3iClitbdFWpdatVVBc2JGdYYDZmH1Jcn9/3JchE5JJBmYymeF8P5/3Sd5dz01eTu47975zxBiDoiiK0v24eloARVGUPQVVuIqiKHFCFa6iKEqcUIWrKIoSJ1ThKoqixAlVuIqiKHEiIRWuiNwhIt4IeWeJiBGRkk62eZRT7/Ao5Q5xyh3VmfY7IccBzviyOlnvTEeu97pDrr5CR9dOF7Uf8ToSkYFO3oXd1b8SO7v6W+tOElLh9nEOAG4HOnsRnOe8HiEiQ7tWJEXpk+zqb63bUIXbCxCRAmAK8CYgwLk9K9HOiEhaT8ughCde301fvwbEkro7bfQJhSsiKSLyKxHZICLNIrJCRK6OoZ5HRH4jIttEpFZEXgLydqV9EbnQuZ0cEpL+nIisCpQBnnWyNjjlY3nU7yzAA/wc+Iwds91QOQ8SkX+ISLWI1IvI5yJydlC+iMiVIvK1iDQ54/5bYMYcyxhCyh0uIn8XkTrgMSfvPBF5T0TKRWS7iPxPRE4MI2uRiDwtIpudz/QbEbnbybtaRBpFJCekTraINIjItdE+MBEZLyIfOu18IyL/F5R3qiP/uJA6buc7fiRa+7EQ6zgCZpCOZA6qO1FE5jmfbb2IvCUi+4SUMSJyu4jcJSKlQH1n+hGRg0XkLyKyyZFzsYhcJyLuoDIlTj+XiMijIrINWLIL9S8SkYdFpMK5bh8UEZeIHCEinzpj/ERE9g/zWVzhtN3sXEf3i0iKk3chHfzWRKSf01fgN71cRC4Oaf85EVklIseKyEKgCftbxBnPCud3VOF8nt+KcCm0kdAKV6xCbHcQXuY/AVcDvwe+D7wBPCAid0bpYqZT71FgGlAOPN6F7Yfyd6dPgJOBQ50jGucBK4wxC4A/A3uLyMTgAiJyKPA+kAv8GDjFkTvY/PBb4CHgHWAqcDGwBijo5DgCPA/8z+nrKSetBHgJOBs4A/gQeENEjg+SNRf4CDgeuNN5nQkUOkWec17PD+nvXOwfzx+iyCXAXGA2cKoj4x9E5Dgn/w2gFPhRSL0pwJCgsXSEO8y16Q4p05lxRJMZEZkEfID9DVyI/YwzgP+IyKCQPi4FJgKXAGd2ph/sNfOp08YJ2M/jFuCXYT6HO4B+2Gv0J7tQ/3ZnPGdhr82rgAewv8PfAtOdMb4aorB/A9wP/AU4CXv9XMSOzzTib01EkoC3nD7vBk4EXgceF5Efh8iXDzyJ/e2fAPzP+YO6x+lrCva7eBvIIRrGmIQ7sF+iiXKUOGX3c85/FtLGE0AjkO2cH+WUO9w5z8H+8/86pN4cp9xRnWz/QqfckJByzwGrgs7DluvgsxjtlL/NOR8IeIEHQ8p9AKwEkiO0MwrwA7/ooK/OjuHOKLK7sIrlr8DrQekzgVZgdAd1/wh8EZL2OfBKjNfOjJD0/wEfBp3fCWwL/ryA14BPorQfuI46Oi7szDg6IfO7wELAHZSWhZ0o/DoozQCrAc+ufDYheeJ8hz8DqgBx0kuctt6L8nlFq//XkPILnPQDg9K+76Qd7JwPA3zAVSF1z3XKjYtyPf8f9rdwYEj6k0AZ4Aq67g1wTEi5R4DPYvn9hh6JPMP1AQeFOW4JKXeE8/pSSPqLQKpTJxz7A+nYf8hgXumi9ruKwOzoeQBjTBl2hnp24B9fRNKx/95/Nsa0RGjnWOzF/0wXyvZGaIKI7C0ic0RkM/aPoRX7gxkTVOw7wAfGmBUdtP04sL+ITHbanYRdBHkyRtlCv9e5wEFBs6QnsX+6U532B2JnOrG2/yN2vjan7OY4Isos1j56JHZmKkGz6gbgYyB018Q8Y0yk3RodfjYikuPcbq8FWrDf4X1ANjAgpO7fQhvvZP1/hZyvACqNMZ8FpS13Xoud1+9g/8xfCbnD+KeT3+FOJOB7TptfhtR/y5FvZFDZemPMuyH1FwAHiMhvHdNHzHZdT6wFewJjb6HbISIjQ5JyndeykPSykPxQipzXrSHpW7qo/a7iXKzdtkJEsp2014DvAsdhF9JysBfgpg7aCdimS7tQtnafiYj0w1701dgZzVrsD+5WrJIJluV/HTVsjPlIRL7CKrZPsOaPtdhbt1gI970mYW8RtxhjNojIPKf9V4AfYG10oX+skVgeen06Snt3xtGRzAGTxT3OEUron1fo9RprP1uwM7sjsWsGX2KVesD8E6pcwvXTmfpVIectEdIIqhswPUW63ndahwmhEBiL/SOIVj9UH4A1JWRgzTVXAg0iMht7F1zZUccJrXBjJDDAAbRXJgNC8kPZ7LwWAt+EqdfZ9puc1+SQ+tG+/IiI3es5zDlCL0KwdrM3nTw/MLiD5sqd10HAughlOjuG0AW/Q7A20DOMMf8NJIaZAZRHkTXAE8A9InIr1l55r3Hu6WKgkB3fMdjvq5UdnwPY2ecbIjIMa/97yRhTG2P7nSHWcXQkcyr2O34AeDlM3aaQ844+p4j9ON/VicCtxpi2xUMR+U6Ettr1swv1d4UK5/UonAXBEDqaeATqLyfC4jOwLOj9Tp+j8909CjwqIvlYW/j92D/EnRY6g0lkk0KsvO+8Tg9JPwt7EX4aod6XWBvsqSHpoe3E2v5657Vt5VtE+rPzoliz8xrLbcj52B/C8cDRIcdrwFQRyTTGNGAXoc4TkVBlGeBd7MXzww76i3UMkUh3XtvMGmJ3PBwVUu5t4HARGR2lvT/j3Do6bT/bcfF2hH6v04AFxhhfUNo8YIPT7ghiNyd0lljHEVFmY0w91k6/nzFmQZjj607I09Fnk4JVHMHfoQs4J8a2d7d+LLyN/fMZFOGzCPyZRPqtvYVd2KuIUL8uVkGMMeXGmCcdmfaNVr7Xz3CNMV+JyCvAr5wtIZ9hb7cvBWYaY6oj1KsSu/3nGhGpx9rBvg8cvIvtf4Jd8b/fsQcJcB07/wMvdV4vF5GXAW8E00kydpX/78aYN8PkC9b+eCp2N8INwHzgPRH5Lfa2cV8gzRhzrzFmpTPeWx0l+ib2NvJYrO13QSfGEImPgVrsP/+dWJvdHdgZR/AK/oPYP5P5InIXdrYxBDjCGHNJoJAxZrvYrXoXYRdXYjWH+LHfa5LT9v8BkwmxsRpj/CLyJHAX8KUx5pMY2+8UMY4jFpl/hv1+/4a9rd2KnZ1+C7uoGct2tg77cWT9H3CdiJQBNcBl2FvoWMe6y/Vj7GOViNwHPCl2S9wH2DWfEuzs+qfGmHVE/q39GftdzHfaWezINxY4xBhzekf9i8gsYDv2eq/Argd9D3g4FuET7sD+SL0R8s4iaJeCk5YC3AtsxP6zrgSuDql3FEG7FJy0JOytQAVWUczGbjFp26UQa/tOuf2wM+J6YBVwASEr/E65u7C2Lz/OHUqYtk5z5DglQr5gV6LfCko7GGtDrQXqsKvhZ4bUuRp7ITZjf7B/BfbqzBjoYKcF1q78BXb2v9wp+ziwNqTcIKfdrU7ZVdg/sND2TnD6Oqkz1w4wAfuDaHI+pwsjlB/ntH9FjO3vdB0F5Q0kZJdCLOPojMzO9zPXuWabsPbgl4DJQWUM9pZ+l/oBhjvXUR3W9HAv9g+y7XfHjl0G54XpZ5frh15rUcr+ELuA1YhVgF84fWVG+61h7zR+6Vx3Lc51+D5weUeyOOkXAP/BmnqasPbz2wnZFRLuCGzRUJSEREQCe59LTHtzQFe1fz1WEQ0yEe6GuqifiOMQkTuwCrJb7zjj1Y8SGf3glYRERPbDmkR+gN2D3KXKVkTGYPcmXwc8213KtrvHofQuVOEqicob2NX0V7FPHHU1T2AXA99l573dXUl3j0PpRahJQVEUJU70hW1hiqIovQJVuIqiKHFCbbidID8/35SUlPS0GIqyx7Nw4cJyY8yuernrMVThdoKSkhIWLNjpGQVFUeKMiER6PD2hUZOCoihKnFCFqyiKEidU4SqKosQJteEmKMYYjN+P3+fD+Hz4fT78Pnvu9wan+drKJKWnkZGXR1JqSk+LryhKGFThdjHbSzfT0ti0QyF62ytFf7vD3z7N277crpLSL5PM/Dwy8/PIyM8jNasf1rlY78TX2kpDZRX1lVXUV1TSUFkNAslpaSSlp5GUlkZyWipJ6Wk2LS2NpLRUXO7QEGOK0rOowu1iNi9eRn1Fh07fuwxxuXC53bjcbsTloqWxEYyhubaO5to6KtbYhVx3cjKZ+blkBJRwbi4uT2IqI+P307i9hvqKSuorqqivrKRpe03Ysi31DR225U5OJjndKt82RZzuKGfn3JOS3Kv/jJTehSrcLsaTmkJSWhouj3uHMnS7cbl3KMcdac7hCZMWlBepfqii8LV6qa+spH5bBXXlFdRVVOBv9eJraWF7aRnbS200FHEJ6Tk5bQo4Mz+PpLSYwzJ1GcYYWuobrMwVzuy1qhoTYXafkplBem4uGXk5iAgtjY20NjTR2tho3zc24vfuqOtraaGxpYXG6u0RZRCXiyRHAdsZc2q7WXJgFr2nzJaNMXibrd/upNT4XxN9HfWl0AkmTZpketM+XOM3NNXUWOW7rYK68vKIs8LkjAyrfAusAk7tn9XlMz9vS4tVqs7Mtb6iqu3HHYo7OZmMvBwycnPJyLNK1pMS3Tbta22lpcEq39bGprb3Lc55a2MjrU1NHQegiSBPcloqntRUq6BTU0lKTSEpNRVP4DwtFXdSUsLOmP1eX9sfU2vDjs+kxTlvbWyitakR47cfTmZBPvnDS8guHozbk1hzMxFZaIyZ1NNydBZVuJ2gtynccLQ2NlJXXkldeTl12ypoqKqGMNeAOymJjLxca4IosGYId1LsPzq/z0dj9XbHNFBJfWUVzbXhI5eIy0V6TrajWHPJyM0hOTOj2xSX8ftpbWreoYgbQhRPk1XUfm+koLeREZfLKuHUlCDFbJWzp915apeZdYwxeIPHE/RHY9OaaG1oxNcaKWZix7g8HnKHFpM/vIT03JyE+ENRhbsH0BcUbih+r4/6ykrqyiuoL6+grrwSX0uYSOsipGf3t2aIgjwy8/JIzrAhzIxjNw4o1vqKShqrq9tmSqGkZvUjIzeX9LwcMvJySevfH5c78XYo+lpbrcJyzBZ2BugczntvU/MuKzJ3UpJVzO1mze2VtSc1BX+rd4fiDCjRdqaUprB/mh3hSvK0mU6SHfNJsH27tamJ8tVrrRkqqO3U/lnkDy8hr2SvmO44uos+rXBFZB9jzOI4yJPQ9EWFG4oxhqaaWkf52iPSzDQpPY2UjAwaq7dHVDqe1NT2poHcHNzJSd05hLjj9/raFLG3qcmZPbdXzt6mZlqbmjB+f/cKI0JSamrbYmFSWpp9n9p+F0esdyutjU1UrF1H+eq17a4DcQnZgweRN7yErAEDEFd8Z719XeH6sTGQZgGvGGMad6kzETfwK2ycq1Rs3KNLjTHlYcreDNwckpwBPGyM+YlT5i1sALcMbEyj2cBNxphmJ38g1unzMdgFws+xsci+2BX59wSFG47WpuZ2Crihsiqs4nB53HYxLsg0kJSelhC3oImAMcaZNQcp5naz5R3KOpxt252U1F6JBm2HC7z3pKR2i/IzxlBfXkH56rVUrd/YbttiUnoa+cOGkjeshJTMLosV2SF9XeHuD1yMDXXsBp4HnjTGLOpUZyK3YAOwTcEGwXsGSDfGHB9D3VHYoISHGCe6qogcACw1xjSLyABsGOoPjTE3O/mvAv2AM7EB7WYCZ2ODJnbalrKnKtxQ/D4fDVXV1JVX0FLfYE0Nebl2v68r8UwDvRHj99Pa3Iy3qRmXx21npQmycOVrbaVq/UbKV6/daQtkvwEF5A8fRvaQQd26s6NPK9y2wjZM+BnYEMNHYkOGPwm8aIypjaH+OuBOY8zTzvkIbNTMYcaYtVHq3gccY4w5MEL+AGz00kpjzDQn7UvgEWPMLOd8DLAMKAg3q47Qbh6QBzB+/PjlixZ16j9GUfo0jdtrqFi9loq169vNyt1JSeSWFJM/fBjpOdld3u8eoXDbVRS5DHgQSMbOHp8GbjfGhN2lLiL9gWpgQvDMWES2A+cbY/7aQV8pwCbg5oDyDMr7PXbWnA5UYcNQf+TknQ+cB5zryPhLbDjpIzoxzjuwIZApKiqitLQ01qqKssfg9/nZXrqZ8tVrqSkra7ftLi0nm/zhJeQOLcaTnNwl/fVWhdupexQRGYSNPvpDIDCjfBIbJO824DWsvTQcWc5r6C706qC8SJyOVewvhGYYY2aIyOXAPliTx8ag7A+xyngb4AM2AFHNFyE8HOi3sLBweSfrKsoegcvtIqd4MDnFg2lpaKBizXoq1qylua6exqpqNixcxMbPvySneDB5w0roN6Bgj7Ttx6RwReQU4EfA97B21IeAPwWHlhaRz4EVHTQTMDn0D0nPBsI/u7mDS4HnjTFhl8sde+zXIrIIeBk4VERcwNvAm8BpQBPwf8D7IrKvMWZLlD4DbVdg7c1MmtTr/lAVJe4kp6dTtM9YBo4bQ93WcrvQtnEjxuenct0GKtdtIDkjnfxhJeQNG9q2vXBPINYZ7ovYHQBHG2M+jFBmM3B/pAaMMdUish44EFgEICLDsbPbLyPVE5FxwBHAlTHI6QFGOe9zgWHYXQ0Bhf6UiNwLHAK8HkN7iqLsIiJCvwEF9BtQQHHLeKrWbaB8zToaKqtoqW+g9OsllH69hKyiAeQPL6H/oEEJuR+7K4lV4Q4Kns2Gw9mKdVOUdmYBN4jIfOys8V7grSgLZpcC/w3dyiUiY4Gx2FlsAzAea9aY58hTLiIrgBkiciPQjJ3h9gO+iiKnoihdiCc5mYJRIygYNYKGqmoq1qylYu0GfC0t1GzeQs3mLXhSkskduheD9huHO6lv7dUOEOvfyTgROSw0UUQOE5FDO9Hfr4A3gE+xi2Bu7KIWInKuiLQzGYhIGnA+8HiYtgS4HmuzDezB/Svw46AyU7Gz3HVYBX85cIYxZnUnZFYUpQtJz8mm+MAD2P+UExj2rcn0G1AIgLe5haqNm3C5E2P7W3cQ6z7cT4FfGmNeC0k/FfugweRuki+h0H24itI9NNfXU7FmHZ7kZApHj4xavq/vUtgbCPd01iLsbb2iKMouk5KRwaB9x/W0GN1OrCaFVpzN/yHk02lHd4qiKHsmsSrc94Cfi0jbjFhEkrC+Dv7THYIpiqL0NWI1KdyIfYhglYi876Qdjt3SFfNTW4qiKHsyMc1wjTHLgAOAOcAg55iDfUx3SfeJpyiK0neIef+FMWYDcG03yqIoitKn6awvhRxgKNavQRsBd4mKoihKZGL1pTAA+CPwnQhF9oyQpoqiKLtBrLsU7sc6nTkcaAROwjokXw2c0j2iKYqi9C1iNSkcA0wzxnzshNtZZYyZ5/iyvRb4W7dJqCiK0keIdYabBQQ8b1ez4yGIhcBBXS2UoihKXyRWhfsN1gkMwFLgbMff7Ok4vmIVRVGUjolV4f4Ruw8XrMevS7DuDu+lAx+4iqIoyg5isuEaY+4Pej9fRPbBOvFeYYxR91mKoigxEFXhOgEc/wpcYYxZCeD4k1WfsoqiKJ0gqknBieRwEODvfnEURVH6LrHacOdiF8gURVGUXSTWfbgbgJtE5FvY8DgNwZnGmAe6WjBFUZS+RqwK9zLsE2aTnSMYA6jCVRRFiUKsuxSKulsQRVGUvk7fDgKvKIqSQMTqLex3HeUbY34SYztu7IMTFwKpwD+BS40x5WHK3owN4RNMBvBwoD8ReQvY30kPhEq/ydlZEWjnO8BMYF+gCXjFGDMjFnkVRVG6klhtuKH+EpKAUVj7bWciPtyI9S52MPaR4GeAPwHHhxY0xtwN3B04F5FRwHLgz0HFbgCWGmOaHReSrwC34yhqETkKG5niR8AbgAB9PzSooigJSaw23END00QkE/gD8Hon+rsEuNN5cAIRuR4bJ63EGLM2St1LgUXBzs6NMYtCyviBMUHn9wCPG2PmBKV91gl5FUVRuoxdtuEaY+qAXwB3xFJeRPoDe2E9jAXa+AaowZoFOqqbgjVDPB4m7/ciUg+UAeNxfDuISAZ2R0WTiHwmIuUi8m8RmRSLvEHt54nIaBEZ7fV6O1NVURSlHbu7aJbMDleN0chyXreHpFcH5UXidKevF0IzHHtsJrAfViFvdLJysOO7GKusB2Ftxv8QkewYZQa4EmvKWL5169ZOVFMURWlPrItmp4UmYRXYFcAHMfZV67z2D0nPxs5yO+JS4HlnVr0TxhgDfC0ii4CXgUOD+nvWGPMlgIjcA1wHfAv4R4xyP4yj6AsLC5fHWEdRFGUnYl00mxMmbTvwNnBVLA0YY6pFZD1wILAIQESGY2e3X0aqJyLjgCOwM81oeLCLeRhjtovIWuzC3k7ixCKz004Fjs/fSZM6ZY1QFEVpR6wKNy3k3G+Mad2F/mYBN4jIfKwSuxd4K8qC2aXAf40xXwQnishYYCxW6Tdg7be3AfOCiv0e+KmIvAisAK7Bbg37aBdkVxRF2S1i3aXQHL1UTPwKa1v9FEgB/gWcByAi5wJPGGMyA4VFJA04H7g6TFsCXA88h40avAV4FbuQF+A+oB/wLnbf7+fA8caYUDuyoihKtyPW/BmlkMhtwGZjzJMh6RcDA4wxM7tJvoRi0qRJZsEC9beuKD2NiCw0xvQ6G1+suxR+SHg765fARV0njqIoSt8lVoU7EHvLHsoWQB3bKIqixECsCnczMDFM+kRAN6cqiqLEQKy7FF4AfisiddgFKICjgQeBF7tDMEVRlL5GrAr3F1gfBfOw/goMdnb8GvDz7hFNURSlbxHrtrAW4HQnPPqBTvJnxpjF3SaZoihKHyPWGS4AjoJVJasoirILxLRoJiKPi8hOj/CKyFUi8mjXi6UoitL3iHWXwveB98Kk/wfrUFxRFEWJQqwKN4+d3SqCda2Y33XiKIqi9F1iVbhrgaPCpH8b2NBVwiiKovRlYl00exK4X0SSsN65AI7FOqP5VXcIpiiK0teIdVvY/SJSBPwuqI4XeAT4TTfJpiiK0qeIeVuYMeZaEZmJDWUD8JUxprp7xFIURel7dCqmmTGm2hjzvnNUi8hxIjK7u4RTFEXpS3Q6iKSIDBSRm0XkG+yjvrldL5aiKErfI2aFKyLHi8irwHrgLuAPwGBjzLHdJZyiKEpfokOFKyKDReR2EVmHjUe2DBs7zA/MMcaE85GrKIqihCHaotk3wGzgR8DbTjhyRKS75VIURelzRDMplAGTnWNI94ujKIrSd4mmcIcBVwGTgFUi8o6I/B/WH66iKIrSCTpUuMYyzxhzKlACzAfuwJoiZorIySKS3O1SKoqi9AFi3qVgjNnshEMfARyPneXOIXxwybCIiFtEfiMi20SkVkTmikhY5zfO1rO6kMOIyO+CyrwlIptFpEZENojIAyKSEqYtl4h85NRX04iiKD1Cp/fhOrPet4wx04C9gHs7Uf1GrDvHg9lhE/5ThH7uNsZkBg5gAlbJ/zmo2A1AiTEmC2v2mAjcHqa5q4GGTsipKIrS5XQq4kMoxpgyOue85hLgTmPMagARuR5rGy4xxqyNUvdSYJEx5pOg/heFlPFjY6+1ISKjgRnANODzTsiqKIrSpXR6hruriEh/7Ix4YSDNGPMNUAPsH6VuCnAh8HiYvN+LSD12R8V44P6gPBfwDHAd1nfvrsidJyKjRWS01+vdlSYURVGAOCpcIMt5DXVkXh2UF4nTgWRsuPZ2GGNmAJlYpzqPAxuDsn8KlBljXt0VgR2uBJYDy7du3bobzSiKsqcTT4Vb67z2D0nPxs5yO+JS4HljTF24TMeu/DWwCHgZQERGAj8DrthliS0PY80UYwoLC3ezKUVR9mRiDSI5Pdz2LxFJEpHpsbThuHJcz44w64jIcOzs9ssO+h4HHEEYc0IYPMAo5/3hQAHwtYiUA5856V+KyIxYZHbkrjDGrDDGrPB4dsvkrSjKHk6sM9wXsTPRULKcvFiZBdwgIsNEJAu7w+GtKAtmlwL/NcZ8EZwoImNFZKqIZDrbviYAt2E9mAG8gt3CdoBznOCkfxf4YydkVhRF6RJiVbhC+KfL8oGwt/kR+BXwBvApsAlwA+cBiMi5ItKuLRFJA84n/OxWgOuxNtvtWJ8PfwV+DGCMaTDGbAwc2EU1sDbdzsisKIrSJYjjjyZ8psg/nLffwz5l1hKU7QbGYSM/nBBaty8yadIks2DBgp4WQ1H2eERkoTFmUk/L0VmiGSUrnFcBqoCmoLwW4D/EZltVFEXZ4+lQ4RpjzgcQkY3ATGNMfVykUhRF6YPEZMM1xtxkjKkXkXEicoqIpAOIiEfUOa6iKEpMxLotLEdE3gG+Bl4FBjpZTxD0ZJeiKIoSmVh3KdznvI6gvROYV7ALaoqiKEoUYt3JPwU4yRizJsSCsBLrH0FRFEWJQqwz3EiP3/YHfF0njqIoSt8lVoX7CTA16Dywefcy4MMulUhRFKWPEqtJ4RbgXyKyt1PnGhHZDzgI6+dAURRFiUKs28I+wjqDycQ+knsisA34ljHms47qKoqiKJaY3V8ZYz4HzupGWRRFUfo0nfY36ERuuAQoBF4zxqgNV1EUJQY6NCmIyMMi8njQeQrwX6zXrxnAeyJyTPeKqChKvGjxG36+tpwTvt7I53VN0SsonSKaDfdodviXBTgHGAyMxm4Jm42NF6YoSi+n1uvnwuVlPLelhq/qWzh76Wb+W9PY02L1KaIp3GJgSdD5FGCuMeYbY4wX+1jv+O4STlGU+LClxcsZS0t531Gw/dxCvd9w/vIy/l3dEKW2EivRFK5gQ48HmAR8HHS+FcjpaqEURYkf3zS2cOqSUhY3tOAC7i7J5+/7DmFwsocmv+GHK8qYV6mOAruCaAp3FfBtABEZAZRgfeAGKAbKu0UyRVG6nc9qmzh1SSkbmr2kiPDEqAGcPyAGczp3AAAgAElEQVSLYalJzB03iGGpSbQauGzlFv5SXhu9QaVDoincx4GHReQPwN+xscWWBeUfhY2UqyhKL+OfVfWcuWwzVV4//d0uXty7iCm5GW35g1M8zNm7iDFpSfiAn36zjRe2RguwrXREhwrXGDMLuAYb/fYjIDRC7zA0IKOi9Dqe31rDxSu20OQ3DE728Jd9BnFQv9SdyhUme5i99yD2y0jGADesKeepzdvjL3AfocOYZkp7NKaZ0tsxxvDApioe2lQNwLj0ZP4wZiADkzvekl/j9XPhijI+rbVbxa4dksNPBmXTU/EHemtMs1id1yiK0svxGsP1a8rblO1hWanM3ntQVGULkOVx8ecxAzkiKw2A+zZWce+GKnTC1jlU4SrKHkCDz89FK8p4aZtd+DolL4M/jikiyxO7Ckh3u3hmzACOy04H4NHN1dy2rgK/Kt2YiavCFRG3iPxGRLaJSK2IzBWR/AhlbxaRupDDiMjvgsq8JSKbRaRGRDaIyAPO03CB/HtFZLGTXyoiT4pIbjzGqiiJQkWrjzOXbubdarvH9pKB/fndiEKSXZ03B6S6XDwxagDfdxbXnttSw3VrtuFTpRsT8Z7h3gicAhwMDHHS/hSuoDHmbmNMZuAAJmD98P45qNgNQIkxJgu7R3gicHtQvg84D8jDPqAxBHi264ajKInNuqZWTl1SyqL6ZgBu2yuXnw/Nw7Ubttckl/DwyELOLOgHwCvb6rhy1VZa/ap0oxFrEMnpIpIcJj1JREJ3LnTEJcC9xpjVxpjtwPXAFBEpiaHupcAiY8wngQRjzCJjTHNQGT8wJij/ZmPM58aYVmPMNuAR7Fa2mBGRPBEZLSKjvV5vZ6oqSo/yZX0zUxeXsqaplWSBR0cWcnFRdpe07Rbh18Py+cGALADeqKznkpVbaPL7o9Tcs4l1hvsiNsxOKFlOXlQcL2N7AQsDacaYb7Che/aPUjcFuBC7Lzg07/ciUg+UYWexHUURPhb4MhZ5g7gSWA4s37p1ayerKkrP8O/qBs5YUkq510c/t/CnMUWcnJfZpX24RPjF0DwuH2RVw9vVDfxg+RYafKp0IxGrwhV2hNUJJh+oi7GNLOc1dBNfdVBeJE4HkoEXQjOMMTOwjtH3wyrkjeEaEJFpwMXAT2OUN8DD2FnzmMLCwk5WVZT4M2dbLT9YUUaD3zAgyc3ccYP4Vv+0bulLRLixOJfrh9gn/D+oaeS8ZZup8arSDUeH+0FE5B/OWwO8KCItQdluYByxxzQLPBfYPyQ9UoDKYC4FnjfGhFXuxu5N+VpEFgEvA4cG54vIGcATwMmdjVBhjKkAKgAmTep12/6UPQhjDI+WVnPvxioARqUm8aexRQxO6bTb605z5eAc0t0u7lhXwad1zZy1rJTnxxSRk+Tu9r57E9FmuAFlI0BV0HkFdib5OHB+LB0ZY6qB9cCBgTQRGY6d3Ua8zReRcdi4aTuZE8LgAUaF1P8BVtl+3xgzPxZZFaW34TOGW9dWtCnbgzJTmLvPoLgo2wAXDezPr4flI8BX9S2csbSUrS267hFMh9+GMeZ8ABHZCMw0xuyuy6BZwA0iMh+rtO8F3jLGrO2gzqVYHw5fBCeKyFhgLPA20IC1395GkP9eEfkJdtfC94wxn+6m7IqSkDT6/fx01VbmVVk3isfnpPPbkYWkueK/zf7swizSXC6u+mYryxtbmbaklJf2jq/iT2RiDSJ5U7CyFZFCEblIRA7tqF4YfgW8AXyKDUbpxm7bQkTOFZF2JgMRScPOoMPNbgW7y2Ej1i48G/gr8OOgMr/FzqDnB+/n7aTMipKwVHl9nLusrE3ZXjAgi8dGDegRZRtgan4mT4waQLLA2mYv05bYnRJKjL4UROTvwNvGmAdFJB3rlLwASAEuMMY8371iJgbqS0FJJDY1ezl/2WZWOsrshiE5XN6D/g1Cea+6gR+ttA5yCpPcvDC2iDHpO+0u3SX6ui+FScC7zvvvA63YhwmuAK7tBrkURemApQ3NnLJ4EyubWvEIPDC8gCsG5ySMsgX4dnY6fx4zkEyXsLXVxxlLS/mqvjl6xT5MrAq3P85KPXAcMMcY0wT8g5BFKkVRupePtjcybUkpW1p9pLuEZ0YP5Aznqa9E4+CsNF7cu4j+bhdVXj9nLd3Mgto9NzhlrAq3DNhPRFxYhfuek94faIlYS1GULuWvFXWcv3wztT5DvsfN7HGDONpxJpOoHJCZyuxxReR73NT4/Jy7bDMfbt8zg1PGqnD/iH3o4HPsYlXAvHAQsCxSJUVRuo4nN1dz+aqttBgoSfHw2j6D2D8jJXrFBGDv9BTmjCuiKNlNg99wwfIy3qna84JTxrpL4TasvfZF4AhjTGBW6wIe6CbZFEUB/MZw57oK7lxfCcD4jBRe22cwQ1OTeliyzjEiLZm54waxV4qHZmP40coy/laxZ20ainlzXLidCMaYp7pWHEWBFr+hwuujstVHhddHRaufCud9ZauPSq+PTLeL4hQPxSlJDEnxUJziYWCyB08CLRp1Bc1+w89Wb+X1Crsr85jsNB4bOYB0d+90ZV2cksSccYM4Z+lmVjW1cvmqrTT6TcLaoLuamBWuiByJneWOxD4iu1FELgRWG2P+02FlZY+m2W+ClGfwq5/KVh/ljhKtaPVR6fVTs4vOT9zAIEf5DknxUJy8QxkXpyQxINmNOwEVsjGGWp+hvNXLNufz2eZ8Lh9sb2RBnV3ZP7OgH78alt/r/1SKkj3MGTeIc5dtZnFDC9es3kaD388FA0Kf+u97xKRwReRk4BXgJaz/hMBmugysj1tVuHsg9T4/C2qbKG+bffqp8IYqUB+1vt3zk9rf7SI3yU2+x77meNzU+vxsaPaysbmVSsdRig/Y0OxlQ3P4x0k9AoOSPTvNjIekJFGc4mFAknu3/MQG4zeGKq+/TXEGH9u8XipaA3n2fXOU/fBXDc7mmgTb9rU75CW5eWnvIi5YXsZndc3curaCRr/hx13kPjJRiXWGextwuTHmacfrVoCPgFu7XiwlkfEaw0tba7lvYyUVu+AVKtvjIs/jJjfJTZ7HRV6SmzyPm7wkN7keN3lJLvKd97keN0lRIhPU+fxsdJTvxmYv64Peb2jxUu3I6DWw3smHnbcmJbcp5J2V8ZAUDzkeN5XeMAq01f65bGv1Ue7kV7T62FV/WSkiFCS5yXeOU/Mzu9y1YiKQ7XHz/Ngifri8jI9rm/jl+koafH6u7kN/LKHEqnD3xvosCKUayOk6cZRE59/VDdy1voIVjfbpJiGCAnWUqJ2Z7sjLiUGBdpZMt4ux6cmMjfAUU43Xz6aWVmdG7GW9o4wDx3bHhNFi7KOoayPMkHeHLLf9XPKT3BR4dijT0KMgyU2GS/qswgkl0+3iD2MHcumKLczf3shTZds5uyCLoj7qeyHWUVVgnYevC0mfBGzoUomUhGRZQwsz11fwXtD+yal5mdxQnMOQlMReLc/yuMjypLB3evgtVNu9PjsbdhTwhmZHObd42dDUSl2Y0DEC5Dp/LsGz0XxPQHF6yEtytb2m9qBvg0QnzeXiqdEDuWHNNs4t7LvKFmJXuC8CvxGR07G+cT0icjRwH/Bkdwmn9DzbWr08sLGKF7bWtt0iT8pM4baheUzITO1R2bqK/h43/T1u9gmzp9UYQ7Vjsqj2+shzFGpukrvXL14lEsku4cERfd/Bf6wK9+fY4I3rnfMl2D/5l4F7ukEupYdp8vt5uqyGRzZVtc3w9krxcFNxLifmZuwxt7wiQo7HLtQpyu4Sk8J1HnSYLiJ7YyPjuoCFxpjF3Slcb+RfVfVsavZycl4mub3Q270xhtcr6rl3QyUbHefR/dzCTwbn8IMB/UnpYvurouxJRAuxsxo4yAkzgzFmKbA0HoL1Vh7fvJ1Papv4xfoKjuqfzrT8TL6Tk94rbHgLapu4c10FnzsendzAeQOyuHpwDnm98M9DURKNaDPcEuzvTokBrzEMSfbwlUto9Bverm7g7eoGstwuTszN4LT8TCb3S+2yvZ5dxfqmVu7ZUMnfKncE9Dg2O51b9splVFrX+C9VFCWKA3IR8QMDjTEaH5zYHZDX+/zMq6zn1fI6PqhpbBfueEiyh1PzM5mWn8mIHlZmNV4/j5RW8XTZdlocIcemJfPzobkc2T+xPVApeza91QF5LAr3AKC8o0aMMaVdLFdCsisRHza3eHm9oo5Xy+tY2tDek+X+GSlMcza158fxlt1rDM9vreGBjVVtT2kVJLm5bkgO0wv6JeTjr4oSTF9WuB09cyjYKOV7hNlhd0PsLG1oZm55HX8pr2Nrq68t3Q0clZ3OafmZHJeT3m3xqIwxzN/eyMx1FW1hWVJEuLSoP5cNyiazlzpEUfY8+rLCnQZUdtSIMea9jvL7Cl0V08xnDB/WNPJqeR3zKutpCNpY388tnJBrTQ4Hd6G9d2lDC3etq+D9mh0PLpyWl8kNxbkM6sMbzZW+SV9WuGrDdeiOIJINPj9vVdUzt7yO97c3tnv+fnCyh6n5mZyWl8noXQy+t7XFy/0bq3hp244HFyb3S+Xne+VyQB95cEHZ8+itCjfaPeTuuXkKQUTcIvIbEdkmIrUiMldE8iOUvTk4tLlzGBH5XVCZt0Rks4jUiMgGEXlARFJ2pb+eIt3t4tT8fvx5bBGfTNiLn++Vyz6Oct3U4uXR0mqO/WojJ3y1kac2b2dba2zP+Tf6/fxuUxVHfrGBFxxlu1eKh1mjBjBn7yJVtorSA8R1hisitwAXAFOw/hmeAdKNMcfHUHcUsBw4xBjziZN2ALDUGNMsIgOwLiQ/NMbcvLv9hSOeYdKXNbTwanktfymvoyzE3ntk/zROy+/H93LSSQuxu/qN4fWKOn61oZLSFlsvy+3ip4OzuUAfXFD6CL11htuhwu3yzkTWAXcaY552zkcAq4Bhxpi1UereBxxjjDkwQv4ArL/eSmPMtN3tLxzxVLgBfMbwcU0Tr5bX8o/KeuqD7L2ZLuH43AxOy+/HoVmpLKxr5s51FXzhPLjgETi/MIurBuf0yqfeFCUSvVXhxm21RET6Yz2OLQykGWO+EZEaYH9gbQd1U4ALgZvD5P0eO4tNB6qAk3a3v5D284A8gPHjx8dSpUtxi3B4/zQO75/GL0v8vFXVwKvltfxneyN1fsPs8jpml9eR63G1bfECOM55cKGn9/oqirKDeC5PZzmv20PSq4PyInE6NsrEC6EZxpgZInI5sA9wDrCxC/oL5krgdoCtW3t27TDN7WJqfiZT8zPZ1url9fJ6Xi2v5auGljZlu096Mj/fK4/D+qf1qKyKouxMPBVurfMaGrgoG6iJUvdS4HljTNgQn8baRb4WkUVYD2aH7mZ/wTyMo+gLCwuXd6Jet1KQ5OFHRf35UVF/VjS08E51A4NSPJyUm6EPLihKghI3hWuMqRaR9cCBwCIAERmOnW1+GameiIwDjsDONKPhAUbtTn9h5K7ALrgxaVJimoxGpyfv8rYxRVHiR7wfLZoF3CAiw0QkC7gXeCvKAtalwH+NMV8EJ4rIWBGZKiKZIuISkQnY2GvzdrM/RVGUbiHeCvdXwBvAp8AmHA+AACJyroi0MxmISBpwPvB4mLYEuB5rs90OzAb+Cvw4lv4URVHiTVy3hfV2emJbmKIoO9Nbt4WptxJFUZQ4oTPcTiAi29g5cnGi4AYGAFsAX5SyiYqOITHoDWMYaowp6GkhOosq3D6CiIzGPvo8xhizoqfl2RV0DIlBXxhDoqImBUVRlDihCldRFCVOqMLtO1QAv3Beeys6hsSgL4whIVEbrqIoSpzQGa6iKEqcUIWrKIoSJ1ThKoqixAlVuIqiKHFCFa6iKEqcUIWrKIoSJ1ThKoqixAlVuIqiKHFCFW6CIyKLRaQu6GgUESMiB4rIUc774PyPQuqPFJG3RaReRDaKyM/iIPNZIvK+iNSIiDdM/hRnXI0i8rWIfLczMotIuog8IyJVIlItIk87zurjMgYROUFE3hWRckeG90XkiJAyRkQaQr6b/kH5PT2G3b524jGGPocxRo9edAC/BBY7748CvB2UdQNLsYEw07Hx3bYCZ3azjN8DzgZ+GCofMBxowEbeSAbOBeqBklhlBp4EPsK6ECx03j8WxzGcC5yKDUjqAS4D6oDioDIGOLyD9nt6DLt97cRjDH3t6HEB9OjEl2V/3JuBnzjn0X40RzvKLTMo7S5gfpzk3Uk+7DP674ekvQ/cHovMQBrQCBwblH+sUyc1HmOIUG4bcGrQeUSFmwhj2N1rJ95j6CuHmhR6F1OxYd//GJTmFpENIlImIn8XkfFBeeOBFaZ9ePnPnPSeYjywMCQtWKZoMo8BUkPa+AyrAEZ3ubQxICL7A3nA1yFZsx2zw/9E5LSg9EQZw+5cO4kyhl6FKtzexaXAy8aYaud8GXAAMAwYiw3//q6IDHLy+2EDbAZTjQ0V31NEkymWfELKBN7HfVwiUgjMAX5tjFkZlPUd7PcyBHgAeF5Epjh5iTCG3b12EmEMvQ5VuL0EERmBvWVri2BsjCkzxnxhjPEaY6qNMTcBlcDxTpFa7Iw4mGygJh4yRyCaTLHkE1Im8D6u43KU03zgn8BNwXnGmHeMMU3O8TLwZ6ztFxJgDF1w7fT4GHojqnB7D5cCXxhj/helnB8bQh7gC2C0iGQE5U9w0nuKL7ALMMEEyxRN5uVAU0gbE7D2xLiFgxGREqzteZ4x5grjGDE7IPh7SYgxhKEz106ijiGx6Wkjsh7RD+xq/lbg0pD0Y4CR2D/OTOAO7G1fsZMfWGn+Lda2dgA2MOBZ3SyvG2vf+y7gdd6nYn/MI7ALK2cDSc5ruF0KEWXGro5/gF0ZL3TePx7HMYwFNgIzI9TdF5jsfG9JWNt7A3ByAo1ht6+deIyhrx09LoAeMXxJcBb2Fi4zJP1qbBThekchvwkcFFJmJPCO84MvBa6Ng7wXYlfpQ48SJ38KsBg7G1oMfLczMmO3KT3jKIhq4GkgLV5jAJ513teFHOc6dY92xlUPVAELCPmTS4Ax7Pa1E48x9LVDIz4oiqLECbXhKoqixAlVuIqiKHFCFa6iKEqcUIWrKIoSJ1ThKoqixAlVuIqiKHFCFa7S5xCRO0RkVU/LoSihqMJVei0icrjjRLskJOs+4JA4ybBKRO6IR19K78fT0wIoSldjrEvBuqgFEwgRSTHGNPe0HEr3ojNcZbcQkX87oVVuF5EtIlIpIs+GOD3pqP4Ux19so4isF5HfBtcVkW+LyEciUuscX4jId4KcxwCscWa6/3bqtDMpBM5FZLrz2iAir4lIloicISIrnLbnhoTBOVBE5onIVicEzQIROSF47FjfELc7/bfNtkXkMBH5UESaHJ+4T4lIVlDd55zwNT8VkXVAo4h4Io23k1+LkqCowlW6gtOxrvu+jXVBeBoQNXaao0jmYn0T7If1GXE48JST7wFeAz4FJmI9U92B9cGwATjFaWoyUOT0G4ki4AKnzPHAYVg/thcB04PSbg6qkwW8hI2OcCDW38DrIjLWyT8NWAvc77RfBGwQkSLgLeAbR+6zsM5ingqR6WDsZ3Yy1jmMdDBepS/Q084c9OjdB/BvrNvI4LSnCAmjE6Hue8DdIWmHYh2sFAA5zvsjI9Q/nCCnOEHpdwCrQs69QH5Q2qOADygMSrsfWBBF5i+AW4LOVwF3hJSZCawHkoLSpjiyjnDOn8M6fAkOYdPhePXo/YfOcJWuYFHI+SZsYMFoTAKuCY4cC7zt5I00xlRhlfc/ReQfInKdiOxq+JZNxpjyoPMyoMwYszUkrTBwIiJ5IvKwiCxzotLWAfsAQ6P0NQ74nzGmNSjtg6C8AEtMUAibLh6vkoCowlW6gtaQc0Ns15YLuBd7Ox04xgOjcJS4MeZirGL+J9bt4dcicnEXyRhN7j84fV4PHOHItwjr5zYasbjha9ipUteNV0lAVOEqPclCYJwxZlWYo81uaYz52hjzkDHmBKz/1R87WS3Oq7ub5Ps28Kgx5q/GmK+wEZOHh5RpCdP/EuBgEQlOPywor0M6GK/Sy1GFq/QktwOnisivRWR/ERklIt8XkVkAIjLMyTtcRIaKyKHYmeZSp/46bFiYKSJSGLzDoItYDpwrIvuJyAHYBbTQrZSrgUNFpFhE8kXEhbUP5wGzRGSciBzjpM02xnwTqbMYxqv0clThKj2GMeYdbHTbycDHwOfAL7EzSbC33COwim4FdkfDR8AVTv0t2Nv9m506r3exiD/A/kY+cdr+p/M+mNuwOzRWANuAvYwxm4HvYUPxfAbMxi4u/ihKfx2OV+n9aMQHRVGUOKEzXEVRlDihClfpNoK3e4U5zu1p+RQl3qgvBaU7OaCDvC1xk0JREgS14SqKosQJNSkoiqLECVW4iqIocUIVrqIoSpxQhasoihInVOEqiqLECd0W1o0sXLjQBQzEOrJWlJ5g28SJEyt6WgjFotvCuokvv/wyNzs7+4ns7OxhHo8ntaflUfZMmpqa6rdt23bPmDFjXutpWRRVuN3CwoULXQUFBS8XFxcPE5GeFkfZwykrK9u2adOmqRMnTtQglT2M2nC7h4HZ2dmqbJWEICMjYwDWtKX0MKpwu4csNSMoiYLb7U4G0npaDkUVrqIoStxQhasoihInVOEqCcEFF1xQnJOTMz49PX3Cpk2bdLui0idRhaswefLkMSIy8amnnsoJTn/33XczRGTi4MGD9+vO/v/1r39lvPLKK/mLFy9e3NDQ8PngwYO9u9vm4MGD9/v973+f2xXydSWbNm3yfPe73x2RkZExIScnZ/xll1022OfzRSx/++23Dxg3btze/fr1OyAvL2/8CSecMHzlypWxRA1WEhBVuAoAw4cPb3rmmWfyg9OeeOKJ/OHDhzd1d98rV65MKSgoaB00aNBuK9qupLm5ucu3mZxxxhnDANavX//lhx9+uHTevHk5t912W8QdBC0tLfLQQw+t37JlyxerVq36Kj093X/iiSeO7Gq5lPigCjcO+H0+adxekxLPw+/zdUpZnHjiiVVLly5NX7JkSTJAVVWVa968eTnnnHNOeaDMrFmzcsaMGTMuMzNzQkFBwf7nnHPO0JqaGhfA2rVrk/Ly8sYHzyqnT58+9OCDDx7t9UbWo7feeuuAq6++umTjxo0p6enpEw455JDRAGVlZe7p06cPHThw4P45OTnjTzjhhOEbNmxoMzXcddddhcOGDdsnIyNjQlFR0X6XX3754EA/xxxzzMjNmzcnX3311SXp6ekTDjvssFFgZ/LXX399UXD/IjLxrbfeygS45pprBh1yyCGjL7nkkiF5eXnjjzvuuJEAK1euTJ4yZcrwgoKC/QsKCvY/++yzh1ZVVXX6t7Ns2bLkjz/+OOvBBx/cmJeX5xs3blzLT3/607LnnnuuIFKde+65p+y73/1ufXp6usnJyfHfeOONZStXrkzbtm1bd4WGV7oRtZXFgea6+uQl8/61bzz7HHf8cV+n9c+KeaN7amqqmTp1auVjjz1W8PDDD296+umncydPnlxbVFTUGiiTnZ3te/7551dPmDChaenSpSmnnHLKyJtuuqno0Ucf3VRSUtL69NNPrz7vvPNGHnLIIQ0fffRRxrvvvpv92WefLfZ4Il9mM2fO3FJYWOi97777itavX/81gN/v58QTTxw5cuTIpsWLFy9OTk42F110UfH06dOHf/zxxysAiouLW+bNm7dy9OjRLR9//HHaySefPLqkpKT5uuuuK3/33XdXDR48eL9bbrll04wZMyo787ktWLCg3/e+973tmzZt+rK1tVUaGhrk2GOPHX3aaadVzpkzZ01jY6Pr9NNPH3bJJZfsNXv27LUARx999MgFCxZkRmrzN7/5zfof//jHlZ9++ml6Zmamb5999mn7XiZPnlxfWlqaXFlZ6crNzfVHk+/NN9/MGjBgQGtBQUFkO4SSsKjCVdqYMWPGthNPPHH0Aw88sOm5554ruPXWW0srKyvbZlLTp0+vCbzfd999my+66KKtL774Yj6wCWDq1Km1l1xyyZbTTjttZHl5edILL7ywaq+99uq0meCDDz5IX7JkSfoHH3ywIi0tzQD87ne/21hUVHTAN998kzRixIjWCy+8sDpQ/rDDDmucNm1axfz587Ouu+668sgtR2fgwIEtv/jFL7aA/RN69tlnc4wxPPTQQ6UAmZmZvpkzZ5Yee+yxY71e71qPx8P8+fNXxdJ2TU2Nq1+/fu0UZV5eng+gqqrKHU3h/utf/8q45557Bj/99NOrd210Sk+jCjcOpGRmtIw7/riv491nZ+scdNBBTYMGDWq5/vrrB5WXlyedfvrp22fNmtVmIvjLX/6SNXPmzKLVq1entra2unw+H7m5ue0U6lVXXbX1kUceGTh+/Pj6k08+uXZXZF+1alVKS0uLq7CwcHy7MaWkmNWrVyePGDGi9Yknnsh9+OGHB2zcuDHF5/PR2trqGj9+fN2u9BfMkCFD2t0VrF69Onnz5s3J/fr1axefTUTYsGFD0rBhw1qJkaysLH9tbW07U0BFRYUbIDs7u0Nl++abb2aeeeaZIx944IF1Z5111vZY+1QSC1W4ccDldpvO3N73JD/4wQ+2XX311SVXXXXV5mBTQFNTk5xzzjkjbrvtto1XXnlleWZmprn77rsLHn300bYFH5/PxznnnDPs6KOP3v75559nPPTQQ3lXXXVVpz1VDRs2rDktLc1fXV29yO3e2VS5atWqpBkzZgz7wx/+8M3pp5++PTU11VxyySVDFi1alBEoE+6x6oyMDF99fX2b7XXt2rVJoWVcrvam2aFDh7aUlJQ0r1q1anEkeY888shRHZkU7r///nWXXXZZ5UEHHdRQV1fnXrJkSfK4ceNaAD799NP0QYMGtQRmuuGYO3du1oUXXjj8kUceWXvBBRdURyqnJD66aKa04+KLL6589dVXV9x0003touo2NzdLS8F3w2EAAAYgSURBVEuLKycnx5eZmWkWLlyY+uSTTxYGl7nhhhuKNm/enDx79uw1zzzzzJpbb711r08//bTTjzgfeeSRDWPHjm344Q9/WFxWVuYGKC0t9cyaNSsHoKamxu33+xkwYEBrcnKyeeeddzLmzp2bF9xGQUFB68qVK9v1PWHChIY333wzu7S01FNVVeW69tprB0eT5cwzz9zu9XrlxhtvHFhVVeXy+/2sWbMm6Y9//GN2oMx//vOflQ0NDZ9HOi677LJKgLFjx7YceuihNddcc82QyspK17Jly5IfeuihogsuuGBbpP6fe+657AsuuGDErFmz1qiy7f2owlXakZ6ebqZOnVobuijTv39//7333rvu9ttvH5Kenj5hxowZe02bNq1tQeqNN97o9/jjjw98+eWXv8nKyvKfdNJJtTNmzCg788wzRwR2MsSK2+3m73//+yq/3y8TJ04cl5GRMWHy5Ml7//vf/+4HcOCBBzb97Gc/K50+ffrI/v37H3DPPfcMPOWUU9otjt14442b58yZk5uVlXXAkUceOQrglltu2TJixIim0aNH77f//vuPO/HEE6Pemvfr18//9ttvL1+6dGnamDFj9s3KyppwzDHHjP7888/TOzOmALNnz17j9/uluLh4/KGHHrr3lClTqu+6666yQP4555yzV0BeR+bipqYm10UXXTQ8PT19QuDQvbi9E3XP2A0sXLhw7N577z0nPT292/ewKko0GhoaUpcuXXr6xIkTl/W0LHs6OsNVFEWJE6pwlW7nscceyw2+HQ4+HnvssYR7/FZRugvdpaB0O5dddlllYOFIUfZkdIarKIoSJ1ThKoqixAlVuIqiKHFCFa6iKEqcUIWrKIoSJ1ThKgmBhthR9gRU4SoaYqcXM23atJIzzzxzaE/LocSGKlwF0BA74eiOEDtdhdfrpaNYaEpiogo3DrT4jaxoaEmJ59HiNxpiJ8FC7DQ1NcnZZ589NDc3d3xmZuaEkpKSfZ999tm2u4qHHnoor7i4eN/MzMwJU6dOHXbKKacMmzZtWgnA8uXLk0Vk4oMPPpg/YsSIfdLT0w+84YYbil5//fXcuXPn5gWe3Ovos1Z6HrWVxYG1Ta3Jx361Ma4hdt7Zb8jXo9OTNcROAoXYeeSRR/IWLVqUsWTJkq8HDhzoW7VqVdL27dvdYB2M33jjjUNffPHFVSeddFLNE088kXfVVVcNDfWC9sorr+TOnz9/eWFhoc/j8Zg1a9akeDwe8/LLL6/rzDiVnkEVrtKGhtjp3hA7ycnJpqGhwbVo0aK0Y489tm7kyJGtQCvAc889lzdlypSqU089tQbgiiuuqHjmmWd2Ci552223le7KZ6okBqpw40BJalLLO/sNiWuInZLUJA2xswt0Z4idyy67rGLLli1J1157bfG6detSDj300NoHHnhg47777ttcWlqaPGHChPrg8sXFxTvdoYwc+f/t3b+q2mAcxvGfaTxCQ9q8Z1GX9gQKjrV4FeIFuAbcch+xdyAUr0GoTjq76pKtU5tm0HJSjpSqeIzHDl1qoRyk5k/p97NlML4QeHj95ZXn1dnPFflB4KbgSiscz/l5nyUqdpKr2CkWi+J53tLzvGUURU86nc4Lx3FuZrPZh2q1eh8EQenXz4VhWLJt++SlpaZpx9+u//S1yCGeFk5QsXPqkhU7o9HInE6nT3e7XcEwjAfDMB50XT+KiDiO83U8HqvhcGju93vp9XrXvu8/2ipRLpf3QRCUOLHwbyBwcYKKnVOXrNhZLBZFx3FspVS9Uqm8DsPwqt/vByIizWbze7fb/ey67o1S6s1kMnnearXuHrun67q3m81GU0rVTdOsc0oh36jYSQAVO7iEdrv9Mo7jwmAw+PQ396FiJz/Y4QJASghcJI6KHeAnRgoJYKSAPGGkkB/scAEgJQRuMr7FcczuFrlwOBzuRWSb9TpA4CZluVqtPjKuQR6s1+svIrLMeh1ghpsY3/evLct6Z1mWrev62Yf/gUvYbrfrKIre1mq191mvBQRuoubzuSYiFRF5lvVa8N+6bTQaZ/+9GskgcAEgJcxwASAlBC4ApITABYCUELgAkBICFwBS8gNFZjaaBQkmIAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#testLGM(trainx,trainy,testx,testy, nleaves, mininleave):\n",
    "\n",
    "def r():\n",
    "    return np.random.rand()\n",
    "\n",
    "#Now plot            \n",
    "fig = plt.figure(figsize = (5, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for s in max_features_values:\n",
    "    plt.plot(n_estimators_values, res[s], \n",
    "             color=(r(),r(),r()), label='Max_feature={}'.format(s))\n",
    "\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(loc='best', bbox_to_anchor=(0.8, -0.3))\n",
    "#plt.legend(loc=4, ncol=3, mode=\"expand\")\n",
    "ax.set_xlabel('n_estimators')\n",
    "ax.set_ylabel('Test Set Accuracy')\n",
    "plt.title('Holdout Accuracy by Hyperparameters')\n",
    "\n",
    "#n_estimator made to 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Holdout Accuracy by Hyperparameters')"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py:2267: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def r():\n",
    "    return np.random.rand()\n",
    "\n",
    "#Now plot            \n",
    "fig = plt.figure(figsize = (5, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for s in min_data_in_leave_values:\n",
    "    plt.plot(leavenumber_values, res2[s], \n",
    "             color=(r(),r(),r()), label='min_data_in_leaves={}'.format(s))\n",
    "\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(loc='center left', bbox_to_anchor=(0, -0.8))\n",
    "#plt.legend(loc=4, ncol=3, mode=\"expand\")\n",
    "ax.set_xlabel('num_of_leave')\n",
    "ax.set_ylabel('Test Set Accuracy')\n",
    "plt.title('Holdout Accuracy by Hyperparameters')\n",
    "\n",
    "#n_estimator made to 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Validation\n",
    "def xValRF(dataset, lab, k, nes, maxf):\n",
    "    '''\n",
    "    Perform k-fold cross validation on RF and return the mean and std for this para setting\n",
    "    '''\n",
    "    n_samp = dataset.shape[0]\n",
    "    cv = KFold(n = n_samp, n_folds = k)\n",
    "    aucs = []\n",
    "\n",
    "    for train_index, test_index in cv:\n",
    "        tr_k = dataset.iloc[train_index]\n",
    "        va_k = dataset.iloc[test_index]\n",
    "        \n",
    "        met = testRF(tr_k.drop(lab,1),tr_k[lab],va_k.drop(lab,1),va_k[lab],nes,maxf)\n",
    "        aucs.append(met)\n",
    "        \n",
    "    \n",
    "    return (np.mean(aucs),np.sqrt(np.array(aucs).var()/k))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([X_Train,Y_Train],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features_values = [0.2,'sqrt']\n",
    "n_estimators_values = [600,750,900,1050,1200,1350,1500,1650]\n",
    "k = 5\n",
    "\n",
    "res3mean = dict()\n",
    "for s in max_features_values:\n",
    "    res3mean[s] = list()\n",
    "    \n",
    "res3std = dict()\n",
    "for s in max_features_values:\n",
    "    res3std[s] = list()\n",
    "\n",
    "#Now train and get results for each option\n",
    "for s in max_features_values:\n",
    "    for l in n_estimators_values:\n",
    "        (a,b) = xValRF(dataset, 'Target', k, l, s)\n",
    "        res3mean[s].append(a)\n",
    "        res3std[s].append(b)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xValLGM(dataset, lab, k, nl, ml):\n",
    "    '''\n",
    "    Perform k-fold cross validation on LGM and return the mean and std for this para setting\n",
    "    '''\n",
    "    n_samp = dataset.shape[0]\n",
    "    cv = KFold(n = n_samp, n_folds = k)\n",
    "    aucs = []\n",
    "\n",
    "    for train_index, test_index in cv:\n",
    "        tr_k = dataset.iloc[train_index]\n",
    "        va_k = dataset.iloc[test_index]\n",
    "        \n",
    "        met = testLGM(tr_k.drop(lab,1),tr_k[lab],va_k.drop(lab,1),va_k[lab],nl,ml)\n",
    "        aucs.append(met)\n",
    "        \n",
    "    \n",
    "    return (np.mean(aucs),np.sqrt(np.array(aucs).var()/k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614504\n",
      "[2]\ttraining's binary_logloss: 0.613479\n",
      "[3]\ttraining's binary_logloss: 0.612496\n",
      "[4]\ttraining's binary_logloss: 0.611552\n",
      "[5]\ttraining's binary_logloss: 0.610649\n",
      "[6]\ttraining's binary_logloss: 0.609737\n",
      "[7]\ttraining's binary_logloss: 0.608836\n",
      "[8]\ttraining's binary_logloss: 0.60809\n",
      "[9]\ttraining's binary_logloss: 0.607273\n",
      "[10]\ttraining's binary_logloss: 0.606471\n",
      "[11]\ttraining's binary_logloss: 0.605716\n",
      "[12]\ttraining's binary_logloss: 0.604997\n",
      "[13]\ttraining's binary_logloss: 0.604393\n",
      "[14]\ttraining's binary_logloss: 0.603696\n",
      "[15]\ttraining's binary_logloss: 0.603059\n",
      "[16]\ttraining's binary_logloss: 0.602578\n",
      "[17]\ttraining's binary_logloss: 0.602042\n",
      "[18]\ttraining's binary_logloss: 0.601557\n",
      "[19]\ttraining's binary_logloss: 0.600984\n",
      "[20]\ttraining's binary_logloss: 0.60057\n",
      "[21]\ttraining's binary_logloss: 0.600073\n",
      "[22]\ttraining's binary_logloss: 0.599521\n",
      "[23]\ttraining's binary_logloss: 0.598996\n",
      "[24]\ttraining's binary_logloss: 0.598485\n",
      "[25]\ttraining's binary_logloss: 0.597996\n",
      "[26]\ttraining's binary_logloss: 0.597598\n",
      "[27]\ttraining's binary_logloss: 0.597176\n",
      "[28]\ttraining's binary_logloss: 0.596831\n",
      "[29]\ttraining's binary_logloss: 0.596492\n",
      "[30]\ttraining's binary_logloss: 0.59617\n",
      "[31]\ttraining's binary_logloss: 0.595831\n",
      "[32]\ttraining's binary_logloss: 0.595514\n",
      "[33]\ttraining's binary_logloss: 0.595107\n",
      "[34]\ttraining's binary_logloss: 0.59477\n",
      "[35]\ttraining's binary_logloss: 0.594491\n",
      "[36]\ttraining's binary_logloss: 0.594213\n",
      "[37]\ttraining's binary_logloss: 0.593878\n",
      "[38]\ttraining's binary_logloss: 0.59365\n",
      "[39]\ttraining's binary_logloss: 0.593358\n",
      "[40]\ttraining's binary_logloss: 0.593087\n",
      "[41]\ttraining's binary_logloss: 0.59287\n",
      "[42]\ttraining's binary_logloss: 0.592641\n",
      "[43]\ttraining's binary_logloss: 0.592426\n",
      "[44]\ttraining's binary_logloss: 0.592166\n",
      "[45]\ttraining's binary_logloss: 0.592003\n",
      "[46]\ttraining's binary_logloss: 0.591834\n",
      "[47]\ttraining's binary_logloss: 0.591687\n",
      "[48]\ttraining's binary_logloss: 0.591472\n",
      "[49]\ttraining's binary_logloss: 0.591355\n",
      "[50]\ttraining's binary_logloss: 0.591173\n",
      "[51]\ttraining's binary_logloss: 0.591019\n",
      "[52]\ttraining's binary_logloss: 0.590915\n",
      "[53]\ttraining's binary_logloss: 0.590797\n",
      "[54]\ttraining's binary_logloss: 0.590651\n",
      "[55]\ttraining's binary_logloss: 0.590525\n",
      "[56]\ttraining's binary_logloss: 0.590482\n",
      "[57]\ttraining's binary_logloss: 0.590381\n",
      "[58]\ttraining's binary_logloss: 0.590285\n",
      "[59]\ttraining's binary_logloss: 0.590229\n",
      "[60]\ttraining's binary_logloss: 0.590177\n",
      "[61]\ttraining's binary_logloss: 0.590173\n",
      "[62]\ttraining's binary_logloss: 0.590052\n",
      "[63]\ttraining's binary_logloss: 0.589941\n",
      "[64]\ttraining's binary_logloss: 0.58989\n",
      "[65]\ttraining's binary_logloss: 0.589824\n",
      "[66]\ttraining's binary_logloss: 0.589764\n",
      "[67]\ttraining's binary_logloss: 0.589747\n",
      "[68]\ttraining's binary_logloss: 0.589704\n",
      "[69]\ttraining's binary_logloss: 0.589666\n",
      "[70]\ttraining's binary_logloss: 0.589665\n",
      "[71]\ttraining's binary_logloss: 0.589615\n",
      "[72]\ttraining's binary_logloss: 0.589572\n",
      "[73]\ttraining's binary_logloss: 0.589536\n",
      "[74]\ttraining's binary_logloss: 0.589508\n",
      "[75]\ttraining's binary_logloss: 0.589544\n",
      "[76]\ttraining's binary_logloss: 0.589466\n",
      "[77]\ttraining's binary_logloss: 0.589404\n",
      "[78]\ttraining's binary_logloss: 0.589349\n",
      "[79]\ttraining's binary_logloss: 0.589392\n",
      "[80]\ttraining's binary_logloss: 0.589373\n",
      "[81]\ttraining's binary_logloss: 0.589358\n",
      "[82]\ttraining's binary_logloss: 0.589301\n",
      "[83]\ttraining's binary_logloss: 0.589319\n",
      "[84]\ttraining's binary_logloss: 0.589285\n",
      "[85]\ttraining's binary_logloss: 0.58926\n",
      "[86]\ttraining's binary_logloss: 0.589238\n",
      "[87]\ttraining's binary_logloss: 0.589221\n",
      "[88]\ttraining's binary_logloss: 0.58921\n",
      "[89]\ttraining's binary_logloss: 0.589231\n",
      "[90]\ttraining's binary_logloss: 0.589265\n",
      "[91]\ttraining's binary_logloss: 0.589277\n",
      "[92]\ttraining's binary_logloss: 0.589293\n",
      "[93]\ttraining's binary_logloss: 0.589303\n",
      "[94]\ttraining's binary_logloss: 0.589321\n",
      "[95]\ttraining's binary_logloss: 0.589341\n",
      "[96]\ttraining's binary_logloss: 0.589317\n",
      "[97]\ttraining's binary_logloss: 0.589364\n",
      "[98]\ttraining's binary_logloss: 0.589406\n",
      "[99]\ttraining's binary_logloss: 0.589393\n",
      "[100]\ttraining's binary_logloss: 0.589383\n",
      "[101]\ttraining's binary_logloss: 0.589423\n",
      "[102]\ttraining's binary_logloss: 0.589463\n",
      "[103]\ttraining's binary_logloss: 0.589505\n",
      "[104]\ttraining's binary_logloss: 0.589551\n",
      "[105]\ttraining's binary_logloss: 0.589604\n",
      "[106]\ttraining's binary_logloss: 0.589614\n",
      "[107]\ttraining's binary_logloss: 0.589613\n",
      "[108]\ttraining's binary_logloss: 0.589615\n",
      "[109]\ttraining's binary_logloss: 0.589621\n",
      "[110]\ttraining's binary_logloss: 0.589634\n",
      "[111]\ttraining's binary_logloss: 0.589628\n",
      "[112]\ttraining's binary_logloss: 0.589619\n",
      "[113]\ttraining's binary_logloss: 0.58962\n",
      "[114]\ttraining's binary_logloss: 0.589652\n",
      "[115]\ttraining's binary_logloss: 0.589658\n",
      "[116]\ttraining's binary_logloss: 0.589714\n",
      "[117]\ttraining's binary_logloss: 0.589767\n",
      "[118]\ttraining's binary_logloss: 0.589825\n",
      "[119]\ttraining's binary_logloss: 0.589886\n",
      "[120]\ttraining's binary_logloss: 0.589947\n",
      "[121]\ttraining's binary_logloss: 0.590012\n",
      "[122]\ttraining's binary_logloss: 0.590065\n",
      "[123]\ttraining's binary_logloss: 0.590122\n",
      "[124]\ttraining's binary_logloss: 0.590182\n",
      "[125]\ttraining's binary_logloss: 0.590234\n",
      "[126]\ttraining's binary_logloss: 0.590279\n",
      "[127]\ttraining's binary_logloss: 0.590326\n",
      "[128]\ttraining's binary_logloss: 0.590377\n",
      "[129]\ttraining's binary_logloss: 0.59044\n",
      "[130]\ttraining's binary_logloss: 0.590492\n",
      "[131]\ttraining's binary_logloss: 0.590533\n",
      "[132]\ttraining's binary_logloss: 0.59057\n",
      "[133]\ttraining's binary_logloss: 0.590616\n",
      "[134]\ttraining's binary_logloss: 0.590656\n",
      "[135]\ttraining's binary_logloss: 0.590699\n",
      "[136]\ttraining's binary_logloss: 0.590707\n",
      "[137]\ttraining's binary_logloss: 0.590756\n",
      "[138]\ttraining's binary_logloss: 0.590827\n",
      "[139]\ttraining's binary_logloss: 0.59089\n",
      "[140]\ttraining's binary_logloss: 0.590965\n",
      "[141]\ttraining's binary_logloss: 0.590996\n",
      "[142]\ttraining's binary_logloss: 0.591068\n",
      "[143]\ttraining's binary_logloss: 0.591126\n",
      "[144]\ttraining's binary_logloss: 0.591186\n",
      "[145]\ttraining's binary_logloss: 0.591242\n",
      "[146]\ttraining's binary_logloss: 0.591253\n",
      "[147]\ttraining's binary_logloss: 0.591271\n",
      "[148]\ttraining's binary_logloss: 0.591291\n",
      "[149]\ttraining's binary_logloss: 0.591316\n",
      "[150]\ttraining's binary_logloss: 0.591329\n",
      "[151]\ttraining's binary_logloss: 0.591327\n",
      "[152]\ttraining's binary_logloss: 0.591328\n",
      "[153]\ttraining's binary_logloss: 0.591358\n",
      "[154]\ttraining's binary_logloss: 0.591369\n",
      "[155]\ttraining's binary_logloss: 0.591384\n",
      "[156]\ttraining's binary_logloss: 0.591446\n",
      "[157]\ttraining's binary_logloss: 0.591511\n",
      "[158]\ttraining's binary_logloss: 0.591582\n",
      "[159]\ttraining's binary_logloss: 0.59165\n",
      "[160]\ttraining's binary_logloss: 0.591742\n",
      "[161]\ttraining's binary_logloss: 0.591739\n",
      "[162]\ttraining's binary_logloss: 0.591738\n",
      "[163]\ttraining's binary_logloss: 0.59176\n",
      "[164]\ttraining's binary_logloss: 0.59176\n",
      "[165]\ttraining's binary_logloss: 0.591764\n",
      "[166]\ttraining's binary_logloss: 0.591775\n",
      "[167]\ttraining's binary_logloss: 0.591798\n",
      "[168]\ttraining's binary_logloss: 0.591813\n",
      "[169]\ttraining's binary_logloss: 0.591835\n",
      "[170]\ttraining's binary_logloss: 0.591855\n",
      "[171]\ttraining's binary_logloss: 0.591892\n",
      "[172]\ttraining's binary_logloss: 0.591919\n",
      "[173]\ttraining's binary_logloss: 0.591953\n",
      "[174]\ttraining's binary_logloss: 0.591983\n",
      "[175]\ttraining's binary_logloss: 0.591992\n",
      "[176]\ttraining's binary_logloss: 0.592019\n",
      "[177]\ttraining's binary_logloss: 0.592048\n",
      "[178]\ttraining's binary_logloss: 0.592086\n",
      "[179]\ttraining's binary_logloss: 0.592141\n",
      "[180]\ttraining's binary_logloss: 0.592169\n",
      "[181]\ttraining's binary_logloss: 0.592168\n",
      "[182]\ttraining's binary_logloss: 0.592155\n",
      "[183]\ttraining's binary_logloss: 0.592133\n",
      "[184]\ttraining's binary_logloss: 0.592131\n",
      "[185]\ttraining's binary_logloss: 0.592109\n",
      "[186]\ttraining's binary_logloss: 0.59213\n",
      "[187]\ttraining's binary_logloss: 0.592158\n",
      "[188]\ttraining's binary_logloss: 0.592177\n",
      "[189]\ttraining's binary_logloss: 0.592182\n",
      "[190]\ttraining's binary_logloss: 0.59221\n",
      "[191]\ttraining's binary_logloss: 0.592229\n",
      "[192]\ttraining's binary_logloss: 0.592242\n",
      "[193]\ttraining's binary_logloss: 0.592263\n",
      "[194]\ttraining's binary_logloss: 0.592286\n",
      "[195]\ttraining's binary_logloss: 0.592308\n",
      "[196]\ttraining's binary_logloss: 0.592329\n",
      "[197]\ttraining's binary_logloss: 0.592347\n",
      "[198]\ttraining's binary_logloss: 0.592365\n",
      "[199]\ttraining's binary_logloss: 0.592384\n",
      "[200]\ttraining's binary_logloss: 0.592391\n",
      "[201]\ttraining's binary_logloss: 0.592398\n",
      "[202]\ttraining's binary_logloss: 0.59241\n",
      "[203]\ttraining's binary_logloss: 0.592421\n",
      "[204]\ttraining's binary_logloss: 0.592431\n",
      "[205]\ttraining's binary_logloss: 0.592444\n",
      "[206]\ttraining's binary_logloss: 0.592453\n",
      "[207]\ttraining's binary_logloss: 0.592463\n",
      "[208]\ttraining's binary_logloss: 0.592473\n",
      "[209]\ttraining's binary_logloss: 0.592493\n",
      "[210]\ttraining's binary_logloss: 0.592508\n",
      "[211]\ttraining's binary_logloss: 0.592527\n",
      "[212]\ttraining's binary_logloss: 0.592519\n",
      "[213]\ttraining's binary_logloss: 0.592523\n",
      "[214]\ttraining's binary_logloss: 0.592529\n",
      "[215]\ttraining's binary_logloss: 0.592535\n",
      "[216]\ttraining's binary_logloss: 0.592516\n",
      "[217]\ttraining's binary_logloss: 0.592507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[218]\ttraining's binary_logloss: 0.592497\n",
      "[219]\ttraining's binary_logloss: 0.592488\n",
      "[220]\ttraining's binary_logloss: 0.592481\n",
      "[221]\ttraining's binary_logloss: 0.592483\n",
      "[222]\ttraining's binary_logloss: 0.592466\n",
      "[223]\ttraining's binary_logloss: 0.592468\n",
      "[224]\ttraining's binary_logloss: 0.592448\n",
      "[225]\ttraining's binary_logloss: 0.592431\n",
      "[226]\ttraining's binary_logloss: 0.592428\n",
      "[227]\ttraining's binary_logloss: 0.59244\n",
      "[228]\ttraining's binary_logloss: 0.592438\n",
      "[229]\ttraining's binary_logloss: 0.592451\n",
      "[230]\ttraining's binary_logloss: 0.592451\n",
      "[231]\ttraining's binary_logloss: 0.592422\n",
      "[232]\ttraining's binary_logloss: 0.592393\n",
      "[233]\ttraining's binary_logloss: 0.592367\n",
      "[234]\ttraining's binary_logloss: 0.59234\n",
      "[235]\ttraining's binary_logloss: 0.592315\n",
      "[236]\ttraining's binary_logloss: 0.592264\n",
      "[237]\ttraining's binary_logloss: 0.592232\n",
      "[238]\ttraining's binary_logloss: 0.592194\n",
      "[239]\ttraining's binary_logloss: 0.592152\n",
      "[240]\ttraining's binary_logloss: 0.592109\n",
      "[241]\ttraining's binary_logloss: 0.592096\n",
      "[242]\ttraining's binary_logloss: 0.592073\n",
      "[243]\ttraining's binary_logloss: 0.592054\n",
      "[244]\ttraining's binary_logloss: 0.592044\n",
      "[245]\ttraining's binary_logloss: 0.592024\n",
      "[246]\ttraining's binary_logloss: 0.592055\n",
      "[247]\ttraining's binary_logloss: 0.592083\n",
      "[248]\ttraining's binary_logloss: 0.592107\n",
      "[249]\ttraining's binary_logloss: 0.592143\n",
      "[250]\ttraining's binary_logloss: 0.592173\n",
      "[251]\ttraining's binary_logloss: 0.592139\n",
      "[252]\ttraining's binary_logloss: 0.592109\n",
      "[253]\ttraining's binary_logloss: 0.592062\n",
      "[254]\ttraining's binary_logloss: 0.592035\n",
      "[255]\ttraining's binary_logloss: 0.591987\n",
      "[256]\ttraining's binary_logloss: 0.591949\n",
      "[257]\ttraining's binary_logloss: 0.59191\n",
      "[258]\ttraining's binary_logloss: 0.59188\n",
      "[259]\ttraining's binary_logloss: 0.591848\n",
      "[260]\ttraining's binary_logloss: 0.591827\n",
      "[261]\ttraining's binary_logloss: 0.59179\n",
      "[262]\ttraining's binary_logloss: 0.591761\n",
      "[263]\ttraining's binary_logloss: 0.591727\n",
      "[264]\ttraining's binary_logloss: 0.591708\n",
      "[265]\ttraining's binary_logloss: 0.591665\n",
      "[266]\ttraining's binary_logloss: 0.591681\n",
      "[267]\ttraining's binary_logloss: 0.591671\n",
      "[268]\ttraining's binary_logloss: 0.591688\n",
      "[269]\ttraining's binary_logloss: 0.591678\n",
      "[270]\ttraining's binary_logloss: 0.591665\n",
      "[271]\ttraining's binary_logloss: 0.591612\n",
      "[272]\ttraining's binary_logloss: 0.591563\n",
      "[273]\ttraining's binary_logloss: 0.591511\n",
      "[274]\ttraining's binary_logloss: 0.591469\n",
      "[275]\ttraining's binary_logloss: 0.591419\n",
      "[276]\ttraining's binary_logloss: 0.591363\n",
      "[277]\ttraining's binary_logloss: 0.591316\n",
      "[278]\ttraining's binary_logloss: 0.591265\n",
      "[279]\ttraining's binary_logloss: 0.591217\n",
      "[280]\ttraining's binary_logloss: 0.591166\n",
      "[281]\ttraining's binary_logloss: 0.591124\n",
      "[282]\ttraining's binary_logloss: 0.591103\n",
      "[283]\ttraining's binary_logloss: 0.591064\n",
      "[284]\ttraining's binary_logloss: 0.591046\n",
      "[285]\ttraining's binary_logloss: 0.591025\n",
      "[286]\ttraining's binary_logloss: 0.590968\n",
      "[287]\ttraining's binary_logloss: 0.590934\n",
      "[288]\ttraining's binary_logloss: 0.590887\n",
      "[289]\ttraining's binary_logloss: 0.59084\n",
      "[290]\ttraining's binary_logloss: 0.590787\n",
      "[291]\ttraining's binary_logloss: 0.590725\n",
      "[292]\ttraining's binary_logloss: 0.590665\n",
      "[293]\ttraining's binary_logloss: 0.590603\n",
      "[294]\ttraining's binary_logloss: 0.590542\n",
      "[295]\ttraining's binary_logloss: 0.590469\n",
      "[296]\ttraining's binary_logloss: 0.590446\n",
      "[297]\ttraining's binary_logloss: 0.590412\n",
      "[298]\ttraining's binary_logloss: 0.590381\n",
      "[299]\ttraining's binary_logloss: 0.590362\n",
      "[300]\ttraining's binary_logloss: 0.590337\n",
      "[301]\ttraining's binary_logloss: 0.590279\n",
      "[302]\ttraining's binary_logloss: 0.590233\n",
      "[303]\ttraining's binary_logloss: 0.590176\n",
      "[304]\ttraining's binary_logloss: 0.59013\n",
      "[305]\ttraining's binary_logloss: 0.590084\n",
      "[306]\ttraining's binary_logloss: 0.590044\n",
      "[307]\ttraining's binary_logloss: 0.59001\n",
      "[308]\ttraining's binary_logloss: 0.58998\n",
      "[309]\ttraining's binary_logloss: 0.589945\n",
      "[310]\ttraining's binary_logloss: 0.58991\n",
      "[311]\ttraining's binary_logloss: 0.589873\n",
      "[312]\ttraining's binary_logloss: 0.58984\n",
      "[313]\ttraining's binary_logloss: 0.589805\n",
      "[314]\ttraining's binary_logloss: 0.589772\n",
      "[315]\ttraining's binary_logloss: 0.589738\n",
      "[316]\ttraining's binary_logloss: 0.589661\n",
      "[317]\ttraining's binary_logloss: 0.589582\n",
      "[318]\ttraining's binary_logloss: 0.589526\n",
      "[319]\ttraining's binary_logloss: 0.589439\n",
      "[320]\ttraining's binary_logloss: 0.589361\n",
      "[321]\ttraining's binary_logloss: 0.589297\n",
      "[322]\ttraining's binary_logloss: 0.589226\n",
      "[323]\ttraining's binary_logloss: 0.589167\n",
      "[324]\ttraining's binary_logloss: 0.589092\n",
      "[325]\ttraining's binary_logloss: 0.589012\n",
      "[326]\ttraining's binary_logloss: 0.588946\n",
      "[327]\ttraining's binary_logloss: 0.588891\n",
      "[328]\ttraining's binary_logloss: 0.588836\n",
      "[329]\ttraining's binary_logloss: 0.588791\n",
      "[330]\ttraining's binary_logloss: 0.588735\n",
      "[331]\ttraining's binary_logloss: 0.58864\n",
      "[332]\ttraining's binary_logloss: 0.588564\n",
      "[333]\ttraining's binary_logloss: 0.588472\n",
      "[334]\ttraining's binary_logloss: 0.5884\n",
      "[335]\ttraining's binary_logloss: 0.588313\n",
      "[336]\ttraining's binary_logloss: 0.588291\n",
      "[337]\ttraining's binary_logloss: 0.588269\n",
      "[338]\ttraining's binary_logloss: 0.588238\n",
      "[339]\ttraining's binary_logloss: 0.588218\n",
      "[340]\ttraining's binary_logloss: 0.588193\n",
      "[341]\ttraining's binary_logloss: 0.588172\n",
      "[342]\ttraining's binary_logloss: 0.588151\n",
      "[343]\ttraining's binary_logloss: 0.58813\n",
      "[344]\ttraining's binary_logloss: 0.588097\n",
      "[345]\ttraining's binary_logloss: 0.588061\n",
      "[346]\ttraining's binary_logloss: 0.588016\n",
      "[347]\ttraining's binary_logloss: 0.58796\n",
      "[348]\ttraining's binary_logloss: 0.587918\n",
      "[349]\ttraining's binary_logloss: 0.587876\n",
      "[350]\ttraining's binary_logloss: 0.587828\n",
      "[351]\ttraining's binary_logloss: 0.587766\n",
      "[352]\ttraining's binary_logloss: 0.587714\n",
      "[353]\ttraining's binary_logloss: 0.58765\n",
      "[354]\ttraining's binary_logloss: 0.587587\n",
      "[355]\ttraining's binary_logloss: 0.587516\n",
      "[356]\ttraining's binary_logloss: 0.587431\n",
      "[357]\ttraining's binary_logloss: 0.587345\n",
      "[358]\ttraining's binary_logloss: 0.587257\n",
      "[359]\ttraining's binary_logloss: 0.587152\n",
      "[360]\ttraining's binary_logloss: 0.587077\n",
      "[361]\ttraining's binary_logloss: 0.586966\n",
      "[362]\ttraining's binary_logloss: 0.586855\n",
      "[363]\ttraining's binary_logloss: 0.586749\n",
      "[364]\ttraining's binary_logloss: 0.586644\n",
      "[365]\ttraining's binary_logloss: 0.586543\n",
      "[366]\ttraining's binary_logloss: 0.586504\n",
      "[367]\ttraining's binary_logloss: 0.586466\n",
      "[368]\ttraining's binary_logloss: 0.586403\n",
      "[369]\ttraining's binary_logloss: 0.586347\n",
      "[370]\ttraining's binary_logloss: 0.586288\n",
      "[371]\ttraining's binary_logloss: 0.586251\n",
      "[372]\ttraining's binary_logloss: 0.586215\n",
      "[373]\ttraining's binary_logloss: 0.586177\n",
      "[374]\ttraining's binary_logloss: 0.586141\n",
      "[375]\ttraining's binary_logloss: 0.586109\n",
      "[376]\ttraining's binary_logloss: 0.58604\n",
      "[377]\ttraining's binary_logloss: 0.585966\n",
      "[378]\ttraining's binary_logloss: 0.585903\n",
      "[379]\ttraining's binary_logloss: 0.585824\n",
      "[380]\ttraining's binary_logloss: 0.585758\n",
      "[381]\ttraining's binary_logloss: 0.585733\n",
      "[382]\ttraining's binary_logloss: 0.585706\n",
      "[383]\ttraining's binary_logloss: 0.585679\n",
      "[384]\ttraining's binary_logloss: 0.585631\n",
      "[385]\ttraining's binary_logloss: 0.585604\n",
      "[386]\ttraining's binary_logloss: 0.585477\n",
      "[387]\ttraining's binary_logloss: 0.585354\n",
      "[388]\ttraining's binary_logloss: 0.585258\n",
      "[389]\ttraining's binary_logloss: 0.585141\n",
      "[390]\ttraining's binary_logloss: 0.585036\n",
      "[391]\ttraining's binary_logloss: 0.584961\n",
      "[392]\ttraining's binary_logloss: 0.584887\n",
      "[393]\ttraining's binary_logloss: 0.584819\n",
      "[394]\ttraining's binary_logloss: 0.584757\n",
      "[395]\ttraining's binary_logloss: 0.584672\n",
      "[396]\ttraining's binary_logloss: 0.584615\n",
      "[397]\ttraining's binary_logloss: 0.584547\n",
      "[398]\ttraining's binary_logloss: 0.584451\n",
      "[399]\ttraining's binary_logloss: 0.584365\n",
      "[400]\ttraining's binary_logloss: 0.584301\n",
      "[401]\ttraining's binary_logloss: 0.584191\n",
      "[402]\ttraining's binary_logloss: 0.584109\n",
      "[403]\ttraining's binary_logloss: 0.584026\n",
      "[404]\ttraining's binary_logloss: 0.583943\n",
      "[405]\ttraining's binary_logloss: 0.58385\n",
      "[406]\ttraining's binary_logloss: 0.583782\n",
      "[407]\ttraining's binary_logloss: 0.583719\n",
      "[408]\ttraining's binary_logloss: 0.583658\n",
      "[409]\ttraining's binary_logloss: 0.583597\n",
      "[410]\ttraining's binary_logloss: 0.583534\n",
      "[411]\ttraining's binary_logloss: 0.58341\n",
      "[412]\ttraining's binary_logloss: 0.583306\n",
      "[413]\ttraining's binary_logloss: 0.58321\n",
      "[414]\ttraining's binary_logloss: 0.583087\n",
      "[415]\ttraining's binary_logloss: 0.582987\n",
      "[416]\ttraining's binary_logloss: 0.582902\n",
      "[417]\ttraining's binary_logloss: 0.582829\n",
      "[418]\ttraining's binary_logloss: 0.582752\n",
      "[419]\ttraining's binary_logloss: 0.582665\n",
      "[420]\ttraining's binary_logloss: 0.582584\n",
      "[421]\ttraining's binary_logloss: 0.582524\n",
      "[422]\ttraining's binary_logloss: 0.582486\n",
      "[423]\ttraining's binary_logloss: 0.582435\n",
      "[424]\ttraining's binary_logloss: 0.582403\n",
      "[425]\ttraining's binary_logloss: 0.58237\n",
      "[426]\ttraining's binary_logloss: 0.582301\n",
      "[427]\ttraining's binary_logloss: 0.582229\n",
      "[428]\ttraining's binary_logloss: 0.582178\n",
      "[429]\ttraining's binary_logloss: 0.582124\n",
      "[430]\ttraining's binary_logloss: 0.582072\n",
      "[431]\ttraining's binary_logloss: 0.581974\n",
      "[432]\ttraining's binary_logloss: 0.581872\n",
      "[433]\ttraining's binary_logloss: 0.581759\n",
      "[434]\ttraining's binary_logloss: 0.581671\n",
      "[435]\ttraining's binary_logloss: 0.581574\n",
      "[436]\ttraining's binary_logloss: 0.581524\n",
      "[437]\ttraining's binary_logloss: 0.581477\n",
      "[438]\ttraining's binary_logloss: 0.581427\n",
      "[439]\ttraining's binary_logloss: 0.581379\n",
      "[440]\ttraining's binary_logloss: 0.581337\n",
      "[441]\ttraining's binary_logloss: 0.581271\n",
      "[442]\ttraining's binary_logloss: 0.581205\n",
      "[443]\ttraining's binary_logloss: 0.581127\n",
      "[444]\ttraining's binary_logloss: 0.581061\n",
      "[445]\ttraining's binary_logloss: 0.580988\n",
      "[446]\ttraining's binary_logloss: 0.580914\n",
      "[447]\ttraining's binary_logloss: 0.580849\n",
      "[448]\ttraining's binary_logloss: 0.580776\n",
      "[449]\ttraining's binary_logloss: 0.580701\n",
      "[450]\ttraining's binary_logloss: 0.580635\n",
      "[451]\ttraining's binary_logloss: 0.580585\n",
      "[452]\ttraining's binary_logloss: 0.580537\n",
      "[453]\ttraining's binary_logloss: 0.580489\n",
      "[454]\ttraining's binary_logloss: 0.580448\n",
      "[455]\ttraining's binary_logloss: 0.580399\n",
      "[456]\ttraining's binary_logloss: 0.580342\n",
      "[457]\ttraining's binary_logloss: 0.580289\n",
      "[458]\ttraining's binary_logloss: 0.580229\n",
      "[459]\ttraining's binary_logloss: 0.580171\n",
      "[460]\ttraining's binary_logloss: 0.580114\n",
      "[461]\ttraining's binary_logloss: 0.580024\n",
      "[462]\ttraining's binary_logloss: 0.579938\n",
      "[463]\ttraining's binary_logloss: 0.579855\n",
      "[464]\ttraining's binary_logloss: 0.579774\n",
      "[465]\ttraining's binary_logloss: 0.579666\n",
      "[466]\ttraining's binary_logloss: 0.579573\n",
      "[467]\ttraining's binary_logloss: 0.579489\n",
      "[468]\ttraining's binary_logloss: 0.5794\n",
      "[469]\ttraining's binary_logloss: 0.57932\n",
      "[470]\ttraining's binary_logloss: 0.579244\n",
      "[471]\ttraining's binary_logloss: 0.579207\n",
      "[472]\ttraining's binary_logloss: 0.579155\n",
      "[473]\ttraining's binary_logloss: 0.579104\n",
      "[474]\ttraining's binary_logloss: 0.57907\n",
      "[475]\ttraining's binary_logloss: 0.579013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[476]\ttraining's binary_logloss: 0.578953\n",
      "[477]\ttraining's binary_logloss: 0.578896\n",
      "[478]\ttraining's binary_logloss: 0.578838\n",
      "[479]\ttraining's binary_logloss: 0.578777\n",
      "[480]\ttraining's binary_logloss: 0.578716\n",
      "[481]\ttraining's binary_logloss: 0.578643\n",
      "[482]\ttraining's binary_logloss: 0.578582\n",
      "[483]\ttraining's binary_logloss: 0.578514\n",
      "[484]\ttraining's binary_logloss: 0.57845\n",
      "[485]\ttraining's binary_logloss: 0.578383\n",
      "[486]\ttraining's binary_logloss: 0.578274\n",
      "[487]\ttraining's binary_logloss: 0.578179\n",
      "[488]\ttraining's binary_logloss: 0.578092\n",
      "[489]\ttraining's binary_logloss: 0.578005\n",
      "[490]\ttraining's binary_logloss: 0.577919\n",
      "[491]\ttraining's binary_logloss: 0.577878\n",
      "[492]\ttraining's binary_logloss: 0.577842\n",
      "[493]\ttraining's binary_logloss: 0.577809\n",
      "[494]\ttraining's binary_logloss: 0.577775\n",
      "[495]\ttraining's binary_logloss: 0.57774\n",
      "[496]\ttraining's binary_logloss: 0.577651\n",
      "[497]\ttraining's binary_logloss: 0.577539\n",
      "[498]\ttraining's binary_logloss: 0.577449\n",
      "[499]\ttraining's binary_logloss: 0.577361\n",
      "[500]\ttraining's binary_logloss: 0.577254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614062\n",
      "[2]\ttraining's binary_logloss: 0.613016\n",
      "[3]\ttraining's binary_logloss: 0.612025\n",
      "[4]\ttraining's binary_logloss: 0.611069\n",
      "[5]\ttraining's binary_logloss: 0.610014\n",
      "[6]\ttraining's binary_logloss: 0.6091\n",
      "[7]\ttraining's binary_logloss: 0.608197\n",
      "[8]\ttraining's binary_logloss: 0.607337\n",
      "[9]\ttraining's binary_logloss: 0.606513\n",
      "[10]\ttraining's binary_logloss: 0.605837\n",
      "[11]\ttraining's binary_logloss: 0.604997\n",
      "[12]\ttraining's binary_logloss: 0.604193\n",
      "[13]\ttraining's binary_logloss: 0.603433\n",
      "[14]\ttraining's binary_logloss: 0.602798\n",
      "[15]\ttraining's binary_logloss: 0.60221\n",
      "[16]\ttraining's binary_logloss: 0.601497\n",
      "[17]\ttraining's binary_logloss: 0.600814\n",
      "[18]\ttraining's binary_logloss: 0.600185\n",
      "[19]\ttraining's binary_logloss: 0.599581\n",
      "[20]\ttraining's binary_logloss: 0.599041\n",
      "[21]\ttraining's binary_logloss: 0.598445\n",
      "[22]\ttraining's binary_logloss: 0.597914\n",
      "[23]\ttraining's binary_logloss: 0.597422\n",
      "[24]\ttraining's binary_logloss: 0.596921\n",
      "[25]\ttraining's binary_logloss: 0.596415\n",
      "[26]\ttraining's binary_logloss: 0.596007\n",
      "[27]\ttraining's binary_logloss: 0.595635\n",
      "[28]\ttraining's binary_logloss: 0.595264\n",
      "[29]\ttraining's binary_logloss: 0.59495\n",
      "[30]\ttraining's binary_logloss: 0.594591\n",
      "[31]\ttraining's binary_logloss: 0.594098\n",
      "[32]\ttraining's binary_logloss: 0.593723\n",
      "[33]\ttraining's binary_logloss: 0.593365\n",
      "[34]\ttraining's binary_logloss: 0.593035\n",
      "[35]\ttraining's binary_logloss: 0.592712\n",
      "[36]\ttraining's binary_logloss: 0.592406\n",
      "[37]\ttraining's binary_logloss: 0.592069\n",
      "[38]\ttraining's binary_logloss: 0.591719\n",
      "[39]\ttraining's binary_logloss: 0.591468\n",
      "[40]\ttraining's binary_logloss: 0.591186\n",
      "[41]\ttraining's binary_logloss: 0.590935\n",
      "[42]\ttraining's binary_logloss: 0.590679\n",
      "[43]\ttraining's binary_logloss: 0.590471\n",
      "[44]\ttraining's binary_logloss: 0.590237\n",
      "[45]\ttraining's binary_logloss: 0.590016\n",
      "[46]\ttraining's binary_logloss: 0.589763\n",
      "[47]\ttraining's binary_logloss: 0.589528\n",
      "[48]\ttraining's binary_logloss: 0.589301\n",
      "[49]\ttraining's binary_logloss: 0.58909\n",
      "[50]\ttraining's binary_logloss: 0.588897\n",
      "[51]\ttraining's binary_logloss: 0.588706\n",
      "[52]\ttraining's binary_logloss: 0.588525\n",
      "[53]\ttraining's binary_logloss: 0.588365\n",
      "[54]\ttraining's binary_logloss: 0.588204\n",
      "[55]\ttraining's binary_logloss: 0.588067\n",
      "[56]\ttraining's binary_logloss: 0.587857\n",
      "[57]\ttraining's binary_logloss: 0.587659\n",
      "[58]\ttraining's binary_logloss: 0.587567\n",
      "[59]\ttraining's binary_logloss: 0.587396\n",
      "[60]\ttraining's binary_logloss: 0.587317\n",
      "[61]\ttraining's binary_logloss: 0.587188\n",
      "[62]\ttraining's binary_logloss: 0.587093\n",
      "[63]\ttraining's binary_logloss: 0.586932\n",
      "[64]\ttraining's binary_logloss: 0.586874\n",
      "[65]\ttraining's binary_logloss: 0.586736\n",
      "[66]\ttraining's binary_logloss: 0.586614\n",
      "[67]\ttraining's binary_logloss: 0.586539\n",
      "[68]\ttraining's binary_logloss: 0.586525\n",
      "[69]\ttraining's binary_logloss: 0.586422\n",
      "[70]\ttraining's binary_logloss: 0.586362\n",
      "[71]\ttraining's binary_logloss: 0.586304\n",
      "[72]\ttraining's binary_logloss: 0.586261\n",
      "[73]\ttraining's binary_logloss: 0.586215\n",
      "[74]\ttraining's binary_logloss: 0.586182\n",
      "[75]\ttraining's binary_logloss: 0.586139\n",
      "[76]\ttraining's binary_logloss: 0.586023\n",
      "[77]\ttraining's binary_logloss: 0.585912\n",
      "[78]\ttraining's binary_logloss: 0.585807\n",
      "[79]\ttraining's binary_logloss: 0.585715\n",
      "[80]\ttraining's binary_logloss: 0.585622\n",
      "[81]\ttraining's binary_logloss: 0.585548\n",
      "[82]\ttraining's binary_logloss: 0.585487\n",
      "[83]\ttraining's binary_logloss: 0.58547\n",
      "[84]\ttraining's binary_logloss: 0.585493\n",
      "[85]\ttraining's binary_logloss: 0.585525\n",
      "[86]\ttraining's binary_logloss: 0.585442\n",
      "[87]\ttraining's binary_logloss: 0.585362\n",
      "[88]\ttraining's binary_logloss: 0.585289\n",
      "[89]\ttraining's binary_logloss: 0.585226\n",
      "[90]\ttraining's binary_logloss: 0.585163\n",
      "[91]\ttraining's binary_logloss: 0.585217\n",
      "[92]\ttraining's binary_logloss: 0.585202\n",
      "[93]\ttraining's binary_logloss: 0.585265\n",
      "[94]\ttraining's binary_logloss: 0.585279\n",
      "[95]\ttraining's binary_logloss: 0.585291\n",
      "[96]\ttraining's binary_logloss: 0.585323\n",
      "[97]\ttraining's binary_logloss: 0.585359\n",
      "[98]\ttraining's binary_logloss: 0.585382\n",
      "[99]\ttraining's binary_logloss: 0.585379\n",
      "[100]\ttraining's binary_logloss: 0.585422\n",
      "[101]\ttraining's binary_logloss: 0.585454\n",
      "[102]\ttraining's binary_logloss: 0.585507\n",
      "[103]\ttraining's binary_logloss: 0.585556\n",
      "[104]\ttraining's binary_logloss: 0.585572\n",
      "[105]\ttraining's binary_logloss: 0.58562\n",
      "[106]\ttraining's binary_logloss: 0.585601\n",
      "[107]\ttraining's binary_logloss: 0.585587\n",
      "[108]\ttraining's binary_logloss: 0.58557\n",
      "[109]\ttraining's binary_logloss: 0.58556\n",
      "[110]\ttraining's binary_logloss: 0.585577\n",
      "[111]\ttraining's binary_logloss: 0.585636\n",
      "[112]\ttraining's binary_logloss: 0.585634\n",
      "[113]\ttraining's binary_logloss: 0.585689\n",
      "[114]\ttraining's binary_logloss: 0.585687\n",
      "[115]\ttraining's binary_logloss: 0.585664\n",
      "[116]\ttraining's binary_logloss: 0.585729\n",
      "[117]\ttraining's binary_logloss: 0.58579\n",
      "[118]\ttraining's binary_logloss: 0.585876\n",
      "[119]\ttraining's binary_logloss: 0.585897\n",
      "[120]\ttraining's binary_logloss: 0.585977\n",
      "[121]\ttraining's binary_logloss: 0.585961\n",
      "[122]\ttraining's binary_logloss: 0.58595\n",
      "[123]\ttraining's binary_logloss: 0.585948\n",
      "[124]\ttraining's binary_logloss: 0.585938\n",
      "[125]\ttraining's binary_logloss: 0.585941\n",
      "[126]\ttraining's binary_logloss: 0.585929\n",
      "[127]\ttraining's binary_logloss: 0.585921\n",
      "[128]\ttraining's binary_logloss: 0.585914\n",
      "[129]\ttraining's binary_logloss: 0.585913\n",
      "[130]\ttraining's binary_logloss: 0.585913\n",
      "[131]\ttraining's binary_logloss: 0.585931\n",
      "[132]\ttraining's binary_logloss: 0.585928\n",
      "[133]\ttraining's binary_logloss: 0.585928\n",
      "[134]\ttraining's binary_logloss: 0.585932\n",
      "[135]\ttraining's binary_logloss: 0.58594\n",
      "[136]\ttraining's binary_logloss: 0.58596\n",
      "[137]\ttraining's binary_logloss: 0.585994\n",
      "[138]\ttraining's binary_logloss: 0.586022\n",
      "[139]\ttraining's binary_logloss: 0.586056\n",
      "[140]\ttraining's binary_logloss: 0.586065\n",
      "[141]\ttraining's binary_logloss: 0.586052\n",
      "[142]\ttraining's binary_logloss: 0.586041\n",
      "[143]\ttraining's binary_logloss: 0.586114\n",
      "[144]\ttraining's binary_logloss: 0.586161\n",
      "[145]\ttraining's binary_logloss: 0.586154\n",
      "[146]\ttraining's binary_logloss: 0.586194\n",
      "[147]\ttraining's binary_logloss: 0.586243\n",
      "[148]\ttraining's binary_logloss: 0.586269\n",
      "[149]\ttraining's binary_logloss: 0.586288\n",
      "[150]\ttraining's binary_logloss: 0.586316\n",
      "[151]\ttraining's binary_logloss: 0.586306\n",
      "[152]\ttraining's binary_logloss: 0.586291\n",
      "[153]\ttraining's binary_logloss: 0.586284\n",
      "[154]\ttraining's binary_logloss: 0.586288\n",
      "[155]\ttraining's binary_logloss: 0.586293\n",
      "[156]\ttraining's binary_logloss: 0.586308\n",
      "[157]\ttraining's binary_logloss: 0.586325\n",
      "[158]\ttraining's binary_logloss: 0.586352\n",
      "[159]\ttraining's binary_logloss: 0.586385\n",
      "[160]\ttraining's binary_logloss: 0.586405\n",
      "[161]\ttraining's binary_logloss: 0.586388\n",
      "[162]\ttraining's binary_logloss: 0.586323\n",
      "[163]\ttraining's binary_logloss: 0.586315\n",
      "[164]\ttraining's binary_logloss: 0.586301\n",
      "[165]\ttraining's binary_logloss: 0.58629\n",
      "[166]\ttraining's binary_logloss: 0.586251\n",
      "[167]\ttraining's binary_logloss: 0.586219\n",
      "[168]\ttraining's binary_logloss: 0.586239\n",
      "[169]\ttraining's binary_logloss: 0.586206\n",
      "[170]\ttraining's binary_logloss: 0.586209\n",
      "[171]\ttraining's binary_logloss: 0.58622\n",
      "[172]\ttraining's binary_logloss: 0.586208\n",
      "[173]\ttraining's binary_logloss: 0.586233\n",
      "[174]\ttraining's binary_logloss: 0.58623\n",
      "[175]\ttraining's binary_logloss: 0.586217\n",
      "[176]\ttraining's binary_logloss: 0.586217\n",
      "[177]\ttraining's binary_logloss: 0.586234\n",
      "[178]\ttraining's binary_logloss: 0.586244\n",
      "[179]\ttraining's binary_logloss: 0.586255\n",
      "[180]\ttraining's binary_logloss: 0.586308\n",
      "[181]\ttraining's binary_logloss: 0.586322\n",
      "[182]\ttraining's binary_logloss: 0.586319\n",
      "[183]\ttraining's binary_logloss: 0.586319\n",
      "[184]\ttraining's binary_logloss: 0.586333\n",
      "[185]\ttraining's binary_logloss: 0.586332\n",
      "[186]\ttraining's binary_logloss: 0.586325\n",
      "[187]\ttraining's binary_logloss: 0.586335\n",
      "[188]\ttraining's binary_logloss: 0.586337\n",
      "[189]\ttraining's binary_logloss: 0.586333\n",
      "[190]\ttraining's binary_logloss: 0.58633\n",
      "[191]\ttraining's binary_logloss: 0.586332\n",
      "[192]\ttraining's binary_logloss: 0.586348\n",
      "[193]\ttraining's binary_logloss: 0.586351\n",
      "[194]\ttraining's binary_logloss: 0.586364\n",
      "[195]\ttraining's binary_logloss: 0.586405\n",
      "[196]\ttraining's binary_logloss: 0.586368\n",
      "[197]\ttraining's binary_logloss: 0.586336\n",
      "[198]\ttraining's binary_logloss: 0.586304\n",
      "[199]\ttraining's binary_logloss: 0.586308\n",
      "[200]\ttraining's binary_logloss: 0.586278\n",
      "[201]\ttraining's binary_logloss: 0.586303\n",
      "[202]\ttraining's binary_logloss: 0.586296\n",
      "[203]\ttraining's binary_logloss: 0.586292\n",
      "[204]\ttraining's binary_logloss: 0.586256\n",
      "[205]\ttraining's binary_logloss: 0.586262\n",
      "[206]\ttraining's binary_logloss: 0.586244\n",
      "[207]\ttraining's binary_logloss: 0.586246\n",
      "[208]\ttraining's binary_logloss: 0.586239\n",
      "[209]\ttraining's binary_logloss: 0.586237\n",
      "[210]\ttraining's binary_logloss: 0.586243\n",
      "[211]\ttraining's binary_logloss: 0.586275\n",
      "[212]\ttraining's binary_logloss: 0.586284\n",
      "[213]\ttraining's binary_logloss: 0.586299\n",
      "[214]\ttraining's binary_logloss: 0.586306\n",
      "[215]\ttraining's binary_logloss: 0.586322\n",
      "[216]\ttraining's binary_logloss: 0.586272\n",
      "[217]\ttraining's binary_logloss: 0.586226\n",
      "[218]\ttraining's binary_logloss: 0.586172\n",
      "[219]\ttraining's binary_logloss: 0.586122\n",
      "[220]\ttraining's binary_logloss: 0.586075\n",
      "[221]\ttraining's binary_logloss: 0.586011\n",
      "[222]\ttraining's binary_logloss: 0.58595\n",
      "[223]\ttraining's binary_logloss: 0.585889\n",
      "[224]\ttraining's binary_logloss: 0.585834\n",
      "[225]\ttraining's binary_logloss: 0.585787\n",
      "[226]\ttraining's binary_logloss: 0.585784\n",
      "[227]\ttraining's binary_logloss: 0.585782\n",
      "[228]\ttraining's binary_logloss: 0.585785\n",
      "[229]\ttraining's binary_logloss: 0.585781\n",
      "[230]\ttraining's binary_logloss: 0.585765\n",
      "[231]\ttraining's binary_logloss: 0.585748\n",
      "[232]\ttraining's binary_logloss: 0.585743\n",
      "[233]\ttraining's binary_logloss: 0.58573\n",
      "[234]\ttraining's binary_logloss: 0.585721\n",
      "[235]\ttraining's binary_logloss: 0.585709\n",
      "[236]\ttraining's binary_logloss: 0.585662\n",
      "[237]\ttraining's binary_logloss: 0.585611\n",
      "[238]\ttraining's binary_logloss: 0.58556\n",
      "[239]\ttraining's binary_logloss: 0.585518\n",
      "[240]\ttraining's binary_logloss: 0.585461\n",
      "[241]\ttraining's binary_logloss: 0.585396\n",
      "[242]\ttraining's binary_logloss: 0.585348\n",
      "[243]\ttraining's binary_logloss: 0.585293\n",
      "[244]\ttraining's binary_logloss: 0.58523\n",
      "[245]\ttraining's binary_logloss: 0.58518\n",
      "[246]\ttraining's binary_logloss: 0.585149\n",
      "[247]\ttraining's binary_logloss: 0.585121\n",
      "[248]\ttraining's binary_logloss: 0.585085\n",
      "[249]\ttraining's binary_logloss: 0.585056\n",
      "[250]\ttraining's binary_logloss: 0.585027\n",
      "[251]\ttraining's binary_logloss: 0.585031\n",
      "[252]\ttraining's binary_logloss: 0.585032\n",
      "[253]\ttraining's binary_logloss: 0.585023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[254]\ttraining's binary_logloss: 0.584988\n",
      "[255]\ttraining's binary_logloss: 0.584993\n",
      "[256]\ttraining's binary_logloss: 0.584961\n",
      "[257]\ttraining's binary_logloss: 0.58491\n",
      "[258]\ttraining's binary_logloss: 0.584858\n",
      "[259]\ttraining's binary_logloss: 0.584814\n",
      "[260]\ttraining's binary_logloss: 0.584769\n",
      "[261]\ttraining's binary_logloss: 0.584721\n",
      "[262]\ttraining's binary_logloss: 0.58469\n",
      "[263]\ttraining's binary_logloss: 0.584677\n",
      "[264]\ttraining's binary_logloss: 0.584664\n",
      "[265]\ttraining's binary_logloss: 0.58461\n",
      "[266]\ttraining's binary_logloss: 0.584632\n",
      "[267]\ttraining's binary_logloss: 0.584659\n",
      "[268]\ttraining's binary_logloss: 0.584678\n",
      "[269]\ttraining's binary_logloss: 0.584694\n",
      "[270]\ttraining's binary_logloss: 0.584711\n",
      "[271]\ttraining's binary_logloss: 0.584629\n",
      "[272]\ttraining's binary_logloss: 0.584536\n",
      "[273]\ttraining's binary_logloss: 0.584449\n",
      "[274]\ttraining's binary_logloss: 0.584363\n",
      "[275]\ttraining's binary_logloss: 0.58428\n",
      "[276]\ttraining's binary_logloss: 0.584208\n",
      "[277]\ttraining's binary_logloss: 0.584137\n",
      "[278]\ttraining's binary_logloss: 0.584081\n",
      "[279]\ttraining's binary_logloss: 0.584005\n",
      "[280]\ttraining's binary_logloss: 0.583934\n",
      "[281]\ttraining's binary_logloss: 0.583873\n",
      "[282]\ttraining's binary_logloss: 0.583811\n",
      "[283]\ttraining's binary_logloss: 0.583758\n",
      "[284]\ttraining's binary_logloss: 0.583696\n",
      "[285]\ttraining's binary_logloss: 0.583649\n",
      "[286]\ttraining's binary_logloss: 0.583594\n",
      "[287]\ttraining's binary_logloss: 0.583538\n",
      "[288]\ttraining's binary_logloss: 0.583486\n",
      "[289]\ttraining's binary_logloss: 0.583434\n",
      "[290]\ttraining's binary_logloss: 0.583386\n",
      "[291]\ttraining's binary_logloss: 0.583307\n",
      "[292]\ttraining's binary_logloss: 0.583237\n",
      "[293]\ttraining's binary_logloss: 0.583174\n",
      "[294]\ttraining's binary_logloss: 0.583105\n",
      "[295]\ttraining's binary_logloss: 0.583042\n",
      "[296]\ttraining's binary_logloss: 0.583016\n",
      "[297]\ttraining's binary_logloss: 0.582998\n",
      "[298]\ttraining's binary_logloss: 0.58298\n",
      "[299]\ttraining's binary_logloss: 0.58296\n",
      "[300]\ttraining's binary_logloss: 0.58295\n",
      "[301]\ttraining's binary_logloss: 0.582892\n",
      "[302]\ttraining's binary_logloss: 0.582835\n",
      "[303]\ttraining's binary_logloss: 0.58278\n",
      "[304]\ttraining's binary_logloss: 0.582704\n",
      "[305]\ttraining's binary_logloss: 0.582639\n",
      "[306]\ttraining's binary_logloss: 0.582601\n",
      "[307]\ttraining's binary_logloss: 0.582536\n",
      "[308]\ttraining's binary_logloss: 0.582465\n",
      "[309]\ttraining's binary_logloss: 0.582412\n",
      "[310]\ttraining's binary_logloss: 0.582343\n",
      "[311]\ttraining's binary_logloss: 0.582291\n",
      "[312]\ttraining's binary_logloss: 0.582241\n",
      "[313]\ttraining's binary_logloss: 0.582184\n",
      "[314]\ttraining's binary_logloss: 0.582113\n",
      "[315]\ttraining's binary_logloss: 0.582058\n",
      "[316]\ttraining's binary_logloss: 0.581996\n",
      "[317]\ttraining's binary_logloss: 0.581944\n",
      "[318]\ttraining's binary_logloss: 0.5819\n",
      "[319]\ttraining's binary_logloss: 0.581852\n",
      "[320]\ttraining's binary_logloss: 0.581802\n",
      "[321]\ttraining's binary_logloss: 0.581777\n",
      "[322]\ttraining's binary_logloss: 0.581728\n",
      "[323]\ttraining's binary_logloss: 0.581682\n",
      "[324]\ttraining's binary_logloss: 0.581645\n",
      "[325]\ttraining's binary_logloss: 0.581601\n",
      "[326]\ttraining's binary_logloss: 0.581535\n",
      "[327]\ttraining's binary_logloss: 0.581452\n",
      "[328]\ttraining's binary_logloss: 0.58139\n",
      "[329]\ttraining's binary_logloss: 0.581331\n",
      "[330]\ttraining's binary_logloss: 0.581272\n",
      "[331]\ttraining's binary_logloss: 0.581209\n",
      "[332]\ttraining's binary_logloss: 0.581145\n",
      "[333]\ttraining's binary_logloss: 0.581078\n",
      "[334]\ttraining's binary_logloss: 0.581011\n",
      "[335]\ttraining's binary_logloss: 0.580959\n",
      "[336]\ttraining's binary_logloss: 0.580903\n",
      "[337]\ttraining's binary_logloss: 0.580856\n",
      "[338]\ttraining's binary_logloss: 0.5808\n",
      "[339]\ttraining's binary_logloss: 0.580763\n",
      "[340]\ttraining's binary_logloss: 0.580704\n",
      "[341]\ttraining's binary_logloss: 0.580671\n",
      "[342]\ttraining's binary_logloss: 0.580637\n",
      "[343]\ttraining's binary_logloss: 0.580603\n",
      "[344]\ttraining's binary_logloss: 0.580562\n",
      "[345]\ttraining's binary_logloss: 0.580535\n",
      "[346]\ttraining's binary_logloss: 0.580487\n",
      "[347]\ttraining's binary_logloss: 0.580429\n",
      "[348]\ttraining's binary_logloss: 0.580376\n",
      "[349]\ttraining's binary_logloss: 0.580337\n",
      "[350]\ttraining's binary_logloss: 0.580291\n",
      "[351]\ttraining's binary_logloss: 0.58021\n",
      "[352]\ttraining's binary_logloss: 0.580123\n",
      "[353]\ttraining's binary_logloss: 0.580052\n",
      "[354]\ttraining's binary_logloss: 0.579976\n",
      "[355]\ttraining's binary_logloss: 0.579894\n",
      "[356]\ttraining's binary_logloss: 0.579784\n",
      "[357]\ttraining's binary_logloss: 0.579676\n",
      "[358]\ttraining's binary_logloss: 0.579571\n",
      "[359]\ttraining's binary_logloss: 0.579474\n",
      "[360]\ttraining's binary_logloss: 0.579379\n",
      "[361]\ttraining's binary_logloss: 0.579268\n",
      "[362]\ttraining's binary_logloss: 0.579154\n",
      "[363]\ttraining's binary_logloss: 0.579046\n",
      "[364]\ttraining's binary_logloss: 0.578949\n",
      "[365]\ttraining's binary_logloss: 0.578844\n",
      "[366]\ttraining's binary_logloss: 0.578765\n",
      "[367]\ttraining's binary_logloss: 0.578685\n",
      "[368]\ttraining's binary_logloss: 0.578607\n",
      "[369]\ttraining's binary_logloss: 0.578538\n",
      "[370]\ttraining's binary_logloss: 0.578463\n",
      "[371]\ttraining's binary_logloss: 0.578426\n",
      "[372]\ttraining's binary_logloss: 0.578388\n",
      "[373]\ttraining's binary_logloss: 0.578346\n",
      "[374]\ttraining's binary_logloss: 0.578304\n",
      "[375]\ttraining's binary_logloss: 0.578271\n",
      "[376]\ttraining's binary_logloss: 0.578189\n",
      "[377]\ttraining's binary_logloss: 0.578118\n",
      "[378]\ttraining's binary_logloss: 0.57805\n",
      "[379]\ttraining's binary_logloss: 0.577995\n",
      "[380]\ttraining's binary_logloss: 0.577928\n",
      "[381]\ttraining's binary_logloss: 0.577886\n",
      "[382]\ttraining's binary_logloss: 0.577833\n",
      "[383]\ttraining's binary_logloss: 0.577793\n",
      "[384]\ttraining's binary_logloss: 0.57775\n",
      "[385]\ttraining's binary_logloss: 0.577711\n",
      "[386]\ttraining's binary_logloss: 0.577613\n",
      "[387]\ttraining's binary_logloss: 0.577515\n",
      "[388]\ttraining's binary_logloss: 0.57742\n",
      "[389]\ttraining's binary_logloss: 0.577325\n",
      "[390]\ttraining's binary_logloss: 0.57724\n",
      "[391]\ttraining's binary_logloss: 0.577151\n",
      "[392]\ttraining's binary_logloss: 0.57707\n",
      "[393]\ttraining's binary_logloss: 0.576992\n",
      "[394]\ttraining's binary_logloss: 0.576916\n",
      "[395]\ttraining's binary_logloss: 0.576854\n",
      "[396]\ttraining's binary_logloss: 0.576784\n",
      "[397]\ttraining's binary_logloss: 0.576709\n",
      "[398]\ttraining's binary_logloss: 0.576641\n",
      "[399]\ttraining's binary_logloss: 0.576567\n",
      "[400]\ttraining's binary_logloss: 0.576494\n",
      "[401]\ttraining's binary_logloss: 0.576411\n",
      "[402]\ttraining's binary_logloss: 0.576332\n",
      "[403]\ttraining's binary_logloss: 0.576257\n",
      "[404]\ttraining's binary_logloss: 0.576176\n",
      "[405]\ttraining's binary_logloss: 0.57609\n",
      "[406]\ttraining's binary_logloss: 0.576011\n",
      "[407]\ttraining's binary_logloss: 0.575941\n",
      "[408]\ttraining's binary_logloss: 0.575873\n",
      "[409]\ttraining's binary_logloss: 0.575774\n",
      "[410]\ttraining's binary_logloss: 0.575699\n",
      "[411]\ttraining's binary_logloss: 0.575582\n",
      "[412]\ttraining's binary_logloss: 0.575465\n",
      "[413]\ttraining's binary_logloss: 0.575354\n",
      "[414]\ttraining's binary_logloss: 0.575249\n",
      "[415]\ttraining's binary_logloss: 0.575137\n",
      "[416]\ttraining's binary_logloss: 0.575043\n",
      "[417]\ttraining's binary_logloss: 0.574954\n",
      "[418]\ttraining's binary_logloss: 0.574867\n",
      "[419]\ttraining's binary_logloss: 0.574802\n",
      "[420]\ttraining's binary_logloss: 0.574734\n",
      "[421]\ttraining's binary_logloss: 0.574699\n",
      "[422]\ttraining's binary_logloss: 0.574651\n",
      "[423]\ttraining's binary_logloss: 0.574605\n",
      "[424]\ttraining's binary_logloss: 0.574573\n",
      "[425]\ttraining's binary_logloss: 0.574529\n",
      "[426]\ttraining's binary_logloss: 0.574476\n",
      "[427]\ttraining's binary_logloss: 0.574409\n",
      "[428]\ttraining's binary_logloss: 0.57433\n",
      "[429]\ttraining's binary_logloss: 0.574253\n",
      "[430]\ttraining's binary_logloss: 0.574174\n",
      "[431]\ttraining's binary_logloss: 0.574078\n",
      "[432]\ttraining's binary_logloss: 0.573984\n",
      "[433]\ttraining's binary_logloss: 0.573891\n",
      "[434]\ttraining's binary_logloss: 0.573793\n",
      "[435]\ttraining's binary_logloss: 0.573698\n",
      "[436]\ttraining's binary_logloss: 0.573611\n",
      "[437]\ttraining's binary_logloss: 0.573524\n",
      "[438]\ttraining's binary_logloss: 0.573438\n",
      "[439]\ttraining's binary_logloss: 0.57335\n",
      "[440]\ttraining's binary_logloss: 0.573263\n",
      "[441]\ttraining's binary_logloss: 0.573183\n",
      "[442]\ttraining's binary_logloss: 0.573126\n",
      "[443]\ttraining's binary_logloss: 0.57307\n",
      "[444]\ttraining's binary_logloss: 0.573022\n",
      "[445]\ttraining's binary_logloss: 0.572961\n",
      "[446]\ttraining's binary_logloss: 0.572869\n",
      "[447]\ttraining's binary_logloss: 0.572798\n",
      "[448]\ttraining's binary_logloss: 0.572705\n",
      "[449]\ttraining's binary_logloss: 0.572617\n",
      "[450]\ttraining's binary_logloss: 0.572528\n",
      "[451]\ttraining's binary_logloss: 0.57245\n",
      "[452]\ttraining's binary_logloss: 0.572372\n",
      "[453]\ttraining's binary_logloss: 0.572289\n",
      "[454]\ttraining's binary_logloss: 0.572221\n",
      "[455]\ttraining's binary_logloss: 0.57214\n",
      "[456]\ttraining's binary_logloss: 0.57208\n",
      "[457]\ttraining's binary_logloss: 0.57202\n",
      "[458]\ttraining's binary_logloss: 0.57196\n",
      "[459]\ttraining's binary_logloss: 0.571897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[460]\ttraining's binary_logloss: 0.571841\n",
      "[461]\ttraining's binary_logloss: 0.571751\n",
      "[462]\ttraining's binary_logloss: 0.571665\n",
      "[463]\ttraining's binary_logloss: 0.571568\n",
      "[464]\ttraining's binary_logloss: 0.571468\n",
      "[465]\ttraining's binary_logloss: 0.571386\n",
      "[466]\ttraining's binary_logloss: 0.57131\n",
      "[467]\ttraining's binary_logloss: 0.571221\n",
      "[468]\ttraining's binary_logloss: 0.571124\n",
      "[469]\ttraining's binary_logloss: 0.571045\n",
      "[470]\ttraining's binary_logloss: 0.570954\n",
      "[471]\ttraining's binary_logloss: 0.570891\n",
      "[472]\ttraining's binary_logloss: 0.570814\n",
      "[473]\ttraining's binary_logloss: 0.570737\n",
      "[474]\ttraining's binary_logloss: 0.570667\n",
      "[475]\ttraining's binary_logloss: 0.570609\n",
      "[476]\ttraining's binary_logloss: 0.570547\n",
      "[477]\ttraining's binary_logloss: 0.570487\n",
      "[478]\ttraining's binary_logloss: 0.570398\n",
      "[479]\ttraining's binary_logloss: 0.570322\n",
      "[480]\ttraining's binary_logloss: 0.570264\n",
      "[481]\ttraining's binary_logloss: 0.570191\n",
      "[482]\ttraining's binary_logloss: 0.570087\n",
      "[483]\ttraining's binary_logloss: 0.569989\n",
      "[484]\ttraining's binary_logloss: 0.569905\n",
      "[485]\ttraining's binary_logloss: 0.569825\n",
      "[486]\ttraining's binary_logloss: 0.569727\n",
      "[487]\ttraining's binary_logloss: 0.569639\n",
      "[488]\ttraining's binary_logloss: 0.569547\n",
      "[489]\ttraining's binary_logloss: 0.569466\n",
      "[490]\ttraining's binary_logloss: 0.569387\n",
      "[491]\ttraining's binary_logloss: 0.569321\n",
      "[492]\ttraining's binary_logloss: 0.569258\n",
      "[493]\ttraining's binary_logloss: 0.569197\n",
      "[494]\ttraining's binary_logloss: 0.569134\n",
      "[495]\ttraining's binary_logloss: 0.569067\n",
      "[496]\ttraining's binary_logloss: 0.568955\n",
      "[497]\ttraining's binary_logloss: 0.568854\n",
      "[498]\ttraining's binary_logloss: 0.568747\n",
      "[499]\ttraining's binary_logloss: 0.568642\n",
      "[500]\ttraining's binary_logloss: 0.568524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613332\n",
      "[2]\ttraining's binary_logloss: 0.612283\n",
      "[3]\ttraining's binary_logloss: 0.611278\n",
      "[4]\ttraining's binary_logloss: 0.610315\n",
      "[5]\ttraining's binary_logloss: 0.609302\n",
      "[6]\ttraining's binary_logloss: 0.608492\n",
      "[7]\ttraining's binary_logloss: 0.607667\n",
      "[8]\ttraining's binary_logloss: 0.606909\n",
      "[9]\ttraining's binary_logloss: 0.606124\n",
      "[10]\ttraining's binary_logloss: 0.605391\n",
      "[11]\ttraining's binary_logloss: 0.604529\n",
      "[12]\ttraining's binary_logloss: 0.603714\n",
      "[13]\ttraining's binary_logloss: 0.603046\n",
      "[14]\ttraining's binary_logloss: 0.602268\n",
      "[15]\ttraining's binary_logloss: 0.601535\n",
      "[16]\ttraining's binary_logloss: 0.600987\n",
      "[17]\ttraining's binary_logloss: 0.600293\n",
      "[18]\ttraining's binary_logloss: 0.599632\n",
      "[19]\ttraining's binary_logloss: 0.598994\n",
      "[20]\ttraining's binary_logloss: 0.598501\n",
      "[21]\ttraining's binary_logloss: 0.598033\n",
      "[22]\ttraining's binary_logloss: 0.597432\n",
      "[23]\ttraining's binary_logloss: 0.596861\n",
      "[24]\ttraining's binary_logloss: 0.5963\n",
      "[25]\ttraining's binary_logloss: 0.595763\n",
      "[26]\ttraining's binary_logloss: 0.595304\n",
      "[27]\ttraining's binary_logloss: 0.594878\n",
      "[28]\ttraining's binary_logloss: 0.594441\n",
      "[29]\ttraining's binary_logloss: 0.594048\n",
      "[30]\ttraining's binary_logloss: 0.593672\n",
      "[31]\ttraining's binary_logloss: 0.593353\n",
      "[32]\ttraining's binary_logloss: 0.592974\n",
      "[33]\ttraining's binary_logloss: 0.592558\n",
      "[34]\ttraining's binary_logloss: 0.592204\n",
      "[35]\ttraining's binary_logloss: 0.591942\n",
      "[36]\ttraining's binary_logloss: 0.591558\n",
      "[37]\ttraining's binary_logloss: 0.591292\n",
      "[38]\ttraining's binary_logloss: 0.591022\n",
      "[39]\ttraining's binary_logloss: 0.590786\n",
      "[40]\ttraining's binary_logloss: 0.590592\n",
      "[41]\ttraining's binary_logloss: 0.590381\n",
      "[42]\ttraining's binary_logloss: 0.590162\n",
      "[43]\ttraining's binary_logloss: 0.589976\n",
      "[44]\ttraining's binary_logloss: 0.589781\n",
      "[45]\ttraining's binary_logloss: 0.58964\n",
      "[46]\ttraining's binary_logloss: 0.589456\n",
      "[47]\ttraining's binary_logloss: 0.589272\n",
      "[48]\ttraining's binary_logloss: 0.589019\n",
      "[49]\ttraining's binary_logloss: 0.588868\n",
      "[50]\ttraining's binary_logloss: 0.588701\n",
      "[51]\ttraining's binary_logloss: 0.588583\n",
      "[52]\ttraining's binary_logloss: 0.588403\n",
      "[53]\ttraining's binary_logloss: 0.588302\n",
      "[54]\ttraining's binary_logloss: 0.588204\n",
      "[55]\ttraining's binary_logloss: 0.588116\n",
      "[56]\ttraining's binary_logloss: 0.587871\n",
      "[57]\ttraining's binary_logloss: 0.587742\n",
      "[58]\ttraining's binary_logloss: 0.58751\n",
      "[59]\ttraining's binary_logloss: 0.587304\n",
      "[60]\ttraining's binary_logloss: 0.587098\n",
      "[61]\ttraining's binary_logloss: 0.586999\n",
      "[62]\ttraining's binary_logloss: 0.586915\n",
      "[63]\ttraining's binary_logloss: 0.586741\n",
      "[64]\ttraining's binary_logloss: 0.586694\n",
      "[65]\ttraining's binary_logloss: 0.586635\n",
      "[66]\ttraining's binary_logloss: 0.586534\n",
      "[67]\ttraining's binary_logloss: 0.586481\n",
      "[68]\ttraining's binary_logloss: 0.586397\n",
      "[69]\ttraining's binary_logloss: 0.586296\n",
      "[70]\ttraining's binary_logloss: 0.586226\n",
      "[71]\ttraining's binary_logloss: 0.586177\n",
      "[72]\ttraining's binary_logloss: 0.586134\n",
      "[73]\ttraining's binary_logloss: 0.586099\n",
      "[74]\ttraining's binary_logloss: 0.586073\n",
      "[75]\ttraining's binary_logloss: 0.586077\n",
      "[76]\ttraining's binary_logloss: 0.585966\n",
      "[77]\ttraining's binary_logloss: 0.585886\n",
      "[78]\ttraining's binary_logloss: 0.585814\n",
      "[79]\ttraining's binary_logloss: 0.585824\n",
      "[80]\ttraining's binary_logloss: 0.585762\n",
      "[81]\ttraining's binary_logloss: 0.585708\n",
      "[82]\ttraining's binary_logloss: 0.585641\n",
      "[83]\ttraining's binary_logloss: 0.585635\n",
      "[84]\ttraining's binary_logloss: 0.585581\n",
      "[85]\ttraining's binary_logloss: 0.585523\n",
      "[86]\ttraining's binary_logloss: 0.585503\n",
      "[87]\ttraining's binary_logloss: 0.58549\n",
      "[88]\ttraining's binary_logloss: 0.58546\n",
      "[89]\ttraining's binary_logloss: 0.585454\n",
      "[90]\ttraining's binary_logloss: 0.585454\n",
      "[91]\ttraining's binary_logloss: 0.585406\n",
      "[92]\ttraining's binary_logloss: 0.585366\n",
      "[93]\ttraining's binary_logloss: 0.585321\n",
      "[94]\ttraining's binary_logloss: 0.585284\n",
      "[95]\ttraining's binary_logloss: 0.585251\n",
      "[96]\ttraining's binary_logloss: 0.585283\n",
      "[97]\ttraining's binary_logloss: 0.58531\n",
      "[98]\ttraining's binary_logloss: 0.585355\n",
      "[99]\ttraining's binary_logloss: 0.585403\n",
      "[100]\ttraining's binary_logloss: 0.585448\n",
      "[101]\ttraining's binary_logloss: 0.585522\n",
      "[102]\ttraining's binary_logloss: 0.585583\n",
      "[103]\ttraining's binary_logloss: 0.58556\n",
      "[104]\ttraining's binary_logloss: 0.585627\n",
      "[105]\ttraining's binary_logloss: 0.585707\n",
      "[106]\ttraining's binary_logloss: 0.585741\n",
      "[107]\ttraining's binary_logloss: 0.58572\n",
      "[108]\ttraining's binary_logloss: 0.585776\n",
      "[109]\ttraining's binary_logloss: 0.58583\n",
      "[110]\ttraining's binary_logloss: 0.585878\n",
      "[111]\ttraining's binary_logloss: 0.585888\n",
      "[112]\ttraining's binary_logloss: 0.585901\n",
      "[113]\ttraining's binary_logloss: 0.585919\n",
      "[114]\ttraining's binary_logloss: 0.585986\n",
      "[115]\ttraining's binary_logloss: 0.586025\n",
      "[116]\ttraining's binary_logloss: 0.586036\n",
      "[117]\ttraining's binary_logloss: 0.586036\n",
      "[118]\ttraining's binary_logloss: 0.586034\n",
      "[119]\ttraining's binary_logloss: 0.586051\n",
      "[120]\ttraining's binary_logloss: 0.586062\n",
      "[121]\ttraining's binary_logloss: 0.586107\n",
      "[122]\ttraining's binary_logloss: 0.586099\n",
      "[123]\ttraining's binary_logloss: 0.586092\n",
      "[124]\ttraining's binary_logloss: 0.58609\n",
      "[125]\ttraining's binary_logloss: 0.586132\n",
      "[126]\ttraining's binary_logloss: 0.586162\n",
      "[127]\ttraining's binary_logloss: 0.586142\n",
      "[128]\ttraining's binary_logloss: 0.586126\n",
      "[129]\ttraining's binary_logloss: 0.586118\n",
      "[130]\ttraining's binary_logloss: 0.586151\n",
      "[131]\ttraining's binary_logloss: 0.586195\n",
      "[132]\ttraining's binary_logloss: 0.586239\n",
      "[133]\ttraining's binary_logloss: 0.586299\n",
      "[134]\ttraining's binary_logloss: 0.586347\n",
      "[135]\ttraining's binary_logloss: 0.5864\n",
      "[136]\ttraining's binary_logloss: 0.586408\n",
      "[137]\ttraining's binary_logloss: 0.586444\n",
      "[138]\ttraining's binary_logloss: 0.586482\n",
      "[139]\ttraining's binary_logloss: 0.586524\n",
      "[140]\ttraining's binary_logloss: 0.586571\n",
      "[141]\ttraining's binary_logloss: 0.586592\n",
      "[142]\ttraining's binary_logloss: 0.586642\n",
      "[143]\ttraining's binary_logloss: 0.586673\n",
      "[144]\ttraining's binary_logloss: 0.586707\n",
      "[145]\ttraining's binary_logloss: 0.586762\n",
      "[146]\ttraining's binary_logloss: 0.586743\n",
      "[147]\ttraining's binary_logloss: 0.586741\n",
      "[148]\ttraining's binary_logloss: 0.586743\n",
      "[149]\ttraining's binary_logloss: 0.586771\n",
      "[150]\ttraining's binary_logloss: 0.586755\n",
      "[151]\ttraining's binary_logloss: 0.586755\n",
      "[152]\ttraining's binary_logloss: 0.586757\n",
      "[153]\ttraining's binary_logloss: 0.586783\n",
      "[154]\ttraining's binary_logloss: 0.58679\n",
      "[155]\ttraining's binary_logloss: 0.58682\n",
      "[156]\ttraining's binary_logloss: 0.586871\n",
      "[157]\ttraining's binary_logloss: 0.586914\n",
      "[158]\ttraining's binary_logloss: 0.586968\n",
      "[159]\ttraining's binary_logloss: 0.587014\n",
      "[160]\ttraining's binary_logloss: 0.587083\n",
      "[161]\ttraining's binary_logloss: 0.587044\n",
      "[162]\ttraining's binary_logloss: 0.587008\n",
      "[163]\ttraining's binary_logloss: 0.587014\n",
      "[164]\ttraining's binary_logloss: 0.586986\n",
      "[165]\ttraining's binary_logloss: 0.586953\n",
      "[166]\ttraining's binary_logloss: 0.586959\n",
      "[167]\ttraining's binary_logloss: 0.586953\n",
      "[168]\ttraining's binary_logloss: 0.586955\n",
      "[169]\ttraining's binary_logloss: 0.586973\n",
      "[170]\ttraining's binary_logloss: 0.586994\n",
      "[171]\ttraining's binary_logloss: 0.587028\n",
      "[172]\ttraining's binary_logloss: 0.58706\n",
      "[173]\ttraining's binary_logloss: 0.587101\n",
      "[174]\ttraining's binary_logloss: 0.58714\n",
      "[175]\ttraining's binary_logloss: 0.58712\n",
      "[176]\ttraining's binary_logloss: 0.58712\n",
      "[177]\ttraining's binary_logloss: 0.587116\n",
      "[178]\ttraining's binary_logloss: 0.587121\n",
      "[179]\ttraining's binary_logloss: 0.587147\n",
      "[180]\ttraining's binary_logloss: 0.587176\n",
      "[181]\ttraining's binary_logloss: 0.587227\n",
      "[182]\ttraining's binary_logloss: 0.58725\n",
      "[183]\ttraining's binary_logloss: 0.587271\n",
      "[184]\ttraining's binary_logloss: 0.587325\n",
      "[185]\ttraining's binary_logloss: 0.587373\n",
      "[186]\ttraining's binary_logloss: 0.587362\n",
      "[187]\ttraining's binary_logloss: 0.587354\n",
      "[188]\ttraining's binary_logloss: 0.587345\n",
      "[189]\ttraining's binary_logloss: 0.587341\n",
      "[190]\ttraining's binary_logloss: 0.587337\n",
      "[191]\ttraining's binary_logloss: 0.587363\n",
      "[192]\ttraining's binary_logloss: 0.587368\n",
      "[193]\ttraining's binary_logloss: 0.587399\n",
      "[194]\ttraining's binary_logloss: 0.587414\n",
      "[195]\ttraining's binary_logloss: 0.587447\n",
      "[196]\ttraining's binary_logloss: 0.587462\n",
      "[197]\ttraining's binary_logloss: 0.587479\n",
      "[198]\ttraining's binary_logloss: 0.587489\n",
      "[199]\ttraining's binary_logloss: 0.587512\n",
      "[200]\ttraining's binary_logloss: 0.587537\n",
      "[201]\ttraining's binary_logloss: 0.587536\n",
      "[202]\ttraining's binary_logloss: 0.587518\n",
      "[203]\ttraining's binary_logloss: 0.587514\n",
      "[204]\ttraining's binary_logloss: 0.587517\n",
      "[205]\ttraining's binary_logloss: 0.587524\n",
      "[206]\ttraining's binary_logloss: 0.587541\n",
      "[207]\ttraining's binary_logloss: 0.587565\n",
      "[208]\ttraining's binary_logloss: 0.587586\n",
      "[209]\ttraining's binary_logloss: 0.587603\n",
      "[210]\ttraining's binary_logloss: 0.587631\n",
      "[211]\ttraining's binary_logloss: 0.587661\n",
      "[212]\ttraining's binary_logloss: 0.587688\n",
      "[213]\ttraining's binary_logloss: 0.587718\n",
      "[214]\ttraining's binary_logloss: 0.58775\n",
      "[215]\ttraining's binary_logloss: 0.587784\n",
      "[216]\ttraining's binary_logloss: 0.587745\n",
      "[217]\ttraining's binary_logloss: 0.587714\n",
      "[218]\ttraining's binary_logloss: 0.587685\n",
      "[219]\ttraining's binary_logloss: 0.587645\n",
      "[220]\ttraining's binary_logloss: 0.58762\n",
      "[221]\ttraining's binary_logloss: 0.587584\n",
      "[222]\ttraining's binary_logloss: 0.587554\n",
      "[223]\ttraining's binary_logloss: 0.587519\n",
      "[224]\ttraining's binary_logloss: 0.587485\n",
      "[225]\ttraining's binary_logloss: 0.587454\n",
      "[226]\ttraining's binary_logloss: 0.587444\n",
      "[227]\ttraining's binary_logloss: 0.587436\n",
      "[228]\ttraining's binary_logloss: 0.587433\n",
      "[229]\ttraining's binary_logloss: 0.587427\n",
      "[230]\ttraining's binary_logloss: 0.587425\n",
      "[231]\ttraining's binary_logloss: 0.587428\n",
      "[232]\ttraining's binary_logloss: 0.587436\n",
      "[233]\ttraining's binary_logloss: 0.587443\n",
      "[234]\ttraining's binary_logloss: 0.587446\n",
      "[235]\ttraining's binary_logloss: 0.587457\n",
      "[236]\ttraining's binary_logloss: 0.587439\n",
      "[237]\ttraining's binary_logloss: 0.587427\n",
      "[238]\ttraining's binary_logloss: 0.58741\n",
      "[239]\ttraining's binary_logloss: 0.587389\n",
      "[240]\ttraining's binary_logloss: 0.587363\n",
      "[241]\ttraining's binary_logloss: 0.587316\n",
      "[242]\ttraining's binary_logloss: 0.587276\n",
      "[243]\ttraining's binary_logloss: 0.587231\n",
      "[244]\ttraining's binary_logloss: 0.587195\n",
      "[245]\ttraining's binary_logloss: 0.58714\n",
      "[246]\ttraining's binary_logloss: 0.587057\n",
      "[247]\ttraining's binary_logloss: 0.586977\n",
      "[248]\ttraining's binary_logloss: 0.586899\n",
      "[249]\ttraining's binary_logloss: 0.58683\n",
      "[250]\ttraining's binary_logloss: 0.586768\n",
      "[251]\ttraining's binary_logloss: 0.586778\n",
      "[252]\ttraining's binary_logloss: 0.586765\n",
      "[253]\ttraining's binary_logloss: 0.586765\n",
      "[254]\ttraining's binary_logloss: 0.58676\n",
      "[255]\ttraining's binary_logloss: 0.586754\n",
      "[256]\ttraining's binary_logloss: 0.586706\n",
      "[257]\ttraining's binary_logloss: 0.586652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[258]\ttraining's binary_logloss: 0.586621\n",
      "[259]\ttraining's binary_logloss: 0.586588\n",
      "[260]\ttraining's binary_logloss: 0.586538\n",
      "[261]\ttraining's binary_logloss: 0.586506\n",
      "[262]\ttraining's binary_logloss: 0.586486\n",
      "[263]\ttraining's binary_logloss: 0.586483\n",
      "[264]\ttraining's binary_logloss: 0.58647\n",
      "[265]\ttraining's binary_logloss: 0.586439\n",
      "[266]\ttraining's binary_logloss: 0.586443\n",
      "[267]\ttraining's binary_logloss: 0.586444\n",
      "[268]\ttraining's binary_logloss: 0.58645\n",
      "[269]\ttraining's binary_logloss: 0.586447\n",
      "[270]\ttraining's binary_logloss: 0.58645\n",
      "[271]\ttraining's binary_logloss: 0.58638\n",
      "[272]\ttraining's binary_logloss: 0.586294\n",
      "[273]\ttraining's binary_logloss: 0.586208\n",
      "[274]\ttraining's binary_logloss: 0.586127\n",
      "[275]\ttraining's binary_logloss: 0.586046\n",
      "[276]\ttraining's binary_logloss: 0.586004\n",
      "[277]\ttraining's binary_logloss: 0.585965\n",
      "[278]\ttraining's binary_logloss: 0.585937\n",
      "[279]\ttraining's binary_logloss: 0.585896\n",
      "[280]\ttraining's binary_logloss: 0.585869\n",
      "[281]\ttraining's binary_logloss: 0.585811\n",
      "[282]\ttraining's binary_logloss: 0.585755\n",
      "[283]\ttraining's binary_logloss: 0.585702\n",
      "[284]\ttraining's binary_logloss: 0.585652\n",
      "[285]\ttraining's binary_logloss: 0.585588\n",
      "[286]\ttraining's binary_logloss: 0.585528\n",
      "[287]\ttraining's binary_logloss: 0.585431\n",
      "[288]\ttraining's binary_logloss: 0.585337\n",
      "[289]\ttraining's binary_logloss: 0.585258\n",
      "[290]\ttraining's binary_logloss: 0.58517\n",
      "[291]\ttraining's binary_logloss: 0.585079\n",
      "[292]\ttraining's binary_logloss: 0.584995\n",
      "[293]\ttraining's binary_logloss: 0.584916\n",
      "[294]\ttraining's binary_logloss: 0.584832\n",
      "[295]\ttraining's binary_logloss: 0.584736\n",
      "[296]\ttraining's binary_logloss: 0.584668\n",
      "[297]\ttraining's binary_logloss: 0.584596\n",
      "[298]\ttraining's binary_logloss: 0.584533\n",
      "[299]\ttraining's binary_logloss: 0.584484\n",
      "[300]\ttraining's binary_logloss: 0.584421\n",
      "[301]\ttraining's binary_logloss: 0.584392\n",
      "[302]\ttraining's binary_logloss: 0.584351\n",
      "[303]\ttraining's binary_logloss: 0.584313\n",
      "[304]\ttraining's binary_logloss: 0.584276\n",
      "[305]\ttraining's binary_logloss: 0.584246\n",
      "[306]\ttraining's binary_logloss: 0.58418\n",
      "[307]\ttraining's binary_logloss: 0.584149\n",
      "[308]\ttraining's binary_logloss: 0.584108\n",
      "[309]\ttraining's binary_logloss: 0.584079\n",
      "[310]\ttraining's binary_logloss: 0.584049\n",
      "[311]\ttraining's binary_logloss: 0.583989\n",
      "[312]\ttraining's binary_logloss: 0.583934\n",
      "[313]\ttraining's binary_logloss: 0.583883\n",
      "[314]\ttraining's binary_logloss: 0.58382\n",
      "[315]\ttraining's binary_logloss: 0.58377\n",
      "[316]\ttraining's binary_logloss: 0.583692\n",
      "[317]\ttraining's binary_logloss: 0.583625\n",
      "[318]\ttraining's binary_logloss: 0.583555\n",
      "[319]\ttraining's binary_logloss: 0.583492\n",
      "[320]\ttraining's binary_logloss: 0.583427\n",
      "[321]\ttraining's binary_logloss: 0.583386\n",
      "[322]\ttraining's binary_logloss: 0.583359\n",
      "[323]\ttraining's binary_logloss: 0.583323\n",
      "[324]\ttraining's binary_logloss: 0.583291\n",
      "[325]\ttraining's binary_logloss: 0.583259\n",
      "[326]\ttraining's binary_logloss: 0.58318\n",
      "[327]\ttraining's binary_logloss: 0.583098\n",
      "[328]\ttraining's binary_logloss: 0.583019\n",
      "[329]\ttraining's binary_logloss: 0.582943\n",
      "[330]\ttraining's binary_logloss: 0.582869\n",
      "[331]\ttraining's binary_logloss: 0.582813\n",
      "[332]\ttraining's binary_logloss: 0.582758\n",
      "[333]\ttraining's binary_logloss: 0.582704\n",
      "[334]\ttraining's binary_logloss: 0.582657\n",
      "[335]\ttraining's binary_logloss: 0.582606\n",
      "[336]\ttraining's binary_logloss: 0.58251\n",
      "[337]\ttraining's binary_logloss: 0.582423\n",
      "[338]\ttraining's binary_logloss: 0.582339\n",
      "[339]\ttraining's binary_logloss: 0.582277\n",
      "[340]\ttraining's binary_logloss: 0.582219\n",
      "[341]\ttraining's binary_logloss: 0.582196\n",
      "[342]\ttraining's binary_logloss: 0.582166\n",
      "[343]\ttraining's binary_logloss: 0.582135\n",
      "[344]\ttraining's binary_logloss: 0.58211\n",
      "[345]\ttraining's binary_logloss: 0.582086\n",
      "[346]\ttraining's binary_logloss: 0.582052\n",
      "[347]\ttraining's binary_logloss: 0.582023\n",
      "[348]\ttraining's binary_logloss: 0.581968\n",
      "[349]\ttraining's binary_logloss: 0.5819\n",
      "[350]\ttraining's binary_logloss: 0.581866\n",
      "[351]\ttraining's binary_logloss: 0.581779\n",
      "[352]\ttraining's binary_logloss: 0.581682\n",
      "[353]\ttraining's binary_logloss: 0.58159\n",
      "[354]\ttraining's binary_logloss: 0.581501\n",
      "[355]\ttraining's binary_logloss: 0.581413\n",
      "[356]\ttraining's binary_logloss: 0.581338\n",
      "[357]\ttraining's binary_logloss: 0.581248\n",
      "[358]\ttraining's binary_logloss: 0.581175\n",
      "[359]\ttraining's binary_logloss: 0.581086\n",
      "[360]\ttraining's binary_logloss: 0.581012\n",
      "[361]\ttraining's binary_logloss: 0.580896\n",
      "[362]\ttraining's binary_logloss: 0.580782\n",
      "[363]\ttraining's binary_logloss: 0.580664\n",
      "[364]\ttraining's binary_logloss: 0.580548\n",
      "[365]\ttraining's binary_logloss: 0.580435\n",
      "[366]\ttraining's binary_logloss: 0.580369\n",
      "[367]\ttraining's binary_logloss: 0.580294\n",
      "[368]\ttraining's binary_logloss: 0.58022\n",
      "[369]\ttraining's binary_logloss: 0.580161\n",
      "[370]\ttraining's binary_logloss: 0.580092\n",
      "[371]\ttraining's binary_logloss: 0.580029\n",
      "[372]\ttraining's binary_logloss: 0.579965\n",
      "[373]\ttraining's binary_logloss: 0.579901\n",
      "[374]\ttraining's binary_logloss: 0.57985\n",
      "[375]\ttraining's binary_logloss: 0.579802\n",
      "[376]\ttraining's binary_logloss: 0.579733\n",
      "[377]\ttraining's binary_logloss: 0.579664\n",
      "[378]\ttraining's binary_logloss: 0.579602\n",
      "[379]\ttraining's binary_logloss: 0.579544\n",
      "[380]\ttraining's binary_logloss: 0.579484\n",
      "[381]\ttraining's binary_logloss: 0.579458\n",
      "[382]\ttraining's binary_logloss: 0.579428\n",
      "[383]\ttraining's binary_logloss: 0.579408\n",
      "[384]\ttraining's binary_logloss: 0.579385\n",
      "[385]\ttraining's binary_logloss: 0.579355\n",
      "[386]\ttraining's binary_logloss: 0.579258\n",
      "[387]\ttraining's binary_logloss: 0.579164\n",
      "[388]\ttraining's binary_logloss: 0.579081\n",
      "[389]\ttraining's binary_logloss: 0.578994\n",
      "[390]\ttraining's binary_logloss: 0.578909\n",
      "[391]\ttraining's binary_logloss: 0.578816\n",
      "[392]\ttraining's binary_logloss: 0.578721\n",
      "[393]\ttraining's binary_logloss: 0.578624\n",
      "[394]\ttraining's binary_logloss: 0.578529\n",
      "[395]\ttraining's binary_logloss: 0.578444\n",
      "[396]\ttraining's binary_logloss: 0.578399\n",
      "[397]\ttraining's binary_logloss: 0.578354\n",
      "[398]\ttraining's binary_logloss: 0.578309\n",
      "[399]\ttraining's binary_logloss: 0.578267\n",
      "[400]\ttraining's binary_logloss: 0.578226\n",
      "[401]\ttraining's binary_logloss: 0.578153\n",
      "[402]\ttraining's binary_logloss: 0.578067\n",
      "[403]\ttraining's binary_logloss: 0.577979\n",
      "[404]\ttraining's binary_logloss: 0.577892\n",
      "[405]\ttraining's binary_logloss: 0.577818\n",
      "[406]\ttraining's binary_logloss: 0.577745\n",
      "[407]\ttraining's binary_logloss: 0.577667\n",
      "[408]\ttraining's binary_logloss: 0.577591\n",
      "[409]\ttraining's binary_logloss: 0.577528\n",
      "[410]\ttraining's binary_logloss: 0.577455\n",
      "[411]\ttraining's binary_logloss: 0.577374\n",
      "[412]\ttraining's binary_logloss: 0.577274\n",
      "[413]\ttraining's binary_logloss: 0.577193\n",
      "[414]\ttraining's binary_logloss: 0.577119\n",
      "[415]\ttraining's binary_logloss: 0.577041\n",
      "[416]\ttraining's binary_logloss: 0.576973\n",
      "[417]\ttraining's binary_logloss: 0.576907\n",
      "[418]\ttraining's binary_logloss: 0.576838\n",
      "[419]\ttraining's binary_logloss: 0.576773\n",
      "[420]\ttraining's binary_logloss: 0.576714\n",
      "[421]\ttraining's binary_logloss: 0.576684\n",
      "[422]\ttraining's binary_logloss: 0.576656\n",
      "[423]\ttraining's binary_logloss: 0.57662\n",
      "[424]\ttraining's binary_logloss: 0.576589\n",
      "[425]\ttraining's binary_logloss: 0.576552\n",
      "[426]\ttraining's binary_logloss: 0.576471\n",
      "[427]\ttraining's binary_logloss: 0.576392\n",
      "[428]\ttraining's binary_logloss: 0.576305\n",
      "[429]\ttraining's binary_logloss: 0.576225\n",
      "[430]\ttraining's binary_logloss: 0.576143\n",
      "[431]\ttraining's binary_logloss: 0.576056\n",
      "[432]\ttraining's binary_logloss: 0.575965\n",
      "[433]\ttraining's binary_logloss: 0.575878\n",
      "[434]\ttraining's binary_logloss: 0.575791\n",
      "[435]\ttraining's binary_logloss: 0.575692\n",
      "[436]\ttraining's binary_logloss: 0.575626\n",
      "[437]\ttraining's binary_logloss: 0.575565\n",
      "[438]\ttraining's binary_logloss: 0.575518\n",
      "[439]\ttraining's binary_logloss: 0.575463\n",
      "[440]\ttraining's binary_logloss: 0.575414\n",
      "[441]\ttraining's binary_logloss: 0.575349\n",
      "[442]\ttraining's binary_logloss: 0.57529\n",
      "[443]\ttraining's binary_logloss: 0.575227\n",
      "[444]\ttraining's binary_logloss: 0.575169\n",
      "[445]\ttraining's binary_logloss: 0.575113\n",
      "[446]\ttraining's binary_logloss: 0.575025\n",
      "[447]\ttraining's binary_logloss: 0.574947\n",
      "[448]\ttraining's binary_logloss: 0.574873\n",
      "[449]\ttraining's binary_logloss: 0.574789\n",
      "[450]\ttraining's binary_logloss: 0.574706\n",
      "[451]\ttraining's binary_logloss: 0.574652\n",
      "[452]\ttraining's binary_logloss: 0.574589\n",
      "[453]\ttraining's binary_logloss: 0.574537\n",
      "[454]\ttraining's binary_logloss: 0.574488\n",
      "[455]\ttraining's binary_logloss: 0.574441\n",
      "[456]\ttraining's binary_logloss: 0.574379\n",
      "[457]\ttraining's binary_logloss: 0.574309\n",
      "[458]\ttraining's binary_logloss: 0.574248\n",
      "[459]\ttraining's binary_logloss: 0.57419\n",
      "[460]\ttraining's binary_logloss: 0.574122\n",
      "[461]\ttraining's binary_logloss: 0.574062\n",
      "[462]\ttraining's binary_logloss: 0.573994\n",
      "[463]\ttraining's binary_logloss: 0.573937\n",
      "[464]\ttraining's binary_logloss: 0.57388\n",
      "[465]\ttraining's binary_logloss: 0.573818\n",
      "[466]\ttraining's binary_logloss: 0.573751\n",
      "[467]\ttraining's binary_logloss: 0.573663\n",
      "[468]\ttraining's binary_logloss: 0.573583\n",
      "[469]\ttraining's binary_logloss: 0.573508\n",
      "[470]\ttraining's binary_logloss: 0.57343\n",
      "[471]\ttraining's binary_logloss: 0.573368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[472]\ttraining's binary_logloss: 0.573308\n",
      "[473]\ttraining's binary_logloss: 0.573249\n",
      "[474]\ttraining's binary_logloss: 0.573212\n",
      "[475]\ttraining's binary_logloss: 0.573159\n",
      "[476]\ttraining's binary_logloss: 0.573079\n",
      "[477]\ttraining's binary_logloss: 0.573015\n",
      "[478]\ttraining's binary_logloss: 0.572935\n",
      "[479]\ttraining's binary_logloss: 0.572876\n",
      "[480]\ttraining's binary_logloss: 0.572802\n",
      "[481]\ttraining's binary_logloss: 0.572728\n",
      "[482]\ttraining's binary_logloss: 0.572653\n",
      "[483]\ttraining's binary_logloss: 0.572581\n",
      "[484]\ttraining's binary_logloss: 0.572519\n",
      "[485]\ttraining's binary_logloss: 0.572451\n",
      "[486]\ttraining's binary_logloss: 0.572338\n",
      "[487]\ttraining's binary_logloss: 0.572226\n",
      "[488]\ttraining's binary_logloss: 0.572117\n",
      "[489]\ttraining's binary_logloss: 0.572004\n",
      "[490]\ttraining's binary_logloss: 0.571895\n",
      "[491]\ttraining's binary_logloss: 0.571812\n",
      "[492]\ttraining's binary_logloss: 0.571734\n",
      "[493]\ttraining's binary_logloss: 0.571648\n",
      "[494]\ttraining's binary_logloss: 0.571569\n",
      "[495]\ttraining's binary_logloss: 0.571495\n",
      "[496]\ttraining's binary_logloss: 0.57142\n",
      "[497]\ttraining's binary_logloss: 0.571328\n",
      "[498]\ttraining's binary_logloss: 0.571239\n",
      "[499]\ttraining's binary_logloss: 0.571153\n",
      "[500]\ttraining's binary_logloss: 0.571088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.617701\n",
      "[2]\ttraining's binary_logloss: 0.61669\n",
      "[3]\ttraining's binary_logloss: 0.615834\n",
      "[4]\ttraining's binary_logloss: 0.61486\n",
      "[5]\ttraining's binary_logloss: 0.613937\n",
      "[6]\ttraining's binary_logloss: 0.613041\n",
      "[7]\ttraining's binary_logloss: 0.612183\n",
      "[8]\ttraining's binary_logloss: 0.611359\n",
      "[9]\ttraining's binary_logloss: 0.610565\n",
      "[10]\ttraining's binary_logloss: 0.609817\n",
      "[11]\ttraining's binary_logloss: 0.609032\n",
      "[12]\ttraining's binary_logloss: 0.608312\n",
      "[13]\ttraining's binary_logloss: 0.60758\n",
      "[14]\ttraining's binary_logloss: 0.606802\n",
      "[15]\ttraining's binary_logloss: 0.60612\n",
      "[16]\ttraining's binary_logloss: 0.60552\n",
      "[17]\ttraining's binary_logloss: 0.604931\n",
      "[18]\ttraining's binary_logloss: 0.604278\n",
      "[19]\ttraining's binary_logloss: 0.603649\n",
      "[20]\ttraining's binary_logloss: 0.603045\n",
      "[21]\ttraining's binary_logloss: 0.602424\n",
      "[22]\ttraining's binary_logloss: 0.601917\n",
      "[23]\ttraining's binary_logloss: 0.601333\n",
      "[24]\ttraining's binary_logloss: 0.600778\n",
      "[25]\ttraining's binary_logloss: 0.600281\n",
      "[26]\ttraining's binary_logloss: 0.599815\n",
      "[27]\ttraining's binary_logloss: 0.599376\n",
      "[28]\ttraining's binary_logloss: 0.598954\n",
      "[29]\ttraining's binary_logloss: 0.598622\n",
      "[30]\ttraining's binary_logloss: 0.598231\n",
      "[31]\ttraining's binary_logloss: 0.59786\n",
      "[32]\ttraining's binary_logloss: 0.59748\n",
      "[33]\ttraining's binary_logloss: 0.597182\n",
      "[34]\ttraining's binary_logloss: 0.596855\n",
      "[35]\ttraining's binary_logloss: 0.596537\n",
      "[36]\ttraining's binary_logloss: 0.596242\n",
      "[37]\ttraining's binary_logloss: 0.595919\n",
      "[38]\ttraining's binary_logloss: 0.595656\n",
      "[39]\ttraining's binary_logloss: 0.595403\n",
      "[40]\ttraining's binary_logloss: 0.595163\n",
      "[41]\ttraining's binary_logloss: 0.594964\n",
      "[42]\ttraining's binary_logloss: 0.594694\n",
      "[43]\ttraining's binary_logloss: 0.59453\n",
      "[44]\ttraining's binary_logloss: 0.594303\n",
      "[45]\ttraining's binary_logloss: 0.594158\n",
      "[46]\ttraining's binary_logloss: 0.593867\n",
      "[47]\ttraining's binary_logloss: 0.593589\n",
      "[48]\ttraining's binary_logloss: 0.593418\n",
      "[49]\ttraining's binary_logloss: 0.593154\n",
      "[50]\ttraining's binary_logloss: 0.592898\n",
      "[51]\ttraining's binary_logloss: 0.592764\n",
      "[52]\ttraining's binary_logloss: 0.59262\n",
      "[53]\ttraining's binary_logloss: 0.592425\n",
      "[54]\ttraining's binary_logloss: 0.592304\n",
      "[55]\ttraining's binary_logloss: 0.59213\n",
      "[56]\ttraining's binary_logloss: 0.592043\n",
      "[57]\ttraining's binary_logloss: 0.591906\n",
      "[58]\ttraining's binary_logloss: 0.59177\n",
      "[59]\ttraining's binary_logloss: 0.591648\n",
      "[60]\ttraining's binary_logloss: 0.591548\n",
      "[61]\ttraining's binary_logloss: 0.591422\n",
      "[62]\ttraining's binary_logloss: 0.591319\n",
      "[63]\ttraining's binary_logloss: 0.591188\n",
      "[64]\ttraining's binary_logloss: 0.591097\n",
      "[65]\ttraining's binary_logloss: 0.590965\n",
      "[66]\ttraining's binary_logloss: 0.590884\n",
      "[67]\ttraining's binary_logloss: 0.590835\n",
      "[68]\ttraining's binary_logloss: 0.590767\n",
      "[69]\ttraining's binary_logloss: 0.590697\n",
      "[70]\ttraining's binary_logloss: 0.590645\n",
      "[71]\ttraining's binary_logloss: 0.59059\n",
      "[72]\ttraining's binary_logloss: 0.590523\n",
      "[73]\ttraining's binary_logloss: 0.590428\n",
      "[74]\ttraining's binary_logloss: 0.590343\n",
      "[75]\ttraining's binary_logloss: 0.590297\n",
      "[76]\ttraining's binary_logloss: 0.590222\n",
      "[77]\ttraining's binary_logloss: 0.590154\n",
      "[78]\ttraining's binary_logloss: 0.59015\n",
      "[79]\ttraining's binary_logloss: 0.590096\n",
      "[80]\ttraining's binary_logloss: 0.590047\n",
      "[81]\ttraining's binary_logloss: 0.590028\n",
      "[82]\ttraining's binary_logloss: 0.589984\n",
      "[83]\ttraining's binary_logloss: 0.589988\n",
      "[84]\ttraining's binary_logloss: 0.589932\n",
      "[85]\ttraining's binary_logloss: 0.589881\n",
      "[86]\ttraining's binary_logloss: 0.589875\n",
      "[87]\ttraining's binary_logloss: 0.589875\n",
      "[88]\ttraining's binary_logloss: 0.589878\n",
      "[89]\ttraining's binary_logloss: 0.589891\n",
      "[90]\ttraining's binary_logloss: 0.589904\n",
      "[91]\ttraining's binary_logloss: 0.589825\n",
      "[92]\ttraining's binary_logloss: 0.589756\n",
      "[93]\ttraining's binary_logloss: 0.589692\n",
      "[94]\ttraining's binary_logloss: 0.589628\n",
      "[95]\ttraining's binary_logloss: 0.589582\n",
      "[96]\ttraining's binary_logloss: 0.58955\n",
      "[97]\ttraining's binary_logloss: 0.589582\n",
      "[98]\ttraining's binary_logloss: 0.589573\n",
      "[99]\ttraining's binary_logloss: 0.589544\n",
      "[100]\ttraining's binary_logloss: 0.589576\n",
      "[101]\ttraining's binary_logloss: 0.58962\n",
      "[102]\ttraining's binary_logloss: 0.589647\n",
      "[103]\ttraining's binary_logloss: 0.589666\n",
      "[104]\ttraining's binary_logloss: 0.589709\n",
      "[105]\ttraining's binary_logloss: 0.589756\n",
      "[106]\ttraining's binary_logloss: 0.589712\n",
      "[107]\ttraining's binary_logloss: 0.589681\n",
      "[108]\ttraining's binary_logloss: 0.589645\n",
      "[109]\ttraining's binary_logloss: 0.589623\n",
      "[110]\ttraining's binary_logloss: 0.589597\n",
      "[111]\ttraining's binary_logloss: 0.589638\n",
      "[112]\ttraining's binary_logloss: 0.589683\n",
      "[113]\ttraining's binary_logloss: 0.589699\n",
      "[114]\ttraining's binary_logloss: 0.589746\n",
      "[115]\ttraining's binary_logloss: 0.589763\n",
      "[116]\ttraining's binary_logloss: 0.589738\n",
      "[117]\ttraining's binary_logloss: 0.589717\n",
      "[118]\ttraining's binary_logloss: 0.589708\n",
      "[119]\ttraining's binary_logloss: 0.589714\n",
      "[120]\ttraining's binary_logloss: 0.589739\n",
      "[121]\ttraining's binary_logloss: 0.589752\n",
      "[122]\ttraining's binary_logloss: 0.589769\n",
      "[123]\ttraining's binary_logloss: 0.589804\n",
      "[124]\ttraining's binary_logloss: 0.589835\n",
      "[125]\ttraining's binary_logloss: 0.58982\n",
      "[126]\ttraining's binary_logloss: 0.589861\n",
      "[127]\ttraining's binary_logloss: 0.589915\n",
      "[128]\ttraining's binary_logloss: 0.589942\n",
      "[129]\ttraining's binary_logloss: 0.589981\n",
      "[130]\ttraining's binary_logloss: 0.590015\n",
      "[131]\ttraining's binary_logloss: 0.589986\n",
      "[132]\ttraining's binary_logloss: 0.589961\n",
      "[133]\ttraining's binary_logloss: 0.58994\n",
      "[134]\ttraining's binary_logloss: 0.589925\n",
      "[135]\ttraining's binary_logloss: 0.589911\n",
      "[136]\ttraining's binary_logloss: 0.589947\n",
      "[137]\ttraining's binary_logloss: 0.589981\n",
      "[138]\ttraining's binary_logloss: 0.590014\n",
      "[139]\ttraining's binary_logloss: 0.590056\n",
      "[140]\ttraining's binary_logloss: 0.5901\n",
      "[141]\ttraining's binary_logloss: 0.590105\n",
      "[142]\ttraining's binary_logloss: 0.590103\n",
      "[143]\ttraining's binary_logloss: 0.590094\n",
      "[144]\ttraining's binary_logloss: 0.590095\n",
      "[145]\ttraining's binary_logloss: 0.590071\n",
      "[146]\ttraining's binary_logloss: 0.590076\n",
      "[147]\ttraining's binary_logloss: 0.59012\n",
      "[148]\ttraining's binary_logloss: 0.590125\n",
      "[149]\ttraining's binary_logloss: 0.590125\n",
      "[150]\ttraining's binary_logloss: 0.590128\n",
      "[151]\ttraining's binary_logloss: 0.590166\n",
      "[152]\ttraining's binary_logloss: 0.590204\n",
      "[153]\ttraining's binary_logloss: 0.590246\n",
      "[154]\ttraining's binary_logloss: 0.590299\n",
      "[155]\ttraining's binary_logloss: 0.590336\n",
      "[156]\ttraining's binary_logloss: 0.590359\n",
      "[157]\ttraining's binary_logloss: 0.590382\n",
      "[158]\ttraining's binary_logloss: 0.590412\n",
      "[159]\ttraining's binary_logloss: 0.590444\n",
      "[160]\ttraining's binary_logloss: 0.590459\n",
      "[161]\ttraining's binary_logloss: 0.590422\n",
      "[162]\ttraining's binary_logloss: 0.590432\n",
      "[163]\ttraining's binary_logloss: 0.590394\n",
      "[164]\ttraining's binary_logloss: 0.590394\n",
      "[165]\ttraining's binary_logloss: 0.590359\n",
      "[166]\ttraining's binary_logloss: 0.590335\n",
      "[167]\ttraining's binary_logloss: 0.590313\n",
      "[168]\ttraining's binary_logloss: 0.590313\n",
      "[169]\ttraining's binary_logloss: 0.590299\n",
      "[170]\ttraining's binary_logloss: 0.590288\n",
      "[171]\ttraining's binary_logloss: 0.590316\n",
      "[172]\ttraining's binary_logloss: 0.590337\n",
      "[173]\ttraining's binary_logloss: 0.590303\n",
      "[174]\ttraining's binary_logloss: 0.590325\n",
      "[175]\ttraining's binary_logloss: 0.590293\n",
      "[176]\ttraining's binary_logloss: 0.590294\n",
      "[177]\ttraining's binary_logloss: 0.590299\n",
      "[178]\ttraining's binary_logloss: 0.590302\n",
      "[179]\ttraining's binary_logloss: 0.590306\n",
      "[180]\ttraining's binary_logloss: 0.590311\n",
      "[181]\ttraining's binary_logloss: 0.590346\n",
      "[182]\ttraining's binary_logloss: 0.590349\n",
      "[183]\ttraining's binary_logloss: 0.590328\n",
      "[184]\ttraining's binary_logloss: 0.590331\n",
      "[185]\ttraining's binary_logloss: 0.590376\n",
      "[186]\ttraining's binary_logloss: 0.590396\n",
      "[187]\ttraining's binary_logloss: 0.590419\n",
      "[188]\ttraining's binary_logloss: 0.590441\n",
      "[189]\ttraining's binary_logloss: 0.59046\n",
      "[190]\ttraining's binary_logloss: 0.590485\n",
      "[191]\ttraining's binary_logloss: 0.59049\n",
      "[192]\ttraining's binary_logloss: 0.590513\n",
      "[193]\ttraining's binary_logloss: 0.590492\n",
      "[194]\ttraining's binary_logloss: 0.590486\n",
      "[195]\ttraining's binary_logloss: 0.590458\n",
      "[196]\ttraining's binary_logloss: 0.590429\n",
      "[197]\ttraining's binary_logloss: 0.590406\n",
      "[198]\ttraining's binary_logloss: 0.590383\n",
      "[199]\ttraining's binary_logloss: 0.590365\n",
      "[200]\ttraining's binary_logloss: 0.590364\n",
      "[201]\ttraining's binary_logloss: 0.590342\n",
      "[202]\ttraining's binary_logloss: 0.590347\n",
      "[203]\ttraining's binary_logloss: 0.590311\n",
      "[204]\ttraining's binary_logloss: 0.590281\n",
      "[205]\ttraining's binary_logloss: 0.590287\n",
      "[206]\ttraining's binary_logloss: 0.590287\n",
      "[207]\ttraining's binary_logloss: 0.590308\n",
      "[208]\ttraining's binary_logloss: 0.590304\n",
      "[209]\ttraining's binary_logloss: 0.590331\n",
      "[210]\ttraining's binary_logloss: 0.590348\n",
      "[211]\ttraining's binary_logloss: 0.590345\n",
      "[212]\ttraining's binary_logloss: 0.590345\n",
      "[213]\ttraining's binary_logloss: 0.590349\n",
      "[214]\ttraining's binary_logloss: 0.59036\n",
      "[215]\ttraining's binary_logloss: 0.590365\n",
      "[216]\ttraining's binary_logloss: 0.590346\n",
      "[217]\ttraining's binary_logloss: 0.590316\n",
      "[218]\ttraining's binary_logloss: 0.590299\n",
      "[219]\ttraining's binary_logloss: 0.590262\n",
      "[220]\ttraining's binary_logloss: 0.590235\n",
      "[221]\ttraining's binary_logloss: 0.590227\n",
      "[222]\ttraining's binary_logloss: 0.590202\n",
      "[223]\ttraining's binary_logloss: 0.590165\n",
      "[224]\ttraining's binary_logloss: 0.590137\n",
      "[225]\ttraining's binary_logloss: 0.590114\n",
      "[226]\ttraining's binary_logloss: 0.590082\n",
      "[227]\ttraining's binary_logloss: 0.590053\n",
      "[228]\ttraining's binary_logloss: 0.590016\n",
      "[229]\ttraining's binary_logloss: 0.589988\n",
      "[230]\ttraining's binary_logloss: 0.589965\n",
      "[231]\ttraining's binary_logloss: 0.589951\n",
      "[232]\ttraining's binary_logloss: 0.589959\n",
      "[233]\ttraining's binary_logloss: 0.589944\n",
      "[234]\ttraining's binary_logloss: 0.589945\n",
      "[235]\ttraining's binary_logloss: 0.589945\n",
      "[236]\ttraining's binary_logloss: 0.589905\n",
      "[237]\ttraining's binary_logloss: 0.58987\n",
      "[238]\ttraining's binary_logloss: 0.589831\n",
      "[239]\ttraining's binary_logloss: 0.589799\n",
      "[240]\ttraining's binary_logloss: 0.589766\n",
      "[241]\ttraining's binary_logloss: 0.589706\n",
      "[242]\ttraining's binary_logloss: 0.589664\n",
      "[243]\ttraining's binary_logloss: 0.589605\n",
      "[244]\ttraining's binary_logloss: 0.589585\n",
      "[245]\ttraining's binary_logloss: 0.589528\n",
      "[246]\ttraining's binary_logloss: 0.589485\n",
      "[247]\ttraining's binary_logloss: 0.589434\n",
      "[248]\ttraining's binary_logloss: 0.589383\n",
      "[249]\ttraining's binary_logloss: 0.589328\n",
      "[250]\ttraining's binary_logloss: 0.589266\n",
      "[251]\ttraining's binary_logloss: 0.589244\n",
      "[252]\ttraining's binary_logloss: 0.589238\n",
      "[253]\ttraining's binary_logloss: 0.589233\n",
      "[254]\ttraining's binary_logloss: 0.589201\n",
      "[255]\ttraining's binary_logloss: 0.589177\n",
      "[256]\ttraining's binary_logloss: 0.589117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[257]\ttraining's binary_logloss: 0.589057\n",
      "[258]\ttraining's binary_logloss: 0.589023\n",
      "[259]\ttraining's binary_logloss: 0.588966\n",
      "[260]\ttraining's binary_logloss: 0.588911\n",
      "[261]\ttraining's binary_logloss: 0.588878\n",
      "[262]\ttraining's binary_logloss: 0.588814\n",
      "[263]\ttraining's binary_logloss: 0.588734\n",
      "[264]\ttraining's binary_logloss: 0.588651\n",
      "[265]\ttraining's binary_logloss: 0.588585\n",
      "[266]\ttraining's binary_logloss: 0.588567\n",
      "[267]\ttraining's binary_logloss: 0.588548\n",
      "[268]\ttraining's binary_logloss: 0.588536\n",
      "[269]\ttraining's binary_logloss: 0.588521\n",
      "[270]\ttraining's binary_logloss: 0.588504\n",
      "[271]\ttraining's binary_logloss: 0.588484\n",
      "[272]\ttraining's binary_logloss: 0.588446\n",
      "[273]\ttraining's binary_logloss: 0.588395\n",
      "[274]\ttraining's binary_logloss: 0.588349\n",
      "[275]\ttraining's binary_logloss: 0.588304\n",
      "[276]\ttraining's binary_logloss: 0.58828\n",
      "[277]\ttraining's binary_logloss: 0.588242\n",
      "[278]\ttraining's binary_logloss: 0.588207\n",
      "[279]\ttraining's binary_logloss: 0.588172\n",
      "[280]\ttraining's binary_logloss: 0.588121\n",
      "[281]\ttraining's binary_logloss: 0.588065\n",
      "[282]\ttraining's binary_logloss: 0.588024\n",
      "[283]\ttraining's binary_logloss: 0.58797\n",
      "[284]\ttraining's binary_logloss: 0.587917\n",
      "[285]\ttraining's binary_logloss: 0.58787\n",
      "[286]\ttraining's binary_logloss: 0.587797\n",
      "[287]\ttraining's binary_logloss: 0.587731\n",
      "[288]\ttraining's binary_logloss: 0.587661\n",
      "[289]\ttraining's binary_logloss: 0.587598\n",
      "[290]\ttraining's binary_logloss: 0.587534\n",
      "[291]\ttraining's binary_logloss: 0.587457\n",
      "[292]\ttraining's binary_logloss: 0.587378\n",
      "[293]\ttraining's binary_logloss: 0.587303\n",
      "[294]\ttraining's binary_logloss: 0.587236\n",
      "[295]\ttraining's binary_logloss: 0.587165\n",
      "[296]\ttraining's binary_logloss: 0.587116\n",
      "[297]\ttraining's binary_logloss: 0.587052\n",
      "[298]\ttraining's binary_logloss: 0.586989\n",
      "[299]\ttraining's binary_logloss: 0.586939\n",
      "[300]\ttraining's binary_logloss: 0.586891\n",
      "[301]\ttraining's binary_logloss: 0.586823\n",
      "[302]\ttraining's binary_logloss: 0.586752\n",
      "[303]\ttraining's binary_logloss: 0.586683\n",
      "[304]\ttraining's binary_logloss: 0.58661\n",
      "[305]\ttraining's binary_logloss: 0.586547\n",
      "[306]\ttraining's binary_logloss: 0.586485\n",
      "[307]\ttraining's binary_logloss: 0.586426\n",
      "[308]\ttraining's binary_logloss: 0.586363\n",
      "[309]\ttraining's binary_logloss: 0.586311\n",
      "[310]\ttraining's binary_logloss: 0.586252\n",
      "[311]\ttraining's binary_logloss: 0.586174\n",
      "[312]\ttraining's binary_logloss: 0.586098\n",
      "[313]\ttraining's binary_logloss: 0.586037\n",
      "[314]\ttraining's binary_logloss: 0.585973\n",
      "[315]\ttraining's binary_logloss: 0.585901\n",
      "[316]\ttraining's binary_logloss: 0.585811\n",
      "[317]\ttraining's binary_logloss: 0.585723\n",
      "[318]\ttraining's binary_logloss: 0.58564\n",
      "[319]\ttraining's binary_logloss: 0.585555\n",
      "[320]\ttraining's binary_logloss: 0.585466\n",
      "[321]\ttraining's binary_logloss: 0.585408\n",
      "[322]\ttraining's binary_logloss: 0.585368\n",
      "[323]\ttraining's binary_logloss: 0.585311\n",
      "[324]\ttraining's binary_logloss: 0.585266\n",
      "[325]\ttraining's binary_logloss: 0.585233\n",
      "[326]\ttraining's binary_logloss: 0.585176\n",
      "[327]\ttraining's binary_logloss: 0.58512\n",
      "[328]\ttraining's binary_logloss: 0.585061\n",
      "[329]\ttraining's binary_logloss: 0.585009\n",
      "[330]\ttraining's binary_logloss: 0.584952\n",
      "[331]\ttraining's binary_logloss: 0.584879\n",
      "[332]\ttraining's binary_logloss: 0.584816\n",
      "[333]\ttraining's binary_logloss: 0.584732\n",
      "[334]\ttraining's binary_logloss: 0.584678\n",
      "[335]\ttraining's binary_logloss: 0.584616\n",
      "[336]\ttraining's binary_logloss: 0.58454\n",
      "[337]\ttraining's binary_logloss: 0.584465\n",
      "[338]\ttraining's binary_logloss: 0.584393\n",
      "[339]\ttraining's binary_logloss: 0.584323\n",
      "[340]\ttraining's binary_logloss: 0.584254\n",
      "[341]\ttraining's binary_logloss: 0.584213\n",
      "[342]\ttraining's binary_logloss: 0.584164\n",
      "[343]\ttraining's binary_logloss: 0.584122\n",
      "[344]\ttraining's binary_logloss: 0.584073\n",
      "[345]\ttraining's binary_logloss: 0.584028\n",
      "[346]\ttraining's binary_logloss: 0.583991\n",
      "[347]\ttraining's binary_logloss: 0.583948\n",
      "[348]\ttraining's binary_logloss: 0.583921\n",
      "[349]\ttraining's binary_logloss: 0.583875\n",
      "[350]\ttraining's binary_logloss: 0.583845\n",
      "[351]\ttraining's binary_logloss: 0.583773\n",
      "[352]\ttraining's binary_logloss: 0.583705\n",
      "[353]\ttraining's binary_logloss: 0.583631\n",
      "[354]\ttraining's binary_logloss: 0.583536\n",
      "[355]\ttraining's binary_logloss: 0.583455\n",
      "[356]\ttraining's binary_logloss: 0.5834\n",
      "[357]\ttraining's binary_logloss: 0.583325\n",
      "[358]\ttraining's binary_logloss: 0.583262\n",
      "[359]\ttraining's binary_logloss: 0.583195\n",
      "[360]\ttraining's binary_logloss: 0.583129\n",
      "[361]\ttraining's binary_logloss: 0.583061\n",
      "[362]\ttraining's binary_logloss: 0.582958\n",
      "[363]\ttraining's binary_logloss: 0.582862\n",
      "[364]\ttraining's binary_logloss: 0.582776\n",
      "[365]\ttraining's binary_logloss: 0.582692\n",
      "[366]\ttraining's binary_logloss: 0.582651\n",
      "[367]\ttraining's binary_logloss: 0.582606\n",
      "[368]\ttraining's binary_logloss: 0.582551\n",
      "[369]\ttraining's binary_logloss: 0.582512\n",
      "[370]\ttraining's binary_logloss: 0.582466\n",
      "[371]\ttraining's binary_logloss: 0.582379\n",
      "[372]\ttraining's binary_logloss: 0.5823\n",
      "[373]\ttraining's binary_logloss: 0.582223\n",
      "[374]\ttraining's binary_logloss: 0.582145\n",
      "[375]\ttraining's binary_logloss: 0.582079\n",
      "[376]\ttraining's binary_logloss: 0.581985\n",
      "[377]\ttraining's binary_logloss: 0.581892\n",
      "[378]\ttraining's binary_logloss: 0.581823\n",
      "[379]\ttraining's binary_logloss: 0.581728\n",
      "[380]\ttraining's binary_logloss: 0.581672\n",
      "[381]\ttraining's binary_logloss: 0.581601\n",
      "[382]\ttraining's binary_logloss: 0.581551\n",
      "[383]\ttraining's binary_logloss: 0.581502\n",
      "[384]\ttraining's binary_logloss: 0.581452\n",
      "[385]\ttraining's binary_logloss: 0.581406\n",
      "[386]\ttraining's binary_logloss: 0.581332\n",
      "[387]\ttraining's binary_logloss: 0.581257\n",
      "[388]\ttraining's binary_logloss: 0.581184\n",
      "[389]\ttraining's binary_logloss: 0.581115\n",
      "[390]\ttraining's binary_logloss: 0.581046\n",
      "[391]\ttraining's binary_logloss: 0.580971\n",
      "[392]\ttraining's binary_logloss: 0.580898\n",
      "[393]\ttraining's binary_logloss: 0.580815\n",
      "[394]\ttraining's binary_logloss: 0.580716\n",
      "[395]\ttraining's binary_logloss: 0.580613\n",
      "[396]\ttraining's binary_logloss: 0.580546\n",
      "[397]\ttraining's binary_logloss: 0.580473\n",
      "[398]\ttraining's binary_logloss: 0.5804\n",
      "[399]\ttraining's binary_logloss: 0.580339\n",
      "[400]\ttraining's binary_logloss: 0.580282\n",
      "[401]\ttraining's binary_logloss: 0.580199\n",
      "[402]\ttraining's binary_logloss: 0.580123\n",
      "[403]\ttraining's binary_logloss: 0.580044\n",
      "[404]\ttraining's binary_logloss: 0.57998\n",
      "[405]\ttraining's binary_logloss: 0.579903\n",
      "[406]\ttraining's binary_logloss: 0.579829\n",
      "[407]\ttraining's binary_logloss: 0.579768\n",
      "[408]\ttraining's binary_logloss: 0.579704\n",
      "[409]\ttraining's binary_logloss: 0.579611\n",
      "[410]\ttraining's binary_logloss: 0.579546\n",
      "[411]\ttraining's binary_logloss: 0.579447\n",
      "[412]\ttraining's binary_logloss: 0.579349\n",
      "[413]\ttraining's binary_logloss: 0.579255\n",
      "[414]\ttraining's binary_logloss: 0.579183\n",
      "[415]\ttraining's binary_logloss: 0.579093\n",
      "[416]\ttraining's binary_logloss: 0.579018\n",
      "[417]\ttraining's binary_logloss: 0.578945\n",
      "[418]\ttraining's binary_logloss: 0.578874\n",
      "[419]\ttraining's binary_logloss: 0.578808\n",
      "[420]\ttraining's binary_logloss: 0.578732\n",
      "[421]\ttraining's binary_logloss: 0.578705\n",
      "[422]\ttraining's binary_logloss: 0.578679\n",
      "[423]\ttraining's binary_logloss: 0.578658\n",
      "[424]\ttraining's binary_logloss: 0.57862\n",
      "[425]\ttraining's binary_logloss: 0.578579\n",
      "[426]\ttraining's binary_logloss: 0.578497\n",
      "[427]\ttraining's binary_logloss: 0.578428\n",
      "[428]\ttraining's binary_logloss: 0.578357\n",
      "[429]\ttraining's binary_logloss: 0.578281\n",
      "[430]\ttraining's binary_logloss: 0.578219\n",
      "[431]\ttraining's binary_logloss: 0.578142\n",
      "[432]\ttraining's binary_logloss: 0.578065\n",
      "[433]\ttraining's binary_logloss: 0.577984\n",
      "[434]\ttraining's binary_logloss: 0.577905\n",
      "[435]\ttraining's binary_logloss: 0.577826\n",
      "[436]\ttraining's binary_logloss: 0.577758\n",
      "[437]\ttraining's binary_logloss: 0.577695\n",
      "[438]\ttraining's binary_logloss: 0.57764\n",
      "[439]\ttraining's binary_logloss: 0.57758\n",
      "[440]\ttraining's binary_logloss: 0.577516\n",
      "[441]\ttraining's binary_logloss: 0.577427\n",
      "[442]\ttraining's binary_logloss: 0.577339\n",
      "[443]\ttraining's binary_logloss: 0.577254\n",
      "[444]\ttraining's binary_logloss: 0.577173\n",
      "[445]\ttraining's binary_logloss: 0.577099\n",
      "[446]\ttraining's binary_logloss: 0.577037\n",
      "[447]\ttraining's binary_logloss: 0.57697\n",
      "[448]\ttraining's binary_logloss: 0.576903\n",
      "[449]\ttraining's binary_logloss: 0.576836\n",
      "[450]\ttraining's binary_logloss: 0.576774\n",
      "[451]\ttraining's binary_logloss: 0.576736\n",
      "[452]\ttraining's binary_logloss: 0.576693\n",
      "[453]\ttraining's binary_logloss: 0.576656\n",
      "[454]\ttraining's binary_logloss: 0.576607\n",
      "[455]\ttraining's binary_logloss: 0.576565\n",
      "[456]\ttraining's binary_logloss: 0.576471\n",
      "[457]\ttraining's binary_logloss: 0.576376\n",
      "[458]\ttraining's binary_logloss: 0.576284\n",
      "[459]\ttraining's binary_logloss: 0.576194\n",
      "[460]\ttraining's binary_logloss: 0.576106\n",
      "[461]\ttraining's binary_logloss: 0.576045\n",
      "[462]\ttraining's binary_logloss: 0.575999\n",
      "[463]\ttraining's binary_logloss: 0.575949\n",
      "[464]\ttraining's binary_logloss: 0.575908\n",
      "[465]\ttraining's binary_logloss: 0.575868\n",
      "[466]\ttraining's binary_logloss: 0.575769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[467]\ttraining's binary_logloss: 0.575673\n",
      "[468]\ttraining's binary_logloss: 0.575588\n",
      "[469]\ttraining's binary_logloss: 0.575498\n",
      "[470]\ttraining's binary_logloss: 0.575422\n",
      "[471]\ttraining's binary_logloss: 0.575368\n",
      "[472]\ttraining's binary_logloss: 0.575305\n",
      "[473]\ttraining's binary_logloss: 0.575242\n",
      "[474]\ttraining's binary_logloss: 0.575178\n",
      "[475]\ttraining's binary_logloss: 0.575117\n",
      "[476]\ttraining's binary_logloss: 0.575021\n",
      "[477]\ttraining's binary_logloss: 0.574926\n",
      "[478]\ttraining's binary_logloss: 0.574845\n",
      "[479]\ttraining's binary_logloss: 0.574741\n",
      "[480]\ttraining's binary_logloss: 0.574649\n",
      "[481]\ttraining's binary_logloss: 0.574559\n",
      "[482]\ttraining's binary_logloss: 0.574483\n",
      "[483]\ttraining's binary_logloss: 0.574409\n",
      "[484]\ttraining's binary_logloss: 0.574333\n",
      "[485]\ttraining's binary_logloss: 0.574253\n",
      "[486]\ttraining's binary_logloss: 0.574185\n",
      "[487]\ttraining's binary_logloss: 0.574118\n",
      "[488]\ttraining's binary_logloss: 0.574052\n",
      "[489]\ttraining's binary_logloss: 0.573988\n",
      "[490]\ttraining's binary_logloss: 0.573925\n",
      "[491]\ttraining's binary_logloss: 0.573809\n",
      "[492]\ttraining's binary_logloss: 0.573689\n",
      "[493]\ttraining's binary_logloss: 0.573595\n",
      "[494]\ttraining's binary_logloss: 0.573494\n",
      "[495]\ttraining's binary_logloss: 0.573398\n",
      "[496]\ttraining's binary_logloss: 0.573249\n",
      "[497]\ttraining's binary_logloss: 0.573112\n",
      "[498]\ttraining's binary_logloss: 0.57299\n",
      "[499]\ttraining's binary_logloss: 0.572869\n",
      "[500]\ttraining's binary_logloss: 0.572755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613828\n",
      "[2]\ttraining's binary_logloss: 0.612788\n",
      "[3]\ttraining's binary_logloss: 0.611792\n",
      "[4]\ttraining's binary_logloss: 0.61084\n",
      "[5]\ttraining's binary_logloss: 0.609872\n",
      "[6]\ttraining's binary_logloss: 0.609059\n",
      "[7]\ttraining's binary_logloss: 0.608226\n",
      "[8]\ttraining's binary_logloss: 0.607439\n",
      "[9]\ttraining's binary_logloss: 0.606668\n",
      "[10]\ttraining's binary_logloss: 0.605935\n",
      "[11]\ttraining's binary_logloss: 0.605233\n",
      "[12]\ttraining's binary_logloss: 0.604504\n",
      "[13]\ttraining's binary_logloss: 0.603871\n",
      "[14]\ttraining's binary_logloss: 0.603264\n",
      "[15]\ttraining's binary_logloss: 0.602609\n",
      "[16]\ttraining's binary_logloss: 0.602051\n",
      "[17]\ttraining's binary_logloss: 0.601427\n",
      "[18]\ttraining's binary_logloss: 0.600823\n",
      "[19]\ttraining's binary_logloss: 0.600245\n",
      "[20]\ttraining's binary_logloss: 0.599772\n",
      "[21]\ttraining's binary_logloss: 0.599294\n",
      "[22]\ttraining's binary_logloss: 0.59882\n",
      "[23]\ttraining's binary_logloss: 0.598396\n",
      "[24]\ttraining's binary_logloss: 0.597949\n",
      "[25]\ttraining's binary_logloss: 0.597538\n",
      "[26]\ttraining's binary_logloss: 0.59706\n",
      "[27]\ttraining's binary_logloss: 0.596605\n",
      "[28]\ttraining's binary_logloss: 0.596191\n",
      "[29]\ttraining's binary_logloss: 0.595772\n",
      "[30]\ttraining's binary_logloss: 0.595374\n",
      "[31]\ttraining's binary_logloss: 0.595043\n",
      "[32]\ttraining's binary_logloss: 0.594761\n",
      "[33]\ttraining's binary_logloss: 0.594468\n",
      "[34]\ttraining's binary_logloss: 0.594146\n",
      "[35]\ttraining's binary_logloss: 0.593877\n",
      "[36]\ttraining's binary_logloss: 0.593539\n",
      "[37]\ttraining's binary_logloss: 0.593219\n",
      "[38]\ttraining's binary_logloss: 0.59292\n",
      "[39]\ttraining's binary_logloss: 0.592706\n",
      "[40]\ttraining's binary_logloss: 0.592509\n",
      "[41]\ttraining's binary_logloss: 0.592314\n",
      "[42]\ttraining's binary_logloss: 0.59211\n",
      "[43]\ttraining's binary_logloss: 0.591927\n",
      "[44]\ttraining's binary_logloss: 0.591749\n",
      "[45]\ttraining's binary_logloss: 0.591624\n",
      "[46]\ttraining's binary_logloss: 0.591389\n",
      "[47]\ttraining's binary_logloss: 0.591249\n",
      "[48]\ttraining's binary_logloss: 0.591045\n",
      "[49]\ttraining's binary_logloss: 0.590894\n",
      "[50]\ttraining's binary_logloss: 0.590715\n",
      "[51]\ttraining's binary_logloss: 0.590447\n",
      "[52]\ttraining's binary_logloss: 0.590251\n",
      "[53]\ttraining's binary_logloss: 0.590115\n",
      "[54]\ttraining's binary_logloss: 0.589969\n",
      "[55]\ttraining's binary_logloss: 0.589736\n",
      "[56]\ttraining's binary_logloss: 0.589677\n",
      "[57]\ttraining's binary_logloss: 0.589576\n",
      "[58]\ttraining's binary_logloss: 0.589428\n",
      "[59]\ttraining's binary_logloss: 0.589346\n",
      "[60]\ttraining's binary_logloss: 0.589261\n",
      "[61]\ttraining's binary_logloss: 0.589174\n",
      "[62]\ttraining's binary_logloss: 0.589036\n",
      "[63]\ttraining's binary_logloss: 0.588904\n",
      "[64]\ttraining's binary_logloss: 0.588883\n",
      "[65]\ttraining's binary_logloss: 0.588774\n",
      "[66]\ttraining's binary_logloss: 0.588656\n",
      "[67]\ttraining's binary_logloss: 0.588618\n",
      "[68]\ttraining's binary_logloss: 0.588512\n",
      "[69]\ttraining's binary_logloss: 0.588397\n",
      "[70]\ttraining's binary_logloss: 0.588346\n",
      "[71]\ttraining's binary_logloss: 0.588226\n",
      "[72]\ttraining's binary_logloss: 0.588123\n",
      "[73]\ttraining's binary_logloss: 0.588018\n",
      "[74]\ttraining's binary_logloss: 0.587923\n",
      "[75]\ttraining's binary_logloss: 0.587911\n",
      "[76]\ttraining's binary_logloss: 0.587868\n",
      "[77]\ttraining's binary_logloss: 0.587803\n",
      "[78]\ttraining's binary_logloss: 0.587745\n",
      "[79]\ttraining's binary_logloss: 0.587754\n",
      "[80]\ttraining's binary_logloss: 0.587707\n",
      "[81]\ttraining's binary_logloss: 0.587709\n",
      "[82]\ttraining's binary_logloss: 0.587697\n",
      "[83]\ttraining's binary_logloss: 0.58771\n",
      "[84]\ttraining's binary_logloss: 0.587709\n",
      "[85]\ttraining's binary_logloss: 0.587713\n",
      "[86]\ttraining's binary_logloss: 0.587729\n",
      "[87]\ttraining's binary_logloss: 0.587751\n",
      "[88]\ttraining's binary_logloss: 0.587748\n",
      "[89]\ttraining's binary_logloss: 0.587725\n",
      "[90]\ttraining's binary_logloss: 0.587769\n",
      "[91]\ttraining's binary_logloss: 0.587792\n",
      "[92]\ttraining's binary_logloss: 0.58781\n",
      "[93]\ttraining's binary_logloss: 0.587825\n",
      "[94]\ttraining's binary_logloss: 0.58786\n",
      "[95]\ttraining's binary_logloss: 0.58783\n",
      "[96]\ttraining's binary_logloss: 0.587802\n",
      "[97]\ttraining's binary_logloss: 0.587851\n",
      "[98]\ttraining's binary_logloss: 0.58788\n",
      "[99]\ttraining's binary_logloss: 0.587935\n",
      "[100]\ttraining's binary_logloss: 0.587994\n",
      "[101]\ttraining's binary_logloss: 0.588004\n",
      "[102]\ttraining's binary_logloss: 0.588042\n",
      "[103]\ttraining's binary_logloss: 0.588064\n",
      "[104]\ttraining's binary_logloss: 0.588072\n",
      "[105]\ttraining's binary_logloss: 0.588081\n",
      "[106]\ttraining's binary_logloss: 0.588164\n",
      "[107]\ttraining's binary_logloss: 0.588169\n",
      "[108]\ttraining's binary_logloss: 0.588179\n",
      "[109]\ttraining's binary_logloss: 0.588192\n",
      "[110]\ttraining's binary_logloss: 0.588212\n",
      "[111]\ttraining's binary_logloss: 0.588236\n",
      "[112]\ttraining's binary_logloss: 0.58827\n",
      "[113]\ttraining's binary_logloss: 0.588299\n",
      "[114]\ttraining's binary_logloss: 0.588346\n",
      "[115]\ttraining's binary_logloss: 0.58838\n",
      "[116]\ttraining's binary_logloss: 0.588376\n",
      "[117]\ttraining's binary_logloss: 0.588371\n",
      "[118]\ttraining's binary_logloss: 0.588371\n",
      "[119]\ttraining's binary_logloss: 0.588374\n",
      "[120]\ttraining's binary_logloss: 0.58838\n",
      "[121]\ttraining's binary_logloss: 0.588441\n",
      "[122]\ttraining's binary_logloss: 0.58847\n",
      "[123]\ttraining's binary_logloss: 0.588505\n",
      "[124]\ttraining's binary_logloss: 0.588543\n",
      "[125]\ttraining's binary_logloss: 0.588579\n",
      "[126]\ttraining's binary_logloss: 0.588575\n",
      "[127]\ttraining's binary_logloss: 0.58859\n",
      "[128]\ttraining's binary_logloss: 0.588599\n",
      "[129]\ttraining's binary_logloss: 0.588609\n",
      "[130]\ttraining's binary_logloss: 0.588611\n",
      "[131]\ttraining's binary_logloss: 0.588647\n",
      "[132]\ttraining's binary_logloss: 0.588692\n",
      "[133]\ttraining's binary_logloss: 0.588673\n",
      "[134]\ttraining's binary_logloss: 0.588722\n",
      "[135]\ttraining's binary_logloss: 0.588734\n",
      "[136]\ttraining's binary_logloss: 0.588724\n",
      "[137]\ttraining's binary_logloss: 0.588766\n",
      "[138]\ttraining's binary_logloss: 0.588809\n",
      "[139]\ttraining's binary_logloss: 0.588859\n",
      "[140]\ttraining's binary_logloss: 0.588906\n",
      "[141]\ttraining's binary_logloss: 0.588929\n",
      "[142]\ttraining's binary_logloss: 0.588973\n",
      "[143]\ttraining's binary_logloss: 0.589002\n",
      "[144]\ttraining's binary_logloss: 0.589034\n",
      "[145]\ttraining's binary_logloss: 0.58908\n",
      "[146]\ttraining's binary_logloss: 0.589121\n",
      "[147]\ttraining's binary_logloss: 0.589161\n",
      "[148]\ttraining's binary_logloss: 0.589158\n",
      "[149]\ttraining's binary_logloss: 0.589196\n",
      "[150]\ttraining's binary_logloss: 0.589234\n",
      "[151]\ttraining's binary_logloss: 0.589285\n",
      "[152]\ttraining's binary_logloss: 0.589341\n",
      "[153]\ttraining's binary_logloss: 0.589376\n",
      "[154]\ttraining's binary_logloss: 0.589433\n",
      "[155]\ttraining's binary_logloss: 0.589506\n",
      "[156]\ttraining's binary_logloss: 0.589531\n",
      "[157]\ttraining's binary_logloss: 0.589555\n",
      "[158]\ttraining's binary_logloss: 0.589572\n",
      "[159]\ttraining's binary_logloss: 0.589599\n",
      "[160]\ttraining's binary_logloss: 0.589608\n",
      "[161]\ttraining's binary_logloss: 0.589621\n",
      "[162]\ttraining's binary_logloss: 0.589641\n",
      "[163]\ttraining's binary_logloss: 0.589666\n",
      "[164]\ttraining's binary_logloss: 0.589682\n",
      "[165]\ttraining's binary_logloss: 0.589685\n",
      "[166]\ttraining's binary_logloss: 0.589709\n",
      "[167]\ttraining's binary_logloss: 0.589723\n",
      "[168]\ttraining's binary_logloss: 0.589761\n",
      "[169]\ttraining's binary_logloss: 0.589803\n",
      "[170]\ttraining's binary_logloss: 0.589847\n",
      "[171]\ttraining's binary_logloss: 0.589841\n",
      "[172]\ttraining's binary_logloss: 0.589823\n",
      "[173]\ttraining's binary_logloss: 0.589815\n",
      "[174]\ttraining's binary_logloss: 0.58981\n",
      "[175]\ttraining's binary_logloss: 0.589799\n",
      "[176]\ttraining's binary_logloss: 0.589822\n",
      "[177]\ttraining's binary_logloss: 0.589849\n",
      "[178]\ttraining's binary_logloss: 0.589879\n",
      "[179]\ttraining's binary_logloss: 0.589898\n",
      "[180]\ttraining's binary_logloss: 0.589918\n",
      "[181]\ttraining's binary_logloss: 0.589967\n",
      "[182]\ttraining's binary_logloss: 0.590023\n",
      "[183]\ttraining's binary_logloss: 0.590056\n",
      "[184]\ttraining's binary_logloss: 0.590081\n",
      "[185]\ttraining's binary_logloss: 0.590127\n",
      "[186]\ttraining's binary_logloss: 0.590174\n",
      "[187]\ttraining's binary_logloss: 0.590232\n",
      "[188]\ttraining's binary_logloss: 0.59028\n",
      "[189]\ttraining's binary_logloss: 0.590333\n",
      "[190]\ttraining's binary_logloss: 0.590394\n",
      "[191]\ttraining's binary_logloss: 0.5904\n",
      "[192]\ttraining's binary_logloss: 0.590427\n",
      "[193]\ttraining's binary_logloss: 0.590433\n",
      "[194]\ttraining's binary_logloss: 0.59045\n",
      "[195]\ttraining's binary_logloss: 0.590432\n",
      "[196]\ttraining's binary_logloss: 0.590429\n",
      "[197]\ttraining's binary_logloss: 0.590425\n",
      "[198]\ttraining's binary_logloss: 0.590428\n",
      "[199]\ttraining's binary_logloss: 0.590395\n",
      "[200]\ttraining's binary_logloss: 0.590399\n",
      "[201]\ttraining's binary_logloss: 0.590375\n",
      "[202]\ttraining's binary_logloss: 0.590358\n",
      "[203]\ttraining's binary_logloss: 0.590342\n",
      "[204]\ttraining's binary_logloss: 0.590329\n",
      "[205]\ttraining's binary_logloss: 0.590315\n",
      "[206]\ttraining's binary_logloss: 0.590345\n",
      "[207]\ttraining's binary_logloss: 0.590353\n",
      "[208]\ttraining's binary_logloss: 0.590391\n",
      "[209]\ttraining's binary_logloss: 0.5904\n",
      "[210]\ttraining's binary_logloss: 0.590421\n",
      "[211]\ttraining's binary_logloss: 0.590398\n",
      "[212]\ttraining's binary_logloss: 0.590383\n",
      "[213]\ttraining's binary_logloss: 0.590373\n",
      "[214]\ttraining's binary_logloss: 0.590355\n",
      "[215]\ttraining's binary_logloss: 0.590337\n",
      "[216]\ttraining's binary_logloss: 0.590313\n",
      "[217]\ttraining's binary_logloss: 0.590291\n",
      "[218]\ttraining's binary_logloss: 0.590271\n",
      "[219]\ttraining's binary_logloss: 0.590235\n",
      "[220]\ttraining's binary_logloss: 0.590204\n",
      "[221]\ttraining's binary_logloss: 0.590204\n",
      "[222]\ttraining's binary_logloss: 0.590203\n",
      "[223]\ttraining's binary_logloss: 0.590166\n",
      "[224]\ttraining's binary_logloss: 0.59018\n",
      "[225]\ttraining's binary_logloss: 0.590193\n",
      "[226]\ttraining's binary_logloss: 0.590185\n",
      "[227]\ttraining's binary_logloss: 0.590179\n",
      "[228]\ttraining's binary_logloss: 0.590164\n",
      "[229]\ttraining's binary_logloss: 0.590159\n",
      "[230]\ttraining's binary_logloss: 0.590145\n",
      "[231]\ttraining's binary_logloss: 0.590096\n",
      "[232]\ttraining's binary_logloss: 0.59005\n",
      "[233]\ttraining's binary_logloss: 0.590007\n",
      "[234]\ttraining's binary_logloss: 0.589979\n",
      "[235]\ttraining's binary_logloss: 0.589949\n",
      "[236]\ttraining's binary_logloss: 0.589942\n",
      "[237]\ttraining's binary_logloss: 0.589923\n",
      "[238]\ttraining's binary_logloss: 0.589925\n",
      "[239]\ttraining's binary_logloss: 0.589919\n",
      "[240]\ttraining's binary_logloss: 0.589901\n",
      "[241]\ttraining's binary_logloss: 0.589889\n",
      "[242]\ttraining's binary_logloss: 0.589879\n",
      "[243]\ttraining's binary_logloss: 0.589859\n",
      "[244]\ttraining's binary_logloss: 0.589844\n",
      "[245]\ttraining's binary_logloss: 0.589822\n",
      "[246]\ttraining's binary_logloss: 0.589773\n",
      "[247]\ttraining's binary_logloss: 0.589725\n",
      "[248]\ttraining's binary_logloss: 0.589662\n",
      "[249]\ttraining's binary_logloss: 0.589615\n",
      "[250]\ttraining's binary_logloss: 0.589573\n",
      "[251]\ttraining's binary_logloss: 0.589565\n",
      "[252]\ttraining's binary_logloss: 0.589562\n",
      "[253]\ttraining's binary_logloss: 0.589558\n",
      "[254]\ttraining's binary_logloss: 0.589559\n",
      "[255]\ttraining's binary_logloss: 0.589561\n",
      "[256]\ttraining's binary_logloss: 0.589528\n",
      "[257]\ttraining's binary_logloss: 0.5895\n",
      "[258]\ttraining's binary_logloss: 0.589469\n",
      "[259]\ttraining's binary_logloss: 0.589438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[260]\ttraining's binary_logloss: 0.58941\n",
      "[261]\ttraining's binary_logloss: 0.589336\n",
      "[262]\ttraining's binary_logloss: 0.58927\n",
      "[263]\ttraining's binary_logloss: 0.589206\n",
      "[264]\ttraining's binary_logloss: 0.589146\n",
      "[265]\ttraining's binary_logloss: 0.589089\n",
      "[266]\ttraining's binary_logloss: 0.589054\n",
      "[267]\ttraining's binary_logloss: 0.589035\n",
      "[268]\ttraining's binary_logloss: 0.589021\n",
      "[269]\ttraining's binary_logloss: 0.589003\n",
      "[270]\ttraining's binary_logloss: 0.588969\n",
      "[271]\ttraining's binary_logloss: 0.588935\n",
      "[272]\ttraining's binary_logloss: 0.588919\n",
      "[273]\ttraining's binary_logloss: 0.588904\n",
      "[274]\ttraining's binary_logloss: 0.58889\n",
      "[275]\ttraining's binary_logloss: 0.588874\n",
      "[276]\ttraining's binary_logloss: 0.588826\n",
      "[277]\ttraining's binary_logloss: 0.588792\n",
      "[278]\ttraining's binary_logloss: 0.588757\n",
      "[279]\ttraining's binary_logloss: 0.588712\n",
      "[280]\ttraining's binary_logloss: 0.588678\n",
      "[281]\ttraining's binary_logloss: 0.58865\n",
      "[282]\ttraining's binary_logloss: 0.588628\n",
      "[283]\ttraining's binary_logloss: 0.588598\n",
      "[284]\ttraining's binary_logloss: 0.58858\n",
      "[285]\ttraining's binary_logloss: 0.588557\n",
      "[286]\ttraining's binary_logloss: 0.588474\n",
      "[287]\ttraining's binary_logloss: 0.588393\n",
      "[288]\ttraining's binary_logloss: 0.588312\n",
      "[289]\ttraining's binary_logloss: 0.588223\n",
      "[290]\ttraining's binary_logloss: 0.588132\n",
      "[291]\ttraining's binary_logloss: 0.588095\n",
      "[292]\ttraining's binary_logloss: 0.588057\n",
      "[293]\ttraining's binary_logloss: 0.588028\n",
      "[294]\ttraining's binary_logloss: 0.587995\n",
      "[295]\ttraining's binary_logloss: 0.587966\n",
      "[296]\ttraining's binary_logloss: 0.587884\n",
      "[297]\ttraining's binary_logloss: 0.587805\n",
      "[298]\ttraining's binary_logloss: 0.587717\n",
      "[299]\ttraining's binary_logloss: 0.587647\n",
      "[300]\ttraining's binary_logloss: 0.587561\n",
      "[301]\ttraining's binary_logloss: 0.58749\n",
      "[302]\ttraining's binary_logloss: 0.587413\n",
      "[303]\ttraining's binary_logloss: 0.587342\n",
      "[304]\ttraining's binary_logloss: 0.587268\n",
      "[305]\ttraining's binary_logloss: 0.587196\n",
      "[306]\ttraining's binary_logloss: 0.58711\n",
      "[307]\ttraining's binary_logloss: 0.587017\n",
      "[308]\ttraining's binary_logloss: 0.586906\n",
      "[309]\ttraining's binary_logloss: 0.586802\n",
      "[310]\ttraining's binary_logloss: 0.586694\n",
      "[311]\ttraining's binary_logloss: 0.586636\n",
      "[312]\ttraining's binary_logloss: 0.586564\n",
      "[313]\ttraining's binary_logloss: 0.586508\n",
      "[314]\ttraining's binary_logloss: 0.586462\n",
      "[315]\ttraining's binary_logloss: 0.586401\n",
      "[316]\ttraining's binary_logloss: 0.586348\n",
      "[317]\ttraining's binary_logloss: 0.586285\n",
      "[318]\ttraining's binary_logloss: 0.586255\n",
      "[319]\ttraining's binary_logloss: 0.586208\n",
      "[320]\ttraining's binary_logloss: 0.586156\n",
      "[321]\ttraining's binary_logloss: 0.586112\n",
      "[322]\ttraining's binary_logloss: 0.586087\n",
      "[323]\ttraining's binary_logloss: 0.586056\n",
      "[324]\ttraining's binary_logloss: 0.586034\n",
      "[325]\ttraining's binary_logloss: 0.585998\n",
      "[326]\ttraining's binary_logloss: 0.58597\n",
      "[327]\ttraining's binary_logloss: 0.585921\n",
      "[328]\ttraining's binary_logloss: 0.585882\n",
      "[329]\ttraining's binary_logloss: 0.585849\n",
      "[330]\ttraining's binary_logloss: 0.585818\n",
      "[331]\ttraining's binary_logloss: 0.585747\n",
      "[332]\ttraining's binary_logloss: 0.585674\n",
      "[333]\ttraining's binary_logloss: 0.585596\n",
      "[334]\ttraining's binary_logloss: 0.585529\n",
      "[335]\ttraining's binary_logloss: 0.585456\n",
      "[336]\ttraining's binary_logloss: 0.585382\n",
      "[337]\ttraining's binary_logloss: 0.585313\n",
      "[338]\ttraining's binary_logloss: 0.585209\n",
      "[339]\ttraining's binary_logloss: 0.585137\n",
      "[340]\ttraining's binary_logloss: 0.58506\n",
      "[341]\ttraining's binary_logloss: 0.584968\n",
      "[342]\ttraining's binary_logloss: 0.584881\n",
      "[343]\ttraining's binary_logloss: 0.584796\n",
      "[344]\ttraining's binary_logloss: 0.584716\n",
      "[345]\ttraining's binary_logloss: 0.584631\n",
      "[346]\ttraining's binary_logloss: 0.584596\n",
      "[347]\ttraining's binary_logloss: 0.584546\n",
      "[348]\ttraining's binary_logloss: 0.584501\n",
      "[349]\ttraining's binary_logloss: 0.58446\n",
      "[350]\ttraining's binary_logloss: 0.584404\n",
      "[351]\ttraining's binary_logloss: 0.584323\n",
      "[352]\ttraining's binary_logloss: 0.584242\n",
      "[353]\ttraining's binary_logloss: 0.584157\n",
      "[354]\ttraining's binary_logloss: 0.584072\n",
      "[355]\ttraining's binary_logloss: 0.583999\n",
      "[356]\ttraining's binary_logloss: 0.583937\n",
      "[357]\ttraining's binary_logloss: 0.583877\n",
      "[358]\ttraining's binary_logloss: 0.583811\n",
      "[359]\ttraining's binary_logloss: 0.58374\n",
      "[360]\ttraining's binary_logloss: 0.583682\n",
      "[361]\ttraining's binary_logloss: 0.58363\n",
      "[362]\ttraining's binary_logloss: 0.583579\n",
      "[363]\ttraining's binary_logloss: 0.583521\n",
      "[364]\ttraining's binary_logloss: 0.58346\n",
      "[365]\ttraining's binary_logloss: 0.583422\n",
      "[366]\ttraining's binary_logloss: 0.583379\n",
      "[367]\ttraining's binary_logloss: 0.583355\n",
      "[368]\ttraining's binary_logloss: 0.583329\n",
      "[369]\ttraining's binary_logloss: 0.583301\n",
      "[370]\ttraining's binary_logloss: 0.583278\n",
      "[371]\ttraining's binary_logloss: 0.58318\n",
      "[372]\ttraining's binary_logloss: 0.583087\n",
      "[373]\ttraining's binary_logloss: 0.58301\n",
      "[374]\ttraining's binary_logloss: 0.582921\n",
      "[375]\ttraining's binary_logloss: 0.582847\n",
      "[376]\ttraining's binary_logloss: 0.582732\n",
      "[377]\ttraining's binary_logloss: 0.582621\n",
      "[378]\ttraining's binary_logloss: 0.582557\n",
      "[379]\ttraining's binary_logloss: 0.582485\n",
      "[380]\ttraining's binary_logloss: 0.582376\n",
      "[381]\ttraining's binary_logloss: 0.58229\n",
      "[382]\ttraining's binary_logloss: 0.582223\n",
      "[383]\ttraining's binary_logloss: 0.582135\n",
      "[384]\ttraining's binary_logloss: 0.582062\n",
      "[385]\ttraining's binary_logloss: 0.581985\n",
      "[386]\ttraining's binary_logloss: 0.581922\n",
      "[387]\ttraining's binary_logloss: 0.581852\n",
      "[388]\ttraining's binary_logloss: 0.581796\n",
      "[389]\ttraining's binary_logloss: 0.581734\n",
      "[390]\ttraining's binary_logloss: 0.581676\n",
      "[391]\ttraining's binary_logloss: 0.581548\n",
      "[392]\ttraining's binary_logloss: 0.581437\n",
      "[393]\ttraining's binary_logloss: 0.581311\n",
      "[394]\ttraining's binary_logloss: 0.581191\n",
      "[395]\ttraining's binary_logloss: 0.581092\n",
      "[396]\ttraining's binary_logloss: 0.581017\n",
      "[397]\ttraining's binary_logloss: 0.580947\n",
      "[398]\ttraining's binary_logloss: 0.580878\n",
      "[399]\ttraining's binary_logloss: 0.580816\n",
      "[400]\ttraining's binary_logloss: 0.580757\n",
      "[401]\ttraining's binary_logloss: 0.580665\n",
      "[402]\ttraining's binary_logloss: 0.580599\n",
      "[403]\ttraining's binary_logloss: 0.580513\n",
      "[404]\ttraining's binary_logloss: 0.580442\n",
      "[405]\ttraining's binary_logloss: 0.580358\n",
      "[406]\ttraining's binary_logloss: 0.58029\n",
      "[407]\ttraining's binary_logloss: 0.580224\n",
      "[408]\ttraining's binary_logloss: 0.580158\n",
      "[409]\ttraining's binary_logloss: 0.580099\n",
      "[410]\ttraining's binary_logloss: 0.580048\n",
      "[411]\ttraining's binary_logloss: 0.579973\n",
      "[412]\ttraining's binary_logloss: 0.579902\n",
      "[413]\ttraining's binary_logloss: 0.579834\n",
      "[414]\ttraining's binary_logloss: 0.579758\n",
      "[415]\ttraining's binary_logloss: 0.579684\n",
      "[416]\ttraining's binary_logloss: 0.579607\n",
      "[417]\ttraining's binary_logloss: 0.579544\n",
      "[418]\ttraining's binary_logloss: 0.579483\n",
      "[419]\ttraining's binary_logloss: 0.579426\n",
      "[420]\ttraining's binary_logloss: 0.579366\n",
      "[421]\ttraining's binary_logloss: 0.579338\n",
      "[422]\ttraining's binary_logloss: 0.579325\n",
      "[423]\ttraining's binary_logloss: 0.579311\n",
      "[424]\ttraining's binary_logloss: 0.579294\n",
      "[425]\ttraining's binary_logloss: 0.579283\n",
      "[426]\ttraining's binary_logloss: 0.579179\n",
      "[427]\ttraining's binary_logloss: 0.579073\n",
      "[428]\ttraining's binary_logloss: 0.578972\n",
      "[429]\ttraining's binary_logloss: 0.578871\n",
      "[430]\ttraining's binary_logloss: 0.578761\n",
      "[431]\ttraining's binary_logloss: 0.578706\n",
      "[432]\ttraining's binary_logloss: 0.578654\n",
      "[433]\ttraining's binary_logloss: 0.578601\n",
      "[434]\ttraining's binary_logloss: 0.57855\n",
      "[435]\ttraining's binary_logloss: 0.578488\n",
      "[436]\ttraining's binary_logloss: 0.578394\n",
      "[437]\ttraining's binary_logloss: 0.578315\n",
      "[438]\ttraining's binary_logloss: 0.578239\n",
      "[439]\ttraining's binary_logloss: 0.578158\n",
      "[440]\ttraining's binary_logloss: 0.578058\n",
      "[441]\ttraining's binary_logloss: 0.577958\n",
      "[442]\ttraining's binary_logloss: 0.577861\n",
      "[443]\ttraining's binary_logloss: 0.577773\n",
      "[444]\ttraining's binary_logloss: 0.57769\n",
      "[445]\ttraining's binary_logloss: 0.577589\n",
      "[446]\ttraining's binary_logloss: 0.577525\n",
      "[447]\ttraining's binary_logloss: 0.57747\n",
      "[448]\ttraining's binary_logloss: 0.577416\n",
      "[449]\ttraining's binary_logloss: 0.577354\n",
      "[450]\ttraining's binary_logloss: 0.577297\n",
      "[451]\ttraining's binary_logloss: 0.577245\n",
      "[452]\ttraining's binary_logloss: 0.577206\n",
      "[453]\ttraining's binary_logloss: 0.577147\n",
      "[454]\ttraining's binary_logloss: 0.577089\n",
      "[455]\ttraining's binary_logloss: 0.577032\n",
      "[456]\ttraining's binary_logloss: 0.576927\n",
      "[457]\ttraining's binary_logloss: 0.576841\n",
      "[458]\ttraining's binary_logloss: 0.576743\n",
      "[459]\ttraining's binary_logloss: 0.576671\n",
      "[460]\ttraining's binary_logloss: 0.576603\n",
      "[461]\ttraining's binary_logloss: 0.576522\n",
      "[462]\ttraining's binary_logloss: 0.576442\n",
      "[463]\ttraining's binary_logloss: 0.576356\n",
      "[464]\ttraining's binary_logloss: 0.576267\n",
      "[465]\ttraining's binary_logloss: 0.576169\n",
      "[466]\ttraining's binary_logloss: 0.576063\n",
      "[467]\ttraining's binary_logloss: 0.575964\n",
      "[468]\ttraining's binary_logloss: 0.575868\n",
      "[469]\ttraining's binary_logloss: 0.575775\n",
      "[470]\ttraining's binary_logloss: 0.575677\n",
      "[471]\ttraining's binary_logloss: 0.575599\n",
      "[472]\ttraining's binary_logloss: 0.575524\n",
      "[473]\ttraining's binary_logloss: 0.575441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[474]\ttraining's binary_logloss: 0.57537\n",
      "[475]\ttraining's binary_logloss: 0.575303\n",
      "[476]\ttraining's binary_logloss: 0.575223\n",
      "[477]\ttraining's binary_logloss: 0.575141\n",
      "[478]\ttraining's binary_logloss: 0.575069\n",
      "[479]\ttraining's binary_logloss: 0.574996\n",
      "[480]\ttraining's binary_logloss: 0.574921\n",
      "[481]\ttraining's binary_logloss: 0.574836\n",
      "[482]\ttraining's binary_logloss: 0.574765\n",
      "[483]\ttraining's binary_logloss: 0.574694\n",
      "[484]\ttraining's binary_logloss: 0.57462\n",
      "[485]\ttraining's binary_logloss: 0.574553\n",
      "[486]\ttraining's binary_logloss: 0.574477\n",
      "[487]\ttraining's binary_logloss: 0.574403\n",
      "[488]\ttraining's binary_logloss: 0.574326\n",
      "[489]\ttraining's binary_logloss: 0.574252\n",
      "[490]\ttraining's binary_logloss: 0.574181\n",
      "[491]\ttraining's binary_logloss: 0.574096\n",
      "[492]\ttraining's binary_logloss: 0.574016\n",
      "[493]\ttraining's binary_logloss: 0.573933\n",
      "[494]\ttraining's binary_logloss: 0.573855\n",
      "[495]\ttraining's binary_logloss: 0.573777\n",
      "[496]\ttraining's binary_logloss: 0.573659\n",
      "[497]\ttraining's binary_logloss: 0.573551\n",
      "[498]\ttraining's binary_logloss: 0.573447\n",
      "[499]\ttraining's binary_logloss: 0.573342\n",
      "[500]\ttraining's binary_logloss: 0.573212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614271\n",
      "[2]\ttraining's binary_logloss: 0.613021\n",
      "[3]\ttraining's binary_logloss: 0.611814\n",
      "[4]\ttraining's binary_logloss: 0.610643\n",
      "[5]\ttraining's binary_logloss: 0.609525\n",
      "[6]\ttraining's binary_logloss: 0.608419\n",
      "[7]\ttraining's binary_logloss: 0.607297\n",
      "[8]\ttraining's binary_logloss: 0.60632\n",
      "[9]\ttraining's binary_logloss: 0.605238\n",
      "[10]\ttraining's binary_logloss: 0.604193\n",
      "[11]\ttraining's binary_logloss: 0.603208\n",
      "[12]\ttraining's binary_logloss: 0.602234\n",
      "[13]\ttraining's binary_logloss: 0.601398\n",
      "[14]\ttraining's binary_logloss: 0.600494\n",
      "[15]\ttraining's binary_logloss: 0.599637\n",
      "[16]\ttraining's binary_logloss: 0.598913\n",
      "[17]\ttraining's binary_logloss: 0.598044\n",
      "[18]\ttraining's binary_logloss: 0.597284\n",
      "[19]\ttraining's binary_logloss: 0.596473\n",
      "[20]\ttraining's binary_logloss: 0.595786\n",
      "[21]\ttraining's binary_logloss: 0.595089\n",
      "[22]\ttraining's binary_logloss: 0.59437\n",
      "[23]\ttraining's binary_logloss: 0.593685\n",
      "[24]\ttraining's binary_logloss: 0.592992\n",
      "[25]\ttraining's binary_logloss: 0.592321\n",
      "[26]\ttraining's binary_logloss: 0.591726\n",
      "[27]\ttraining's binary_logloss: 0.591139\n",
      "[28]\ttraining's binary_logloss: 0.5906\n",
      "[29]\ttraining's binary_logloss: 0.590058\n",
      "[30]\ttraining's binary_logloss: 0.589538\n",
      "[31]\ttraining's binary_logloss: 0.589014\n",
      "[32]\ttraining's binary_logloss: 0.588557\n",
      "[33]\ttraining's binary_logloss: 0.587983\n",
      "[34]\ttraining's binary_logloss: 0.587475\n",
      "[35]\ttraining's binary_logloss: 0.587018\n",
      "[36]\ttraining's binary_logloss: 0.58655\n",
      "[37]\ttraining's binary_logloss: 0.586144\n",
      "[38]\ttraining's binary_logloss: 0.585755\n",
      "[39]\ttraining's binary_logloss: 0.585383\n",
      "[40]\ttraining's binary_logloss: 0.585055\n",
      "[41]\ttraining's binary_logloss: 0.584681\n",
      "[42]\ttraining's binary_logloss: 0.584277\n",
      "[43]\ttraining's binary_logloss: 0.583888\n",
      "[44]\ttraining's binary_logloss: 0.583498\n",
      "[45]\ttraining's binary_logloss: 0.583107\n",
      "[46]\ttraining's binary_logloss: 0.582806\n",
      "[47]\ttraining's binary_logloss: 0.582516\n",
      "[48]\ttraining's binary_logloss: 0.582156\n",
      "[49]\ttraining's binary_logloss: 0.581862\n",
      "[50]\ttraining's binary_logloss: 0.58155\n",
      "[51]\ttraining's binary_logloss: 0.581247\n",
      "[52]\ttraining's binary_logloss: 0.581019\n",
      "[53]\ttraining's binary_logloss: 0.580738\n",
      "[54]\ttraining's binary_logloss: 0.580452\n",
      "[55]\ttraining's binary_logloss: 0.580194\n",
      "[56]\ttraining's binary_logloss: 0.579975\n",
      "[57]\ttraining's binary_logloss: 0.579743\n",
      "[58]\ttraining's binary_logloss: 0.579478\n",
      "[59]\ttraining's binary_logloss: 0.579293\n",
      "[60]\ttraining's binary_logloss: 0.579088\n",
      "[61]\ttraining's binary_logloss: 0.578885\n",
      "[62]\ttraining's binary_logloss: 0.578687\n",
      "[63]\ttraining's binary_logloss: 0.578455\n",
      "[64]\ttraining's binary_logloss: 0.578301\n",
      "[65]\ttraining's binary_logloss: 0.578129\n",
      "[66]\ttraining's binary_logloss: 0.577937\n",
      "[67]\ttraining's binary_logloss: 0.577773\n",
      "[68]\ttraining's binary_logloss: 0.577567\n",
      "[69]\ttraining's binary_logloss: 0.577401\n",
      "[70]\ttraining's binary_logloss: 0.577251\n",
      "[71]\ttraining's binary_logloss: 0.577114\n",
      "[72]\ttraining's binary_logloss: 0.576961\n",
      "[73]\ttraining's binary_logloss: 0.57685\n",
      "[74]\ttraining's binary_logloss: 0.576683\n",
      "[75]\ttraining's binary_logloss: 0.576579\n",
      "[76]\ttraining's binary_logloss: 0.576391\n",
      "[77]\ttraining's binary_logloss: 0.576261\n",
      "[78]\ttraining's binary_logloss: 0.576142\n",
      "[79]\ttraining's binary_logloss: 0.576071\n",
      "[80]\ttraining's binary_logloss: 0.575968\n",
      "[81]\ttraining's binary_logloss: 0.575847\n",
      "[82]\ttraining's binary_logloss: 0.575695\n",
      "[83]\ttraining's binary_logloss: 0.575598\n",
      "[84]\ttraining's binary_logloss: 0.575467\n",
      "[85]\ttraining's binary_logloss: 0.575344\n",
      "[86]\ttraining's binary_logloss: 0.575298\n",
      "[87]\ttraining's binary_logloss: 0.575219\n",
      "[88]\ttraining's binary_logloss: 0.575137\n",
      "[89]\ttraining's binary_logloss: 0.575023\n",
      "[90]\ttraining's binary_logloss: 0.574955\n",
      "[91]\ttraining's binary_logloss: 0.574864\n",
      "[92]\ttraining's binary_logloss: 0.574767\n",
      "[93]\ttraining's binary_logloss: 0.574672\n",
      "[94]\ttraining's binary_logloss: 0.574578\n",
      "[95]\ttraining's binary_logloss: 0.574494\n",
      "[96]\ttraining's binary_logloss: 0.574363\n",
      "[97]\ttraining's binary_logloss: 0.574282\n",
      "[98]\ttraining's binary_logloss: 0.574174\n",
      "[99]\ttraining's binary_logloss: 0.574079\n",
      "[100]\ttraining's binary_logloss: 0.573971\n",
      "[101]\ttraining's binary_logloss: 0.573908\n",
      "[102]\ttraining's binary_logloss: 0.573825\n",
      "[103]\ttraining's binary_logloss: 0.573761\n",
      "[104]\ttraining's binary_logloss: 0.573696\n",
      "[105]\ttraining's binary_logloss: 0.573631\n",
      "[106]\ttraining's binary_logloss: 0.573541\n",
      "[107]\ttraining's binary_logloss: 0.573429\n",
      "[108]\ttraining's binary_logloss: 0.573325\n",
      "[109]\ttraining's binary_logloss: 0.573228\n",
      "[110]\ttraining's binary_logloss: 0.573134\n",
      "[111]\ttraining's binary_logloss: 0.573038\n",
      "[112]\ttraining's binary_logloss: 0.572941\n",
      "[113]\ttraining's binary_logloss: 0.572853\n",
      "[114]\ttraining's binary_logloss: 0.572785\n",
      "[115]\ttraining's binary_logloss: 0.572704\n",
      "[116]\ttraining's binary_logloss: 0.572639\n",
      "[117]\ttraining's binary_logloss: 0.572589\n",
      "[118]\ttraining's binary_logloss: 0.572529\n",
      "[119]\ttraining's binary_logloss: 0.572481\n",
      "[120]\ttraining's binary_logloss: 0.572435\n",
      "[121]\ttraining's binary_logloss: 0.572389\n",
      "[122]\ttraining's binary_logloss: 0.572339\n",
      "[123]\ttraining's binary_logloss: 0.572307\n",
      "[124]\ttraining's binary_logloss: 0.572283\n",
      "[125]\ttraining's binary_logloss: 0.57225\n",
      "[126]\ttraining's binary_logloss: 0.572191\n",
      "[127]\ttraining's binary_logloss: 0.57213\n",
      "[128]\ttraining's binary_logloss: 0.572062\n",
      "[129]\ttraining's binary_logloss: 0.572014\n",
      "[130]\ttraining's binary_logloss: 0.571953\n",
      "[131]\ttraining's binary_logloss: 0.57187\n",
      "[132]\ttraining's binary_logloss: 0.571798\n",
      "[133]\ttraining's binary_logloss: 0.571731\n",
      "[134]\ttraining's binary_logloss: 0.571661\n",
      "[135]\ttraining's binary_logloss: 0.571614\n",
      "[136]\ttraining's binary_logloss: 0.571532\n",
      "[137]\ttraining's binary_logloss: 0.571477\n",
      "[138]\ttraining's binary_logloss: 0.571436\n",
      "[139]\ttraining's binary_logloss: 0.571385\n",
      "[140]\ttraining's binary_logloss: 0.571325\n",
      "[141]\ttraining's binary_logloss: 0.571297\n",
      "[142]\ttraining's binary_logloss: 0.571235\n",
      "[143]\ttraining's binary_logloss: 0.571168\n",
      "[144]\ttraining's binary_logloss: 0.571102\n",
      "[145]\ttraining's binary_logloss: 0.57106\n",
      "[146]\ttraining's binary_logloss: 0.570977\n",
      "[147]\ttraining's binary_logloss: 0.570892\n",
      "[148]\ttraining's binary_logloss: 0.570824\n",
      "[149]\ttraining's binary_logloss: 0.570779\n",
      "[150]\ttraining's binary_logloss: 0.570702\n",
      "[151]\ttraining's binary_logloss: 0.570646\n",
      "[152]\ttraining's binary_logloss: 0.570566\n",
      "[153]\ttraining's binary_logloss: 0.570512\n",
      "[154]\ttraining's binary_logloss: 0.570447\n",
      "[155]\ttraining's binary_logloss: 0.570359\n",
      "[156]\ttraining's binary_logloss: 0.570301\n",
      "[157]\ttraining's binary_logloss: 0.570279\n",
      "[158]\ttraining's binary_logloss: 0.570243\n",
      "[159]\ttraining's binary_logloss: 0.570238\n",
      "[160]\ttraining's binary_logloss: 0.570187\n",
      "[161]\ttraining's binary_logloss: 0.570092\n",
      "[162]\ttraining's binary_logloss: 0.56999\n",
      "[163]\ttraining's binary_logloss: 0.569916\n",
      "[164]\ttraining's binary_logloss: 0.569807\n",
      "[165]\ttraining's binary_logloss: 0.569698\n",
      "[166]\ttraining's binary_logloss: 0.56962\n",
      "[167]\ttraining's binary_logloss: 0.569538\n",
      "[168]\ttraining's binary_logloss: 0.56948\n",
      "[169]\ttraining's binary_logloss: 0.569398\n",
      "[170]\ttraining's binary_logloss: 0.569294\n",
      "[171]\ttraining's binary_logloss: 0.569215\n",
      "[172]\ttraining's binary_logloss: 0.569139\n",
      "[173]\ttraining's binary_logloss: 0.569066\n",
      "[174]\ttraining's binary_logloss: 0.569\n",
      "[175]\ttraining's binary_logloss: 0.56894\n",
      "[176]\ttraining's binary_logloss: 0.568873\n",
      "[177]\ttraining's binary_logloss: 0.568816\n",
      "[178]\ttraining's binary_logloss: 0.568747\n",
      "[179]\ttraining's binary_logloss: 0.568682\n",
      "[180]\ttraining's binary_logloss: 0.568631\n",
      "[181]\ttraining's binary_logloss: 0.568543\n",
      "[182]\ttraining's binary_logloss: 0.568435\n",
      "[183]\ttraining's binary_logloss: 0.568355\n",
      "[184]\ttraining's binary_logloss: 0.568292\n",
      "[185]\ttraining's binary_logloss: 0.568186\n",
      "[186]\ttraining's binary_logloss: 0.568113\n",
      "[187]\ttraining's binary_logloss: 0.56803\n",
      "[188]\ttraining's binary_logloss: 0.567949\n",
      "[189]\ttraining's binary_logloss: 0.567866\n",
      "[190]\ttraining's binary_logloss: 0.567789\n",
      "[191]\ttraining's binary_logloss: 0.567708\n",
      "[192]\ttraining's binary_logloss: 0.56764\n",
      "[193]\ttraining's binary_logloss: 0.567575\n",
      "[194]\ttraining's binary_logloss: 0.567518\n",
      "[195]\ttraining's binary_logloss: 0.567464\n",
      "[196]\ttraining's binary_logloss: 0.567366\n",
      "[197]\ttraining's binary_logloss: 0.567306\n",
      "[198]\ttraining's binary_logloss: 0.567212\n",
      "[199]\ttraining's binary_logloss: 0.567147\n",
      "[200]\ttraining's binary_logloss: 0.567055\n",
      "[201]\ttraining's binary_logloss: 0.56697\n",
      "[202]\ttraining's binary_logloss: 0.566911\n",
      "[203]\ttraining's binary_logloss: 0.566826\n",
      "[204]\ttraining's binary_logloss: 0.566772\n",
      "[205]\ttraining's binary_logloss: 0.566705\n",
      "[206]\ttraining's binary_logloss: 0.566628\n",
      "[207]\ttraining's binary_logloss: 0.566538\n",
      "[208]\ttraining's binary_logloss: 0.566461\n",
      "[209]\ttraining's binary_logloss: 0.566394\n",
      "[210]\ttraining's binary_logloss: 0.5663\n",
      "[211]\ttraining's binary_logloss: 0.566217\n",
      "[212]\ttraining's binary_logloss: 0.56614\n",
      "[213]\ttraining's binary_logloss: 0.566063\n",
      "[214]\ttraining's binary_logloss: 0.565968\n",
      "[215]\ttraining's binary_logloss: 0.565896\n",
      "[216]\ttraining's binary_logloss: 0.565815\n",
      "[217]\ttraining's binary_logloss: 0.565728\n",
      "[218]\ttraining's binary_logloss: 0.565644\n",
      "[219]\ttraining's binary_logloss: 0.565568\n",
      "[220]\ttraining's binary_logloss: 0.5655\n",
      "[221]\ttraining's binary_logloss: 0.565356\n",
      "[222]\ttraining's binary_logloss: 0.565222\n",
      "[223]\ttraining's binary_logloss: 0.565087\n",
      "[224]\ttraining's binary_logloss: 0.564952\n",
      "[225]\ttraining's binary_logloss: 0.564829\n",
      "[226]\ttraining's binary_logloss: 0.564742\n",
      "[227]\ttraining's binary_logloss: 0.564656\n",
      "[228]\ttraining's binary_logloss: 0.564574\n",
      "[229]\ttraining's binary_logloss: 0.564503\n",
      "[230]\ttraining's binary_logloss: 0.564427\n",
      "[231]\ttraining's binary_logloss: 0.564303\n",
      "[232]\ttraining's binary_logloss: 0.564188\n",
      "[233]\ttraining's binary_logloss: 0.564067\n",
      "[234]\ttraining's binary_logloss: 0.56394\n",
      "[235]\ttraining's binary_logloss: 0.563817\n",
      "[236]\ttraining's binary_logloss: 0.563685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[237]\ttraining's binary_logloss: 0.563577\n",
      "[238]\ttraining's binary_logloss: 0.563471\n",
      "[239]\ttraining's binary_logloss: 0.563341\n",
      "[240]\ttraining's binary_logloss: 0.563227\n",
      "[241]\ttraining's binary_logloss: 0.563127\n",
      "[242]\ttraining's binary_logloss: 0.563009\n",
      "[243]\ttraining's binary_logloss: 0.562898\n",
      "[244]\ttraining's binary_logloss: 0.562807\n",
      "[245]\ttraining's binary_logloss: 0.562694\n",
      "[246]\ttraining's binary_logloss: 0.562632\n",
      "[247]\ttraining's binary_logloss: 0.562578\n",
      "[248]\ttraining's binary_logloss: 0.562513\n",
      "[249]\ttraining's binary_logloss: 0.562455\n",
      "[250]\ttraining's binary_logloss: 0.562402\n",
      "[251]\ttraining's binary_logloss: 0.562296\n",
      "[252]\ttraining's binary_logloss: 0.562193\n",
      "[253]\ttraining's binary_logloss: 0.562086\n",
      "[254]\ttraining's binary_logloss: 0.561971\n",
      "[255]\ttraining's binary_logloss: 0.561839\n",
      "[256]\ttraining's binary_logloss: 0.561728\n",
      "[257]\ttraining's binary_logloss: 0.561616\n",
      "[258]\ttraining's binary_logloss: 0.561502\n",
      "[259]\ttraining's binary_logloss: 0.561395\n",
      "[260]\ttraining's binary_logloss: 0.561307\n",
      "[261]\ttraining's binary_logloss: 0.561177\n",
      "[262]\ttraining's binary_logloss: 0.561068\n",
      "[263]\ttraining's binary_logloss: 0.560944\n",
      "[264]\ttraining's binary_logloss: 0.560826\n",
      "[265]\ttraining's binary_logloss: 0.56072\n",
      "[266]\ttraining's binary_logloss: 0.560652\n",
      "[267]\ttraining's binary_logloss: 0.560585\n",
      "[268]\ttraining's binary_logloss: 0.560521\n",
      "[269]\ttraining's binary_logloss: 0.560425\n",
      "[270]\ttraining's binary_logloss: 0.560362\n",
      "[271]\ttraining's binary_logloss: 0.560228\n",
      "[272]\ttraining's binary_logloss: 0.560085\n",
      "[273]\ttraining's binary_logloss: 0.559956\n",
      "[274]\ttraining's binary_logloss: 0.559838\n",
      "[275]\ttraining's binary_logloss: 0.55971\n",
      "[276]\ttraining's binary_logloss: 0.559591\n",
      "[277]\ttraining's binary_logloss: 0.559462\n",
      "[278]\ttraining's binary_logloss: 0.55932\n",
      "[279]\ttraining's binary_logloss: 0.559184\n",
      "[280]\ttraining's binary_logloss: 0.559059\n",
      "[281]\ttraining's binary_logloss: 0.558978\n",
      "[282]\ttraining's binary_logloss: 0.558899\n",
      "[283]\ttraining's binary_logloss: 0.558822\n",
      "[284]\ttraining's binary_logloss: 0.558731\n",
      "[285]\ttraining's binary_logloss: 0.558624\n",
      "[286]\ttraining's binary_logloss: 0.558486\n",
      "[287]\ttraining's binary_logloss: 0.558344\n",
      "[288]\ttraining's binary_logloss: 0.558206\n",
      "[289]\ttraining's binary_logloss: 0.55808\n",
      "[290]\ttraining's binary_logloss: 0.557948\n",
      "[291]\ttraining's binary_logloss: 0.557815\n",
      "[292]\ttraining's binary_logloss: 0.557674\n",
      "[293]\ttraining's binary_logloss: 0.55754\n",
      "[294]\ttraining's binary_logloss: 0.557393\n",
      "[295]\ttraining's binary_logloss: 0.557242\n",
      "[296]\ttraining's binary_logloss: 0.557106\n",
      "[297]\ttraining's binary_logloss: 0.556987\n",
      "[298]\ttraining's binary_logloss: 0.556884\n",
      "[299]\ttraining's binary_logloss: 0.556803\n",
      "[300]\ttraining's binary_logloss: 0.556721\n",
      "[301]\ttraining's binary_logloss: 0.556575\n",
      "[302]\ttraining's binary_logloss: 0.556443\n",
      "[303]\ttraining's binary_logloss: 0.556305\n",
      "[304]\ttraining's binary_logloss: 0.556177\n",
      "[305]\ttraining's binary_logloss: 0.556043\n",
      "[306]\ttraining's binary_logloss: 0.555944\n",
      "[307]\ttraining's binary_logloss: 0.55585\n",
      "[308]\ttraining's binary_logloss: 0.555742\n",
      "[309]\ttraining's binary_logloss: 0.555626\n",
      "[310]\ttraining's binary_logloss: 0.55551\n",
      "[311]\ttraining's binary_logloss: 0.555412\n",
      "[312]\ttraining's binary_logloss: 0.555318\n",
      "[313]\ttraining's binary_logloss: 0.555227\n",
      "[314]\ttraining's binary_logloss: 0.555141\n",
      "[315]\ttraining's binary_logloss: 0.555055\n",
      "[316]\ttraining's binary_logloss: 0.554905\n",
      "[317]\ttraining's binary_logloss: 0.554725\n",
      "[318]\ttraining's binary_logloss: 0.554579\n",
      "[319]\ttraining's binary_logloss: 0.554409\n",
      "[320]\ttraining's binary_logloss: 0.55424\n",
      "[321]\ttraining's binary_logloss: 0.554103\n",
      "[322]\ttraining's binary_logloss: 0.553962\n",
      "[323]\ttraining's binary_logloss: 0.553817\n",
      "[324]\ttraining's binary_logloss: 0.553658\n",
      "[325]\ttraining's binary_logloss: 0.55353\n",
      "[326]\ttraining's binary_logloss: 0.553377\n",
      "[327]\ttraining's binary_logloss: 0.553228\n",
      "[328]\ttraining's binary_logloss: 0.553077\n",
      "[329]\ttraining's binary_logloss: 0.552928\n",
      "[330]\ttraining's binary_logloss: 0.552779\n",
      "[331]\ttraining's binary_logloss: 0.552606\n",
      "[332]\ttraining's binary_logloss: 0.552451\n",
      "[333]\ttraining's binary_logloss: 0.552302\n",
      "[334]\ttraining's binary_logloss: 0.552158\n",
      "[335]\ttraining's binary_logloss: 0.552013\n",
      "[336]\ttraining's binary_logloss: 0.551922\n",
      "[337]\ttraining's binary_logloss: 0.551798\n",
      "[338]\ttraining's binary_logloss: 0.551706\n",
      "[339]\ttraining's binary_logloss: 0.551589\n",
      "[340]\ttraining's binary_logloss: 0.55148\n",
      "[341]\ttraining's binary_logloss: 0.551391\n",
      "[342]\ttraining's binary_logloss: 0.551299\n",
      "[343]\ttraining's binary_logloss: 0.551204\n",
      "[344]\ttraining's binary_logloss: 0.551112\n",
      "[345]\ttraining's binary_logloss: 0.551021\n",
      "[346]\ttraining's binary_logloss: 0.550858\n",
      "[347]\ttraining's binary_logloss: 0.550718\n",
      "[348]\ttraining's binary_logloss: 0.550569\n",
      "[349]\ttraining's binary_logloss: 0.550431\n",
      "[350]\ttraining's binary_logloss: 0.550286\n",
      "[351]\ttraining's binary_logloss: 0.550144\n",
      "[352]\ttraining's binary_logloss: 0.550013\n",
      "[353]\ttraining's binary_logloss: 0.549882\n",
      "[354]\ttraining's binary_logloss: 0.549771\n",
      "[355]\ttraining's binary_logloss: 0.549637\n",
      "[356]\ttraining's binary_logloss: 0.549487\n",
      "[357]\ttraining's binary_logloss: 0.549346\n",
      "[358]\ttraining's binary_logloss: 0.549204\n",
      "[359]\ttraining's binary_logloss: 0.549027\n",
      "[360]\ttraining's binary_logloss: 0.548872\n",
      "[361]\ttraining's binary_logloss: 0.548702\n",
      "[362]\ttraining's binary_logloss: 0.548542\n",
      "[363]\ttraining's binary_logloss: 0.548373\n",
      "[364]\ttraining's binary_logloss: 0.548206\n",
      "[365]\ttraining's binary_logloss: 0.548036\n",
      "[366]\ttraining's binary_logloss: 0.547894\n",
      "[367]\ttraining's binary_logloss: 0.547737\n",
      "[368]\ttraining's binary_logloss: 0.5476\n",
      "[369]\ttraining's binary_logloss: 0.54746\n",
      "[370]\ttraining's binary_logloss: 0.547319\n",
      "[371]\ttraining's binary_logloss: 0.547204\n",
      "[372]\ttraining's binary_logloss: 0.547096\n",
      "[373]\ttraining's binary_logloss: 0.546987\n",
      "[374]\ttraining's binary_logloss: 0.546886\n",
      "[375]\ttraining's binary_logloss: 0.546783\n",
      "[376]\ttraining's binary_logloss: 0.546632\n",
      "[377]\ttraining's binary_logloss: 0.546491\n",
      "[378]\ttraining's binary_logloss: 0.546335\n",
      "[379]\ttraining's binary_logloss: 0.546179\n",
      "[380]\ttraining's binary_logloss: 0.546043\n",
      "[381]\ttraining's binary_logloss: 0.545908\n",
      "[382]\ttraining's binary_logloss: 0.545798\n",
      "[383]\ttraining's binary_logloss: 0.545721\n",
      "[384]\ttraining's binary_logloss: 0.545639\n",
      "[385]\ttraining's binary_logloss: 0.545516\n",
      "[386]\ttraining's binary_logloss: 0.545318\n",
      "[387]\ttraining's binary_logloss: 0.545103\n",
      "[388]\ttraining's binary_logloss: 0.54488\n",
      "[389]\ttraining's binary_logloss: 0.544692\n",
      "[390]\ttraining's binary_logloss: 0.544506\n",
      "[391]\ttraining's binary_logloss: 0.544362\n",
      "[392]\ttraining's binary_logloss: 0.544214\n",
      "[393]\ttraining's binary_logloss: 0.544068\n",
      "[394]\ttraining's binary_logloss: 0.543915\n",
      "[395]\ttraining's binary_logloss: 0.543762\n",
      "[396]\ttraining's binary_logloss: 0.54361\n",
      "[397]\ttraining's binary_logloss: 0.543446\n",
      "[398]\ttraining's binary_logloss: 0.543281\n",
      "[399]\ttraining's binary_logloss: 0.543138\n",
      "[400]\ttraining's binary_logloss: 0.54299\n",
      "[401]\ttraining's binary_logloss: 0.542815\n",
      "[402]\ttraining's binary_logloss: 0.542643\n",
      "[403]\ttraining's binary_logloss: 0.542468\n",
      "[404]\ttraining's binary_logloss: 0.542314\n",
      "[405]\ttraining's binary_logloss: 0.542159\n",
      "[406]\ttraining's binary_logloss: 0.542038\n",
      "[407]\ttraining's binary_logloss: 0.541915\n",
      "[408]\ttraining's binary_logloss: 0.541788\n",
      "[409]\ttraining's binary_logloss: 0.541667\n",
      "[410]\ttraining's binary_logloss: 0.54155\n",
      "[411]\ttraining's binary_logloss: 0.541372\n",
      "[412]\ttraining's binary_logloss: 0.54119\n",
      "[413]\ttraining's binary_logloss: 0.541026\n",
      "[414]\ttraining's binary_logloss: 0.540852\n",
      "[415]\ttraining's binary_logloss: 0.540667\n",
      "[416]\ttraining's binary_logloss: 0.540517\n",
      "[417]\ttraining's binary_logloss: 0.540371\n",
      "[418]\ttraining's binary_logloss: 0.540229\n",
      "[419]\ttraining's binary_logloss: 0.54007\n",
      "[420]\ttraining's binary_logloss: 0.539933\n",
      "[421]\ttraining's binary_logloss: 0.539812\n",
      "[422]\ttraining's binary_logloss: 0.539698\n",
      "[423]\ttraining's binary_logloss: 0.539602\n",
      "[424]\ttraining's binary_logloss: 0.539483\n",
      "[425]\ttraining's binary_logloss: 0.53938\n",
      "[426]\ttraining's binary_logloss: 0.53926\n",
      "[427]\ttraining's binary_logloss: 0.539159\n",
      "[428]\ttraining's binary_logloss: 0.539033\n",
      "[429]\ttraining's binary_logloss: 0.538931\n",
      "[430]\ttraining's binary_logloss: 0.538835\n",
      "[431]\ttraining's binary_logloss: 0.538662\n",
      "[432]\ttraining's binary_logloss: 0.538517\n",
      "[433]\ttraining's binary_logloss: 0.538337\n",
      "[434]\ttraining's binary_logloss: 0.538166\n",
      "[435]\ttraining's binary_logloss: 0.538029\n",
      "[436]\ttraining's binary_logloss: 0.537907\n",
      "[437]\ttraining's binary_logloss: 0.537789\n",
      "[438]\ttraining's binary_logloss: 0.537663\n",
      "[439]\ttraining's binary_logloss: 0.537521\n",
      "[440]\ttraining's binary_logloss: 0.537388\n",
      "[441]\ttraining's binary_logloss: 0.537242\n",
      "[442]\ttraining's binary_logloss: 0.537083\n",
      "[443]\ttraining's binary_logloss: 0.536936\n",
      "[444]\ttraining's binary_logloss: 0.5368\n",
      "[445]\ttraining's binary_logloss: 0.53667\n",
      "[446]\ttraining's binary_logloss: 0.536523\n",
      "[447]\ttraining's binary_logloss: 0.536376\n",
      "[448]\ttraining's binary_logloss: 0.536247\n",
      "[449]\ttraining's binary_logloss: 0.536109\n",
      "[450]\ttraining's binary_logloss: 0.535973\n",
      "[451]\ttraining's binary_logloss: 0.535851\n",
      "[452]\ttraining's binary_logloss: 0.535718\n",
      "[453]\ttraining's binary_logloss: 0.535601\n",
      "[454]\ttraining's binary_logloss: 0.535463\n",
      "[455]\ttraining's binary_logloss: 0.53534\n",
      "[456]\ttraining's binary_logloss: 0.535225\n",
      "[457]\ttraining's binary_logloss: 0.535116\n",
      "[458]\ttraining's binary_logloss: 0.535004\n",
      "[459]\ttraining's binary_logloss: 0.534892\n",
      "[460]\ttraining's binary_logloss: 0.534781\n",
      "[461]\ttraining's binary_logloss: 0.534608\n",
      "[462]\ttraining's binary_logloss: 0.534459\n",
      "[463]\ttraining's binary_logloss: 0.534301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[464]\ttraining's binary_logloss: 0.534134\n",
      "[465]\ttraining's binary_logloss: 0.533982\n",
      "[466]\ttraining's binary_logloss: 0.533841\n",
      "[467]\ttraining's binary_logloss: 0.533697\n",
      "[468]\ttraining's binary_logloss: 0.533547\n",
      "[469]\ttraining's binary_logloss: 0.533388\n",
      "[470]\ttraining's binary_logloss: 0.533256\n",
      "[471]\ttraining's binary_logloss: 0.533128\n",
      "[472]\ttraining's binary_logloss: 0.533004\n",
      "[473]\ttraining's binary_logloss: 0.532872\n",
      "[474]\ttraining's binary_logloss: 0.53272\n",
      "[475]\ttraining's binary_logloss: 0.532611\n",
      "[476]\ttraining's binary_logloss: 0.532474\n",
      "[477]\ttraining's binary_logloss: 0.532342\n",
      "[478]\ttraining's binary_logloss: 0.532211\n",
      "[479]\ttraining's binary_logloss: 0.532081\n",
      "[480]\ttraining's binary_logloss: 0.531954\n",
      "[481]\ttraining's binary_logloss: 0.531827\n",
      "[482]\ttraining's binary_logloss: 0.531712\n",
      "[483]\ttraining's binary_logloss: 0.53158\n",
      "[484]\ttraining's binary_logloss: 0.53145\n",
      "[485]\ttraining's binary_logloss: 0.531309\n",
      "[486]\ttraining's binary_logloss: 0.531154\n",
      "[487]\ttraining's binary_logloss: 0.530988\n",
      "[488]\ttraining's binary_logloss: 0.530845\n",
      "[489]\ttraining's binary_logloss: 0.530683\n",
      "[490]\ttraining's binary_logloss: 0.530523\n",
      "[491]\ttraining's binary_logloss: 0.530415\n",
      "[492]\ttraining's binary_logloss: 0.530309\n",
      "[493]\ttraining's binary_logloss: 0.530228\n",
      "[494]\ttraining's binary_logloss: 0.530127\n",
      "[495]\ttraining's binary_logloss: 0.530034\n",
      "[496]\ttraining's binary_logloss: 0.529874\n",
      "[497]\ttraining's binary_logloss: 0.52971\n",
      "[498]\ttraining's binary_logloss: 0.529558\n",
      "[499]\ttraining's binary_logloss: 0.529424\n",
      "[500]\ttraining's binary_logloss: 0.529263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613744\n",
      "[2]\ttraining's binary_logloss: 0.61239\n",
      "[3]\ttraining's binary_logloss: 0.611104\n",
      "[4]\ttraining's binary_logloss: 0.609801\n",
      "[5]\ttraining's binary_logloss: 0.608455\n",
      "[6]\ttraining's binary_logloss: 0.607281\n",
      "[7]\ttraining's binary_logloss: 0.606146\n",
      "[8]\ttraining's binary_logloss: 0.605042\n",
      "[9]\ttraining's binary_logloss: 0.603943\n",
      "[10]\ttraining's binary_logloss: 0.603021\n",
      "[11]\ttraining's binary_logloss: 0.601932\n",
      "[12]\ttraining's binary_logloss: 0.600886\n",
      "[13]\ttraining's binary_logloss: 0.599861\n",
      "[14]\ttraining's binary_logloss: 0.598979\n",
      "[15]\ttraining's binary_logloss: 0.598112\n",
      "[16]\ttraining's binary_logloss: 0.597198\n",
      "[17]\ttraining's binary_logloss: 0.596323\n",
      "[18]\ttraining's binary_logloss: 0.595473\n",
      "[19]\ttraining's binary_logloss: 0.594629\n",
      "[20]\ttraining's binary_logloss: 0.593894\n",
      "[21]\ttraining's binary_logloss: 0.59311\n",
      "[22]\ttraining's binary_logloss: 0.592352\n",
      "[23]\ttraining's binary_logloss: 0.591692\n",
      "[24]\ttraining's binary_logloss: 0.590999\n",
      "[25]\ttraining's binary_logloss: 0.590317\n",
      "[26]\ttraining's binary_logloss: 0.589725\n",
      "[27]\ttraining's binary_logloss: 0.589144\n",
      "[28]\ttraining's binary_logloss: 0.588596\n",
      "[29]\ttraining's binary_logloss: 0.588106\n",
      "[30]\ttraining's binary_logloss: 0.587535\n",
      "[31]\ttraining's binary_logloss: 0.58692\n",
      "[32]\ttraining's binary_logloss: 0.586301\n",
      "[33]\ttraining's binary_logloss: 0.585706\n",
      "[34]\ttraining's binary_logloss: 0.585208\n",
      "[35]\ttraining's binary_logloss: 0.58465\n",
      "[36]\ttraining's binary_logloss: 0.58419\n",
      "[37]\ttraining's binary_logloss: 0.583665\n",
      "[38]\ttraining's binary_logloss: 0.583128\n",
      "[39]\ttraining's binary_logloss: 0.582628\n",
      "[40]\ttraining's binary_logloss: 0.582156\n",
      "[41]\ttraining's binary_logloss: 0.581757\n",
      "[42]\ttraining's binary_logloss: 0.581374\n",
      "[43]\ttraining's binary_logloss: 0.581037\n",
      "[44]\ttraining's binary_logloss: 0.580675\n",
      "[45]\ttraining's binary_logloss: 0.580328\n",
      "[46]\ttraining's binary_logloss: 0.579921\n",
      "[47]\ttraining's binary_logloss: 0.579512\n",
      "[48]\ttraining's binary_logloss: 0.579159\n",
      "[49]\ttraining's binary_logloss: 0.578787\n",
      "[50]\ttraining's binary_logloss: 0.578431\n",
      "[51]\ttraining's binary_logloss: 0.578062\n",
      "[52]\ttraining's binary_logloss: 0.577712\n",
      "[53]\ttraining's binary_logloss: 0.577384\n",
      "[54]\ttraining's binary_logloss: 0.577061\n",
      "[55]\ttraining's binary_logloss: 0.576755\n",
      "[56]\ttraining's binary_logloss: 0.576419\n",
      "[57]\ttraining's binary_logloss: 0.576107\n",
      "[58]\ttraining's binary_logloss: 0.575863\n",
      "[59]\ttraining's binary_logloss: 0.575557\n",
      "[60]\ttraining's binary_logloss: 0.575333\n",
      "[61]\ttraining's binary_logloss: 0.575053\n",
      "[62]\ttraining's binary_logloss: 0.574824\n",
      "[63]\ttraining's binary_logloss: 0.574549\n",
      "[64]\ttraining's binary_logloss: 0.574332\n",
      "[65]\ttraining's binary_logloss: 0.574084\n",
      "[66]\ttraining's binary_logloss: 0.573865\n",
      "[67]\ttraining's binary_logloss: 0.573651\n",
      "[68]\ttraining's binary_logloss: 0.573476\n",
      "[69]\ttraining's binary_logloss: 0.573268\n",
      "[70]\ttraining's binary_logloss: 0.57306\n",
      "[71]\ttraining's binary_logloss: 0.57286\n",
      "[72]\ttraining's binary_logloss: 0.572685\n",
      "[73]\ttraining's binary_logloss: 0.5725\n",
      "[74]\ttraining's binary_logloss: 0.572338\n",
      "[75]\ttraining's binary_logloss: 0.572179\n",
      "[76]\ttraining's binary_logloss: 0.571953\n",
      "[77]\ttraining's binary_logloss: 0.571731\n",
      "[78]\ttraining's binary_logloss: 0.571507\n",
      "[79]\ttraining's binary_logloss: 0.571299\n",
      "[80]\ttraining's binary_logloss: 0.57109\n",
      "[81]\ttraining's binary_logloss: 0.570922\n",
      "[82]\ttraining's binary_logloss: 0.57077\n",
      "[83]\ttraining's binary_logloss: 0.570641\n",
      "[84]\ttraining's binary_logloss: 0.57055\n",
      "[85]\ttraining's binary_logloss: 0.570456\n",
      "[86]\ttraining's binary_logloss: 0.570265\n",
      "[87]\ttraining's binary_logloss: 0.570086\n",
      "[88]\ttraining's binary_logloss: 0.56992\n",
      "[89]\ttraining's binary_logloss: 0.569754\n",
      "[90]\ttraining's binary_logloss: 0.569581\n",
      "[91]\ttraining's binary_logloss: 0.5695\n",
      "[92]\ttraining's binary_logloss: 0.569432\n",
      "[93]\ttraining's binary_logloss: 0.569378\n",
      "[94]\ttraining's binary_logloss: 0.569279\n",
      "[95]\ttraining's binary_logloss: 0.569164\n",
      "[96]\ttraining's binary_logloss: 0.569065\n",
      "[97]\ttraining's binary_logloss: 0.568949\n",
      "[98]\ttraining's binary_logloss: 0.568848\n",
      "[99]\ttraining's binary_logloss: 0.568758\n",
      "[100]\ttraining's binary_logloss: 0.568648\n",
      "[101]\ttraining's binary_logloss: 0.568554\n",
      "[102]\ttraining's binary_logloss: 0.568482\n",
      "[103]\ttraining's binary_logloss: 0.568396\n",
      "[104]\ttraining's binary_logloss: 0.568332\n",
      "[105]\ttraining's binary_logloss: 0.56828\n",
      "[106]\ttraining's binary_logloss: 0.568123\n",
      "[107]\ttraining's binary_logloss: 0.567967\n",
      "[108]\ttraining's binary_logloss: 0.567859\n",
      "[109]\ttraining's binary_logloss: 0.56777\n",
      "[110]\ttraining's binary_logloss: 0.567688\n",
      "[111]\ttraining's binary_logloss: 0.567591\n",
      "[112]\ttraining's binary_logloss: 0.567486\n",
      "[113]\ttraining's binary_logloss: 0.567432\n",
      "[114]\ttraining's binary_logloss: 0.567333\n",
      "[115]\ttraining's binary_logloss: 0.567217\n",
      "[116]\ttraining's binary_logloss: 0.567123\n",
      "[117]\ttraining's binary_logloss: 0.567056\n",
      "[118]\ttraining's binary_logloss: 0.566977\n",
      "[119]\ttraining's binary_logloss: 0.56689\n",
      "[120]\ttraining's binary_logloss: 0.566845\n",
      "[121]\ttraining's binary_logloss: 0.566733\n",
      "[122]\ttraining's binary_logloss: 0.566624\n",
      "[123]\ttraining's binary_logloss: 0.566523\n",
      "[124]\ttraining's binary_logloss: 0.566429\n",
      "[125]\ttraining's binary_logloss: 0.566336\n",
      "[126]\ttraining's binary_logloss: 0.56623\n",
      "[127]\ttraining's binary_logloss: 0.566123\n",
      "[128]\ttraining's binary_logloss: 0.566014\n",
      "[129]\ttraining's binary_logloss: 0.565923\n",
      "[130]\ttraining's binary_logloss: 0.565829\n",
      "[131]\ttraining's binary_logloss: 0.565722\n",
      "[132]\ttraining's binary_logloss: 0.565652\n",
      "[133]\ttraining's binary_logloss: 0.565578\n",
      "[134]\ttraining's binary_logloss: 0.56551\n",
      "[135]\ttraining's binary_logloss: 0.565458\n",
      "[136]\ttraining's binary_logloss: 0.56537\n",
      "[137]\ttraining's binary_logloss: 0.565287\n",
      "[138]\ttraining's binary_logloss: 0.565196\n",
      "[139]\ttraining's binary_logloss: 0.565107\n",
      "[140]\ttraining's binary_logloss: 0.565046\n",
      "[141]\ttraining's binary_logloss: 0.564941\n",
      "[142]\ttraining's binary_logloss: 0.564852\n",
      "[143]\ttraining's binary_logloss: 0.564825\n",
      "[144]\ttraining's binary_logloss: 0.564777\n",
      "[145]\ttraining's binary_logloss: 0.564694\n",
      "[146]\ttraining's binary_logloss: 0.564626\n",
      "[147]\ttraining's binary_logloss: 0.564557\n",
      "[148]\ttraining's binary_logloss: 0.5645\n",
      "[149]\ttraining's binary_logloss: 0.564405\n",
      "[150]\ttraining's binary_logloss: 0.564349\n",
      "[151]\ttraining's binary_logloss: 0.564261\n",
      "[152]\ttraining's binary_logloss: 0.564171\n",
      "[153]\ttraining's binary_logloss: 0.564088\n",
      "[154]\ttraining's binary_logloss: 0.564003\n",
      "[155]\ttraining's binary_logloss: 0.56391\n",
      "[156]\ttraining's binary_logloss: 0.563832\n",
      "[157]\ttraining's binary_logloss: 0.563762\n",
      "[158]\ttraining's binary_logloss: 0.563707\n",
      "[159]\ttraining's binary_logloss: 0.56366\n",
      "[160]\ttraining's binary_logloss: 0.563579\n",
      "[161]\ttraining's binary_logloss: 0.563473\n",
      "[162]\ttraining's binary_logloss: 0.563345\n",
      "[163]\ttraining's binary_logloss: 0.563258\n",
      "[164]\ttraining's binary_logloss: 0.563156\n",
      "[165]\ttraining's binary_logloss: 0.563059\n",
      "[166]\ttraining's binary_logloss: 0.562956\n",
      "[167]\ttraining's binary_logloss: 0.562846\n",
      "[168]\ttraining's binary_logloss: 0.562784\n",
      "[169]\ttraining's binary_logloss: 0.56267\n",
      "[170]\ttraining's binary_logloss: 0.562581\n",
      "[171]\ttraining's binary_logloss: 0.562458\n",
      "[172]\ttraining's binary_logloss: 0.562334\n",
      "[173]\ttraining's binary_logloss: 0.562267\n",
      "[174]\ttraining's binary_logloss: 0.562169\n",
      "[175]\ttraining's binary_logloss: 0.562049\n",
      "[176]\ttraining's binary_logloss: 0.561959\n",
      "[177]\ttraining's binary_logloss: 0.561891\n",
      "[178]\ttraining's binary_logloss: 0.561807\n",
      "[179]\ttraining's binary_logloss: 0.561732\n",
      "[180]\ttraining's binary_logloss: 0.561667\n",
      "[181]\ttraining's binary_logloss: 0.561582\n",
      "[182]\ttraining's binary_logloss: 0.561516\n",
      "[183]\ttraining's binary_logloss: 0.561454\n",
      "[184]\ttraining's binary_logloss: 0.56139\n",
      "[185]\ttraining's binary_logloss: 0.561329\n",
      "[186]\ttraining's binary_logloss: 0.561222\n",
      "[187]\ttraining's binary_logloss: 0.561131\n",
      "[188]\ttraining's binary_logloss: 0.561034\n",
      "[189]\ttraining's binary_logloss: 0.560929\n",
      "[190]\ttraining's binary_logloss: 0.560831\n",
      "[191]\ttraining's binary_logloss: 0.560723\n",
      "[192]\ttraining's binary_logloss: 0.560658\n",
      "[193]\ttraining's binary_logloss: 0.56056\n",
      "[194]\ttraining's binary_logloss: 0.560462\n",
      "[195]\ttraining's binary_logloss: 0.560414\n",
      "[196]\ttraining's binary_logloss: 0.560285\n",
      "[197]\ttraining's binary_logloss: 0.560157\n",
      "[198]\ttraining's binary_logloss: 0.560055\n",
      "[199]\ttraining's binary_logloss: 0.559969\n",
      "[200]\ttraining's binary_logloss: 0.55986\n",
      "[201]\ttraining's binary_logloss: 0.559817\n",
      "[202]\ttraining's binary_logloss: 0.55971\n",
      "[203]\ttraining's binary_logloss: 0.559597\n",
      "[204]\ttraining's binary_logloss: 0.559494\n",
      "[205]\ttraining's binary_logloss: 0.559405\n",
      "[206]\ttraining's binary_logloss: 0.559297\n",
      "[207]\ttraining's binary_logloss: 0.559202\n",
      "[208]\ttraining's binary_logloss: 0.559121\n",
      "[209]\ttraining's binary_logloss: 0.559052\n",
      "[210]\ttraining's binary_logloss: 0.558979\n",
      "[211]\ttraining's binary_logloss: 0.558911\n",
      "[212]\ttraining's binary_logloss: 0.558843\n",
      "[213]\ttraining's binary_logloss: 0.558785\n",
      "[214]\ttraining's binary_logloss: 0.558712\n",
      "[215]\ttraining's binary_logloss: 0.558657\n",
      "[216]\ttraining's binary_logloss: 0.558528\n",
      "[217]\ttraining's binary_logloss: 0.558413\n",
      "[218]\ttraining's binary_logloss: 0.558295\n",
      "[219]\ttraining's binary_logloss: 0.558181\n",
      "[220]\ttraining's binary_logloss: 0.558047\n",
      "[221]\ttraining's binary_logloss: 0.557899\n",
      "[222]\ttraining's binary_logloss: 0.55775\n",
      "[223]\ttraining's binary_logloss: 0.557606\n",
      "[224]\ttraining's binary_logloss: 0.557462\n",
      "[225]\ttraining's binary_logloss: 0.557329\n",
      "[226]\ttraining's binary_logloss: 0.557229\n",
      "[227]\ttraining's binary_logloss: 0.557133\n",
      "[228]\ttraining's binary_logloss: 0.557056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[229]\ttraining's binary_logloss: 0.556989\n",
      "[230]\ttraining's binary_logloss: 0.556901\n",
      "[231]\ttraining's binary_logloss: 0.5568\n",
      "[232]\ttraining's binary_logloss: 0.556718\n",
      "[233]\ttraining's binary_logloss: 0.556623\n",
      "[234]\ttraining's binary_logloss: 0.556536\n",
      "[235]\ttraining's binary_logloss: 0.556444\n",
      "[236]\ttraining's binary_logloss: 0.55633\n",
      "[237]\ttraining's binary_logloss: 0.556219\n",
      "[238]\ttraining's binary_logloss: 0.556111\n",
      "[239]\ttraining's binary_logloss: 0.556\n",
      "[240]\ttraining's binary_logloss: 0.555879\n",
      "[241]\ttraining's binary_logloss: 0.555759\n",
      "[242]\ttraining's binary_logloss: 0.555653\n",
      "[243]\ttraining's binary_logloss: 0.555547\n",
      "[244]\ttraining's binary_logloss: 0.55543\n",
      "[245]\ttraining's binary_logloss: 0.555318\n",
      "[246]\ttraining's binary_logloss: 0.555213\n",
      "[247]\ttraining's binary_logloss: 0.555098\n",
      "[248]\ttraining's binary_logloss: 0.55497\n",
      "[249]\ttraining's binary_logloss: 0.554849\n",
      "[250]\ttraining's binary_logloss: 0.554735\n",
      "[251]\ttraining's binary_logloss: 0.554627\n",
      "[252]\ttraining's binary_logloss: 0.554549\n",
      "[253]\ttraining's binary_logloss: 0.554442\n",
      "[254]\ttraining's binary_logloss: 0.554341\n",
      "[255]\ttraining's binary_logloss: 0.554242\n",
      "[256]\ttraining's binary_logloss: 0.554151\n",
      "[257]\ttraining's binary_logloss: 0.553996\n",
      "[258]\ttraining's binary_logloss: 0.553844\n",
      "[259]\ttraining's binary_logloss: 0.553692\n",
      "[260]\ttraining's binary_logloss: 0.553537\n",
      "[261]\ttraining's binary_logloss: 0.553438\n",
      "[262]\ttraining's binary_logloss: 0.553311\n",
      "[263]\ttraining's binary_logloss: 0.553219\n",
      "[264]\ttraining's binary_logloss: 0.553128\n",
      "[265]\ttraining's binary_logloss: 0.55303\n",
      "[266]\ttraining's binary_logloss: 0.552956\n",
      "[267]\ttraining's binary_logloss: 0.552914\n",
      "[268]\ttraining's binary_logloss: 0.552854\n",
      "[269]\ttraining's binary_logloss: 0.552793\n",
      "[270]\ttraining's binary_logloss: 0.552745\n",
      "[271]\ttraining's binary_logloss: 0.552587\n",
      "[272]\ttraining's binary_logloss: 0.552429\n",
      "[273]\ttraining's binary_logloss: 0.552266\n",
      "[274]\ttraining's binary_logloss: 0.552114\n",
      "[275]\ttraining's binary_logloss: 0.551964\n",
      "[276]\ttraining's binary_logloss: 0.551818\n",
      "[277]\ttraining's binary_logloss: 0.551648\n",
      "[278]\ttraining's binary_logloss: 0.551509\n",
      "[279]\ttraining's binary_logloss: 0.551348\n",
      "[280]\ttraining's binary_logloss: 0.55121\n",
      "[281]\ttraining's binary_logloss: 0.551074\n",
      "[282]\ttraining's binary_logloss: 0.550935\n",
      "[283]\ttraining's binary_logloss: 0.550807\n",
      "[284]\ttraining's binary_logloss: 0.550689\n",
      "[285]\ttraining's binary_logloss: 0.550578\n",
      "[286]\ttraining's binary_logloss: 0.550448\n",
      "[287]\ttraining's binary_logloss: 0.550324\n",
      "[288]\ttraining's binary_logloss: 0.550198\n",
      "[289]\ttraining's binary_logloss: 0.550064\n",
      "[290]\ttraining's binary_logloss: 0.549939\n",
      "[291]\ttraining's binary_logloss: 0.549779\n",
      "[292]\ttraining's binary_logloss: 0.549629\n",
      "[293]\ttraining's binary_logloss: 0.549468\n",
      "[294]\ttraining's binary_logloss: 0.549321\n",
      "[295]\ttraining's binary_logloss: 0.549184\n",
      "[296]\ttraining's binary_logloss: 0.549074\n",
      "[297]\ttraining's binary_logloss: 0.548971\n",
      "[298]\ttraining's binary_logloss: 0.548858\n",
      "[299]\ttraining's binary_logloss: 0.548748\n",
      "[300]\ttraining's binary_logloss: 0.548647\n",
      "[301]\ttraining's binary_logloss: 0.548531\n",
      "[302]\ttraining's binary_logloss: 0.548375\n",
      "[303]\ttraining's binary_logloss: 0.548224\n",
      "[304]\ttraining's binary_logloss: 0.5481\n",
      "[305]\ttraining's binary_logloss: 0.547969\n",
      "[306]\ttraining's binary_logloss: 0.54786\n",
      "[307]\ttraining's binary_logloss: 0.547727\n",
      "[308]\ttraining's binary_logloss: 0.547577\n",
      "[309]\ttraining's binary_logloss: 0.547438\n",
      "[310]\ttraining's binary_logloss: 0.547299\n",
      "[311]\ttraining's binary_logloss: 0.547185\n",
      "[312]\ttraining's binary_logloss: 0.547074\n",
      "[313]\ttraining's binary_logloss: 0.546965\n",
      "[314]\ttraining's binary_logloss: 0.546867\n",
      "[315]\ttraining's binary_logloss: 0.546758\n",
      "[316]\ttraining's binary_logloss: 0.546639\n",
      "[317]\ttraining's binary_logloss: 0.546518\n",
      "[318]\ttraining's binary_logloss: 0.546414\n",
      "[319]\ttraining's binary_logloss: 0.546295\n",
      "[320]\ttraining's binary_logloss: 0.546183\n",
      "[321]\ttraining's binary_logloss: 0.546085\n",
      "[322]\ttraining's binary_logloss: 0.54597\n",
      "[323]\ttraining's binary_logloss: 0.545868\n",
      "[324]\ttraining's binary_logloss: 0.545757\n",
      "[325]\ttraining's binary_logloss: 0.545647\n",
      "[326]\ttraining's binary_logloss: 0.545504\n",
      "[327]\ttraining's binary_logloss: 0.545361\n",
      "[328]\ttraining's binary_logloss: 0.545228\n",
      "[329]\ttraining's binary_logloss: 0.545074\n",
      "[330]\ttraining's binary_logloss: 0.544947\n",
      "[331]\ttraining's binary_logloss: 0.54483\n",
      "[332]\ttraining's binary_logloss: 0.544687\n",
      "[333]\ttraining's binary_logloss: 0.544555\n",
      "[334]\ttraining's binary_logloss: 0.544417\n",
      "[335]\ttraining's binary_logloss: 0.544297\n",
      "[336]\ttraining's binary_logloss: 0.544183\n",
      "[337]\ttraining's binary_logloss: 0.544046\n",
      "[338]\ttraining's binary_logloss: 0.543917\n",
      "[339]\ttraining's binary_logloss: 0.543784\n",
      "[340]\ttraining's binary_logloss: 0.543646\n",
      "[341]\ttraining's binary_logloss: 0.543555\n",
      "[342]\ttraining's binary_logloss: 0.543469\n",
      "[343]\ttraining's binary_logloss: 0.543396\n",
      "[344]\ttraining's binary_logloss: 0.543294\n",
      "[345]\ttraining's binary_logloss: 0.543196\n",
      "[346]\ttraining's binary_logloss: 0.543069\n",
      "[347]\ttraining's binary_logloss: 0.542948\n",
      "[348]\ttraining's binary_logloss: 0.542825\n",
      "[349]\ttraining's binary_logloss: 0.542699\n",
      "[350]\ttraining's binary_logloss: 0.542578\n",
      "[351]\ttraining's binary_logloss: 0.542422\n",
      "[352]\ttraining's binary_logloss: 0.542273\n",
      "[353]\ttraining's binary_logloss: 0.542133\n",
      "[354]\ttraining's binary_logloss: 0.541995\n",
      "[355]\ttraining's binary_logloss: 0.541837\n",
      "[356]\ttraining's binary_logloss: 0.541687\n",
      "[357]\ttraining's binary_logloss: 0.541507\n",
      "[358]\ttraining's binary_logloss: 0.541324\n",
      "[359]\ttraining's binary_logloss: 0.541161\n",
      "[360]\ttraining's binary_logloss: 0.540997\n",
      "[361]\ttraining's binary_logloss: 0.540853\n",
      "[362]\ttraining's binary_logloss: 0.540701\n",
      "[363]\ttraining's binary_logloss: 0.54054\n",
      "[364]\ttraining's binary_logloss: 0.540384\n",
      "[365]\ttraining's binary_logloss: 0.540236\n",
      "[366]\ttraining's binary_logloss: 0.540093\n",
      "[367]\ttraining's binary_logloss: 0.539956\n",
      "[368]\ttraining's binary_logloss: 0.539823\n",
      "[369]\ttraining's binary_logloss: 0.539687\n",
      "[370]\ttraining's binary_logloss: 0.539536\n",
      "[371]\ttraining's binary_logloss: 0.539434\n",
      "[372]\ttraining's binary_logloss: 0.539332\n",
      "[373]\ttraining's binary_logloss: 0.539233\n",
      "[374]\ttraining's binary_logloss: 0.539135\n",
      "[375]\ttraining's binary_logloss: 0.53904\n",
      "[376]\ttraining's binary_logloss: 0.538904\n",
      "[377]\ttraining's binary_logloss: 0.538757\n",
      "[378]\ttraining's binary_logloss: 0.538605\n",
      "[379]\ttraining's binary_logloss: 0.538484\n",
      "[380]\ttraining's binary_logloss: 0.538355\n",
      "[381]\ttraining's binary_logloss: 0.538236\n",
      "[382]\ttraining's binary_logloss: 0.538111\n",
      "[383]\ttraining's binary_logloss: 0.53799\n",
      "[384]\ttraining's binary_logloss: 0.537889\n",
      "[385]\ttraining's binary_logloss: 0.537756\n",
      "[386]\ttraining's binary_logloss: 0.537607\n",
      "[387]\ttraining's binary_logloss: 0.537456\n",
      "[388]\ttraining's binary_logloss: 0.537307\n",
      "[389]\ttraining's binary_logloss: 0.537158\n",
      "[390]\ttraining's binary_logloss: 0.537008\n",
      "[391]\ttraining's binary_logloss: 0.536851\n",
      "[392]\ttraining's binary_logloss: 0.536707\n",
      "[393]\ttraining's binary_logloss: 0.536569\n",
      "[394]\ttraining's binary_logloss: 0.536431\n",
      "[395]\ttraining's binary_logloss: 0.536283\n",
      "[396]\ttraining's binary_logloss: 0.536145\n",
      "[397]\ttraining's binary_logloss: 0.536029\n",
      "[398]\ttraining's binary_logloss: 0.535921\n",
      "[399]\ttraining's binary_logloss: 0.535811\n",
      "[400]\ttraining's binary_logloss: 0.535708\n",
      "[401]\ttraining's binary_logloss: 0.535567\n",
      "[402]\ttraining's binary_logloss: 0.535432\n",
      "[403]\ttraining's binary_logloss: 0.535292\n",
      "[404]\ttraining's binary_logloss: 0.53514\n",
      "[405]\ttraining's binary_logloss: 0.535008\n",
      "[406]\ttraining's binary_logloss: 0.534877\n",
      "[407]\ttraining's binary_logloss: 0.534745\n",
      "[408]\ttraining's binary_logloss: 0.534623\n",
      "[409]\ttraining's binary_logloss: 0.534486\n",
      "[410]\ttraining's binary_logloss: 0.534369\n",
      "[411]\ttraining's binary_logloss: 0.534162\n",
      "[412]\ttraining's binary_logloss: 0.533968\n",
      "[413]\ttraining's binary_logloss: 0.533785\n",
      "[414]\ttraining's binary_logloss: 0.533603\n",
      "[415]\ttraining's binary_logloss: 0.533422\n",
      "[416]\ttraining's binary_logloss: 0.53326\n",
      "[417]\ttraining's binary_logloss: 0.533099\n",
      "[418]\ttraining's binary_logloss: 0.532937\n",
      "[419]\ttraining's binary_logloss: 0.532793\n",
      "[420]\ttraining's binary_logloss: 0.53261\n",
      "[421]\ttraining's binary_logloss: 0.532479\n",
      "[422]\ttraining's binary_logloss: 0.532369\n",
      "[423]\ttraining's binary_logloss: 0.532238\n",
      "[424]\ttraining's binary_logloss: 0.532112\n",
      "[425]\ttraining's binary_logloss: 0.532012\n",
      "[426]\ttraining's binary_logloss: 0.53191\n",
      "[427]\ttraining's binary_logloss: 0.531765\n",
      "[428]\ttraining's binary_logloss: 0.531628\n",
      "[429]\ttraining's binary_logloss: 0.531491\n",
      "[430]\ttraining's binary_logloss: 0.53136\n",
      "[431]\ttraining's binary_logloss: 0.531199\n",
      "[432]\ttraining's binary_logloss: 0.531031\n",
      "[433]\ttraining's binary_logloss: 0.530863\n",
      "[434]\ttraining's binary_logloss: 0.53069\n",
      "[435]\ttraining's binary_logloss: 0.530522\n",
      "[436]\ttraining's binary_logloss: 0.530369\n",
      "[437]\ttraining's binary_logloss: 0.530211\n",
      "[438]\ttraining's binary_logloss: 0.530058\n",
      "[439]\ttraining's binary_logloss: 0.529886\n",
      "[440]\ttraining's binary_logloss: 0.529738\n",
      "[441]\ttraining's binary_logloss: 0.529599\n",
      "[442]\ttraining's binary_logloss: 0.529456\n",
      "[443]\ttraining's binary_logloss: 0.529342\n",
      "[444]\ttraining's binary_logloss: 0.529226\n",
      "[445]\ttraining's binary_logloss: 0.529115\n",
      "[446]\ttraining's binary_logloss: 0.528956\n",
      "[447]\ttraining's binary_logloss: 0.528795\n",
      "[448]\ttraining's binary_logloss: 0.52865\n",
      "[449]\ttraining's binary_logloss: 0.528486\n",
      "[450]\ttraining's binary_logloss: 0.528321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[451]\ttraining's binary_logloss: 0.528196\n",
      "[452]\ttraining's binary_logloss: 0.528015\n",
      "[453]\ttraining's binary_logloss: 0.52788\n",
      "[454]\ttraining's binary_logloss: 0.527766\n",
      "[455]\ttraining's binary_logloss: 0.527626\n",
      "[456]\ttraining's binary_logloss: 0.527508\n",
      "[457]\ttraining's binary_logloss: 0.527401\n",
      "[458]\ttraining's binary_logloss: 0.527286\n",
      "[459]\ttraining's binary_logloss: 0.527175\n",
      "[460]\ttraining's binary_logloss: 0.527064\n",
      "[461]\ttraining's binary_logloss: 0.526897\n",
      "[462]\ttraining's binary_logloss: 0.526754\n",
      "[463]\ttraining's binary_logloss: 0.526596\n",
      "[464]\ttraining's binary_logloss: 0.526421\n",
      "[465]\ttraining's binary_logloss: 0.526246\n",
      "[466]\ttraining's binary_logloss: 0.526138\n",
      "[467]\ttraining's binary_logloss: 0.526008\n",
      "[468]\ttraining's binary_logloss: 0.525881\n",
      "[469]\ttraining's binary_logloss: 0.525764\n",
      "[470]\ttraining's binary_logloss: 0.5256\n",
      "[471]\ttraining's binary_logloss: 0.525486\n",
      "[472]\ttraining's binary_logloss: 0.525357\n",
      "[473]\ttraining's binary_logloss: 0.525226\n",
      "[474]\ttraining's binary_logloss: 0.525112\n",
      "[475]\ttraining's binary_logloss: 0.524997\n",
      "[476]\ttraining's binary_logloss: 0.524888\n",
      "[477]\ttraining's binary_logloss: 0.524775\n",
      "[478]\ttraining's binary_logloss: 0.524612\n",
      "[479]\ttraining's binary_logloss: 0.524465\n",
      "[480]\ttraining's binary_logloss: 0.524353\n",
      "[481]\ttraining's binary_logloss: 0.524232\n",
      "[482]\ttraining's binary_logloss: 0.524105\n",
      "[483]\ttraining's binary_logloss: 0.523958\n",
      "[484]\ttraining's binary_logloss: 0.523814\n",
      "[485]\ttraining's binary_logloss: 0.523665\n",
      "[486]\ttraining's binary_logloss: 0.523483\n",
      "[487]\ttraining's binary_logloss: 0.523303\n",
      "[488]\ttraining's binary_logloss: 0.523129\n",
      "[489]\ttraining's binary_logloss: 0.522953\n",
      "[490]\ttraining's binary_logloss: 0.522783\n",
      "[491]\ttraining's binary_logloss: 0.522671\n",
      "[492]\ttraining's binary_logloss: 0.52255\n",
      "[493]\ttraining's binary_logloss: 0.522435\n",
      "[494]\ttraining's binary_logloss: 0.522307\n",
      "[495]\ttraining's binary_logloss: 0.522192\n",
      "[496]\ttraining's binary_logloss: 0.522015\n",
      "[497]\ttraining's binary_logloss: 0.521834\n",
      "[498]\ttraining's binary_logloss: 0.521663\n",
      "[499]\ttraining's binary_logloss: 0.521495\n",
      "[500]\ttraining's binary_logloss: 0.521338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613033\n",
      "[2]\ttraining's binary_logloss: 0.611721\n",
      "[3]\ttraining's binary_logloss: 0.610453\n",
      "[4]\ttraining's binary_logloss: 0.609242\n",
      "[5]\ttraining's binary_logloss: 0.607963\n",
      "[6]\ttraining's binary_logloss: 0.606892\n",
      "[7]\ttraining's binary_logloss: 0.605777\n",
      "[8]\ttraining's binary_logloss: 0.604801\n",
      "[9]\ttraining's binary_logloss: 0.603697\n",
      "[10]\ttraining's binary_logloss: 0.602679\n",
      "[11]\ttraining's binary_logloss: 0.601622\n",
      "[12]\ttraining's binary_logloss: 0.60059\n",
      "[13]\ttraining's binary_logloss: 0.599666\n",
      "[14]\ttraining's binary_logloss: 0.598687\n",
      "[15]\ttraining's binary_logloss: 0.597744\n",
      "[16]\ttraining's binary_logloss: 0.597011\n",
      "[17]\ttraining's binary_logloss: 0.596065\n",
      "[18]\ttraining's binary_logloss: 0.595184\n",
      "[19]\ttraining's binary_logloss: 0.594303\n",
      "[20]\ttraining's binary_logloss: 0.593575\n",
      "[21]\ttraining's binary_logloss: 0.592848\n",
      "[22]\ttraining's binary_logloss: 0.59208\n",
      "[23]\ttraining's binary_logloss: 0.59138\n",
      "[24]\ttraining's binary_logloss: 0.590722\n",
      "[25]\ttraining's binary_logloss: 0.590084\n",
      "[26]\ttraining's binary_logloss: 0.589416\n",
      "[27]\ttraining's binary_logloss: 0.588763\n",
      "[28]\ttraining's binary_logloss: 0.588151\n",
      "[29]\ttraining's binary_logloss: 0.587553\n",
      "[30]\ttraining's binary_logloss: 0.586978\n",
      "[31]\ttraining's binary_logloss: 0.586467\n",
      "[32]\ttraining's binary_logloss: 0.585914\n",
      "[33]\ttraining's binary_logloss: 0.585433\n",
      "[34]\ttraining's binary_logloss: 0.584904\n",
      "[35]\ttraining's binary_logloss: 0.584447\n",
      "[36]\ttraining's binary_logloss: 0.583965\n",
      "[37]\ttraining's binary_logloss: 0.583484\n",
      "[38]\ttraining's binary_logloss: 0.583009\n",
      "[39]\ttraining's binary_logloss: 0.582566\n",
      "[40]\ttraining's binary_logloss: 0.582203\n",
      "[41]\ttraining's binary_logloss: 0.581802\n",
      "[42]\ttraining's binary_logloss: 0.581398\n",
      "[43]\ttraining's binary_logloss: 0.581059\n",
      "[44]\ttraining's binary_logloss: 0.580678\n",
      "[45]\ttraining's binary_logloss: 0.580294\n",
      "[46]\ttraining's binary_logloss: 0.579926\n",
      "[47]\ttraining's binary_logloss: 0.579587\n",
      "[48]\ttraining's binary_logloss: 0.579217\n",
      "[49]\ttraining's binary_logloss: 0.5789\n",
      "[50]\ttraining's binary_logloss: 0.578586\n",
      "[51]\ttraining's binary_logloss: 0.578245\n",
      "[52]\ttraining's binary_logloss: 0.577891\n",
      "[53]\ttraining's binary_logloss: 0.577615\n",
      "[54]\ttraining's binary_logloss: 0.577372\n",
      "[55]\ttraining's binary_logloss: 0.577133\n",
      "[56]\ttraining's binary_logloss: 0.57686\n",
      "[57]\ttraining's binary_logloss: 0.576606\n",
      "[58]\ttraining's binary_logloss: 0.576332\n",
      "[59]\ttraining's binary_logloss: 0.576086\n",
      "[60]\ttraining's binary_logloss: 0.575857\n",
      "[61]\ttraining's binary_logloss: 0.575635\n",
      "[62]\ttraining's binary_logloss: 0.575452\n",
      "[63]\ttraining's binary_logloss: 0.575158\n",
      "[64]\ttraining's binary_logloss: 0.575003\n",
      "[65]\ttraining's binary_logloss: 0.574786\n",
      "[66]\ttraining's binary_logloss: 0.574534\n",
      "[67]\ttraining's binary_logloss: 0.574356\n",
      "[68]\ttraining's binary_logloss: 0.574155\n",
      "[69]\ttraining's binary_logloss: 0.573896\n",
      "[70]\ttraining's binary_logloss: 0.573706\n",
      "[71]\ttraining's binary_logloss: 0.573478\n",
      "[72]\ttraining's binary_logloss: 0.57328\n",
      "[73]\ttraining's binary_logloss: 0.573092\n",
      "[74]\ttraining's binary_logloss: 0.572905\n",
      "[75]\ttraining's binary_logloss: 0.572766\n",
      "[76]\ttraining's binary_logloss: 0.572529\n",
      "[77]\ttraining's binary_logloss: 0.572338\n",
      "[78]\ttraining's binary_logloss: 0.572169\n",
      "[79]\ttraining's binary_logloss: 0.572073\n",
      "[80]\ttraining's binary_logloss: 0.571941\n",
      "[81]\ttraining's binary_logloss: 0.571793\n",
      "[82]\ttraining's binary_logloss: 0.571625\n",
      "[83]\ttraining's binary_logloss: 0.571499\n",
      "[84]\ttraining's binary_logloss: 0.571346\n",
      "[85]\ttraining's binary_logloss: 0.571186\n",
      "[86]\ttraining's binary_logloss: 0.571048\n",
      "[87]\ttraining's binary_logloss: 0.570915\n",
      "[88]\ttraining's binary_logloss: 0.570758\n",
      "[89]\ttraining's binary_logloss: 0.570645\n",
      "[90]\ttraining's binary_logloss: 0.570528\n",
      "[91]\ttraining's binary_logloss: 0.570389\n",
      "[92]\ttraining's binary_logloss: 0.570261\n",
      "[93]\ttraining's binary_logloss: 0.570125\n",
      "[94]\ttraining's binary_logloss: 0.570003\n",
      "[95]\ttraining's binary_logloss: 0.569878\n",
      "[96]\ttraining's binary_logloss: 0.569778\n",
      "[97]\ttraining's binary_logloss: 0.569685\n",
      "[98]\ttraining's binary_logloss: 0.56965\n",
      "[99]\ttraining's binary_logloss: 0.569557\n",
      "[100]\ttraining's binary_logloss: 0.569474\n",
      "[101]\ttraining's binary_logloss: 0.569424\n",
      "[102]\ttraining's binary_logloss: 0.569348\n",
      "[103]\ttraining's binary_logloss: 0.569258\n",
      "[104]\ttraining's binary_logloss: 0.569185\n",
      "[105]\ttraining's binary_logloss: 0.569119\n",
      "[106]\ttraining's binary_logloss: 0.569039\n",
      "[107]\ttraining's binary_logloss: 0.568964\n",
      "[108]\ttraining's binary_logloss: 0.568901\n",
      "[109]\ttraining's binary_logloss: 0.568842\n",
      "[110]\ttraining's binary_logloss: 0.568734\n",
      "[111]\ttraining's binary_logloss: 0.568652\n",
      "[112]\ttraining's binary_logloss: 0.568548\n",
      "[113]\ttraining's binary_logloss: 0.568468\n",
      "[114]\ttraining's binary_logloss: 0.568418\n",
      "[115]\ttraining's binary_logloss: 0.568354\n",
      "[116]\ttraining's binary_logloss: 0.568272\n",
      "[117]\ttraining's binary_logloss: 0.568201\n",
      "[118]\ttraining's binary_logloss: 0.568113\n",
      "[119]\ttraining's binary_logloss: 0.568024\n",
      "[120]\ttraining's binary_logloss: 0.567973\n",
      "[121]\ttraining's binary_logloss: 0.567895\n",
      "[122]\ttraining's binary_logloss: 0.567796\n",
      "[123]\ttraining's binary_logloss: 0.567698\n",
      "[124]\ttraining's binary_logloss: 0.567616\n",
      "[125]\ttraining's binary_logloss: 0.56754\n",
      "[126]\ttraining's binary_logloss: 0.567477\n",
      "[127]\ttraining's binary_logloss: 0.567374\n",
      "[128]\ttraining's binary_logloss: 0.567277\n",
      "[129]\ttraining's binary_logloss: 0.567198\n",
      "[130]\ttraining's binary_logloss: 0.56713\n",
      "[131]\ttraining's binary_logloss: 0.567055\n",
      "[132]\ttraining's binary_logloss: 0.566987\n",
      "[133]\ttraining's binary_logloss: 0.566944\n",
      "[134]\ttraining's binary_logloss: 0.566886\n",
      "[135]\ttraining's binary_logloss: 0.566841\n",
      "[136]\ttraining's binary_logloss: 0.566762\n",
      "[137]\ttraining's binary_logloss: 0.566704\n",
      "[138]\ttraining's binary_logloss: 0.566657\n",
      "[139]\ttraining's binary_logloss: 0.566622\n",
      "[140]\ttraining's binary_logloss: 0.566565\n",
      "[141]\ttraining's binary_logloss: 0.56649\n",
      "[142]\ttraining's binary_logloss: 0.566424\n",
      "[143]\ttraining's binary_logloss: 0.566331\n",
      "[144]\ttraining's binary_logloss: 0.566254\n",
      "[145]\ttraining's binary_logloss: 0.566225\n",
      "[146]\ttraining's binary_logloss: 0.566145\n",
      "[147]\ttraining's binary_logloss: 0.566021\n",
      "[148]\ttraining's binary_logloss: 0.565911\n",
      "[149]\ttraining's binary_logloss: 0.565811\n",
      "[150]\ttraining's binary_logloss: 0.565695\n",
      "[151]\ttraining's binary_logloss: 0.565612\n",
      "[152]\ttraining's binary_logloss: 0.565517\n",
      "[153]\ttraining's binary_logloss: 0.565428\n",
      "[154]\ttraining's binary_logloss: 0.565346\n",
      "[155]\ttraining's binary_logloss: 0.565261\n",
      "[156]\ttraining's binary_logloss: 0.5652\n",
      "[157]\ttraining's binary_logloss: 0.565144\n",
      "[158]\ttraining's binary_logloss: 0.565094\n",
      "[159]\ttraining's binary_logloss: 0.565046\n",
      "[160]\ttraining's binary_logloss: 0.565016\n",
      "[161]\ttraining's binary_logloss: 0.56491\n",
      "[162]\ttraining's binary_logloss: 0.564793\n",
      "[163]\ttraining's binary_logloss: 0.564677\n",
      "[164]\ttraining's binary_logloss: 0.564558\n",
      "[165]\ttraining's binary_logloss: 0.564417\n",
      "[166]\ttraining's binary_logloss: 0.564306\n",
      "[167]\ttraining's binary_logloss: 0.564197\n",
      "[168]\ttraining's binary_logloss: 0.564111\n",
      "[169]\ttraining's binary_logloss: 0.564012\n",
      "[170]\ttraining's binary_logloss: 0.563923\n",
      "[171]\ttraining's binary_logloss: 0.563881\n",
      "[172]\ttraining's binary_logloss: 0.563834\n",
      "[173]\ttraining's binary_logloss: 0.563819\n",
      "[174]\ttraining's binary_logloss: 0.563798\n",
      "[175]\ttraining's binary_logloss: 0.563695\n",
      "[176]\ttraining's binary_logloss: 0.563623\n",
      "[177]\ttraining's binary_logloss: 0.563545\n",
      "[178]\ttraining's binary_logloss: 0.563467\n",
      "[179]\ttraining's binary_logloss: 0.563389\n",
      "[180]\ttraining's binary_logloss: 0.563316\n",
      "[181]\ttraining's binary_logloss: 0.563289\n",
      "[182]\ttraining's binary_logloss: 0.563237\n",
      "[183]\ttraining's binary_logloss: 0.563164\n",
      "[184]\ttraining's binary_logloss: 0.563086\n",
      "[185]\ttraining's binary_logloss: 0.563034\n",
      "[186]\ttraining's binary_logloss: 0.562961\n",
      "[187]\ttraining's binary_logloss: 0.562886\n",
      "[188]\ttraining's binary_logloss: 0.562804\n",
      "[189]\ttraining's binary_logloss: 0.562735\n",
      "[190]\ttraining's binary_logloss: 0.562664\n",
      "[191]\ttraining's binary_logloss: 0.562604\n",
      "[192]\ttraining's binary_logloss: 0.562529\n",
      "[193]\ttraining's binary_logloss: 0.562458\n",
      "[194]\ttraining's binary_logloss: 0.562403\n",
      "[195]\ttraining's binary_logloss: 0.562291\n",
      "[196]\ttraining's binary_logloss: 0.56221\n",
      "[197]\ttraining's binary_logloss: 0.562144\n",
      "[198]\ttraining's binary_logloss: 0.56208\n",
      "[199]\ttraining's binary_logloss: 0.562022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's binary_logloss: 0.561972\n",
      "[201]\ttraining's binary_logloss: 0.56187\n",
      "[202]\ttraining's binary_logloss: 0.561771\n",
      "[203]\ttraining's binary_logloss: 0.561678\n",
      "[204]\ttraining's binary_logloss: 0.561585\n",
      "[205]\ttraining's binary_logloss: 0.56153\n",
      "[206]\ttraining's binary_logloss: 0.561474\n",
      "[207]\ttraining's binary_logloss: 0.561417\n",
      "[208]\ttraining's binary_logloss: 0.56136\n",
      "[209]\ttraining's binary_logloss: 0.561287\n",
      "[210]\ttraining's binary_logloss: 0.561234\n",
      "[211]\ttraining's binary_logloss: 0.561167\n",
      "[212]\ttraining's binary_logloss: 0.561093\n",
      "[213]\ttraining's binary_logloss: 0.56103\n",
      "[214]\ttraining's binary_logloss: 0.560981\n",
      "[215]\ttraining's binary_logloss: 0.560923\n",
      "[216]\ttraining's binary_logloss: 0.560807\n",
      "[217]\ttraining's binary_logloss: 0.560692\n",
      "[218]\ttraining's binary_logloss: 0.560557\n",
      "[219]\ttraining's binary_logloss: 0.560448\n",
      "[220]\ttraining's binary_logloss: 0.56034\n",
      "[221]\ttraining's binary_logloss: 0.560218\n",
      "[222]\ttraining's binary_logloss: 0.560106\n",
      "[223]\ttraining's binary_logloss: 0.559995\n",
      "[224]\ttraining's binary_logloss: 0.559887\n",
      "[225]\ttraining's binary_logloss: 0.55978\n",
      "[226]\ttraining's binary_logloss: 0.559667\n",
      "[227]\ttraining's binary_logloss: 0.559565\n",
      "[228]\ttraining's binary_logloss: 0.559462\n",
      "[229]\ttraining's binary_logloss: 0.55938\n",
      "[230]\ttraining's binary_logloss: 0.559273\n",
      "[231]\ttraining's binary_logloss: 0.55919\n",
      "[232]\ttraining's binary_logloss: 0.55913\n",
      "[233]\ttraining's binary_logloss: 0.559047\n",
      "[234]\ttraining's binary_logloss: 0.558956\n",
      "[235]\ttraining's binary_logloss: 0.558873\n",
      "[236]\ttraining's binary_logloss: 0.558783\n",
      "[237]\ttraining's binary_logloss: 0.558696\n",
      "[238]\ttraining's binary_logloss: 0.558603\n",
      "[239]\ttraining's binary_logloss: 0.55852\n",
      "[240]\ttraining's binary_logloss: 0.558434\n",
      "[241]\ttraining's binary_logloss: 0.5583\n",
      "[242]\ttraining's binary_logloss: 0.558173\n",
      "[243]\ttraining's binary_logloss: 0.558037\n",
      "[244]\ttraining's binary_logloss: 0.557926\n",
      "[245]\ttraining's binary_logloss: 0.557783\n",
      "[246]\ttraining's binary_logloss: 0.557605\n",
      "[247]\ttraining's binary_logloss: 0.557437\n",
      "[248]\ttraining's binary_logloss: 0.557267\n",
      "[249]\ttraining's binary_logloss: 0.557169\n",
      "[250]\ttraining's binary_logloss: 0.557006\n",
      "[251]\ttraining's binary_logloss: 0.556936\n",
      "[252]\ttraining's binary_logloss: 0.556815\n",
      "[253]\ttraining's binary_logloss: 0.556729\n",
      "[254]\ttraining's binary_logloss: 0.556662\n",
      "[255]\ttraining's binary_logloss: 0.556578\n",
      "[256]\ttraining's binary_logloss: 0.556456\n",
      "[257]\ttraining's binary_logloss: 0.556359\n",
      "[258]\ttraining's binary_logloss: 0.556231\n",
      "[259]\ttraining's binary_logloss: 0.556111\n",
      "[260]\ttraining's binary_logloss: 0.556001\n",
      "[261]\ttraining's binary_logloss: 0.555904\n",
      "[262]\ttraining's binary_logloss: 0.555813\n",
      "[263]\ttraining's binary_logloss: 0.55574\n",
      "[264]\ttraining's binary_logloss: 0.555639\n",
      "[265]\ttraining's binary_logloss: 0.555541\n",
      "[266]\ttraining's binary_logloss: 0.55546\n",
      "[267]\ttraining's binary_logloss: 0.555363\n",
      "[268]\ttraining's binary_logloss: 0.555295\n",
      "[269]\ttraining's binary_logloss: 0.55522\n",
      "[270]\ttraining's binary_logloss: 0.555138\n",
      "[271]\ttraining's binary_logloss: 0.554996\n",
      "[272]\ttraining's binary_logloss: 0.554814\n",
      "[273]\ttraining's binary_logloss: 0.554648\n",
      "[274]\ttraining's binary_logloss: 0.554478\n",
      "[275]\ttraining's binary_logloss: 0.554319\n",
      "[276]\ttraining's binary_logloss: 0.554217\n",
      "[277]\ttraining's binary_logloss: 0.554085\n",
      "[278]\ttraining's binary_logloss: 0.553973\n",
      "[279]\ttraining's binary_logloss: 0.553865\n",
      "[280]\ttraining's binary_logloss: 0.553751\n",
      "[281]\ttraining's binary_logloss: 0.553642\n",
      "[282]\ttraining's binary_logloss: 0.553523\n",
      "[283]\ttraining's binary_logloss: 0.553416\n",
      "[284]\ttraining's binary_logloss: 0.553292\n",
      "[285]\ttraining's binary_logloss: 0.553146\n",
      "[286]\ttraining's binary_logloss: 0.553011\n",
      "[287]\ttraining's binary_logloss: 0.552861\n",
      "[288]\ttraining's binary_logloss: 0.552716\n",
      "[289]\ttraining's binary_logloss: 0.552587\n",
      "[290]\ttraining's binary_logloss: 0.552443\n",
      "[291]\ttraining's binary_logloss: 0.552272\n",
      "[292]\ttraining's binary_logloss: 0.552112\n",
      "[293]\ttraining's binary_logloss: 0.551945\n",
      "[294]\ttraining's binary_logloss: 0.551789\n",
      "[295]\ttraining's binary_logloss: 0.551633\n",
      "[296]\ttraining's binary_logloss: 0.551515\n",
      "[297]\ttraining's binary_logloss: 0.551382\n",
      "[298]\ttraining's binary_logloss: 0.551244\n",
      "[299]\ttraining's binary_logloss: 0.551103\n",
      "[300]\ttraining's binary_logloss: 0.550976\n",
      "[301]\ttraining's binary_logloss: 0.550838\n",
      "[302]\ttraining's binary_logloss: 0.550719\n",
      "[303]\ttraining's binary_logloss: 0.550604\n",
      "[304]\ttraining's binary_logloss: 0.550494\n",
      "[305]\ttraining's binary_logloss: 0.550363\n",
      "[306]\ttraining's binary_logloss: 0.550248\n",
      "[307]\ttraining's binary_logloss: 0.550143\n",
      "[308]\ttraining's binary_logloss: 0.550041\n",
      "[309]\ttraining's binary_logloss: 0.549946\n",
      "[310]\ttraining's binary_logloss: 0.549849\n",
      "[311]\ttraining's binary_logloss: 0.549689\n",
      "[312]\ttraining's binary_logloss: 0.549517\n",
      "[313]\ttraining's binary_logloss: 0.549391\n",
      "[314]\ttraining's binary_logloss: 0.549264\n",
      "[315]\ttraining's binary_logloss: 0.549145\n",
      "[316]\ttraining's binary_logloss: 0.549\n",
      "[317]\ttraining's binary_logloss: 0.548845\n",
      "[318]\ttraining's binary_logloss: 0.548719\n",
      "[319]\ttraining's binary_logloss: 0.548593\n",
      "[320]\ttraining's binary_logloss: 0.548449\n",
      "[321]\ttraining's binary_logloss: 0.548309\n",
      "[322]\ttraining's binary_logloss: 0.548191\n",
      "[323]\ttraining's binary_logloss: 0.548073\n",
      "[324]\ttraining's binary_logloss: 0.547968\n",
      "[325]\ttraining's binary_logloss: 0.547873\n",
      "[326]\ttraining's binary_logloss: 0.547727\n",
      "[327]\ttraining's binary_logloss: 0.547574\n",
      "[328]\ttraining's binary_logloss: 0.547448\n",
      "[329]\ttraining's binary_logloss: 0.547312\n",
      "[330]\ttraining's binary_logloss: 0.547181\n",
      "[331]\ttraining's binary_logloss: 0.547059\n",
      "[332]\ttraining's binary_logloss: 0.546939\n",
      "[333]\ttraining's binary_logloss: 0.546822\n",
      "[334]\ttraining's binary_logloss: 0.546703\n",
      "[335]\ttraining's binary_logloss: 0.546589\n",
      "[336]\ttraining's binary_logloss: 0.54644\n",
      "[337]\ttraining's binary_logloss: 0.546279\n",
      "[338]\ttraining's binary_logloss: 0.54611\n",
      "[339]\ttraining's binary_logloss: 0.545965\n",
      "[340]\ttraining's binary_logloss: 0.545811\n",
      "[341]\ttraining's binary_logloss: 0.545722\n",
      "[342]\ttraining's binary_logloss: 0.545631\n",
      "[343]\ttraining's binary_logloss: 0.545542\n",
      "[344]\ttraining's binary_logloss: 0.545444\n",
      "[345]\ttraining's binary_logloss: 0.545352\n",
      "[346]\ttraining's binary_logloss: 0.545255\n",
      "[347]\ttraining's binary_logloss: 0.545163\n",
      "[348]\ttraining's binary_logloss: 0.545065\n",
      "[349]\ttraining's binary_logloss: 0.544952\n",
      "[350]\ttraining's binary_logloss: 0.544854\n",
      "[351]\ttraining's binary_logloss: 0.544675\n",
      "[352]\ttraining's binary_logloss: 0.544493\n",
      "[353]\ttraining's binary_logloss: 0.544333\n",
      "[354]\ttraining's binary_logloss: 0.544172\n",
      "[355]\ttraining's binary_logloss: 0.544006\n",
      "[356]\ttraining's binary_logloss: 0.543849\n",
      "[357]\ttraining's binary_logloss: 0.54372\n",
      "[358]\ttraining's binary_logloss: 0.543584\n",
      "[359]\ttraining's binary_logloss: 0.543424\n",
      "[360]\ttraining's binary_logloss: 0.543276\n",
      "[361]\ttraining's binary_logloss: 0.543081\n",
      "[362]\ttraining's binary_logloss: 0.542913\n",
      "[363]\ttraining's binary_logloss: 0.542741\n",
      "[364]\ttraining's binary_logloss: 0.542571\n",
      "[365]\ttraining's binary_logloss: 0.542401\n",
      "[366]\ttraining's binary_logloss: 0.542278\n",
      "[367]\ttraining's binary_logloss: 0.542136\n",
      "[368]\ttraining's binary_logloss: 0.541994\n",
      "[369]\ttraining's binary_logloss: 0.541862\n",
      "[370]\ttraining's binary_logloss: 0.541727\n",
      "[371]\ttraining's binary_logloss: 0.541612\n",
      "[372]\ttraining's binary_logloss: 0.541495\n",
      "[373]\ttraining's binary_logloss: 0.541378\n",
      "[374]\ttraining's binary_logloss: 0.54124\n",
      "[375]\ttraining's binary_logloss: 0.541128\n",
      "[376]\ttraining's binary_logloss: 0.54099\n",
      "[377]\ttraining's binary_logloss: 0.54086\n",
      "[378]\ttraining's binary_logloss: 0.540715\n",
      "[379]\ttraining's binary_logloss: 0.540587\n",
      "[380]\ttraining's binary_logloss: 0.540469\n",
      "[381]\ttraining's binary_logloss: 0.540379\n",
      "[382]\ttraining's binary_logloss: 0.540274\n",
      "[383]\ttraining's binary_logloss: 0.540182\n",
      "[384]\ttraining's binary_logloss: 0.540076\n",
      "[385]\ttraining's binary_logloss: 0.539966\n",
      "[386]\ttraining's binary_logloss: 0.539849\n",
      "[387]\ttraining's binary_logloss: 0.539701\n",
      "[388]\ttraining's binary_logloss: 0.539527\n",
      "[389]\ttraining's binary_logloss: 0.539366\n",
      "[390]\ttraining's binary_logloss: 0.539205\n",
      "[391]\ttraining's binary_logloss: 0.539048\n",
      "[392]\ttraining's binary_logloss: 0.538891\n",
      "[393]\ttraining's binary_logloss: 0.53873\n",
      "[394]\ttraining's binary_logloss: 0.53857\n",
      "[395]\ttraining's binary_logloss: 0.538419\n",
      "[396]\ttraining's binary_logloss: 0.538308\n",
      "[397]\ttraining's binary_logloss: 0.538199\n",
      "[398]\ttraining's binary_logloss: 0.5381\n",
      "[399]\ttraining's binary_logloss: 0.538001\n",
      "[400]\ttraining's binary_logloss: 0.537893\n",
      "[401]\ttraining's binary_logloss: 0.537724\n",
      "[402]\ttraining's binary_logloss: 0.537553\n",
      "[403]\ttraining's binary_logloss: 0.537383\n",
      "[404]\ttraining's binary_logloss: 0.537221\n",
      "[405]\ttraining's binary_logloss: 0.537087\n",
      "[406]\ttraining's binary_logloss: 0.536939\n",
      "[407]\ttraining's binary_logloss: 0.53679\n",
      "[408]\ttraining's binary_logloss: 0.53665\n",
      "[409]\ttraining's binary_logloss: 0.536515\n",
      "[410]\ttraining's binary_logloss: 0.53638\n",
      "[411]\ttraining's binary_logloss: 0.536237\n",
      "[412]\ttraining's binary_logloss: 0.536092\n",
      "[413]\ttraining's binary_logloss: 0.535942\n",
      "[414]\ttraining's binary_logloss: 0.535811\n",
      "[415]\ttraining's binary_logloss: 0.535668\n",
      "[416]\ttraining's binary_logloss: 0.535519\n",
      "[417]\ttraining's binary_logloss: 0.535408\n",
      "[418]\ttraining's binary_logloss: 0.53527\n",
      "[419]\ttraining's binary_logloss: 0.535126\n",
      "[420]\ttraining's binary_logloss: 0.535019\n",
      "[421]\ttraining's binary_logloss: 0.534906\n",
      "[422]\ttraining's binary_logloss: 0.534783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[423]\ttraining's binary_logloss: 0.534679\n",
      "[424]\ttraining's binary_logloss: 0.534571\n",
      "[425]\ttraining's binary_logloss: 0.534487\n",
      "[426]\ttraining's binary_logloss: 0.53434\n",
      "[427]\ttraining's binary_logloss: 0.534198\n",
      "[428]\ttraining's binary_logloss: 0.534064\n",
      "[429]\ttraining's binary_logloss: 0.533938\n",
      "[430]\ttraining's binary_logloss: 0.533805\n",
      "[431]\ttraining's binary_logloss: 0.533632\n",
      "[432]\ttraining's binary_logloss: 0.533452\n",
      "[433]\ttraining's binary_logloss: 0.533271\n",
      "[434]\ttraining's binary_logloss: 0.533108\n",
      "[435]\ttraining's binary_logloss: 0.532948\n",
      "[436]\ttraining's binary_logloss: 0.532821\n",
      "[437]\ttraining's binary_logloss: 0.532697\n",
      "[438]\ttraining's binary_logloss: 0.532565\n",
      "[439]\ttraining's binary_logloss: 0.532453\n",
      "[440]\ttraining's binary_logloss: 0.532355\n",
      "[441]\ttraining's binary_logloss: 0.532192\n",
      "[442]\ttraining's binary_logloss: 0.532042\n",
      "[443]\ttraining's binary_logloss: 0.531904\n",
      "[444]\ttraining's binary_logloss: 0.531765\n",
      "[445]\ttraining's binary_logloss: 0.53164\n",
      "[446]\ttraining's binary_logloss: 0.531485\n",
      "[447]\ttraining's binary_logloss: 0.531334\n",
      "[448]\ttraining's binary_logloss: 0.531187\n",
      "[449]\ttraining's binary_logloss: 0.53105\n",
      "[450]\ttraining's binary_logloss: 0.530909\n",
      "[451]\ttraining's binary_logloss: 0.530789\n",
      "[452]\ttraining's binary_logloss: 0.530641\n",
      "[453]\ttraining's binary_logloss: 0.530512\n",
      "[454]\ttraining's binary_logloss: 0.53038\n",
      "[455]\ttraining's binary_logloss: 0.530244\n",
      "[456]\ttraining's binary_logloss: 0.530114\n",
      "[457]\ttraining's binary_logloss: 0.529985\n",
      "[458]\ttraining's binary_logloss: 0.529859\n",
      "[459]\ttraining's binary_logloss: 0.529723\n",
      "[460]\ttraining's binary_logloss: 0.529572\n",
      "[461]\ttraining's binary_logloss: 0.529452\n",
      "[462]\ttraining's binary_logloss: 0.529317\n",
      "[463]\ttraining's binary_logloss: 0.529176\n",
      "[464]\ttraining's binary_logloss: 0.529046\n",
      "[465]\ttraining's binary_logloss: 0.528915\n",
      "[466]\ttraining's binary_logloss: 0.528793\n",
      "[467]\ttraining's binary_logloss: 0.528624\n",
      "[468]\ttraining's binary_logloss: 0.528504\n",
      "[469]\ttraining's binary_logloss: 0.528383\n",
      "[470]\ttraining's binary_logloss: 0.52823\n",
      "[471]\ttraining's binary_logloss: 0.528125\n",
      "[472]\ttraining's binary_logloss: 0.528019\n",
      "[473]\ttraining's binary_logloss: 0.527926\n",
      "[474]\ttraining's binary_logloss: 0.527829\n",
      "[475]\ttraining's binary_logloss: 0.527723\n",
      "[476]\ttraining's binary_logloss: 0.527562\n",
      "[477]\ttraining's binary_logloss: 0.527412\n",
      "[478]\ttraining's binary_logloss: 0.527259\n",
      "[479]\ttraining's binary_logloss: 0.527114\n",
      "[480]\ttraining's binary_logloss: 0.527002\n",
      "[481]\ttraining's binary_logloss: 0.526874\n",
      "[482]\ttraining's binary_logloss: 0.52674\n",
      "[483]\ttraining's binary_logloss: 0.526607\n",
      "[484]\ttraining's binary_logloss: 0.526477\n",
      "[485]\ttraining's binary_logloss: 0.526353\n",
      "[486]\ttraining's binary_logloss: 0.526198\n",
      "[487]\ttraining's binary_logloss: 0.52603\n",
      "[488]\ttraining's binary_logloss: 0.525858\n",
      "[489]\ttraining's binary_logloss: 0.525697\n",
      "[490]\ttraining's binary_logloss: 0.525522\n",
      "[491]\ttraining's binary_logloss: 0.525387\n",
      "[492]\ttraining's binary_logloss: 0.525255\n",
      "[493]\ttraining's binary_logloss: 0.525099\n",
      "[494]\ttraining's binary_logloss: 0.524954\n",
      "[495]\ttraining's binary_logloss: 0.524816\n",
      "[496]\ttraining's binary_logloss: 0.524681\n",
      "[497]\ttraining's binary_logloss: 0.524515\n",
      "[498]\ttraining's binary_logloss: 0.524377\n",
      "[499]\ttraining's binary_logloss: 0.524247\n",
      "[500]\ttraining's binary_logloss: 0.524109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.617428\n",
      "[2]\ttraining's binary_logloss: 0.616164\n",
      "[3]\ttraining's binary_logloss: 0.614987\n",
      "[4]\ttraining's binary_logloss: 0.613746\n",
      "[5]\ttraining's binary_logloss: 0.612571\n",
      "[6]\ttraining's binary_logloss: 0.611385\n",
      "[7]\ttraining's binary_logloss: 0.61024\n",
      "[8]\ttraining's binary_logloss: 0.609141\n",
      "[9]\ttraining's binary_logloss: 0.608076\n",
      "[10]\ttraining's binary_logloss: 0.607046\n",
      "[11]\ttraining's binary_logloss: 0.605994\n",
      "[12]\ttraining's binary_logloss: 0.605008\n",
      "[13]\ttraining's binary_logloss: 0.604053\n",
      "[14]\ttraining's binary_logloss: 0.603072\n",
      "[15]\ttraining's binary_logloss: 0.602127\n",
      "[16]\ttraining's binary_logloss: 0.601322\n",
      "[17]\ttraining's binary_logloss: 0.600533\n",
      "[18]\ttraining's binary_logloss: 0.5998\n",
      "[19]\ttraining's binary_logloss: 0.598956\n",
      "[20]\ttraining's binary_logloss: 0.598205\n",
      "[21]\ttraining's binary_logloss: 0.597434\n",
      "[22]\ttraining's binary_logloss: 0.596731\n",
      "[23]\ttraining's binary_logloss: 0.595956\n",
      "[24]\ttraining's binary_logloss: 0.595195\n",
      "[25]\ttraining's binary_logloss: 0.594453\n",
      "[26]\ttraining's binary_logloss: 0.593802\n",
      "[27]\ttraining's binary_logloss: 0.593204\n",
      "[28]\ttraining's binary_logloss: 0.592633\n",
      "[29]\ttraining's binary_logloss: 0.592096\n",
      "[30]\ttraining's binary_logloss: 0.59153\n",
      "[31]\ttraining's binary_logloss: 0.590962\n",
      "[32]\ttraining's binary_logloss: 0.590391\n",
      "[33]\ttraining's binary_logloss: 0.589896\n",
      "[34]\ttraining's binary_logloss: 0.589375\n",
      "[35]\ttraining's binary_logloss: 0.588849\n",
      "[36]\ttraining's binary_logloss: 0.588371\n",
      "[37]\ttraining's binary_logloss: 0.587914\n",
      "[38]\ttraining's binary_logloss: 0.587477\n",
      "[39]\ttraining's binary_logloss: 0.587051\n",
      "[40]\ttraining's binary_logloss: 0.586636\n",
      "[41]\ttraining's binary_logloss: 0.586236\n",
      "[42]\ttraining's binary_logloss: 0.585858\n",
      "[43]\ttraining's binary_logloss: 0.585424\n",
      "[44]\ttraining's binary_logloss: 0.585049\n",
      "[45]\ttraining's binary_logloss: 0.584751\n",
      "[46]\ttraining's binary_logloss: 0.584365\n",
      "[47]\ttraining's binary_logloss: 0.583996\n",
      "[48]\ttraining's binary_logloss: 0.583628\n",
      "[49]\ttraining's binary_logloss: 0.583308\n",
      "[50]\ttraining's binary_logloss: 0.582989\n",
      "[51]\ttraining's binary_logloss: 0.582701\n",
      "[52]\ttraining's binary_logloss: 0.582414\n",
      "[53]\ttraining's binary_logloss: 0.582068\n",
      "[54]\ttraining's binary_logloss: 0.581807\n",
      "[55]\ttraining's binary_logloss: 0.581508\n",
      "[56]\ttraining's binary_logloss: 0.581303\n",
      "[57]\ttraining's binary_logloss: 0.581059\n",
      "[58]\ttraining's binary_logloss: 0.580814\n",
      "[59]\ttraining's binary_logloss: 0.580586\n",
      "[60]\ttraining's binary_logloss: 0.58038\n",
      "[61]\ttraining's binary_logloss: 0.580147\n",
      "[62]\ttraining's binary_logloss: 0.579938\n",
      "[63]\ttraining's binary_logloss: 0.579734\n",
      "[64]\ttraining's binary_logloss: 0.579521\n",
      "[65]\ttraining's binary_logloss: 0.579269\n",
      "[66]\ttraining's binary_logloss: 0.579008\n",
      "[67]\ttraining's binary_logloss: 0.578808\n",
      "[68]\ttraining's binary_logloss: 0.578584\n",
      "[69]\ttraining's binary_logloss: 0.578363\n",
      "[70]\ttraining's binary_logloss: 0.578141\n",
      "[71]\ttraining's binary_logloss: 0.577982\n",
      "[72]\ttraining's binary_logloss: 0.577761\n",
      "[73]\ttraining's binary_logloss: 0.577561\n",
      "[74]\ttraining's binary_logloss: 0.57736\n",
      "[75]\ttraining's binary_logloss: 0.577169\n",
      "[76]\ttraining's binary_logloss: 0.576959\n",
      "[77]\ttraining's binary_logloss: 0.576761\n",
      "[78]\ttraining's binary_logloss: 0.576642\n",
      "[79]\ttraining's binary_logloss: 0.576473\n",
      "[80]\ttraining's binary_logloss: 0.576319\n",
      "[81]\ttraining's binary_logloss: 0.576197\n",
      "[82]\ttraining's binary_logloss: 0.576034\n",
      "[83]\ttraining's binary_logloss: 0.575906\n",
      "[84]\ttraining's binary_logloss: 0.57574\n",
      "[85]\ttraining's binary_logloss: 0.575595\n",
      "[86]\ttraining's binary_logloss: 0.575498\n",
      "[87]\ttraining's binary_logloss: 0.575382\n",
      "[88]\ttraining's binary_logloss: 0.57531\n",
      "[89]\ttraining's binary_logloss: 0.5752\n",
      "[90]\ttraining's binary_logloss: 0.575109\n",
      "[91]\ttraining's binary_logloss: 0.574928\n",
      "[92]\ttraining's binary_logloss: 0.57475\n",
      "[93]\ttraining's binary_logloss: 0.574581\n",
      "[94]\ttraining's binary_logloss: 0.57446\n",
      "[95]\ttraining's binary_logloss: 0.574317\n",
      "[96]\ttraining's binary_logloss: 0.574223\n",
      "[97]\ttraining's binary_logloss: 0.574154\n",
      "[98]\ttraining's binary_logloss: 0.574057\n",
      "[99]\ttraining's binary_logloss: 0.573932\n",
      "[100]\ttraining's binary_logloss: 0.573864\n",
      "[101]\ttraining's binary_logloss: 0.573787\n",
      "[102]\ttraining's binary_logloss: 0.573703\n",
      "[103]\ttraining's binary_logloss: 0.573607\n",
      "[104]\ttraining's binary_logloss: 0.573538\n",
      "[105]\ttraining's binary_logloss: 0.573458\n",
      "[106]\ttraining's binary_logloss: 0.57333\n",
      "[107]\ttraining's binary_logloss: 0.573236\n",
      "[108]\ttraining's binary_logloss: 0.573111\n",
      "[109]\ttraining's binary_logloss: 0.573027\n",
      "[110]\ttraining's binary_logloss: 0.572922\n",
      "[111]\ttraining's binary_logloss: 0.572842\n",
      "[112]\ttraining's binary_logloss: 0.572776\n",
      "[113]\ttraining's binary_logloss: 0.572698\n",
      "[114]\ttraining's binary_logloss: 0.572648\n",
      "[115]\ttraining's binary_logloss: 0.572587\n",
      "[116]\ttraining's binary_logloss: 0.572453\n",
      "[117]\ttraining's binary_logloss: 0.572339\n",
      "[118]\ttraining's binary_logloss: 0.572226\n",
      "[119]\ttraining's binary_logloss: 0.572122\n",
      "[120]\ttraining's binary_logloss: 0.571986\n",
      "[121]\ttraining's binary_logloss: 0.571909\n",
      "[122]\ttraining's binary_logloss: 0.571845\n",
      "[123]\ttraining's binary_logloss: 0.571766\n",
      "[124]\ttraining's binary_logloss: 0.571704\n",
      "[125]\ttraining's binary_logloss: 0.571619\n",
      "[126]\ttraining's binary_logloss: 0.571556\n",
      "[127]\ttraining's binary_logloss: 0.571504\n",
      "[128]\ttraining's binary_logloss: 0.571434\n",
      "[129]\ttraining's binary_logloss: 0.571359\n",
      "[130]\ttraining's binary_logloss: 0.571287\n",
      "[131]\ttraining's binary_logloss: 0.571169\n",
      "[132]\ttraining's binary_logloss: 0.571051\n",
      "[133]\ttraining's binary_logloss: 0.570943\n",
      "[134]\ttraining's binary_logloss: 0.570844\n",
      "[135]\ttraining's binary_logloss: 0.570743\n",
      "[136]\ttraining's binary_logloss: 0.570674\n",
      "[137]\ttraining's binary_logloss: 0.57061\n",
      "[138]\ttraining's binary_logloss: 0.570548\n",
      "[139]\ttraining's binary_logloss: 0.570482\n",
      "[140]\ttraining's binary_logloss: 0.5704\n",
      "[141]\ttraining's binary_logloss: 0.570299\n",
      "[142]\ttraining's binary_logloss: 0.570196\n",
      "[143]\ttraining's binary_logloss: 0.570094\n",
      "[144]\ttraining's binary_logloss: 0.569981\n",
      "[145]\ttraining's binary_logloss: 0.56987\n",
      "[146]\ttraining's binary_logloss: 0.569746\n",
      "[147]\ttraining's binary_logloss: 0.569678\n",
      "[148]\ttraining's binary_logloss: 0.569561\n",
      "[149]\ttraining's binary_logloss: 0.569442\n",
      "[150]\ttraining's binary_logloss: 0.569334\n",
      "[151]\ttraining's binary_logloss: 0.569279\n",
      "[152]\ttraining's binary_logloss: 0.569245\n",
      "[153]\ttraining's binary_logloss: 0.5692\n",
      "[154]\ttraining's binary_logloss: 0.569152\n",
      "[155]\ttraining's binary_logloss: 0.569072\n",
      "[156]\ttraining's binary_logloss: 0.568992\n",
      "[157]\ttraining's binary_logloss: 0.568914\n",
      "[158]\ttraining's binary_logloss: 0.568841\n",
      "[159]\ttraining's binary_logloss: 0.568774\n",
      "[160]\ttraining's binary_logloss: 0.56866\n",
      "[161]\ttraining's binary_logloss: 0.568562\n",
      "[162]\ttraining's binary_logloss: 0.568472\n",
      "[163]\ttraining's binary_logloss: 0.568374\n",
      "[164]\ttraining's binary_logloss: 0.568316\n",
      "[165]\ttraining's binary_logloss: 0.568209\n",
      "[166]\ttraining's binary_logloss: 0.568081\n",
      "[167]\ttraining's binary_logloss: 0.567964\n",
      "[168]\ttraining's binary_logloss: 0.567863\n",
      "[169]\ttraining's binary_logloss: 0.567756\n",
      "[170]\ttraining's binary_logloss: 0.567643\n",
      "[171]\ttraining's binary_logloss: 0.56758\n",
      "[172]\ttraining's binary_logloss: 0.567518\n",
      "[173]\ttraining's binary_logloss: 0.567468\n",
      "[174]\ttraining's binary_logloss: 0.567416\n",
      "[175]\ttraining's binary_logloss: 0.567371\n",
      "[176]\ttraining's binary_logloss: 0.567272\n",
      "[177]\ttraining's binary_logloss: 0.567188\n",
      "[178]\ttraining's binary_logloss: 0.56709\n",
      "[179]\ttraining's binary_logloss: 0.567001\n",
      "[180]\ttraining's binary_logloss: 0.566911\n",
      "[181]\ttraining's binary_logloss: 0.566847\n",
      "[182]\ttraining's binary_logloss: 0.566765\n",
      "[183]\ttraining's binary_logloss: 0.566666\n",
      "[184]\ttraining's binary_logloss: 0.566581\n",
      "[185]\ttraining's binary_logloss: 0.566497\n",
      "[186]\ttraining's binary_logloss: 0.56645\n",
      "[187]\ttraining's binary_logloss: 0.56636\n",
      "[188]\ttraining's binary_logloss: 0.566295\n",
      "[189]\ttraining's binary_logloss: 0.566232\n",
      "[190]\ttraining's binary_logloss: 0.56618\n",
      "[191]\ttraining's binary_logloss: 0.56607\n",
      "[192]\ttraining's binary_logloss: 0.565995\n",
      "[193]\ttraining's binary_logloss: 0.565886\n",
      "[194]\ttraining's binary_logloss: 0.565792\n",
      "[195]\ttraining's binary_logloss: 0.565673\n",
      "[196]\ttraining's binary_logloss: 0.565544\n",
      "[197]\ttraining's binary_logloss: 0.565434\n",
      "[198]\ttraining's binary_logloss: 0.565331\n",
      "[199]\ttraining's binary_logloss: 0.565241\n",
      "[200]\ttraining's binary_logloss: 0.565142\n",
      "[201]\ttraining's binary_logloss: 0.565029\n",
      "[202]\ttraining's binary_logloss: 0.564903\n",
      "[203]\ttraining's binary_logloss: 0.564787\n",
      "[204]\ttraining's binary_logloss: 0.56468\n",
      "[205]\ttraining's binary_logloss: 0.564584\n",
      "[206]\ttraining's binary_logloss: 0.564506\n",
      "[207]\ttraining's binary_logloss: 0.564439\n",
      "[208]\ttraining's binary_logloss: 0.564377\n",
      "[209]\ttraining's binary_logloss: 0.564319\n",
      "[210]\ttraining's binary_logloss: 0.564273\n",
      "[211]\ttraining's binary_logloss: 0.564184\n",
      "[212]\ttraining's binary_logloss: 0.564094\n",
      "[213]\ttraining's binary_logloss: 0.564002\n",
      "[214]\ttraining's binary_logloss: 0.563898\n",
      "[215]\ttraining's binary_logloss: 0.563811\n",
      "[216]\ttraining's binary_logloss: 0.563702\n",
      "[217]\ttraining's binary_logloss: 0.563609\n",
      "[218]\ttraining's binary_logloss: 0.56348\n",
      "[219]\ttraining's binary_logloss: 0.56336\n",
      "[220]\ttraining's binary_logloss: 0.563243\n",
      "[221]\ttraining's binary_logloss: 0.563164\n",
      "[222]\ttraining's binary_logloss: 0.563069\n",
      "[223]\ttraining's binary_logloss: 0.562975\n",
      "[224]\ttraining's binary_logloss: 0.562841\n",
      "[225]\ttraining's binary_logloss: 0.562738\n",
      "[226]\ttraining's binary_logloss: 0.562647\n",
      "[227]\ttraining's binary_logloss: 0.562559\n",
      "[228]\ttraining's binary_logloss: 0.562431\n",
      "[229]\ttraining's binary_logloss: 0.562327\n",
      "[230]\ttraining's binary_logloss: 0.562238\n",
      "[231]\ttraining's binary_logloss: 0.562141\n",
      "[232]\ttraining's binary_logloss: 0.562054\n",
      "[233]\ttraining's binary_logloss: 0.561967\n",
      "[234]\ttraining's binary_logloss: 0.561858\n",
      "[235]\ttraining's binary_logloss: 0.561769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[236]\ttraining's binary_logloss: 0.561642\n",
      "[237]\ttraining's binary_logloss: 0.561511\n",
      "[238]\ttraining's binary_logloss: 0.561399\n",
      "[239]\ttraining's binary_logloss: 0.561295\n",
      "[240]\ttraining's binary_logloss: 0.561185\n",
      "[241]\ttraining's binary_logloss: 0.561048\n",
      "[242]\ttraining's binary_logloss: 0.560916\n",
      "[243]\ttraining's binary_logloss: 0.560753\n",
      "[244]\ttraining's binary_logloss: 0.560635\n",
      "[245]\ttraining's binary_logloss: 0.560501\n",
      "[246]\ttraining's binary_logloss: 0.560371\n",
      "[247]\ttraining's binary_logloss: 0.560235\n",
      "[248]\ttraining's binary_logloss: 0.560073\n",
      "[249]\ttraining's binary_logloss: 0.559954\n",
      "[250]\ttraining's binary_logloss: 0.559793\n",
      "[251]\ttraining's binary_logloss: 0.559683\n",
      "[252]\ttraining's binary_logloss: 0.559578\n",
      "[253]\ttraining's binary_logloss: 0.559477\n",
      "[254]\ttraining's binary_logloss: 0.559383\n",
      "[255]\ttraining's binary_logloss: 0.559275\n",
      "[256]\ttraining's binary_logloss: 0.55916\n",
      "[257]\ttraining's binary_logloss: 0.559058\n",
      "[258]\ttraining's binary_logloss: 0.558972\n",
      "[259]\ttraining's binary_logloss: 0.558871\n",
      "[260]\ttraining's binary_logloss: 0.558774\n",
      "[261]\ttraining's binary_logloss: 0.558663\n",
      "[262]\ttraining's binary_logloss: 0.558533\n",
      "[263]\ttraining's binary_logloss: 0.558397\n",
      "[264]\ttraining's binary_logloss: 0.558254\n",
      "[265]\ttraining's binary_logloss: 0.558136\n",
      "[266]\ttraining's binary_logloss: 0.55804\n",
      "[267]\ttraining's binary_logloss: 0.557922\n",
      "[268]\ttraining's binary_logloss: 0.557842\n",
      "[269]\ttraining's binary_logloss: 0.557748\n",
      "[270]\ttraining's binary_logloss: 0.557633\n",
      "[271]\ttraining's binary_logloss: 0.557519\n",
      "[272]\ttraining's binary_logloss: 0.5574\n",
      "[273]\ttraining's binary_logloss: 0.557254\n",
      "[274]\ttraining's binary_logloss: 0.557114\n",
      "[275]\ttraining's binary_logloss: 0.556976\n",
      "[276]\ttraining's binary_logloss: 0.556866\n",
      "[277]\ttraining's binary_logloss: 0.556738\n",
      "[278]\ttraining's binary_logloss: 0.556606\n",
      "[279]\ttraining's binary_logloss: 0.556475\n",
      "[280]\ttraining's binary_logloss: 0.556347\n",
      "[281]\ttraining's binary_logloss: 0.556203\n",
      "[282]\ttraining's binary_logloss: 0.556109\n",
      "[283]\ttraining's binary_logloss: 0.555967\n",
      "[284]\ttraining's binary_logloss: 0.555834\n",
      "[285]\ttraining's binary_logloss: 0.555703\n",
      "[286]\ttraining's binary_logloss: 0.555567\n",
      "[287]\ttraining's binary_logloss: 0.555438\n",
      "[288]\ttraining's binary_logloss: 0.555308\n",
      "[289]\ttraining's binary_logloss: 0.555178\n",
      "[290]\ttraining's binary_logloss: 0.555051\n",
      "[291]\ttraining's binary_logloss: 0.554922\n",
      "[292]\ttraining's binary_logloss: 0.554811\n",
      "[293]\ttraining's binary_logloss: 0.554657\n",
      "[294]\ttraining's binary_logloss: 0.554502\n",
      "[295]\ttraining's binary_logloss: 0.554369\n",
      "[296]\ttraining's binary_logloss: 0.554245\n",
      "[297]\ttraining's binary_logloss: 0.554098\n",
      "[298]\ttraining's binary_logloss: 0.553961\n",
      "[299]\ttraining's binary_logloss: 0.553844\n",
      "[300]\ttraining's binary_logloss: 0.553712\n",
      "[301]\ttraining's binary_logloss: 0.553564\n",
      "[302]\ttraining's binary_logloss: 0.553417\n",
      "[303]\ttraining's binary_logloss: 0.55327\n",
      "[304]\ttraining's binary_logloss: 0.55313\n",
      "[305]\ttraining's binary_logloss: 0.552992\n",
      "[306]\ttraining's binary_logloss: 0.552842\n",
      "[307]\ttraining's binary_logloss: 0.55271\n",
      "[308]\ttraining's binary_logloss: 0.552581\n",
      "[309]\ttraining's binary_logloss: 0.552456\n",
      "[310]\ttraining's binary_logloss: 0.552314\n",
      "[311]\ttraining's binary_logloss: 0.552179\n",
      "[312]\ttraining's binary_logloss: 0.552033\n",
      "[313]\ttraining's binary_logloss: 0.55192\n",
      "[314]\ttraining's binary_logloss: 0.551808\n",
      "[315]\ttraining's binary_logloss: 0.551668\n",
      "[316]\ttraining's binary_logloss: 0.551503\n",
      "[317]\ttraining's binary_logloss: 0.551362\n",
      "[318]\ttraining's binary_logloss: 0.551204\n",
      "[319]\ttraining's binary_logloss: 0.551044\n",
      "[320]\ttraining's binary_logloss: 0.550904\n",
      "[321]\ttraining's binary_logloss: 0.550751\n",
      "[322]\ttraining's binary_logloss: 0.550627\n",
      "[323]\ttraining's binary_logloss: 0.550522\n",
      "[324]\ttraining's binary_logloss: 0.550441\n",
      "[325]\ttraining's binary_logloss: 0.550338\n",
      "[326]\ttraining's binary_logloss: 0.550207\n",
      "[327]\ttraining's binary_logloss: 0.550085\n",
      "[328]\ttraining's binary_logloss: 0.549959\n",
      "[329]\ttraining's binary_logloss: 0.549849\n",
      "[330]\ttraining's binary_logloss: 0.549733\n",
      "[331]\ttraining's binary_logloss: 0.549566\n",
      "[332]\ttraining's binary_logloss: 0.549432\n",
      "[333]\ttraining's binary_logloss: 0.549261\n",
      "[334]\ttraining's binary_logloss: 0.549117\n",
      "[335]\ttraining's binary_logloss: 0.548973\n",
      "[336]\ttraining's binary_logloss: 0.548844\n",
      "[337]\ttraining's binary_logloss: 0.548719\n",
      "[338]\ttraining's binary_logloss: 0.548587\n",
      "[339]\ttraining's binary_logloss: 0.548466\n",
      "[340]\ttraining's binary_logloss: 0.54835\n",
      "[341]\ttraining's binary_logloss: 0.548244\n",
      "[342]\ttraining's binary_logloss: 0.548102\n",
      "[343]\ttraining's binary_logloss: 0.547965\n",
      "[344]\ttraining's binary_logloss: 0.547834\n",
      "[345]\ttraining's binary_logloss: 0.547722\n",
      "[346]\ttraining's binary_logloss: 0.547616\n",
      "[347]\ttraining's binary_logloss: 0.547529\n",
      "[348]\ttraining's binary_logloss: 0.547449\n",
      "[349]\ttraining's binary_logloss: 0.547369\n",
      "[350]\ttraining's binary_logloss: 0.547265\n",
      "[351]\ttraining's binary_logloss: 0.547123\n",
      "[352]\ttraining's binary_logloss: 0.546997\n",
      "[353]\ttraining's binary_logloss: 0.546865\n",
      "[354]\ttraining's binary_logloss: 0.546709\n",
      "[355]\ttraining's binary_logloss: 0.546551\n",
      "[356]\ttraining's binary_logloss: 0.546423\n",
      "[357]\ttraining's binary_logloss: 0.546287\n",
      "[358]\ttraining's binary_logloss: 0.546157\n",
      "[359]\ttraining's binary_logloss: 0.546021\n",
      "[360]\ttraining's binary_logloss: 0.545895\n",
      "[361]\ttraining's binary_logloss: 0.545745\n",
      "[362]\ttraining's binary_logloss: 0.545578\n",
      "[363]\ttraining's binary_logloss: 0.545403\n",
      "[364]\ttraining's binary_logloss: 0.545252\n",
      "[365]\ttraining's binary_logloss: 0.545102\n",
      "[366]\ttraining's binary_logloss: 0.544975\n",
      "[367]\ttraining's binary_logloss: 0.54486\n",
      "[368]\ttraining's binary_logloss: 0.544741\n",
      "[369]\ttraining's binary_logloss: 0.544629\n",
      "[370]\ttraining's binary_logloss: 0.544511\n",
      "[371]\ttraining's binary_logloss: 0.544372\n",
      "[372]\ttraining's binary_logloss: 0.54423\n",
      "[373]\ttraining's binary_logloss: 0.54409\n",
      "[374]\ttraining's binary_logloss: 0.543947\n",
      "[375]\ttraining's binary_logloss: 0.54383\n",
      "[376]\ttraining's binary_logloss: 0.543665\n",
      "[377]\ttraining's binary_logloss: 0.543499\n",
      "[378]\ttraining's binary_logloss: 0.543361\n",
      "[379]\ttraining's binary_logloss: 0.543201\n",
      "[380]\ttraining's binary_logloss: 0.543085\n",
      "[381]\ttraining's binary_logloss: 0.542936\n",
      "[382]\ttraining's binary_logloss: 0.54277\n",
      "[383]\ttraining's binary_logloss: 0.542607\n",
      "[384]\ttraining's binary_logloss: 0.542477\n",
      "[385]\ttraining's binary_logloss: 0.542322\n",
      "[386]\ttraining's binary_logloss: 0.542201\n",
      "[387]\ttraining's binary_logloss: 0.542062\n",
      "[388]\ttraining's binary_logloss: 0.541916\n",
      "[389]\ttraining's binary_logloss: 0.541777\n",
      "[390]\ttraining's binary_logloss: 0.541641\n",
      "[391]\ttraining's binary_logloss: 0.541466\n",
      "[392]\ttraining's binary_logloss: 0.541314\n",
      "[393]\ttraining's binary_logloss: 0.541163\n",
      "[394]\ttraining's binary_logloss: 0.541021\n",
      "[395]\ttraining's binary_logloss: 0.540847\n",
      "[396]\ttraining's binary_logloss: 0.540697\n",
      "[397]\ttraining's binary_logloss: 0.540548\n",
      "[398]\ttraining's binary_logloss: 0.540405\n",
      "[399]\ttraining's binary_logloss: 0.540278\n",
      "[400]\ttraining's binary_logloss: 0.540139\n",
      "[401]\ttraining's binary_logloss: 0.540001\n",
      "[402]\ttraining's binary_logloss: 0.539853\n",
      "[403]\ttraining's binary_logloss: 0.539705\n",
      "[404]\ttraining's binary_logloss: 0.53955\n",
      "[405]\ttraining's binary_logloss: 0.539397\n",
      "[406]\ttraining's binary_logloss: 0.539232\n",
      "[407]\ttraining's binary_logloss: 0.539069\n",
      "[408]\ttraining's binary_logloss: 0.538917\n",
      "[409]\ttraining's binary_logloss: 0.53877\n",
      "[410]\ttraining's binary_logloss: 0.538625\n",
      "[411]\ttraining's binary_logloss: 0.538476\n",
      "[412]\ttraining's binary_logloss: 0.538333\n",
      "[413]\ttraining's binary_logloss: 0.53819\n",
      "[414]\ttraining's binary_logloss: 0.538063\n",
      "[415]\ttraining's binary_logloss: 0.537925\n",
      "[416]\ttraining's binary_logloss: 0.537774\n",
      "[417]\ttraining's binary_logloss: 0.537623\n",
      "[418]\ttraining's binary_logloss: 0.537475\n",
      "[419]\ttraining's binary_logloss: 0.537341\n",
      "[420]\ttraining's binary_logloss: 0.537185\n",
      "[421]\ttraining's binary_logloss: 0.537086\n",
      "[422]\ttraining's binary_logloss: 0.536986\n",
      "[423]\ttraining's binary_logloss: 0.5369\n",
      "[424]\ttraining's binary_logloss: 0.536791\n",
      "[425]\ttraining's binary_logloss: 0.536681\n",
      "[426]\ttraining's binary_logloss: 0.536535\n",
      "[427]\ttraining's binary_logloss: 0.536392\n",
      "[428]\ttraining's binary_logloss: 0.536244\n",
      "[429]\ttraining's binary_logloss: 0.536103\n",
      "[430]\ttraining's binary_logloss: 0.535974\n",
      "[431]\ttraining's binary_logloss: 0.535846\n",
      "[432]\ttraining's binary_logloss: 0.535712\n",
      "[433]\ttraining's binary_logloss: 0.535588\n",
      "[434]\ttraining's binary_logloss: 0.535457\n",
      "[435]\ttraining's binary_logloss: 0.535299\n",
      "[436]\ttraining's binary_logloss: 0.535197\n",
      "[437]\ttraining's binary_logloss: 0.535084\n",
      "[438]\ttraining's binary_logloss: 0.534965\n",
      "[439]\ttraining's binary_logloss: 0.534861\n",
      "[440]\ttraining's binary_logloss: 0.534745\n",
      "[441]\ttraining's binary_logloss: 0.534595\n",
      "[442]\ttraining's binary_logloss: 0.53444\n",
      "[443]\ttraining's binary_logloss: 0.534283\n",
      "[444]\ttraining's binary_logloss: 0.53413\n",
      "[445]\ttraining's binary_logloss: 0.533993\n",
      "[446]\ttraining's binary_logloss: 0.533876\n",
      "[447]\ttraining's binary_logloss: 0.533758\n",
      "[448]\ttraining's binary_logloss: 0.533605\n",
      "[449]\ttraining's binary_logloss: 0.533502\n",
      "[450]\ttraining's binary_logloss: 0.533392\n",
      "[451]\ttraining's binary_logloss: 0.533288\n",
      "[452]\ttraining's binary_logloss: 0.533177\n",
      "[453]\ttraining's binary_logloss: 0.533083\n",
      "[454]\ttraining's binary_logloss: 0.532991\n",
      "[455]\ttraining's binary_logloss: 0.532884\n",
      "[456]\ttraining's binary_logloss: 0.532716\n",
      "[457]\ttraining's binary_logloss: 0.532557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[458]\ttraining's binary_logloss: 0.532392\n",
      "[459]\ttraining's binary_logloss: 0.532226\n",
      "[460]\ttraining's binary_logloss: 0.532082\n",
      "[461]\ttraining's binary_logloss: 0.531966\n",
      "[462]\ttraining's binary_logloss: 0.531871\n",
      "[463]\ttraining's binary_logloss: 0.531761\n",
      "[464]\ttraining's binary_logloss: 0.531667\n",
      "[465]\ttraining's binary_logloss: 0.531581\n",
      "[466]\ttraining's binary_logloss: 0.531395\n",
      "[467]\ttraining's binary_logloss: 0.5312\n",
      "[468]\ttraining's binary_logloss: 0.53103\n",
      "[469]\ttraining's binary_logloss: 0.530862\n",
      "[470]\ttraining's binary_logloss: 0.53069\n",
      "[471]\ttraining's binary_logloss: 0.530548\n",
      "[472]\ttraining's binary_logloss: 0.530409\n",
      "[473]\ttraining's binary_logloss: 0.53028\n",
      "[474]\ttraining's binary_logloss: 0.530156\n",
      "[475]\ttraining's binary_logloss: 0.530031\n",
      "[476]\ttraining's binary_logloss: 0.529874\n",
      "[477]\ttraining's binary_logloss: 0.529717\n",
      "[478]\ttraining's binary_logloss: 0.529562\n",
      "[479]\ttraining's binary_logloss: 0.529417\n",
      "[480]\ttraining's binary_logloss: 0.529262\n",
      "[481]\ttraining's binary_logloss: 0.529085\n",
      "[482]\ttraining's binary_logloss: 0.528967\n",
      "[483]\ttraining's binary_logloss: 0.528843\n",
      "[484]\ttraining's binary_logloss: 0.528694\n",
      "[485]\ttraining's binary_logloss: 0.52857\n",
      "[486]\ttraining's binary_logloss: 0.528447\n",
      "[487]\ttraining's binary_logloss: 0.528331\n",
      "[488]\ttraining's binary_logloss: 0.528223\n",
      "[489]\ttraining's binary_logloss: 0.528088\n",
      "[490]\ttraining's binary_logloss: 0.52796\n",
      "[491]\ttraining's binary_logloss: 0.527793\n",
      "[492]\ttraining's binary_logloss: 0.527647\n",
      "[493]\ttraining's binary_logloss: 0.527484\n",
      "[494]\ttraining's binary_logloss: 0.527336\n",
      "[495]\ttraining's binary_logloss: 0.527193\n",
      "[496]\ttraining's binary_logloss: 0.526998\n",
      "[497]\ttraining's binary_logloss: 0.526788\n",
      "[498]\ttraining's binary_logloss: 0.526616\n",
      "[499]\ttraining's binary_logloss: 0.526417\n",
      "[500]\ttraining's binary_logloss: 0.526238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.61348\n",
      "[2]\ttraining's binary_logloss: 0.612143\n",
      "[3]\ttraining's binary_logloss: 0.610883\n",
      "[4]\ttraining's binary_logloss: 0.609594\n",
      "[5]\ttraining's binary_logloss: 0.608355\n",
      "[6]\ttraining's binary_logloss: 0.607225\n",
      "[7]\ttraining's binary_logloss: 0.606068\n",
      "[8]\ttraining's binary_logloss: 0.605025\n",
      "[9]\ttraining's binary_logloss: 0.603919\n",
      "[10]\ttraining's binary_logloss: 0.602868\n",
      "[11]\ttraining's binary_logloss: 0.6019\n",
      "[12]\ttraining's binary_logloss: 0.600961\n",
      "[13]\ttraining's binary_logloss: 0.600123\n",
      "[14]\ttraining's binary_logloss: 0.599227\n",
      "[15]\ttraining's binary_logloss: 0.598361\n",
      "[16]\ttraining's binary_logloss: 0.597618\n",
      "[17]\ttraining's binary_logloss: 0.596779\n",
      "[18]\ttraining's binary_logloss: 0.595972\n",
      "[19]\ttraining's binary_logloss: 0.595202\n",
      "[20]\ttraining's binary_logloss: 0.594541\n",
      "[21]\ttraining's binary_logloss: 0.593865\n",
      "[22]\ttraining's binary_logloss: 0.59322\n",
      "[23]\ttraining's binary_logloss: 0.5926\n",
      "[24]\ttraining's binary_logloss: 0.591903\n",
      "[25]\ttraining's binary_logloss: 0.591244\n",
      "[26]\ttraining's binary_logloss: 0.59059\n",
      "[27]\ttraining's binary_logloss: 0.589987\n",
      "[28]\ttraining's binary_logloss: 0.589342\n",
      "[29]\ttraining's binary_logloss: 0.58876\n",
      "[30]\ttraining's binary_logloss: 0.588201\n",
      "[31]\ttraining's binary_logloss: 0.587711\n",
      "[32]\ttraining's binary_logloss: 0.587184\n",
      "[33]\ttraining's binary_logloss: 0.586669\n",
      "[34]\ttraining's binary_logloss: 0.586198\n",
      "[35]\ttraining's binary_logloss: 0.585763\n",
      "[36]\ttraining's binary_logloss: 0.585243\n",
      "[37]\ttraining's binary_logloss: 0.58474\n",
      "[38]\ttraining's binary_logloss: 0.58427\n",
      "[39]\ttraining's binary_logloss: 0.583844\n",
      "[40]\ttraining's binary_logloss: 0.583482\n",
      "[41]\ttraining's binary_logloss: 0.583109\n",
      "[42]\ttraining's binary_logloss: 0.582735\n",
      "[43]\ttraining's binary_logloss: 0.582379\n",
      "[44]\ttraining's binary_logloss: 0.582037\n",
      "[45]\ttraining's binary_logloss: 0.581691\n",
      "[46]\ttraining's binary_logloss: 0.581389\n",
      "[47]\ttraining's binary_logloss: 0.581085\n",
      "[48]\ttraining's binary_logloss: 0.580711\n",
      "[49]\ttraining's binary_logloss: 0.580452\n",
      "[50]\ttraining's binary_logloss: 0.580128\n",
      "[51]\ttraining's binary_logloss: 0.579789\n",
      "[52]\ttraining's binary_logloss: 0.579557\n",
      "[53]\ttraining's binary_logloss: 0.579297\n",
      "[54]\ttraining's binary_logloss: 0.579028\n",
      "[55]\ttraining's binary_logloss: 0.578779\n",
      "[56]\ttraining's binary_logloss: 0.578486\n",
      "[57]\ttraining's binary_logloss: 0.578273\n",
      "[58]\ttraining's binary_logloss: 0.57795\n",
      "[59]\ttraining's binary_logloss: 0.577755\n",
      "[60]\ttraining's binary_logloss: 0.577557\n",
      "[61]\ttraining's binary_logloss: 0.577354\n",
      "[62]\ttraining's binary_logloss: 0.577069\n",
      "[63]\ttraining's binary_logloss: 0.576812\n",
      "[64]\ttraining's binary_logloss: 0.576618\n",
      "[65]\ttraining's binary_logloss: 0.576375\n",
      "[66]\ttraining's binary_logloss: 0.57611\n",
      "[67]\ttraining's binary_logloss: 0.575888\n",
      "[68]\ttraining's binary_logloss: 0.575641\n",
      "[69]\ttraining's binary_logloss: 0.575403\n",
      "[70]\ttraining's binary_logloss: 0.575228\n",
      "[71]\ttraining's binary_logloss: 0.575059\n",
      "[72]\ttraining's binary_logloss: 0.574873\n",
      "[73]\ttraining's binary_logloss: 0.574638\n",
      "[74]\ttraining's binary_logloss: 0.574487\n",
      "[75]\ttraining's binary_logloss: 0.574336\n",
      "[76]\ttraining's binary_logloss: 0.574152\n",
      "[77]\ttraining's binary_logloss: 0.574003\n",
      "[78]\ttraining's binary_logloss: 0.573867\n",
      "[79]\ttraining's binary_logloss: 0.573742\n",
      "[80]\ttraining's binary_logloss: 0.573612\n",
      "[81]\ttraining's binary_logloss: 0.573508\n",
      "[82]\ttraining's binary_logloss: 0.573376\n",
      "[83]\ttraining's binary_logloss: 0.573262\n",
      "[84]\ttraining's binary_logloss: 0.573132\n",
      "[85]\ttraining's binary_logloss: 0.573004\n",
      "[86]\ttraining's binary_logloss: 0.572875\n",
      "[87]\ttraining's binary_logloss: 0.572754\n",
      "[88]\ttraining's binary_logloss: 0.572626\n",
      "[89]\ttraining's binary_logloss: 0.572507\n",
      "[90]\ttraining's binary_logloss: 0.572392\n",
      "[91]\ttraining's binary_logloss: 0.572235\n",
      "[92]\ttraining's binary_logloss: 0.572132\n",
      "[93]\ttraining's binary_logloss: 0.572023\n",
      "[94]\ttraining's binary_logloss: 0.571934\n",
      "[95]\ttraining's binary_logloss: 0.571819\n",
      "[96]\ttraining's binary_logloss: 0.571749\n",
      "[97]\ttraining's binary_logloss: 0.571683\n",
      "[98]\ttraining's binary_logloss: 0.57164\n",
      "[99]\ttraining's binary_logloss: 0.571569\n",
      "[100]\ttraining's binary_logloss: 0.571519\n",
      "[101]\ttraining's binary_logloss: 0.571424\n",
      "[102]\ttraining's binary_logloss: 0.571333\n",
      "[103]\ttraining's binary_logloss: 0.571241\n",
      "[104]\ttraining's binary_logloss: 0.571141\n",
      "[105]\ttraining's binary_logloss: 0.571067\n",
      "[106]\ttraining's binary_logloss: 0.571019\n",
      "[107]\ttraining's binary_logloss: 0.570915\n",
      "[108]\ttraining's binary_logloss: 0.570813\n",
      "[109]\ttraining's binary_logloss: 0.570735\n",
      "[110]\ttraining's binary_logloss: 0.570637\n",
      "[111]\ttraining's binary_logloss: 0.570537\n",
      "[112]\ttraining's binary_logloss: 0.570479\n",
      "[113]\ttraining's binary_logloss: 0.570378\n",
      "[114]\ttraining's binary_logloss: 0.570328\n",
      "[115]\ttraining's binary_logloss: 0.570237\n",
      "[116]\ttraining's binary_logloss: 0.57015\n",
      "[117]\ttraining's binary_logloss: 0.570048\n",
      "[118]\ttraining's binary_logloss: 0.56997\n",
      "[119]\ttraining's binary_logloss: 0.569877\n",
      "[120]\ttraining's binary_logloss: 0.56979\n",
      "[121]\ttraining's binary_logloss: 0.569733\n",
      "[122]\ttraining's binary_logloss: 0.569647\n",
      "[123]\ttraining's binary_logloss: 0.569588\n",
      "[124]\ttraining's binary_logloss: 0.569527\n",
      "[125]\ttraining's binary_logloss: 0.569462\n",
      "[126]\ttraining's binary_logloss: 0.569372\n",
      "[127]\ttraining's binary_logloss: 0.569272\n",
      "[128]\ttraining's binary_logloss: 0.569163\n",
      "[129]\ttraining's binary_logloss: 0.569054\n",
      "[130]\ttraining's binary_logloss: 0.568954\n",
      "[131]\ttraining's binary_logloss: 0.568935\n",
      "[132]\ttraining's binary_logloss: 0.56891\n",
      "[133]\ttraining's binary_logloss: 0.568887\n",
      "[134]\ttraining's binary_logloss: 0.568828\n",
      "[135]\ttraining's binary_logloss: 0.568779\n",
      "[136]\ttraining's binary_logloss: 0.568675\n",
      "[137]\ttraining's binary_logloss: 0.568607\n",
      "[138]\ttraining's binary_logloss: 0.568553\n",
      "[139]\ttraining's binary_logloss: 0.568483\n",
      "[140]\ttraining's binary_logloss: 0.56841\n",
      "[141]\ttraining's binary_logloss: 0.568317\n",
      "[142]\ttraining's binary_logloss: 0.568254\n",
      "[143]\ttraining's binary_logloss: 0.568178\n",
      "[144]\ttraining's binary_logloss: 0.568114\n",
      "[145]\ttraining's binary_logloss: 0.568056\n",
      "[146]\ttraining's binary_logloss: 0.567978\n",
      "[147]\ttraining's binary_logloss: 0.567882\n",
      "[148]\ttraining's binary_logloss: 0.567782\n",
      "[149]\ttraining's binary_logloss: 0.567742\n",
      "[150]\ttraining's binary_logloss: 0.567655\n",
      "[151]\ttraining's binary_logloss: 0.567614\n",
      "[152]\ttraining's binary_logloss: 0.567586\n",
      "[153]\ttraining's binary_logloss: 0.567544\n",
      "[154]\ttraining's binary_logloss: 0.567507\n",
      "[155]\ttraining's binary_logloss: 0.567457\n",
      "[156]\ttraining's binary_logloss: 0.567389\n",
      "[157]\ttraining's binary_logloss: 0.567317\n",
      "[158]\ttraining's binary_logloss: 0.567258\n",
      "[159]\ttraining's binary_logloss: 0.567192\n",
      "[160]\ttraining's binary_logloss: 0.56711\n",
      "[161]\ttraining's binary_logloss: 0.567025\n",
      "[162]\ttraining's binary_logloss: 0.566942\n",
      "[163]\ttraining's binary_logloss: 0.566868\n",
      "[164]\ttraining's binary_logloss: 0.566802\n",
      "[165]\ttraining's binary_logloss: 0.566728\n",
      "[166]\ttraining's binary_logloss: 0.566648\n",
      "[167]\ttraining's binary_logloss: 0.566591\n",
      "[168]\ttraining's binary_logloss: 0.566546\n",
      "[169]\ttraining's binary_logloss: 0.566499\n",
      "[170]\ttraining's binary_logloss: 0.566457\n",
      "[171]\ttraining's binary_logloss: 0.566371\n",
      "[172]\ttraining's binary_logloss: 0.566272\n",
      "[173]\ttraining's binary_logloss: 0.566185\n",
      "[174]\ttraining's binary_logloss: 0.56611\n",
      "[175]\ttraining's binary_logloss: 0.566024\n",
      "[176]\ttraining's binary_logloss: 0.565931\n",
      "[177]\ttraining's binary_logloss: 0.565847\n",
      "[178]\ttraining's binary_logloss: 0.565758\n",
      "[179]\ttraining's binary_logloss: 0.565678\n",
      "[180]\ttraining's binary_logloss: 0.565617\n",
      "[181]\ttraining's binary_logloss: 0.565564\n",
      "[182]\ttraining's binary_logloss: 0.565526\n",
      "[183]\ttraining's binary_logloss: 0.56547\n",
      "[184]\ttraining's binary_logloss: 0.565398\n",
      "[185]\ttraining's binary_logloss: 0.565321\n",
      "[186]\ttraining's binary_logloss: 0.565309\n",
      "[187]\ttraining's binary_logloss: 0.56526\n",
      "[188]\ttraining's binary_logloss: 0.565241\n",
      "[189]\ttraining's binary_logloss: 0.5652\n",
      "[190]\ttraining's binary_logloss: 0.565155\n",
      "[191]\ttraining's binary_logloss: 0.565079\n",
      "[192]\ttraining's binary_logloss: 0.564998\n",
      "[193]\ttraining's binary_logloss: 0.564918\n",
      "[194]\ttraining's binary_logloss: 0.564874\n",
      "[195]\ttraining's binary_logloss: 0.564782\n",
      "[196]\ttraining's binary_logloss: 0.564693\n",
      "[197]\ttraining's binary_logloss: 0.564607\n",
      "[198]\ttraining's binary_logloss: 0.564519\n",
      "[199]\ttraining's binary_logloss: 0.564395\n",
      "[200]\ttraining's binary_logloss: 0.564305\n",
      "[201]\ttraining's binary_logloss: 0.56419\n",
      "[202]\ttraining's binary_logloss: 0.564086\n",
      "[203]\ttraining's binary_logloss: 0.563985\n",
      "[204]\ttraining's binary_logloss: 0.563888\n",
      "[205]\ttraining's binary_logloss: 0.563797\n",
      "[206]\ttraining's binary_logloss: 0.563728\n",
      "[207]\ttraining's binary_logloss: 0.563634\n",
      "[208]\ttraining's binary_logloss: 0.563578\n",
      "[209]\ttraining's binary_logloss: 0.563486\n",
      "[210]\ttraining's binary_logloss: 0.563431\n",
      "[211]\ttraining's binary_logloss: 0.563318\n",
      "[212]\ttraining's binary_logloss: 0.563208\n",
      "[213]\ttraining's binary_logloss: 0.563107\n",
      "[214]\ttraining's binary_logloss: 0.563012\n",
      "[215]\ttraining's binary_logloss: 0.562921\n",
      "[216]\ttraining's binary_logloss: 0.562797\n",
      "[217]\ttraining's binary_logloss: 0.562687\n",
      "[218]\ttraining's binary_logloss: 0.562574\n",
      "[219]\ttraining's binary_logloss: 0.562459\n",
      "[220]\ttraining's binary_logloss: 0.562341\n",
      "[221]\ttraining's binary_logloss: 0.562267\n",
      "[222]\ttraining's binary_logloss: 0.562188\n",
      "[223]\ttraining's binary_logloss: 0.56206\n",
      "[224]\ttraining's binary_logloss: 0.561973\n",
      "[225]\ttraining's binary_logloss: 0.56188\n",
      "[226]\ttraining's binary_logloss: 0.561769\n",
      "[227]\ttraining's binary_logloss: 0.561674\n",
      "[228]\ttraining's binary_logloss: 0.561578\n",
      "[229]\ttraining's binary_logloss: 0.561501\n",
      "[230]\ttraining's binary_logloss: 0.561407\n",
      "[231]\ttraining's binary_logloss: 0.561272\n",
      "[232]\ttraining's binary_logloss: 0.561142\n",
      "[233]\ttraining's binary_logloss: 0.561021\n",
      "[234]\ttraining's binary_logloss: 0.560904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[235]\ttraining's binary_logloss: 0.560795\n",
      "[236]\ttraining's binary_logloss: 0.560696\n",
      "[237]\ttraining's binary_logloss: 0.560587\n",
      "[238]\ttraining's binary_logloss: 0.560487\n",
      "[239]\ttraining's binary_logloss: 0.560402\n",
      "[240]\ttraining's binary_logloss: 0.56027\n",
      "[241]\ttraining's binary_logloss: 0.560175\n",
      "[242]\ttraining's binary_logloss: 0.560081\n",
      "[243]\ttraining's binary_logloss: 0.559981\n",
      "[244]\ttraining's binary_logloss: 0.559895\n",
      "[245]\ttraining's binary_logloss: 0.559789\n",
      "[246]\ttraining's binary_logloss: 0.559664\n",
      "[247]\ttraining's binary_logloss: 0.55954\n",
      "[248]\ttraining's binary_logloss: 0.559406\n",
      "[249]\ttraining's binary_logloss: 0.559291\n",
      "[250]\ttraining's binary_logloss: 0.559178\n",
      "[251]\ttraining's binary_logloss: 0.559064\n",
      "[252]\ttraining's binary_logloss: 0.558954\n",
      "[253]\ttraining's binary_logloss: 0.558854\n",
      "[254]\ttraining's binary_logloss: 0.558752\n",
      "[255]\ttraining's binary_logloss: 0.558653\n",
      "[256]\ttraining's binary_logloss: 0.558527\n",
      "[257]\ttraining's binary_logloss: 0.558433\n",
      "[258]\ttraining's binary_logloss: 0.55834\n",
      "[259]\ttraining's binary_logloss: 0.558214\n",
      "[260]\ttraining's binary_logloss: 0.558107\n",
      "[261]\ttraining's binary_logloss: 0.557959\n",
      "[262]\ttraining's binary_logloss: 0.557808\n",
      "[263]\ttraining's binary_logloss: 0.557666\n",
      "[264]\ttraining's binary_logloss: 0.557524\n",
      "[265]\ttraining's binary_logloss: 0.557382\n",
      "[266]\ttraining's binary_logloss: 0.557268\n",
      "[267]\ttraining's binary_logloss: 0.557167\n",
      "[268]\ttraining's binary_logloss: 0.557077\n",
      "[269]\ttraining's binary_logloss: 0.557022\n",
      "[270]\ttraining's binary_logloss: 0.556928\n",
      "[271]\ttraining's binary_logloss: 0.55679\n",
      "[272]\ttraining's binary_logloss: 0.556692\n",
      "[273]\ttraining's binary_logloss: 0.5566\n",
      "[274]\ttraining's binary_logloss: 0.556503\n",
      "[275]\ttraining's binary_logloss: 0.556413\n",
      "[276]\ttraining's binary_logloss: 0.556309\n",
      "[277]\ttraining's binary_logloss: 0.556189\n",
      "[278]\ttraining's binary_logloss: 0.556066\n",
      "[279]\ttraining's binary_logloss: 0.555944\n",
      "[280]\ttraining's binary_logloss: 0.555822\n",
      "[281]\ttraining's binary_logloss: 0.555728\n",
      "[282]\ttraining's binary_logloss: 0.555629\n",
      "[283]\ttraining's binary_logloss: 0.555518\n",
      "[284]\ttraining's binary_logloss: 0.555413\n",
      "[285]\ttraining's binary_logloss: 0.55531\n",
      "[286]\ttraining's binary_logloss: 0.555136\n",
      "[287]\ttraining's binary_logloss: 0.554963\n",
      "[288]\ttraining's binary_logloss: 0.554804\n",
      "[289]\ttraining's binary_logloss: 0.554629\n",
      "[290]\ttraining's binary_logloss: 0.554468\n",
      "[291]\ttraining's binary_logloss: 0.55434\n",
      "[292]\ttraining's binary_logloss: 0.554194\n",
      "[293]\ttraining's binary_logloss: 0.554093\n",
      "[294]\ttraining's binary_logloss: 0.553994\n",
      "[295]\ttraining's binary_logloss: 0.553904\n",
      "[296]\ttraining's binary_logloss: 0.553738\n",
      "[297]\ttraining's binary_logloss: 0.553599\n",
      "[298]\ttraining's binary_logloss: 0.553437\n",
      "[299]\ttraining's binary_logloss: 0.553303\n",
      "[300]\ttraining's binary_logloss: 0.553151\n",
      "[301]\ttraining's binary_logloss: 0.552994\n",
      "[302]\ttraining's binary_logloss: 0.552849\n",
      "[303]\ttraining's binary_logloss: 0.552709\n",
      "[304]\ttraining's binary_logloss: 0.552558\n",
      "[305]\ttraining's binary_logloss: 0.552406\n",
      "[306]\ttraining's binary_logloss: 0.552231\n",
      "[307]\ttraining's binary_logloss: 0.552065\n",
      "[308]\ttraining's binary_logloss: 0.551929\n",
      "[309]\ttraining's binary_logloss: 0.551767\n",
      "[310]\ttraining's binary_logloss: 0.551644\n",
      "[311]\ttraining's binary_logloss: 0.551504\n",
      "[312]\ttraining's binary_logloss: 0.551356\n",
      "[313]\ttraining's binary_logloss: 0.551222\n",
      "[314]\ttraining's binary_logloss: 0.551117\n",
      "[315]\ttraining's binary_logloss: 0.550973\n",
      "[316]\ttraining's binary_logloss: 0.550833\n",
      "[317]\ttraining's binary_logloss: 0.550693\n",
      "[318]\ttraining's binary_logloss: 0.550571\n",
      "[319]\ttraining's binary_logloss: 0.550441\n",
      "[320]\ttraining's binary_logloss: 0.550319\n",
      "[321]\ttraining's binary_logloss: 0.550224\n",
      "[322]\ttraining's binary_logloss: 0.550142\n",
      "[323]\ttraining's binary_logloss: 0.550057\n",
      "[324]\ttraining's binary_logloss: 0.549974\n",
      "[325]\ttraining's binary_logloss: 0.549863\n",
      "[326]\ttraining's binary_logloss: 0.549757\n",
      "[327]\ttraining's binary_logloss: 0.549636\n",
      "[328]\ttraining's binary_logloss: 0.549553\n",
      "[329]\ttraining's binary_logloss: 0.549467\n",
      "[330]\ttraining's binary_logloss: 0.549374\n",
      "[331]\ttraining's binary_logloss: 0.54922\n",
      "[332]\ttraining's binary_logloss: 0.549057\n",
      "[333]\ttraining's binary_logloss: 0.548903\n",
      "[334]\ttraining's binary_logloss: 0.548745\n",
      "[335]\ttraining's binary_logloss: 0.548602\n",
      "[336]\ttraining's binary_logloss: 0.54848\n",
      "[337]\ttraining's binary_logloss: 0.548356\n",
      "[338]\ttraining's binary_logloss: 0.548228\n",
      "[339]\ttraining's binary_logloss: 0.548078\n",
      "[340]\ttraining's binary_logloss: 0.547923\n",
      "[341]\ttraining's binary_logloss: 0.547761\n",
      "[342]\ttraining's binary_logloss: 0.547597\n",
      "[343]\ttraining's binary_logloss: 0.547445\n",
      "[344]\ttraining's binary_logloss: 0.547279\n",
      "[345]\ttraining's binary_logloss: 0.547133\n",
      "[346]\ttraining's binary_logloss: 0.54705\n",
      "[347]\ttraining's binary_logloss: 0.546958\n",
      "[348]\ttraining's binary_logloss: 0.546873\n",
      "[349]\ttraining's binary_logloss: 0.546784\n",
      "[350]\ttraining's binary_logloss: 0.546682\n",
      "[351]\ttraining's binary_logloss: 0.546503\n",
      "[352]\ttraining's binary_logloss: 0.546354\n",
      "[353]\ttraining's binary_logloss: 0.546177\n",
      "[354]\ttraining's binary_logloss: 0.546028\n",
      "[355]\ttraining's binary_logloss: 0.545875\n",
      "[356]\ttraining's binary_logloss: 0.545731\n",
      "[357]\ttraining's binary_logloss: 0.545605\n",
      "[358]\ttraining's binary_logloss: 0.545487\n",
      "[359]\ttraining's binary_logloss: 0.545371\n",
      "[360]\ttraining's binary_logloss: 0.545252\n",
      "[361]\ttraining's binary_logloss: 0.545102\n",
      "[362]\ttraining's binary_logloss: 0.544964\n",
      "[363]\ttraining's binary_logloss: 0.544841\n",
      "[364]\ttraining's binary_logloss: 0.544718\n",
      "[365]\ttraining's binary_logloss: 0.544613\n",
      "[366]\ttraining's binary_logloss: 0.544499\n",
      "[367]\ttraining's binary_logloss: 0.544401\n",
      "[368]\ttraining's binary_logloss: 0.544307\n",
      "[369]\ttraining's binary_logloss: 0.544217\n",
      "[370]\ttraining's binary_logloss: 0.544108\n",
      "[371]\ttraining's binary_logloss: 0.543947\n",
      "[372]\ttraining's binary_logloss: 0.543778\n",
      "[373]\ttraining's binary_logloss: 0.543628\n",
      "[374]\ttraining's binary_logloss: 0.54347\n",
      "[375]\ttraining's binary_logloss: 0.543316\n",
      "[376]\ttraining's binary_logloss: 0.543148\n",
      "[377]\ttraining's binary_logloss: 0.542961\n",
      "[378]\ttraining's binary_logloss: 0.542853\n",
      "[379]\ttraining's binary_logloss: 0.542717\n",
      "[380]\ttraining's binary_logloss: 0.542553\n",
      "[381]\ttraining's binary_logloss: 0.542402\n",
      "[382]\ttraining's binary_logloss: 0.54226\n",
      "[383]\ttraining's binary_logloss: 0.542123\n",
      "[384]\ttraining's binary_logloss: 0.54198\n",
      "[385]\ttraining's binary_logloss: 0.541834\n",
      "[386]\ttraining's binary_logloss: 0.541696\n",
      "[387]\ttraining's binary_logloss: 0.541557\n",
      "[388]\ttraining's binary_logloss: 0.541404\n",
      "[389]\ttraining's binary_logloss: 0.541276\n",
      "[390]\ttraining's binary_logloss: 0.541132\n",
      "[391]\ttraining's binary_logloss: 0.540916\n",
      "[392]\ttraining's binary_logloss: 0.54072\n",
      "[393]\ttraining's binary_logloss: 0.540529\n",
      "[394]\ttraining's binary_logloss: 0.540336\n",
      "[395]\ttraining's binary_logloss: 0.540172\n",
      "[396]\ttraining's binary_logloss: 0.540019\n",
      "[397]\ttraining's binary_logloss: 0.539892\n",
      "[398]\ttraining's binary_logloss: 0.539737\n",
      "[399]\ttraining's binary_logloss: 0.539568\n",
      "[400]\ttraining's binary_logloss: 0.539408\n",
      "[401]\ttraining's binary_logloss: 0.53926\n",
      "[402]\ttraining's binary_logloss: 0.539135\n",
      "[403]\ttraining's binary_logloss: 0.538996\n",
      "[404]\ttraining's binary_logloss: 0.538851\n",
      "[405]\ttraining's binary_logloss: 0.538713\n",
      "[406]\ttraining's binary_logloss: 0.538552\n",
      "[407]\ttraining's binary_logloss: 0.538411\n",
      "[408]\ttraining's binary_logloss: 0.53827\n",
      "[409]\ttraining's binary_logloss: 0.53813\n",
      "[410]\ttraining's binary_logloss: 0.537986\n",
      "[411]\ttraining's binary_logloss: 0.537828\n",
      "[412]\ttraining's binary_logloss: 0.537701\n",
      "[413]\ttraining's binary_logloss: 0.537557\n",
      "[414]\ttraining's binary_logloss: 0.537445\n",
      "[415]\ttraining's binary_logloss: 0.537312\n",
      "[416]\ttraining's binary_logloss: 0.537165\n",
      "[417]\ttraining's binary_logloss: 0.537025\n",
      "[418]\ttraining's binary_logloss: 0.536893\n",
      "[419]\ttraining's binary_logloss: 0.536766\n",
      "[420]\ttraining's binary_logloss: 0.536622\n",
      "[421]\ttraining's binary_logloss: 0.536537\n",
      "[422]\ttraining's binary_logloss: 0.536438\n",
      "[423]\ttraining's binary_logloss: 0.536355\n",
      "[424]\ttraining's binary_logloss: 0.536256\n",
      "[425]\ttraining's binary_logloss: 0.536158\n",
      "[426]\ttraining's binary_logloss: 0.536\n",
      "[427]\ttraining's binary_logloss: 0.535842\n",
      "[428]\ttraining's binary_logloss: 0.53567\n",
      "[429]\ttraining's binary_logloss: 0.535529\n",
      "[430]\ttraining's binary_logloss: 0.535345\n",
      "[431]\ttraining's binary_logloss: 0.53523\n",
      "[432]\ttraining's binary_logloss: 0.535113\n",
      "[433]\ttraining's binary_logloss: 0.534993\n",
      "[434]\ttraining's binary_logloss: 0.53489\n",
      "[435]\ttraining's binary_logloss: 0.534772\n",
      "[436]\ttraining's binary_logloss: 0.534617\n",
      "[437]\ttraining's binary_logloss: 0.534477\n",
      "[438]\ttraining's binary_logloss: 0.534347\n",
      "[439]\ttraining's binary_logloss: 0.534187\n",
      "[440]\ttraining's binary_logloss: 0.534042\n",
      "[441]\ttraining's binary_logloss: 0.533879\n",
      "[442]\ttraining's binary_logloss: 0.533717\n",
      "[443]\ttraining's binary_logloss: 0.533557\n",
      "[444]\ttraining's binary_logloss: 0.533402\n",
      "[445]\ttraining's binary_logloss: 0.533255\n",
      "[446]\ttraining's binary_logloss: 0.533135\n",
      "[447]\ttraining's binary_logloss: 0.533004\n",
      "[448]\ttraining's binary_logloss: 0.532885\n",
      "[449]\ttraining's binary_logloss: 0.532776\n",
      "[450]\ttraining's binary_logloss: 0.532662\n",
      "[451]\ttraining's binary_logloss: 0.532574\n",
      "[452]\ttraining's binary_logloss: 0.532452\n",
      "[453]\ttraining's binary_logloss: 0.532362\n",
      "[454]\ttraining's binary_logloss: 0.532272\n",
      "[455]\ttraining's binary_logloss: 0.532183\n",
      "[456]\ttraining's binary_logloss: 0.532005\n",
      "[457]\ttraining's binary_logloss: 0.531847\n",
      "[458]\ttraining's binary_logloss: 0.531676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[459]\ttraining's binary_logloss: 0.531532\n",
      "[460]\ttraining's binary_logloss: 0.531397\n",
      "[461]\ttraining's binary_logloss: 0.531227\n",
      "[462]\ttraining's binary_logloss: 0.531071\n",
      "[463]\ttraining's binary_logloss: 0.530928\n",
      "[464]\ttraining's binary_logloss: 0.530753\n",
      "[465]\ttraining's binary_logloss: 0.530603\n",
      "[466]\ttraining's binary_logloss: 0.530425\n",
      "[467]\ttraining's binary_logloss: 0.530254\n",
      "[468]\ttraining's binary_logloss: 0.53008\n",
      "[469]\ttraining's binary_logloss: 0.529911\n",
      "[470]\ttraining's binary_logloss: 0.529729\n",
      "[471]\ttraining's binary_logloss: 0.529585\n",
      "[472]\ttraining's binary_logloss: 0.529453\n",
      "[473]\ttraining's binary_logloss: 0.529279\n",
      "[474]\ttraining's binary_logloss: 0.52913\n",
      "[475]\ttraining's binary_logloss: 0.528989\n",
      "[476]\ttraining's binary_logloss: 0.528864\n",
      "[477]\ttraining's binary_logloss: 0.528728\n",
      "[478]\ttraining's binary_logloss: 0.528602\n",
      "[479]\ttraining's binary_logloss: 0.528477\n",
      "[480]\ttraining's binary_logloss: 0.528352\n",
      "[481]\ttraining's binary_logloss: 0.528195\n",
      "[482]\ttraining's binary_logloss: 0.528043\n",
      "[483]\ttraining's binary_logloss: 0.527917\n",
      "[484]\ttraining's binary_logloss: 0.527774\n",
      "[485]\ttraining's binary_logloss: 0.527646\n",
      "[486]\ttraining's binary_logloss: 0.527505\n",
      "[487]\ttraining's binary_logloss: 0.527371\n",
      "[488]\ttraining's binary_logloss: 0.527238\n",
      "[489]\ttraining's binary_logloss: 0.527108\n",
      "[490]\ttraining's binary_logloss: 0.526982\n",
      "[491]\ttraining's binary_logloss: 0.526856\n",
      "[492]\ttraining's binary_logloss: 0.526738\n",
      "[493]\ttraining's binary_logloss: 0.526614\n",
      "[494]\ttraining's binary_logloss: 0.526465\n",
      "[495]\ttraining's binary_logloss: 0.526351\n",
      "[496]\ttraining's binary_logloss: 0.526181\n",
      "[497]\ttraining's binary_logloss: 0.526017\n",
      "[498]\ttraining's binary_logloss: 0.525854\n",
      "[499]\ttraining's binary_logloss: 0.525689\n",
      "[500]\ttraining's binary_logloss: 0.52553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.6141\n",
      "[2]\ttraining's binary_logloss: 0.612692\n",
      "[3]\ttraining's binary_logloss: 0.611316\n",
      "[4]\ttraining's binary_logloss: 0.610001\n",
      "[5]\ttraining's binary_logloss: 0.608715\n",
      "[6]\ttraining's binary_logloss: 0.607456\n",
      "[7]\ttraining's binary_logloss: 0.606187\n",
      "[8]\ttraining's binary_logloss: 0.605049\n",
      "[9]\ttraining's binary_logloss: 0.603859\n",
      "[10]\ttraining's binary_logloss: 0.602702\n",
      "[11]\ttraining's binary_logloss: 0.601586\n",
      "[12]\ttraining's binary_logloss: 0.600468\n",
      "[13]\ttraining's binary_logloss: 0.59945\n",
      "[14]\ttraining's binary_logloss: 0.598405\n",
      "[15]\ttraining's binary_logloss: 0.597398\n",
      "[16]\ttraining's binary_logloss: 0.596493\n",
      "[17]\ttraining's binary_logloss: 0.595482\n",
      "[18]\ttraining's binary_logloss: 0.594488\n",
      "[19]\ttraining's binary_logloss: 0.593574\n",
      "[20]\ttraining's binary_logloss: 0.592741\n",
      "[21]\ttraining's binary_logloss: 0.591913\n",
      "[22]\ttraining's binary_logloss: 0.591067\n",
      "[23]\ttraining's binary_logloss: 0.590278\n",
      "[24]\ttraining's binary_logloss: 0.589453\n",
      "[25]\ttraining's binary_logloss: 0.588658\n",
      "[26]\ttraining's binary_logloss: 0.587942\n",
      "[27]\ttraining's binary_logloss: 0.587217\n",
      "[28]\ttraining's binary_logloss: 0.586518\n",
      "[29]\ttraining's binary_logloss: 0.585838\n",
      "[30]\ttraining's binary_logloss: 0.585203\n",
      "[31]\ttraining's binary_logloss: 0.584514\n",
      "[32]\ttraining's binary_logloss: 0.583923\n",
      "[33]\ttraining's binary_logloss: 0.583216\n",
      "[34]\ttraining's binary_logloss: 0.582581\n",
      "[35]\ttraining's binary_logloss: 0.581992\n",
      "[36]\ttraining's binary_logloss: 0.581398\n",
      "[37]\ttraining's binary_logloss: 0.580868\n",
      "[38]\ttraining's binary_logloss: 0.580352\n",
      "[39]\ttraining's binary_logloss: 0.579866\n",
      "[40]\ttraining's binary_logloss: 0.579425\n",
      "[41]\ttraining's binary_logloss: 0.578894\n",
      "[42]\ttraining's binary_logloss: 0.57837\n",
      "[43]\ttraining's binary_logloss: 0.577838\n",
      "[44]\ttraining's binary_logloss: 0.577324\n",
      "[45]\ttraining's binary_logloss: 0.5768\n",
      "[46]\ttraining's binary_logloss: 0.576348\n",
      "[47]\ttraining's binary_logloss: 0.575939\n",
      "[48]\ttraining's binary_logloss: 0.575444\n",
      "[49]\ttraining's binary_logloss: 0.575052\n",
      "[50]\ttraining's binary_logloss: 0.574651\n",
      "[51]\ttraining's binary_logloss: 0.574191\n",
      "[52]\ttraining's binary_logloss: 0.57384\n",
      "[53]\ttraining's binary_logloss: 0.57344\n",
      "[54]\ttraining's binary_logloss: 0.573043\n",
      "[55]\ttraining's binary_logloss: 0.57269\n",
      "[56]\ttraining's binary_logloss: 0.572326\n",
      "[57]\ttraining's binary_logloss: 0.571979\n",
      "[58]\ttraining's binary_logloss: 0.571598\n",
      "[59]\ttraining's binary_logloss: 0.571249\n",
      "[60]\ttraining's binary_logloss: 0.570914\n",
      "[61]\ttraining's binary_logloss: 0.570586\n",
      "[62]\ttraining's binary_logloss: 0.570271\n",
      "[63]\ttraining's binary_logloss: 0.569955\n",
      "[64]\ttraining's binary_logloss: 0.569672\n",
      "[65]\ttraining's binary_logloss: 0.569361\n",
      "[66]\ttraining's binary_logloss: 0.569061\n",
      "[67]\ttraining's binary_logloss: 0.568763\n",
      "[68]\ttraining's binary_logloss: 0.568444\n",
      "[69]\ttraining's binary_logloss: 0.568146\n",
      "[70]\ttraining's binary_logloss: 0.567907\n",
      "[71]\ttraining's binary_logloss: 0.567653\n",
      "[72]\ttraining's binary_logloss: 0.567416\n",
      "[73]\ttraining's binary_logloss: 0.567197\n",
      "[74]\ttraining's binary_logloss: 0.566914\n",
      "[75]\ttraining's binary_logloss: 0.566679\n",
      "[76]\ttraining's binary_logloss: 0.566407\n",
      "[77]\ttraining's binary_logloss: 0.566181\n",
      "[78]\ttraining's binary_logloss: 0.565948\n",
      "[79]\ttraining's binary_logloss: 0.565778\n",
      "[80]\ttraining's binary_logloss: 0.56553\n",
      "[81]\ttraining's binary_logloss: 0.565301\n",
      "[82]\ttraining's binary_logloss: 0.565046\n",
      "[83]\ttraining's binary_logloss: 0.564823\n",
      "[84]\ttraining's binary_logloss: 0.564586\n",
      "[85]\ttraining's binary_logloss: 0.564368\n",
      "[86]\ttraining's binary_logloss: 0.564204\n",
      "[87]\ttraining's binary_logloss: 0.564008\n",
      "[88]\ttraining's binary_logloss: 0.563793\n",
      "[89]\ttraining's binary_logloss: 0.563583\n",
      "[90]\ttraining's binary_logloss: 0.563403\n",
      "[91]\ttraining's binary_logloss: 0.563202\n",
      "[92]\ttraining's binary_logloss: 0.563002\n",
      "[93]\ttraining's binary_logloss: 0.562816\n",
      "[94]\ttraining's binary_logloss: 0.562616\n",
      "[95]\ttraining's binary_logloss: 0.562437\n",
      "[96]\ttraining's binary_logloss: 0.562255\n",
      "[97]\ttraining's binary_logloss: 0.562076\n",
      "[98]\ttraining's binary_logloss: 0.561885\n",
      "[99]\ttraining's binary_logloss: 0.561695\n",
      "[100]\ttraining's binary_logloss: 0.561494\n",
      "[101]\ttraining's binary_logloss: 0.561309\n",
      "[102]\ttraining's binary_logloss: 0.56112\n",
      "[103]\ttraining's binary_logloss: 0.560955\n",
      "[104]\ttraining's binary_logloss: 0.560812\n",
      "[105]\ttraining's binary_logloss: 0.560655\n",
      "[106]\ttraining's binary_logloss: 0.560525\n",
      "[107]\ttraining's binary_logloss: 0.560327\n",
      "[108]\ttraining's binary_logloss: 0.560134\n",
      "[109]\ttraining's binary_logloss: 0.559965\n",
      "[110]\ttraining's binary_logloss: 0.559796\n",
      "[111]\ttraining's binary_logloss: 0.559616\n",
      "[112]\ttraining's binary_logloss: 0.559416\n",
      "[113]\ttraining's binary_logloss: 0.559235\n",
      "[114]\ttraining's binary_logloss: 0.559075\n",
      "[115]\ttraining's binary_logloss: 0.558911\n",
      "[116]\ttraining's binary_logloss: 0.558755\n",
      "[117]\ttraining's binary_logloss: 0.558594\n",
      "[118]\ttraining's binary_logloss: 0.558443\n",
      "[119]\ttraining's binary_logloss: 0.558294\n",
      "[120]\ttraining's binary_logloss: 0.558147\n",
      "[121]\ttraining's binary_logloss: 0.557989\n",
      "[122]\ttraining's binary_logloss: 0.557858\n",
      "[123]\ttraining's binary_logloss: 0.557745\n",
      "[124]\ttraining's binary_logloss: 0.557636\n",
      "[125]\ttraining's binary_logloss: 0.557529\n",
      "[126]\ttraining's binary_logloss: 0.557363\n",
      "[127]\ttraining's binary_logloss: 0.557215\n",
      "[128]\ttraining's binary_logloss: 0.557036\n",
      "[129]\ttraining's binary_logloss: 0.556873\n",
      "[130]\ttraining's binary_logloss: 0.556748\n",
      "[131]\ttraining's binary_logloss: 0.556558\n",
      "[132]\ttraining's binary_logloss: 0.556373\n",
      "[133]\ttraining's binary_logloss: 0.55621\n",
      "[134]\ttraining's binary_logloss: 0.556027\n",
      "[135]\ttraining's binary_logloss: 0.555842\n",
      "[136]\ttraining's binary_logloss: 0.555685\n",
      "[137]\ttraining's binary_logloss: 0.55555\n",
      "[138]\ttraining's binary_logloss: 0.555431\n",
      "[139]\ttraining's binary_logloss: 0.555286\n",
      "[140]\ttraining's binary_logloss: 0.555132\n",
      "[141]\ttraining's binary_logloss: 0.555007\n",
      "[142]\ttraining's binary_logloss: 0.554868\n",
      "[143]\ttraining's binary_logloss: 0.554725\n",
      "[144]\ttraining's binary_logloss: 0.554573\n",
      "[145]\ttraining's binary_logloss: 0.554429\n",
      "[146]\ttraining's binary_logloss: 0.554263\n",
      "[147]\ttraining's binary_logloss: 0.554113\n",
      "[148]\ttraining's binary_logloss: 0.553973\n",
      "[149]\ttraining's binary_logloss: 0.553847\n",
      "[150]\ttraining's binary_logloss: 0.553708\n",
      "[151]\ttraining's binary_logloss: 0.553532\n",
      "[152]\ttraining's binary_logloss: 0.553371\n",
      "[153]\ttraining's binary_logloss: 0.55322\n",
      "[154]\ttraining's binary_logloss: 0.552997\n",
      "[155]\ttraining's binary_logloss: 0.552807\n",
      "[156]\ttraining's binary_logloss: 0.552671\n",
      "[157]\ttraining's binary_logloss: 0.552572\n",
      "[158]\ttraining's binary_logloss: 0.55245\n",
      "[159]\ttraining's binary_logloss: 0.552342\n",
      "[160]\ttraining's binary_logloss: 0.552268\n",
      "[161]\ttraining's binary_logloss: 0.552092\n",
      "[162]\ttraining's binary_logloss: 0.551879\n",
      "[163]\ttraining's binary_logloss: 0.551696\n",
      "[164]\ttraining's binary_logloss: 0.551496\n",
      "[165]\ttraining's binary_logloss: 0.551314\n",
      "[166]\ttraining's binary_logloss: 0.551154\n",
      "[167]\ttraining's binary_logloss: 0.550983\n",
      "[168]\ttraining's binary_logloss: 0.550838\n",
      "[169]\ttraining's binary_logloss: 0.550649\n",
      "[170]\ttraining's binary_logloss: 0.550473\n",
      "[171]\ttraining's binary_logloss: 0.550293\n",
      "[172]\ttraining's binary_logloss: 0.550098\n",
      "[173]\ttraining's binary_logloss: 0.549909\n",
      "[174]\ttraining's binary_logloss: 0.549747\n",
      "[175]\ttraining's binary_logloss: 0.549596\n",
      "[176]\ttraining's binary_logloss: 0.549448\n",
      "[177]\ttraining's binary_logloss: 0.549305\n",
      "[178]\ttraining's binary_logloss: 0.549158\n",
      "[179]\ttraining's binary_logloss: 0.54901\n",
      "[180]\ttraining's binary_logloss: 0.548871\n",
      "[181]\ttraining's binary_logloss: 0.548714\n",
      "[182]\ttraining's binary_logloss: 0.548506\n",
      "[183]\ttraining's binary_logloss: 0.548317\n",
      "[184]\ttraining's binary_logloss: 0.548173\n",
      "[185]\ttraining's binary_logloss: 0.547987\n",
      "[186]\ttraining's binary_logloss: 0.547846\n",
      "[187]\ttraining's binary_logloss: 0.54768\n",
      "[188]\ttraining's binary_logloss: 0.547539\n",
      "[189]\ttraining's binary_logloss: 0.547402\n",
      "[190]\ttraining's binary_logloss: 0.547245\n",
      "[191]\ttraining's binary_logloss: 0.54708\n",
      "[192]\ttraining's binary_logloss: 0.54692\n",
      "[193]\ttraining's binary_logloss: 0.546735\n",
      "[194]\ttraining's binary_logloss: 0.54656\n",
      "[195]\ttraining's binary_logloss: 0.546403\n",
      "[196]\ttraining's binary_logloss: 0.546255\n",
      "[197]\ttraining's binary_logloss: 0.546081\n",
      "[198]\ttraining's binary_logloss: 0.545938\n",
      "[199]\ttraining's binary_logloss: 0.545754\n",
      "[200]\ttraining's binary_logloss: 0.545599\n",
      "[201]\ttraining's binary_logloss: 0.545411\n",
      "[202]\ttraining's binary_logloss: 0.545259\n",
      "[203]\ttraining's binary_logloss: 0.545088\n",
      "[204]\ttraining's binary_logloss: 0.544917\n",
      "[205]\ttraining's binary_logloss: 0.544733\n",
      "[206]\ttraining's binary_logloss: 0.544543\n",
      "[207]\ttraining's binary_logloss: 0.544348\n",
      "[208]\ttraining's binary_logloss: 0.544185\n",
      "[209]\ttraining's binary_logloss: 0.544017\n",
      "[210]\ttraining's binary_logloss: 0.543831\n",
      "[211]\ttraining's binary_logloss: 0.54365\n",
      "[212]\ttraining's binary_logloss: 0.543474\n",
      "[213]\ttraining's binary_logloss: 0.543332\n",
      "[214]\ttraining's binary_logloss: 0.543171\n",
      "[215]\ttraining's binary_logloss: 0.543022\n",
      "[216]\ttraining's binary_logloss: 0.542867\n",
      "[217]\ttraining's binary_logloss: 0.542726\n",
      "[218]\ttraining's binary_logloss: 0.542563\n",
      "[219]\ttraining's binary_logloss: 0.542415\n",
      "[220]\ttraining's binary_logloss: 0.542274\n",
      "[221]\ttraining's binary_logloss: 0.542051\n",
      "[222]\ttraining's binary_logloss: 0.541846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[223]\ttraining's binary_logloss: 0.541639\n",
      "[224]\ttraining's binary_logloss: 0.541438\n",
      "[225]\ttraining's binary_logloss: 0.541227\n",
      "[226]\ttraining's binary_logloss: 0.541058\n",
      "[227]\ttraining's binary_logloss: 0.540935\n",
      "[228]\ttraining's binary_logloss: 0.540775\n",
      "[229]\ttraining's binary_logloss: 0.540633\n",
      "[230]\ttraining's binary_logloss: 0.540473\n",
      "[231]\ttraining's binary_logloss: 0.540268\n",
      "[232]\ttraining's binary_logloss: 0.540102\n",
      "[233]\ttraining's binary_logloss: 0.539912\n",
      "[234]\ttraining's binary_logloss: 0.53974\n",
      "[235]\ttraining's binary_logloss: 0.539538\n",
      "[236]\ttraining's binary_logloss: 0.539345\n",
      "[237]\ttraining's binary_logloss: 0.539155\n",
      "[238]\ttraining's binary_logloss: 0.538969\n",
      "[239]\ttraining's binary_logloss: 0.538778\n",
      "[240]\ttraining's binary_logloss: 0.538594\n",
      "[241]\ttraining's binary_logloss: 0.538401\n",
      "[242]\ttraining's binary_logloss: 0.538238\n",
      "[243]\ttraining's binary_logloss: 0.538058\n",
      "[244]\ttraining's binary_logloss: 0.537886\n",
      "[245]\ttraining's binary_logloss: 0.53769\n",
      "[246]\ttraining's binary_logloss: 0.537575\n",
      "[247]\ttraining's binary_logloss: 0.537463\n",
      "[248]\ttraining's binary_logloss: 0.537348\n",
      "[249]\ttraining's binary_logloss: 0.537227\n",
      "[250]\ttraining's binary_logloss: 0.537123\n",
      "[251]\ttraining's binary_logloss: 0.536966\n",
      "[252]\ttraining's binary_logloss: 0.536795\n",
      "[253]\ttraining's binary_logloss: 0.536621\n",
      "[254]\ttraining's binary_logloss: 0.536429\n",
      "[255]\ttraining's binary_logloss: 0.53627\n",
      "[256]\ttraining's binary_logloss: 0.5361\n",
      "[257]\ttraining's binary_logloss: 0.535935\n",
      "[258]\ttraining's binary_logloss: 0.535759\n",
      "[259]\ttraining's binary_logloss: 0.535583\n",
      "[260]\ttraining's binary_logloss: 0.535427\n",
      "[261]\ttraining's binary_logloss: 0.53523\n",
      "[262]\ttraining's binary_logloss: 0.535051\n",
      "[263]\ttraining's binary_logloss: 0.534871\n",
      "[264]\ttraining's binary_logloss: 0.5347\n",
      "[265]\ttraining's binary_logloss: 0.534527\n",
      "[266]\ttraining's binary_logloss: 0.534403\n",
      "[267]\ttraining's binary_logloss: 0.534242\n",
      "[268]\ttraining's binary_logloss: 0.534128\n",
      "[269]\ttraining's binary_logloss: 0.533979\n",
      "[270]\ttraining's binary_logloss: 0.533838\n",
      "[271]\ttraining's binary_logloss: 0.533636\n",
      "[272]\ttraining's binary_logloss: 0.533415\n",
      "[273]\ttraining's binary_logloss: 0.533208\n",
      "[274]\ttraining's binary_logloss: 0.533035\n",
      "[275]\ttraining's binary_logloss: 0.532862\n",
      "[276]\ttraining's binary_logloss: 0.532652\n",
      "[277]\ttraining's binary_logloss: 0.532473\n",
      "[278]\ttraining's binary_logloss: 0.53227\n",
      "[279]\ttraining's binary_logloss: 0.532048\n",
      "[280]\ttraining's binary_logloss: 0.531848\n",
      "[281]\ttraining's binary_logloss: 0.531689\n",
      "[282]\ttraining's binary_logloss: 0.531553\n",
      "[283]\ttraining's binary_logloss: 0.531425\n",
      "[284]\ttraining's binary_logloss: 0.531255\n",
      "[285]\ttraining's binary_logloss: 0.531091\n",
      "[286]\ttraining's binary_logloss: 0.530904\n",
      "[287]\ttraining's binary_logloss: 0.530719\n",
      "[288]\ttraining's binary_logloss: 0.530549\n",
      "[289]\ttraining's binary_logloss: 0.530364\n",
      "[290]\ttraining's binary_logloss: 0.530186\n",
      "[291]\ttraining's binary_logloss: 0.529982\n",
      "[292]\ttraining's binary_logloss: 0.529783\n",
      "[293]\ttraining's binary_logloss: 0.529578\n",
      "[294]\ttraining's binary_logloss: 0.529387\n",
      "[295]\ttraining's binary_logloss: 0.529175\n",
      "[296]\ttraining's binary_logloss: 0.528951\n",
      "[297]\ttraining's binary_logloss: 0.528759\n",
      "[298]\ttraining's binary_logloss: 0.528581\n",
      "[299]\ttraining's binary_logloss: 0.528402\n",
      "[300]\ttraining's binary_logloss: 0.528236\n",
      "[301]\ttraining's binary_logloss: 0.528035\n",
      "[302]\ttraining's binary_logloss: 0.527819\n",
      "[303]\ttraining's binary_logloss: 0.52761\n",
      "[304]\ttraining's binary_logloss: 0.527412\n",
      "[305]\ttraining's binary_logloss: 0.52722\n",
      "[306]\ttraining's binary_logloss: 0.527058\n",
      "[307]\ttraining's binary_logloss: 0.52687\n",
      "[308]\ttraining's binary_logloss: 0.52667\n",
      "[309]\ttraining's binary_logloss: 0.526481\n",
      "[310]\ttraining's binary_logloss: 0.526282\n",
      "[311]\ttraining's binary_logloss: 0.526104\n",
      "[312]\ttraining's binary_logloss: 0.525953\n",
      "[313]\ttraining's binary_logloss: 0.525764\n",
      "[314]\ttraining's binary_logloss: 0.525624\n",
      "[315]\ttraining's binary_logloss: 0.525465\n",
      "[316]\ttraining's binary_logloss: 0.52527\n",
      "[317]\ttraining's binary_logloss: 0.525073\n",
      "[318]\ttraining's binary_logloss: 0.524878\n",
      "[319]\ttraining's binary_logloss: 0.524648\n",
      "[320]\ttraining's binary_logloss: 0.524413\n",
      "[321]\ttraining's binary_logloss: 0.524209\n",
      "[322]\ttraining's binary_logloss: 0.52401\n",
      "[323]\ttraining's binary_logloss: 0.523829\n",
      "[324]\ttraining's binary_logloss: 0.523639\n",
      "[325]\ttraining's binary_logloss: 0.52345\n",
      "[326]\ttraining's binary_logloss: 0.523239\n",
      "[327]\ttraining's binary_logloss: 0.523022\n",
      "[328]\ttraining's binary_logloss: 0.52283\n",
      "[329]\ttraining's binary_logloss: 0.522627\n",
      "[330]\ttraining's binary_logloss: 0.522424\n",
      "[331]\ttraining's binary_logloss: 0.522192\n",
      "[332]\ttraining's binary_logloss: 0.521978\n",
      "[333]\ttraining's binary_logloss: 0.521778\n",
      "[334]\ttraining's binary_logloss: 0.521576\n",
      "[335]\ttraining's binary_logloss: 0.521375\n",
      "[336]\ttraining's binary_logloss: 0.521211\n",
      "[337]\ttraining's binary_logloss: 0.521021\n",
      "[338]\ttraining's binary_logloss: 0.520862\n",
      "[339]\ttraining's binary_logloss: 0.520676\n",
      "[340]\ttraining's binary_logloss: 0.52049\n",
      "[341]\ttraining's binary_logloss: 0.520344\n",
      "[342]\ttraining's binary_logloss: 0.52021\n",
      "[343]\ttraining's binary_logloss: 0.520073\n",
      "[344]\ttraining's binary_logloss: 0.519936\n",
      "[345]\ttraining's binary_logloss: 0.519746\n",
      "[346]\ttraining's binary_logloss: 0.519515\n",
      "[347]\ttraining's binary_logloss: 0.519316\n",
      "[348]\ttraining's binary_logloss: 0.519096\n",
      "[349]\ttraining's binary_logloss: 0.518906\n",
      "[350]\ttraining's binary_logloss: 0.518701\n",
      "[351]\ttraining's binary_logloss: 0.518478\n",
      "[352]\ttraining's binary_logloss: 0.518284\n",
      "[353]\ttraining's binary_logloss: 0.518063\n",
      "[354]\ttraining's binary_logloss: 0.517913\n",
      "[355]\ttraining's binary_logloss: 0.517711\n",
      "[356]\ttraining's binary_logloss: 0.517518\n",
      "[357]\ttraining's binary_logloss: 0.517332\n",
      "[358]\ttraining's binary_logloss: 0.517154\n",
      "[359]\ttraining's binary_logloss: 0.516892\n",
      "[360]\ttraining's binary_logloss: 0.516713\n",
      "[361]\ttraining's binary_logloss: 0.516489\n",
      "[362]\ttraining's binary_logloss: 0.516282\n",
      "[363]\ttraining's binary_logloss: 0.51607\n",
      "[364]\ttraining's binary_logloss: 0.515843\n",
      "[365]\ttraining's binary_logloss: 0.515629\n",
      "[366]\ttraining's binary_logloss: 0.515433\n",
      "[367]\ttraining's binary_logloss: 0.515226\n",
      "[368]\ttraining's binary_logloss: 0.515052\n",
      "[369]\ttraining's binary_logloss: 0.514886\n",
      "[370]\ttraining's binary_logloss: 0.514724\n",
      "[371]\ttraining's binary_logloss: 0.51454\n",
      "[372]\ttraining's binary_logloss: 0.514345\n",
      "[373]\ttraining's binary_logloss: 0.514172\n",
      "[374]\ttraining's binary_logloss: 0.513983\n",
      "[375]\ttraining's binary_logloss: 0.513799\n",
      "[376]\ttraining's binary_logloss: 0.513598\n",
      "[377]\ttraining's binary_logloss: 0.513376\n",
      "[378]\ttraining's binary_logloss: 0.513156\n",
      "[379]\ttraining's binary_logloss: 0.512961\n",
      "[380]\ttraining's binary_logloss: 0.512781\n",
      "[381]\ttraining's binary_logloss: 0.512587\n",
      "[382]\ttraining's binary_logloss: 0.51239\n",
      "[383]\ttraining's binary_logloss: 0.512233\n",
      "[384]\ttraining's binary_logloss: 0.512078\n",
      "[385]\ttraining's binary_logloss: 0.511886\n",
      "[386]\ttraining's binary_logloss: 0.511603\n",
      "[387]\ttraining's binary_logloss: 0.511347\n",
      "[388]\ttraining's binary_logloss: 0.511075\n",
      "[389]\ttraining's binary_logloss: 0.510831\n",
      "[390]\ttraining's binary_logloss: 0.510626\n",
      "[391]\ttraining's binary_logloss: 0.510454\n",
      "[392]\ttraining's binary_logloss: 0.510255\n",
      "[393]\ttraining's binary_logloss: 0.510066\n",
      "[394]\ttraining's binary_logloss: 0.509864\n",
      "[395]\ttraining's binary_logloss: 0.509668\n",
      "[396]\ttraining's binary_logloss: 0.509452\n",
      "[397]\ttraining's binary_logloss: 0.509211\n",
      "[398]\ttraining's binary_logloss: 0.508978\n",
      "[399]\ttraining's binary_logloss: 0.508785\n",
      "[400]\ttraining's binary_logloss: 0.508565\n",
      "[401]\ttraining's binary_logloss: 0.50833\n",
      "[402]\ttraining's binary_logloss: 0.50809\n",
      "[403]\ttraining's binary_logloss: 0.507838\n",
      "[404]\ttraining's binary_logloss: 0.507588\n",
      "[405]\ttraining's binary_logloss: 0.507382\n",
      "[406]\ttraining's binary_logloss: 0.507207\n",
      "[407]\ttraining's binary_logloss: 0.507041\n",
      "[408]\ttraining's binary_logloss: 0.50686\n",
      "[409]\ttraining's binary_logloss: 0.506677\n",
      "[410]\ttraining's binary_logloss: 0.506503\n",
      "[411]\ttraining's binary_logloss: 0.50628\n",
      "[412]\ttraining's binary_logloss: 0.506035\n",
      "[413]\ttraining's binary_logloss: 0.50582\n",
      "[414]\ttraining's binary_logloss: 0.505608\n",
      "[415]\ttraining's binary_logloss: 0.505371\n",
      "[416]\ttraining's binary_logloss: 0.505163\n",
      "[417]\ttraining's binary_logloss: 0.504975\n",
      "[418]\ttraining's binary_logloss: 0.504769\n",
      "[419]\ttraining's binary_logloss: 0.504536\n",
      "[420]\ttraining's binary_logloss: 0.504327\n",
      "[421]\ttraining's binary_logloss: 0.504161\n",
      "[422]\ttraining's binary_logloss: 0.504014\n",
      "[423]\ttraining's binary_logloss: 0.503839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[424]\ttraining's binary_logloss: 0.503691\n",
      "[425]\ttraining's binary_logloss: 0.503531\n",
      "[426]\ttraining's binary_logloss: 0.503366\n",
      "[427]\ttraining's binary_logloss: 0.503196\n",
      "[428]\ttraining's binary_logloss: 0.503033\n",
      "[429]\ttraining's binary_logloss: 0.50285\n",
      "[430]\ttraining's binary_logloss: 0.502687\n",
      "[431]\ttraining's binary_logloss: 0.502472\n",
      "[432]\ttraining's binary_logloss: 0.502252\n",
      "[433]\ttraining's binary_logloss: 0.502051\n",
      "[434]\ttraining's binary_logloss: 0.501804\n",
      "[435]\ttraining's binary_logloss: 0.501563\n",
      "[436]\ttraining's binary_logloss: 0.501359\n",
      "[437]\ttraining's binary_logloss: 0.501158\n",
      "[438]\ttraining's binary_logloss: 0.500963\n",
      "[439]\ttraining's binary_logloss: 0.500774\n",
      "[440]\ttraining's binary_logloss: 0.500586\n",
      "[441]\ttraining's binary_logloss: 0.500385\n",
      "[442]\ttraining's binary_logloss: 0.500195\n",
      "[443]\ttraining's binary_logloss: 0.500041\n",
      "[444]\ttraining's binary_logloss: 0.499868\n",
      "[445]\ttraining's binary_logloss: 0.499697\n",
      "[446]\ttraining's binary_logloss: 0.499522\n",
      "[447]\ttraining's binary_logloss: 0.499314\n",
      "[448]\ttraining's binary_logloss: 0.4991\n",
      "[449]\ttraining's binary_logloss: 0.498861\n",
      "[450]\ttraining's binary_logloss: 0.498654\n",
      "[451]\ttraining's binary_logloss: 0.498492\n",
      "[452]\ttraining's binary_logloss: 0.498328\n",
      "[453]\ttraining's binary_logloss: 0.498175\n",
      "[454]\ttraining's binary_logloss: 0.497968\n",
      "[455]\ttraining's binary_logloss: 0.49782\n",
      "[456]\ttraining's binary_logloss: 0.497655\n",
      "[457]\ttraining's binary_logloss: 0.497486\n",
      "[458]\ttraining's binary_logloss: 0.497337\n",
      "[459]\ttraining's binary_logloss: 0.497184\n",
      "[460]\ttraining's binary_logloss: 0.497006\n",
      "[461]\ttraining's binary_logloss: 0.496826\n",
      "[462]\ttraining's binary_logloss: 0.496626\n",
      "[463]\ttraining's binary_logloss: 0.496395\n",
      "[464]\ttraining's binary_logloss: 0.496164\n",
      "[465]\ttraining's binary_logloss: 0.495963\n",
      "[466]\ttraining's binary_logloss: 0.495746\n",
      "[467]\ttraining's binary_logloss: 0.495528\n",
      "[468]\ttraining's binary_logloss: 0.495319\n",
      "[469]\ttraining's binary_logloss: 0.495109\n",
      "[470]\ttraining's binary_logloss: 0.494909\n",
      "[471]\ttraining's binary_logloss: 0.494767\n",
      "[472]\ttraining's binary_logloss: 0.494609\n",
      "[473]\ttraining's binary_logloss: 0.494425\n",
      "[474]\ttraining's binary_logloss: 0.494248\n",
      "[475]\ttraining's binary_logloss: 0.494084\n",
      "[476]\ttraining's binary_logloss: 0.493879\n",
      "[477]\ttraining's binary_logloss: 0.493683\n",
      "[478]\ttraining's binary_logloss: 0.493491\n",
      "[479]\ttraining's binary_logloss: 0.493309\n",
      "[480]\ttraining's binary_logloss: 0.493118\n",
      "[481]\ttraining's binary_logloss: 0.492947\n",
      "[482]\ttraining's binary_logloss: 0.492768\n",
      "[483]\ttraining's binary_logloss: 0.492599\n",
      "[484]\ttraining's binary_logloss: 0.492414\n",
      "[485]\ttraining's binary_logloss: 0.492233\n",
      "[486]\ttraining's binary_logloss: 0.49203\n",
      "[487]\ttraining's binary_logloss: 0.491832\n",
      "[488]\ttraining's binary_logloss: 0.491621\n",
      "[489]\ttraining's binary_logloss: 0.491433\n",
      "[490]\ttraining's binary_logloss: 0.49122\n",
      "[491]\ttraining's binary_logloss: 0.491085\n",
      "[492]\ttraining's binary_logloss: 0.490955\n",
      "[493]\ttraining's binary_logloss: 0.490837\n",
      "[494]\ttraining's binary_logloss: 0.490691\n",
      "[495]\ttraining's binary_logloss: 0.490561\n",
      "[496]\ttraining's binary_logloss: 0.490369\n",
      "[497]\ttraining's binary_logloss: 0.490175\n",
      "[498]\ttraining's binary_logloss: 0.489977\n",
      "[499]\ttraining's binary_logloss: 0.489759\n",
      "[500]\ttraining's binary_logloss: 0.489573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613596\n",
      "[2]\ttraining's binary_logloss: 0.612097\n",
      "[3]\ttraining's binary_logloss: 0.610647\n",
      "[4]\ttraining's binary_logloss: 0.609184\n",
      "[5]\ttraining's binary_logloss: 0.607707\n",
      "[6]\ttraining's binary_logloss: 0.606381\n",
      "[7]\ttraining's binary_logloss: 0.605063\n",
      "[8]\ttraining's binary_logloss: 0.603803\n",
      "[9]\ttraining's binary_logloss: 0.602564\n",
      "[10]\ttraining's binary_logloss: 0.601475\n",
      "[11]\ttraining's binary_logloss: 0.600217\n",
      "[12]\ttraining's binary_logloss: 0.599021\n",
      "[13]\ttraining's binary_logloss: 0.597853\n",
      "[14]\ttraining's binary_logloss: 0.596826\n",
      "[15]\ttraining's binary_logloss: 0.59581\n",
      "[16]\ttraining's binary_logloss: 0.594744\n",
      "[17]\ttraining's binary_logloss: 0.593683\n",
      "[18]\ttraining's binary_logloss: 0.592677\n",
      "[19]\ttraining's binary_logloss: 0.591702\n",
      "[20]\ttraining's binary_logloss: 0.590809\n",
      "[21]\ttraining's binary_logloss: 0.589886\n",
      "[22]\ttraining's binary_logloss: 0.588979\n",
      "[23]\ttraining's binary_logloss: 0.588174\n",
      "[24]\ttraining's binary_logloss: 0.587306\n",
      "[25]\ttraining's binary_logloss: 0.586489\n",
      "[26]\ttraining's binary_logloss: 0.585722\n",
      "[27]\ttraining's binary_logloss: 0.584989\n",
      "[28]\ttraining's binary_logloss: 0.584282\n",
      "[29]\ttraining's binary_logloss: 0.583648\n",
      "[30]\ttraining's binary_logloss: 0.582964\n",
      "[31]\ttraining's binary_logloss: 0.582196\n",
      "[32]\ttraining's binary_logloss: 0.581427\n",
      "[33]\ttraining's binary_logloss: 0.580692\n",
      "[34]\ttraining's binary_logloss: 0.580048\n",
      "[35]\ttraining's binary_logloss: 0.579352\n",
      "[36]\ttraining's binary_logloss: 0.578695\n",
      "[37]\ttraining's binary_logloss: 0.578066\n",
      "[38]\ttraining's binary_logloss: 0.577414\n",
      "[39]\ttraining's binary_logloss: 0.576756\n",
      "[40]\ttraining's binary_logloss: 0.576137\n",
      "[41]\ttraining's binary_logloss: 0.575608\n",
      "[42]\ttraining's binary_logloss: 0.575093\n",
      "[43]\ttraining's binary_logloss: 0.574616\n",
      "[44]\ttraining's binary_logloss: 0.574121\n",
      "[45]\ttraining's binary_logloss: 0.57366\n",
      "[46]\ttraining's binary_logloss: 0.573093\n",
      "[47]\ttraining's binary_logloss: 0.572552\n",
      "[48]\ttraining's binary_logloss: 0.572043\n",
      "[49]\ttraining's binary_logloss: 0.571565\n",
      "[50]\ttraining's binary_logloss: 0.571104\n",
      "[51]\ttraining's binary_logloss: 0.570602\n",
      "[52]\ttraining's binary_logloss: 0.570118\n",
      "[53]\ttraining's binary_logloss: 0.569672\n",
      "[54]\ttraining's binary_logloss: 0.569244\n",
      "[55]\ttraining's binary_logloss: 0.568789\n",
      "[56]\ttraining's binary_logloss: 0.568322\n",
      "[57]\ttraining's binary_logloss: 0.567869\n",
      "[58]\ttraining's binary_logloss: 0.56749\n",
      "[59]\ttraining's binary_logloss: 0.567061\n",
      "[60]\ttraining's binary_logloss: 0.566669\n",
      "[61]\ttraining's binary_logloss: 0.566281\n",
      "[62]\ttraining's binary_logloss: 0.565952\n",
      "[63]\ttraining's binary_logloss: 0.565581\n",
      "[64]\ttraining's binary_logloss: 0.565254\n",
      "[65]\ttraining's binary_logloss: 0.564903\n",
      "[66]\ttraining's binary_logloss: 0.564554\n",
      "[67]\ttraining's binary_logloss: 0.564213\n",
      "[68]\ttraining's binary_logloss: 0.563899\n",
      "[69]\ttraining's binary_logloss: 0.563571\n",
      "[70]\ttraining's binary_logloss: 0.563254\n",
      "[71]\ttraining's binary_logloss: 0.562915\n",
      "[72]\ttraining's binary_logloss: 0.562625\n",
      "[73]\ttraining's binary_logloss: 0.562319\n",
      "[74]\ttraining's binary_logloss: 0.562071\n",
      "[75]\ttraining's binary_logloss: 0.561786\n",
      "[76]\ttraining's binary_logloss: 0.561454\n",
      "[77]\ttraining's binary_logloss: 0.56112\n",
      "[78]\ttraining's binary_logloss: 0.560796\n",
      "[79]\ttraining's binary_logloss: 0.560489\n",
      "[80]\ttraining's binary_logloss: 0.560187\n",
      "[81]\ttraining's binary_logloss: 0.559907\n",
      "[82]\ttraining's binary_logloss: 0.559656\n",
      "[83]\ttraining's binary_logloss: 0.559432\n",
      "[84]\ttraining's binary_logloss: 0.559246\n",
      "[85]\ttraining's binary_logloss: 0.559027\n",
      "[86]\ttraining's binary_logloss: 0.558727\n",
      "[87]\ttraining's binary_logloss: 0.558418\n",
      "[88]\ttraining's binary_logloss: 0.558134\n",
      "[89]\ttraining's binary_logloss: 0.557839\n",
      "[90]\ttraining's binary_logloss: 0.557561\n",
      "[91]\ttraining's binary_logloss: 0.557405\n",
      "[92]\ttraining's binary_logloss: 0.557243\n",
      "[93]\ttraining's binary_logloss: 0.557091\n",
      "[94]\ttraining's binary_logloss: 0.556887\n",
      "[95]\ttraining's binary_logloss: 0.556675\n",
      "[96]\ttraining's binary_logloss: 0.556444\n",
      "[97]\ttraining's binary_logloss: 0.55624\n",
      "[98]\ttraining's binary_logloss: 0.556026\n",
      "[99]\ttraining's binary_logloss: 0.555826\n",
      "[100]\ttraining's binary_logloss: 0.555608\n",
      "[101]\ttraining's binary_logloss: 0.55543\n",
      "[102]\ttraining's binary_logloss: 0.55524\n",
      "[103]\ttraining's binary_logloss: 0.555061\n",
      "[104]\ttraining's binary_logloss: 0.554873\n",
      "[105]\ttraining's binary_logloss: 0.554704\n",
      "[106]\ttraining's binary_logloss: 0.554464\n",
      "[107]\ttraining's binary_logloss: 0.554276\n",
      "[108]\ttraining's binary_logloss: 0.554066\n",
      "[109]\ttraining's binary_logloss: 0.553873\n",
      "[110]\ttraining's binary_logloss: 0.553688\n",
      "[111]\ttraining's binary_logloss: 0.553488\n",
      "[112]\ttraining's binary_logloss: 0.553302\n",
      "[113]\ttraining's binary_logloss: 0.553162\n",
      "[114]\ttraining's binary_logloss: 0.552964\n",
      "[115]\ttraining's binary_logloss: 0.552776\n",
      "[116]\ttraining's binary_logloss: 0.552589\n",
      "[117]\ttraining's binary_logloss: 0.552455\n",
      "[118]\ttraining's binary_logloss: 0.552299\n",
      "[119]\ttraining's binary_logloss: 0.552129\n",
      "[120]\ttraining's binary_logloss: 0.551961\n",
      "[121]\ttraining's binary_logloss: 0.551762\n",
      "[122]\ttraining's binary_logloss: 0.551575\n",
      "[123]\ttraining's binary_logloss: 0.551385\n",
      "[124]\ttraining's binary_logloss: 0.551217\n",
      "[125]\ttraining's binary_logloss: 0.551049\n",
      "[126]\ttraining's binary_logloss: 0.550861\n",
      "[127]\ttraining's binary_logloss: 0.550694\n",
      "[128]\ttraining's binary_logloss: 0.550512\n",
      "[129]\ttraining's binary_logloss: 0.550335\n",
      "[130]\ttraining's binary_logloss: 0.550131\n",
      "[131]\ttraining's binary_logloss: 0.549919\n",
      "[132]\ttraining's binary_logloss: 0.549737\n",
      "[133]\ttraining's binary_logloss: 0.549599\n",
      "[134]\ttraining's binary_logloss: 0.549406\n",
      "[135]\ttraining's binary_logloss: 0.549257\n",
      "[136]\ttraining's binary_logloss: 0.549077\n",
      "[137]\ttraining's binary_logloss: 0.548909\n",
      "[138]\ttraining's binary_logloss: 0.548716\n",
      "[139]\ttraining's binary_logloss: 0.548535\n",
      "[140]\ttraining's binary_logloss: 0.548379\n",
      "[141]\ttraining's binary_logloss: 0.548204\n",
      "[142]\ttraining's binary_logloss: 0.548029\n",
      "[143]\ttraining's binary_logloss: 0.547921\n",
      "[144]\ttraining's binary_logloss: 0.547805\n",
      "[145]\ttraining's binary_logloss: 0.547622\n",
      "[146]\ttraining's binary_logloss: 0.54747\n",
      "[147]\ttraining's binary_logloss: 0.547319\n",
      "[148]\ttraining's binary_logloss: 0.54717\n",
      "[149]\ttraining's binary_logloss: 0.547\n",
      "[150]\ttraining's binary_logloss: 0.546833\n",
      "[151]\ttraining's binary_logloss: 0.54667\n",
      "[152]\ttraining's binary_logloss: 0.546509\n",
      "[153]\ttraining's binary_logloss: 0.546323\n",
      "[154]\ttraining's binary_logloss: 0.546153\n",
      "[155]\ttraining's binary_logloss: 0.545981\n",
      "[156]\ttraining's binary_logloss: 0.545807\n",
      "[157]\ttraining's binary_logloss: 0.545642\n",
      "[158]\ttraining's binary_logloss: 0.545507\n",
      "[159]\ttraining's binary_logloss: 0.545375\n",
      "[160]\ttraining's binary_logloss: 0.545213\n",
      "[161]\ttraining's binary_logloss: 0.545019\n",
      "[162]\ttraining's binary_logloss: 0.544777\n",
      "[163]\ttraining's binary_logloss: 0.544618\n",
      "[164]\ttraining's binary_logloss: 0.544439\n",
      "[165]\ttraining's binary_logloss: 0.544266\n",
      "[166]\ttraining's binary_logloss: 0.544118\n",
      "[167]\ttraining's binary_logloss: 0.543943\n",
      "[168]\ttraining's binary_logloss: 0.543798\n",
      "[169]\ttraining's binary_logloss: 0.543602\n",
      "[170]\ttraining's binary_logloss: 0.543441\n",
      "[171]\ttraining's binary_logloss: 0.543237\n",
      "[172]\ttraining's binary_logloss: 0.543013\n",
      "[173]\ttraining's binary_logloss: 0.542847\n",
      "[174]\ttraining's binary_logloss: 0.542663\n",
      "[175]\ttraining's binary_logloss: 0.542464\n",
      "[176]\ttraining's binary_logloss: 0.54229\n",
      "[177]\ttraining's binary_logloss: 0.542128\n",
      "[178]\ttraining's binary_logloss: 0.541968\n",
      "[179]\ttraining's binary_logloss: 0.541804\n",
      "[180]\ttraining's binary_logloss: 0.541647\n",
      "[181]\ttraining's binary_logloss: 0.541464\n",
      "[182]\ttraining's binary_logloss: 0.541316\n",
      "[183]\ttraining's binary_logloss: 0.541185\n",
      "[184]\ttraining's binary_logloss: 0.541052\n",
      "[185]\ttraining's binary_logloss: 0.540921\n",
      "[186]\ttraining's binary_logloss: 0.540734\n",
      "[187]\ttraining's binary_logloss: 0.540551\n",
      "[188]\ttraining's binary_logloss: 0.540356\n",
      "[189]\ttraining's binary_logloss: 0.540178\n",
      "[190]\ttraining's binary_logloss: 0.54\n",
      "[191]\ttraining's binary_logloss: 0.539797\n",
      "[192]\ttraining's binary_logloss: 0.539611\n",
      "[193]\ttraining's binary_logloss: 0.539417\n",
      "[194]\ttraining's binary_logloss: 0.539217\n",
      "[195]\ttraining's binary_logloss: 0.53905\n",
      "[196]\ttraining's binary_logloss: 0.538876\n",
      "[197]\ttraining's binary_logloss: 0.538703\n",
      "[198]\ttraining's binary_logloss: 0.53854\n",
      "[199]\ttraining's binary_logloss: 0.538362\n",
      "[200]\ttraining's binary_logloss: 0.538199\n",
      "[201]\ttraining's binary_logloss: 0.538075\n",
      "[202]\ttraining's binary_logloss: 0.537885\n",
      "[203]\ttraining's binary_logloss: 0.537703\n",
      "[204]\ttraining's binary_logloss: 0.537532\n",
      "[205]\ttraining's binary_logloss: 0.537386\n",
      "[206]\ttraining's binary_logloss: 0.537195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[207]\ttraining's binary_logloss: 0.537017\n",
      "[208]\ttraining's binary_logloss: 0.536848\n",
      "[209]\ttraining's binary_logloss: 0.536716\n",
      "[210]\ttraining's binary_logloss: 0.536532\n",
      "[211]\ttraining's binary_logloss: 0.536382\n",
      "[212]\ttraining's binary_logloss: 0.536228\n",
      "[213]\ttraining's binary_logloss: 0.536088\n",
      "[214]\ttraining's binary_logloss: 0.535957\n",
      "[215]\ttraining's binary_logloss: 0.53582\n",
      "[216]\ttraining's binary_logloss: 0.535619\n",
      "[217]\ttraining's binary_logloss: 0.535413\n",
      "[218]\ttraining's binary_logloss: 0.535223\n",
      "[219]\ttraining's binary_logloss: 0.53502\n",
      "[220]\ttraining's binary_logloss: 0.534813\n",
      "[221]\ttraining's binary_logloss: 0.534577\n",
      "[222]\ttraining's binary_logloss: 0.53435\n",
      "[223]\ttraining's binary_logloss: 0.534127\n",
      "[224]\ttraining's binary_logloss: 0.533909\n",
      "[225]\ttraining's binary_logloss: 0.533705\n",
      "[226]\ttraining's binary_logloss: 0.53355\n",
      "[227]\ttraining's binary_logloss: 0.533408\n",
      "[228]\ttraining's binary_logloss: 0.533245\n",
      "[229]\ttraining's binary_logloss: 0.533091\n",
      "[230]\ttraining's binary_logloss: 0.53296\n",
      "[231]\ttraining's binary_logloss: 0.532794\n",
      "[232]\ttraining's binary_logloss: 0.532633\n",
      "[233]\ttraining's binary_logloss: 0.53248\n",
      "[234]\ttraining's binary_logloss: 0.532318\n",
      "[235]\ttraining's binary_logloss: 0.532156\n",
      "[236]\ttraining's binary_logloss: 0.531961\n",
      "[237]\ttraining's binary_logloss: 0.531741\n",
      "[238]\ttraining's binary_logloss: 0.531524\n",
      "[239]\ttraining's binary_logloss: 0.531325\n",
      "[240]\ttraining's binary_logloss: 0.531128\n",
      "[241]\ttraining's binary_logloss: 0.530943\n",
      "[242]\ttraining's binary_logloss: 0.530757\n",
      "[243]\ttraining's binary_logloss: 0.53057\n",
      "[244]\ttraining's binary_logloss: 0.530391\n",
      "[245]\ttraining's binary_logloss: 0.530218\n",
      "[246]\ttraining's binary_logloss: 0.530054\n",
      "[247]\ttraining's binary_logloss: 0.529866\n",
      "[248]\ttraining's binary_logloss: 0.529688\n",
      "[249]\ttraining's binary_logloss: 0.529516\n",
      "[250]\ttraining's binary_logloss: 0.529312\n",
      "[251]\ttraining's binary_logloss: 0.52913\n",
      "[252]\ttraining's binary_logloss: 0.528968\n",
      "[253]\ttraining's binary_logloss: 0.528786\n",
      "[254]\ttraining's binary_logloss: 0.528646\n",
      "[255]\ttraining's binary_logloss: 0.528473\n",
      "[256]\ttraining's binary_logloss: 0.5283\n",
      "[257]\ttraining's binary_logloss: 0.528096\n",
      "[258]\ttraining's binary_logloss: 0.527877\n",
      "[259]\ttraining's binary_logloss: 0.527643\n",
      "[260]\ttraining's binary_logloss: 0.527416\n",
      "[261]\ttraining's binary_logloss: 0.527218\n",
      "[262]\ttraining's binary_logloss: 0.527044\n",
      "[263]\ttraining's binary_logloss: 0.526873\n",
      "[264]\ttraining's binary_logloss: 0.526722\n",
      "[265]\ttraining's binary_logloss: 0.526564\n",
      "[266]\ttraining's binary_logloss: 0.52643\n",
      "[267]\ttraining's binary_logloss: 0.526295\n",
      "[268]\ttraining's binary_logloss: 0.526172\n",
      "[269]\ttraining's binary_logloss: 0.52602\n",
      "[270]\ttraining's binary_logloss: 0.52591\n",
      "[271]\ttraining's binary_logloss: 0.525678\n",
      "[272]\ttraining's binary_logloss: 0.525446\n",
      "[273]\ttraining's binary_logloss: 0.52526\n",
      "[274]\ttraining's binary_logloss: 0.525048\n",
      "[275]\ttraining's binary_logloss: 0.524818\n",
      "[276]\ttraining's binary_logloss: 0.524577\n",
      "[277]\ttraining's binary_logloss: 0.524315\n",
      "[278]\ttraining's binary_logloss: 0.524117\n",
      "[279]\ttraining's binary_logloss: 0.523853\n",
      "[280]\ttraining's binary_logloss: 0.523588\n",
      "[281]\ttraining's binary_logloss: 0.523393\n",
      "[282]\ttraining's binary_logloss: 0.523195\n",
      "[283]\ttraining's binary_logloss: 0.522995\n",
      "[284]\ttraining's binary_logloss: 0.522799\n",
      "[285]\ttraining's binary_logloss: 0.522613\n",
      "[286]\ttraining's binary_logloss: 0.52241\n",
      "[287]\ttraining's binary_logloss: 0.522213\n",
      "[288]\ttraining's binary_logloss: 0.522039\n",
      "[289]\ttraining's binary_logloss: 0.521822\n",
      "[290]\ttraining's binary_logloss: 0.521645\n",
      "[291]\ttraining's binary_logloss: 0.521434\n",
      "[292]\ttraining's binary_logloss: 0.521238\n",
      "[293]\ttraining's binary_logloss: 0.521026\n",
      "[294]\ttraining's binary_logloss: 0.520837\n",
      "[295]\ttraining's binary_logloss: 0.520639\n",
      "[296]\ttraining's binary_logloss: 0.520462\n",
      "[297]\ttraining's binary_logloss: 0.520315\n",
      "[298]\ttraining's binary_logloss: 0.520138\n",
      "[299]\ttraining's binary_logloss: 0.519971\n",
      "[300]\ttraining's binary_logloss: 0.519857\n",
      "[301]\ttraining's binary_logloss: 0.519666\n",
      "[302]\ttraining's binary_logloss: 0.519456\n",
      "[303]\ttraining's binary_logloss: 0.519235\n",
      "[304]\ttraining's binary_logloss: 0.519035\n",
      "[305]\ttraining's binary_logloss: 0.518831\n",
      "[306]\ttraining's binary_logloss: 0.518635\n",
      "[307]\ttraining's binary_logloss: 0.518416\n",
      "[308]\ttraining's binary_logloss: 0.518202\n",
      "[309]\ttraining's binary_logloss: 0.517993\n",
      "[310]\ttraining's binary_logloss: 0.517821\n",
      "[311]\ttraining's binary_logloss: 0.517645\n",
      "[312]\ttraining's binary_logloss: 0.517476\n",
      "[313]\ttraining's binary_logloss: 0.517294\n",
      "[314]\ttraining's binary_logloss: 0.517133\n",
      "[315]\ttraining's binary_logloss: 0.516978\n",
      "[316]\ttraining's binary_logloss: 0.51681\n",
      "[317]\ttraining's binary_logloss: 0.516613\n",
      "[318]\ttraining's binary_logloss: 0.51646\n",
      "[319]\ttraining's binary_logloss: 0.516271\n",
      "[320]\ttraining's binary_logloss: 0.516101\n",
      "[321]\ttraining's binary_logloss: 0.515937\n",
      "[322]\ttraining's binary_logloss: 0.515741\n",
      "[323]\ttraining's binary_logloss: 0.515576\n",
      "[324]\ttraining's binary_logloss: 0.515409\n",
      "[325]\ttraining's binary_logloss: 0.515236\n",
      "[326]\ttraining's binary_logloss: 0.515029\n",
      "[327]\ttraining's binary_logloss: 0.514807\n",
      "[328]\ttraining's binary_logloss: 0.514596\n",
      "[329]\ttraining's binary_logloss: 0.51439\n",
      "[330]\ttraining's binary_logloss: 0.514143\n",
      "[331]\ttraining's binary_logloss: 0.513926\n",
      "[332]\ttraining's binary_logloss: 0.513736\n",
      "[333]\ttraining's binary_logloss: 0.513551\n",
      "[334]\ttraining's binary_logloss: 0.513347\n",
      "[335]\ttraining's binary_logloss: 0.513159\n",
      "[336]\ttraining's binary_logloss: 0.512981\n",
      "[337]\ttraining's binary_logloss: 0.512796\n",
      "[338]\ttraining's binary_logloss: 0.512607\n",
      "[339]\ttraining's binary_logloss: 0.51243\n",
      "[340]\ttraining's binary_logloss: 0.512224\n",
      "[341]\ttraining's binary_logloss: 0.512061\n",
      "[342]\ttraining's binary_logloss: 0.5119\n",
      "[343]\ttraining's binary_logloss: 0.511754\n",
      "[344]\ttraining's binary_logloss: 0.511601\n",
      "[345]\ttraining's binary_logloss: 0.511438\n",
      "[346]\ttraining's binary_logloss: 0.511267\n",
      "[347]\ttraining's binary_logloss: 0.511087\n",
      "[348]\ttraining's binary_logloss: 0.51093\n",
      "[349]\ttraining's binary_logloss: 0.510739\n",
      "[350]\ttraining's binary_logloss: 0.510567\n",
      "[351]\ttraining's binary_logloss: 0.510352\n",
      "[352]\ttraining's binary_logloss: 0.510148\n",
      "[353]\ttraining's binary_logloss: 0.509948\n",
      "[354]\ttraining's binary_logloss: 0.509758\n",
      "[355]\ttraining's binary_logloss: 0.509557\n",
      "[356]\ttraining's binary_logloss: 0.509351\n",
      "[357]\ttraining's binary_logloss: 0.509134\n",
      "[358]\ttraining's binary_logloss: 0.508906\n",
      "[359]\ttraining's binary_logloss: 0.508662\n",
      "[360]\ttraining's binary_logloss: 0.50844\n",
      "[361]\ttraining's binary_logloss: 0.508234\n",
      "[362]\ttraining's binary_logloss: 0.508025\n",
      "[363]\ttraining's binary_logloss: 0.507824\n",
      "[364]\ttraining's binary_logloss: 0.507618\n",
      "[365]\ttraining's binary_logloss: 0.507414\n",
      "[366]\ttraining's binary_logloss: 0.507223\n",
      "[367]\ttraining's binary_logloss: 0.507039\n",
      "[368]\ttraining's binary_logloss: 0.506838\n",
      "[369]\ttraining's binary_logloss: 0.506621\n",
      "[370]\ttraining's binary_logloss: 0.506427\n",
      "[371]\ttraining's binary_logloss: 0.506269\n",
      "[372]\ttraining's binary_logloss: 0.506112\n",
      "[373]\ttraining's binary_logloss: 0.50596\n",
      "[374]\ttraining's binary_logloss: 0.505805\n",
      "[375]\ttraining's binary_logloss: 0.505662\n",
      "[376]\ttraining's binary_logloss: 0.505451\n",
      "[377]\ttraining's binary_logloss: 0.505282\n",
      "[378]\ttraining's binary_logloss: 0.505097\n",
      "[379]\ttraining's binary_logloss: 0.504938\n",
      "[380]\ttraining's binary_logloss: 0.504765\n",
      "[381]\ttraining's binary_logloss: 0.504597\n",
      "[382]\ttraining's binary_logloss: 0.504438\n",
      "[383]\ttraining's binary_logloss: 0.504293\n",
      "[384]\ttraining's binary_logloss: 0.504136\n",
      "[385]\ttraining's binary_logloss: 0.503993\n",
      "[386]\ttraining's binary_logloss: 0.503787\n",
      "[387]\ttraining's binary_logloss: 0.503584\n",
      "[388]\ttraining's binary_logloss: 0.50339\n",
      "[389]\ttraining's binary_logloss: 0.503176\n",
      "[390]\ttraining's binary_logloss: 0.502957\n",
      "[391]\ttraining's binary_logloss: 0.502758\n",
      "[392]\ttraining's binary_logloss: 0.502568\n",
      "[393]\ttraining's binary_logloss: 0.502398\n",
      "[394]\ttraining's binary_logloss: 0.502211\n",
      "[395]\ttraining's binary_logloss: 0.502022\n",
      "[396]\ttraining's binary_logloss: 0.501846\n",
      "[397]\ttraining's binary_logloss: 0.501683\n",
      "[398]\ttraining's binary_logloss: 0.501518\n",
      "[399]\ttraining's binary_logloss: 0.501351\n",
      "[400]\ttraining's binary_logloss: 0.501185\n",
      "[401]\ttraining's binary_logloss: 0.500973\n",
      "[402]\ttraining's binary_logloss: 0.500808\n",
      "[403]\ttraining's binary_logloss: 0.500586\n",
      "[404]\ttraining's binary_logloss: 0.500415\n",
      "[405]\ttraining's binary_logloss: 0.50022\n",
      "[406]\ttraining's binary_logloss: 0.500029\n",
      "[407]\ttraining's binary_logloss: 0.499848\n",
      "[408]\ttraining's binary_logloss: 0.499661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[409]\ttraining's binary_logloss: 0.499483\n",
      "[410]\ttraining's binary_logloss: 0.499292\n",
      "[411]\ttraining's binary_logloss: 0.499054\n",
      "[412]\ttraining's binary_logloss: 0.498797\n",
      "[413]\ttraining's binary_logloss: 0.498576\n",
      "[414]\ttraining's binary_logloss: 0.498363\n",
      "[415]\ttraining's binary_logloss: 0.498161\n",
      "[416]\ttraining's binary_logloss: 0.497951\n",
      "[417]\ttraining's binary_logloss: 0.497739\n",
      "[418]\ttraining's binary_logloss: 0.497526\n",
      "[419]\ttraining's binary_logloss: 0.497324\n",
      "[420]\ttraining's binary_logloss: 0.497071\n",
      "[421]\ttraining's binary_logloss: 0.496927\n",
      "[422]\ttraining's binary_logloss: 0.496758\n",
      "[423]\ttraining's binary_logloss: 0.496609\n",
      "[424]\ttraining's binary_logloss: 0.496447\n",
      "[425]\ttraining's binary_logloss: 0.496308\n",
      "[426]\ttraining's binary_logloss: 0.496154\n",
      "[427]\ttraining's binary_logloss: 0.495948\n",
      "[428]\ttraining's binary_logloss: 0.495767\n",
      "[429]\ttraining's binary_logloss: 0.495572\n",
      "[430]\ttraining's binary_logloss: 0.495367\n",
      "[431]\ttraining's binary_logloss: 0.49514\n",
      "[432]\ttraining's binary_logloss: 0.494918\n",
      "[433]\ttraining's binary_logloss: 0.494687\n",
      "[434]\ttraining's binary_logloss: 0.494481\n",
      "[435]\ttraining's binary_logloss: 0.494262\n",
      "[436]\ttraining's binary_logloss: 0.494012\n",
      "[437]\ttraining's binary_logloss: 0.493766\n",
      "[438]\ttraining's binary_logloss: 0.493547\n",
      "[439]\ttraining's binary_logloss: 0.493303\n",
      "[440]\ttraining's binary_logloss: 0.493074\n",
      "[441]\ttraining's binary_logloss: 0.492869\n",
      "[442]\ttraining's binary_logloss: 0.492682\n",
      "[443]\ttraining's binary_logloss: 0.492488\n",
      "[444]\ttraining's binary_logloss: 0.492298\n",
      "[445]\ttraining's binary_logloss: 0.492099\n",
      "[446]\ttraining's binary_logloss: 0.491856\n",
      "[447]\ttraining's binary_logloss: 0.491622\n",
      "[448]\ttraining's binary_logloss: 0.491427\n",
      "[449]\ttraining's binary_logloss: 0.491206\n",
      "[450]\ttraining's binary_logloss: 0.490984\n",
      "[451]\ttraining's binary_logloss: 0.490754\n",
      "[452]\ttraining's binary_logloss: 0.490531\n",
      "[453]\ttraining's binary_logloss: 0.49034\n",
      "[454]\ttraining's binary_logloss: 0.490126\n",
      "[455]\ttraining's binary_logloss: 0.489963\n",
      "[456]\ttraining's binary_logloss: 0.489772\n",
      "[457]\ttraining's binary_logloss: 0.489587\n",
      "[458]\ttraining's binary_logloss: 0.489425\n",
      "[459]\ttraining's binary_logloss: 0.489242\n",
      "[460]\ttraining's binary_logloss: 0.489065\n",
      "[461]\ttraining's binary_logloss: 0.488817\n",
      "[462]\ttraining's binary_logloss: 0.488593\n",
      "[463]\ttraining's binary_logloss: 0.488339\n",
      "[464]\ttraining's binary_logloss: 0.488127\n",
      "[465]\ttraining's binary_logloss: 0.48786\n",
      "[466]\ttraining's binary_logloss: 0.487706\n",
      "[467]\ttraining's binary_logloss: 0.487509\n",
      "[468]\ttraining's binary_logloss: 0.487312\n",
      "[469]\ttraining's binary_logloss: 0.487136\n",
      "[470]\ttraining's binary_logloss: 0.486926\n",
      "[471]\ttraining's binary_logloss: 0.486752\n",
      "[472]\ttraining's binary_logloss: 0.48661\n",
      "[473]\ttraining's binary_logloss: 0.486441\n",
      "[474]\ttraining's binary_logloss: 0.486272\n",
      "[475]\ttraining's binary_logloss: 0.48609\n",
      "[476]\ttraining's binary_logloss: 0.48591\n",
      "[477]\ttraining's binary_logloss: 0.485731\n",
      "[478]\ttraining's binary_logloss: 0.485506\n",
      "[479]\ttraining's binary_logloss: 0.485286\n",
      "[480]\ttraining's binary_logloss: 0.485113\n",
      "[481]\ttraining's binary_logloss: 0.484961\n",
      "[482]\ttraining's binary_logloss: 0.48475\n",
      "[483]\ttraining's binary_logloss: 0.484556\n",
      "[484]\ttraining's binary_logloss: 0.484358\n",
      "[485]\ttraining's binary_logloss: 0.484196\n",
      "[486]\ttraining's binary_logloss: 0.483964\n",
      "[487]\ttraining's binary_logloss: 0.483722\n",
      "[488]\ttraining's binary_logloss: 0.483488\n",
      "[489]\ttraining's binary_logloss: 0.483271\n",
      "[490]\ttraining's binary_logloss: 0.483052\n",
      "[491]\ttraining's binary_logloss: 0.482871\n",
      "[492]\ttraining's binary_logloss: 0.482685\n",
      "[493]\ttraining's binary_logloss: 0.482496\n",
      "[494]\ttraining's binary_logloss: 0.482314\n",
      "[495]\ttraining's binary_logloss: 0.48214\n",
      "[496]\ttraining's binary_logloss: 0.481896\n",
      "[497]\ttraining's binary_logloss: 0.481686\n",
      "[498]\ttraining's binary_logloss: 0.481453\n",
      "[499]\ttraining's binary_logloss: 0.48125\n",
      "[500]\ttraining's binary_logloss: 0.481041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.612787\n",
      "[2]\ttraining's binary_logloss: 0.611259\n",
      "[3]\ttraining's binary_logloss: 0.609787\n",
      "[4]\ttraining's binary_logloss: 0.608383\n",
      "[5]\ttraining's binary_logloss: 0.606938\n",
      "[6]\ttraining's binary_logloss: 0.605696\n",
      "[7]\ttraining's binary_logloss: 0.604414\n",
      "[8]\ttraining's binary_logloss: 0.603262\n",
      "[9]\ttraining's binary_logloss: 0.602038\n",
      "[10]\ttraining's binary_logloss: 0.600825\n",
      "[11]\ttraining's binary_logloss: 0.599614\n",
      "[12]\ttraining's binary_logloss: 0.598433\n",
      "[13]\ttraining's binary_logloss: 0.597341\n",
      "[14]\ttraining's binary_logloss: 0.596221\n",
      "[15]\ttraining's binary_logloss: 0.595187\n",
      "[16]\ttraining's binary_logloss: 0.594317\n",
      "[17]\ttraining's binary_logloss: 0.593293\n",
      "[18]\ttraining's binary_logloss: 0.592303\n",
      "[19]\ttraining's binary_logloss: 0.591327\n",
      "[20]\ttraining's binary_logloss: 0.590448\n",
      "[21]\ttraining's binary_logloss: 0.589566\n",
      "[22]\ttraining's binary_logloss: 0.588639\n",
      "[23]\ttraining's binary_logloss: 0.587799\n",
      "[24]\ttraining's binary_logloss: 0.587006\n",
      "[25]\ttraining's binary_logloss: 0.586234\n",
      "[26]\ttraining's binary_logloss: 0.585416\n",
      "[27]\ttraining's binary_logloss: 0.584642\n",
      "[28]\ttraining's binary_logloss: 0.583894\n",
      "[29]\ttraining's binary_logloss: 0.58315\n",
      "[30]\ttraining's binary_logloss: 0.582422\n",
      "[31]\ttraining's binary_logloss: 0.581764\n",
      "[32]\ttraining's binary_logloss: 0.58112\n",
      "[33]\ttraining's binary_logloss: 0.580467\n",
      "[34]\ttraining's binary_logloss: 0.579828\n",
      "[35]\ttraining's binary_logloss: 0.579228\n",
      "[36]\ttraining's binary_logloss: 0.578592\n",
      "[37]\ttraining's binary_logloss: 0.577946\n",
      "[38]\ttraining's binary_logloss: 0.577323\n",
      "[39]\ttraining's binary_logloss: 0.576732\n",
      "[40]\ttraining's binary_logloss: 0.576235\n",
      "[41]\ttraining's binary_logloss: 0.575715\n",
      "[42]\ttraining's binary_logloss: 0.575155\n",
      "[43]\ttraining's binary_logloss: 0.57467\n",
      "[44]\ttraining's binary_logloss: 0.574171\n",
      "[45]\ttraining's binary_logloss: 0.573644\n",
      "[46]\ttraining's binary_logloss: 0.573153\n",
      "[47]\ttraining's binary_logloss: 0.572697\n",
      "[48]\ttraining's binary_logloss: 0.572229\n",
      "[49]\ttraining's binary_logloss: 0.571782\n",
      "[50]\ttraining's binary_logloss: 0.57139\n",
      "[51]\ttraining's binary_logloss: 0.570945\n",
      "[52]\ttraining's binary_logloss: 0.570477\n",
      "[53]\ttraining's binary_logloss: 0.570051\n",
      "[54]\ttraining's binary_logloss: 0.569665\n",
      "[55]\ttraining's binary_logloss: 0.569263\n",
      "[56]\ttraining's binary_logloss: 0.568881\n",
      "[57]\ttraining's binary_logloss: 0.568498\n",
      "[58]\ttraining's binary_logloss: 0.568112\n",
      "[59]\ttraining's binary_logloss: 0.567756\n",
      "[60]\ttraining's binary_logloss: 0.567424\n",
      "[61]\ttraining's binary_logloss: 0.567078\n",
      "[62]\ttraining's binary_logloss: 0.566762\n",
      "[63]\ttraining's binary_logloss: 0.566349\n",
      "[64]\ttraining's binary_logloss: 0.56608\n",
      "[65]\ttraining's binary_logloss: 0.565799\n",
      "[66]\ttraining's binary_logloss: 0.565428\n",
      "[67]\ttraining's binary_logloss: 0.565148\n",
      "[68]\ttraining's binary_logloss: 0.564804\n",
      "[69]\ttraining's binary_logloss: 0.564453\n",
      "[70]\ttraining's binary_logloss: 0.564164\n",
      "[71]\ttraining's binary_logloss: 0.563825\n",
      "[72]\ttraining's binary_logloss: 0.563511\n",
      "[73]\ttraining's binary_logloss: 0.563187\n",
      "[74]\ttraining's binary_logloss: 0.562896\n",
      "[75]\ttraining's binary_logloss: 0.562653\n",
      "[76]\ttraining's binary_logloss: 0.562337\n",
      "[77]\ttraining's binary_logloss: 0.562046\n",
      "[78]\ttraining's binary_logloss: 0.561773\n",
      "[79]\ttraining's binary_logloss: 0.561571\n",
      "[80]\ttraining's binary_logloss: 0.561349\n",
      "[81]\ttraining's binary_logloss: 0.561103\n",
      "[82]\ttraining's binary_logloss: 0.560849\n",
      "[83]\ttraining's binary_logloss: 0.560608\n",
      "[84]\ttraining's binary_logloss: 0.560373\n",
      "[85]\ttraining's binary_logloss: 0.560108\n",
      "[86]\ttraining's binary_logloss: 0.559879\n",
      "[87]\ttraining's binary_logloss: 0.559631\n",
      "[88]\ttraining's binary_logloss: 0.55937\n",
      "[89]\ttraining's binary_logloss: 0.559148\n",
      "[90]\ttraining's binary_logloss: 0.558923\n",
      "[91]\ttraining's binary_logloss: 0.558678\n",
      "[92]\ttraining's binary_logloss: 0.558448\n",
      "[93]\ttraining's binary_logloss: 0.55822\n",
      "[94]\ttraining's binary_logloss: 0.557999\n",
      "[95]\ttraining's binary_logloss: 0.557775\n",
      "[96]\ttraining's binary_logloss: 0.557572\n",
      "[97]\ttraining's binary_logloss: 0.557383\n",
      "[98]\ttraining's binary_logloss: 0.557232\n",
      "[99]\ttraining's binary_logloss: 0.557058\n",
      "[100]\ttraining's binary_logloss: 0.55688\n",
      "[101]\ttraining's binary_logloss: 0.556739\n",
      "[102]\ttraining's binary_logloss: 0.556532\n",
      "[103]\ttraining's binary_logloss: 0.556344\n",
      "[104]\ttraining's binary_logloss: 0.556161\n",
      "[105]\ttraining's binary_logloss: 0.555976\n",
      "[106]\ttraining's binary_logloss: 0.555811\n",
      "[107]\ttraining's binary_logloss: 0.555628\n",
      "[108]\ttraining's binary_logloss: 0.555444\n",
      "[109]\ttraining's binary_logloss: 0.555267\n",
      "[110]\ttraining's binary_logloss: 0.555132\n",
      "[111]\ttraining's binary_logloss: 0.554944\n",
      "[112]\ttraining's binary_logloss: 0.55477\n",
      "[113]\ttraining's binary_logloss: 0.554593\n",
      "[114]\ttraining's binary_logloss: 0.554468\n",
      "[115]\ttraining's binary_logloss: 0.554324\n",
      "[116]\ttraining's binary_logloss: 0.554122\n",
      "[117]\ttraining's binary_logloss: 0.553931\n",
      "[118]\ttraining's binary_logloss: 0.553748\n",
      "[119]\ttraining's binary_logloss: 0.553589\n",
      "[120]\ttraining's binary_logloss: 0.553412\n",
      "[121]\ttraining's binary_logloss: 0.553268\n",
      "[122]\ttraining's binary_logloss: 0.553079\n",
      "[123]\ttraining's binary_logloss: 0.552913\n",
      "[124]\ttraining's binary_logloss: 0.552742\n",
      "[125]\ttraining's binary_logloss: 0.552585\n",
      "[126]\ttraining's binary_logloss: 0.55244\n",
      "[127]\ttraining's binary_logloss: 0.55226\n",
      "[128]\ttraining's binary_logloss: 0.552088\n",
      "[129]\ttraining's binary_logloss: 0.551907\n",
      "[130]\ttraining's binary_logloss: 0.551739\n",
      "[131]\ttraining's binary_logloss: 0.551563\n",
      "[132]\ttraining's binary_logloss: 0.551415\n",
      "[133]\ttraining's binary_logloss: 0.551255\n",
      "[134]\ttraining's binary_logloss: 0.551122\n",
      "[135]\ttraining's binary_logloss: 0.550971\n",
      "[136]\ttraining's binary_logloss: 0.550794\n",
      "[137]\ttraining's binary_logloss: 0.550647\n",
      "[138]\ttraining's binary_logloss: 0.550509\n",
      "[139]\ttraining's binary_logloss: 0.550381\n",
      "[140]\ttraining's binary_logloss: 0.550226\n",
      "[141]\ttraining's binary_logloss: 0.55009\n",
      "[142]\ttraining's binary_logloss: 0.549953\n",
      "[143]\ttraining's binary_logloss: 0.549811\n",
      "[144]\ttraining's binary_logloss: 0.54964\n",
      "[145]\ttraining's binary_logloss: 0.549492\n",
      "[146]\ttraining's binary_logloss: 0.549326\n",
      "[147]\ttraining's binary_logloss: 0.549106\n",
      "[148]\ttraining's binary_logloss: 0.548884\n",
      "[149]\ttraining's binary_logloss: 0.548699\n",
      "[150]\ttraining's binary_logloss: 0.548477\n",
      "[151]\ttraining's binary_logloss: 0.548311\n",
      "[152]\ttraining's binary_logloss: 0.548144\n",
      "[153]\ttraining's binary_logloss: 0.547982\n",
      "[154]\ttraining's binary_logloss: 0.547802\n",
      "[155]\ttraining's binary_logloss: 0.547664\n",
      "[156]\ttraining's binary_logloss: 0.547524\n",
      "[157]\ttraining's binary_logloss: 0.5474\n",
      "[158]\ttraining's binary_logloss: 0.547277\n",
      "[159]\ttraining's binary_logloss: 0.547157\n",
      "[160]\ttraining's binary_logloss: 0.547055\n",
      "[161]\ttraining's binary_logloss: 0.546853\n",
      "[162]\ttraining's binary_logloss: 0.54666\n",
      "[163]\ttraining's binary_logloss: 0.546492\n",
      "[164]\ttraining's binary_logloss: 0.546289\n",
      "[165]\ttraining's binary_logloss: 0.546079\n",
      "[166]\ttraining's binary_logloss: 0.545884\n",
      "[167]\ttraining's binary_logloss: 0.545693\n",
      "[168]\ttraining's binary_logloss: 0.545522\n",
      "[169]\ttraining's binary_logloss: 0.545339\n",
      "[170]\ttraining's binary_logloss: 0.545155\n",
      "[171]\ttraining's binary_logloss: 0.545029\n",
      "[172]\ttraining's binary_logloss: 0.544887\n",
      "[173]\ttraining's binary_logloss: 0.544774\n",
      "[174]\ttraining's binary_logloss: 0.544617\n",
      "[175]\ttraining's binary_logloss: 0.544482\n",
      "[176]\ttraining's binary_logloss: 0.544331\n",
      "[177]\ttraining's binary_logloss: 0.544186\n",
      "[178]\ttraining's binary_logloss: 0.54405\n",
      "[179]\ttraining's binary_logloss: 0.543912\n",
      "[180]\ttraining's binary_logloss: 0.543782\n",
      "[181]\ttraining's binary_logloss: 0.543677\n",
      "[182]\ttraining's binary_logloss: 0.543543\n",
      "[183]\ttraining's binary_logloss: 0.543389\n",
      "[184]\ttraining's binary_logloss: 0.543234\n",
      "[185]\ttraining's binary_logloss: 0.543098\n",
      "[186]\ttraining's binary_logloss: 0.542957\n",
      "[187]\ttraining's binary_logloss: 0.54281\n",
      "[188]\ttraining's binary_logloss: 0.54265\n",
      "[189]\ttraining's binary_logloss: 0.542516\n",
      "[190]\ttraining's binary_logloss: 0.54238\n",
      "[191]\ttraining's binary_logloss: 0.542219\n",
      "[192]\ttraining's binary_logloss: 0.542062\n",
      "[193]\ttraining's binary_logloss: 0.541885\n",
      "[194]\ttraining's binary_logloss: 0.541746\n",
      "[195]\ttraining's binary_logloss: 0.541576\n",
      "[196]\ttraining's binary_logloss: 0.541422\n",
      "[197]\ttraining's binary_logloss: 0.541289\n",
      "[198]\ttraining's binary_logloss: 0.541136\n",
      "[199]\ttraining's binary_logloss: 0.541009\n",
      "[200]\ttraining's binary_logloss: 0.540874\n",
      "[201]\ttraining's binary_logloss: 0.540707\n",
      "[202]\ttraining's binary_logloss: 0.540542\n",
      "[203]\ttraining's binary_logloss: 0.540372\n",
      "[204]\ttraining's binary_logloss: 0.540199\n",
      "[205]\ttraining's binary_logloss: 0.540033\n",
      "[206]\ttraining's binary_logloss: 0.539907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[207]\ttraining's binary_logloss: 0.53977\n",
      "[208]\ttraining's binary_logloss: 0.539629\n",
      "[209]\ttraining's binary_logloss: 0.53948\n",
      "[210]\ttraining's binary_logloss: 0.539348\n",
      "[211]\ttraining's binary_logloss: 0.539193\n",
      "[212]\ttraining's binary_logloss: 0.539028\n",
      "[213]\ttraining's binary_logloss: 0.538868\n",
      "[214]\ttraining's binary_logloss: 0.538739\n",
      "[215]\ttraining's binary_logloss: 0.538606\n",
      "[216]\ttraining's binary_logloss: 0.538428\n",
      "[217]\ttraining's binary_logloss: 0.538222\n",
      "[218]\ttraining's binary_logloss: 0.538034\n",
      "[219]\ttraining's binary_logloss: 0.53787\n",
      "[220]\ttraining's binary_logloss: 0.537684\n",
      "[221]\ttraining's binary_logloss: 0.537493\n",
      "[222]\ttraining's binary_logloss: 0.53732\n",
      "[223]\ttraining's binary_logloss: 0.537143\n",
      "[224]\ttraining's binary_logloss: 0.536966\n",
      "[225]\ttraining's binary_logloss: 0.536788\n",
      "[226]\ttraining's binary_logloss: 0.536594\n",
      "[227]\ttraining's binary_logloss: 0.536422\n",
      "[228]\ttraining's binary_logloss: 0.536239\n",
      "[229]\ttraining's binary_logloss: 0.536058\n",
      "[230]\ttraining's binary_logloss: 0.535864\n",
      "[231]\ttraining's binary_logloss: 0.535707\n",
      "[232]\ttraining's binary_logloss: 0.535558\n",
      "[233]\ttraining's binary_logloss: 0.535407\n",
      "[234]\ttraining's binary_logloss: 0.535254\n",
      "[235]\ttraining's binary_logloss: 0.535085\n",
      "[236]\ttraining's binary_logloss: 0.534936\n",
      "[237]\ttraining's binary_logloss: 0.534791\n",
      "[238]\ttraining's binary_logloss: 0.534625\n",
      "[239]\ttraining's binary_logloss: 0.534478\n",
      "[240]\ttraining's binary_logloss: 0.534307\n",
      "[241]\ttraining's binary_logloss: 0.534094\n",
      "[242]\ttraining's binary_logloss: 0.533895\n",
      "[243]\ttraining's binary_logloss: 0.533694\n",
      "[244]\ttraining's binary_logloss: 0.533457\n",
      "[245]\ttraining's binary_logloss: 0.533262\n",
      "[246]\ttraining's binary_logloss: 0.532996\n",
      "[247]\ttraining's binary_logloss: 0.532726\n",
      "[248]\ttraining's binary_logloss: 0.532487\n",
      "[249]\ttraining's binary_logloss: 0.532299\n",
      "[250]\ttraining's binary_logloss: 0.532103\n",
      "[251]\ttraining's binary_logloss: 0.531962\n",
      "[252]\ttraining's binary_logloss: 0.531796\n",
      "[253]\ttraining's binary_logloss: 0.531638\n",
      "[254]\ttraining's binary_logloss: 0.531464\n",
      "[255]\ttraining's binary_logloss: 0.531303\n",
      "[256]\ttraining's binary_logloss: 0.531124\n",
      "[257]\ttraining's binary_logloss: 0.530952\n",
      "[258]\ttraining's binary_logloss: 0.530747\n",
      "[259]\ttraining's binary_logloss: 0.530552\n",
      "[260]\ttraining's binary_logloss: 0.530365\n",
      "[261]\ttraining's binary_logloss: 0.530181\n",
      "[262]\ttraining's binary_logloss: 0.529993\n",
      "[263]\ttraining's binary_logloss: 0.529793\n",
      "[264]\ttraining's binary_logloss: 0.529646\n",
      "[265]\ttraining's binary_logloss: 0.529493\n",
      "[266]\ttraining's binary_logloss: 0.529324\n",
      "[267]\ttraining's binary_logloss: 0.529148\n",
      "[268]\ttraining's binary_logloss: 0.528993\n",
      "[269]\ttraining's binary_logloss: 0.528832\n",
      "[270]\ttraining's binary_logloss: 0.52867\n",
      "[271]\ttraining's binary_logloss: 0.528457\n",
      "[272]\ttraining's binary_logloss: 0.528195\n",
      "[273]\ttraining's binary_logloss: 0.527967\n",
      "[274]\ttraining's binary_logloss: 0.52773\n",
      "[275]\ttraining's binary_logloss: 0.52751\n",
      "[276]\ttraining's binary_logloss: 0.52736\n",
      "[277]\ttraining's binary_logloss: 0.527152\n",
      "[278]\ttraining's binary_logloss: 0.526962\n",
      "[279]\ttraining's binary_logloss: 0.526751\n",
      "[280]\ttraining's binary_logloss: 0.52657\n",
      "[281]\ttraining's binary_logloss: 0.526374\n",
      "[282]\ttraining's binary_logloss: 0.526169\n",
      "[283]\ttraining's binary_logloss: 0.525963\n",
      "[284]\ttraining's binary_logloss: 0.525779\n",
      "[285]\ttraining's binary_logloss: 0.525559\n",
      "[286]\ttraining's binary_logloss: 0.525339\n",
      "[287]\ttraining's binary_logloss: 0.525132\n",
      "[288]\ttraining's binary_logloss: 0.524941\n",
      "[289]\ttraining's binary_logloss: 0.524737\n",
      "[290]\ttraining's binary_logloss: 0.524489\n",
      "[291]\ttraining's binary_logloss: 0.524266\n",
      "[292]\ttraining's binary_logloss: 0.524043\n",
      "[293]\ttraining's binary_logloss: 0.523807\n",
      "[294]\ttraining's binary_logloss: 0.523587\n",
      "[295]\ttraining's binary_logloss: 0.523371\n",
      "[296]\ttraining's binary_logloss: 0.523172\n",
      "[297]\ttraining's binary_logloss: 0.522972\n",
      "[298]\ttraining's binary_logloss: 0.522766\n",
      "[299]\ttraining's binary_logloss: 0.522557\n",
      "[300]\ttraining's binary_logloss: 0.522354\n",
      "[301]\ttraining's binary_logloss: 0.522157\n",
      "[302]\ttraining's binary_logloss: 0.521941\n",
      "[303]\ttraining's binary_logloss: 0.521734\n",
      "[304]\ttraining's binary_logloss: 0.521535\n",
      "[305]\ttraining's binary_logloss: 0.521346\n",
      "[306]\ttraining's binary_logloss: 0.521181\n",
      "[307]\ttraining's binary_logloss: 0.521027\n",
      "[308]\ttraining's binary_logloss: 0.520871\n",
      "[309]\ttraining's binary_logloss: 0.520706\n",
      "[310]\ttraining's binary_logloss: 0.520558\n",
      "[311]\ttraining's binary_logloss: 0.520328\n",
      "[312]\ttraining's binary_logloss: 0.520104\n",
      "[313]\ttraining's binary_logloss: 0.519888\n",
      "[314]\ttraining's binary_logloss: 0.51967\n",
      "[315]\ttraining's binary_logloss: 0.519469\n",
      "[316]\ttraining's binary_logloss: 0.519246\n",
      "[317]\ttraining's binary_logloss: 0.519023\n",
      "[318]\ttraining's binary_logloss: 0.51884\n",
      "[319]\ttraining's binary_logloss: 0.518675\n",
      "[320]\ttraining's binary_logloss: 0.518494\n",
      "[321]\ttraining's binary_logloss: 0.518276\n",
      "[322]\ttraining's binary_logloss: 0.518087\n",
      "[323]\ttraining's binary_logloss: 0.517891\n",
      "[324]\ttraining's binary_logloss: 0.517737\n",
      "[325]\ttraining's binary_logloss: 0.517559\n",
      "[326]\ttraining's binary_logloss: 0.517355\n",
      "[327]\ttraining's binary_logloss: 0.517177\n",
      "[328]\ttraining's binary_logloss: 0.516994\n",
      "[329]\ttraining's binary_logloss: 0.516772\n",
      "[330]\ttraining's binary_logloss: 0.516589\n",
      "[331]\ttraining's binary_logloss: 0.51641\n",
      "[332]\ttraining's binary_logloss: 0.516235\n",
      "[333]\ttraining's binary_logloss: 0.516063\n",
      "[334]\ttraining's binary_logloss: 0.51589\n",
      "[335]\ttraining's binary_logloss: 0.515714\n",
      "[336]\ttraining's binary_logloss: 0.515481\n",
      "[337]\ttraining's binary_logloss: 0.515258\n",
      "[338]\ttraining's binary_logloss: 0.515053\n",
      "[339]\ttraining's binary_logloss: 0.514825\n",
      "[340]\ttraining's binary_logloss: 0.514621\n",
      "[341]\ttraining's binary_logloss: 0.514482\n",
      "[342]\ttraining's binary_logloss: 0.514324\n",
      "[343]\ttraining's binary_logloss: 0.514174\n",
      "[344]\ttraining's binary_logloss: 0.514025\n",
      "[345]\ttraining's binary_logloss: 0.513885\n",
      "[346]\ttraining's binary_logloss: 0.513733\n",
      "[347]\ttraining's binary_logloss: 0.513583\n",
      "[348]\ttraining's binary_logloss: 0.513415\n",
      "[349]\ttraining's binary_logloss: 0.513249\n",
      "[350]\ttraining's binary_logloss: 0.513097\n",
      "[351]\ttraining's binary_logloss: 0.512851\n",
      "[352]\ttraining's binary_logloss: 0.512626\n",
      "[353]\ttraining's binary_logloss: 0.512399\n",
      "[354]\ttraining's binary_logloss: 0.512159\n",
      "[355]\ttraining's binary_logloss: 0.511945\n",
      "[356]\ttraining's binary_logloss: 0.511718\n",
      "[357]\ttraining's binary_logloss: 0.511531\n",
      "[358]\ttraining's binary_logloss: 0.511322\n",
      "[359]\ttraining's binary_logloss: 0.511118\n",
      "[360]\ttraining's binary_logloss: 0.510882\n",
      "[361]\ttraining's binary_logloss: 0.510628\n",
      "[362]\ttraining's binary_logloss: 0.510422\n",
      "[363]\ttraining's binary_logloss: 0.510196\n",
      "[364]\ttraining's binary_logloss: 0.509971\n",
      "[365]\ttraining's binary_logloss: 0.509758\n",
      "[366]\ttraining's binary_logloss: 0.509549\n",
      "[367]\ttraining's binary_logloss: 0.509355\n",
      "[368]\ttraining's binary_logloss: 0.509158\n",
      "[369]\ttraining's binary_logloss: 0.508948\n",
      "[370]\ttraining's binary_logloss: 0.508759\n",
      "[371]\ttraining's binary_logloss: 0.5086\n",
      "[372]\ttraining's binary_logloss: 0.508434\n",
      "[373]\ttraining's binary_logloss: 0.508236\n",
      "[374]\ttraining's binary_logloss: 0.50803\n",
      "[375]\ttraining's binary_logloss: 0.507827\n",
      "[376]\ttraining's binary_logloss: 0.507622\n",
      "[377]\ttraining's binary_logloss: 0.50742\n",
      "[378]\ttraining's binary_logloss: 0.507237\n",
      "[379]\ttraining's binary_logloss: 0.507043\n",
      "[380]\ttraining's binary_logloss: 0.506853\n",
      "[381]\ttraining's binary_logloss: 0.506715\n",
      "[382]\ttraining's binary_logloss: 0.506535\n",
      "[383]\ttraining's binary_logloss: 0.50638\n",
      "[384]\ttraining's binary_logloss: 0.50623\n",
      "[385]\ttraining's binary_logloss: 0.506052\n",
      "[386]\ttraining's binary_logloss: 0.505864\n",
      "[387]\ttraining's binary_logloss: 0.505631\n",
      "[388]\ttraining's binary_logloss: 0.505436\n",
      "[389]\ttraining's binary_logloss: 0.505231\n",
      "[390]\ttraining's binary_logloss: 0.505039\n",
      "[391]\ttraining's binary_logloss: 0.504811\n",
      "[392]\ttraining's binary_logloss: 0.504614\n",
      "[393]\ttraining's binary_logloss: 0.504403\n",
      "[394]\ttraining's binary_logloss: 0.504222\n",
      "[395]\ttraining's binary_logloss: 0.504044\n",
      "[396]\ttraining's binary_logloss: 0.503894\n",
      "[397]\ttraining's binary_logloss: 0.503739\n",
      "[398]\ttraining's binary_logloss: 0.503595\n",
      "[399]\ttraining's binary_logloss: 0.50346\n",
      "[400]\ttraining's binary_logloss: 0.503314\n",
      "[401]\ttraining's binary_logloss: 0.503094\n",
      "[402]\ttraining's binary_logloss: 0.502867\n",
      "[403]\ttraining's binary_logloss: 0.502671\n",
      "[404]\ttraining's binary_logloss: 0.502427\n",
      "[405]\ttraining's binary_logloss: 0.502192\n",
      "[406]\ttraining's binary_logloss: 0.501976\n",
      "[407]\ttraining's binary_logloss: 0.501766\n",
      "[408]\ttraining's binary_logloss: 0.501563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[409]\ttraining's binary_logloss: 0.501361\n",
      "[410]\ttraining's binary_logloss: 0.501159\n",
      "[411]\ttraining's binary_logloss: 0.500933\n",
      "[412]\ttraining's binary_logloss: 0.500722\n",
      "[413]\ttraining's binary_logloss: 0.500524\n",
      "[414]\ttraining's binary_logloss: 0.500321\n",
      "[415]\ttraining's binary_logloss: 0.50012\n",
      "[416]\ttraining's binary_logloss: 0.499903\n",
      "[417]\ttraining's binary_logloss: 0.499707\n",
      "[418]\ttraining's binary_logloss: 0.499518\n",
      "[419]\ttraining's binary_logloss: 0.499299\n",
      "[420]\ttraining's binary_logloss: 0.499127\n",
      "[421]\ttraining's binary_logloss: 0.498986\n",
      "[422]\ttraining's binary_logloss: 0.498849\n",
      "[423]\ttraining's binary_logloss: 0.498716\n",
      "[424]\ttraining's binary_logloss: 0.498557\n",
      "[425]\ttraining's binary_logloss: 0.498401\n",
      "[426]\ttraining's binary_logloss: 0.498217\n",
      "[427]\ttraining's binary_logloss: 0.498044\n",
      "[428]\ttraining's binary_logloss: 0.497866\n",
      "[429]\ttraining's binary_logloss: 0.497683\n",
      "[430]\ttraining's binary_logloss: 0.497503\n",
      "[431]\ttraining's binary_logloss: 0.497285\n",
      "[432]\ttraining's binary_logloss: 0.497051\n",
      "[433]\ttraining's binary_logloss: 0.496817\n",
      "[434]\ttraining's binary_logloss: 0.496591\n",
      "[435]\ttraining's binary_logloss: 0.496332\n",
      "[436]\ttraining's binary_logloss: 0.496163\n",
      "[437]\ttraining's binary_logloss: 0.495995\n",
      "[438]\ttraining's binary_logloss: 0.495815\n",
      "[439]\ttraining's binary_logloss: 0.495644\n",
      "[440]\ttraining's binary_logloss: 0.495479\n",
      "[441]\ttraining's binary_logloss: 0.495253\n",
      "[442]\ttraining's binary_logloss: 0.495052\n",
      "[443]\ttraining's binary_logloss: 0.494853\n",
      "[444]\ttraining's binary_logloss: 0.494655\n",
      "[445]\ttraining's binary_logloss: 0.494459\n",
      "[446]\ttraining's binary_logloss: 0.494245\n",
      "[447]\ttraining's binary_logloss: 0.494032\n",
      "[448]\ttraining's binary_logloss: 0.493818\n",
      "[449]\ttraining's binary_logloss: 0.493616\n",
      "[450]\ttraining's binary_logloss: 0.493412\n",
      "[451]\ttraining's binary_logloss: 0.493232\n",
      "[452]\ttraining's binary_logloss: 0.49305\n",
      "[453]\ttraining's binary_logloss: 0.492873\n",
      "[454]\ttraining's binary_logloss: 0.49268\n",
      "[455]\ttraining's binary_logloss: 0.492496\n",
      "[456]\ttraining's binary_logloss: 0.492312\n",
      "[457]\ttraining's binary_logloss: 0.492103\n",
      "[458]\ttraining's binary_logloss: 0.491923\n",
      "[459]\ttraining's binary_logloss: 0.49175\n",
      "[460]\ttraining's binary_logloss: 0.491549\n",
      "[461]\ttraining's binary_logloss: 0.49137\n",
      "[462]\ttraining's binary_logloss: 0.491174\n",
      "[463]\ttraining's binary_logloss: 0.490954\n",
      "[464]\ttraining's binary_logloss: 0.490758\n",
      "[465]\ttraining's binary_logloss: 0.490537\n",
      "[466]\ttraining's binary_logloss: 0.490344\n",
      "[467]\ttraining's binary_logloss: 0.490145\n",
      "[468]\ttraining's binary_logloss: 0.489954\n",
      "[469]\ttraining's binary_logloss: 0.489768\n",
      "[470]\ttraining's binary_logloss: 0.489585\n",
      "[471]\ttraining's binary_logloss: 0.489427\n",
      "[472]\ttraining's binary_logloss: 0.48928\n",
      "[473]\ttraining's binary_logloss: 0.489119\n",
      "[474]\ttraining's binary_logloss: 0.488977\n",
      "[475]\ttraining's binary_logloss: 0.488829\n",
      "[476]\ttraining's binary_logloss: 0.488591\n",
      "[477]\ttraining's binary_logloss: 0.488361\n",
      "[478]\ttraining's binary_logloss: 0.488138\n",
      "[479]\ttraining's binary_logloss: 0.487923\n",
      "[480]\ttraining's binary_logloss: 0.48771\n",
      "[481]\ttraining's binary_logloss: 0.48751\n",
      "[482]\ttraining's binary_logloss: 0.487328\n",
      "[483]\ttraining's binary_logloss: 0.487129\n",
      "[484]\ttraining's binary_logloss: 0.486952\n",
      "[485]\ttraining's binary_logloss: 0.486788\n",
      "[486]\ttraining's binary_logloss: 0.486573\n",
      "[487]\ttraining's binary_logloss: 0.486347\n",
      "[488]\ttraining's binary_logloss: 0.486133\n",
      "[489]\ttraining's binary_logloss: 0.4859\n",
      "[490]\ttraining's binary_logloss: 0.485676\n",
      "[491]\ttraining's binary_logloss: 0.485492\n",
      "[492]\ttraining's binary_logloss: 0.485313\n",
      "[493]\ttraining's binary_logloss: 0.485122\n",
      "[494]\ttraining's binary_logloss: 0.484943\n",
      "[495]\ttraining's binary_logloss: 0.484756\n",
      "[496]\ttraining's binary_logloss: 0.484564\n",
      "[497]\ttraining's binary_logloss: 0.484333\n",
      "[498]\ttraining's binary_logloss: 0.484157\n",
      "[499]\ttraining's binary_logloss: 0.483972\n",
      "[500]\ttraining's binary_logloss: 0.483804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.617264\n",
      "[2]\ttraining's binary_logloss: 0.615832\n",
      "[3]\ttraining's binary_logloss: 0.614481\n",
      "[4]\ttraining's binary_logloss: 0.613073\n",
      "[5]\ttraining's binary_logloss: 0.611711\n",
      "[6]\ttraining's binary_logloss: 0.61036\n",
      "[7]\ttraining's binary_logloss: 0.609056\n",
      "[8]\ttraining's binary_logloss: 0.60779\n",
      "[9]\ttraining's binary_logloss: 0.606572\n",
      "[10]\ttraining's binary_logloss: 0.605392\n",
      "[11]\ttraining's binary_logloss: 0.604178\n",
      "[12]\ttraining's binary_logloss: 0.603032\n",
      "[13]\ttraining's binary_logloss: 0.601871\n",
      "[14]\ttraining's binary_logloss: 0.600763\n",
      "[15]\ttraining's binary_logloss: 0.599663\n",
      "[16]\ttraining's binary_logloss: 0.598658\n",
      "[17]\ttraining's binary_logloss: 0.597652\n",
      "[18]\ttraining's binary_logloss: 0.59674\n",
      "[19]\ttraining's binary_logloss: 0.595749\n",
      "[20]\ttraining's binary_logloss: 0.59485\n",
      "[21]\ttraining's binary_logloss: 0.593859\n",
      "[22]\ttraining's binary_logloss: 0.593013\n",
      "[23]\ttraining's binary_logloss: 0.592063\n",
      "[24]\ttraining's binary_logloss: 0.591164\n",
      "[25]\ttraining's binary_logloss: 0.590286\n",
      "[26]\ttraining's binary_logloss: 0.589504\n",
      "[27]\ttraining's binary_logloss: 0.588738\n",
      "[28]\ttraining's binary_logloss: 0.588019\n",
      "[29]\ttraining's binary_logloss: 0.587375\n",
      "[30]\ttraining's binary_logloss: 0.58668\n",
      "[31]\ttraining's binary_logloss: 0.585975\n",
      "[32]\ttraining's binary_logloss: 0.585256\n",
      "[33]\ttraining's binary_logloss: 0.584614\n",
      "[34]\ttraining's binary_logloss: 0.583975\n",
      "[35]\ttraining's binary_logloss: 0.583299\n",
      "[36]\ttraining's binary_logloss: 0.582663\n",
      "[37]\ttraining's binary_logloss: 0.582079\n",
      "[38]\ttraining's binary_logloss: 0.581514\n",
      "[39]\ttraining's binary_logloss: 0.580932\n",
      "[40]\ttraining's binary_logloss: 0.580388\n",
      "[41]\ttraining's binary_logloss: 0.579901\n",
      "[42]\ttraining's binary_logloss: 0.57939\n",
      "[43]\ttraining's binary_logloss: 0.578832\n",
      "[44]\ttraining's binary_logloss: 0.578317\n",
      "[45]\ttraining's binary_logloss: 0.577866\n",
      "[46]\ttraining's binary_logloss: 0.577358\n",
      "[47]\ttraining's binary_logloss: 0.576882\n",
      "[48]\ttraining's binary_logloss: 0.576388\n",
      "[49]\ttraining's binary_logloss: 0.575947\n",
      "[50]\ttraining's binary_logloss: 0.575513\n",
      "[51]\ttraining's binary_logloss: 0.57507\n",
      "[52]\ttraining's binary_logloss: 0.574632\n",
      "[53]\ttraining's binary_logloss: 0.574182\n",
      "[54]\ttraining's binary_logloss: 0.573794\n",
      "[55]\ttraining's binary_logloss: 0.57339\n",
      "[56]\ttraining's binary_logloss: 0.573056\n",
      "[57]\ttraining's binary_logloss: 0.57269\n",
      "[58]\ttraining's binary_logloss: 0.572351\n",
      "[59]\ttraining's binary_logloss: 0.572026\n",
      "[60]\ttraining's binary_logloss: 0.571722\n",
      "[61]\ttraining's binary_logloss: 0.571401\n",
      "[62]\ttraining's binary_logloss: 0.571104\n",
      "[63]\ttraining's binary_logloss: 0.570793\n",
      "[64]\ttraining's binary_logloss: 0.570474\n",
      "[65]\ttraining's binary_logloss: 0.570122\n",
      "[66]\ttraining's binary_logloss: 0.569755\n",
      "[67]\ttraining's binary_logloss: 0.569435\n",
      "[68]\ttraining's binary_logloss: 0.569087\n",
      "[69]\ttraining's binary_logloss: 0.568753\n",
      "[70]\ttraining's binary_logloss: 0.568434\n",
      "[71]\ttraining's binary_logloss: 0.568159\n",
      "[72]\ttraining's binary_logloss: 0.567814\n",
      "[73]\ttraining's binary_logloss: 0.567513\n",
      "[74]\ttraining's binary_logloss: 0.567214\n",
      "[75]\ttraining's binary_logloss: 0.566907\n",
      "[76]\ttraining's binary_logloss: 0.566574\n",
      "[77]\ttraining's binary_logloss: 0.566253\n",
      "[78]\ttraining's binary_logloss: 0.566019\n",
      "[79]\ttraining's binary_logloss: 0.565745\n",
      "[80]\ttraining's binary_logloss: 0.565506\n",
      "[81]\ttraining's binary_logloss: 0.565278\n",
      "[82]\ttraining's binary_logloss: 0.564973\n",
      "[83]\ttraining's binary_logloss: 0.564736\n",
      "[84]\ttraining's binary_logloss: 0.564481\n",
      "[85]\ttraining's binary_logloss: 0.564242\n",
      "[86]\ttraining's binary_logloss: 0.564037\n",
      "[87]\ttraining's binary_logloss: 0.563824\n",
      "[88]\ttraining's binary_logloss: 0.563633\n",
      "[89]\ttraining's binary_logloss: 0.563419\n",
      "[90]\ttraining's binary_logloss: 0.563196\n",
      "[91]\ttraining's binary_logloss: 0.562912\n",
      "[92]\ttraining's binary_logloss: 0.562654\n",
      "[93]\ttraining's binary_logloss: 0.56238\n",
      "[94]\ttraining's binary_logloss: 0.562188\n",
      "[95]\ttraining's binary_logloss: 0.561939\n",
      "[96]\ttraining's binary_logloss: 0.56174\n",
      "[97]\ttraining's binary_logloss: 0.561562\n",
      "[98]\ttraining's binary_logloss: 0.561366\n",
      "[99]\ttraining's binary_logloss: 0.561124\n",
      "[100]\ttraining's binary_logloss: 0.560982\n",
      "[101]\ttraining's binary_logloss: 0.560798\n",
      "[102]\ttraining's binary_logloss: 0.560621\n",
      "[103]\ttraining's binary_logloss: 0.560422\n",
      "[104]\ttraining's binary_logloss: 0.560252\n",
      "[105]\ttraining's binary_logloss: 0.560077\n",
      "[106]\ttraining's binary_logloss: 0.559852\n",
      "[107]\ttraining's binary_logloss: 0.559642\n",
      "[108]\ttraining's binary_logloss: 0.559446\n",
      "[109]\ttraining's binary_logloss: 0.559249\n",
      "[110]\ttraining's binary_logloss: 0.559041\n",
      "[111]\ttraining's binary_logloss: 0.558872\n",
      "[112]\ttraining's binary_logloss: 0.558717\n",
      "[113]\ttraining's binary_logloss: 0.558532\n",
      "[114]\ttraining's binary_logloss: 0.558395\n",
      "[115]\ttraining's binary_logloss: 0.558236\n",
      "[116]\ttraining's binary_logloss: 0.558015\n",
      "[117]\ttraining's binary_logloss: 0.557828\n",
      "[118]\ttraining's binary_logloss: 0.557624\n",
      "[119]\ttraining's binary_logloss: 0.557418\n",
      "[120]\ttraining's binary_logloss: 0.557226\n",
      "[121]\ttraining's binary_logloss: 0.557066\n",
      "[122]\ttraining's binary_logloss: 0.55691\n",
      "[123]\ttraining's binary_logloss: 0.556756\n",
      "[124]\ttraining's binary_logloss: 0.556624\n",
      "[125]\ttraining's binary_logloss: 0.556433\n",
      "[126]\ttraining's binary_logloss: 0.556285\n",
      "[127]\ttraining's binary_logloss: 0.556156\n",
      "[128]\ttraining's binary_logloss: 0.555996\n",
      "[129]\ttraining's binary_logloss: 0.555834\n",
      "[130]\ttraining's binary_logloss: 0.555665\n",
      "[131]\ttraining's binary_logloss: 0.555477\n",
      "[132]\ttraining's binary_logloss: 0.555308\n",
      "[133]\ttraining's binary_logloss: 0.555126\n",
      "[134]\ttraining's binary_logloss: 0.554967\n",
      "[135]\ttraining's binary_logloss: 0.554796\n",
      "[136]\ttraining's binary_logloss: 0.554632\n",
      "[137]\ttraining's binary_logloss: 0.554479\n",
      "[138]\ttraining's binary_logloss: 0.55429\n",
      "[139]\ttraining's binary_logloss: 0.554141\n",
      "[140]\ttraining's binary_logloss: 0.55396\n",
      "[141]\ttraining's binary_logloss: 0.553752\n",
      "[142]\ttraining's binary_logloss: 0.553575\n",
      "[143]\ttraining's binary_logloss: 0.55338\n",
      "[144]\ttraining's binary_logloss: 0.553206\n",
      "[145]\ttraining's binary_logloss: 0.553014\n",
      "[146]\ttraining's binary_logloss: 0.552815\n",
      "[147]\ttraining's binary_logloss: 0.552615\n",
      "[148]\ttraining's binary_logloss: 0.552418\n",
      "[149]\ttraining's binary_logloss: 0.552192\n",
      "[150]\ttraining's binary_logloss: 0.552009\n",
      "[151]\ttraining's binary_logloss: 0.551864\n",
      "[152]\ttraining's binary_logloss: 0.551736\n",
      "[153]\ttraining's binary_logloss: 0.551607\n",
      "[154]\ttraining's binary_logloss: 0.551477\n",
      "[155]\ttraining's binary_logloss: 0.551351\n",
      "[156]\ttraining's binary_logloss: 0.551175\n",
      "[157]\ttraining's binary_logloss: 0.550962\n",
      "[158]\ttraining's binary_logloss: 0.550786\n",
      "[159]\ttraining's binary_logloss: 0.550616\n",
      "[160]\ttraining's binary_logloss: 0.550431\n",
      "[161]\ttraining's binary_logloss: 0.550262\n",
      "[162]\ttraining's binary_logloss: 0.550116\n",
      "[163]\ttraining's binary_logloss: 0.549947\n",
      "[164]\ttraining's binary_logloss: 0.549792\n",
      "[165]\ttraining's binary_logloss: 0.549629\n",
      "[166]\ttraining's binary_logloss: 0.549404\n",
      "[167]\ttraining's binary_logloss: 0.549194\n",
      "[168]\ttraining's binary_logloss: 0.549009\n",
      "[169]\ttraining's binary_logloss: 0.54882\n",
      "[170]\ttraining's binary_logloss: 0.548629\n",
      "[171]\ttraining's binary_logloss: 0.548483\n",
      "[172]\ttraining's binary_logloss: 0.548329\n",
      "[173]\ttraining's binary_logloss: 0.548199\n",
      "[174]\ttraining's binary_logloss: 0.548039\n",
      "[175]\ttraining's binary_logloss: 0.547903\n",
      "[176]\ttraining's binary_logloss: 0.547754\n",
      "[177]\ttraining's binary_logloss: 0.547583\n",
      "[178]\ttraining's binary_logloss: 0.547408\n",
      "[179]\ttraining's binary_logloss: 0.547238\n",
      "[180]\ttraining's binary_logloss: 0.54706\n",
      "[181]\ttraining's binary_logloss: 0.546888\n",
      "[182]\ttraining's binary_logloss: 0.546685\n",
      "[183]\ttraining's binary_logloss: 0.546492\n",
      "[184]\ttraining's binary_logloss: 0.54634\n",
      "[185]\ttraining's binary_logloss: 0.546175\n",
      "[186]\ttraining's binary_logloss: 0.546035\n",
      "[187]\ttraining's binary_logloss: 0.54589\n",
      "[188]\ttraining's binary_logloss: 0.545745\n",
      "[189]\ttraining's binary_logloss: 0.54557\n",
      "[190]\ttraining's binary_logloss: 0.545416\n",
      "[191]\ttraining's binary_logloss: 0.545247\n",
      "[192]\ttraining's binary_logloss: 0.545084\n",
      "[193]\ttraining's binary_logloss: 0.544898\n",
      "[194]\ttraining's binary_logloss: 0.544741\n",
      "[195]\ttraining's binary_logloss: 0.544545\n",
      "[196]\ttraining's binary_logloss: 0.544359\n",
      "[197]\ttraining's binary_logloss: 0.544176\n",
      "[198]\ttraining's binary_logloss: 0.543975\n",
      "[199]\ttraining's binary_logloss: 0.54382\n",
      "[200]\ttraining's binary_logloss: 0.543669\n",
      "[201]\ttraining's binary_logloss: 0.543465\n",
      "[202]\ttraining's binary_logloss: 0.543275\n",
      "[203]\ttraining's binary_logloss: 0.54308\n",
      "[204]\ttraining's binary_logloss: 0.54289\n",
      "[205]\ttraining's binary_logloss: 0.54271\n",
      "[206]\ttraining's binary_logloss: 0.542564\n",
      "[207]\ttraining's binary_logloss: 0.542412\n",
      "[208]\ttraining's binary_logloss: 0.542281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[209]\ttraining's binary_logloss: 0.54215\n",
      "[210]\ttraining's binary_logloss: 0.542022\n",
      "[211]\ttraining's binary_logloss: 0.541838\n",
      "[212]\ttraining's binary_logloss: 0.541653\n",
      "[213]\ttraining's binary_logloss: 0.541487\n",
      "[214]\ttraining's binary_logloss: 0.541303\n",
      "[215]\ttraining's binary_logloss: 0.541144\n",
      "[216]\ttraining's binary_logloss: 0.540931\n",
      "[217]\ttraining's binary_logloss: 0.540749\n",
      "[218]\ttraining's binary_logloss: 0.540573\n",
      "[219]\ttraining's binary_logloss: 0.540389\n",
      "[220]\ttraining's binary_logloss: 0.54023\n",
      "[221]\ttraining's binary_logloss: 0.540066\n",
      "[222]\ttraining's binary_logloss: 0.539901\n",
      "[223]\ttraining's binary_logloss: 0.539745\n",
      "[224]\ttraining's binary_logloss: 0.539532\n",
      "[225]\ttraining's binary_logloss: 0.539333\n",
      "[226]\ttraining's binary_logloss: 0.539166\n",
      "[227]\ttraining's binary_logloss: 0.538991\n",
      "[228]\ttraining's binary_logloss: 0.538793\n",
      "[229]\ttraining's binary_logloss: 0.538609\n",
      "[230]\ttraining's binary_logloss: 0.538441\n",
      "[231]\ttraining's binary_logloss: 0.538265\n",
      "[232]\ttraining's binary_logloss: 0.538137\n",
      "[233]\ttraining's binary_logloss: 0.537999\n",
      "[234]\ttraining's binary_logloss: 0.537829\n",
      "[235]\ttraining's binary_logloss: 0.537669\n",
      "[236]\ttraining's binary_logloss: 0.53747\n",
      "[237]\ttraining's binary_logloss: 0.53727\n",
      "[238]\ttraining's binary_logloss: 0.537076\n",
      "[239]\ttraining's binary_logloss: 0.536868\n",
      "[240]\ttraining's binary_logloss: 0.536682\n",
      "[241]\ttraining's binary_logloss: 0.536451\n",
      "[242]\ttraining's binary_logloss: 0.536228\n",
      "[243]\ttraining's binary_logloss: 0.536025\n",
      "[244]\ttraining's binary_logloss: 0.535836\n",
      "[245]\ttraining's binary_logloss: 0.535657\n",
      "[246]\ttraining's binary_logloss: 0.535435\n",
      "[247]\ttraining's binary_logloss: 0.535251\n",
      "[248]\ttraining's binary_logloss: 0.53505\n",
      "[249]\ttraining's binary_logloss: 0.534839\n",
      "[250]\ttraining's binary_logloss: 0.534612\n",
      "[251]\ttraining's binary_logloss: 0.534429\n",
      "[252]\ttraining's binary_logloss: 0.534252\n",
      "[253]\ttraining's binary_logloss: 0.534071\n",
      "[254]\ttraining's binary_logloss: 0.533894\n",
      "[255]\ttraining's binary_logloss: 0.533722\n",
      "[256]\ttraining's binary_logloss: 0.533559\n",
      "[257]\ttraining's binary_logloss: 0.533391\n",
      "[258]\ttraining's binary_logloss: 0.533223\n",
      "[259]\ttraining's binary_logloss: 0.533015\n",
      "[260]\ttraining's binary_logloss: 0.532848\n",
      "[261]\ttraining's binary_logloss: 0.532658\n",
      "[262]\ttraining's binary_logloss: 0.532459\n",
      "[263]\ttraining's binary_logloss: 0.532262\n",
      "[264]\ttraining's binary_logloss: 0.532055\n",
      "[265]\ttraining's binary_logloss: 0.531879\n",
      "[266]\ttraining's binary_logloss: 0.531704\n",
      "[267]\ttraining's binary_logloss: 0.53153\n",
      "[268]\ttraining's binary_logloss: 0.531323\n",
      "[269]\ttraining's binary_logloss: 0.531131\n",
      "[270]\ttraining's binary_logloss: 0.530939\n",
      "[271]\ttraining's binary_logloss: 0.530774\n",
      "[272]\ttraining's binary_logloss: 0.530582\n",
      "[273]\ttraining's binary_logloss: 0.530382\n",
      "[274]\ttraining's binary_logloss: 0.530195\n",
      "[275]\ttraining's binary_logloss: 0.529986\n",
      "[276]\ttraining's binary_logloss: 0.529785\n",
      "[277]\ttraining's binary_logloss: 0.529585\n",
      "[278]\ttraining's binary_logloss: 0.529404\n",
      "[279]\ttraining's binary_logloss: 0.529214\n",
      "[280]\ttraining's binary_logloss: 0.529004\n",
      "[281]\ttraining's binary_logloss: 0.528803\n",
      "[282]\ttraining's binary_logloss: 0.528634\n",
      "[283]\ttraining's binary_logloss: 0.52842\n",
      "[284]\ttraining's binary_logloss: 0.528225\n",
      "[285]\ttraining's binary_logloss: 0.528039\n",
      "[286]\ttraining's binary_logloss: 0.52784\n",
      "[287]\ttraining's binary_logloss: 0.527658\n",
      "[288]\ttraining's binary_logloss: 0.527432\n",
      "[289]\ttraining's binary_logloss: 0.527216\n",
      "[290]\ttraining's binary_logloss: 0.527004\n",
      "[291]\ttraining's binary_logloss: 0.526784\n",
      "[292]\ttraining's binary_logloss: 0.526617\n",
      "[293]\ttraining's binary_logloss: 0.526394\n",
      "[294]\ttraining's binary_logloss: 0.526199\n",
      "[295]\ttraining's binary_logloss: 0.525985\n",
      "[296]\ttraining's binary_logloss: 0.525799\n",
      "[297]\ttraining's binary_logloss: 0.525569\n",
      "[298]\ttraining's binary_logloss: 0.525384\n",
      "[299]\ttraining's binary_logloss: 0.525189\n",
      "[300]\ttraining's binary_logloss: 0.524978\n",
      "[301]\ttraining's binary_logloss: 0.524777\n",
      "[302]\ttraining's binary_logloss: 0.524568\n",
      "[303]\ttraining's binary_logloss: 0.524367\n",
      "[304]\ttraining's binary_logloss: 0.524155\n",
      "[305]\ttraining's binary_logloss: 0.523901\n",
      "[306]\ttraining's binary_logloss: 0.523691\n",
      "[307]\ttraining's binary_logloss: 0.523496\n",
      "[308]\ttraining's binary_logloss: 0.523288\n",
      "[309]\ttraining's binary_logloss: 0.523098\n",
      "[310]\ttraining's binary_logloss: 0.522897\n",
      "[311]\ttraining's binary_logloss: 0.522712\n",
      "[312]\ttraining's binary_logloss: 0.522543\n",
      "[313]\ttraining's binary_logloss: 0.522328\n",
      "[314]\ttraining's binary_logloss: 0.522151\n",
      "[315]\ttraining's binary_logloss: 0.521941\n",
      "[316]\ttraining's binary_logloss: 0.521739\n",
      "[317]\ttraining's binary_logloss: 0.521534\n",
      "[318]\ttraining's binary_logloss: 0.521319\n",
      "[319]\ttraining's binary_logloss: 0.521107\n",
      "[320]\ttraining's binary_logloss: 0.520892\n",
      "[321]\ttraining's binary_logloss: 0.520729\n",
      "[322]\ttraining's binary_logloss: 0.520577\n",
      "[323]\ttraining's binary_logloss: 0.520415\n",
      "[324]\ttraining's binary_logloss: 0.520238\n",
      "[325]\ttraining's binary_logloss: 0.520076\n",
      "[326]\ttraining's binary_logloss: 0.519877\n",
      "[327]\ttraining's binary_logloss: 0.519699\n",
      "[328]\ttraining's binary_logloss: 0.519507\n",
      "[329]\ttraining's binary_logloss: 0.519322\n",
      "[330]\ttraining's binary_logloss: 0.519143\n",
      "[331]\ttraining's binary_logloss: 0.518948\n",
      "[332]\ttraining's binary_logloss: 0.518717\n",
      "[333]\ttraining's binary_logloss: 0.518506\n",
      "[334]\ttraining's binary_logloss: 0.518327\n",
      "[335]\ttraining's binary_logloss: 0.518123\n",
      "[336]\ttraining's binary_logloss: 0.517935\n",
      "[337]\ttraining's binary_logloss: 0.517754\n",
      "[338]\ttraining's binary_logloss: 0.517564\n",
      "[339]\ttraining's binary_logloss: 0.517386\n",
      "[340]\ttraining's binary_logloss: 0.517159\n",
      "[341]\ttraining's binary_logloss: 0.517019\n",
      "[342]\ttraining's binary_logloss: 0.516826\n",
      "[343]\ttraining's binary_logloss: 0.516617\n",
      "[344]\ttraining's binary_logloss: 0.516434\n",
      "[345]\ttraining's binary_logloss: 0.516254\n",
      "[346]\ttraining's binary_logloss: 0.516075\n",
      "[347]\ttraining's binary_logloss: 0.515911\n",
      "[348]\ttraining's binary_logloss: 0.515775\n",
      "[349]\ttraining's binary_logloss: 0.515652\n",
      "[350]\ttraining's binary_logloss: 0.51549\n",
      "[351]\ttraining's binary_logloss: 0.515279\n",
      "[352]\ttraining's binary_logloss: 0.515057\n",
      "[353]\ttraining's binary_logloss: 0.514866\n",
      "[354]\ttraining's binary_logloss: 0.51467\n",
      "[355]\ttraining's binary_logloss: 0.514471\n",
      "[356]\ttraining's binary_logloss: 0.514253\n",
      "[357]\ttraining's binary_logloss: 0.514033\n",
      "[358]\ttraining's binary_logloss: 0.513846\n",
      "[359]\ttraining's binary_logloss: 0.513642\n",
      "[360]\ttraining's binary_logloss: 0.513438\n",
      "[361]\ttraining's binary_logloss: 0.513219\n",
      "[362]\ttraining's binary_logloss: 0.51298\n",
      "[363]\ttraining's binary_logloss: 0.512749\n",
      "[364]\ttraining's binary_logloss: 0.512526\n",
      "[365]\ttraining's binary_logloss: 0.512317\n",
      "[366]\ttraining's binary_logloss: 0.512143\n",
      "[367]\ttraining's binary_logloss: 0.51197\n",
      "[368]\ttraining's binary_logloss: 0.511789\n",
      "[369]\ttraining's binary_logloss: 0.511602\n",
      "[370]\ttraining's binary_logloss: 0.511436\n",
      "[371]\ttraining's binary_logloss: 0.51127\n",
      "[372]\ttraining's binary_logloss: 0.511093\n",
      "[373]\ttraining's binary_logloss: 0.510906\n",
      "[374]\ttraining's binary_logloss: 0.51073\n",
      "[375]\ttraining's binary_logloss: 0.510536\n",
      "[376]\ttraining's binary_logloss: 0.510316\n",
      "[377]\ttraining's binary_logloss: 0.510096\n",
      "[378]\ttraining's binary_logloss: 0.509919\n",
      "[379]\ttraining's binary_logloss: 0.509702\n",
      "[380]\ttraining's binary_logloss: 0.509547\n",
      "[381]\ttraining's binary_logloss: 0.50933\n",
      "[382]\ttraining's binary_logloss: 0.5091\n",
      "[383]\ttraining's binary_logloss: 0.508867\n",
      "[384]\ttraining's binary_logloss: 0.508677\n",
      "[385]\ttraining's binary_logloss: 0.508452\n",
      "[386]\ttraining's binary_logloss: 0.508267\n",
      "[387]\ttraining's binary_logloss: 0.508081\n",
      "[388]\ttraining's binary_logloss: 0.507866\n",
      "[389]\ttraining's binary_logloss: 0.507665\n",
      "[390]\ttraining's binary_logloss: 0.507474\n",
      "[391]\ttraining's binary_logloss: 0.50724\n",
      "[392]\ttraining's binary_logloss: 0.507011\n",
      "[393]\ttraining's binary_logloss: 0.506814\n",
      "[394]\ttraining's binary_logloss: 0.506615\n",
      "[395]\ttraining's binary_logloss: 0.506397\n",
      "[396]\ttraining's binary_logloss: 0.506198\n",
      "[397]\ttraining's binary_logloss: 0.505976\n",
      "[398]\ttraining's binary_logloss: 0.505757\n",
      "[399]\ttraining's binary_logloss: 0.505555\n",
      "[400]\ttraining's binary_logloss: 0.505351\n",
      "[401]\ttraining's binary_logloss: 0.505147\n",
      "[402]\ttraining's binary_logloss: 0.504937\n",
      "[403]\ttraining's binary_logloss: 0.504738\n",
      "[404]\ttraining's binary_logloss: 0.504542\n",
      "[405]\ttraining's binary_logloss: 0.504335\n",
      "[406]\ttraining's binary_logloss: 0.504106\n",
      "[407]\ttraining's binary_logloss: 0.50391\n",
      "[408]\ttraining's binary_logloss: 0.503715\n",
      "[409]\ttraining's binary_logloss: 0.503536\n",
      "[410]\ttraining's binary_logloss: 0.503339\n",
      "[411]\ttraining's binary_logloss: 0.503152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[412]\ttraining's binary_logloss: 0.502968\n",
      "[413]\ttraining's binary_logloss: 0.502791\n",
      "[414]\ttraining's binary_logloss: 0.5026\n",
      "[415]\ttraining's binary_logloss: 0.502445\n",
      "[416]\ttraining's binary_logloss: 0.502236\n",
      "[417]\ttraining's binary_logloss: 0.502029\n",
      "[418]\ttraining's binary_logloss: 0.501827\n",
      "[419]\ttraining's binary_logloss: 0.501649\n",
      "[420]\ttraining's binary_logloss: 0.501433\n",
      "[421]\ttraining's binary_logloss: 0.50127\n",
      "[422]\ttraining's binary_logloss: 0.501103\n",
      "[423]\ttraining's binary_logloss: 0.500913\n",
      "[424]\ttraining's binary_logloss: 0.500753\n",
      "[425]\ttraining's binary_logloss: 0.50057\n",
      "[426]\ttraining's binary_logloss: 0.500398\n",
      "[427]\ttraining's binary_logloss: 0.500213\n",
      "[428]\ttraining's binary_logloss: 0.500035\n",
      "[429]\ttraining's binary_logloss: 0.499837\n",
      "[430]\ttraining's binary_logloss: 0.499668\n",
      "[431]\ttraining's binary_logloss: 0.499476\n",
      "[432]\ttraining's binary_logloss: 0.499297\n",
      "[433]\ttraining's binary_logloss: 0.499139\n",
      "[434]\ttraining's binary_logloss: 0.498976\n",
      "[435]\ttraining's binary_logloss: 0.49877\n",
      "[436]\ttraining's binary_logloss: 0.498605\n",
      "[437]\ttraining's binary_logloss: 0.498416\n",
      "[438]\ttraining's binary_logloss: 0.498209\n",
      "[439]\ttraining's binary_logloss: 0.498052\n",
      "[440]\ttraining's binary_logloss: 0.497893\n",
      "[441]\ttraining's binary_logloss: 0.497683\n",
      "[442]\ttraining's binary_logloss: 0.497469\n",
      "[443]\ttraining's binary_logloss: 0.497261\n",
      "[444]\ttraining's binary_logloss: 0.497047\n",
      "[445]\ttraining's binary_logloss: 0.496839\n",
      "[446]\ttraining's binary_logloss: 0.496683\n",
      "[447]\ttraining's binary_logloss: 0.496526\n",
      "[448]\ttraining's binary_logloss: 0.496323\n",
      "[449]\ttraining's binary_logloss: 0.496133\n",
      "[450]\ttraining's binary_logloss: 0.495977\n",
      "[451]\ttraining's binary_logloss: 0.495838\n",
      "[452]\ttraining's binary_logloss: 0.495638\n",
      "[453]\ttraining's binary_logloss: 0.495502\n",
      "[454]\ttraining's binary_logloss: 0.495361\n",
      "[455]\ttraining's binary_logloss: 0.495203\n",
      "[456]\ttraining's binary_logloss: 0.494956\n",
      "[457]\ttraining's binary_logloss: 0.494723\n",
      "[458]\ttraining's binary_logloss: 0.494491\n",
      "[459]\ttraining's binary_logloss: 0.494257\n",
      "[460]\ttraining's binary_logloss: 0.494032\n",
      "[461]\ttraining's binary_logloss: 0.493863\n",
      "[462]\ttraining's binary_logloss: 0.493689\n",
      "[463]\ttraining's binary_logloss: 0.493514\n",
      "[464]\ttraining's binary_logloss: 0.493353\n",
      "[465]\ttraining's binary_logloss: 0.493201\n",
      "[466]\ttraining's binary_logloss: 0.492967\n",
      "[467]\ttraining's binary_logloss: 0.492726\n",
      "[468]\ttraining's binary_logloss: 0.492493\n",
      "[469]\ttraining's binary_logloss: 0.492285\n",
      "[470]\ttraining's binary_logloss: 0.492065\n",
      "[471]\ttraining's binary_logloss: 0.491889\n",
      "[472]\ttraining's binary_logloss: 0.49172\n",
      "[473]\ttraining's binary_logloss: 0.491551\n",
      "[474]\ttraining's binary_logloss: 0.491377\n",
      "[475]\ttraining's binary_logloss: 0.491196\n",
      "[476]\ttraining's binary_logloss: 0.490988\n",
      "[477]\ttraining's binary_logloss: 0.490799\n",
      "[478]\ttraining's binary_logloss: 0.490622\n",
      "[479]\ttraining's binary_logloss: 0.490444\n",
      "[480]\ttraining's binary_logloss: 0.490256\n",
      "[481]\ttraining's binary_logloss: 0.490048\n",
      "[482]\ttraining's binary_logloss: 0.489882\n",
      "[483]\ttraining's binary_logloss: 0.48971\n",
      "[484]\ttraining's binary_logloss: 0.489528\n",
      "[485]\ttraining's binary_logloss: 0.489369\n",
      "[486]\ttraining's binary_logloss: 0.48919\n",
      "[487]\ttraining's binary_logloss: 0.488984\n",
      "[488]\ttraining's binary_logloss: 0.488837\n",
      "[489]\ttraining's binary_logloss: 0.488649\n",
      "[490]\ttraining's binary_logloss: 0.488466\n",
      "[491]\ttraining's binary_logloss: 0.488226\n",
      "[492]\ttraining's binary_logloss: 0.487985\n",
      "[493]\ttraining's binary_logloss: 0.487732\n",
      "[494]\ttraining's binary_logloss: 0.487498\n",
      "[495]\ttraining's binary_logloss: 0.48726\n",
      "[496]\ttraining's binary_logloss: 0.487035\n",
      "[497]\ttraining's binary_logloss: 0.48681\n",
      "[498]\ttraining's binary_logloss: 0.486593\n",
      "[499]\ttraining's binary_logloss: 0.486382\n",
      "[500]\ttraining's binary_logloss: 0.486173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613305\n",
      "[2]\ttraining's binary_logloss: 0.611789\n",
      "[3]\ttraining's binary_logloss: 0.610337\n",
      "[4]\ttraining's binary_logloss: 0.608855\n",
      "[5]\ttraining's binary_logloss: 0.607445\n",
      "[6]\ttraining's binary_logloss: 0.606142\n",
      "[7]\ttraining's binary_logloss: 0.604805\n",
      "[8]\ttraining's binary_logloss: 0.603593\n",
      "[9]\ttraining's binary_logloss: 0.602338\n",
      "[10]\ttraining's binary_logloss: 0.60113\n",
      "[11]\ttraining's binary_logloss: 0.599968\n",
      "[12]\ttraining's binary_logloss: 0.598877\n",
      "[13]\ttraining's binary_logloss: 0.597897\n",
      "[14]\ttraining's binary_logloss: 0.596856\n",
      "[15]\ttraining's binary_logloss: 0.595847\n",
      "[16]\ttraining's binary_logloss: 0.59495\n",
      "[17]\ttraining's binary_logloss: 0.593981\n",
      "[18]\ttraining's binary_logloss: 0.593041\n",
      "[19]\ttraining's binary_logloss: 0.592134\n",
      "[20]\ttraining's binary_logloss: 0.591334\n",
      "[21]\ttraining's binary_logloss: 0.590505\n",
      "[22]\ttraining's binary_logloss: 0.589709\n",
      "[23]\ttraining's binary_logloss: 0.588935\n",
      "[24]\ttraining's binary_logloss: 0.588102\n",
      "[25]\ttraining's binary_logloss: 0.587276\n",
      "[26]\ttraining's binary_logloss: 0.586493\n",
      "[27]\ttraining's binary_logloss: 0.585701\n",
      "[28]\ttraining's binary_logloss: 0.584916\n",
      "[29]\ttraining's binary_logloss: 0.584209\n",
      "[30]\ttraining's binary_logloss: 0.5835\n",
      "[31]\ttraining's binary_logloss: 0.58286\n",
      "[32]\ttraining's binary_logloss: 0.582259\n",
      "[33]\ttraining's binary_logloss: 0.581609\n",
      "[34]\ttraining's binary_logloss: 0.580953\n",
      "[35]\ttraining's binary_logloss: 0.580398\n",
      "[36]\ttraining's binary_logloss: 0.579755\n",
      "[37]\ttraining's binary_logloss: 0.579122\n",
      "[38]\ttraining's binary_logloss: 0.578548\n",
      "[39]\ttraining's binary_logloss: 0.57799\n",
      "[40]\ttraining's binary_logloss: 0.577442\n",
      "[41]\ttraining's binary_logloss: 0.576954\n",
      "[42]\ttraining's binary_logloss: 0.576449\n",
      "[43]\ttraining's binary_logloss: 0.575961\n",
      "[44]\ttraining's binary_logloss: 0.57549\n",
      "[45]\ttraining's binary_logloss: 0.575035\n",
      "[46]\ttraining's binary_logloss: 0.574608\n",
      "[47]\ttraining's binary_logloss: 0.574189\n",
      "[48]\ttraining's binary_logloss: 0.573688\n",
      "[49]\ttraining's binary_logloss: 0.573305\n",
      "[50]\ttraining's binary_logloss: 0.572876\n",
      "[51]\ttraining's binary_logloss: 0.572423\n",
      "[52]\ttraining's binary_logloss: 0.57199\n",
      "[53]\ttraining's binary_logloss: 0.571607\n",
      "[54]\ttraining's binary_logloss: 0.571219\n",
      "[55]\ttraining's binary_logloss: 0.57084\n",
      "[56]\ttraining's binary_logloss: 0.570436\n",
      "[57]\ttraining's binary_logloss: 0.570116\n",
      "[58]\ttraining's binary_logloss: 0.569757\n",
      "[59]\ttraining's binary_logloss: 0.569447\n",
      "[60]\ttraining's binary_logloss: 0.569122\n",
      "[61]\ttraining's binary_logloss: 0.5688\n",
      "[62]\ttraining's binary_logloss: 0.56839\n",
      "[63]\ttraining's binary_logloss: 0.568017\n",
      "[64]\ttraining's binary_logloss: 0.56767\n",
      "[65]\ttraining's binary_logloss: 0.567302\n",
      "[66]\ttraining's binary_logloss: 0.566914\n",
      "[67]\ttraining's binary_logloss: 0.566559\n",
      "[68]\ttraining's binary_logloss: 0.56621\n",
      "[69]\ttraining's binary_logloss: 0.565869\n",
      "[70]\ttraining's binary_logloss: 0.565582\n",
      "[71]\ttraining's binary_logloss: 0.565282\n",
      "[72]\ttraining's binary_logloss: 0.564992\n",
      "[73]\ttraining's binary_logloss: 0.564715\n",
      "[74]\ttraining's binary_logloss: 0.564433\n",
      "[75]\ttraining's binary_logloss: 0.564165\n",
      "[76]\ttraining's binary_logloss: 0.563878\n",
      "[77]\ttraining's binary_logloss: 0.563625\n",
      "[78]\ttraining's binary_logloss: 0.563388\n",
      "[79]\ttraining's binary_logloss: 0.563201\n",
      "[80]\ttraining's binary_logloss: 0.562961\n",
      "[81]\ttraining's binary_logloss: 0.562752\n",
      "[82]\ttraining's binary_logloss: 0.562513\n",
      "[83]\ttraining's binary_logloss: 0.562297\n",
      "[84]\ttraining's binary_logloss: 0.562058\n",
      "[85]\ttraining's binary_logloss: 0.561811\n",
      "[86]\ttraining's binary_logloss: 0.561551\n",
      "[87]\ttraining's binary_logloss: 0.561302\n",
      "[88]\ttraining's binary_logloss: 0.561073\n",
      "[89]\ttraining's binary_logloss: 0.560837\n",
      "[90]\ttraining's binary_logloss: 0.560613\n",
      "[91]\ttraining's binary_logloss: 0.560357\n",
      "[92]\ttraining's binary_logloss: 0.560142\n",
      "[93]\ttraining's binary_logloss: 0.559944\n",
      "[94]\ttraining's binary_logloss: 0.559716\n",
      "[95]\ttraining's binary_logloss: 0.55947\n",
      "[96]\ttraining's binary_logloss: 0.559277\n",
      "[97]\ttraining's binary_logloss: 0.559102\n",
      "[98]\ttraining's binary_logloss: 0.558958\n",
      "[99]\ttraining's binary_logloss: 0.558769\n",
      "[100]\ttraining's binary_logloss: 0.558609\n",
      "[101]\ttraining's binary_logloss: 0.558422\n",
      "[102]\ttraining's binary_logloss: 0.558233\n",
      "[103]\ttraining's binary_logloss: 0.558047\n",
      "[104]\ttraining's binary_logloss: 0.557859\n",
      "[105]\ttraining's binary_logloss: 0.557675\n",
      "[106]\ttraining's binary_logloss: 0.55752\n",
      "[107]\ttraining's binary_logloss: 0.557336\n",
      "[108]\ttraining's binary_logloss: 0.557137\n",
      "[109]\ttraining's binary_logloss: 0.556942\n",
      "[110]\ttraining's binary_logloss: 0.556764\n",
      "[111]\ttraining's binary_logloss: 0.55661\n",
      "[112]\ttraining's binary_logloss: 0.556449\n",
      "[113]\ttraining's binary_logloss: 0.55626\n",
      "[114]\ttraining's binary_logloss: 0.556136\n",
      "[115]\ttraining's binary_logloss: 0.555929\n",
      "[116]\ttraining's binary_logloss: 0.555758\n",
      "[117]\ttraining's binary_logloss: 0.555576\n",
      "[118]\ttraining's binary_logloss: 0.555413\n",
      "[119]\ttraining's binary_logloss: 0.555258\n",
      "[120]\ttraining's binary_logloss: 0.55512\n",
      "[121]\ttraining's binary_logloss: 0.554979\n",
      "[122]\ttraining's binary_logloss: 0.554798\n",
      "[123]\ttraining's binary_logloss: 0.55464\n",
      "[124]\ttraining's binary_logloss: 0.554486\n",
      "[125]\ttraining's binary_logloss: 0.554329\n",
      "[126]\ttraining's binary_logloss: 0.554145\n",
      "[127]\ttraining's binary_logloss: 0.55396\n",
      "[128]\ttraining's binary_logloss: 0.553781\n",
      "[129]\ttraining's binary_logloss: 0.553563\n",
      "[130]\ttraining's binary_logloss: 0.553403\n",
      "[131]\ttraining's binary_logloss: 0.553288\n",
      "[132]\ttraining's binary_logloss: 0.553172\n",
      "[133]\ttraining's binary_logloss: 0.55306\n",
      "[134]\ttraining's binary_logloss: 0.55293\n",
      "[135]\ttraining's binary_logloss: 0.552831\n",
      "[136]\ttraining's binary_logloss: 0.552636\n",
      "[137]\ttraining's binary_logloss: 0.552469\n",
      "[138]\ttraining's binary_logloss: 0.552313\n",
      "[139]\ttraining's binary_logloss: 0.552175\n",
      "[140]\ttraining's binary_logloss: 0.552012\n",
      "[141]\ttraining's binary_logloss: 0.551838\n",
      "[142]\ttraining's binary_logloss: 0.551678\n",
      "[143]\ttraining's binary_logloss: 0.55151\n",
      "[144]\ttraining's binary_logloss: 0.551356\n",
      "[145]\ttraining's binary_logloss: 0.551198\n",
      "[146]\ttraining's binary_logloss: 0.551026\n",
      "[147]\ttraining's binary_logloss: 0.550891\n",
      "[148]\ttraining's binary_logloss: 0.550736\n",
      "[149]\ttraining's binary_logloss: 0.550606\n",
      "[150]\ttraining's binary_logloss: 0.550428\n",
      "[151]\ttraining's binary_logloss: 0.550286\n",
      "[152]\ttraining's binary_logloss: 0.550137\n",
      "[153]\ttraining's binary_logloss: 0.549972\n",
      "[154]\ttraining's binary_logloss: 0.549821\n",
      "[155]\ttraining's binary_logloss: 0.549678\n",
      "[156]\ttraining's binary_logloss: 0.549519\n",
      "[157]\ttraining's binary_logloss: 0.54937\n",
      "[158]\ttraining's binary_logloss: 0.549208\n",
      "[159]\ttraining's binary_logloss: 0.549068\n",
      "[160]\ttraining's binary_logloss: 0.548928\n",
      "[161]\ttraining's binary_logloss: 0.548777\n",
      "[162]\ttraining's binary_logloss: 0.548627\n",
      "[163]\ttraining's binary_logloss: 0.548462\n",
      "[164]\ttraining's binary_logloss: 0.548308\n",
      "[165]\ttraining's binary_logloss: 0.548147\n",
      "[166]\ttraining's binary_logloss: 0.547975\n",
      "[167]\ttraining's binary_logloss: 0.547813\n",
      "[168]\ttraining's binary_logloss: 0.547646\n",
      "[169]\ttraining's binary_logloss: 0.547507\n",
      "[170]\ttraining's binary_logloss: 0.547354\n",
      "[171]\ttraining's binary_logloss: 0.547178\n",
      "[172]\ttraining's binary_logloss: 0.547013\n",
      "[173]\ttraining's binary_logloss: 0.546862\n",
      "[174]\ttraining's binary_logloss: 0.546711\n",
      "[175]\ttraining's binary_logloss: 0.546557\n",
      "[176]\ttraining's binary_logloss: 0.546368\n",
      "[177]\ttraining's binary_logloss: 0.546178\n",
      "[178]\ttraining's binary_logloss: 0.546004\n",
      "[179]\ttraining's binary_logloss: 0.545829\n",
      "[180]\ttraining's binary_logloss: 0.545662\n",
      "[181]\ttraining's binary_logloss: 0.545523\n",
      "[182]\ttraining's binary_logloss: 0.545392\n",
      "[183]\ttraining's binary_logloss: 0.545224\n",
      "[184]\ttraining's binary_logloss: 0.545069\n",
      "[185]\ttraining's binary_logloss: 0.544897\n",
      "[186]\ttraining's binary_logloss: 0.544772\n",
      "[187]\ttraining's binary_logloss: 0.54466\n",
      "[188]\ttraining's binary_logloss: 0.544554\n",
      "[189]\ttraining's binary_logloss: 0.54442\n",
      "[190]\ttraining's binary_logloss: 0.54429\n",
      "[191]\ttraining's binary_logloss: 0.544106\n",
      "[192]\ttraining's binary_logloss: 0.543931\n",
      "[193]\ttraining's binary_logloss: 0.543758\n",
      "[194]\ttraining's binary_logloss: 0.543592\n",
      "[195]\ttraining's binary_logloss: 0.543424\n",
      "[196]\ttraining's binary_logloss: 0.543233\n",
      "[197]\ttraining's binary_logloss: 0.543059\n",
      "[198]\ttraining's binary_logloss: 0.54288\n",
      "[199]\ttraining's binary_logloss: 0.542705\n",
      "[200]\ttraining's binary_logloss: 0.542544\n",
      "[201]\ttraining's binary_logloss: 0.542362\n",
      "[202]\ttraining's binary_logloss: 0.542186\n",
      "[203]\ttraining's binary_logloss: 0.542004\n",
      "[204]\ttraining's binary_logloss: 0.541839\n",
      "[205]\ttraining's binary_logloss: 0.541679\n",
      "[206]\ttraining's binary_logloss: 0.541505\n",
      "[207]\ttraining's binary_logloss: 0.541318\n",
      "[208]\ttraining's binary_logloss: 0.541195\n",
      "[209]\ttraining's binary_logloss: 0.541003\n",
      "[210]\ttraining's binary_logloss: 0.540891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[211]\ttraining's binary_logloss: 0.540698\n",
      "[212]\ttraining's binary_logloss: 0.540511\n",
      "[213]\ttraining's binary_logloss: 0.540336\n",
      "[214]\ttraining's binary_logloss: 0.540167\n",
      "[215]\ttraining's binary_logloss: 0.539995\n",
      "[216]\ttraining's binary_logloss: 0.539807\n",
      "[217]\ttraining's binary_logloss: 0.539637\n",
      "[218]\ttraining's binary_logloss: 0.539445\n",
      "[219]\ttraining's binary_logloss: 0.539255\n",
      "[220]\ttraining's binary_logloss: 0.539049\n",
      "[221]\ttraining's binary_logloss: 0.538901\n",
      "[222]\ttraining's binary_logloss: 0.538736\n",
      "[223]\ttraining's binary_logloss: 0.538501\n",
      "[224]\ttraining's binary_logloss: 0.538338\n",
      "[225]\ttraining's binary_logloss: 0.538181\n",
      "[226]\ttraining's binary_logloss: 0.538015\n",
      "[227]\ttraining's binary_logloss: 0.537808\n",
      "[228]\ttraining's binary_logloss: 0.537617\n",
      "[229]\ttraining's binary_logloss: 0.537469\n",
      "[230]\ttraining's binary_logloss: 0.537314\n",
      "[231]\ttraining's binary_logloss: 0.537101\n",
      "[232]\ttraining's binary_logloss: 0.536885\n",
      "[233]\ttraining's binary_logloss: 0.536682\n",
      "[234]\ttraining's binary_logloss: 0.536486\n",
      "[235]\ttraining's binary_logloss: 0.536287\n",
      "[236]\ttraining's binary_logloss: 0.536121\n",
      "[237]\ttraining's binary_logloss: 0.535924\n",
      "[238]\ttraining's binary_logloss: 0.535761\n",
      "[239]\ttraining's binary_logloss: 0.535616\n",
      "[240]\ttraining's binary_logloss: 0.535469\n",
      "[241]\ttraining's binary_logloss: 0.53531\n",
      "[242]\ttraining's binary_logloss: 0.535114\n",
      "[243]\ttraining's binary_logloss: 0.534945\n",
      "[244]\ttraining's binary_logloss: 0.534787\n",
      "[245]\ttraining's binary_logloss: 0.534579\n",
      "[246]\ttraining's binary_logloss: 0.534368\n",
      "[247]\ttraining's binary_logloss: 0.534163\n",
      "[248]\ttraining's binary_logloss: 0.533953\n",
      "[249]\ttraining's binary_logloss: 0.533764\n",
      "[250]\ttraining's binary_logloss: 0.53359\n",
      "[251]\ttraining's binary_logloss: 0.533416\n",
      "[252]\ttraining's binary_logloss: 0.533233\n",
      "[253]\ttraining's binary_logloss: 0.533065\n",
      "[254]\ttraining's binary_logloss: 0.532873\n",
      "[255]\ttraining's binary_logloss: 0.532682\n",
      "[256]\ttraining's binary_logloss: 0.532494\n",
      "[257]\ttraining's binary_logloss: 0.532324\n",
      "[258]\ttraining's binary_logloss: 0.532128\n",
      "[259]\ttraining's binary_logloss: 0.531918\n",
      "[260]\ttraining's binary_logloss: 0.531704\n",
      "[261]\ttraining's binary_logloss: 0.53149\n",
      "[262]\ttraining's binary_logloss: 0.531277\n",
      "[263]\ttraining's binary_logloss: 0.531073\n",
      "[264]\ttraining's binary_logloss: 0.530884\n",
      "[265]\ttraining's binary_logloss: 0.530688\n",
      "[266]\ttraining's binary_logloss: 0.530554\n",
      "[267]\ttraining's binary_logloss: 0.530427\n",
      "[268]\ttraining's binary_logloss: 0.530293\n",
      "[269]\ttraining's binary_logloss: 0.530171\n",
      "[270]\ttraining's binary_logloss: 0.530036\n",
      "[271]\ttraining's binary_logloss: 0.529813\n",
      "[272]\ttraining's binary_logloss: 0.529606\n",
      "[273]\ttraining's binary_logloss: 0.529401\n",
      "[274]\ttraining's binary_logloss: 0.529225\n",
      "[275]\ttraining's binary_logloss: 0.529059\n",
      "[276]\ttraining's binary_logloss: 0.528859\n",
      "[277]\ttraining's binary_logloss: 0.52867\n",
      "[278]\ttraining's binary_logloss: 0.528454\n",
      "[279]\ttraining's binary_logloss: 0.52824\n",
      "[280]\ttraining's binary_logloss: 0.528036\n",
      "[281]\ttraining's binary_logloss: 0.527836\n",
      "[282]\ttraining's binary_logloss: 0.527663\n",
      "[283]\ttraining's binary_logloss: 0.527471\n",
      "[284]\ttraining's binary_logloss: 0.527285\n",
      "[285]\ttraining's binary_logloss: 0.527103\n",
      "[286]\ttraining's binary_logloss: 0.526839\n",
      "[287]\ttraining's binary_logloss: 0.52659\n",
      "[288]\ttraining's binary_logloss: 0.526336\n",
      "[289]\ttraining's binary_logloss: 0.526093\n",
      "[290]\ttraining's binary_logloss: 0.525857\n",
      "[291]\ttraining's binary_logloss: 0.525669\n",
      "[292]\ttraining's binary_logloss: 0.525458\n",
      "[293]\ttraining's binary_logloss: 0.525283\n",
      "[294]\ttraining's binary_logloss: 0.525094\n",
      "[295]\ttraining's binary_logloss: 0.524922\n",
      "[296]\ttraining's binary_logloss: 0.524703\n",
      "[297]\ttraining's binary_logloss: 0.524445\n",
      "[298]\ttraining's binary_logloss: 0.524205\n",
      "[299]\ttraining's binary_logloss: 0.523961\n",
      "[300]\ttraining's binary_logloss: 0.523776\n",
      "[301]\ttraining's binary_logloss: 0.523564\n",
      "[302]\ttraining's binary_logloss: 0.523369\n",
      "[303]\ttraining's binary_logloss: 0.523183\n",
      "[304]\ttraining's binary_logloss: 0.52297\n",
      "[305]\ttraining's binary_logloss: 0.522768\n",
      "[306]\ttraining's binary_logloss: 0.522536\n",
      "[307]\ttraining's binary_logloss: 0.522337\n",
      "[308]\ttraining's binary_logloss: 0.522106\n",
      "[309]\ttraining's binary_logloss: 0.521873\n",
      "[310]\ttraining's binary_logloss: 0.521695\n",
      "[311]\ttraining's binary_logloss: 0.521506\n",
      "[312]\ttraining's binary_logloss: 0.521317\n",
      "[313]\ttraining's binary_logloss: 0.521139\n",
      "[314]\ttraining's binary_logloss: 0.520921\n",
      "[315]\ttraining's binary_logloss: 0.520732\n",
      "[316]\ttraining's binary_logloss: 0.520524\n",
      "[317]\ttraining's binary_logloss: 0.520338\n",
      "[318]\ttraining's binary_logloss: 0.520165\n",
      "[319]\ttraining's binary_logloss: 0.519975\n",
      "[320]\ttraining's binary_logloss: 0.519771\n",
      "[321]\ttraining's binary_logloss: 0.519601\n",
      "[322]\ttraining's binary_logloss: 0.519456\n",
      "[323]\ttraining's binary_logloss: 0.519304\n",
      "[324]\ttraining's binary_logloss: 0.519149\n",
      "[325]\ttraining's binary_logloss: 0.519007\n",
      "[326]\ttraining's binary_logloss: 0.518838\n",
      "[327]\ttraining's binary_logloss: 0.518647\n",
      "[328]\ttraining's binary_logloss: 0.518484\n",
      "[329]\ttraining's binary_logloss: 0.518358\n",
      "[330]\ttraining's binary_logloss: 0.51821\n",
      "[331]\ttraining's binary_logloss: 0.517972\n",
      "[332]\ttraining's binary_logloss: 0.517757\n",
      "[333]\ttraining's binary_logloss: 0.517528\n",
      "[334]\ttraining's binary_logloss: 0.51731\n",
      "[335]\ttraining's binary_logloss: 0.517095\n",
      "[336]\ttraining's binary_logloss: 0.516899\n",
      "[337]\ttraining's binary_logloss: 0.516721\n",
      "[338]\ttraining's binary_logloss: 0.516544\n",
      "[339]\ttraining's binary_logloss: 0.516372\n",
      "[340]\ttraining's binary_logloss: 0.516163\n",
      "[341]\ttraining's binary_logloss: 0.515918\n",
      "[342]\ttraining's binary_logloss: 0.515699\n",
      "[343]\ttraining's binary_logloss: 0.515461\n",
      "[344]\ttraining's binary_logloss: 0.515228\n",
      "[345]\ttraining's binary_logloss: 0.515013\n",
      "[346]\ttraining's binary_logloss: 0.514853\n",
      "[347]\ttraining's binary_logloss: 0.514687\n",
      "[348]\ttraining's binary_logloss: 0.514533\n",
      "[349]\ttraining's binary_logloss: 0.514371\n",
      "[350]\ttraining's binary_logloss: 0.514216\n",
      "[351]\ttraining's binary_logloss: 0.514009\n",
      "[352]\ttraining's binary_logloss: 0.513769\n",
      "[353]\ttraining's binary_logloss: 0.513541\n",
      "[354]\ttraining's binary_logloss: 0.513308\n",
      "[355]\ttraining's binary_logloss: 0.513102\n",
      "[356]\ttraining's binary_logloss: 0.512893\n",
      "[357]\ttraining's binary_logloss: 0.512706\n",
      "[358]\ttraining's binary_logloss: 0.512524\n",
      "[359]\ttraining's binary_logloss: 0.512367\n",
      "[360]\ttraining's binary_logloss: 0.512172\n",
      "[361]\ttraining's binary_logloss: 0.511959\n",
      "[362]\ttraining's binary_logloss: 0.511786\n",
      "[363]\ttraining's binary_logloss: 0.511584\n",
      "[364]\ttraining's binary_logloss: 0.511419\n",
      "[365]\ttraining's binary_logloss: 0.511253\n",
      "[366]\ttraining's binary_logloss: 0.511064\n",
      "[367]\ttraining's binary_logloss: 0.510875\n",
      "[368]\ttraining's binary_logloss: 0.510717\n",
      "[369]\ttraining's binary_logloss: 0.510545\n",
      "[370]\ttraining's binary_logloss: 0.510361\n",
      "[371]\ttraining's binary_logloss: 0.510134\n",
      "[372]\ttraining's binary_logloss: 0.50991\n",
      "[373]\ttraining's binary_logloss: 0.50969\n",
      "[374]\ttraining's binary_logloss: 0.509496\n",
      "[375]\ttraining's binary_logloss: 0.509291\n",
      "[376]\ttraining's binary_logloss: 0.509053\n",
      "[377]\ttraining's binary_logloss: 0.508817\n",
      "[378]\ttraining's binary_logloss: 0.508655\n",
      "[379]\ttraining's binary_logloss: 0.508491\n",
      "[380]\ttraining's binary_logloss: 0.508251\n",
      "[381]\ttraining's binary_logloss: 0.50806\n",
      "[382]\ttraining's binary_logloss: 0.50786\n",
      "[383]\ttraining's binary_logloss: 0.507661\n",
      "[384]\ttraining's binary_logloss: 0.50748\n",
      "[385]\ttraining's binary_logloss: 0.507305\n",
      "[386]\ttraining's binary_logloss: 0.507099\n",
      "[387]\ttraining's binary_logloss: 0.506915\n",
      "[388]\ttraining's binary_logloss: 0.506715\n",
      "[389]\ttraining's binary_logloss: 0.506534\n",
      "[390]\ttraining's binary_logloss: 0.506344\n",
      "[391]\ttraining's binary_logloss: 0.506122\n",
      "[392]\ttraining's binary_logloss: 0.505861\n",
      "[393]\ttraining's binary_logloss: 0.505635\n",
      "[394]\ttraining's binary_logloss: 0.505366\n",
      "[395]\ttraining's binary_logloss: 0.505148\n",
      "[396]\ttraining's binary_logloss: 0.504929\n",
      "[397]\ttraining's binary_logloss: 0.504683\n",
      "[398]\ttraining's binary_logloss: 0.504477\n",
      "[399]\ttraining's binary_logloss: 0.504252\n",
      "[400]\ttraining's binary_logloss: 0.504043\n",
      "[401]\ttraining's binary_logloss: 0.503844\n",
      "[402]\ttraining's binary_logloss: 0.50366\n",
      "[403]\ttraining's binary_logloss: 0.50347\n",
      "[404]\ttraining's binary_logloss: 0.50326\n",
      "[405]\ttraining's binary_logloss: 0.503067\n",
      "[406]\ttraining's binary_logloss: 0.502844\n",
      "[407]\ttraining's binary_logloss: 0.502646\n",
      "[408]\ttraining's binary_logloss: 0.502446\n",
      "[409]\ttraining's binary_logloss: 0.502254\n",
      "[410]\ttraining's binary_logloss: 0.502051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[411]\ttraining's binary_logloss: 0.501834\n",
      "[412]\ttraining's binary_logloss: 0.501665\n",
      "[413]\ttraining's binary_logloss: 0.501457\n",
      "[414]\ttraining's binary_logloss: 0.50126\n",
      "[415]\ttraining's binary_logloss: 0.501071\n",
      "[416]\ttraining's binary_logloss: 0.500859\n",
      "[417]\ttraining's binary_logloss: 0.500677\n",
      "[418]\ttraining's binary_logloss: 0.500481\n",
      "[419]\ttraining's binary_logloss: 0.500287\n",
      "[420]\ttraining's binary_logloss: 0.500085\n",
      "[421]\ttraining's binary_logloss: 0.499958\n",
      "[422]\ttraining's binary_logloss: 0.499808\n",
      "[423]\ttraining's binary_logloss: 0.49967\n",
      "[424]\ttraining's binary_logloss: 0.499529\n",
      "[425]\ttraining's binary_logloss: 0.499378\n",
      "[426]\ttraining's binary_logloss: 0.499186\n",
      "[427]\ttraining's binary_logloss: 0.49898\n",
      "[428]\ttraining's binary_logloss: 0.498782\n",
      "[429]\ttraining's binary_logloss: 0.498595\n",
      "[430]\ttraining's binary_logloss: 0.498355\n",
      "[431]\ttraining's binary_logloss: 0.498207\n",
      "[432]\ttraining's binary_logloss: 0.498054\n",
      "[433]\ttraining's binary_logloss: 0.497887\n",
      "[434]\ttraining's binary_logloss: 0.497728\n",
      "[435]\ttraining's binary_logloss: 0.497556\n",
      "[436]\ttraining's binary_logloss: 0.497363\n",
      "[437]\ttraining's binary_logloss: 0.497134\n",
      "[438]\ttraining's binary_logloss: 0.49692\n",
      "[439]\ttraining's binary_logloss: 0.496731\n",
      "[440]\ttraining's binary_logloss: 0.496544\n",
      "[441]\ttraining's binary_logloss: 0.496326\n",
      "[442]\ttraining's binary_logloss: 0.4961\n",
      "[443]\ttraining's binary_logloss: 0.495875\n",
      "[444]\ttraining's binary_logloss: 0.495649\n",
      "[445]\ttraining's binary_logloss: 0.495439\n",
      "[446]\ttraining's binary_logloss: 0.495264\n",
      "[447]\ttraining's binary_logloss: 0.495075\n",
      "[448]\ttraining's binary_logloss: 0.494885\n",
      "[449]\ttraining's binary_logloss: 0.494729\n",
      "[450]\ttraining's binary_logloss: 0.494565\n",
      "[451]\ttraining's binary_logloss: 0.494431\n",
      "[452]\ttraining's binary_logloss: 0.494268\n",
      "[453]\ttraining's binary_logloss: 0.494134\n",
      "[454]\ttraining's binary_logloss: 0.494004\n",
      "[455]\ttraining's binary_logloss: 0.493836\n",
      "[456]\ttraining's binary_logloss: 0.493642\n",
      "[457]\ttraining's binary_logloss: 0.493469\n",
      "[458]\ttraining's binary_logloss: 0.493293\n",
      "[459]\ttraining's binary_logloss: 0.493127\n",
      "[460]\ttraining's binary_logloss: 0.492944\n",
      "[461]\ttraining's binary_logloss: 0.49273\n",
      "[462]\ttraining's binary_logloss: 0.492519\n",
      "[463]\ttraining's binary_logloss: 0.492303\n",
      "[464]\ttraining's binary_logloss: 0.492077\n",
      "[465]\ttraining's binary_logloss: 0.491851\n",
      "[466]\ttraining's binary_logloss: 0.49162\n",
      "[467]\ttraining's binary_logloss: 0.49139\n",
      "[468]\ttraining's binary_logloss: 0.491172\n",
      "[469]\ttraining's binary_logloss: 0.490909\n",
      "[470]\ttraining's binary_logloss: 0.49071\n",
      "[471]\ttraining's binary_logloss: 0.490506\n",
      "[472]\ttraining's binary_logloss: 0.49032\n",
      "[473]\ttraining's binary_logloss: 0.490124\n",
      "[474]\ttraining's binary_logloss: 0.489922\n",
      "[475]\ttraining's binary_logloss: 0.489746\n",
      "[476]\ttraining's binary_logloss: 0.489565\n",
      "[477]\ttraining's binary_logloss: 0.489382\n",
      "[478]\ttraining's binary_logloss: 0.489214\n",
      "[479]\ttraining's binary_logloss: 0.489041\n",
      "[480]\ttraining's binary_logloss: 0.488871\n",
      "[481]\ttraining's binary_logloss: 0.488663\n",
      "[482]\ttraining's binary_logloss: 0.488458\n",
      "[483]\ttraining's binary_logloss: 0.48825\n",
      "[484]\ttraining's binary_logloss: 0.488065\n",
      "[485]\ttraining's binary_logloss: 0.487889\n",
      "[486]\ttraining's binary_logloss: 0.487704\n",
      "[487]\ttraining's binary_logloss: 0.487532\n",
      "[488]\ttraining's binary_logloss: 0.487364\n",
      "[489]\ttraining's binary_logloss: 0.487186\n",
      "[490]\ttraining's binary_logloss: 0.487021\n",
      "[491]\ttraining's binary_logloss: 0.486869\n",
      "[492]\ttraining's binary_logloss: 0.486704\n",
      "[493]\ttraining's binary_logloss: 0.486554\n",
      "[494]\ttraining's binary_logloss: 0.486383\n",
      "[495]\ttraining's binary_logloss: 0.486241\n",
      "[496]\ttraining's binary_logloss: 0.48602\n",
      "[497]\ttraining's binary_logloss: 0.485789\n",
      "[498]\ttraining's binary_logloss: 0.485585\n",
      "[499]\ttraining's binary_logloss: 0.485372\n",
      "[500]\ttraining's binary_logloss: 0.485145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613955\n",
      "[2]\ttraining's binary_logloss: 0.61241\n",
      "[3]\ttraining's binary_logloss: 0.610885\n",
      "[4]\ttraining's binary_logloss: 0.609449\n",
      "[5]\ttraining's binary_logloss: 0.607986\n",
      "[6]\ttraining's binary_logloss: 0.606581\n",
      "[7]\ttraining's binary_logloss: 0.605169\n",
      "[8]\ttraining's binary_logloss: 0.603895\n",
      "[9]\ttraining's binary_logloss: 0.602563\n",
      "[10]\ttraining's binary_logloss: 0.601268\n",
      "[11]\ttraining's binary_logloss: 0.600027\n",
      "[12]\ttraining's binary_logloss: 0.598776\n",
      "[13]\ttraining's binary_logloss: 0.597609\n",
      "[14]\ttraining's binary_logloss: 0.596446\n",
      "[15]\ttraining's binary_logloss: 0.595334\n",
      "[16]\ttraining's binary_logloss: 0.59427\n",
      "[17]\ttraining's binary_logloss: 0.593208\n",
      "[18]\ttraining's binary_logloss: 0.592061\n",
      "[19]\ttraining's binary_logloss: 0.590976\n",
      "[20]\ttraining's binary_logloss: 0.59\n",
      "[21]\ttraining's binary_logloss: 0.58907\n",
      "[22]\ttraining's binary_logloss: 0.588102\n",
      "[23]\ttraining's binary_logloss: 0.587174\n",
      "[24]\ttraining's binary_logloss: 0.58625\n",
      "[25]\ttraining's binary_logloss: 0.585342\n",
      "[26]\ttraining's binary_logloss: 0.584504\n",
      "[27]\ttraining's binary_logloss: 0.583664\n",
      "[28]\ttraining's binary_logloss: 0.582817\n",
      "[29]\ttraining's binary_logloss: 0.582023\n",
      "[30]\ttraining's binary_logloss: 0.581273\n",
      "[31]\ttraining's binary_logloss: 0.580456\n",
      "[32]\ttraining's binary_logloss: 0.579739\n",
      "[33]\ttraining's binary_logloss: 0.578917\n",
      "[34]\ttraining's binary_logloss: 0.578128\n",
      "[35]\ttraining's binary_logloss: 0.577419\n",
      "[36]\ttraining's binary_logloss: 0.576679\n",
      "[37]\ttraining's binary_logloss: 0.57602\n",
      "[38]\ttraining's binary_logloss: 0.575397\n",
      "[39]\ttraining's binary_logloss: 0.574768\n",
      "[40]\ttraining's binary_logloss: 0.574213\n",
      "[41]\ttraining's binary_logloss: 0.573551\n",
      "[42]\ttraining's binary_logloss: 0.572917\n",
      "[43]\ttraining's binary_logloss: 0.57226\n",
      "[44]\ttraining's binary_logloss: 0.571631\n",
      "[45]\ttraining's binary_logloss: 0.571009\n",
      "[46]\ttraining's binary_logloss: 0.570458\n",
      "[47]\ttraining's binary_logloss: 0.569927\n",
      "[48]\ttraining's binary_logloss: 0.569339\n",
      "[49]\ttraining's binary_logloss: 0.568837\n",
      "[50]\ttraining's binary_logloss: 0.568322\n",
      "[51]\ttraining's binary_logloss: 0.567802\n",
      "[52]\ttraining's binary_logloss: 0.567246\n",
      "[53]\ttraining's binary_logloss: 0.566759\n",
      "[54]\ttraining's binary_logloss: 0.566301\n",
      "[55]\ttraining's binary_logloss: 0.565843\n",
      "[56]\ttraining's binary_logloss: 0.56533\n",
      "[57]\ttraining's binary_logloss: 0.56489\n",
      "[58]\ttraining's binary_logloss: 0.564383\n",
      "[59]\ttraining's binary_logloss: 0.563936\n",
      "[60]\ttraining's binary_logloss: 0.5635\n",
      "[61]\ttraining's binary_logloss: 0.563069\n",
      "[62]\ttraining's binary_logloss: 0.562639\n",
      "[63]\ttraining's binary_logloss: 0.562228\n",
      "[64]\ttraining's binary_logloss: 0.561835\n",
      "[65]\ttraining's binary_logloss: 0.561434\n",
      "[66]\ttraining's binary_logloss: 0.561011\n",
      "[67]\ttraining's binary_logloss: 0.560609\n",
      "[68]\ttraining's binary_logloss: 0.560159\n",
      "[69]\ttraining's binary_logloss: 0.559792\n",
      "[70]\ttraining's binary_logloss: 0.559459\n",
      "[71]\ttraining's binary_logloss: 0.559136\n",
      "[72]\ttraining's binary_logloss: 0.558822\n",
      "[73]\ttraining's binary_logloss: 0.558523\n",
      "[74]\ttraining's binary_logloss: 0.558138\n",
      "[75]\ttraining's binary_logloss: 0.557801\n",
      "[76]\ttraining's binary_logloss: 0.557425\n",
      "[77]\ttraining's binary_logloss: 0.557096\n",
      "[78]\ttraining's binary_logloss: 0.556746\n",
      "[79]\ttraining's binary_logloss: 0.556463\n",
      "[80]\ttraining's binary_logloss: 0.556133\n",
      "[81]\ttraining's binary_logloss: 0.55584\n",
      "[82]\ttraining's binary_logloss: 0.555501\n",
      "[83]\ttraining's binary_logloss: 0.555193\n",
      "[84]\ttraining's binary_logloss: 0.554855\n",
      "[85]\ttraining's binary_logloss: 0.554563\n",
      "[86]\ttraining's binary_logloss: 0.554302\n",
      "[87]\ttraining's binary_logloss: 0.553999\n",
      "[88]\ttraining's binary_logloss: 0.553688\n",
      "[89]\ttraining's binary_logloss: 0.553406\n",
      "[90]\ttraining's binary_logloss: 0.553119\n",
      "[91]\ttraining's binary_logloss: 0.552841\n",
      "[92]\ttraining's binary_logloss: 0.552559\n",
      "[93]\ttraining's binary_logloss: 0.552281\n",
      "[94]\ttraining's binary_logloss: 0.551992\n",
      "[95]\ttraining's binary_logloss: 0.551713\n",
      "[96]\ttraining's binary_logloss: 0.551416\n",
      "[97]\ttraining's binary_logloss: 0.551149\n",
      "[98]\ttraining's binary_logloss: 0.550885\n",
      "[99]\ttraining's binary_logloss: 0.550611\n",
      "[100]\ttraining's binary_logloss: 0.550378\n",
      "[101]\ttraining's binary_logloss: 0.550095\n",
      "[102]\ttraining's binary_logloss: 0.549821\n",
      "[103]\ttraining's binary_logloss: 0.549565\n",
      "[104]\ttraining's binary_logloss: 0.549314\n",
      "[105]\ttraining's binary_logloss: 0.549064\n",
      "[106]\ttraining's binary_logloss: 0.548826\n",
      "[107]\ttraining's binary_logloss: 0.548546\n",
      "[108]\ttraining's binary_logloss: 0.54828\n",
      "[109]\ttraining's binary_logloss: 0.548018\n",
      "[110]\ttraining's binary_logloss: 0.547765\n",
      "[111]\ttraining's binary_logloss: 0.547494\n",
      "[112]\ttraining's binary_logloss: 0.547215\n",
      "[113]\ttraining's binary_logloss: 0.546943\n",
      "[114]\ttraining's binary_logloss: 0.546705\n",
      "[115]\ttraining's binary_logloss: 0.546446\n",
      "[116]\ttraining's binary_logloss: 0.54621\n",
      "[117]\ttraining's binary_logloss: 0.545968\n",
      "[118]\ttraining's binary_logloss: 0.545744\n",
      "[119]\ttraining's binary_logloss: 0.54551\n",
      "[120]\ttraining's binary_logloss: 0.545273\n",
      "[121]\ttraining's binary_logloss: 0.54502\n",
      "[122]\ttraining's binary_logloss: 0.544824\n",
      "[123]\ttraining's binary_logloss: 0.544632\n",
      "[124]\ttraining's binary_logloss: 0.544453\n",
      "[125]\ttraining's binary_logloss: 0.544283\n",
      "[126]\ttraining's binary_logloss: 0.544017\n",
      "[127]\ttraining's binary_logloss: 0.543747\n",
      "[128]\ttraining's binary_logloss: 0.543487\n",
      "[129]\ttraining's binary_logloss: 0.543235\n",
      "[130]\ttraining's binary_logloss: 0.542989\n",
      "[131]\ttraining's binary_logloss: 0.542719\n",
      "[132]\ttraining's binary_logloss: 0.542462\n",
      "[133]\ttraining's binary_logloss: 0.542219\n",
      "[134]\ttraining's binary_logloss: 0.541975\n",
      "[135]\ttraining's binary_logloss: 0.541722\n",
      "[136]\ttraining's binary_logloss: 0.541475\n",
      "[137]\ttraining's binary_logloss: 0.541244\n",
      "[138]\ttraining's binary_logloss: 0.541022\n",
      "[139]\ttraining's binary_logloss: 0.540788\n",
      "[140]\ttraining's binary_logloss: 0.540555\n",
      "[141]\ttraining's binary_logloss: 0.540336\n",
      "[142]\ttraining's binary_logloss: 0.540112\n",
      "[143]\ttraining's binary_logloss: 0.539881\n",
      "[144]\ttraining's binary_logloss: 0.539634\n",
      "[145]\ttraining's binary_logloss: 0.539362\n",
      "[146]\ttraining's binary_logloss: 0.539084\n",
      "[147]\ttraining's binary_logloss: 0.538849\n",
      "[148]\ttraining's binary_logloss: 0.538617\n",
      "[149]\ttraining's binary_logloss: 0.538399\n",
      "[150]\ttraining's binary_logloss: 0.538154\n",
      "[151]\ttraining's binary_logloss: 0.537917\n",
      "[152]\ttraining's binary_logloss: 0.537648\n",
      "[153]\ttraining's binary_logloss: 0.537423\n",
      "[154]\ttraining's binary_logloss: 0.537177\n",
      "[155]\ttraining's binary_logloss: 0.536925\n",
      "[156]\ttraining's binary_logloss: 0.536703\n",
      "[157]\ttraining's binary_logloss: 0.536489\n",
      "[158]\ttraining's binary_logloss: 0.536276\n",
      "[159]\ttraining's binary_logloss: 0.536077\n",
      "[160]\ttraining's binary_logloss: 0.535872\n",
      "[161]\ttraining's binary_logloss: 0.535639\n",
      "[162]\ttraining's binary_logloss: 0.53539\n",
      "[163]\ttraining's binary_logloss: 0.535178\n",
      "[164]\ttraining's binary_logloss: 0.534922\n",
      "[165]\ttraining's binary_logloss: 0.534666\n",
      "[166]\ttraining's binary_logloss: 0.534401\n",
      "[167]\ttraining's binary_logloss: 0.534133\n",
      "[168]\ttraining's binary_logloss: 0.533894\n",
      "[169]\ttraining's binary_logloss: 0.533653\n",
      "[170]\ttraining's binary_logloss: 0.53341\n",
      "[171]\ttraining's binary_logloss: 0.533128\n",
      "[172]\ttraining's binary_logloss: 0.532864\n",
      "[173]\ttraining's binary_logloss: 0.532617\n",
      "[174]\ttraining's binary_logloss: 0.532349\n",
      "[175]\ttraining's binary_logloss: 0.532116\n",
      "[176]\ttraining's binary_logloss: 0.531909\n",
      "[177]\ttraining's binary_logloss: 0.53166\n",
      "[178]\ttraining's binary_logloss: 0.531432\n",
      "[179]\ttraining's binary_logloss: 0.531178\n",
      "[180]\ttraining's binary_logloss: 0.530968\n",
      "[181]\ttraining's binary_logloss: 0.530746\n",
      "[182]\ttraining's binary_logloss: 0.530481\n",
      "[183]\ttraining's binary_logloss: 0.530252\n",
      "[184]\ttraining's binary_logloss: 0.530024\n",
      "[185]\ttraining's binary_logloss: 0.529761\n",
      "[186]\ttraining's binary_logloss: 0.529552\n",
      "[187]\ttraining's binary_logloss: 0.529299\n",
      "[188]\ttraining's binary_logloss: 0.529091\n",
      "[189]\ttraining's binary_logloss: 0.528902\n",
      "[190]\ttraining's binary_logloss: 0.528707\n",
      "[191]\ttraining's binary_logloss: 0.528466\n",
      "[192]\ttraining's binary_logloss: 0.528219\n",
      "[193]\ttraining's binary_logloss: 0.527975\n",
      "[194]\ttraining's binary_logloss: 0.527744\n",
      "[195]\ttraining's binary_logloss: 0.527539\n",
      "[196]\ttraining's binary_logloss: 0.527293\n",
      "[197]\ttraining's binary_logloss: 0.527061\n",
      "[198]\ttraining's binary_logloss: 0.526823\n",
      "[199]\ttraining's binary_logloss: 0.526575\n",
      "[200]\ttraining's binary_logloss: 0.52635\n",
      "[201]\ttraining's binary_logloss: 0.526159\n",
      "[202]\ttraining's binary_logloss: 0.525933\n",
      "[203]\ttraining's binary_logloss: 0.525709\n",
      "[204]\ttraining's binary_logloss: 0.525501\n",
      "[205]\ttraining's binary_logloss: 0.52528\n",
      "[206]\ttraining's binary_logloss: 0.525042\n",
      "[207]\ttraining's binary_logloss: 0.524828\n",
      "[208]\ttraining's binary_logloss: 0.524616\n",
      "[209]\ttraining's binary_logloss: 0.524393\n",
      "[210]\ttraining's binary_logloss: 0.524185\n",
      "[211]\ttraining's binary_logloss: 0.523925\n",
      "[212]\ttraining's binary_logloss: 0.523695\n",
      "[213]\ttraining's binary_logloss: 0.523482\n",
      "[214]\ttraining's binary_logloss: 0.523257\n",
      "[215]\ttraining's binary_logloss: 0.523054\n",
      "[216]\ttraining's binary_logloss: 0.522846\n",
      "[217]\ttraining's binary_logloss: 0.52261\n",
      "[218]\ttraining's binary_logloss: 0.522362\n",
      "[219]\ttraining's binary_logloss: 0.522154\n",
      "[220]\ttraining's binary_logloss: 0.52193\n",
      "[221]\ttraining's binary_logloss: 0.521638\n",
      "[222]\ttraining's binary_logloss: 0.521362\n",
      "[223]\ttraining's binary_logloss: 0.521076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[224]\ttraining's binary_logloss: 0.52082\n",
      "[225]\ttraining's binary_logloss: 0.52056\n",
      "[226]\ttraining's binary_logloss: 0.520348\n",
      "[227]\ttraining's binary_logloss: 0.520143\n",
      "[228]\ttraining's binary_logloss: 0.519914\n",
      "[229]\ttraining's binary_logloss: 0.519698\n",
      "[230]\ttraining's binary_logloss: 0.519509\n",
      "[231]\ttraining's binary_logloss: 0.519254\n",
      "[232]\ttraining's binary_logloss: 0.519021\n",
      "[233]\ttraining's binary_logloss: 0.518791\n",
      "[234]\ttraining's binary_logloss: 0.51854\n",
      "[235]\ttraining's binary_logloss: 0.518278\n",
      "[236]\ttraining's binary_logloss: 0.518026\n",
      "[237]\ttraining's binary_logloss: 0.517769\n",
      "[238]\ttraining's binary_logloss: 0.517532\n",
      "[239]\ttraining's binary_logloss: 0.517279\n",
      "[240]\ttraining's binary_logloss: 0.517037\n",
      "[241]\ttraining's binary_logloss: 0.516764\n",
      "[242]\ttraining's binary_logloss: 0.516532\n",
      "[243]\ttraining's binary_logloss: 0.51628\n",
      "[244]\ttraining's binary_logloss: 0.516001\n",
      "[245]\ttraining's binary_logloss: 0.515749\n",
      "[246]\ttraining's binary_logloss: 0.515553\n",
      "[247]\ttraining's binary_logloss: 0.51538\n",
      "[248]\ttraining's binary_logloss: 0.515184\n",
      "[249]\ttraining's binary_logloss: 0.514997\n",
      "[250]\ttraining's binary_logloss: 0.514831\n",
      "[251]\ttraining's binary_logloss: 0.51464\n",
      "[252]\ttraining's binary_logloss: 0.514386\n",
      "[253]\ttraining's binary_logloss: 0.51415\n",
      "[254]\ttraining's binary_logloss: 0.513912\n",
      "[255]\ttraining's binary_logloss: 0.513699\n",
      "[256]\ttraining's binary_logloss: 0.513459\n",
      "[257]\ttraining's binary_logloss: 0.51323\n",
      "[258]\ttraining's binary_logloss: 0.512999\n",
      "[259]\ttraining's binary_logloss: 0.512759\n",
      "[260]\ttraining's binary_logloss: 0.51253\n",
      "[261]\ttraining's binary_logloss: 0.512288\n",
      "[262]\ttraining's binary_logloss: 0.51206\n",
      "[263]\ttraining's binary_logloss: 0.511831\n",
      "[264]\ttraining's binary_logloss: 0.511568\n",
      "[265]\ttraining's binary_logloss: 0.511315\n",
      "[266]\ttraining's binary_logloss: 0.51112\n",
      "[267]\ttraining's binary_logloss: 0.510868\n",
      "[268]\ttraining's binary_logloss: 0.510655\n",
      "[269]\ttraining's binary_logloss: 0.510473\n",
      "[270]\ttraining's binary_logloss: 0.510284\n",
      "[271]\ttraining's binary_logloss: 0.510015\n",
      "[272]\ttraining's binary_logloss: 0.509763\n",
      "[273]\ttraining's binary_logloss: 0.509535\n",
      "[274]\ttraining's binary_logloss: 0.509304\n",
      "[275]\ttraining's binary_logloss: 0.509067\n",
      "[276]\ttraining's binary_logloss: 0.508808\n",
      "[277]\ttraining's binary_logloss: 0.508559\n",
      "[278]\ttraining's binary_logloss: 0.508286\n",
      "[279]\ttraining's binary_logloss: 0.508056\n",
      "[280]\ttraining's binary_logloss: 0.507859\n",
      "[281]\ttraining's binary_logloss: 0.507632\n",
      "[282]\ttraining's binary_logloss: 0.507412\n",
      "[283]\ttraining's binary_logloss: 0.507194\n",
      "[284]\ttraining's binary_logloss: 0.506983\n",
      "[285]\ttraining's binary_logloss: 0.506781\n",
      "[286]\ttraining's binary_logloss: 0.506527\n",
      "[287]\ttraining's binary_logloss: 0.506276\n",
      "[288]\ttraining's binary_logloss: 0.506041\n",
      "[289]\ttraining's binary_logloss: 0.505784\n",
      "[290]\ttraining's binary_logloss: 0.505555\n",
      "[291]\ttraining's binary_logloss: 0.505275\n",
      "[292]\ttraining's binary_logloss: 0.505023\n",
      "[293]\ttraining's binary_logloss: 0.504762\n",
      "[294]\ttraining's binary_logloss: 0.504522\n",
      "[295]\ttraining's binary_logloss: 0.504251\n",
      "[296]\ttraining's binary_logloss: 0.503961\n",
      "[297]\ttraining's binary_logloss: 0.503713\n",
      "[298]\ttraining's binary_logloss: 0.503469\n",
      "[299]\ttraining's binary_logloss: 0.503218\n",
      "[300]\ttraining's binary_logloss: 0.502991\n",
      "[301]\ttraining's binary_logloss: 0.502732\n",
      "[302]\ttraining's binary_logloss: 0.502467\n",
      "[303]\ttraining's binary_logloss: 0.502208\n",
      "[304]\ttraining's binary_logloss: 0.50195\n",
      "[305]\ttraining's binary_logloss: 0.501692\n",
      "[306]\ttraining's binary_logloss: 0.501462\n",
      "[307]\ttraining's binary_logloss: 0.501201\n",
      "[308]\ttraining's binary_logloss: 0.500984\n",
      "[309]\ttraining's binary_logloss: 0.500755\n",
      "[310]\ttraining's binary_logloss: 0.500526\n",
      "[311]\ttraining's binary_logloss: 0.500288\n",
      "[312]\ttraining's binary_logloss: 0.500071\n",
      "[313]\ttraining's binary_logloss: 0.499884\n",
      "[314]\ttraining's binary_logloss: 0.499697\n",
      "[315]\ttraining's binary_logloss: 0.499459\n",
      "[316]\ttraining's binary_logloss: 0.499205\n",
      "[317]\ttraining's binary_logloss: 0.498976\n",
      "[318]\ttraining's binary_logloss: 0.498739\n",
      "[319]\ttraining's binary_logloss: 0.49851\n",
      "[320]\ttraining's binary_logloss: 0.498289\n",
      "[321]\ttraining's binary_logloss: 0.498007\n",
      "[322]\ttraining's binary_logloss: 0.497741\n",
      "[323]\ttraining's binary_logloss: 0.497449\n",
      "[324]\ttraining's binary_logloss: 0.497204\n",
      "[325]\ttraining's binary_logloss: 0.496947\n",
      "[326]\ttraining's binary_logloss: 0.496669\n",
      "[327]\ttraining's binary_logloss: 0.496399\n",
      "[328]\ttraining's binary_logloss: 0.496141\n",
      "[329]\ttraining's binary_logloss: 0.495877\n",
      "[330]\ttraining's binary_logloss: 0.495622\n",
      "[331]\ttraining's binary_logloss: 0.495319\n",
      "[332]\ttraining's binary_logloss: 0.495066\n",
      "[333]\ttraining's binary_logloss: 0.494815\n",
      "[334]\ttraining's binary_logloss: 0.494577\n",
      "[335]\ttraining's binary_logloss: 0.494344\n",
      "[336]\ttraining's binary_logloss: 0.49407\n",
      "[337]\ttraining's binary_logloss: 0.493848\n",
      "[338]\ttraining's binary_logloss: 0.493591\n",
      "[339]\ttraining's binary_logloss: 0.493374\n",
      "[340]\ttraining's binary_logloss: 0.493153\n",
      "[341]\ttraining's binary_logloss: 0.492922\n",
      "[342]\ttraining's binary_logloss: 0.492689\n",
      "[343]\ttraining's binary_logloss: 0.492468\n",
      "[344]\ttraining's binary_logloss: 0.49228\n",
      "[345]\ttraining's binary_logloss: 0.492046\n",
      "[346]\ttraining's binary_logloss: 0.491782\n",
      "[347]\ttraining's binary_logloss: 0.491534\n",
      "[348]\ttraining's binary_logloss: 0.491255\n",
      "[349]\ttraining's binary_logloss: 0.491011\n",
      "[350]\ttraining's binary_logloss: 0.490735\n",
      "[351]\ttraining's binary_logloss: 0.490472\n",
      "[352]\ttraining's binary_logloss: 0.490217\n",
      "[353]\ttraining's binary_logloss: 0.489952\n",
      "[354]\ttraining's binary_logloss: 0.489686\n",
      "[355]\ttraining's binary_logloss: 0.489437\n",
      "[356]\ttraining's binary_logloss: 0.489126\n",
      "[357]\ttraining's binary_logloss: 0.488879\n",
      "[358]\ttraining's binary_logloss: 0.488653\n",
      "[359]\ttraining's binary_logloss: 0.488355\n",
      "[360]\ttraining's binary_logloss: 0.48812\n",
      "[361]\ttraining's binary_logloss: 0.487851\n",
      "[362]\ttraining's binary_logloss: 0.487587\n",
      "[363]\ttraining's binary_logloss: 0.487308\n",
      "[364]\ttraining's binary_logloss: 0.487036\n",
      "[365]\ttraining's binary_logloss: 0.486776\n",
      "[366]\ttraining's binary_logloss: 0.486546\n",
      "[367]\ttraining's binary_logloss: 0.4863\n",
      "[368]\ttraining's binary_logloss: 0.486072\n",
      "[369]\ttraining's binary_logloss: 0.485857\n",
      "[370]\ttraining's binary_logloss: 0.48566\n",
      "[371]\ttraining's binary_logloss: 0.485433\n",
      "[372]\ttraining's binary_logloss: 0.485196\n",
      "[373]\ttraining's binary_logloss: 0.484954\n",
      "[374]\ttraining's binary_logloss: 0.484736\n",
      "[375]\ttraining's binary_logloss: 0.484483\n",
      "[376]\ttraining's binary_logloss: 0.484219\n",
      "[377]\ttraining's binary_logloss: 0.483953\n",
      "[378]\ttraining's binary_logloss: 0.483732\n",
      "[379]\ttraining's binary_logloss: 0.483475\n",
      "[380]\ttraining's binary_logloss: 0.483257\n",
      "[381]\ttraining's binary_logloss: 0.483032\n",
      "[382]\ttraining's binary_logloss: 0.482777\n",
      "[383]\ttraining's binary_logloss: 0.482568\n",
      "[384]\ttraining's binary_logloss: 0.482364\n",
      "[385]\ttraining's binary_logloss: 0.482115\n",
      "[386]\ttraining's binary_logloss: 0.481806\n",
      "[387]\ttraining's binary_logloss: 0.481473\n",
      "[388]\ttraining's binary_logloss: 0.481153\n",
      "[389]\ttraining's binary_logloss: 0.480867\n",
      "[390]\ttraining's binary_logloss: 0.48063\n",
      "[391]\ttraining's binary_logloss: 0.480418\n",
      "[392]\ttraining's binary_logloss: 0.480184\n",
      "[393]\ttraining's binary_logloss: 0.479952\n",
      "[394]\ttraining's binary_logloss: 0.479724\n",
      "[395]\ttraining's binary_logloss: 0.479485\n",
      "[396]\ttraining's binary_logloss: 0.479225\n",
      "[397]\ttraining's binary_logloss: 0.478928\n",
      "[398]\ttraining's binary_logloss: 0.478678\n",
      "[399]\ttraining's binary_logloss: 0.478435\n",
      "[400]\ttraining's binary_logloss: 0.478163\n",
      "[401]\ttraining's binary_logloss: 0.477881\n",
      "[402]\ttraining's binary_logloss: 0.477591\n",
      "[403]\ttraining's binary_logloss: 0.477315\n",
      "[404]\ttraining's binary_logloss: 0.477032\n",
      "[405]\ttraining's binary_logloss: 0.476763\n",
      "[406]\ttraining's binary_logloss: 0.476544\n",
      "[407]\ttraining's binary_logloss: 0.47631\n",
      "[408]\ttraining's binary_logloss: 0.476101\n",
      "[409]\ttraining's binary_logloss: 0.475871\n",
      "[410]\ttraining's binary_logloss: 0.475667\n",
      "[411]\ttraining's binary_logloss: 0.475415\n",
      "[412]\ttraining's binary_logloss: 0.475119\n",
      "[413]\ttraining's binary_logloss: 0.474833\n",
      "[414]\ttraining's binary_logloss: 0.474576\n",
      "[415]\ttraining's binary_logloss: 0.474294\n",
      "[416]\ttraining's binary_logloss: 0.474029\n",
      "[417]\ttraining's binary_logloss: 0.473772\n",
      "[418]\ttraining's binary_logloss: 0.473547\n",
      "[419]\ttraining's binary_logloss: 0.473243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[420]\ttraining's binary_logloss: 0.472992\n",
      "[421]\ttraining's binary_logloss: 0.472759\n",
      "[422]\ttraining's binary_logloss: 0.472575\n",
      "[423]\ttraining's binary_logloss: 0.472352\n",
      "[424]\ttraining's binary_logloss: 0.472135\n",
      "[425]\ttraining's binary_logloss: 0.471929\n",
      "[426]\ttraining's binary_logloss: 0.471723\n",
      "[427]\ttraining's binary_logloss: 0.471534\n",
      "[428]\ttraining's binary_logloss: 0.471334\n",
      "[429]\ttraining's binary_logloss: 0.471116\n",
      "[430]\ttraining's binary_logloss: 0.470923\n",
      "[431]\ttraining's binary_logloss: 0.470712\n",
      "[432]\ttraining's binary_logloss: 0.470486\n",
      "[433]\ttraining's binary_logloss: 0.470256\n",
      "[434]\ttraining's binary_logloss: 0.470024\n",
      "[435]\ttraining's binary_logloss: 0.469815\n",
      "[436]\ttraining's binary_logloss: 0.469538\n",
      "[437]\ttraining's binary_logloss: 0.469337\n",
      "[438]\ttraining's binary_logloss: 0.46908\n",
      "[439]\ttraining's binary_logloss: 0.468878\n",
      "[440]\ttraining's binary_logloss: 0.468609\n",
      "[441]\ttraining's binary_logloss: 0.468379\n",
      "[442]\ttraining's binary_logloss: 0.46813\n",
      "[443]\ttraining's binary_logloss: 0.467861\n",
      "[444]\ttraining's binary_logloss: 0.467622\n",
      "[445]\ttraining's binary_logloss: 0.467376\n",
      "[446]\ttraining's binary_logloss: 0.467158\n",
      "[447]\ttraining's binary_logloss: 0.466904\n",
      "[448]\ttraining's binary_logloss: 0.466644\n",
      "[449]\ttraining's binary_logloss: 0.466428\n",
      "[450]\ttraining's binary_logloss: 0.466174\n",
      "[451]\ttraining's binary_logloss: 0.465951\n",
      "[452]\ttraining's binary_logloss: 0.465747\n",
      "[453]\ttraining's binary_logloss: 0.465552\n",
      "[454]\ttraining's binary_logloss: 0.465311\n",
      "[455]\ttraining's binary_logloss: 0.465101\n",
      "[456]\ttraining's binary_logloss: 0.464896\n",
      "[457]\ttraining's binary_logloss: 0.464672\n",
      "[458]\ttraining's binary_logloss: 0.464492\n",
      "[459]\ttraining's binary_logloss: 0.464255\n",
      "[460]\ttraining's binary_logloss: 0.46403\n",
      "[461]\ttraining's binary_logloss: 0.463812\n",
      "[462]\ttraining's binary_logloss: 0.463583\n",
      "[463]\ttraining's binary_logloss: 0.463308\n",
      "[464]\ttraining's binary_logloss: 0.463045\n",
      "[465]\ttraining's binary_logloss: 0.462805\n",
      "[466]\ttraining's binary_logloss: 0.462558\n",
      "[467]\ttraining's binary_logloss: 0.462286\n",
      "[468]\ttraining's binary_logloss: 0.462042\n",
      "[469]\ttraining's binary_logloss: 0.461817\n",
      "[470]\ttraining's binary_logloss: 0.461602\n",
      "[471]\ttraining's binary_logloss: 0.461417\n",
      "[472]\ttraining's binary_logloss: 0.461184\n",
      "[473]\ttraining's binary_logloss: 0.460974\n",
      "[474]\ttraining's binary_logloss: 0.46074\n",
      "[475]\ttraining's binary_logloss: 0.460496\n",
      "[476]\ttraining's binary_logloss: 0.460251\n",
      "[477]\ttraining's binary_logloss: 0.460031\n",
      "[478]\ttraining's binary_logloss: 0.459808\n",
      "[479]\ttraining's binary_logloss: 0.459594\n",
      "[480]\ttraining's binary_logloss: 0.459357\n",
      "[481]\ttraining's binary_logloss: 0.459109\n",
      "[482]\ttraining's binary_logloss: 0.458857\n",
      "[483]\ttraining's binary_logloss: 0.458623\n",
      "[484]\ttraining's binary_logloss: 0.458411\n",
      "[485]\ttraining's binary_logloss: 0.458178\n",
      "[486]\ttraining's binary_logloss: 0.457979\n",
      "[487]\ttraining's binary_logloss: 0.457729\n",
      "[488]\ttraining's binary_logloss: 0.457483\n",
      "[489]\ttraining's binary_logloss: 0.457213\n",
      "[490]\ttraining's binary_logloss: 0.456969\n",
      "[491]\ttraining's binary_logloss: 0.456796\n",
      "[492]\ttraining's binary_logloss: 0.456652\n",
      "[493]\ttraining's binary_logloss: 0.456497\n",
      "[494]\ttraining's binary_logloss: 0.456323\n",
      "[495]\ttraining's binary_logloss: 0.456158\n",
      "[496]\ttraining's binary_logloss: 0.455931\n",
      "[497]\ttraining's binary_logloss: 0.455666\n",
      "[498]\ttraining's binary_logloss: 0.455443\n",
      "[499]\ttraining's binary_logloss: 0.455212\n",
      "[500]\ttraining's binary_logloss: 0.454982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613466\n",
      "[2]\ttraining's binary_logloss: 0.611816\n",
      "[3]\ttraining's binary_logloss: 0.610224\n",
      "[4]\ttraining's binary_logloss: 0.608618\n",
      "[5]\ttraining's binary_logloss: 0.607007\n",
      "[6]\ttraining's binary_logloss: 0.605537\n",
      "[7]\ttraining's binary_logloss: 0.604109\n",
      "[8]\ttraining's binary_logloss: 0.602686\n",
      "[9]\ttraining's binary_logloss: 0.601317\n",
      "[10]\ttraining's binary_logloss: 0.600082\n",
      "[11]\ttraining's binary_logloss: 0.598691\n",
      "[12]\ttraining's binary_logloss: 0.597348\n",
      "[13]\ttraining's binary_logloss: 0.596038\n",
      "[14]\ttraining's binary_logloss: 0.594873\n",
      "[15]\ttraining's binary_logloss: 0.593731\n",
      "[16]\ttraining's binary_logloss: 0.592484\n",
      "[17]\ttraining's binary_logloss: 0.59129\n",
      "[18]\ttraining's binary_logloss: 0.590125\n",
      "[19]\ttraining's binary_logloss: 0.589029\n",
      "[20]\ttraining's binary_logloss: 0.58798\n",
      "[21]\ttraining's binary_logloss: 0.586931\n",
      "[22]\ttraining's binary_logloss: 0.585893\n",
      "[23]\ttraining's binary_logloss: 0.584966\n",
      "[24]\ttraining's binary_logloss: 0.583978\n",
      "[25]\ttraining's binary_logloss: 0.583051\n",
      "[26]\ttraining's binary_logloss: 0.58217\n",
      "[27]\ttraining's binary_logloss: 0.581298\n",
      "[28]\ttraining's binary_logloss: 0.580426\n",
      "[29]\ttraining's binary_logloss: 0.579668\n",
      "[30]\ttraining's binary_logloss: 0.578874\n",
      "[31]\ttraining's binary_logloss: 0.577986\n",
      "[32]\ttraining's binary_logloss: 0.577091\n",
      "[33]\ttraining's binary_logloss: 0.576226\n",
      "[34]\ttraining's binary_logloss: 0.575482\n",
      "[35]\ttraining's binary_logloss: 0.574668\n",
      "[36]\ttraining's binary_logloss: 0.573893\n",
      "[37]\ttraining's binary_logloss: 0.573143\n",
      "[38]\ttraining's binary_logloss: 0.572362\n",
      "[39]\ttraining's binary_logloss: 0.571573\n",
      "[40]\ttraining's binary_logloss: 0.570859\n",
      "[41]\ttraining's binary_logloss: 0.570201\n",
      "[42]\ttraining's binary_logloss: 0.569556\n",
      "[43]\ttraining's binary_logloss: 0.568973\n",
      "[44]\ttraining's binary_logloss: 0.568367\n",
      "[45]\ttraining's binary_logloss: 0.567769\n",
      "[46]\ttraining's binary_logloss: 0.567103\n",
      "[47]\ttraining's binary_logloss: 0.566454\n",
      "[48]\ttraining's binary_logloss: 0.565839\n",
      "[49]\ttraining's binary_logloss: 0.565248\n",
      "[50]\ttraining's binary_logloss: 0.564677\n",
      "[51]\ttraining's binary_logloss: 0.56406\n",
      "[52]\ttraining's binary_logloss: 0.563474\n",
      "[53]\ttraining's binary_logloss: 0.562873\n",
      "[54]\ttraining's binary_logloss: 0.562311\n",
      "[55]\ttraining's binary_logloss: 0.56174\n",
      "[56]\ttraining's binary_logloss: 0.561143\n",
      "[57]\ttraining's binary_logloss: 0.56058\n",
      "[58]\ttraining's binary_logloss: 0.560097\n",
      "[59]\ttraining's binary_logloss: 0.559565\n",
      "[60]\ttraining's binary_logloss: 0.559068\n",
      "[61]\ttraining's binary_logloss: 0.558593\n",
      "[62]\ttraining's binary_logloss: 0.55815\n",
      "[63]\ttraining's binary_logloss: 0.557675\n",
      "[64]\ttraining's binary_logloss: 0.557257\n",
      "[65]\ttraining's binary_logloss: 0.556811\n",
      "[66]\ttraining's binary_logloss: 0.556373\n",
      "[67]\ttraining's binary_logloss: 0.555943\n",
      "[68]\ttraining's binary_logloss: 0.555526\n",
      "[69]\ttraining's binary_logloss: 0.555095\n",
      "[70]\ttraining's binary_logloss: 0.554686\n",
      "[71]\ttraining's binary_logloss: 0.554267\n",
      "[72]\ttraining's binary_logloss: 0.55388\n",
      "[73]\ttraining's binary_logloss: 0.553465\n",
      "[74]\ttraining's binary_logloss: 0.553093\n",
      "[75]\ttraining's binary_logloss: 0.552747\n",
      "[76]\ttraining's binary_logloss: 0.552311\n",
      "[77]\ttraining's binary_logloss: 0.551894\n",
      "[78]\ttraining's binary_logloss: 0.551494\n",
      "[79]\ttraining's binary_logloss: 0.551104\n",
      "[80]\ttraining's binary_logloss: 0.550719\n",
      "[81]\ttraining's binary_logloss: 0.550348\n",
      "[82]\ttraining's binary_logloss: 0.550007\n",
      "[83]\ttraining's binary_logloss: 0.549678\n",
      "[84]\ttraining's binary_logloss: 0.549354\n",
      "[85]\ttraining's binary_logloss: 0.549049\n",
      "[86]\ttraining's binary_logloss: 0.548643\n",
      "[87]\ttraining's binary_logloss: 0.548247\n",
      "[88]\ttraining's binary_logloss: 0.547845\n",
      "[89]\ttraining's binary_logloss: 0.547466\n",
      "[90]\ttraining's binary_logloss: 0.547098\n",
      "[91]\ttraining's binary_logloss: 0.546855\n",
      "[92]\ttraining's binary_logloss: 0.546584\n",
      "[93]\ttraining's binary_logloss: 0.546349\n",
      "[94]\ttraining's binary_logloss: 0.54604\n",
      "[95]\ttraining's binary_logloss: 0.54571\n",
      "[96]\ttraining's binary_logloss: 0.545391\n",
      "[97]\ttraining's binary_logloss: 0.545072\n",
      "[98]\ttraining's binary_logloss: 0.544814\n",
      "[99]\ttraining's binary_logloss: 0.544513\n",
      "[100]\ttraining's binary_logloss: 0.54422\n",
      "[101]\ttraining's binary_logloss: 0.543944\n",
      "[102]\ttraining's binary_logloss: 0.543685\n",
      "[103]\ttraining's binary_logloss: 0.5434\n",
      "[104]\ttraining's binary_logloss: 0.543128\n",
      "[105]\ttraining's binary_logloss: 0.542864\n",
      "[106]\ttraining's binary_logloss: 0.542537\n",
      "[107]\ttraining's binary_logloss: 0.542243\n",
      "[108]\ttraining's binary_logloss: 0.541964\n",
      "[109]\ttraining's binary_logloss: 0.541673\n",
      "[110]\ttraining's binary_logloss: 0.541393\n",
      "[111]\ttraining's binary_logloss: 0.541111\n",
      "[112]\ttraining's binary_logloss: 0.540842\n",
      "[113]\ttraining's binary_logloss: 0.540564\n",
      "[114]\ttraining's binary_logloss: 0.540266\n",
      "[115]\ttraining's binary_logloss: 0.540003\n",
      "[116]\ttraining's binary_logloss: 0.539721\n",
      "[117]\ttraining's binary_logloss: 0.539491\n",
      "[118]\ttraining's binary_logloss: 0.539247\n",
      "[119]\ttraining's binary_logloss: 0.53898\n",
      "[120]\ttraining's binary_logloss: 0.538738\n",
      "[121]\ttraining's binary_logloss: 0.538442\n",
      "[122]\ttraining's binary_logloss: 0.538184\n",
      "[123]\ttraining's binary_logloss: 0.537939\n",
      "[124]\ttraining's binary_logloss: 0.537692\n",
      "[125]\ttraining's binary_logloss: 0.53746\n",
      "[126]\ttraining's binary_logloss: 0.537181\n",
      "[127]\ttraining's binary_logloss: 0.536916\n",
      "[128]\ttraining's binary_logloss: 0.536654\n",
      "[129]\ttraining's binary_logloss: 0.536385\n",
      "[130]\ttraining's binary_logloss: 0.536104\n",
      "[131]\ttraining's binary_logloss: 0.535804\n",
      "[132]\ttraining's binary_logloss: 0.535585\n",
      "[133]\ttraining's binary_logloss: 0.535391\n",
      "[134]\ttraining's binary_logloss: 0.535134\n",
      "[135]\ttraining's binary_logloss: 0.534903\n",
      "[136]\ttraining's binary_logloss: 0.534645\n",
      "[137]\ttraining's binary_logloss: 0.534387\n",
      "[138]\ttraining's binary_logloss: 0.534117\n",
      "[139]\ttraining's binary_logloss: 0.53387\n",
      "[140]\ttraining's binary_logloss: 0.533634\n",
      "[141]\ttraining's binary_logloss: 0.533369\n",
      "[142]\ttraining's binary_logloss: 0.533126\n",
      "[143]\ttraining's binary_logloss: 0.532933\n",
      "[144]\ttraining's binary_logloss: 0.532731\n",
      "[145]\ttraining's binary_logloss: 0.532451\n",
      "[146]\ttraining's binary_logloss: 0.532188\n",
      "[147]\ttraining's binary_logloss: 0.531941\n",
      "[148]\ttraining's binary_logloss: 0.531701\n",
      "[149]\ttraining's binary_logloss: 0.531449\n",
      "[150]\ttraining's binary_logloss: 0.531205\n",
      "[151]\ttraining's binary_logloss: 0.530961\n",
      "[152]\ttraining's binary_logloss: 0.530702\n",
      "[153]\ttraining's binary_logloss: 0.530453\n",
      "[154]\ttraining's binary_logloss: 0.530184\n",
      "[155]\ttraining's binary_logloss: 0.529938\n",
      "[156]\ttraining's binary_logloss: 0.529687\n",
      "[157]\ttraining's binary_logloss: 0.529439\n",
      "[158]\ttraining's binary_logloss: 0.529225\n",
      "[159]\ttraining's binary_logloss: 0.52903\n",
      "[160]\ttraining's binary_logloss: 0.528828\n",
      "[161]\ttraining's binary_logloss: 0.528564\n",
      "[162]\ttraining's binary_logloss: 0.528245\n",
      "[163]\ttraining's binary_logloss: 0.527988\n",
      "[164]\ttraining's binary_logloss: 0.52772\n",
      "[165]\ttraining's binary_logloss: 0.52746\n",
      "[166]\ttraining's binary_logloss: 0.527217\n",
      "[167]\ttraining's binary_logloss: 0.526972\n",
      "[168]\ttraining's binary_logloss: 0.526719\n",
      "[169]\ttraining's binary_logloss: 0.526438\n",
      "[170]\ttraining's binary_logloss: 0.526199\n",
      "[171]\ttraining's binary_logloss: 0.525922\n",
      "[172]\ttraining's binary_logloss: 0.525643\n",
      "[173]\ttraining's binary_logloss: 0.525394\n",
      "[174]\ttraining's binary_logloss: 0.525136\n",
      "[175]\ttraining's binary_logloss: 0.524846\n",
      "[176]\ttraining's binary_logloss: 0.524615\n",
      "[177]\ttraining's binary_logloss: 0.52438\n",
      "[178]\ttraining's binary_logloss: 0.52415\n",
      "[179]\ttraining's binary_logloss: 0.5239\n",
      "[180]\ttraining's binary_logloss: 0.523706\n",
      "[181]\ttraining's binary_logloss: 0.523447\n",
      "[182]\ttraining's binary_logloss: 0.523216\n",
      "[183]\ttraining's binary_logloss: 0.522978\n",
      "[184]\ttraining's binary_logloss: 0.522742\n",
      "[185]\ttraining's binary_logloss: 0.522523\n",
      "[186]\ttraining's binary_logloss: 0.522256\n",
      "[187]\ttraining's binary_logloss: 0.521996\n",
      "[188]\ttraining's binary_logloss: 0.521744\n",
      "[189]\ttraining's binary_logloss: 0.521469\n",
      "[190]\ttraining's binary_logloss: 0.521218\n",
      "[191]\ttraining's binary_logloss: 0.520977\n",
      "[192]\ttraining's binary_logloss: 0.520754\n",
      "[193]\ttraining's binary_logloss: 0.520511\n",
      "[194]\ttraining's binary_logloss: 0.520232\n",
      "[195]\ttraining's binary_logloss: 0.520009\n",
      "[196]\ttraining's binary_logloss: 0.519773\n",
      "[197]\ttraining's binary_logloss: 0.519527\n",
      "[198]\ttraining's binary_logloss: 0.519305\n",
      "[199]\ttraining's binary_logloss: 0.519058\n",
      "[200]\ttraining's binary_logloss: 0.518819\n",
      "[201]\ttraining's binary_logloss: 0.518617\n",
      "[202]\ttraining's binary_logloss: 0.518363\n",
      "[203]\ttraining's binary_logloss: 0.518119\n",
      "[204]\ttraining's binary_logloss: 0.517885\n",
      "[205]\ttraining's binary_logloss: 0.517655\n",
      "[206]\ttraining's binary_logloss: 0.517413\n",
      "[207]\ttraining's binary_logloss: 0.517162\n",
      "[208]\ttraining's binary_logloss: 0.516914\n",
      "[209]\ttraining's binary_logloss: 0.516673\n",
      "[210]\ttraining's binary_logloss: 0.516419\n",
      "[211]\ttraining's binary_logloss: 0.516208\n",
      "[212]\ttraining's binary_logloss: 0.515991\n",
      "[213]\ttraining's binary_logloss: 0.515779\n",
      "[214]\ttraining's binary_logloss: 0.515572\n",
      "[215]\ttraining's binary_logloss: 0.515369\n",
      "[216]\ttraining's binary_logloss: 0.515092\n",
      "[217]\ttraining's binary_logloss: 0.514804\n",
      "[218]\ttraining's binary_logloss: 0.514533\n",
      "[219]\ttraining's binary_logloss: 0.514273\n",
      "[220]\ttraining's binary_logloss: 0.514009\n",
      "[221]\ttraining's binary_logloss: 0.513731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[222]\ttraining's binary_logloss: 0.513465\n",
      "[223]\ttraining's binary_logloss: 0.513182\n",
      "[224]\ttraining's binary_logloss: 0.512901\n",
      "[225]\ttraining's binary_logloss: 0.512633\n",
      "[226]\ttraining's binary_logloss: 0.512429\n",
      "[227]\ttraining's binary_logloss: 0.512218\n",
      "[228]\ttraining's binary_logloss: 0.511978\n",
      "[229]\ttraining's binary_logloss: 0.511777\n",
      "[230]\ttraining's binary_logloss: 0.511539\n",
      "[231]\ttraining's binary_logloss: 0.511308\n",
      "[232]\ttraining's binary_logloss: 0.511089\n",
      "[233]\ttraining's binary_logloss: 0.510866\n",
      "[234]\ttraining's binary_logloss: 0.510641\n",
      "[235]\ttraining's binary_logloss: 0.510421\n",
      "[236]\ttraining's binary_logloss: 0.510121\n",
      "[237]\ttraining's binary_logloss: 0.509835\n",
      "[238]\ttraining's binary_logloss: 0.509561\n",
      "[239]\ttraining's binary_logloss: 0.50928\n",
      "[240]\ttraining's binary_logloss: 0.50901\n",
      "[241]\ttraining's binary_logloss: 0.508766\n",
      "[242]\ttraining's binary_logloss: 0.508527\n",
      "[243]\ttraining's binary_logloss: 0.508266\n",
      "[244]\ttraining's binary_logloss: 0.50803\n",
      "[245]\ttraining's binary_logloss: 0.507806\n",
      "[246]\ttraining's binary_logloss: 0.507549\n",
      "[247]\ttraining's binary_logloss: 0.507259\n",
      "[248]\ttraining's binary_logloss: 0.507021\n",
      "[249]\ttraining's binary_logloss: 0.506783\n",
      "[250]\ttraining's binary_logloss: 0.506526\n",
      "[251]\ttraining's binary_logloss: 0.506271\n",
      "[252]\ttraining's binary_logloss: 0.506037\n",
      "[253]\ttraining's binary_logloss: 0.505802\n",
      "[254]\ttraining's binary_logloss: 0.50559\n",
      "[255]\ttraining's binary_logloss: 0.505344\n",
      "[256]\ttraining's binary_logloss: 0.50508\n",
      "[257]\ttraining's binary_logloss: 0.504841\n",
      "[258]\ttraining's binary_logloss: 0.504554\n",
      "[259]\ttraining's binary_logloss: 0.504251\n",
      "[260]\ttraining's binary_logloss: 0.503964\n",
      "[261]\ttraining's binary_logloss: 0.503718\n",
      "[262]\ttraining's binary_logloss: 0.503503\n",
      "[263]\ttraining's binary_logloss: 0.50328\n",
      "[264]\ttraining's binary_logloss: 0.503048\n",
      "[265]\ttraining's binary_logloss: 0.50284\n",
      "[266]\ttraining's binary_logloss: 0.502655\n",
      "[267]\ttraining's binary_logloss: 0.502503\n",
      "[268]\ttraining's binary_logloss: 0.502322\n",
      "[269]\ttraining's binary_logloss: 0.502123\n",
      "[270]\ttraining's binary_logloss: 0.501948\n",
      "[271]\ttraining's binary_logloss: 0.501669\n",
      "[272]\ttraining's binary_logloss: 0.501371\n",
      "[273]\ttraining's binary_logloss: 0.50108\n",
      "[274]\ttraining's binary_logloss: 0.500794\n",
      "[275]\ttraining's binary_logloss: 0.500513\n",
      "[276]\ttraining's binary_logloss: 0.500214\n",
      "[277]\ttraining's binary_logloss: 0.499906\n",
      "[278]\ttraining's binary_logloss: 0.499632\n",
      "[279]\ttraining's binary_logloss: 0.499335\n",
      "[280]\ttraining's binary_logloss: 0.49903\n",
      "[281]\ttraining's binary_logloss: 0.49877\n",
      "[282]\ttraining's binary_logloss: 0.498511\n",
      "[283]\ttraining's binary_logloss: 0.498234\n",
      "[284]\ttraining's binary_logloss: 0.497969\n",
      "[285]\ttraining's binary_logloss: 0.497724\n",
      "[286]\ttraining's binary_logloss: 0.497485\n",
      "[287]\ttraining's binary_logloss: 0.497258\n",
      "[288]\ttraining's binary_logloss: 0.497005\n",
      "[289]\ttraining's binary_logloss: 0.496708\n",
      "[290]\ttraining's binary_logloss: 0.496487\n",
      "[291]\ttraining's binary_logloss: 0.496245\n",
      "[292]\ttraining's binary_logloss: 0.495991\n",
      "[293]\ttraining's binary_logloss: 0.49572\n",
      "[294]\ttraining's binary_logloss: 0.495482\n",
      "[295]\ttraining's binary_logloss: 0.495225\n",
      "[296]\ttraining's binary_logloss: 0.494976\n",
      "[297]\ttraining's binary_logloss: 0.494747\n",
      "[298]\ttraining's binary_logloss: 0.49455\n",
      "[299]\ttraining's binary_logloss: 0.494337\n",
      "[300]\ttraining's binary_logloss: 0.494117\n",
      "[301]\ttraining's binary_logloss: 0.493867\n",
      "[302]\ttraining's binary_logloss: 0.493576\n",
      "[303]\ttraining's binary_logloss: 0.493312\n",
      "[304]\ttraining's binary_logloss: 0.493032\n",
      "[305]\ttraining's binary_logloss: 0.492772\n",
      "[306]\ttraining's binary_logloss: 0.492519\n",
      "[307]\ttraining's binary_logloss: 0.492258\n",
      "[308]\ttraining's binary_logloss: 0.491994\n",
      "[309]\ttraining's binary_logloss: 0.491749\n",
      "[310]\ttraining's binary_logloss: 0.491516\n",
      "[311]\ttraining's binary_logloss: 0.491282\n",
      "[312]\ttraining's binary_logloss: 0.491031\n",
      "[313]\ttraining's binary_logloss: 0.490807\n",
      "[314]\ttraining's binary_logloss: 0.490612\n",
      "[315]\ttraining's binary_logloss: 0.490414\n",
      "[316]\ttraining's binary_logloss: 0.490191\n",
      "[317]\ttraining's binary_logloss: 0.489973\n",
      "[318]\ttraining's binary_logloss: 0.48975\n",
      "[319]\ttraining's binary_logloss: 0.489523\n",
      "[320]\ttraining's binary_logloss: 0.489299\n",
      "[321]\ttraining's binary_logloss: 0.489077\n",
      "[322]\ttraining's binary_logloss: 0.488837\n",
      "[323]\ttraining's binary_logloss: 0.488586\n",
      "[324]\ttraining's binary_logloss: 0.488365\n",
      "[325]\ttraining's binary_logloss: 0.488121\n",
      "[326]\ttraining's binary_logloss: 0.487878\n",
      "[327]\ttraining's binary_logloss: 0.48756\n",
      "[328]\ttraining's binary_logloss: 0.487281\n",
      "[329]\ttraining's binary_logloss: 0.487051\n",
      "[330]\ttraining's binary_logloss: 0.486795\n",
      "[331]\ttraining's binary_logloss: 0.48653\n",
      "[332]\ttraining's binary_logloss: 0.486293\n",
      "[333]\ttraining's binary_logloss: 0.486067\n",
      "[334]\ttraining's binary_logloss: 0.485822\n",
      "[335]\ttraining's binary_logloss: 0.485569\n",
      "[336]\ttraining's binary_logloss: 0.485343\n",
      "[337]\ttraining's binary_logloss: 0.485109\n",
      "[338]\ttraining's binary_logloss: 0.484878\n",
      "[339]\ttraining's binary_logloss: 0.484638\n",
      "[340]\ttraining's binary_logloss: 0.484375\n",
      "[341]\ttraining's binary_logloss: 0.484148\n",
      "[342]\ttraining's binary_logloss: 0.483943\n",
      "[343]\ttraining's binary_logloss: 0.483748\n",
      "[344]\ttraining's binary_logloss: 0.483521\n",
      "[345]\ttraining's binary_logloss: 0.483286\n",
      "[346]\ttraining's binary_logloss: 0.483053\n",
      "[347]\ttraining's binary_logloss: 0.482829\n",
      "[348]\ttraining's binary_logloss: 0.482603\n",
      "[349]\ttraining's binary_logloss: 0.482385\n",
      "[350]\ttraining's binary_logloss: 0.482173\n",
      "[351]\ttraining's binary_logloss: 0.481927\n",
      "[352]\ttraining's binary_logloss: 0.48169\n",
      "[353]\ttraining's binary_logloss: 0.481445\n",
      "[354]\ttraining's binary_logloss: 0.481209\n",
      "[355]\ttraining's binary_logloss: 0.480976\n",
      "[356]\ttraining's binary_logloss: 0.480707\n",
      "[357]\ttraining's binary_logloss: 0.480445\n",
      "[358]\ttraining's binary_logloss: 0.480184\n",
      "[359]\ttraining's binary_logloss: 0.47991\n",
      "[360]\ttraining's binary_logloss: 0.479629\n",
      "[361]\ttraining's binary_logloss: 0.479378\n",
      "[362]\ttraining's binary_logloss: 0.479134\n",
      "[363]\ttraining's binary_logloss: 0.478906\n",
      "[364]\ttraining's binary_logloss: 0.478649\n",
      "[365]\ttraining's binary_logloss: 0.478431\n",
      "[366]\ttraining's binary_logloss: 0.478149\n",
      "[367]\ttraining's binary_logloss: 0.477899\n",
      "[368]\ttraining's binary_logloss: 0.477641\n",
      "[369]\ttraining's binary_logloss: 0.477392\n",
      "[370]\ttraining's binary_logloss: 0.477146\n",
      "[371]\ttraining's binary_logloss: 0.476942\n",
      "[372]\ttraining's binary_logloss: 0.47674\n",
      "[373]\ttraining's binary_logloss: 0.476543\n",
      "[374]\ttraining's binary_logloss: 0.476342\n",
      "[375]\ttraining's binary_logloss: 0.476137\n",
      "[376]\ttraining's binary_logloss: 0.475895\n",
      "[377]\ttraining's binary_logloss: 0.475658\n",
      "[378]\ttraining's binary_logloss: 0.475408\n",
      "[379]\ttraining's binary_logloss: 0.475197\n",
      "[380]\ttraining's binary_logloss: 0.474955\n",
      "[381]\ttraining's binary_logloss: 0.474728\n",
      "[382]\ttraining's binary_logloss: 0.474519\n",
      "[383]\ttraining's binary_logloss: 0.474319\n",
      "[384]\ttraining's binary_logloss: 0.474114\n",
      "[385]\ttraining's binary_logloss: 0.473925\n",
      "[386]\ttraining's binary_logloss: 0.47367\n",
      "[387]\ttraining's binary_logloss: 0.473415\n",
      "[388]\ttraining's binary_logloss: 0.473189\n",
      "[389]\ttraining's binary_logloss: 0.472958\n",
      "[390]\ttraining's binary_logloss: 0.472707\n",
      "[391]\ttraining's binary_logloss: 0.472455\n",
      "[392]\ttraining's binary_logloss: 0.472244\n",
      "[393]\ttraining's binary_logloss: 0.471993\n",
      "[394]\ttraining's binary_logloss: 0.471742\n",
      "[395]\ttraining's binary_logloss: 0.471536\n",
      "[396]\ttraining's binary_logloss: 0.4713\n",
      "[397]\ttraining's binary_logloss: 0.471068\n",
      "[398]\ttraining's binary_logloss: 0.470814\n",
      "[399]\ttraining's binary_logloss: 0.470611\n",
      "[400]\ttraining's binary_logloss: 0.470398\n",
      "[401]\ttraining's binary_logloss: 0.470161\n",
      "[402]\ttraining's binary_logloss: 0.469949\n",
      "[403]\ttraining's binary_logloss: 0.469743\n",
      "[404]\ttraining's binary_logloss: 0.469522\n",
      "[405]\ttraining's binary_logloss: 0.469316\n",
      "[406]\ttraining's binary_logloss: 0.46909\n",
      "[407]\ttraining's binary_logloss: 0.468882\n",
      "[408]\ttraining's binary_logloss: 0.468668\n",
      "[409]\ttraining's binary_logloss: 0.468439\n",
      "[410]\ttraining's binary_logloss: 0.468226\n",
      "[411]\ttraining's binary_logloss: 0.467945\n",
      "[412]\ttraining's binary_logloss: 0.467672\n",
      "[413]\ttraining's binary_logloss: 0.467409\n",
      "[414]\ttraining's binary_logloss: 0.467149\n",
      "[415]\ttraining's binary_logloss: 0.466899\n",
      "[416]\ttraining's binary_logloss: 0.466638\n",
      "[417]\ttraining's binary_logloss: 0.466372\n",
      "[418]\ttraining's binary_logloss: 0.466107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[419]\ttraining's binary_logloss: 0.465858\n",
      "[420]\ttraining's binary_logloss: 0.46555\n",
      "[421]\ttraining's binary_logloss: 0.465316\n",
      "[422]\ttraining's binary_logloss: 0.465105\n",
      "[423]\ttraining's binary_logloss: 0.464879\n",
      "[424]\ttraining's binary_logloss: 0.464702\n",
      "[425]\ttraining's binary_logloss: 0.464491\n",
      "[426]\ttraining's binary_logloss: 0.464309\n",
      "[427]\ttraining's binary_logloss: 0.46406\n",
      "[428]\ttraining's binary_logloss: 0.46382\n",
      "[429]\ttraining's binary_logloss: 0.463579\n",
      "[430]\ttraining's binary_logloss: 0.463348\n",
      "[431]\ttraining's binary_logloss: 0.463079\n",
      "[432]\ttraining's binary_logloss: 0.462821\n",
      "[433]\ttraining's binary_logloss: 0.462534\n",
      "[434]\ttraining's binary_logloss: 0.462247\n",
      "[435]\ttraining's binary_logloss: 0.461974\n",
      "[436]\ttraining's binary_logloss: 0.461696\n",
      "[437]\ttraining's binary_logloss: 0.461392\n",
      "[438]\ttraining's binary_logloss: 0.461116\n",
      "[439]\ttraining's binary_logloss: 0.460836\n",
      "[440]\ttraining's binary_logloss: 0.46055\n",
      "[441]\ttraining's binary_logloss: 0.460285\n",
      "[442]\ttraining's binary_logloss: 0.460022\n",
      "[443]\ttraining's binary_logloss: 0.459761\n",
      "[444]\ttraining's binary_logloss: 0.459497\n",
      "[445]\ttraining's binary_logloss: 0.459249\n",
      "[446]\ttraining's binary_logloss: 0.458962\n",
      "[447]\ttraining's binary_logloss: 0.458679\n",
      "[448]\ttraining's binary_logloss: 0.458455\n",
      "[449]\ttraining's binary_logloss: 0.45819\n",
      "[450]\ttraining's binary_logloss: 0.457925\n",
      "[451]\ttraining's binary_logloss: 0.4577\n",
      "[452]\ttraining's binary_logloss: 0.457478\n",
      "[453]\ttraining's binary_logloss: 0.457254\n",
      "[454]\ttraining's binary_logloss: 0.457054\n",
      "[455]\ttraining's binary_logloss: 0.456842\n",
      "[456]\ttraining's binary_logloss: 0.456623\n",
      "[457]\ttraining's binary_logloss: 0.456424\n",
      "[458]\ttraining's binary_logloss: 0.456224\n",
      "[459]\ttraining's binary_logloss: 0.456011\n",
      "[460]\ttraining's binary_logloss: 0.455809\n",
      "[461]\ttraining's binary_logloss: 0.455526\n",
      "[462]\ttraining's binary_logloss: 0.455258\n",
      "[463]\ttraining's binary_logloss: 0.454998\n",
      "[464]\ttraining's binary_logloss: 0.454745\n",
      "[465]\ttraining's binary_logloss: 0.454506\n",
      "[466]\ttraining's binary_logloss: 0.454298\n",
      "[467]\ttraining's binary_logloss: 0.454064\n",
      "[468]\ttraining's binary_logloss: 0.453851\n",
      "[469]\ttraining's binary_logloss: 0.453644\n",
      "[470]\ttraining's binary_logloss: 0.453399\n",
      "[471]\ttraining's binary_logloss: 0.453194\n",
      "[472]\ttraining's binary_logloss: 0.452986\n",
      "[473]\ttraining's binary_logloss: 0.452763\n",
      "[474]\ttraining's binary_logloss: 0.452556\n",
      "[475]\ttraining's binary_logloss: 0.452356\n",
      "[476]\ttraining's binary_logloss: 0.452045\n",
      "[477]\ttraining's binary_logloss: 0.451761\n",
      "[478]\ttraining's binary_logloss: 0.451511\n",
      "[479]\ttraining's binary_logloss: 0.451302\n",
      "[480]\ttraining's binary_logloss: 0.45104\n",
      "[481]\ttraining's binary_logloss: 0.450833\n",
      "[482]\ttraining's binary_logloss: 0.450582\n",
      "[483]\ttraining's binary_logloss: 0.450352\n",
      "[484]\ttraining's binary_logloss: 0.450116\n",
      "[485]\ttraining's binary_logloss: 0.449898\n",
      "[486]\ttraining's binary_logloss: 0.449629\n",
      "[487]\ttraining's binary_logloss: 0.449362\n",
      "[488]\ttraining's binary_logloss: 0.449104\n",
      "[489]\ttraining's binary_logloss: 0.448815\n",
      "[490]\ttraining's binary_logloss: 0.448568\n",
      "[491]\ttraining's binary_logloss: 0.448348\n",
      "[492]\ttraining's binary_logloss: 0.448116\n",
      "[493]\ttraining's binary_logloss: 0.447902\n",
      "[494]\ttraining's binary_logloss: 0.447677\n",
      "[495]\ttraining's binary_logloss: 0.447461\n",
      "[496]\ttraining's binary_logloss: 0.447181\n",
      "[497]\ttraining's binary_logloss: 0.446911\n",
      "[498]\ttraining's binary_logloss: 0.446647\n",
      "[499]\ttraining's binary_logloss: 0.446389\n",
      "[500]\ttraining's binary_logloss: 0.446131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.612624\n",
      "[2]\ttraining's binary_logloss: 0.610937\n",
      "[3]\ttraining's binary_logloss: 0.60929\n",
      "[4]\ttraining's binary_logloss: 0.607711\n",
      "[5]\ttraining's binary_logloss: 0.606138\n",
      "[6]\ttraining's binary_logloss: 0.60475\n",
      "[7]\ttraining's binary_logloss: 0.603334\n",
      "[8]\ttraining's binary_logloss: 0.602037\n",
      "[9]\ttraining's binary_logloss: 0.600681\n",
      "[10]\ttraining's binary_logloss: 0.599323\n",
      "[11]\ttraining's binary_logloss: 0.597975\n",
      "[12]\ttraining's binary_logloss: 0.596664\n",
      "[13]\ttraining's binary_logloss: 0.595466\n",
      "[14]\ttraining's binary_logloss: 0.594218\n",
      "[15]\ttraining's binary_logloss: 0.593067\n",
      "[16]\ttraining's binary_logloss: 0.59205\n",
      "[17]\ttraining's binary_logloss: 0.590898\n",
      "[18]\ttraining's binary_logloss: 0.589775\n",
      "[19]\ttraining's binary_logloss: 0.588679\n",
      "[20]\ttraining's binary_logloss: 0.587651\n",
      "[21]\ttraining's binary_logloss: 0.586609\n",
      "[22]\ttraining's binary_logloss: 0.585563\n",
      "[23]\ttraining's binary_logloss: 0.584597\n",
      "[24]\ttraining's binary_logloss: 0.583638\n",
      "[25]\ttraining's binary_logloss: 0.582735\n",
      "[26]\ttraining's binary_logloss: 0.581796\n",
      "[27]\ttraining's binary_logloss: 0.580886\n",
      "[28]\ttraining's binary_logloss: 0.580025\n",
      "[29]\ttraining's binary_logloss: 0.579163\n",
      "[30]\ttraining's binary_logloss: 0.578338\n",
      "[31]\ttraining's binary_logloss: 0.577535\n",
      "[32]\ttraining's binary_logloss: 0.576786\n",
      "[33]\ttraining's binary_logloss: 0.576023\n",
      "[34]\ttraining's binary_logloss: 0.575267\n",
      "[35]\ttraining's binary_logloss: 0.574542\n",
      "[36]\ttraining's binary_logloss: 0.573768\n",
      "[37]\ttraining's binary_logloss: 0.572998\n",
      "[38]\ttraining's binary_logloss: 0.572299\n",
      "[39]\ttraining's binary_logloss: 0.571579\n",
      "[40]\ttraining's binary_logloss: 0.570934\n",
      "[41]\ttraining's binary_logloss: 0.570281\n",
      "[42]\ttraining's binary_logloss: 0.569652\n",
      "[43]\ttraining's binary_logloss: 0.569058\n",
      "[44]\ttraining's binary_logloss: 0.568396\n",
      "[45]\ttraining's binary_logloss: 0.567763\n",
      "[46]\ttraining's binary_logloss: 0.567137\n",
      "[47]\ttraining's binary_logloss: 0.566577\n",
      "[48]\ttraining's binary_logloss: 0.565992\n",
      "[49]\ttraining's binary_logloss: 0.565435\n",
      "[50]\ttraining's binary_logloss: 0.564926\n",
      "[51]\ttraining's binary_logloss: 0.564343\n",
      "[52]\ttraining's binary_logloss: 0.563756\n",
      "[53]\ttraining's binary_logloss: 0.563206\n",
      "[54]\ttraining's binary_logloss: 0.562707\n",
      "[55]\ttraining's binary_logloss: 0.562208\n",
      "[56]\ttraining's binary_logloss: 0.561734\n",
      "[57]\ttraining's binary_logloss: 0.561259\n",
      "[58]\ttraining's binary_logloss: 0.560756\n",
      "[59]\ttraining's binary_logloss: 0.560317\n",
      "[60]\ttraining's binary_logloss: 0.559888\n",
      "[61]\ttraining's binary_logloss: 0.559517\n",
      "[62]\ttraining's binary_logloss: 0.559101\n",
      "[63]\ttraining's binary_logloss: 0.558591\n",
      "[64]\ttraining's binary_logloss: 0.558222\n",
      "[65]\ttraining's binary_logloss: 0.557844\n",
      "[66]\ttraining's binary_logloss: 0.557349\n",
      "[67]\ttraining's binary_logloss: 0.556976\n",
      "[68]\ttraining's binary_logloss: 0.556506\n",
      "[69]\ttraining's binary_logloss: 0.556077\n",
      "[70]\ttraining's binary_logloss: 0.55565\n",
      "[71]\ttraining's binary_logloss: 0.555204\n",
      "[72]\ttraining's binary_logloss: 0.554768\n",
      "[73]\ttraining's binary_logloss: 0.554366\n",
      "[74]\ttraining's binary_logloss: 0.553989\n",
      "[75]\ttraining's binary_logloss: 0.553655\n",
      "[76]\ttraining's binary_logloss: 0.553259\n",
      "[77]\ttraining's binary_logloss: 0.552873\n",
      "[78]\ttraining's binary_logloss: 0.5525\n",
      "[79]\ttraining's binary_logloss: 0.552205\n",
      "[80]\ttraining's binary_logloss: 0.551871\n",
      "[81]\ttraining's binary_logloss: 0.551523\n",
      "[82]\ttraining's binary_logloss: 0.551151\n",
      "[83]\ttraining's binary_logloss: 0.550813\n",
      "[84]\ttraining's binary_logloss: 0.550462\n",
      "[85]\ttraining's binary_logloss: 0.550101\n",
      "[86]\ttraining's binary_logloss: 0.549781\n",
      "[87]\ttraining's binary_logloss: 0.549471\n",
      "[88]\ttraining's binary_logloss: 0.549121\n",
      "[89]\ttraining's binary_logloss: 0.548795\n",
      "[90]\ttraining's binary_logloss: 0.548474\n",
      "[91]\ttraining's binary_logloss: 0.548152\n",
      "[92]\ttraining's binary_logloss: 0.547843\n",
      "[93]\ttraining's binary_logloss: 0.547525\n",
      "[94]\ttraining's binary_logloss: 0.547209\n",
      "[95]\ttraining's binary_logloss: 0.546907\n",
      "[96]\ttraining's binary_logloss: 0.546598\n",
      "[97]\ttraining's binary_logloss: 0.546314\n",
      "[98]\ttraining's binary_logloss: 0.546052\n",
      "[99]\ttraining's binary_logloss: 0.545761\n",
      "[100]\ttraining's binary_logloss: 0.545494\n",
      "[101]\ttraining's binary_logloss: 0.545253\n",
      "[102]\ttraining's binary_logloss: 0.544986\n",
      "[103]\ttraining's binary_logloss: 0.544668\n",
      "[104]\ttraining's binary_logloss: 0.54443\n",
      "[105]\ttraining's binary_logloss: 0.544182\n",
      "[106]\ttraining's binary_logloss: 0.543914\n",
      "[107]\ttraining's binary_logloss: 0.543643\n",
      "[108]\ttraining's binary_logloss: 0.543369\n",
      "[109]\ttraining's binary_logloss: 0.543096\n",
      "[110]\ttraining's binary_logloss: 0.542862\n",
      "[111]\ttraining's binary_logloss: 0.5426\n",
      "[112]\ttraining's binary_logloss: 0.542367\n",
      "[113]\ttraining's binary_logloss: 0.542096\n",
      "[114]\ttraining's binary_logloss: 0.541896\n",
      "[115]\ttraining's binary_logloss: 0.541667\n",
      "[116]\ttraining's binary_logloss: 0.541373\n",
      "[117]\ttraining's binary_logloss: 0.541066\n",
      "[118]\ttraining's binary_logloss: 0.540787\n",
      "[119]\ttraining's binary_logloss: 0.540518\n",
      "[120]\ttraining's binary_logloss: 0.540224\n",
      "[121]\ttraining's binary_logloss: 0.539985\n",
      "[122]\ttraining's binary_logloss: 0.539689\n",
      "[123]\ttraining's binary_logloss: 0.539437\n",
      "[124]\ttraining's binary_logloss: 0.539177\n",
      "[125]\ttraining's binary_logloss: 0.538937\n",
      "[126]\ttraining's binary_logloss: 0.538718\n",
      "[127]\ttraining's binary_logloss: 0.538423\n",
      "[128]\ttraining's binary_logloss: 0.538162\n",
      "[129]\ttraining's binary_logloss: 0.537898\n",
      "[130]\ttraining's binary_logloss: 0.537653\n",
      "[131]\ttraining's binary_logloss: 0.537405\n",
      "[132]\ttraining's binary_logloss: 0.537173\n",
      "[133]\ttraining's binary_logloss: 0.536928\n",
      "[134]\ttraining's binary_logloss: 0.536733\n",
      "[135]\ttraining's binary_logloss: 0.536503\n",
      "[136]\ttraining's binary_logloss: 0.536259\n",
      "[137]\ttraining's binary_logloss: 0.536037\n",
      "[138]\ttraining's binary_logloss: 0.535839\n",
      "[139]\ttraining's binary_logloss: 0.535616\n",
      "[140]\ttraining's binary_logloss: 0.535354\n",
      "[141]\ttraining's binary_logloss: 0.535143\n",
      "[142]\ttraining's binary_logloss: 0.53492\n",
      "[143]\ttraining's binary_logloss: 0.534681\n",
      "[144]\ttraining's binary_logloss: 0.534429\n",
      "[145]\ttraining's binary_logloss: 0.534224\n",
      "[146]\ttraining's binary_logloss: 0.533987\n",
      "[147]\ttraining's binary_logloss: 0.533714\n",
      "[148]\ttraining's binary_logloss: 0.533442\n",
      "[149]\ttraining's binary_logloss: 0.533146\n",
      "[150]\ttraining's binary_logloss: 0.532878\n",
      "[151]\ttraining's binary_logloss: 0.532627\n",
      "[152]\ttraining's binary_logloss: 0.532372\n",
      "[153]\ttraining's binary_logloss: 0.532135\n",
      "[154]\ttraining's binary_logloss: 0.531898\n",
      "[155]\ttraining's binary_logloss: 0.531663\n",
      "[156]\ttraining's binary_logloss: 0.531465\n",
      "[157]\ttraining's binary_logloss: 0.531264\n",
      "[158]\ttraining's binary_logloss: 0.531086\n",
      "[159]\ttraining's binary_logloss: 0.530845\n",
      "[160]\ttraining's binary_logloss: 0.530655\n",
      "[161]\ttraining's binary_logloss: 0.530385\n",
      "[162]\ttraining's binary_logloss: 0.530096\n",
      "[163]\ttraining's binary_logloss: 0.529842\n",
      "[164]\ttraining's binary_logloss: 0.529562\n",
      "[165]\ttraining's binary_logloss: 0.529271\n",
      "[166]\ttraining's binary_logloss: 0.529007\n",
      "[167]\ttraining's binary_logloss: 0.528723\n",
      "[168]\ttraining's binary_logloss: 0.528469\n",
      "[169]\ttraining's binary_logloss: 0.528216\n",
      "[170]\ttraining's binary_logloss: 0.527947\n",
      "[171]\ttraining's binary_logloss: 0.527731\n",
      "[172]\ttraining's binary_logloss: 0.527517\n",
      "[173]\ttraining's binary_logloss: 0.527298\n",
      "[174]\ttraining's binary_logloss: 0.52708\n",
      "[175]\ttraining's binary_logloss: 0.526851\n",
      "[176]\ttraining's binary_logloss: 0.526627\n",
      "[177]\ttraining's binary_logloss: 0.526425\n",
      "[178]\ttraining's binary_logloss: 0.526211\n",
      "[179]\ttraining's binary_logloss: 0.526006\n",
      "[180]\ttraining's binary_logloss: 0.525807\n",
      "[181]\ttraining's binary_logloss: 0.525634\n",
      "[182]\ttraining's binary_logloss: 0.525434\n",
      "[183]\ttraining's binary_logloss: 0.525207\n",
      "[184]\ttraining's binary_logloss: 0.525002\n",
      "[185]\ttraining's binary_logloss: 0.52479\n",
      "[186]\ttraining's binary_logloss: 0.524578\n",
      "[187]\ttraining's binary_logloss: 0.524367\n",
      "[188]\ttraining's binary_logloss: 0.52416\n",
      "[189]\ttraining's binary_logloss: 0.523964\n",
      "[190]\ttraining's binary_logloss: 0.523748\n",
      "[191]\ttraining's binary_logloss: 0.52349\n",
      "[192]\ttraining's binary_logloss: 0.52326\n",
      "[193]\ttraining's binary_logloss: 0.523015\n",
      "[194]\ttraining's binary_logloss: 0.522798\n",
      "[195]\ttraining's binary_logloss: 0.522533\n",
      "[196]\ttraining's binary_logloss: 0.522302\n",
      "[197]\ttraining's binary_logloss: 0.522089\n",
      "[198]\ttraining's binary_logloss: 0.52186\n",
      "[199]\ttraining's binary_logloss: 0.521641\n",
      "[200]\ttraining's binary_logloss: 0.521433\n",
      "[201]\ttraining's binary_logloss: 0.521193\n",
      "[202]\ttraining's binary_logloss: 0.520972\n",
      "[203]\ttraining's binary_logloss: 0.520725\n",
      "[204]\ttraining's binary_logloss: 0.520507\n",
      "[205]\ttraining's binary_logloss: 0.520267\n",
      "[206]\ttraining's binary_logloss: 0.520087\n",
      "[207]\ttraining's binary_logloss: 0.519879\n",
      "[208]\ttraining's binary_logloss: 0.519677\n",
      "[209]\ttraining's binary_logloss: 0.519446\n",
      "[210]\ttraining's binary_logloss: 0.519226\n",
      "[211]\ttraining's binary_logloss: 0.518979\n",
      "[212]\ttraining's binary_logloss: 0.518788\n",
      "[213]\ttraining's binary_logloss: 0.518527\n",
      "[214]\ttraining's binary_logloss: 0.518296\n",
      "[215]\ttraining's binary_logloss: 0.51805\n",
      "[216]\ttraining's binary_logloss: 0.517797\n",
      "[217]\ttraining's binary_logloss: 0.517518\n",
      "[218]\ttraining's binary_logloss: 0.51725\n",
      "[219]\ttraining's binary_logloss: 0.517006\n",
      "[220]\ttraining's binary_logloss: 0.516773\n",
      "[221]\ttraining's binary_logloss: 0.516511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[222]\ttraining's binary_logloss: 0.516282\n",
      "[223]\ttraining's binary_logloss: 0.516044\n",
      "[224]\ttraining's binary_logloss: 0.515804\n",
      "[225]\ttraining's binary_logloss: 0.515581\n",
      "[226]\ttraining's binary_logloss: 0.515332\n",
      "[227]\ttraining's binary_logloss: 0.515097\n",
      "[228]\ttraining's binary_logloss: 0.5148\n",
      "[229]\ttraining's binary_logloss: 0.514543\n",
      "[230]\ttraining's binary_logloss: 0.514298\n",
      "[231]\ttraining's binary_logloss: 0.514079\n",
      "[232]\ttraining's binary_logloss: 0.513835\n",
      "[233]\ttraining's binary_logloss: 0.51362\n",
      "[234]\ttraining's binary_logloss: 0.5134\n",
      "[235]\ttraining's binary_logloss: 0.513162\n",
      "[236]\ttraining's binary_logloss: 0.51295\n",
      "[237]\ttraining's binary_logloss: 0.512719\n",
      "[238]\ttraining's binary_logloss: 0.512503\n",
      "[239]\ttraining's binary_logloss: 0.512303\n",
      "[240]\ttraining's binary_logloss: 0.512077\n",
      "[241]\ttraining's binary_logloss: 0.511802\n",
      "[242]\ttraining's binary_logloss: 0.511528\n",
      "[243]\ttraining's binary_logloss: 0.511286\n",
      "[244]\ttraining's binary_logloss: 0.511026\n",
      "[245]\ttraining's binary_logloss: 0.51077\n",
      "[246]\ttraining's binary_logloss: 0.510477\n",
      "[247]\ttraining's binary_logloss: 0.510229\n",
      "[248]\ttraining's binary_logloss: 0.509973\n",
      "[249]\ttraining's binary_logloss: 0.509724\n",
      "[250]\ttraining's binary_logloss: 0.509463\n",
      "[251]\ttraining's binary_logloss: 0.509274\n",
      "[252]\ttraining's binary_logloss: 0.509029\n",
      "[253]\ttraining's binary_logloss: 0.508789\n",
      "[254]\ttraining's binary_logloss: 0.508547\n",
      "[255]\ttraining's binary_logloss: 0.508317\n",
      "[256]\ttraining's binary_logloss: 0.508057\n",
      "[257]\ttraining's binary_logloss: 0.507834\n",
      "[258]\ttraining's binary_logloss: 0.507562\n",
      "[259]\ttraining's binary_logloss: 0.507313\n",
      "[260]\ttraining's binary_logloss: 0.507088\n",
      "[261]\ttraining's binary_logloss: 0.506811\n",
      "[262]\ttraining's binary_logloss: 0.50654\n",
      "[263]\ttraining's binary_logloss: 0.506293\n",
      "[264]\ttraining's binary_logloss: 0.506017\n",
      "[265]\ttraining's binary_logloss: 0.505808\n",
      "[266]\ttraining's binary_logloss: 0.505588\n",
      "[267]\ttraining's binary_logloss: 0.505354\n",
      "[268]\ttraining's binary_logloss: 0.505134\n",
      "[269]\ttraining's binary_logloss: 0.504882\n",
      "[270]\ttraining's binary_logloss: 0.504613\n",
      "[271]\ttraining's binary_logloss: 0.504331\n",
      "[272]\ttraining's binary_logloss: 0.503999\n",
      "[273]\ttraining's binary_logloss: 0.50369\n",
      "[274]\ttraining's binary_logloss: 0.503389\n",
      "[275]\ttraining's binary_logloss: 0.503093\n",
      "[276]\ttraining's binary_logloss: 0.50286\n",
      "[277]\ttraining's binary_logloss: 0.502547\n",
      "[278]\ttraining's binary_logloss: 0.502264\n",
      "[279]\ttraining's binary_logloss: 0.501974\n",
      "[280]\ttraining's binary_logloss: 0.501741\n",
      "[281]\ttraining's binary_logloss: 0.501487\n",
      "[282]\ttraining's binary_logloss: 0.50122\n",
      "[283]\ttraining's binary_logloss: 0.500995\n",
      "[284]\ttraining's binary_logloss: 0.50074\n",
      "[285]\ttraining's binary_logloss: 0.500458\n",
      "[286]\ttraining's binary_logloss: 0.500139\n",
      "[287]\ttraining's binary_logloss: 0.499891\n",
      "[288]\ttraining's binary_logloss: 0.499599\n",
      "[289]\ttraining's binary_logloss: 0.499287\n",
      "[290]\ttraining's binary_logloss: 0.499002\n",
      "[291]\ttraining's binary_logloss: 0.498716\n",
      "[292]\ttraining's binary_logloss: 0.498411\n",
      "[293]\ttraining's binary_logloss: 0.49817\n",
      "[294]\ttraining's binary_logloss: 0.497906\n",
      "[295]\ttraining's binary_logloss: 0.497638\n",
      "[296]\ttraining's binary_logloss: 0.497388\n",
      "[297]\ttraining's binary_logloss: 0.497116\n",
      "[298]\ttraining's binary_logloss: 0.496867\n",
      "[299]\ttraining's binary_logloss: 0.4966\n",
      "[300]\ttraining's binary_logloss: 0.49636\n",
      "[301]\ttraining's binary_logloss: 0.496125\n",
      "[302]\ttraining's binary_logloss: 0.495877\n",
      "[303]\ttraining's binary_logloss: 0.495641\n",
      "[304]\ttraining's binary_logloss: 0.495397\n",
      "[305]\ttraining's binary_logloss: 0.49514\n",
      "[306]\ttraining's binary_logloss: 0.494899\n",
      "[307]\ttraining's binary_logloss: 0.494689\n",
      "[308]\ttraining's binary_logloss: 0.49448\n",
      "[309]\ttraining's binary_logloss: 0.494257\n",
      "[310]\ttraining's binary_logloss: 0.494047\n",
      "[311]\ttraining's binary_logloss: 0.493832\n",
      "[312]\ttraining's binary_logloss: 0.493567\n",
      "[313]\ttraining's binary_logloss: 0.493271\n",
      "[314]\ttraining's binary_logloss: 0.492992\n",
      "[315]\ttraining's binary_logloss: 0.49275\n",
      "[316]\ttraining's binary_logloss: 0.492464\n",
      "[317]\ttraining's binary_logloss: 0.492189\n",
      "[318]\ttraining's binary_logloss: 0.491938\n",
      "[319]\ttraining's binary_logloss: 0.491708\n",
      "[320]\ttraining's binary_logloss: 0.491465\n",
      "[321]\ttraining's binary_logloss: 0.4912\n",
      "[322]\ttraining's binary_logloss: 0.490949\n",
      "[323]\ttraining's binary_logloss: 0.490697\n",
      "[324]\ttraining's binary_logloss: 0.49043\n",
      "[325]\ttraining's binary_logloss: 0.49016\n",
      "[326]\ttraining's binary_logloss: 0.489913\n",
      "[327]\ttraining's binary_logloss: 0.48966\n",
      "[328]\ttraining's binary_logloss: 0.489421\n",
      "[329]\ttraining's binary_logloss: 0.489153\n",
      "[330]\ttraining's binary_logloss: 0.488909\n",
      "[331]\ttraining's binary_logloss: 0.488641\n",
      "[332]\ttraining's binary_logloss: 0.488388\n",
      "[333]\ttraining's binary_logloss: 0.488115\n",
      "[334]\ttraining's binary_logloss: 0.487877\n",
      "[335]\ttraining's binary_logloss: 0.487635\n",
      "[336]\ttraining's binary_logloss: 0.487342\n",
      "[337]\ttraining's binary_logloss: 0.487049\n",
      "[338]\ttraining's binary_logloss: 0.486757\n",
      "[339]\ttraining's binary_logloss: 0.486478\n",
      "[340]\ttraining's binary_logloss: 0.486222\n",
      "[341]\ttraining's binary_logloss: 0.486022\n",
      "[342]\ttraining's binary_logloss: 0.485807\n",
      "[343]\ttraining's binary_logloss: 0.485604\n",
      "[344]\ttraining's binary_logloss: 0.485397\n",
      "[345]\ttraining's binary_logloss: 0.485192\n",
      "[346]\ttraining's binary_logloss: 0.485005\n",
      "[347]\ttraining's binary_logloss: 0.484827\n",
      "[348]\ttraining's binary_logloss: 0.484636\n",
      "[349]\ttraining's binary_logloss: 0.484423\n",
      "[350]\ttraining's binary_logloss: 0.48427\n",
      "[351]\ttraining's binary_logloss: 0.483975\n",
      "[352]\ttraining's binary_logloss: 0.483715\n",
      "[353]\ttraining's binary_logloss: 0.483472\n",
      "[354]\ttraining's binary_logloss: 0.483178\n",
      "[355]\ttraining's binary_logloss: 0.482912\n",
      "[356]\ttraining's binary_logloss: 0.482637\n",
      "[357]\ttraining's binary_logloss: 0.482355\n",
      "[358]\ttraining's binary_logloss: 0.482102\n",
      "[359]\ttraining's binary_logloss: 0.481832\n",
      "[360]\ttraining's binary_logloss: 0.481538\n",
      "[361]\ttraining's binary_logloss: 0.481256\n",
      "[362]\ttraining's binary_logloss: 0.481008\n",
      "[363]\ttraining's binary_logloss: 0.480745\n",
      "[364]\ttraining's binary_logloss: 0.480491\n",
      "[365]\ttraining's binary_logloss: 0.480229\n",
      "[366]\ttraining's binary_logloss: 0.480002\n",
      "[367]\ttraining's binary_logloss: 0.479766\n",
      "[368]\ttraining's binary_logloss: 0.479527\n",
      "[369]\ttraining's binary_logloss: 0.479268\n",
      "[370]\ttraining's binary_logloss: 0.479044\n",
      "[371]\ttraining's binary_logloss: 0.478845\n",
      "[372]\ttraining's binary_logloss: 0.478622\n",
      "[373]\ttraining's binary_logloss: 0.478433\n",
      "[374]\ttraining's binary_logloss: 0.478226\n",
      "[375]\ttraining's binary_logloss: 0.478039\n",
      "[376]\ttraining's binary_logloss: 0.477815\n",
      "[377]\ttraining's binary_logloss: 0.477588\n",
      "[378]\ttraining's binary_logloss: 0.477342\n",
      "[379]\ttraining's binary_logloss: 0.477112\n",
      "[380]\ttraining's binary_logloss: 0.476893\n",
      "[381]\ttraining's binary_logloss: 0.476652\n",
      "[382]\ttraining's binary_logloss: 0.476416\n",
      "[383]\ttraining's binary_logloss: 0.476214\n",
      "[384]\ttraining's binary_logloss: 0.47598\n",
      "[385]\ttraining's binary_logloss: 0.475751\n",
      "[386]\ttraining's binary_logloss: 0.475494\n",
      "[387]\ttraining's binary_logloss: 0.475227\n",
      "[388]\ttraining's binary_logloss: 0.475003\n",
      "[389]\ttraining's binary_logloss: 0.474748\n",
      "[390]\ttraining's binary_logloss: 0.474502\n",
      "[391]\ttraining's binary_logloss: 0.474222\n",
      "[392]\ttraining's binary_logloss: 0.473948\n",
      "[393]\ttraining's binary_logloss: 0.473677\n",
      "[394]\ttraining's binary_logloss: 0.473431\n",
      "[395]\ttraining's binary_logloss: 0.473154\n",
      "[396]\ttraining's binary_logloss: 0.472954\n",
      "[397]\ttraining's binary_logloss: 0.472748\n",
      "[398]\ttraining's binary_logloss: 0.472563\n",
      "[399]\ttraining's binary_logloss: 0.472385\n",
      "[400]\ttraining's binary_logloss: 0.472209\n",
      "[401]\ttraining's binary_logloss: 0.471955\n",
      "[402]\ttraining's binary_logloss: 0.47166\n",
      "[403]\ttraining's binary_logloss: 0.471394\n",
      "[404]\ttraining's binary_logloss: 0.471123\n",
      "[405]\ttraining's binary_logloss: 0.470918\n",
      "[406]\ttraining's binary_logloss: 0.470637\n",
      "[407]\ttraining's binary_logloss: 0.470359\n",
      "[408]\ttraining's binary_logloss: 0.470104\n",
      "[409]\ttraining's binary_logloss: 0.469836\n",
      "[410]\ttraining's binary_logloss: 0.469594\n",
      "[411]\ttraining's binary_logloss: 0.46931\n",
      "[412]\ttraining's binary_logloss: 0.46905\n",
      "[413]\ttraining's binary_logloss: 0.468783\n",
      "[414]\ttraining's binary_logloss: 0.468546\n",
      "[415]\ttraining's binary_logloss: 0.468309\n",
      "[416]\ttraining's binary_logloss: 0.468082\n",
      "[417]\ttraining's binary_logloss: 0.467877\n",
      "[418]\ttraining's binary_logloss: 0.467614\n",
      "[419]\ttraining's binary_logloss: 0.467361\n",
      "[420]\ttraining's binary_logloss: 0.467135\n",
      "[421]\ttraining's binary_logloss: 0.466941\n",
      "[422]\ttraining's binary_logloss: 0.46675\n",
      "[423]\ttraining's binary_logloss: 0.466557\n",
      "[424]\ttraining's binary_logloss: 0.466341\n",
      "[425]\ttraining's binary_logloss: 0.466135\n",
      "[426]\ttraining's binary_logloss: 0.465905\n",
      "[427]\ttraining's binary_logloss: 0.465685\n",
      "[428]\ttraining's binary_logloss: 0.465437\n",
      "[429]\ttraining's binary_logloss: 0.465204\n",
      "[430]\ttraining's binary_logloss: 0.464987\n",
      "[431]\ttraining's binary_logloss: 0.46472\n",
      "[432]\ttraining's binary_logloss: 0.464464\n",
      "[433]\ttraining's binary_logloss: 0.464186\n",
      "[434]\ttraining's binary_logloss: 0.463946\n",
      "[435]\ttraining's binary_logloss: 0.463695\n",
      "[436]\ttraining's binary_logloss: 0.463468\n",
      "[437]\ttraining's binary_logloss: 0.463249\n",
      "[438]\ttraining's binary_logloss: 0.463023\n",
      "[439]\ttraining's binary_logloss: 0.462802\n",
      "[440]\ttraining's binary_logloss: 0.462571\n",
      "[441]\ttraining's binary_logloss: 0.462321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[442]\ttraining's binary_logloss: 0.462082\n",
      "[443]\ttraining's binary_logloss: 0.46185\n",
      "[444]\ttraining's binary_logloss: 0.461605\n",
      "[445]\ttraining's binary_logloss: 0.461342\n",
      "[446]\ttraining's binary_logloss: 0.461073\n",
      "[447]\ttraining's binary_logloss: 0.460831\n",
      "[448]\ttraining's binary_logloss: 0.460589\n",
      "[449]\ttraining's binary_logloss: 0.460354\n",
      "[450]\ttraining's binary_logloss: 0.460183\n",
      "[451]\ttraining's binary_logloss: 0.459959\n",
      "[452]\ttraining's binary_logloss: 0.459714\n",
      "[453]\ttraining's binary_logloss: 0.459487\n",
      "[454]\ttraining's binary_logloss: 0.459255\n",
      "[455]\ttraining's binary_logloss: 0.459026\n",
      "[456]\ttraining's binary_logloss: 0.45879\n",
      "[457]\ttraining's binary_logloss: 0.458562\n",
      "[458]\ttraining's binary_logloss: 0.45834\n",
      "[459]\ttraining's binary_logloss: 0.45811\n",
      "[460]\ttraining's binary_logloss: 0.457879\n",
      "[461]\ttraining's binary_logloss: 0.457677\n",
      "[462]\ttraining's binary_logloss: 0.457439\n",
      "[463]\ttraining's binary_logloss: 0.457178\n",
      "[464]\ttraining's binary_logloss: 0.456921\n",
      "[465]\ttraining's binary_logloss: 0.456691\n",
      "[466]\ttraining's binary_logloss: 0.456465\n",
      "[467]\ttraining's binary_logloss: 0.456239\n",
      "[468]\ttraining's binary_logloss: 0.456032\n",
      "[469]\ttraining's binary_logloss: 0.455833\n",
      "[470]\ttraining's binary_logloss: 0.455614\n",
      "[471]\ttraining's binary_logloss: 0.455405\n",
      "[472]\ttraining's binary_logloss: 0.45521\n",
      "[473]\ttraining's binary_logloss: 0.455028\n",
      "[474]\ttraining's binary_logloss: 0.454853\n",
      "[475]\ttraining's binary_logloss: 0.45465\n",
      "[476]\ttraining's binary_logloss: 0.454413\n",
      "[477]\ttraining's binary_logloss: 0.454139\n",
      "[478]\ttraining's binary_logloss: 0.453868\n",
      "[479]\ttraining's binary_logloss: 0.453635\n",
      "[480]\ttraining's binary_logloss: 0.453381\n",
      "[481]\ttraining's binary_logloss: 0.453157\n",
      "[482]\ttraining's binary_logloss: 0.452954\n",
      "[483]\ttraining's binary_logloss: 0.452738\n",
      "[484]\ttraining's binary_logloss: 0.452554\n",
      "[485]\ttraining's binary_logloss: 0.452339\n",
      "[486]\ttraining's binary_logloss: 0.452059\n",
      "[487]\ttraining's binary_logloss: 0.451771\n",
      "[488]\ttraining's binary_logloss: 0.451514\n",
      "[489]\ttraining's binary_logloss: 0.451223\n",
      "[490]\ttraining's binary_logloss: 0.450943\n",
      "[491]\ttraining's binary_logloss: 0.450717\n",
      "[492]\ttraining's binary_logloss: 0.450499\n",
      "[493]\ttraining's binary_logloss: 0.45029\n",
      "[494]\ttraining's binary_logloss: 0.45008\n",
      "[495]\ttraining's binary_logloss: 0.449864\n",
      "[496]\ttraining's binary_logloss: 0.449634\n",
      "[497]\ttraining's binary_logloss: 0.449346\n",
      "[498]\ttraining's binary_logloss: 0.449143\n",
      "[499]\ttraining's binary_logloss: 0.448924\n",
      "[500]\ttraining's binary_logloss: 0.448717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.617107\n",
      "[2]\ttraining's binary_logloss: 0.615535\n",
      "[3]\ttraining's binary_logloss: 0.614047\n",
      "[4]\ttraining's binary_logloss: 0.612507\n",
      "[5]\ttraining's binary_logloss: 0.610989\n",
      "[6]\ttraining's binary_logloss: 0.609492\n",
      "[7]\ttraining's binary_logloss: 0.608047\n",
      "[8]\ttraining's binary_logloss: 0.606639\n",
      "[9]\ttraining's binary_logloss: 0.605273\n",
      "[10]\ttraining's binary_logloss: 0.603933\n",
      "[11]\ttraining's binary_logloss: 0.602604\n",
      "[12]\ttraining's binary_logloss: 0.601335\n",
      "[13]\ttraining's binary_logloss: 0.600101\n",
      "[14]\ttraining's binary_logloss: 0.59883\n",
      "[15]\ttraining's binary_logloss: 0.597595\n",
      "[16]\ttraining's binary_logloss: 0.596471\n",
      "[17]\ttraining's binary_logloss: 0.595364\n",
      "[18]\ttraining's binary_logloss: 0.594306\n",
      "[19]\ttraining's binary_logloss: 0.593186\n",
      "[20]\ttraining's binary_logloss: 0.592192\n",
      "[21]\ttraining's binary_logloss: 0.591057\n",
      "[22]\ttraining's binary_logloss: 0.590076\n",
      "[23]\ttraining's binary_logloss: 0.589015\n",
      "[24]\ttraining's binary_logloss: 0.587992\n",
      "[25]\ttraining's binary_logloss: 0.58702\n",
      "[26]\ttraining's binary_logloss: 0.586117\n",
      "[27]\ttraining's binary_logloss: 0.585222\n",
      "[28]\ttraining's binary_logloss: 0.584367\n",
      "[29]\ttraining's binary_logloss: 0.583594\n",
      "[30]\ttraining's binary_logloss: 0.582765\n",
      "[31]\ttraining's binary_logloss: 0.581956\n",
      "[32]\ttraining's binary_logloss: 0.581127\n",
      "[33]\ttraining's binary_logloss: 0.580372\n",
      "[34]\ttraining's binary_logloss: 0.579619\n",
      "[35]\ttraining's binary_logloss: 0.578839\n",
      "[36]\ttraining's binary_logloss: 0.578078\n",
      "[37]\ttraining's binary_logloss: 0.577357\n",
      "[38]\ttraining's binary_logloss: 0.576675\n",
      "[39]\ttraining's binary_logloss: 0.575966\n",
      "[40]\ttraining's binary_logloss: 0.575283\n",
      "[41]\ttraining's binary_logloss: 0.574655\n",
      "[42]\ttraining's binary_logloss: 0.573997\n",
      "[43]\ttraining's binary_logloss: 0.573432\n",
      "[44]\ttraining's binary_logloss: 0.572816\n",
      "[45]\ttraining's binary_logloss: 0.572233\n",
      "[46]\ttraining's binary_logloss: 0.571623\n",
      "[47]\ttraining's binary_logloss: 0.571038\n",
      "[48]\ttraining's binary_logloss: 0.570452\n",
      "[49]\ttraining's binary_logloss: 0.569909\n",
      "[50]\ttraining's binary_logloss: 0.569385\n",
      "[51]\ttraining's binary_logloss: 0.568828\n",
      "[52]\ttraining's binary_logloss: 0.568299\n",
      "[53]\ttraining's binary_logloss: 0.567748\n",
      "[54]\ttraining's binary_logloss: 0.567245\n",
      "[55]\ttraining's binary_logloss: 0.566735\n",
      "[56]\ttraining's binary_logloss: 0.566302\n",
      "[57]\ttraining's binary_logloss: 0.565847\n",
      "[58]\ttraining's binary_logloss: 0.565401\n",
      "[59]\ttraining's binary_logloss: 0.564985\n",
      "[60]\ttraining's binary_logloss: 0.564596\n",
      "[61]\ttraining's binary_logloss: 0.564175\n",
      "[62]\ttraining's binary_logloss: 0.563722\n",
      "[63]\ttraining's binary_logloss: 0.56332\n",
      "[64]\ttraining's binary_logloss: 0.562923\n",
      "[65]\ttraining's binary_logloss: 0.562462\n",
      "[66]\ttraining's binary_logloss: 0.561968\n",
      "[67]\ttraining's binary_logloss: 0.561534\n",
      "[68]\ttraining's binary_logloss: 0.561077\n",
      "[69]\ttraining's binary_logloss: 0.560621\n",
      "[70]\ttraining's binary_logloss: 0.560174\n",
      "[71]\ttraining's binary_logloss: 0.559761\n",
      "[72]\ttraining's binary_logloss: 0.559293\n",
      "[73]\ttraining's binary_logloss: 0.558908\n",
      "[74]\ttraining's binary_logloss: 0.558497\n",
      "[75]\ttraining's binary_logloss: 0.558109\n",
      "[76]\ttraining's binary_logloss: 0.557654\n",
      "[77]\ttraining's binary_logloss: 0.557227\n",
      "[78]\ttraining's binary_logloss: 0.556904\n",
      "[79]\ttraining's binary_logloss: 0.556508\n",
      "[80]\ttraining's binary_logloss: 0.556158\n",
      "[81]\ttraining's binary_logloss: 0.555837\n",
      "[82]\ttraining's binary_logloss: 0.555487\n",
      "[83]\ttraining's binary_logloss: 0.555173\n",
      "[84]\ttraining's binary_logloss: 0.554836\n",
      "[85]\ttraining's binary_logloss: 0.55446\n",
      "[86]\ttraining's binary_logloss: 0.554121\n",
      "[87]\ttraining's binary_logloss: 0.553789\n",
      "[88]\ttraining's binary_logloss: 0.55345\n",
      "[89]\ttraining's binary_logloss: 0.553123\n",
      "[90]\ttraining's binary_logloss: 0.552867\n",
      "[91]\ttraining's binary_logloss: 0.552535\n",
      "[92]\ttraining's binary_logloss: 0.552202\n",
      "[93]\ttraining's binary_logloss: 0.551881\n",
      "[94]\ttraining's binary_logloss: 0.551595\n",
      "[95]\ttraining's binary_logloss: 0.551255\n",
      "[96]\ttraining's binary_logloss: 0.550976\n",
      "[97]\ttraining's binary_logloss: 0.550685\n",
      "[98]\ttraining's binary_logloss: 0.550412\n",
      "[99]\ttraining's binary_logloss: 0.550043\n",
      "[100]\ttraining's binary_logloss: 0.549801\n",
      "[101]\ttraining's binary_logloss: 0.549506\n",
      "[102]\ttraining's binary_logloss: 0.549243\n",
      "[103]\ttraining's binary_logloss: 0.548964\n",
      "[104]\ttraining's binary_logloss: 0.548684\n",
      "[105]\ttraining's binary_logloss: 0.548407\n",
      "[106]\ttraining's binary_logloss: 0.548093\n",
      "[107]\ttraining's binary_logloss: 0.547767\n",
      "[108]\ttraining's binary_logloss: 0.547462\n",
      "[109]\ttraining's binary_logloss: 0.547165\n",
      "[110]\ttraining's binary_logloss: 0.54688\n",
      "[111]\ttraining's binary_logloss: 0.54662\n",
      "[112]\ttraining's binary_logloss: 0.54637\n",
      "[113]\ttraining's binary_logloss: 0.546129\n",
      "[114]\ttraining's binary_logloss: 0.545907\n",
      "[115]\ttraining's binary_logloss: 0.545649\n",
      "[116]\ttraining's binary_logloss: 0.545372\n",
      "[117]\ttraining's binary_logloss: 0.545107\n",
      "[118]\ttraining's binary_logloss: 0.544818\n",
      "[119]\ttraining's binary_logloss: 0.544528\n",
      "[120]\ttraining's binary_logloss: 0.544268\n",
      "[121]\ttraining's binary_logloss: 0.544033\n",
      "[122]\ttraining's binary_logloss: 0.543814\n",
      "[123]\ttraining's binary_logloss: 0.543596\n",
      "[124]\ttraining's binary_logloss: 0.543395\n",
      "[125]\ttraining's binary_logloss: 0.543127\n",
      "[126]\ttraining's binary_logloss: 0.542902\n",
      "[127]\ttraining's binary_logloss: 0.542677\n",
      "[128]\ttraining's binary_logloss: 0.542424\n",
      "[129]\ttraining's binary_logloss: 0.542179\n",
      "[130]\ttraining's binary_logloss: 0.541911\n",
      "[131]\ttraining's binary_logloss: 0.541661\n",
      "[132]\ttraining's binary_logloss: 0.541405\n",
      "[133]\ttraining's binary_logloss: 0.541168\n",
      "[134]\ttraining's binary_logloss: 0.540916\n",
      "[135]\ttraining's binary_logloss: 0.540669\n",
      "[136]\ttraining's binary_logloss: 0.540405\n",
      "[137]\ttraining's binary_logloss: 0.540112\n",
      "[138]\ttraining's binary_logloss: 0.539859\n",
      "[139]\ttraining's binary_logloss: 0.53959\n",
      "[140]\ttraining's binary_logloss: 0.539282\n",
      "[141]\ttraining's binary_logloss: 0.538978\n",
      "[142]\ttraining's binary_logloss: 0.538683\n",
      "[143]\ttraining's binary_logloss: 0.5384\n",
      "[144]\ttraining's binary_logloss: 0.538075\n",
      "[145]\ttraining's binary_logloss: 0.53779\n",
      "[146]\ttraining's binary_logloss: 0.537507\n",
      "[147]\ttraining's binary_logloss: 0.537202\n",
      "[148]\ttraining's binary_logloss: 0.536916\n",
      "[149]\ttraining's binary_logloss: 0.536603\n",
      "[150]\ttraining's binary_logloss: 0.536342\n",
      "[151]\ttraining's binary_logloss: 0.536118\n",
      "[152]\ttraining's binary_logloss: 0.535916\n",
      "[153]\ttraining's binary_logloss: 0.535731\n",
      "[154]\ttraining's binary_logloss: 0.535478\n",
      "[155]\ttraining's binary_logloss: 0.535264\n",
      "[156]\ttraining's binary_logloss: 0.534991\n",
      "[157]\ttraining's binary_logloss: 0.534692\n",
      "[158]\ttraining's binary_logloss: 0.534426\n",
      "[159]\ttraining's binary_logloss: 0.534175\n",
      "[160]\ttraining's binary_logloss: 0.533893\n",
      "[161]\ttraining's binary_logloss: 0.53366\n",
      "[162]\ttraining's binary_logloss: 0.533392\n",
      "[163]\ttraining's binary_logloss: 0.533147\n",
      "[164]\ttraining's binary_logloss: 0.532896\n",
      "[165]\ttraining's binary_logloss: 0.532676\n",
      "[166]\ttraining's binary_logloss: 0.532365\n",
      "[167]\ttraining's binary_logloss: 0.532088\n",
      "[168]\ttraining's binary_logloss: 0.531831\n",
      "[169]\ttraining's binary_logloss: 0.531557\n",
      "[170]\ttraining's binary_logloss: 0.53128\n",
      "[171]\ttraining's binary_logloss: 0.531035\n",
      "[172]\ttraining's binary_logloss: 0.530756\n",
      "[173]\ttraining's binary_logloss: 0.530506\n",
      "[174]\ttraining's binary_logloss: 0.530262\n",
      "[175]\ttraining's binary_logloss: 0.530041\n",
      "[176]\ttraining's binary_logloss: 0.529845\n",
      "[177]\ttraining's binary_logloss: 0.529626\n",
      "[178]\ttraining's binary_logloss: 0.529375\n",
      "[179]\ttraining's binary_logloss: 0.529142\n",
      "[180]\ttraining's binary_logloss: 0.528912\n",
      "[181]\ttraining's binary_logloss: 0.528685\n",
      "[182]\ttraining's binary_logloss: 0.528408\n",
      "[183]\ttraining's binary_logloss: 0.528136\n",
      "[184]\ttraining's binary_logloss: 0.527883\n",
      "[185]\ttraining's binary_logloss: 0.52763\n",
      "[186]\ttraining's binary_logloss: 0.527417\n",
      "[187]\ttraining's binary_logloss: 0.527243\n",
      "[188]\ttraining's binary_logloss: 0.527021\n",
      "[189]\ttraining's binary_logloss: 0.52676\n",
      "[190]\ttraining's binary_logloss: 0.526518\n",
      "[191]\ttraining's binary_logloss: 0.526261\n",
      "[192]\ttraining's binary_logloss: 0.526049\n",
      "[193]\ttraining's binary_logloss: 0.525776\n",
      "[194]\ttraining's binary_logloss: 0.525531\n",
      "[195]\ttraining's binary_logloss: 0.525269\n",
      "[196]\ttraining's binary_logloss: 0.52502\n",
      "[197]\ttraining's binary_logloss: 0.524767\n",
      "[198]\ttraining's binary_logloss: 0.524523\n",
      "[199]\ttraining's binary_logloss: 0.524327\n",
      "[200]\ttraining's binary_logloss: 0.524127\n",
      "[201]\ttraining's binary_logloss: 0.523869\n",
      "[202]\ttraining's binary_logloss: 0.523618\n",
      "[203]\ttraining's binary_logloss: 0.523371\n",
      "[204]\ttraining's binary_logloss: 0.523124\n",
      "[205]\ttraining's binary_logloss: 0.522842\n",
      "[206]\ttraining's binary_logloss: 0.522638\n",
      "[207]\ttraining's binary_logloss: 0.522425\n",
      "[208]\ttraining's binary_logloss: 0.522231\n",
      "[209]\ttraining's binary_logloss: 0.522032\n",
      "[210]\ttraining's binary_logloss: 0.521829\n",
      "[211]\ttraining's binary_logloss: 0.521634\n",
      "[212]\ttraining's binary_logloss: 0.521392\n",
      "[213]\ttraining's binary_logloss: 0.521163\n",
      "[214]\ttraining's binary_logloss: 0.520915\n",
      "[215]\ttraining's binary_logloss: 0.52068\n",
      "[216]\ttraining's binary_logloss: 0.520432\n",
      "[217]\ttraining's binary_logloss: 0.520195\n",
      "[218]\ttraining's binary_logloss: 0.519938\n",
      "[219]\ttraining's binary_logloss: 0.51971\n",
      "[220]\ttraining's binary_logloss: 0.519484\n",
      "[221]\ttraining's binary_logloss: 0.51926\n",
      "[222]\ttraining's binary_logloss: 0.519013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[223]\ttraining's binary_logloss: 0.518762\n",
      "[224]\ttraining's binary_logloss: 0.518474\n",
      "[225]\ttraining's binary_logloss: 0.518216\n",
      "[226]\ttraining's binary_logloss: 0.51793\n",
      "[227]\ttraining's binary_logloss: 0.517656\n",
      "[228]\ttraining's binary_logloss: 0.517396\n",
      "[229]\ttraining's binary_logloss: 0.517123\n",
      "[230]\ttraining's binary_logloss: 0.516847\n",
      "[231]\ttraining's binary_logloss: 0.5166\n",
      "[232]\ttraining's binary_logloss: 0.516396\n",
      "[233]\ttraining's binary_logloss: 0.516177\n",
      "[234]\ttraining's binary_logloss: 0.515926\n",
      "[235]\ttraining's binary_logloss: 0.515702\n",
      "[236]\ttraining's binary_logloss: 0.515444\n",
      "[237]\ttraining's binary_logloss: 0.515148\n",
      "[238]\ttraining's binary_logloss: 0.51487\n",
      "[239]\ttraining's binary_logloss: 0.514586\n",
      "[240]\ttraining's binary_logloss: 0.514324\n",
      "[241]\ttraining's binary_logloss: 0.514057\n",
      "[242]\ttraining's binary_logloss: 0.513799\n",
      "[243]\ttraining's binary_logloss: 0.513531\n",
      "[244]\ttraining's binary_logloss: 0.513277\n",
      "[245]\ttraining's binary_logloss: 0.513012\n",
      "[246]\ttraining's binary_logloss: 0.512753\n",
      "[247]\ttraining's binary_logloss: 0.512457\n",
      "[248]\ttraining's binary_logloss: 0.51222\n",
      "[249]\ttraining's binary_logloss: 0.511948\n",
      "[250]\ttraining's binary_logloss: 0.511709\n",
      "[251]\ttraining's binary_logloss: 0.511481\n",
      "[252]\ttraining's binary_logloss: 0.511258\n",
      "[253]\ttraining's binary_logloss: 0.51101\n",
      "[254]\ttraining's binary_logloss: 0.510758\n",
      "[255]\ttraining's binary_logloss: 0.510517\n",
      "[256]\ttraining's binary_logloss: 0.510294\n",
      "[257]\ttraining's binary_logloss: 0.510066\n",
      "[258]\ttraining's binary_logloss: 0.509852\n",
      "[259]\ttraining's binary_logloss: 0.509627\n",
      "[260]\ttraining's binary_logloss: 0.509436\n",
      "[261]\ttraining's binary_logloss: 0.509174\n",
      "[262]\ttraining's binary_logloss: 0.508954\n",
      "[263]\ttraining's binary_logloss: 0.508724\n",
      "[264]\ttraining's binary_logloss: 0.508476\n",
      "[265]\ttraining's binary_logloss: 0.50826\n",
      "[266]\ttraining's binary_logloss: 0.508033\n",
      "[267]\ttraining's binary_logloss: 0.507793\n",
      "[268]\ttraining's binary_logloss: 0.507555\n",
      "[269]\ttraining's binary_logloss: 0.507312\n",
      "[270]\ttraining's binary_logloss: 0.507043\n",
      "[271]\ttraining's binary_logloss: 0.506775\n",
      "[272]\ttraining's binary_logloss: 0.506514\n",
      "[273]\ttraining's binary_logloss: 0.50623\n",
      "[274]\ttraining's binary_logloss: 0.505988\n",
      "[275]\ttraining's binary_logloss: 0.505692\n",
      "[276]\ttraining's binary_logloss: 0.505409\n",
      "[277]\ttraining's binary_logloss: 0.505126\n",
      "[278]\ttraining's binary_logloss: 0.50486\n",
      "[279]\ttraining's binary_logloss: 0.504601\n",
      "[280]\ttraining's binary_logloss: 0.504338\n",
      "[281]\ttraining's binary_logloss: 0.504059\n",
      "[282]\ttraining's binary_logloss: 0.503842\n",
      "[283]\ttraining's binary_logloss: 0.503598\n",
      "[284]\ttraining's binary_logloss: 0.503359\n",
      "[285]\ttraining's binary_logloss: 0.503113\n",
      "[286]\ttraining's binary_logloss: 0.502819\n",
      "[287]\ttraining's binary_logloss: 0.502584\n",
      "[288]\ttraining's binary_logloss: 0.502353\n",
      "[289]\ttraining's binary_logloss: 0.502101\n",
      "[290]\ttraining's binary_logloss: 0.501828\n",
      "[291]\ttraining's binary_logloss: 0.501533\n",
      "[292]\ttraining's binary_logloss: 0.501251\n",
      "[293]\ttraining's binary_logloss: 0.500935\n",
      "[294]\ttraining's binary_logloss: 0.500674\n",
      "[295]\ttraining's binary_logloss: 0.500408\n",
      "[296]\ttraining's binary_logloss: 0.500132\n",
      "[297]\ttraining's binary_logloss: 0.499869\n",
      "[298]\ttraining's binary_logloss: 0.49961\n",
      "[299]\ttraining's binary_logloss: 0.499351\n",
      "[300]\ttraining's binary_logloss: 0.499131\n",
      "[301]\ttraining's binary_logloss: 0.498886\n",
      "[302]\ttraining's binary_logloss: 0.49863\n",
      "[303]\ttraining's binary_logloss: 0.49838\n",
      "[304]\ttraining's binary_logloss: 0.498084\n",
      "[305]\ttraining's binary_logloss: 0.497791\n",
      "[306]\ttraining's binary_logloss: 0.49753\n",
      "[307]\ttraining's binary_logloss: 0.497267\n",
      "[308]\ttraining's binary_logloss: 0.497006\n",
      "[309]\ttraining's binary_logloss: 0.49676\n",
      "[310]\ttraining's binary_logloss: 0.496493\n",
      "[311]\ttraining's binary_logloss: 0.496236\n",
      "[312]\ttraining's binary_logloss: 0.495971\n",
      "[313]\ttraining's binary_logloss: 0.495734\n",
      "[314]\ttraining's binary_logloss: 0.495507\n",
      "[315]\ttraining's binary_logloss: 0.495243\n",
      "[316]\ttraining's binary_logloss: 0.494994\n",
      "[317]\ttraining's binary_logloss: 0.494754\n",
      "[318]\ttraining's binary_logloss: 0.494533\n",
      "[319]\ttraining's binary_logloss: 0.4943\n",
      "[320]\ttraining's binary_logloss: 0.494032\n",
      "[321]\ttraining's binary_logloss: 0.493785\n",
      "[322]\ttraining's binary_logloss: 0.493565\n",
      "[323]\ttraining's binary_logloss: 0.493328\n",
      "[324]\ttraining's binary_logloss: 0.493112\n",
      "[325]\ttraining's binary_logloss: 0.492863\n",
      "[326]\ttraining's binary_logloss: 0.492604\n",
      "[327]\ttraining's binary_logloss: 0.492374\n",
      "[328]\ttraining's binary_logloss: 0.492136\n",
      "[329]\ttraining's binary_logloss: 0.4919\n",
      "[330]\ttraining's binary_logloss: 0.491669\n",
      "[331]\ttraining's binary_logloss: 0.491411\n",
      "[332]\ttraining's binary_logloss: 0.491175\n",
      "[333]\ttraining's binary_logloss: 0.490928\n",
      "[334]\ttraining's binary_logloss: 0.490673\n",
      "[335]\ttraining's binary_logloss: 0.490406\n",
      "[336]\ttraining's binary_logloss: 0.49013\n",
      "[337]\ttraining's binary_logloss: 0.489885\n",
      "[338]\ttraining's binary_logloss: 0.489652\n",
      "[339]\ttraining's binary_logloss: 0.48941\n",
      "[340]\ttraining's binary_logloss: 0.489148\n",
      "[341]\ttraining's binary_logloss: 0.488962\n",
      "[342]\ttraining's binary_logloss: 0.48872\n",
      "[343]\ttraining's binary_logloss: 0.488463\n",
      "[344]\ttraining's binary_logloss: 0.488217\n",
      "[345]\ttraining's binary_logloss: 0.487998\n",
      "[346]\ttraining's binary_logloss: 0.487771\n",
      "[347]\ttraining's binary_logloss: 0.487561\n",
      "[348]\ttraining's binary_logloss: 0.48736\n",
      "[349]\ttraining's binary_logloss: 0.487179\n",
      "[350]\ttraining's binary_logloss: 0.486994\n",
      "[351]\ttraining's binary_logloss: 0.486745\n",
      "[352]\ttraining's binary_logloss: 0.486496\n",
      "[353]\ttraining's binary_logloss: 0.486245\n",
      "[354]\ttraining's binary_logloss: 0.485988\n",
      "[355]\ttraining's binary_logloss: 0.485749\n",
      "[356]\ttraining's binary_logloss: 0.485468\n",
      "[357]\ttraining's binary_logloss: 0.485198\n",
      "[358]\ttraining's binary_logloss: 0.484934\n",
      "[359]\ttraining's binary_logloss: 0.484662\n",
      "[360]\ttraining's binary_logloss: 0.4844\n",
      "[361]\ttraining's binary_logloss: 0.48414\n",
      "[362]\ttraining's binary_logloss: 0.483848\n",
      "[363]\ttraining's binary_logloss: 0.483576\n",
      "[364]\ttraining's binary_logloss: 0.483335\n",
      "[365]\ttraining's binary_logloss: 0.483126\n",
      "[366]\ttraining's binary_logloss: 0.482891\n",
      "[367]\ttraining's binary_logloss: 0.482677\n",
      "[368]\ttraining's binary_logloss: 0.482458\n",
      "[369]\ttraining's binary_logloss: 0.482228\n",
      "[370]\ttraining's binary_logloss: 0.482006\n",
      "[371]\ttraining's binary_logloss: 0.481784\n",
      "[372]\ttraining's binary_logloss: 0.481508\n",
      "[373]\ttraining's binary_logloss: 0.481259\n",
      "[374]\ttraining's binary_logloss: 0.481025\n",
      "[375]\ttraining's binary_logloss: 0.480787\n",
      "[376]\ttraining's binary_logloss: 0.480502\n",
      "[377]\ttraining's binary_logloss: 0.480241\n",
      "[378]\ttraining's binary_logloss: 0.480016\n",
      "[379]\ttraining's binary_logloss: 0.479751\n",
      "[380]\ttraining's binary_logloss: 0.479519\n",
      "[381]\ttraining's binary_logloss: 0.47927\n",
      "[382]\ttraining's binary_logloss: 0.479005\n",
      "[383]\ttraining's binary_logloss: 0.478721\n",
      "[384]\ttraining's binary_logloss: 0.478466\n",
      "[385]\ttraining's binary_logloss: 0.478175\n",
      "[386]\ttraining's binary_logloss: 0.477942\n",
      "[387]\ttraining's binary_logloss: 0.477686\n",
      "[388]\ttraining's binary_logloss: 0.477443\n",
      "[389]\ttraining's binary_logloss: 0.477207\n",
      "[390]\ttraining's binary_logloss: 0.476947\n",
      "[391]\ttraining's binary_logloss: 0.476686\n",
      "[392]\ttraining's binary_logloss: 0.476458\n",
      "[393]\ttraining's binary_logloss: 0.476237\n",
      "[394]\ttraining's binary_logloss: 0.47602\n",
      "[395]\ttraining's binary_logloss: 0.475763\n",
      "[396]\ttraining's binary_logloss: 0.47551\n",
      "[397]\ttraining's binary_logloss: 0.475259\n",
      "[398]\ttraining's binary_logloss: 0.474995\n",
      "[399]\ttraining's binary_logloss: 0.474744\n",
      "[400]\ttraining's binary_logloss: 0.474494\n",
      "[401]\ttraining's binary_logloss: 0.474244\n",
      "[402]\ttraining's binary_logloss: 0.473989\n",
      "[403]\ttraining's binary_logloss: 0.473705\n",
      "[404]\ttraining's binary_logloss: 0.473456\n",
      "[405]\ttraining's binary_logloss: 0.473164\n",
      "[406]\ttraining's binary_logloss: 0.472917\n",
      "[407]\ttraining's binary_logloss: 0.47263\n",
      "[408]\ttraining's binary_logloss: 0.472389\n",
      "[409]\ttraining's binary_logloss: 0.472122\n",
      "[410]\ttraining's binary_logloss: 0.471911\n",
      "[411]\ttraining's binary_logloss: 0.471671\n",
      "[412]\ttraining's binary_logloss: 0.471461\n",
      "[413]\ttraining's binary_logloss: 0.471227\n",
      "[414]\ttraining's binary_logloss: 0.471\n",
      "[415]\ttraining's binary_logloss: 0.470774\n",
      "[416]\ttraining's binary_logloss: 0.470529\n",
      "[417]\ttraining's binary_logloss: 0.470285\n",
      "[418]\ttraining's binary_logloss: 0.470045\n",
      "[419]\ttraining's binary_logloss: 0.469825\n",
      "[420]\ttraining's binary_logloss: 0.469581\n",
      "[421]\ttraining's binary_logloss: 0.469379\n",
      "[422]\ttraining's binary_logloss: 0.46918\n",
      "[423]\ttraining's binary_logloss: 0.46894\n",
      "[424]\ttraining's binary_logloss: 0.468738\n",
      "[425]\ttraining's binary_logloss: 0.468534\n",
      "[426]\ttraining's binary_logloss: 0.46832\n",
      "[427]\ttraining's binary_logloss: 0.468083\n",
      "[428]\ttraining's binary_logloss: 0.467864\n",
      "[429]\ttraining's binary_logloss: 0.467625\n",
      "[430]\ttraining's binary_logloss: 0.467394\n",
      "[431]\ttraining's binary_logloss: 0.467149\n",
      "[432]\ttraining's binary_logloss: 0.46693\n",
      "[433]\ttraining's binary_logloss: 0.466693\n",
      "[434]\ttraining's binary_logloss: 0.466438\n",
      "[435]\ttraining's binary_logloss: 0.466183\n",
      "[436]\ttraining's binary_logloss: 0.465969\n",
      "[437]\ttraining's binary_logloss: 0.465724\n",
      "[438]\ttraining's binary_logloss: 0.465476\n",
      "[439]\ttraining's binary_logloss: 0.465272\n",
      "[440]\ttraining's binary_logloss: 0.46506\n",
      "[441]\ttraining's binary_logloss: 0.464785\n",
      "[442]\ttraining's binary_logloss: 0.464513\n",
      "[443]\ttraining's binary_logloss: 0.464251\n",
      "[444]\ttraining's binary_logloss: 0.463998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[445]\ttraining's binary_logloss: 0.463729\n",
      "[446]\ttraining's binary_logloss: 0.463544\n",
      "[447]\ttraining's binary_logloss: 0.463358\n",
      "[448]\ttraining's binary_logloss: 0.463107\n",
      "[449]\ttraining's binary_logloss: 0.462936\n",
      "[450]\ttraining's binary_logloss: 0.462746\n",
      "[451]\ttraining's binary_logloss: 0.462519\n",
      "[452]\ttraining's binary_logloss: 0.462304\n",
      "[453]\ttraining's binary_logloss: 0.462097\n",
      "[454]\ttraining's binary_logloss: 0.461895\n",
      "[455]\ttraining's binary_logloss: 0.461676\n",
      "[456]\ttraining's binary_logloss: 0.461384\n",
      "[457]\ttraining's binary_logloss: 0.461099\n",
      "[458]\ttraining's binary_logloss: 0.460832\n",
      "[459]\ttraining's binary_logloss: 0.460539\n",
      "[460]\ttraining's binary_logloss: 0.460275\n",
      "[461]\ttraining's binary_logloss: 0.460055\n",
      "[462]\ttraining's binary_logloss: 0.459817\n",
      "[463]\ttraining's binary_logloss: 0.459623\n",
      "[464]\ttraining's binary_logloss: 0.459415\n",
      "[465]\ttraining's binary_logloss: 0.459191\n",
      "[466]\ttraining's binary_logloss: 0.458916\n",
      "[467]\ttraining's binary_logloss: 0.458657\n",
      "[468]\ttraining's binary_logloss: 0.458399\n",
      "[469]\ttraining's binary_logloss: 0.458147\n",
      "[470]\ttraining's binary_logloss: 0.457884\n",
      "[471]\ttraining's binary_logloss: 0.45766\n",
      "[472]\ttraining's binary_logloss: 0.457462\n",
      "[473]\ttraining's binary_logloss: 0.457244\n",
      "[474]\ttraining's binary_logloss: 0.457027\n",
      "[475]\ttraining's binary_logloss: 0.456825\n",
      "[476]\ttraining's binary_logloss: 0.456594\n",
      "[477]\ttraining's binary_logloss: 0.456372\n",
      "[478]\ttraining's binary_logloss: 0.456138\n",
      "[479]\ttraining's binary_logloss: 0.455916\n",
      "[480]\ttraining's binary_logloss: 0.455698\n",
      "[481]\ttraining's binary_logloss: 0.455476\n",
      "[482]\ttraining's binary_logloss: 0.455277\n",
      "[483]\ttraining's binary_logloss: 0.455068\n",
      "[484]\ttraining's binary_logloss: 0.454855\n",
      "[485]\ttraining's binary_logloss: 0.454658\n",
      "[486]\ttraining's binary_logloss: 0.454455\n",
      "[487]\ttraining's binary_logloss: 0.454256\n",
      "[488]\ttraining's binary_logloss: 0.45406\n",
      "[489]\ttraining's binary_logloss: 0.453837\n",
      "[490]\ttraining's binary_logloss: 0.453612\n",
      "[491]\ttraining's binary_logloss: 0.453322\n",
      "[492]\ttraining's binary_logloss: 0.453027\n",
      "[493]\ttraining's binary_logloss: 0.452727\n",
      "[494]\ttraining's binary_logloss: 0.452456\n",
      "[495]\ttraining's binary_logloss: 0.452177\n",
      "[496]\ttraining's binary_logloss: 0.451873\n",
      "[497]\ttraining's binary_logloss: 0.451616\n",
      "[498]\ttraining's binary_logloss: 0.45134\n",
      "[499]\ttraining's binary_logloss: 0.451097\n",
      "[500]\ttraining's binary_logloss: 0.450855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613164\n",
      "[2]\ttraining's binary_logloss: 0.611522\n",
      "[3]\ttraining's binary_logloss: 0.609919\n",
      "[4]\ttraining's binary_logloss: 0.608317\n",
      "[5]\ttraining's binary_logloss: 0.60675\n",
      "[6]\ttraining's binary_logloss: 0.605298\n",
      "[7]\ttraining's binary_logloss: 0.603826\n",
      "[8]\ttraining's binary_logloss: 0.602472\n",
      "[9]\ttraining's binary_logloss: 0.601092\n",
      "[10]\ttraining's binary_logloss: 0.59976\n",
      "[11]\ttraining's binary_logloss: 0.598489\n",
      "[12]\ttraining's binary_logloss: 0.597244\n",
      "[13]\ttraining's binary_logloss: 0.596144\n",
      "[14]\ttraining's binary_logloss: 0.594964\n",
      "[15]\ttraining's binary_logloss: 0.593835\n",
      "[16]\ttraining's binary_logloss: 0.59282\n",
      "[17]\ttraining's binary_logloss: 0.591728\n",
      "[18]\ttraining's binary_logloss: 0.590651\n",
      "[19]\ttraining's binary_logloss: 0.589603\n",
      "[20]\ttraining's binary_logloss: 0.588679\n",
      "[21]\ttraining's binary_logloss: 0.587724\n",
      "[22]\ttraining's binary_logloss: 0.586767\n",
      "[23]\ttraining's binary_logloss: 0.58587\n",
      "[24]\ttraining's binary_logloss: 0.584917\n",
      "[25]\ttraining's binary_logloss: 0.583973\n",
      "[26]\ttraining's binary_logloss: 0.583075\n",
      "[27]\ttraining's binary_logloss: 0.582187\n",
      "[28]\ttraining's binary_logloss: 0.581302\n",
      "[29]\ttraining's binary_logloss: 0.58043\n",
      "[30]\ttraining's binary_logloss: 0.579587\n",
      "[31]\ttraining's binary_logloss: 0.578823\n",
      "[32]\ttraining's binary_logloss: 0.578097\n",
      "[33]\ttraining's binary_logloss: 0.577339\n",
      "[34]\ttraining's binary_logloss: 0.576604\n",
      "[35]\ttraining's binary_logloss: 0.575965\n",
      "[36]\ttraining's binary_logloss: 0.575188\n",
      "[37]\ttraining's binary_logloss: 0.57444\n",
      "[38]\ttraining's binary_logloss: 0.573734\n",
      "[39]\ttraining's binary_logloss: 0.573065\n",
      "[40]\ttraining's binary_logloss: 0.572424\n",
      "[41]\ttraining's binary_logloss: 0.571808\n",
      "[42]\ttraining's binary_logloss: 0.571169\n",
      "[43]\ttraining's binary_logloss: 0.570559\n",
      "[44]\ttraining's binary_logloss: 0.569978\n",
      "[45]\ttraining's binary_logloss: 0.569372\n",
      "[46]\ttraining's binary_logloss: 0.568826\n",
      "[47]\ttraining's binary_logloss: 0.568308\n",
      "[48]\ttraining's binary_logloss: 0.567712\n",
      "[49]\ttraining's binary_logloss: 0.567193\n",
      "[50]\ttraining's binary_logloss: 0.566664\n",
      "[51]\ttraining's binary_logloss: 0.566078\n",
      "[52]\ttraining's binary_logloss: 0.565526\n",
      "[53]\ttraining's binary_logloss: 0.565065\n",
      "[54]\ttraining's binary_logloss: 0.564546\n",
      "[55]\ttraining's binary_logloss: 0.564055\n",
      "[56]\ttraining's binary_logloss: 0.563645\n",
      "[57]\ttraining's binary_logloss: 0.563212\n",
      "[58]\ttraining's binary_logloss: 0.562756\n",
      "[59]\ttraining's binary_logloss: 0.562338\n",
      "[60]\ttraining's binary_logloss: 0.561909\n",
      "[61]\ttraining's binary_logloss: 0.561486\n",
      "[62]\ttraining's binary_logloss: 0.560962\n",
      "[63]\ttraining's binary_logloss: 0.560465\n",
      "[64]\ttraining's binary_logloss: 0.560027\n",
      "[65]\ttraining's binary_logloss: 0.559558\n",
      "[66]\ttraining's binary_logloss: 0.55907\n",
      "[67]\ttraining's binary_logloss: 0.558625\n",
      "[68]\ttraining's binary_logloss: 0.558158\n",
      "[69]\ttraining's binary_logloss: 0.557726\n",
      "[70]\ttraining's binary_logloss: 0.55733\n",
      "[71]\ttraining's binary_logloss: 0.556879\n",
      "[72]\ttraining's binary_logloss: 0.556471\n",
      "[73]\ttraining's binary_logloss: 0.55608\n",
      "[74]\ttraining's binary_logloss: 0.555679\n",
      "[75]\ttraining's binary_logloss: 0.555306\n",
      "[76]\ttraining's binary_logloss: 0.55493\n",
      "[77]\ttraining's binary_logloss: 0.554581\n",
      "[78]\ttraining's binary_logloss: 0.554253\n",
      "[79]\ttraining's binary_logloss: 0.553977\n",
      "[80]\ttraining's binary_logloss: 0.55366\n",
      "[81]\ttraining's binary_logloss: 0.553358\n",
      "[82]\ttraining's binary_logloss: 0.553033\n",
      "[83]\ttraining's binary_logloss: 0.552726\n",
      "[84]\ttraining's binary_logloss: 0.552406\n",
      "[85]\ttraining's binary_logloss: 0.552083\n",
      "[86]\ttraining's binary_logloss: 0.551761\n",
      "[87]\ttraining's binary_logloss: 0.551447\n",
      "[88]\ttraining's binary_logloss: 0.551103\n",
      "[89]\ttraining's binary_logloss: 0.550763\n",
      "[90]\ttraining's binary_logloss: 0.550456\n",
      "[91]\ttraining's binary_logloss: 0.550112\n",
      "[92]\ttraining's binary_logloss: 0.54979\n",
      "[93]\ttraining's binary_logloss: 0.549447\n",
      "[94]\ttraining's binary_logloss: 0.549167\n",
      "[95]\ttraining's binary_logloss: 0.548861\n",
      "[96]\ttraining's binary_logloss: 0.548592\n",
      "[97]\ttraining's binary_logloss: 0.548325\n",
      "[98]\ttraining's binary_logloss: 0.548095\n",
      "[99]\ttraining's binary_logloss: 0.547859\n",
      "[100]\ttraining's binary_logloss: 0.547608\n",
      "[101]\ttraining's binary_logloss: 0.547329\n",
      "[102]\ttraining's binary_logloss: 0.547041\n",
      "[103]\ttraining's binary_logloss: 0.546785\n",
      "[104]\ttraining's binary_logloss: 0.546535\n",
      "[105]\ttraining's binary_logloss: 0.546271\n",
      "[106]\ttraining's binary_logloss: 0.546\n",
      "[107]\ttraining's binary_logloss: 0.545707\n",
      "[108]\ttraining's binary_logloss: 0.545418\n",
      "[109]\ttraining's binary_logloss: 0.545141\n",
      "[110]\ttraining's binary_logloss: 0.544887\n",
      "[111]\ttraining's binary_logloss: 0.544616\n",
      "[112]\ttraining's binary_logloss: 0.544373\n",
      "[113]\ttraining's binary_logloss: 0.54411\n",
      "[114]\ttraining's binary_logloss: 0.543916\n",
      "[115]\ttraining's binary_logloss: 0.54366\n",
      "[116]\ttraining's binary_logloss: 0.543412\n",
      "[117]\ttraining's binary_logloss: 0.543143\n",
      "[118]\ttraining's binary_logloss: 0.542887\n",
      "[119]\ttraining's binary_logloss: 0.542662\n",
      "[120]\ttraining's binary_logloss: 0.542444\n",
      "[121]\ttraining's binary_logloss: 0.542216\n",
      "[122]\ttraining's binary_logloss: 0.541945\n",
      "[123]\ttraining's binary_logloss: 0.541706\n",
      "[124]\ttraining's binary_logloss: 0.541481\n",
      "[125]\ttraining's binary_logloss: 0.541219\n",
      "[126]\ttraining's binary_logloss: 0.540967\n",
      "[127]\ttraining's binary_logloss: 0.540708\n",
      "[128]\ttraining's binary_logloss: 0.540426\n",
      "[129]\ttraining's binary_logloss: 0.540164\n",
      "[130]\ttraining's binary_logloss: 0.539934\n",
      "[131]\ttraining's binary_logloss: 0.539708\n",
      "[132]\ttraining's binary_logloss: 0.539484\n",
      "[133]\ttraining's binary_logloss: 0.539278\n",
      "[134]\ttraining's binary_logloss: 0.539059\n",
      "[135]\ttraining's binary_logloss: 0.538871\n",
      "[136]\ttraining's binary_logloss: 0.538637\n",
      "[137]\ttraining's binary_logloss: 0.538371\n",
      "[138]\ttraining's binary_logloss: 0.538138\n",
      "[139]\ttraining's binary_logloss: 0.537892\n",
      "[140]\ttraining's binary_logloss: 0.53766\n",
      "[141]\ttraining's binary_logloss: 0.537404\n",
      "[142]\ttraining's binary_logloss: 0.537167\n",
      "[143]\ttraining's binary_logloss: 0.536909\n",
      "[144]\ttraining's binary_logloss: 0.536675\n",
      "[145]\ttraining's binary_logloss: 0.536439\n",
      "[146]\ttraining's binary_logloss: 0.536207\n",
      "[147]\ttraining's binary_logloss: 0.536007\n",
      "[148]\ttraining's binary_logloss: 0.53577\n",
      "[149]\ttraining's binary_logloss: 0.535574\n",
      "[150]\ttraining's binary_logloss: 0.535326\n",
      "[151]\ttraining's binary_logloss: 0.535102\n",
      "[152]\ttraining's binary_logloss: 0.534883\n",
      "[153]\ttraining's binary_logloss: 0.534655\n",
      "[154]\ttraining's binary_logloss: 0.534417\n",
      "[155]\ttraining's binary_logloss: 0.534215\n",
      "[156]\ttraining's binary_logloss: 0.533983\n",
      "[157]\ttraining's binary_logloss: 0.533737\n",
      "[158]\ttraining's binary_logloss: 0.5335\n",
      "[159]\ttraining's binary_logloss: 0.53325\n",
      "[160]\ttraining's binary_logloss: 0.533006\n",
      "[161]\ttraining's binary_logloss: 0.532799\n",
      "[162]\ttraining's binary_logloss: 0.532563\n",
      "[163]\ttraining's binary_logloss: 0.532335\n",
      "[164]\ttraining's binary_logloss: 0.53212\n",
      "[165]\ttraining's binary_logloss: 0.531879\n",
      "[166]\ttraining's binary_logloss: 0.531628\n",
      "[167]\ttraining's binary_logloss: 0.531389\n",
      "[168]\ttraining's binary_logloss: 0.53115\n",
      "[169]\ttraining's binary_logloss: 0.530945\n",
      "[170]\ttraining's binary_logloss: 0.530721\n",
      "[171]\ttraining's binary_logloss: 0.530488\n",
      "[172]\ttraining's binary_logloss: 0.530266\n",
      "[173]\ttraining's binary_logloss: 0.530042\n",
      "[174]\ttraining's binary_logloss: 0.529833\n",
      "[175]\ttraining's binary_logloss: 0.529622\n",
      "[176]\ttraining's binary_logloss: 0.529353\n",
      "[177]\ttraining's binary_logloss: 0.529088\n",
      "[178]\ttraining's binary_logloss: 0.528863\n",
      "[179]\ttraining's binary_logloss: 0.528608\n",
      "[180]\ttraining's binary_logloss: 0.528371\n",
      "[181]\ttraining's binary_logloss: 0.528155\n",
      "[182]\ttraining's binary_logloss: 0.527934\n",
      "[183]\ttraining's binary_logloss: 0.527729\n",
      "[184]\ttraining's binary_logloss: 0.527506\n",
      "[185]\ttraining's binary_logloss: 0.527266\n",
      "[186]\ttraining's binary_logloss: 0.527053\n",
      "[187]\ttraining's binary_logloss: 0.52686\n",
      "[188]\ttraining's binary_logloss: 0.526679\n",
      "[189]\ttraining's binary_logloss: 0.526495\n",
      "[190]\ttraining's binary_logloss: 0.526309\n",
      "[191]\ttraining's binary_logloss: 0.526047\n",
      "[192]\ttraining's binary_logloss: 0.525828\n",
      "[193]\ttraining's binary_logloss: 0.52559\n",
      "[194]\ttraining's binary_logloss: 0.52533\n",
      "[195]\ttraining's binary_logloss: 0.525092\n",
      "[196]\ttraining's binary_logloss: 0.524819\n",
      "[197]\ttraining's binary_logloss: 0.524555\n",
      "[198]\ttraining's binary_logloss: 0.524303\n",
      "[199]\ttraining's binary_logloss: 0.524053\n",
      "[200]\ttraining's binary_logloss: 0.523807\n",
      "[201]\ttraining's binary_logloss: 0.523557\n",
      "[202]\ttraining's binary_logloss: 0.523321\n",
      "[203]\ttraining's binary_logloss: 0.523081\n",
      "[204]\ttraining's binary_logloss: 0.522845\n",
      "[205]\ttraining's binary_logloss: 0.522623\n",
      "[206]\ttraining's binary_logloss: 0.522387\n",
      "[207]\ttraining's binary_logloss: 0.522165\n",
      "[208]\ttraining's binary_logloss: 0.521974\n",
      "[209]\ttraining's binary_logloss: 0.521772\n",
      "[210]\ttraining's binary_logloss: 0.521594\n",
      "[211]\ttraining's binary_logloss: 0.521319\n",
      "[212]\ttraining's binary_logloss: 0.521052\n",
      "[213]\ttraining's binary_logloss: 0.520798\n",
      "[214]\ttraining's binary_logloss: 0.520552\n",
      "[215]\ttraining's binary_logloss: 0.520315\n",
      "[216]\ttraining's binary_logloss: 0.520052\n",
      "[217]\ttraining's binary_logloss: 0.519835\n",
      "[218]\ttraining's binary_logloss: 0.519561\n",
      "[219]\ttraining's binary_logloss: 0.519317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[220]\ttraining's binary_logloss: 0.519044\n",
      "[221]\ttraining's binary_logloss: 0.518804\n",
      "[222]\ttraining's binary_logloss: 0.518587\n",
      "[223]\ttraining's binary_logloss: 0.518286\n",
      "[224]\ttraining's binary_logloss: 0.51805\n",
      "[225]\ttraining's binary_logloss: 0.517829\n",
      "[226]\ttraining's binary_logloss: 0.517559\n",
      "[227]\ttraining's binary_logloss: 0.517298\n",
      "[228]\ttraining's binary_logloss: 0.517031\n",
      "[229]\ttraining's binary_logloss: 0.5168\n",
      "[230]\ttraining's binary_logloss: 0.516549\n",
      "[231]\ttraining's binary_logloss: 0.516281\n",
      "[232]\ttraining's binary_logloss: 0.516023\n",
      "[233]\ttraining's binary_logloss: 0.515762\n",
      "[234]\ttraining's binary_logloss: 0.515509\n",
      "[235]\ttraining's binary_logloss: 0.515257\n",
      "[236]\ttraining's binary_logloss: 0.515024\n",
      "[237]\ttraining's binary_logloss: 0.514802\n",
      "[238]\ttraining's binary_logloss: 0.514581\n",
      "[239]\ttraining's binary_logloss: 0.514352\n",
      "[240]\ttraining's binary_logloss: 0.514135\n",
      "[241]\ttraining's binary_logloss: 0.513887\n",
      "[242]\ttraining's binary_logloss: 0.51365\n",
      "[243]\ttraining's binary_logloss: 0.513437\n",
      "[244]\ttraining's binary_logloss: 0.513224\n",
      "[245]\ttraining's binary_logloss: 0.512938\n",
      "[246]\ttraining's binary_logloss: 0.512672\n",
      "[247]\ttraining's binary_logloss: 0.512415\n",
      "[248]\ttraining's binary_logloss: 0.512152\n",
      "[249]\ttraining's binary_logloss: 0.511887\n",
      "[250]\ttraining's binary_logloss: 0.511631\n",
      "[251]\ttraining's binary_logloss: 0.511388\n",
      "[252]\ttraining's binary_logloss: 0.511142\n",
      "[253]\ttraining's binary_logloss: 0.510914\n",
      "[254]\ttraining's binary_logloss: 0.510652\n",
      "[255]\ttraining's binary_logloss: 0.510394\n",
      "[256]\ttraining's binary_logloss: 0.510055\n",
      "[257]\ttraining's binary_logloss: 0.509813\n",
      "[258]\ttraining's binary_logloss: 0.509538\n",
      "[259]\ttraining's binary_logloss: 0.509237\n",
      "[260]\ttraining's binary_logloss: 0.508976\n",
      "[261]\ttraining's binary_logloss: 0.508692\n",
      "[262]\ttraining's binary_logloss: 0.508424\n",
      "[263]\ttraining's binary_logloss: 0.508145\n",
      "[264]\ttraining's binary_logloss: 0.507891\n",
      "[265]\ttraining's binary_logloss: 0.507621\n",
      "[266]\ttraining's binary_logloss: 0.50741\n",
      "[267]\ttraining's binary_logloss: 0.50719\n",
      "[268]\ttraining's binary_logloss: 0.507001\n",
      "[269]\ttraining's binary_logloss: 0.506799\n",
      "[270]\ttraining's binary_logloss: 0.506609\n",
      "[271]\ttraining's binary_logloss: 0.50635\n",
      "[272]\ttraining's binary_logloss: 0.506089\n",
      "[273]\ttraining's binary_logloss: 0.505853\n",
      "[274]\ttraining's binary_logloss: 0.50561\n",
      "[275]\ttraining's binary_logloss: 0.505377\n",
      "[276]\ttraining's binary_logloss: 0.505105\n",
      "[277]\ttraining's binary_logloss: 0.504831\n",
      "[278]\ttraining's binary_logloss: 0.504555\n",
      "[279]\ttraining's binary_logloss: 0.50431\n",
      "[280]\ttraining's binary_logloss: 0.504034\n",
      "[281]\ttraining's binary_logloss: 0.503786\n",
      "[282]\ttraining's binary_logloss: 0.503555\n",
      "[283]\ttraining's binary_logloss: 0.50333\n",
      "[284]\ttraining's binary_logloss: 0.503063\n",
      "[285]\ttraining's binary_logloss: 0.502806\n",
      "[286]\ttraining's binary_logloss: 0.502479\n",
      "[287]\ttraining's binary_logloss: 0.502172\n",
      "[288]\ttraining's binary_logloss: 0.501854\n",
      "[289]\ttraining's binary_logloss: 0.501572\n",
      "[290]\ttraining's binary_logloss: 0.50127\n",
      "[291]\ttraining's binary_logloss: 0.501019\n",
      "[292]\ttraining's binary_logloss: 0.500762\n",
      "[293]\ttraining's binary_logloss: 0.500528\n",
      "[294]\ttraining's binary_logloss: 0.500288\n",
      "[295]\ttraining's binary_logloss: 0.50007\n",
      "[296]\ttraining's binary_logloss: 0.499828\n",
      "[297]\ttraining's binary_logloss: 0.499512\n",
      "[298]\ttraining's binary_logloss: 0.499201\n",
      "[299]\ttraining's binary_logloss: 0.498895\n",
      "[300]\ttraining's binary_logloss: 0.498592\n",
      "[301]\ttraining's binary_logloss: 0.498349\n",
      "[302]\ttraining's binary_logloss: 0.498069\n",
      "[303]\ttraining's binary_logloss: 0.49782\n",
      "[304]\ttraining's binary_logloss: 0.497542\n",
      "[305]\ttraining's binary_logloss: 0.497302\n",
      "[306]\ttraining's binary_logloss: 0.497029\n",
      "[307]\ttraining's binary_logloss: 0.496748\n",
      "[308]\ttraining's binary_logloss: 0.496472\n",
      "[309]\ttraining's binary_logloss: 0.496186\n",
      "[310]\ttraining's binary_logloss: 0.495954\n",
      "[311]\ttraining's binary_logloss: 0.495697\n",
      "[312]\ttraining's binary_logloss: 0.495426\n",
      "[313]\ttraining's binary_logloss: 0.495188\n",
      "[314]\ttraining's binary_logloss: 0.494908\n",
      "[315]\ttraining's binary_logloss: 0.494654\n",
      "[316]\ttraining's binary_logloss: 0.494422\n",
      "[317]\ttraining's binary_logloss: 0.494186\n",
      "[318]\ttraining's binary_logloss: 0.493937\n",
      "[319]\ttraining's binary_logloss: 0.49371\n",
      "[320]\ttraining's binary_logloss: 0.493447\n",
      "[321]\ttraining's binary_logloss: 0.493214\n",
      "[322]\ttraining's binary_logloss: 0.492992\n",
      "[323]\ttraining's binary_logloss: 0.492781\n",
      "[324]\ttraining's binary_logloss: 0.492559\n",
      "[325]\ttraining's binary_logloss: 0.492361\n",
      "[326]\ttraining's binary_logloss: 0.492156\n",
      "[327]\ttraining's binary_logloss: 0.491919\n",
      "[328]\ttraining's binary_logloss: 0.491717\n",
      "[329]\ttraining's binary_logloss: 0.491532\n",
      "[330]\ttraining's binary_logloss: 0.491342\n",
      "[331]\ttraining's binary_logloss: 0.491075\n",
      "[332]\ttraining's binary_logloss: 0.490813\n",
      "[333]\ttraining's binary_logloss: 0.490505\n",
      "[334]\ttraining's binary_logloss: 0.490246\n",
      "[335]\ttraining's binary_logloss: 0.489981\n",
      "[336]\ttraining's binary_logloss: 0.489737\n",
      "[337]\ttraining's binary_logloss: 0.489517\n",
      "[338]\ttraining's binary_logloss: 0.489295\n",
      "[339]\ttraining's binary_logloss: 0.489032\n",
      "[340]\ttraining's binary_logloss: 0.488733\n",
      "[341]\ttraining's binary_logloss: 0.488455\n",
      "[342]\ttraining's binary_logloss: 0.488172\n",
      "[343]\ttraining's binary_logloss: 0.487878\n",
      "[344]\ttraining's binary_logloss: 0.48763\n",
      "[345]\ttraining's binary_logloss: 0.48734\n",
      "[346]\ttraining's binary_logloss: 0.487137\n",
      "[347]\ttraining's binary_logloss: 0.486911\n",
      "[348]\ttraining's binary_logloss: 0.486701\n",
      "[349]\ttraining's binary_logloss: 0.486476\n",
      "[350]\ttraining's binary_logloss: 0.486268\n",
      "[351]\ttraining's binary_logloss: 0.485975\n",
      "[352]\ttraining's binary_logloss: 0.48569\n",
      "[353]\ttraining's binary_logloss: 0.485424\n",
      "[354]\ttraining's binary_logloss: 0.485162\n",
      "[355]\ttraining's binary_logloss: 0.48489\n",
      "[356]\ttraining's binary_logloss: 0.484634\n",
      "[357]\ttraining's binary_logloss: 0.484383\n",
      "[358]\ttraining's binary_logloss: 0.484151\n",
      "[359]\ttraining's binary_logloss: 0.483932\n",
      "[360]\ttraining's binary_logloss: 0.483698\n",
      "[361]\ttraining's binary_logloss: 0.48346\n",
      "[362]\ttraining's binary_logloss: 0.48324\n",
      "[363]\ttraining's binary_logloss: 0.482989\n",
      "[364]\ttraining's binary_logloss: 0.482799\n",
      "[365]\ttraining's binary_logloss: 0.48256\n",
      "[366]\ttraining's binary_logloss: 0.482302\n",
      "[367]\ttraining's binary_logloss: 0.48207\n",
      "[368]\ttraining's binary_logloss: 0.481861\n",
      "[369]\ttraining's binary_logloss: 0.481644\n",
      "[370]\ttraining's binary_logloss: 0.48143\n",
      "[371]\ttraining's binary_logloss: 0.481182\n",
      "[372]\ttraining's binary_logloss: 0.48093\n",
      "[373]\ttraining's binary_logloss: 0.480659\n",
      "[374]\ttraining's binary_logloss: 0.480421\n",
      "[375]\ttraining's binary_logloss: 0.480134\n",
      "[376]\ttraining's binary_logloss: 0.479835\n",
      "[377]\ttraining's binary_logloss: 0.479549\n",
      "[378]\ttraining's binary_logloss: 0.479345\n",
      "[379]\ttraining's binary_logloss: 0.479143\n",
      "[380]\ttraining's binary_logloss: 0.478854\n",
      "[381]\ttraining's binary_logloss: 0.478612\n",
      "[382]\ttraining's binary_logloss: 0.478368\n",
      "[383]\ttraining's binary_logloss: 0.478117\n",
      "[384]\ttraining's binary_logloss: 0.477861\n",
      "[385]\ttraining's binary_logloss: 0.477653\n",
      "[386]\ttraining's binary_logloss: 0.477417\n",
      "[387]\ttraining's binary_logloss: 0.4772\n",
      "[388]\ttraining's binary_logloss: 0.476972\n",
      "[389]\ttraining's binary_logloss: 0.476734\n",
      "[390]\ttraining's binary_logloss: 0.476493\n",
      "[391]\ttraining's binary_logloss: 0.476244\n",
      "[392]\ttraining's binary_logloss: 0.475984\n",
      "[393]\ttraining's binary_logloss: 0.475711\n",
      "[394]\ttraining's binary_logloss: 0.475396\n",
      "[395]\ttraining's binary_logloss: 0.475161\n",
      "[396]\ttraining's binary_logloss: 0.474878\n",
      "[397]\ttraining's binary_logloss: 0.474596\n",
      "[398]\ttraining's binary_logloss: 0.474316\n",
      "[399]\ttraining's binary_logloss: 0.474065\n",
      "[400]\ttraining's binary_logloss: 0.473816\n",
      "[401]\ttraining's binary_logloss: 0.473586\n",
      "[402]\ttraining's binary_logloss: 0.473363\n",
      "[403]\ttraining's binary_logloss: 0.473104\n",
      "[404]\ttraining's binary_logloss: 0.472862\n",
      "[405]\ttraining's binary_logloss: 0.472636\n",
      "[406]\ttraining's binary_logloss: 0.472362\n",
      "[407]\ttraining's binary_logloss: 0.472097\n",
      "[408]\ttraining's binary_logloss: 0.471863\n",
      "[409]\ttraining's binary_logloss: 0.471633\n",
      "[410]\ttraining's binary_logloss: 0.471365\n",
      "[411]\ttraining's binary_logloss: 0.471126\n",
      "[412]\ttraining's binary_logloss: 0.47092\n",
      "[413]\ttraining's binary_logloss: 0.470653\n",
      "[414]\ttraining's binary_logloss: 0.470393\n",
      "[415]\ttraining's binary_logloss: 0.470129\n",
      "[416]\ttraining's binary_logloss: 0.469855\n",
      "[417]\ttraining's binary_logloss: 0.469632\n",
      "[418]\ttraining's binary_logloss: 0.469396\n",
      "[419]\ttraining's binary_logloss: 0.469133\n",
      "[420]\ttraining's binary_logloss: 0.468879\n",
      "[421]\ttraining's binary_logloss: 0.468689\n",
      "[422]\ttraining's binary_logloss: 0.468503\n",
      "[423]\ttraining's binary_logloss: 0.468321\n",
      "[424]\ttraining's binary_logloss: 0.468096\n",
      "[425]\ttraining's binary_logloss: 0.467916\n",
      "[426]\ttraining's binary_logloss: 0.467662\n",
      "[427]\ttraining's binary_logloss: 0.467403\n",
      "[428]\ttraining's binary_logloss: 0.467154\n",
      "[429]\ttraining's binary_logloss: 0.46693\n",
      "[430]\ttraining's binary_logloss: 0.46665\n",
      "[431]\ttraining's binary_logloss: 0.466433\n",
      "[432]\ttraining's binary_logloss: 0.466245\n",
      "[433]\ttraining's binary_logloss: 0.466029\n",
      "[434]\ttraining's binary_logloss: 0.4658\n",
      "[435]\ttraining's binary_logloss: 0.465612\n",
      "[436]\ttraining's binary_logloss: 0.465359\n",
      "[437]\ttraining's binary_logloss: 0.465044\n",
      "[438]\ttraining's binary_logloss: 0.464822\n",
      "[439]\ttraining's binary_logloss: 0.46452\n",
      "[440]\ttraining's binary_logloss: 0.464303\n",
      "[441]\ttraining's binary_logloss: 0.464015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[442]\ttraining's binary_logloss: 0.463778\n",
      "[443]\ttraining's binary_logloss: 0.463507\n",
      "[444]\ttraining's binary_logloss: 0.463267\n",
      "[445]\ttraining's binary_logloss: 0.462992\n",
      "[446]\ttraining's binary_logloss: 0.46278\n",
      "[447]\ttraining's binary_logloss: 0.462557\n",
      "[448]\ttraining's binary_logloss: 0.462341\n",
      "[449]\ttraining's binary_logloss: 0.462141\n",
      "[450]\ttraining's binary_logloss: 0.461953\n",
      "[451]\ttraining's binary_logloss: 0.461752\n",
      "[452]\ttraining's binary_logloss: 0.461538\n",
      "[453]\ttraining's binary_logloss: 0.461339\n",
      "[454]\ttraining's binary_logloss: 0.461149\n",
      "[455]\ttraining's binary_logloss: 0.460953\n",
      "[456]\ttraining's binary_logloss: 0.460708\n",
      "[457]\ttraining's binary_logloss: 0.460472\n",
      "[458]\ttraining's binary_logloss: 0.460256\n",
      "[459]\ttraining's binary_logloss: 0.460053\n",
      "[460]\ttraining's binary_logloss: 0.459842\n",
      "[461]\ttraining's binary_logloss: 0.459569\n",
      "[462]\ttraining's binary_logloss: 0.459289\n",
      "[463]\ttraining's binary_logloss: 0.459007\n",
      "[464]\ttraining's binary_logloss: 0.458747\n",
      "[465]\ttraining's binary_logloss: 0.458472\n",
      "[466]\ttraining's binary_logloss: 0.458163\n",
      "[467]\ttraining's binary_logloss: 0.457856\n",
      "[468]\ttraining's binary_logloss: 0.457577\n",
      "[469]\ttraining's binary_logloss: 0.457276\n",
      "[470]\ttraining's binary_logloss: 0.457013\n",
      "[471]\ttraining's binary_logloss: 0.456768\n",
      "[472]\ttraining's binary_logloss: 0.456533\n",
      "[473]\ttraining's binary_logloss: 0.456288\n",
      "[474]\ttraining's binary_logloss: 0.456014\n",
      "[475]\ttraining's binary_logloss: 0.455786\n",
      "[476]\ttraining's binary_logloss: 0.45556\n",
      "[477]\ttraining's binary_logloss: 0.455346\n",
      "[478]\ttraining's binary_logloss: 0.455154\n",
      "[479]\ttraining's binary_logloss: 0.454945\n",
      "[480]\ttraining's binary_logloss: 0.454739\n",
      "[481]\ttraining's binary_logloss: 0.454511\n",
      "[482]\ttraining's binary_logloss: 0.454287\n",
      "[483]\ttraining's binary_logloss: 0.454075\n",
      "[484]\ttraining's binary_logloss: 0.453885\n",
      "[485]\ttraining's binary_logloss: 0.453648\n",
      "[486]\ttraining's binary_logloss: 0.453437\n",
      "[487]\ttraining's binary_logloss: 0.453222\n",
      "[488]\ttraining's binary_logloss: 0.453018\n",
      "[489]\ttraining's binary_logloss: 0.452816\n",
      "[490]\ttraining's binary_logloss: 0.452622\n",
      "[491]\ttraining's binary_logloss: 0.452429\n",
      "[492]\ttraining's binary_logloss: 0.452225\n",
      "[493]\ttraining's binary_logloss: 0.452028\n",
      "[494]\ttraining's binary_logloss: 0.451843\n",
      "[495]\ttraining's binary_logloss: 0.451677\n",
      "[496]\ttraining's binary_logloss: 0.451399\n",
      "[497]\ttraining's binary_logloss: 0.451145\n",
      "[498]\ttraining's binary_logloss: 0.450884\n",
      "[499]\ttraining's binary_logloss: 0.45061\n",
      "[500]\ttraining's binary_logloss: 0.450356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614504\n",
      "[2]\ttraining's binary_logloss: 0.613487\n",
      "[3]\ttraining's binary_logloss: 0.612503\n",
      "[4]\ttraining's binary_logloss: 0.611564\n",
      "[5]\ttraining's binary_logloss: 0.61066\n",
      "[6]\ttraining's binary_logloss: 0.609886\n",
      "[7]\ttraining's binary_logloss: 0.608979\n",
      "[8]\ttraining's binary_logloss: 0.608133\n",
      "[9]\ttraining's binary_logloss: 0.607314\n",
      "[10]\ttraining's binary_logloss: 0.606675\n",
      "[11]\ttraining's binary_logloss: 0.606064\n",
      "[12]\ttraining's binary_logloss: 0.605349\n",
      "[13]\ttraining's binary_logloss: 0.604834\n",
      "[14]\ttraining's binary_logloss: 0.604148\n",
      "[15]\ttraining's binary_logloss: 0.603477\n",
      "[16]\ttraining's binary_logloss: 0.602915\n",
      "[17]\ttraining's binary_logloss: 0.602292\n",
      "[18]\ttraining's binary_logloss: 0.601694\n",
      "[19]\ttraining's binary_logloss: 0.601188\n",
      "[20]\ttraining's binary_logloss: 0.600635\n",
      "[21]\ttraining's binary_logloss: 0.600059\n",
      "[22]\ttraining's binary_logloss: 0.599615\n",
      "[23]\ttraining's binary_logloss: 0.599082\n",
      "[24]\ttraining's binary_logloss: 0.598573\n",
      "[25]\ttraining's binary_logloss: 0.598087\n",
      "[26]\ttraining's binary_logloss: 0.597694\n",
      "[27]\ttraining's binary_logloss: 0.597314\n",
      "[28]\ttraining's binary_logloss: 0.59695\n",
      "[29]\ttraining's binary_logloss: 0.596624\n",
      "[30]\ttraining's binary_logloss: 0.596288\n",
      "[31]\ttraining's binary_logloss: 0.595975\n",
      "[32]\ttraining's binary_logloss: 0.595615\n",
      "[33]\ttraining's binary_logloss: 0.595302\n",
      "[34]\ttraining's binary_logloss: 0.594962\n",
      "[35]\ttraining's binary_logloss: 0.594738\n",
      "[36]\ttraining's binary_logloss: 0.594477\n",
      "[37]\ttraining's binary_logloss: 0.594269\n",
      "[38]\ttraining's binary_logloss: 0.59401\n",
      "[39]\ttraining's binary_logloss: 0.593778\n",
      "[40]\ttraining's binary_logloss: 0.593546\n",
      "[41]\ttraining's binary_logloss: 0.593295\n",
      "[42]\ttraining's binary_logloss: 0.593061\n",
      "[43]\ttraining's binary_logloss: 0.592831\n",
      "[44]\ttraining's binary_logloss: 0.592668\n",
      "[45]\ttraining's binary_logloss: 0.592521\n",
      "[46]\ttraining's binary_logloss: 0.592272\n",
      "[47]\ttraining's binary_logloss: 0.592036\n",
      "[48]\ttraining's binary_logloss: 0.591814\n",
      "[49]\ttraining's binary_logloss: 0.591602\n",
      "[50]\ttraining's binary_logloss: 0.591407\n",
      "[51]\ttraining's binary_logloss: 0.591235\n",
      "[52]\ttraining's binary_logloss: 0.591132\n",
      "[53]\ttraining's binary_logloss: 0.590978\n",
      "[54]\ttraining's binary_logloss: 0.590856\n",
      "[55]\ttraining's binary_logloss: 0.590744\n",
      "[56]\ttraining's binary_logloss: 0.590668\n",
      "[57]\ttraining's binary_logloss: 0.590609\n",
      "[58]\ttraining's binary_logloss: 0.590553\n",
      "[59]\ttraining's binary_logloss: 0.5905\n",
      "[60]\ttraining's binary_logloss: 0.590447\n",
      "[61]\ttraining's binary_logloss: 0.590452\n",
      "[62]\ttraining's binary_logloss: 0.590365\n",
      "[63]\ttraining's binary_logloss: 0.590281\n",
      "[64]\ttraining's binary_logloss: 0.590218\n",
      "[65]\ttraining's binary_logloss: 0.590167\n",
      "[66]\ttraining's binary_logloss: 0.590101\n",
      "[67]\ttraining's binary_logloss: 0.59005\n",
      "[68]\ttraining's binary_logloss: 0.589999\n",
      "[69]\ttraining's binary_logloss: 0.589985\n",
      "[70]\ttraining's binary_logloss: 0.589947\n",
      "[71]\ttraining's binary_logloss: 0.589907\n",
      "[72]\ttraining's binary_logloss: 0.589862\n",
      "[73]\ttraining's binary_logloss: 0.589823\n",
      "[74]\ttraining's binary_logloss: 0.589803\n",
      "[75]\ttraining's binary_logloss: 0.589764\n",
      "[76]\ttraining's binary_logloss: 0.589697\n",
      "[77]\ttraining's binary_logloss: 0.589637\n",
      "[78]\ttraining's binary_logloss: 0.589583\n",
      "[79]\ttraining's binary_logloss: 0.589537\n",
      "[80]\ttraining's binary_logloss: 0.589531\n",
      "[81]\ttraining's binary_logloss: 0.589469\n",
      "[82]\ttraining's binary_logloss: 0.589414\n",
      "[83]\ttraining's binary_logloss: 0.589384\n",
      "[84]\ttraining's binary_logloss: 0.58935\n",
      "[85]\ttraining's binary_logloss: 0.58932\n",
      "[86]\ttraining's binary_logloss: 0.589298\n",
      "[87]\ttraining's binary_logloss: 0.589349\n",
      "[88]\ttraining's binary_logloss: 0.589409\n",
      "[89]\ttraining's binary_logloss: 0.589396\n",
      "[90]\ttraining's binary_logloss: 0.589389\n",
      "[91]\ttraining's binary_logloss: 0.589402\n",
      "[92]\ttraining's binary_logloss: 0.589412\n",
      "[93]\ttraining's binary_logloss: 0.589432\n",
      "[94]\ttraining's binary_logloss: 0.589458\n",
      "[95]\ttraining's binary_logloss: 0.589487\n",
      "[96]\ttraining's binary_logloss: 0.58946\n",
      "[97]\ttraining's binary_logloss: 0.589439\n",
      "[98]\ttraining's binary_logloss: 0.58942\n",
      "[99]\ttraining's binary_logloss: 0.589407\n",
      "[100]\ttraining's binary_logloss: 0.5894\n",
      "[101]\ttraining's binary_logloss: 0.589451\n",
      "[102]\ttraining's binary_logloss: 0.589486\n",
      "[103]\ttraining's binary_logloss: 0.589531\n",
      "[104]\ttraining's binary_logloss: 0.589586\n",
      "[105]\ttraining's binary_logloss: 0.589638\n",
      "[106]\ttraining's binary_logloss: 0.589638\n",
      "[107]\ttraining's binary_logloss: 0.589642\n",
      "[108]\ttraining's binary_logloss: 0.589648\n",
      "[109]\ttraining's binary_logloss: 0.589659\n",
      "[110]\ttraining's binary_logloss: 0.589708\n",
      "[111]\ttraining's binary_logloss: 0.589738\n",
      "[112]\ttraining's binary_logloss: 0.589739\n",
      "[113]\ttraining's binary_logloss: 0.589754\n",
      "[114]\ttraining's binary_logloss: 0.589801\n",
      "[115]\ttraining's binary_logloss: 0.589833\n",
      "[116]\ttraining's binary_logloss: 0.58991\n",
      "[117]\ttraining's binary_logloss: 0.589966\n",
      "[118]\ttraining's binary_logloss: 0.59002\n",
      "[119]\ttraining's binary_logloss: 0.590072\n",
      "[120]\ttraining's binary_logloss: 0.590117\n",
      "[121]\ttraining's binary_logloss: 0.590162\n",
      "[122]\ttraining's binary_logloss: 0.59022\n",
      "[123]\ttraining's binary_logloss: 0.590273\n",
      "[124]\ttraining's binary_logloss: 0.590335\n",
      "[125]\ttraining's binary_logloss: 0.590389\n",
      "[126]\ttraining's binary_logloss: 0.590441\n",
      "[127]\ttraining's binary_logloss: 0.590499\n",
      "[128]\ttraining's binary_logloss: 0.590565\n",
      "[129]\ttraining's binary_logloss: 0.590631\n",
      "[130]\ttraining's binary_logloss: 0.590695\n",
      "[131]\ttraining's binary_logloss: 0.590786\n",
      "[132]\ttraining's binary_logloss: 0.590862\n",
      "[133]\ttraining's binary_logloss: 0.590881\n",
      "[134]\ttraining's binary_logloss: 0.590906\n",
      "[135]\ttraining's binary_logloss: 0.590927\n",
      "[136]\ttraining's binary_logloss: 0.590962\n",
      "[137]\ttraining's binary_logloss: 0.591008\n",
      "[138]\ttraining's binary_logloss: 0.591045\n",
      "[139]\ttraining's binary_logloss: 0.59106\n",
      "[140]\ttraining's binary_logloss: 0.591093\n",
      "[141]\ttraining's binary_logloss: 0.591147\n",
      "[142]\ttraining's binary_logloss: 0.591204\n",
      "[143]\ttraining's binary_logloss: 0.591262\n",
      "[144]\ttraining's binary_logloss: 0.591323\n",
      "[145]\ttraining's binary_logloss: 0.591365\n",
      "[146]\ttraining's binary_logloss: 0.591373\n",
      "[147]\ttraining's binary_logloss: 0.5914\n",
      "[148]\ttraining's binary_logloss: 0.591414\n",
      "[149]\ttraining's binary_logloss: 0.591431\n",
      "[150]\ttraining's binary_logloss: 0.59145\n",
      "[151]\ttraining's binary_logloss: 0.591448\n",
      "[152]\ttraining's binary_logloss: 0.591455\n",
      "[153]\ttraining's binary_logloss: 0.591485\n",
      "[154]\ttraining's binary_logloss: 0.5915\n",
      "[155]\ttraining's binary_logloss: 0.591506\n",
      "[156]\ttraining's binary_logloss: 0.591573\n",
      "[157]\ttraining's binary_logloss: 0.591664\n",
      "[158]\ttraining's binary_logloss: 0.591733\n",
      "[159]\ttraining's binary_logloss: 0.591809\n",
      "[160]\ttraining's binary_logloss: 0.591867\n",
      "[161]\ttraining's binary_logloss: 0.591865\n",
      "[162]\ttraining's binary_logloss: 0.591871\n",
      "[163]\ttraining's binary_logloss: 0.591887\n",
      "[164]\ttraining's binary_logloss: 0.591903\n",
      "[165]\ttraining's binary_logloss: 0.591915\n",
      "[166]\ttraining's binary_logloss: 0.591943\n",
      "[167]\ttraining's binary_logloss: 0.59196\n",
      "[168]\ttraining's binary_logloss: 0.591965\n",
      "[169]\ttraining's binary_logloss: 0.592003\n",
      "[170]\ttraining's binary_logloss: 0.592024\n",
      "[171]\ttraining's binary_logloss: 0.592054\n",
      "[172]\ttraining's binary_logloss: 0.592051\n",
      "[173]\ttraining's binary_logloss: 0.59209\n",
      "[174]\ttraining's binary_logloss: 0.592091\n",
      "[175]\ttraining's binary_logloss: 0.592119\n",
      "[176]\ttraining's binary_logloss: 0.592185\n",
      "[177]\ttraining's binary_logloss: 0.592254\n",
      "[178]\ttraining's binary_logloss: 0.59231\n",
      "[179]\ttraining's binary_logloss: 0.592335\n",
      "[180]\ttraining's binary_logloss: 0.592391\n",
      "[181]\ttraining's binary_logloss: 0.592389\n",
      "[182]\ttraining's binary_logloss: 0.592376\n",
      "[183]\ttraining's binary_logloss: 0.592378\n",
      "[184]\ttraining's binary_logloss: 0.592358\n",
      "[185]\ttraining's binary_logloss: 0.592352\n",
      "[186]\ttraining's binary_logloss: 0.592371\n",
      "[187]\ttraining's binary_logloss: 0.592386\n",
      "[188]\ttraining's binary_logloss: 0.592408\n",
      "[189]\ttraining's binary_logloss: 0.592434\n",
      "[190]\ttraining's binary_logloss: 0.592453\n",
      "[191]\ttraining's binary_logloss: 0.592469\n",
      "[192]\ttraining's binary_logloss: 0.592487\n",
      "[193]\ttraining's binary_logloss: 0.592527\n",
      "[194]\ttraining's binary_logloss: 0.592546\n",
      "[195]\ttraining's binary_logloss: 0.59256\n",
      "[196]\ttraining's binary_logloss: 0.592589\n",
      "[197]\ttraining's binary_logloss: 0.592602\n",
      "[198]\ttraining's binary_logloss: 0.592604\n",
      "[199]\ttraining's binary_logloss: 0.592621\n",
      "[200]\ttraining's binary_logloss: 0.592643\n",
      "[201]\ttraining's binary_logloss: 0.592657\n",
      "[202]\ttraining's binary_logloss: 0.592673\n",
      "[203]\ttraining's binary_logloss: 0.592687\n",
      "[204]\ttraining's binary_logloss: 0.59271\n",
      "[205]\ttraining's binary_logloss: 0.592722\n",
      "[206]\ttraining's binary_logloss: 0.592751\n",
      "[207]\ttraining's binary_logloss: 0.59276\n",
      "[208]\ttraining's binary_logloss: 0.592767\n",
      "[209]\ttraining's binary_logloss: 0.592797\n",
      "[210]\ttraining's binary_logloss: 0.592817\n",
      "[211]\ttraining's binary_logloss: 0.592824\n",
      "[212]\ttraining's binary_logloss: 0.592832\n",
      "[213]\ttraining's binary_logloss: 0.592842\n",
      "[214]\ttraining's binary_logloss: 0.592852\n",
      "[215]\ttraining's binary_logloss: 0.592869\n",
      "[216]\ttraining's binary_logloss: 0.592858\n",
      "[217]\ttraining's binary_logloss: 0.592841\n",
      "[218]\ttraining's binary_logloss: 0.592831\n",
      "[219]\ttraining's binary_logloss: 0.592812\n",
      "[220]\ttraining's binary_logloss: 0.592806\n",
      "[221]\ttraining's binary_logloss: 0.592806\n",
      "[222]\ttraining's binary_logloss: 0.592811\n",
      "[223]\ttraining's binary_logloss: 0.592817\n",
      "[224]\ttraining's binary_logloss: 0.592821\n",
      "[225]\ttraining's binary_logloss: 0.592784\n",
      "[226]\ttraining's binary_logloss: 0.592806\n",
      "[227]\ttraining's binary_logloss: 0.592802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[228]\ttraining's binary_logloss: 0.592804\n",
      "[229]\ttraining's binary_logloss: 0.592803\n",
      "[230]\ttraining's binary_logloss: 0.592817\n",
      "[231]\ttraining's binary_logloss: 0.592785\n",
      "[232]\ttraining's binary_logloss: 0.592752\n",
      "[233]\ttraining's binary_logloss: 0.592728\n",
      "[234]\ttraining's binary_logloss: 0.592698\n",
      "[235]\ttraining's binary_logloss: 0.592666\n",
      "[236]\ttraining's binary_logloss: 0.592638\n",
      "[237]\ttraining's binary_logloss: 0.592587\n",
      "[238]\ttraining's binary_logloss: 0.592537\n",
      "[239]\ttraining's binary_logloss: 0.592492\n",
      "[240]\ttraining's binary_logloss: 0.592453\n",
      "[241]\ttraining's binary_logloss: 0.592418\n",
      "[242]\ttraining's binary_logloss: 0.592409\n",
      "[243]\ttraining's binary_logloss: 0.592378\n",
      "[244]\ttraining's binary_logloss: 0.592345\n",
      "[245]\ttraining's binary_logloss: 0.592339\n",
      "[246]\ttraining's binary_logloss: 0.592373\n",
      "[247]\ttraining's binary_logloss: 0.592407\n",
      "[248]\ttraining's binary_logloss: 0.592447\n",
      "[249]\ttraining's binary_logloss: 0.592486\n",
      "[250]\ttraining's binary_logloss: 0.592491\n",
      "[251]\ttraining's binary_logloss: 0.592444\n",
      "[252]\ttraining's binary_logloss: 0.592395\n",
      "[253]\ttraining's binary_logloss: 0.592357\n",
      "[254]\ttraining's binary_logloss: 0.59232\n",
      "[255]\ttraining's binary_logloss: 0.592278\n",
      "[256]\ttraining's binary_logloss: 0.592243\n",
      "[257]\ttraining's binary_logloss: 0.592223\n",
      "[258]\ttraining's binary_logloss: 0.592199\n",
      "[259]\ttraining's binary_logloss: 0.592188\n",
      "[260]\ttraining's binary_logloss: 0.592157\n",
      "[261]\ttraining's binary_logloss: 0.59214\n",
      "[262]\ttraining's binary_logloss: 0.592107\n",
      "[263]\ttraining's binary_logloss: 0.592077\n",
      "[264]\ttraining's binary_logloss: 0.592047\n",
      "[265]\ttraining's binary_logloss: 0.592028\n",
      "[266]\ttraining's binary_logloss: 0.592033\n",
      "[267]\ttraining's binary_logloss: 0.592035\n",
      "[268]\ttraining's binary_logloss: 0.592031\n",
      "[269]\ttraining's binary_logloss: 0.592037\n",
      "[270]\ttraining's binary_logloss: 0.592051\n",
      "[271]\ttraining's binary_logloss: 0.592002\n",
      "[272]\ttraining's binary_logloss: 0.591967\n",
      "[273]\ttraining's binary_logloss: 0.591929\n",
      "[274]\ttraining's binary_logloss: 0.591883\n",
      "[275]\ttraining's binary_logloss: 0.591835\n",
      "[276]\ttraining's binary_logloss: 0.591781\n",
      "[277]\ttraining's binary_logloss: 0.591737\n",
      "[278]\ttraining's binary_logloss: 0.591691\n",
      "[279]\ttraining's binary_logloss: 0.591648\n",
      "[280]\ttraining's binary_logloss: 0.591605\n",
      "[281]\ttraining's binary_logloss: 0.591584\n",
      "[282]\ttraining's binary_logloss: 0.591551\n",
      "[283]\ttraining's binary_logloss: 0.591535\n",
      "[284]\ttraining's binary_logloss: 0.591504\n",
      "[285]\ttraining's binary_logloss: 0.591483\n",
      "[286]\ttraining's binary_logloss: 0.591435\n",
      "[287]\ttraining's binary_logloss: 0.591412\n",
      "[288]\ttraining's binary_logloss: 0.591362\n",
      "[289]\ttraining's binary_logloss: 0.59131\n",
      "[290]\ttraining's binary_logloss: 0.591262\n",
      "[291]\ttraining's binary_logloss: 0.591215\n",
      "[292]\ttraining's binary_logloss: 0.591154\n",
      "[293]\ttraining's binary_logloss: 0.591094\n",
      "[294]\ttraining's binary_logloss: 0.591045\n",
      "[295]\ttraining's binary_logloss: 0.59099\n",
      "[296]\ttraining's binary_logloss: 0.590942\n",
      "[297]\ttraining's binary_logloss: 0.590896\n",
      "[298]\ttraining's binary_logloss: 0.590879\n",
      "[299]\ttraining's binary_logloss: 0.590857\n",
      "[300]\ttraining's binary_logloss: 0.590837\n",
      "[301]\ttraining's binary_logloss: 0.590777\n",
      "[302]\ttraining's binary_logloss: 0.59072\n",
      "[303]\ttraining's binary_logloss: 0.590663\n",
      "[304]\ttraining's binary_logloss: 0.590609\n",
      "[305]\ttraining's binary_logloss: 0.590557\n",
      "[306]\ttraining's binary_logloss: 0.590522\n",
      "[307]\ttraining's binary_logloss: 0.590479\n",
      "[308]\ttraining's binary_logloss: 0.590446\n",
      "[309]\ttraining's binary_logloss: 0.590415\n",
      "[310]\ttraining's binary_logloss: 0.590389\n",
      "[311]\ttraining's binary_logloss: 0.590353\n",
      "[312]\ttraining's binary_logloss: 0.59034\n",
      "[313]\ttraining's binary_logloss: 0.590301\n",
      "[314]\ttraining's binary_logloss: 0.590283\n",
      "[315]\ttraining's binary_logloss: 0.590246\n",
      "[316]\ttraining's binary_logloss: 0.590174\n",
      "[317]\ttraining's binary_logloss: 0.590114\n",
      "[318]\ttraining's binary_logloss: 0.590038\n",
      "[319]\ttraining's binary_logloss: 0.589956\n",
      "[320]\ttraining's binary_logloss: 0.589907\n",
      "[321]\ttraining's binary_logloss: 0.589842\n",
      "[322]\ttraining's binary_logloss: 0.589762\n",
      "[323]\ttraining's binary_logloss: 0.589688\n",
      "[324]\ttraining's binary_logloss: 0.58962\n",
      "[325]\ttraining's binary_logloss: 0.589551\n",
      "[326]\ttraining's binary_logloss: 0.589486\n",
      "[327]\ttraining's binary_logloss: 0.589433\n",
      "[328]\ttraining's binary_logloss: 0.589378\n",
      "[329]\ttraining's binary_logloss: 0.589319\n",
      "[330]\ttraining's binary_logloss: 0.589275\n",
      "[331]\ttraining's binary_logloss: 0.589212\n",
      "[332]\ttraining's binary_logloss: 0.589144\n",
      "[333]\ttraining's binary_logloss: 0.589085\n",
      "[334]\ttraining's binary_logloss: 0.588985\n",
      "[335]\ttraining's binary_logloss: 0.588923\n",
      "[336]\ttraining's binary_logloss: 0.588881\n",
      "[337]\ttraining's binary_logloss: 0.588861\n",
      "[338]\ttraining's binary_logloss: 0.588836\n",
      "[339]\ttraining's binary_logloss: 0.588795\n",
      "[340]\ttraining's binary_logloss: 0.588758\n",
      "[341]\ttraining's binary_logloss: 0.58873\n",
      "[342]\ttraining's binary_logloss: 0.588699\n",
      "[343]\ttraining's binary_logloss: 0.588677\n",
      "[344]\ttraining's binary_logloss: 0.588637\n",
      "[345]\ttraining's binary_logloss: 0.588618\n",
      "[346]\ttraining's binary_logloss: 0.58857\n",
      "[347]\ttraining's binary_logloss: 0.588527\n",
      "[348]\ttraining's binary_logloss: 0.588488\n",
      "[349]\ttraining's binary_logloss: 0.588445\n",
      "[350]\ttraining's binary_logloss: 0.58841\n",
      "[351]\ttraining's binary_logloss: 0.588351\n",
      "[352]\ttraining's binary_logloss: 0.588304\n",
      "[353]\ttraining's binary_logloss: 0.588248\n",
      "[354]\ttraining's binary_logloss: 0.588185\n",
      "[355]\ttraining's binary_logloss: 0.588124\n",
      "[356]\ttraining's binary_logloss: 0.588033\n",
      "[357]\ttraining's binary_logloss: 0.587944\n",
      "[358]\ttraining's binary_logloss: 0.587858\n",
      "[359]\ttraining's binary_logloss: 0.587773\n",
      "[360]\ttraining's binary_logloss: 0.58769\n",
      "[361]\ttraining's binary_logloss: 0.587579\n",
      "[362]\ttraining's binary_logloss: 0.587471\n",
      "[363]\ttraining's binary_logloss: 0.587365\n",
      "[364]\ttraining's binary_logloss: 0.587264\n",
      "[365]\ttraining's binary_logloss: 0.587161\n",
      "[366]\ttraining's binary_logloss: 0.587116\n",
      "[367]\ttraining's binary_logloss: 0.587048\n",
      "[368]\ttraining's binary_logloss: 0.587002\n",
      "[369]\ttraining's binary_logloss: 0.586958\n",
      "[370]\ttraining's binary_logloss: 0.586914\n",
      "[371]\ttraining's binary_logloss: 0.586878\n",
      "[372]\ttraining's binary_logloss: 0.58683\n",
      "[373]\ttraining's binary_logloss: 0.586794\n",
      "[374]\ttraining's binary_logloss: 0.58676\n",
      "[375]\ttraining's binary_logloss: 0.586727\n",
      "[376]\ttraining's binary_logloss: 0.586675\n",
      "[377]\ttraining's binary_logloss: 0.586596\n",
      "[378]\ttraining's binary_logloss: 0.586515\n",
      "[379]\ttraining's binary_logloss: 0.586437\n",
      "[380]\ttraining's binary_logloss: 0.58636\n",
      "[381]\ttraining's binary_logloss: 0.58634\n",
      "[382]\ttraining's binary_logloss: 0.586312\n",
      "[383]\ttraining's binary_logloss: 0.586294\n",
      "[384]\ttraining's binary_logloss: 0.586276\n",
      "[385]\ttraining's binary_logloss: 0.586237\n",
      "[386]\ttraining's binary_logloss: 0.586147\n",
      "[387]\ttraining's binary_logloss: 0.58601\n",
      "[388]\ttraining's binary_logloss: 0.585877\n",
      "[389]\ttraining's binary_logloss: 0.585772\n",
      "[390]\ttraining's binary_logloss: 0.585671\n",
      "[391]\ttraining's binary_logloss: 0.585594\n",
      "[392]\ttraining's binary_logloss: 0.58554\n",
      "[393]\ttraining's binary_logloss: 0.585466\n",
      "[394]\ttraining's binary_logloss: 0.585386\n",
      "[395]\ttraining's binary_logloss: 0.585308\n",
      "[396]\ttraining's binary_logloss: 0.585217\n",
      "[397]\ttraining's binary_logloss: 0.585151\n",
      "[398]\ttraining's binary_logloss: 0.585059\n",
      "[399]\ttraining's binary_logloss: 0.584983\n",
      "[400]\ttraining's binary_logloss: 0.584915\n",
      "[401]\ttraining's binary_logloss: 0.5848\n",
      "[402]\ttraining's binary_logloss: 0.584688\n",
      "[403]\ttraining's binary_logloss: 0.584578\n",
      "[404]\ttraining's binary_logloss: 0.584462\n",
      "[405]\ttraining's binary_logloss: 0.584366\n",
      "[406]\ttraining's binary_logloss: 0.584306\n",
      "[407]\ttraining's binary_logloss: 0.584242\n",
      "[408]\ttraining's binary_logloss: 0.584189\n",
      "[409]\ttraining's binary_logloss: 0.584132\n",
      "[410]\ttraining's binary_logloss: 0.58408\n",
      "[411]\ttraining's binary_logloss: 0.58398\n",
      "[412]\ttraining's binary_logloss: 0.58387\n",
      "[413]\ttraining's binary_logloss: 0.583775\n",
      "[414]\ttraining's binary_logloss: 0.583675\n",
      "[415]\ttraining's binary_logloss: 0.583563\n",
      "[416]\ttraining's binary_logloss: 0.58347\n",
      "[417]\ttraining's binary_logloss: 0.583373\n",
      "[418]\ttraining's binary_logloss: 0.583308\n",
      "[419]\ttraining's binary_logloss: 0.583244\n",
      "[420]\ttraining's binary_logloss: 0.583148\n",
      "[421]\ttraining's binary_logloss: 0.583117\n",
      "[422]\ttraining's binary_logloss: 0.58309\n",
      "[423]\ttraining's binary_logloss: 0.583056\n",
      "[424]\ttraining's binary_logloss: 0.583027\n",
      "[425]\ttraining's binary_logloss: 0.582995\n",
      "[426]\ttraining's binary_logloss: 0.582927\n",
      "[427]\ttraining's binary_logloss: 0.582869\n",
      "[428]\ttraining's binary_logloss: 0.582803\n",
      "[429]\ttraining's binary_logloss: 0.582747\n",
      "[430]\ttraining's binary_logloss: 0.582689\n",
      "[431]\ttraining's binary_logloss: 0.582595\n",
      "[432]\ttraining's binary_logloss: 0.582487\n",
      "[433]\ttraining's binary_logloss: 0.582406\n",
      "[434]\ttraining's binary_logloss: 0.582301\n",
      "[435]\ttraining's binary_logloss: 0.582219\n",
      "[436]\ttraining's binary_logloss: 0.582162\n",
      "[437]\ttraining's binary_logloss: 0.582103\n",
      "[438]\ttraining's binary_logloss: 0.582051\n",
      "[439]\ttraining's binary_logloss: 0.581994\n",
      "[440]\ttraining's binary_logloss: 0.581941\n",
      "[441]\ttraining's binary_logloss: 0.581879\n",
      "[442]\ttraining's binary_logloss: 0.5818\n",
      "[443]\ttraining's binary_logloss: 0.581728\n",
      "[444]\ttraining's binary_logloss: 0.581647\n",
      "[445]\ttraining's binary_logloss: 0.58158\n",
      "[446]\ttraining's binary_logloss: 0.581505\n",
      "[447]\ttraining's binary_logloss: 0.581422\n",
      "[448]\ttraining's binary_logloss: 0.581349\n",
      "[449]\ttraining's binary_logloss: 0.581263\n",
      "[450]\ttraining's binary_logloss: 0.581183\n",
      "[451]\ttraining's binary_logloss: 0.581137\n",
      "[452]\ttraining's binary_logloss: 0.581094\n",
      "[453]\ttraining's binary_logloss: 0.581054\n",
      "[454]\ttraining's binary_logloss: 0.581003\n",
      "[455]\ttraining's binary_logloss: 0.580961\n",
      "[456]\ttraining's binary_logloss: 0.58089\n",
      "[457]\ttraining's binary_logloss: 0.58083\n",
      "[458]\ttraining's binary_logloss: 0.580765\n",
      "[459]\ttraining's binary_logloss: 0.580702\n",
      "[460]\ttraining's binary_logloss: 0.58064\n",
      "[461]\ttraining's binary_logloss: 0.580551\n",
      "[462]\ttraining's binary_logloss: 0.580464\n",
      "[463]\ttraining's binary_logloss: 0.58038\n",
      "[464]\ttraining's binary_logloss: 0.580288\n",
      "[465]\ttraining's binary_logloss: 0.580205\n",
      "[466]\ttraining's binary_logloss: 0.580117\n",
      "[467]\ttraining's binary_logloss: 0.580029\n",
      "[468]\ttraining's binary_logloss: 0.579959\n",
      "[469]\ttraining's binary_logloss: 0.579879\n",
      "[470]\ttraining's binary_logloss: 0.579818\n",
      "[471]\ttraining's binary_logloss: 0.579768\n",
      "[472]\ttraining's binary_logloss: 0.579719\n",
      "[473]\ttraining's binary_logloss: 0.579675\n",
      "[474]\ttraining's binary_logloss: 0.579637\n",
      "[475]\ttraining's binary_logloss: 0.579587\n",
      "[476]\ttraining's binary_logloss: 0.579522\n",
      "[477]\ttraining's binary_logloss: 0.579461\n",
      "[478]\ttraining's binary_logloss: 0.579399\n",
      "[479]\ttraining's binary_logloss: 0.579334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[480]\ttraining's binary_logloss: 0.579275\n",
      "[481]\ttraining's binary_logloss: 0.579205\n",
      "[482]\ttraining's binary_logloss: 0.579141\n",
      "[483]\ttraining's binary_logloss: 0.579083\n",
      "[484]\ttraining's binary_logloss: 0.579015\n",
      "[485]\ttraining's binary_logloss: 0.578964\n",
      "[486]\ttraining's binary_logloss: 0.578871\n",
      "[487]\ttraining's binary_logloss: 0.578768\n",
      "[488]\ttraining's binary_logloss: 0.57868\n",
      "[489]\ttraining's binary_logloss: 0.578594\n",
      "[490]\ttraining's binary_logloss: 0.57851\n",
      "[491]\ttraining's binary_logloss: 0.578469\n",
      "[492]\ttraining's binary_logloss: 0.578435\n",
      "[493]\ttraining's binary_logloss: 0.578393\n",
      "[494]\ttraining's binary_logloss: 0.578354\n",
      "[495]\ttraining's binary_logloss: 0.57832\n",
      "[496]\ttraining's binary_logloss: 0.578237\n",
      "[497]\ttraining's binary_logloss: 0.578139\n",
      "[498]\ttraining's binary_logloss: 0.578053\n",
      "[499]\ttraining's binary_logloss: 0.577944\n",
      "[500]\ttraining's binary_logloss: 0.577849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614075\n",
      "[2]\ttraining's binary_logloss: 0.612915\n",
      "[3]\ttraining's binary_logloss: 0.611841\n",
      "[4]\ttraining's binary_logloss: 0.610732\n",
      "[5]\ttraining's binary_logloss: 0.609742\n",
      "[6]\ttraining's binary_logloss: 0.608809\n",
      "[7]\ttraining's binary_logloss: 0.607912\n",
      "[8]\ttraining's binary_logloss: 0.607071\n",
      "[9]\ttraining's binary_logloss: 0.606211\n",
      "[10]\ttraining's binary_logloss: 0.60541\n",
      "[11]\ttraining's binary_logloss: 0.604579\n",
      "[12]\ttraining's binary_logloss: 0.603929\n",
      "[13]\ttraining's binary_logloss: 0.603278\n",
      "[14]\ttraining's binary_logloss: 0.602547\n",
      "[15]\ttraining's binary_logloss: 0.601851\n",
      "[16]\ttraining's binary_logloss: 0.601148\n",
      "[17]\ttraining's binary_logloss: 0.600496\n",
      "[18]\ttraining's binary_logloss: 0.599847\n",
      "[19]\ttraining's binary_logloss: 0.59925\n",
      "[20]\ttraining's binary_logloss: 0.59877\n",
      "[21]\ttraining's binary_logloss: 0.598308\n",
      "[22]\ttraining's binary_logloss: 0.597813\n",
      "[23]\ttraining's binary_logloss: 0.597379\n",
      "[24]\ttraining's binary_logloss: 0.596839\n",
      "[25]\ttraining's binary_logloss: 0.596322\n",
      "[26]\ttraining's binary_logloss: 0.595907\n",
      "[27]\ttraining's binary_logloss: 0.595531\n",
      "[28]\ttraining's binary_logloss: 0.595145\n",
      "[29]\ttraining's binary_logloss: 0.59479\n",
      "[30]\ttraining's binary_logloss: 0.594433\n",
      "[31]\ttraining's binary_logloss: 0.594057\n",
      "[32]\ttraining's binary_logloss: 0.593688\n",
      "[33]\ttraining's binary_logloss: 0.593338\n",
      "[34]\ttraining's binary_logloss: 0.593004\n",
      "[35]\ttraining's binary_logloss: 0.592562\n",
      "[36]\ttraining's binary_logloss: 0.592186\n",
      "[37]\ttraining's binary_logloss: 0.591887\n",
      "[38]\ttraining's binary_logloss: 0.591542\n",
      "[39]\ttraining's binary_logloss: 0.591206\n",
      "[40]\ttraining's binary_logloss: 0.590895\n",
      "[41]\ttraining's binary_logloss: 0.59063\n",
      "[42]\ttraining's binary_logloss: 0.59038\n",
      "[43]\ttraining's binary_logloss: 0.590128\n",
      "[44]\ttraining's binary_logloss: 0.589903\n",
      "[45]\ttraining's binary_logloss: 0.589696\n",
      "[46]\ttraining's binary_logloss: 0.589539\n",
      "[47]\ttraining's binary_logloss: 0.589297\n",
      "[48]\ttraining's binary_logloss: 0.589063\n",
      "[49]\ttraining's binary_logloss: 0.588845\n",
      "[50]\ttraining's binary_logloss: 0.588639\n",
      "[51]\ttraining's binary_logloss: 0.588456\n",
      "[52]\ttraining's binary_logloss: 0.588309\n",
      "[53]\ttraining's binary_logloss: 0.588192\n",
      "[54]\ttraining's binary_logloss: 0.588003\n",
      "[55]\ttraining's binary_logloss: 0.587923\n",
      "[56]\ttraining's binary_logloss: 0.587784\n",
      "[57]\ttraining's binary_logloss: 0.587686\n",
      "[58]\ttraining's binary_logloss: 0.587592\n",
      "[59]\ttraining's binary_logloss: 0.587405\n",
      "[60]\ttraining's binary_logloss: 0.587298\n",
      "[61]\ttraining's binary_logloss: 0.587175\n",
      "[62]\ttraining's binary_logloss: 0.587065\n",
      "[63]\ttraining's binary_logloss: 0.586965\n",
      "[64]\ttraining's binary_logloss: 0.586896\n",
      "[65]\ttraining's binary_logloss: 0.586813\n",
      "[66]\ttraining's binary_logloss: 0.586701\n",
      "[67]\ttraining's binary_logloss: 0.586602\n",
      "[68]\ttraining's binary_logloss: 0.586529\n",
      "[69]\ttraining's binary_logloss: 0.586514\n",
      "[70]\ttraining's binary_logloss: 0.586441\n",
      "[71]\ttraining's binary_logloss: 0.586391\n",
      "[72]\ttraining's binary_logloss: 0.586325\n",
      "[73]\ttraining's binary_logloss: 0.586289\n",
      "[74]\ttraining's binary_logloss: 0.586203\n",
      "[75]\ttraining's binary_logloss: 0.58616\n",
      "[76]\ttraining's binary_logloss: 0.586016\n",
      "[77]\ttraining's binary_logloss: 0.58588\n",
      "[78]\ttraining's binary_logloss: 0.585752\n",
      "[79]\ttraining's binary_logloss: 0.585697\n",
      "[80]\ttraining's binary_logloss: 0.585651\n",
      "[81]\ttraining's binary_logloss: 0.585564\n",
      "[82]\ttraining's binary_logloss: 0.58549\n",
      "[83]\ttraining's binary_logloss: 0.58546\n",
      "[84]\ttraining's binary_logloss: 0.585462\n",
      "[85]\ttraining's binary_logloss: 0.585404\n",
      "[86]\ttraining's binary_logloss: 0.585452\n",
      "[87]\ttraining's binary_logloss: 0.585398\n",
      "[88]\ttraining's binary_logloss: 0.585333\n",
      "[89]\ttraining's binary_logloss: 0.585345\n",
      "[90]\ttraining's binary_logloss: 0.585365\n",
      "[91]\ttraining's binary_logloss: 0.585365\n",
      "[92]\ttraining's binary_logloss: 0.585371\n",
      "[93]\ttraining's binary_logloss: 0.585377\n",
      "[94]\ttraining's binary_logloss: 0.585393\n",
      "[95]\ttraining's binary_logloss: 0.585383\n",
      "[96]\ttraining's binary_logloss: 0.585401\n",
      "[97]\ttraining's binary_logloss: 0.585425\n",
      "[98]\ttraining's binary_logloss: 0.585465\n",
      "[99]\ttraining's binary_logloss: 0.585489\n",
      "[100]\ttraining's binary_logloss: 0.585523\n",
      "[101]\ttraining's binary_logloss: 0.585532\n",
      "[102]\ttraining's binary_logloss: 0.58558\n",
      "[103]\ttraining's binary_logloss: 0.585614\n",
      "[104]\ttraining's binary_logloss: 0.585659\n",
      "[105]\ttraining's binary_logloss: 0.585687\n",
      "[106]\ttraining's binary_logloss: 0.585669\n",
      "[107]\ttraining's binary_logloss: 0.585652\n",
      "[108]\ttraining's binary_logloss: 0.585643\n",
      "[109]\ttraining's binary_logloss: 0.585631\n",
      "[110]\ttraining's binary_logloss: 0.585662\n",
      "[111]\ttraining's binary_logloss: 0.585709\n",
      "[112]\ttraining's binary_logloss: 0.585759\n",
      "[113]\ttraining's binary_logloss: 0.585819\n",
      "[114]\ttraining's binary_logloss: 0.585805\n",
      "[115]\ttraining's binary_logloss: 0.58585\n",
      "[116]\ttraining's binary_logloss: 0.585863\n",
      "[117]\ttraining's binary_logloss: 0.585954\n",
      "[118]\ttraining's binary_logloss: 0.586037\n",
      "[119]\ttraining's binary_logloss: 0.586109\n",
      "[120]\ttraining's binary_logloss: 0.586181\n",
      "[121]\ttraining's binary_logloss: 0.586166\n",
      "[122]\ttraining's binary_logloss: 0.586152\n",
      "[123]\ttraining's binary_logloss: 0.586147\n",
      "[124]\ttraining's binary_logloss: 0.586178\n",
      "[125]\ttraining's binary_logloss: 0.58617\n",
      "[126]\ttraining's binary_logloss: 0.586206\n",
      "[127]\ttraining's binary_logloss: 0.586194\n",
      "[128]\ttraining's binary_logloss: 0.586182\n",
      "[129]\ttraining's binary_logloss: 0.586183\n",
      "[130]\ttraining's binary_logloss: 0.586179\n",
      "[131]\ttraining's binary_logloss: 0.586179\n",
      "[132]\ttraining's binary_logloss: 0.586181\n",
      "[133]\ttraining's binary_logloss: 0.586187\n",
      "[134]\ttraining's binary_logloss: 0.586183\n",
      "[135]\ttraining's binary_logloss: 0.586192\n",
      "[136]\ttraining's binary_logloss: 0.586202\n",
      "[137]\ttraining's binary_logloss: 0.58619\n",
      "[138]\ttraining's binary_logloss: 0.586192\n",
      "[139]\ttraining's binary_logloss: 0.586196\n",
      "[140]\ttraining's binary_logloss: 0.586217\n",
      "[141]\ttraining's binary_logloss: 0.586214\n",
      "[142]\ttraining's binary_logloss: 0.586224\n",
      "[143]\ttraining's binary_logloss: 0.58625\n",
      "[144]\ttraining's binary_logloss: 0.586237\n",
      "[145]\ttraining's binary_logloss: 0.586228\n",
      "[146]\ttraining's binary_logloss: 0.586273\n",
      "[147]\ttraining's binary_logloss: 0.586307\n",
      "[148]\ttraining's binary_logloss: 0.586351\n",
      "[149]\ttraining's binary_logloss: 0.58636\n",
      "[150]\ttraining's binary_logloss: 0.586387\n",
      "[151]\ttraining's binary_logloss: 0.586381\n",
      "[152]\ttraining's binary_logloss: 0.586377\n",
      "[153]\ttraining's binary_logloss: 0.586369\n",
      "[154]\ttraining's binary_logloss: 0.586369\n",
      "[155]\ttraining's binary_logloss: 0.586363\n",
      "[156]\ttraining's binary_logloss: 0.5864\n",
      "[157]\ttraining's binary_logloss: 0.586424\n",
      "[158]\ttraining's binary_logloss: 0.586446\n",
      "[159]\ttraining's binary_logloss: 0.586467\n",
      "[160]\ttraining's binary_logloss: 0.586491\n",
      "[161]\ttraining's binary_logloss: 0.586478\n",
      "[162]\ttraining's binary_logloss: 0.586485\n",
      "[163]\ttraining's binary_logloss: 0.58647\n",
      "[164]\ttraining's binary_logloss: 0.586457\n",
      "[165]\ttraining's binary_logloss: 0.586457\n",
      "[166]\ttraining's binary_logloss: 0.586419\n",
      "[167]\ttraining's binary_logloss: 0.586384\n",
      "[168]\ttraining's binary_logloss: 0.586363\n",
      "[169]\ttraining's binary_logloss: 0.586378\n",
      "[170]\ttraining's binary_logloss: 0.586359\n",
      "[171]\ttraining's binary_logloss: 0.586341\n",
      "[172]\ttraining's binary_logloss: 0.58636\n",
      "[173]\ttraining's binary_logloss: 0.586349\n",
      "[174]\ttraining's binary_logloss: 0.586341\n",
      "[175]\ttraining's binary_logloss: 0.586345\n",
      "[176]\ttraining's binary_logloss: 0.586346\n",
      "[177]\ttraining's binary_logloss: 0.586348\n",
      "[178]\ttraining's binary_logloss: 0.586354\n",
      "[179]\ttraining's binary_logloss: 0.586361\n",
      "[180]\ttraining's binary_logloss: 0.586395\n",
      "[181]\ttraining's binary_logloss: 0.586419\n",
      "[182]\ttraining's binary_logloss: 0.586436\n",
      "[183]\ttraining's binary_logloss: 0.586451\n",
      "[184]\ttraining's binary_logloss: 0.586443\n",
      "[185]\ttraining's binary_logloss: 0.586437\n",
      "[186]\ttraining's binary_logloss: 0.58643\n",
      "[187]\ttraining's binary_logloss: 0.586434\n",
      "[188]\ttraining's binary_logloss: 0.586434\n",
      "[189]\ttraining's binary_logloss: 0.586442\n",
      "[190]\ttraining's binary_logloss: 0.586445\n",
      "[191]\ttraining's binary_logloss: 0.58645\n",
      "[192]\ttraining's binary_logloss: 0.586448\n",
      "[193]\ttraining's binary_logloss: 0.586456\n",
      "[194]\ttraining's binary_logloss: 0.58646\n",
      "[195]\ttraining's binary_logloss: 0.586471\n",
      "[196]\ttraining's binary_logloss: 0.586435\n",
      "[197]\ttraining's binary_logloss: 0.586401\n",
      "[198]\ttraining's binary_logloss: 0.586374\n",
      "[199]\ttraining's binary_logloss: 0.586344\n",
      "[200]\ttraining's binary_logloss: 0.586342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[201]\ttraining's binary_logloss: 0.586333\n",
      "[202]\ttraining's binary_logloss: 0.586329\n",
      "[203]\ttraining's binary_logloss: 0.586338\n",
      "[204]\ttraining's binary_logloss: 0.586357\n",
      "[205]\ttraining's binary_logloss: 0.58637\n",
      "[206]\ttraining's binary_logloss: 0.586361\n",
      "[207]\ttraining's binary_logloss: 0.586368\n",
      "[208]\ttraining's binary_logloss: 0.586323\n",
      "[209]\ttraining's binary_logloss: 0.586315\n",
      "[210]\ttraining's binary_logloss: 0.586312\n",
      "[211]\ttraining's binary_logloss: 0.586327\n",
      "[212]\ttraining's binary_logloss: 0.586343\n",
      "[213]\ttraining's binary_logloss: 0.586378\n",
      "[214]\ttraining's binary_logloss: 0.58641\n",
      "[215]\ttraining's binary_logloss: 0.586433\n",
      "[216]\ttraining's binary_logloss: 0.586382\n",
      "[217]\ttraining's binary_logloss: 0.586333\n",
      "[218]\ttraining's binary_logloss: 0.586285\n",
      "[219]\ttraining's binary_logloss: 0.586238\n",
      "[220]\ttraining's binary_logloss: 0.586194\n",
      "[221]\ttraining's binary_logloss: 0.586126\n",
      "[222]\ttraining's binary_logloss: 0.586099\n",
      "[223]\ttraining's binary_logloss: 0.586033\n",
      "[224]\ttraining's binary_logloss: 0.585971\n",
      "[225]\ttraining's binary_logloss: 0.585937\n",
      "[226]\ttraining's binary_logloss: 0.585926\n",
      "[227]\ttraining's binary_logloss: 0.585928\n",
      "[228]\ttraining's binary_logloss: 0.585925\n",
      "[229]\ttraining's binary_logloss: 0.585922\n",
      "[230]\ttraining's binary_logloss: 0.585926\n",
      "[231]\ttraining's binary_logloss: 0.585914\n",
      "[232]\ttraining's binary_logloss: 0.585897\n",
      "[233]\ttraining's binary_logloss: 0.585884\n",
      "[234]\ttraining's binary_logloss: 0.585862\n",
      "[235]\ttraining's binary_logloss: 0.585838\n",
      "[236]\ttraining's binary_logloss: 0.585806\n",
      "[237]\ttraining's binary_logloss: 0.585761\n",
      "[238]\ttraining's binary_logloss: 0.585734\n",
      "[239]\ttraining's binary_logloss: 0.585701\n",
      "[240]\ttraining's binary_logloss: 0.585666\n",
      "[241]\ttraining's binary_logloss: 0.585616\n",
      "[242]\ttraining's binary_logloss: 0.585567\n",
      "[243]\ttraining's binary_logloss: 0.58552\n",
      "[244]\ttraining's binary_logloss: 0.58547\n",
      "[245]\ttraining's binary_logloss: 0.585415\n",
      "[246]\ttraining's binary_logloss: 0.585371\n",
      "[247]\ttraining's binary_logloss: 0.585346\n",
      "[248]\ttraining's binary_logloss: 0.585308\n",
      "[249]\ttraining's binary_logloss: 0.585267\n",
      "[250]\ttraining's binary_logloss: 0.585227\n",
      "[251]\ttraining's binary_logloss: 0.585228\n",
      "[252]\ttraining's binary_logloss: 0.585229\n",
      "[253]\ttraining's binary_logloss: 0.585219\n",
      "[254]\ttraining's binary_logloss: 0.58521\n",
      "[255]\ttraining's binary_logloss: 0.585209\n",
      "[256]\ttraining's binary_logloss: 0.585169\n",
      "[257]\ttraining's binary_logloss: 0.585124\n",
      "[258]\ttraining's binary_logloss: 0.585079\n",
      "[259]\ttraining's binary_logloss: 0.585039\n",
      "[260]\ttraining's binary_logloss: 0.584992\n",
      "[261]\ttraining's binary_logloss: 0.584977\n",
      "[262]\ttraining's binary_logloss: 0.584917\n",
      "[263]\ttraining's binary_logloss: 0.584895\n",
      "[264]\ttraining's binary_logloss: 0.584871\n",
      "[265]\ttraining's binary_logloss: 0.584845\n",
      "[266]\ttraining's binary_logloss: 0.58484\n",
      "[267]\ttraining's binary_logloss: 0.584856\n",
      "[268]\ttraining's binary_logloss: 0.584883\n",
      "[269]\ttraining's binary_logloss: 0.584902\n",
      "[270]\ttraining's binary_logloss: 0.584915\n",
      "[271]\ttraining's binary_logloss: 0.584832\n",
      "[272]\ttraining's binary_logloss: 0.584749\n",
      "[273]\ttraining's binary_logloss: 0.584669\n",
      "[274]\ttraining's binary_logloss: 0.584592\n",
      "[275]\ttraining's binary_logloss: 0.584517\n",
      "[276]\ttraining's binary_logloss: 0.584439\n",
      "[277]\ttraining's binary_logloss: 0.584365\n",
      "[278]\ttraining's binary_logloss: 0.584287\n",
      "[279]\ttraining's binary_logloss: 0.584218\n",
      "[280]\ttraining's binary_logloss: 0.584142\n",
      "[281]\ttraining's binary_logloss: 0.584098\n",
      "[282]\ttraining's binary_logloss: 0.584067\n",
      "[283]\ttraining's binary_logloss: 0.584009\n",
      "[284]\ttraining's binary_logloss: 0.583966\n",
      "[285]\ttraining's binary_logloss: 0.583906\n",
      "[286]\ttraining's binary_logloss: 0.583845\n",
      "[287]\ttraining's binary_logloss: 0.583783\n",
      "[288]\ttraining's binary_logloss: 0.58373\n",
      "[289]\ttraining's binary_logloss: 0.583682\n",
      "[290]\ttraining's binary_logloss: 0.58363\n",
      "[291]\ttraining's binary_logloss: 0.583556\n",
      "[292]\ttraining's binary_logloss: 0.58348\n",
      "[293]\ttraining's binary_logloss: 0.583411\n",
      "[294]\ttraining's binary_logloss: 0.583342\n",
      "[295]\ttraining's binary_logloss: 0.583274\n",
      "[296]\ttraining's binary_logloss: 0.58326\n",
      "[297]\ttraining's binary_logloss: 0.583251\n",
      "[298]\ttraining's binary_logloss: 0.583219\n",
      "[299]\ttraining's binary_logloss: 0.583179\n",
      "[300]\ttraining's binary_logloss: 0.583168\n",
      "[301]\ttraining's binary_logloss: 0.583128\n",
      "[302]\ttraining's binary_logloss: 0.583052\n",
      "[303]\ttraining's binary_logloss: 0.582986\n",
      "[304]\ttraining's binary_logloss: 0.582927\n",
      "[305]\ttraining's binary_logloss: 0.582858\n",
      "[306]\ttraining's binary_logloss: 0.582787\n",
      "[307]\ttraining's binary_logloss: 0.582718\n",
      "[308]\ttraining's binary_logloss: 0.582665\n",
      "[309]\ttraining's binary_logloss: 0.582607\n",
      "[310]\ttraining's binary_logloss: 0.582551\n",
      "[311]\ttraining's binary_logloss: 0.582495\n",
      "[312]\ttraining's binary_logloss: 0.58244\n",
      "[313]\ttraining's binary_logloss: 0.582391\n",
      "[314]\ttraining's binary_logloss: 0.582338\n",
      "[315]\ttraining's binary_logloss: 0.582285\n",
      "[316]\ttraining's binary_logloss: 0.582235\n",
      "[317]\ttraining's binary_logloss: 0.582182\n",
      "[318]\ttraining's binary_logloss: 0.582123\n",
      "[319]\ttraining's binary_logloss: 0.582068\n",
      "[320]\ttraining's binary_logloss: 0.582019\n",
      "[321]\ttraining's binary_logloss: 0.581965\n",
      "[322]\ttraining's binary_logloss: 0.581933\n",
      "[323]\ttraining's binary_logloss: 0.581884\n",
      "[324]\ttraining's binary_logloss: 0.581838\n",
      "[325]\ttraining's binary_logloss: 0.5818\n",
      "[326]\ttraining's binary_logloss: 0.581739\n",
      "[327]\ttraining's binary_logloss: 0.581679\n",
      "[328]\ttraining's binary_logloss: 0.58162\n",
      "[329]\ttraining's binary_logloss: 0.581578\n",
      "[330]\ttraining's binary_logloss: 0.581515\n",
      "[331]\ttraining's binary_logloss: 0.581437\n",
      "[332]\ttraining's binary_logloss: 0.581364\n",
      "[333]\ttraining's binary_logloss: 0.581296\n",
      "[334]\ttraining's binary_logloss: 0.581208\n",
      "[335]\ttraining's binary_logloss: 0.581136\n",
      "[336]\ttraining's binary_logloss: 0.581085\n",
      "[337]\ttraining's binary_logloss: 0.581032\n",
      "[338]\ttraining's binary_logloss: 0.580981\n",
      "[339]\ttraining's binary_logloss: 0.580942\n",
      "[340]\ttraining's binary_logloss: 0.580894\n",
      "[341]\ttraining's binary_logloss: 0.580863\n",
      "[342]\ttraining's binary_logloss: 0.580828\n",
      "[343]\ttraining's binary_logloss: 0.580798\n",
      "[344]\ttraining's binary_logloss: 0.580774\n",
      "[345]\ttraining's binary_logloss: 0.580736\n",
      "[346]\ttraining's binary_logloss: 0.58067\n",
      "[347]\ttraining's binary_logloss: 0.580627\n",
      "[348]\ttraining's binary_logloss: 0.580588\n",
      "[349]\ttraining's binary_logloss: 0.580549\n",
      "[350]\ttraining's binary_logloss: 0.580504\n",
      "[351]\ttraining's binary_logloss: 0.580433\n",
      "[352]\ttraining's binary_logloss: 0.580354\n",
      "[353]\ttraining's binary_logloss: 0.58028\n",
      "[354]\ttraining's binary_logloss: 0.580196\n",
      "[355]\ttraining's binary_logloss: 0.580115\n",
      "[356]\ttraining's binary_logloss: 0.58001\n",
      "[357]\ttraining's binary_logloss: 0.579915\n",
      "[358]\ttraining's binary_logloss: 0.579822\n",
      "[359]\ttraining's binary_logloss: 0.579718\n",
      "[360]\ttraining's binary_logloss: 0.579617\n",
      "[361]\ttraining's binary_logloss: 0.579495\n",
      "[362]\ttraining's binary_logloss: 0.579373\n",
      "[363]\ttraining's binary_logloss: 0.579264\n",
      "[364]\ttraining's binary_logloss: 0.579148\n",
      "[365]\ttraining's binary_logloss: 0.579073\n",
      "[366]\ttraining's binary_logloss: 0.578991\n",
      "[367]\ttraining's binary_logloss: 0.578928\n",
      "[368]\ttraining's binary_logloss: 0.578856\n",
      "[369]\ttraining's binary_logloss: 0.578784\n",
      "[370]\ttraining's binary_logloss: 0.578709\n",
      "[371]\ttraining's binary_logloss: 0.578678\n",
      "[372]\ttraining's binary_logloss: 0.578642\n",
      "[373]\ttraining's binary_logloss: 0.578609\n",
      "[374]\ttraining's binary_logloss: 0.578577\n",
      "[375]\ttraining's binary_logloss: 0.578547\n",
      "[376]\ttraining's binary_logloss: 0.578466\n",
      "[377]\ttraining's binary_logloss: 0.578388\n",
      "[378]\ttraining's binary_logloss: 0.578312\n",
      "[379]\ttraining's binary_logloss: 0.578242\n",
      "[380]\ttraining's binary_logloss: 0.578166\n",
      "[381]\ttraining's binary_logloss: 0.578104\n",
      "[382]\ttraining's binary_logloss: 0.578063\n",
      "[383]\ttraining's binary_logloss: 0.578005\n",
      "[384]\ttraining's binary_logloss: 0.57795\n",
      "[385]\ttraining's binary_logloss: 0.577912\n",
      "[386]\ttraining's binary_logloss: 0.577813\n",
      "[387]\ttraining's binary_logloss: 0.577717\n",
      "[388]\ttraining's binary_logloss: 0.577623\n",
      "[389]\ttraining's binary_logloss: 0.57753\n",
      "[390]\ttraining's binary_logloss: 0.577438\n",
      "[391]\ttraining's binary_logloss: 0.57736\n",
      "[392]\ttraining's binary_logloss: 0.577275\n",
      "[393]\ttraining's binary_logloss: 0.577199\n",
      "[394]\ttraining's binary_logloss: 0.577132\n",
      "[395]\ttraining's binary_logloss: 0.57704\n",
      "[396]\ttraining's binary_logloss: 0.576969\n",
      "[397]\ttraining's binary_logloss: 0.576906\n",
      "[398]\ttraining's binary_logloss: 0.576833\n",
      "[399]\ttraining's binary_logloss: 0.576766\n",
      "[400]\ttraining's binary_logloss: 0.576705\n",
      "[401]\ttraining's binary_logloss: 0.576627\n",
      "[402]\ttraining's binary_logloss: 0.576539\n",
      "[403]\ttraining's binary_logloss: 0.576453\n",
      "[404]\ttraining's binary_logloss: 0.576369\n",
      "[405]\ttraining's binary_logloss: 0.576297\n",
      "[406]\ttraining's binary_logloss: 0.576227\n",
      "[407]\ttraining's binary_logloss: 0.576149\n",
      "[408]\ttraining's binary_logloss: 0.576083\n",
      "[409]\ttraining's binary_logloss: 0.576019\n",
      "[410]\ttraining's binary_logloss: 0.575944\n",
      "[411]\ttraining's binary_logloss: 0.575827\n",
      "[412]\ttraining's binary_logloss: 0.575713\n",
      "[413]\ttraining's binary_logloss: 0.575602\n",
      "[414]\ttraining's binary_logloss: 0.575494\n",
      "[415]\ttraining's binary_logloss: 0.575379\n",
      "[416]\ttraining's binary_logloss: 0.575291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[417]\ttraining's binary_logloss: 0.57523\n",
      "[418]\ttraining's binary_logloss: 0.575151\n",
      "[419]\ttraining's binary_logloss: 0.575094\n",
      "[420]\ttraining's binary_logloss: 0.575015\n",
      "[421]\ttraining's binary_logloss: 0.574967\n",
      "[422]\ttraining's binary_logloss: 0.574932\n",
      "[423]\ttraining's binary_logloss: 0.574886\n",
      "[424]\ttraining's binary_logloss: 0.574838\n",
      "[425]\ttraining's binary_logloss: 0.574802\n",
      "[426]\ttraining's binary_logloss: 0.574743\n",
      "[427]\ttraining's binary_logloss: 0.574695\n",
      "[428]\ttraining's binary_logloss: 0.574617\n",
      "[429]\ttraining's binary_logloss: 0.574551\n",
      "[430]\ttraining's binary_logloss: 0.574496\n",
      "[431]\ttraining's binary_logloss: 0.574412\n",
      "[432]\ttraining's binary_logloss: 0.574331\n",
      "[433]\ttraining's binary_logloss: 0.574242\n",
      "[434]\ttraining's binary_logloss: 0.574133\n",
      "[435]\ttraining's binary_logloss: 0.574038\n",
      "[436]\ttraining's binary_logloss: 0.573942\n",
      "[437]\ttraining's binary_logloss: 0.573871\n",
      "[438]\ttraining's binary_logloss: 0.573789\n",
      "[439]\ttraining's binary_logloss: 0.573697\n",
      "[440]\ttraining's binary_logloss: 0.573618\n",
      "[441]\ttraining's binary_logloss: 0.573565\n",
      "[442]\ttraining's binary_logloss: 0.573514\n",
      "[443]\ttraining's binary_logloss: 0.573465\n",
      "[444]\ttraining's binary_logloss: 0.573399\n",
      "[445]\ttraining's binary_logloss: 0.573351\n",
      "[446]\ttraining's binary_logloss: 0.573276\n",
      "[447]\ttraining's binary_logloss: 0.573201\n",
      "[448]\ttraining's binary_logloss: 0.573126\n",
      "[449]\ttraining's binary_logloss: 0.573036\n",
      "[450]\ttraining's binary_logloss: 0.572968\n",
      "[451]\ttraining's binary_logloss: 0.572894\n",
      "[452]\ttraining's binary_logloss: 0.57281\n",
      "[453]\ttraining's binary_logloss: 0.572742\n",
      "[454]\ttraining's binary_logloss: 0.572664\n",
      "[455]\ttraining's binary_logloss: 0.5726\n",
      "[456]\ttraining's binary_logloss: 0.572526\n",
      "[457]\ttraining's binary_logloss: 0.572454\n",
      "[458]\ttraining's binary_logloss: 0.572384\n",
      "[459]\ttraining's binary_logloss: 0.572336\n",
      "[460]\ttraining's binary_logloss: 0.572276\n",
      "[461]\ttraining's binary_logloss: 0.572175\n",
      "[462]\ttraining's binary_logloss: 0.572095\n",
      "[463]\ttraining's binary_logloss: 0.572\n",
      "[464]\ttraining's binary_logloss: 0.571912\n",
      "[465]\ttraining's binary_logloss: 0.571814\n",
      "[466]\ttraining's binary_logloss: 0.571722\n",
      "[467]\ttraining's binary_logloss: 0.571659\n",
      "[468]\ttraining's binary_logloss: 0.571571\n",
      "[469]\ttraining's binary_logloss: 0.571509\n",
      "[470]\ttraining's binary_logloss: 0.571424\n",
      "[471]\ttraining's binary_logloss: 0.57135\n",
      "[472]\ttraining's binary_logloss: 0.571286\n",
      "[473]\ttraining's binary_logloss: 0.571213\n",
      "[474]\ttraining's binary_logloss: 0.571145\n",
      "[475]\ttraining's binary_logloss: 0.571077\n",
      "[476]\ttraining's binary_logloss: 0.571021\n",
      "[477]\ttraining's binary_logloss: 0.570963\n",
      "[478]\ttraining's binary_logloss: 0.570908\n",
      "[479]\ttraining's binary_logloss: 0.570849\n",
      "[480]\ttraining's binary_logloss: 0.570796\n",
      "[481]\ttraining's binary_logloss: 0.570693\n",
      "[482]\ttraining's binary_logloss: 0.570628\n",
      "[483]\ttraining's binary_logloss: 0.570557\n",
      "[484]\ttraining's binary_logloss: 0.570464\n",
      "[485]\ttraining's binary_logloss: 0.57037\n",
      "[486]\ttraining's binary_logloss: 0.570297\n",
      "[487]\ttraining's binary_logloss: 0.570207\n",
      "[488]\ttraining's binary_logloss: 0.570117\n",
      "[489]\ttraining's binary_logloss: 0.57003\n",
      "[490]\ttraining's binary_logloss: 0.569962\n",
      "[491]\ttraining's binary_logloss: 0.569899\n",
      "[492]\ttraining's binary_logloss: 0.569824\n",
      "[493]\ttraining's binary_logloss: 0.569763\n",
      "[494]\ttraining's binary_logloss: 0.569693\n",
      "[495]\ttraining's binary_logloss: 0.569632\n",
      "[496]\ttraining's binary_logloss: 0.56953\n",
      "[497]\ttraining's binary_logloss: 0.569446\n",
      "[498]\ttraining's binary_logloss: 0.569348\n",
      "[499]\ttraining's binary_logloss: 0.569231\n",
      "[500]\ttraining's binary_logloss: 0.569127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613304\n",
      "[2]\ttraining's binary_logloss: 0.612269\n",
      "[3]\ttraining's binary_logloss: 0.611291\n",
      "[4]\ttraining's binary_logloss: 0.610235\n",
      "[5]\ttraining's binary_logloss: 0.609346\n",
      "[6]\ttraining's binary_logloss: 0.608593\n",
      "[7]\ttraining's binary_logloss: 0.607767\n",
      "[8]\ttraining's binary_logloss: 0.607033\n",
      "[9]\ttraining's binary_logloss: 0.606275\n",
      "[10]\ttraining's binary_logloss: 0.605544\n",
      "[11]\ttraining's binary_logloss: 0.604855\n",
      "[12]\ttraining's binary_logloss: 0.604222\n",
      "[13]\ttraining's binary_logloss: 0.603417\n",
      "[14]\ttraining's binary_logloss: 0.602632\n",
      "[15]\ttraining's binary_logloss: 0.601892\n",
      "[16]\ttraining's binary_logloss: 0.601171\n",
      "[17]\ttraining's binary_logloss: 0.60048\n",
      "[18]\ttraining's binary_logloss: 0.599818\n",
      "[19]\ttraining's binary_logloss: 0.599268\n",
      "[20]\ttraining's binary_logloss: 0.59876\n",
      "[21]\ttraining's binary_logloss: 0.598148\n",
      "[22]\ttraining's binary_logloss: 0.597597\n",
      "[23]\ttraining's binary_logloss: 0.597086\n",
      "[24]\ttraining's binary_logloss: 0.596524\n",
      "[25]\ttraining's binary_logloss: 0.596158\n",
      "[26]\ttraining's binary_logloss: 0.595708\n",
      "[27]\ttraining's binary_logloss: 0.595332\n",
      "[28]\ttraining's binary_logloss: 0.594988\n",
      "[29]\ttraining's binary_logloss: 0.594575\n",
      "[30]\ttraining's binary_logloss: 0.594195\n",
      "[31]\ttraining's binary_logloss: 0.593878\n",
      "[32]\ttraining's binary_logloss: 0.593494\n",
      "[33]\ttraining's binary_logloss: 0.59313\n",
      "[34]\ttraining's binary_logloss: 0.592755\n",
      "[35]\ttraining's binary_logloss: 0.592339\n",
      "[36]\ttraining's binary_logloss: 0.592048\n",
      "[37]\ttraining's binary_logloss: 0.591779\n",
      "[38]\ttraining's binary_logloss: 0.591478\n",
      "[39]\ttraining's binary_logloss: 0.591315\n",
      "[40]\ttraining's binary_logloss: 0.591022\n",
      "[41]\ttraining's binary_logloss: 0.590833\n",
      "[42]\ttraining's binary_logloss: 0.590626\n",
      "[43]\ttraining's binary_logloss: 0.590413\n",
      "[44]\ttraining's binary_logloss: 0.59023\n",
      "[45]\ttraining's binary_logloss: 0.590023\n",
      "[46]\ttraining's binary_logloss: 0.589825\n",
      "[47]\ttraining's binary_logloss: 0.589627\n",
      "[48]\ttraining's binary_logloss: 0.589443\n",
      "[49]\ttraining's binary_logloss: 0.589242\n",
      "[50]\ttraining's binary_logloss: 0.589007\n",
      "[51]\ttraining's binary_logloss: 0.5889\n",
      "[52]\ttraining's binary_logloss: 0.588797\n",
      "[53]\ttraining's binary_logloss: 0.58871\n",
      "[54]\ttraining's binary_logloss: 0.588627\n",
      "[55]\ttraining's binary_logloss: 0.588559\n",
      "[56]\ttraining's binary_logloss: 0.588324\n",
      "[57]\ttraining's binary_logloss: 0.588103\n",
      "[58]\ttraining's binary_logloss: 0.587892\n",
      "[59]\ttraining's binary_logloss: 0.587801\n",
      "[60]\ttraining's binary_logloss: 0.587606\n",
      "[61]\ttraining's binary_logloss: 0.587527\n",
      "[62]\ttraining's binary_logloss: 0.587395\n",
      "[63]\ttraining's binary_logloss: 0.587343\n",
      "[64]\ttraining's binary_logloss: 0.587281\n",
      "[65]\ttraining's binary_logloss: 0.587226\n",
      "[66]\ttraining's binary_logloss: 0.58713\n",
      "[67]\ttraining's binary_logloss: 0.587044\n",
      "[68]\ttraining's binary_logloss: 0.586962\n",
      "[69]\ttraining's binary_logloss: 0.586892\n",
      "[70]\ttraining's binary_logloss: 0.586824\n",
      "[71]\ttraining's binary_logloss: 0.586751\n",
      "[72]\ttraining's binary_logloss: 0.586685\n",
      "[73]\ttraining's binary_logloss: 0.586616\n",
      "[74]\ttraining's binary_logloss: 0.586564\n",
      "[75]\ttraining's binary_logloss: 0.586509\n",
      "[76]\ttraining's binary_logloss: 0.586432\n",
      "[77]\ttraining's binary_logloss: 0.586397\n",
      "[78]\ttraining's binary_logloss: 0.586299\n",
      "[79]\ttraining's binary_logloss: 0.586238\n",
      "[80]\ttraining's binary_logloss: 0.586192\n",
      "[81]\ttraining's binary_logloss: 0.586121\n",
      "[82]\ttraining's binary_logloss: 0.586057\n",
      "[83]\ttraining's binary_logloss: 0.585993\n",
      "[84]\ttraining's binary_logloss: 0.585958\n",
      "[85]\ttraining's binary_logloss: 0.585906\n",
      "[86]\ttraining's binary_logloss: 0.585869\n",
      "[87]\ttraining's binary_logloss: 0.585856\n",
      "[88]\ttraining's binary_logloss: 0.585851\n",
      "[89]\ttraining's binary_logloss: 0.585816\n",
      "[90]\ttraining's binary_logloss: 0.58582\n",
      "[91]\ttraining's binary_logloss: 0.585767\n",
      "[92]\ttraining's binary_logloss: 0.585721\n",
      "[93]\ttraining's binary_logloss: 0.585681\n",
      "[94]\ttraining's binary_logloss: 0.585643\n",
      "[95]\ttraining's binary_logloss: 0.585629\n",
      "[96]\ttraining's binary_logloss: 0.585665\n",
      "[97]\ttraining's binary_logloss: 0.585705\n",
      "[98]\ttraining's binary_logloss: 0.585673\n",
      "[99]\ttraining's binary_logloss: 0.585719\n",
      "[100]\ttraining's binary_logloss: 0.585774\n",
      "[101]\ttraining's binary_logloss: 0.585805\n",
      "[102]\ttraining's binary_logloss: 0.585864\n",
      "[103]\ttraining's binary_logloss: 0.58593\n",
      "[104]\ttraining's binary_logloss: 0.585931\n",
      "[105]\ttraining's binary_logloss: 0.586006\n",
      "[106]\ttraining's binary_logloss: 0.586051\n",
      "[107]\ttraining's binary_logloss: 0.586105\n",
      "[108]\ttraining's binary_logloss: 0.586088\n",
      "[109]\ttraining's binary_logloss: 0.586142\n",
      "[110]\ttraining's binary_logloss: 0.586202\n",
      "[111]\ttraining's binary_logloss: 0.586212\n",
      "[112]\ttraining's binary_logloss: 0.586243\n",
      "[113]\ttraining's binary_logloss: 0.58626\n",
      "[114]\ttraining's binary_logloss: 0.58628\n",
      "[115]\ttraining's binary_logloss: 0.586301\n",
      "[116]\ttraining's binary_logloss: 0.586323\n",
      "[117]\ttraining's binary_logloss: 0.586301\n",
      "[118]\ttraining's binary_logloss: 0.586318\n",
      "[119]\ttraining's binary_logloss: 0.586336\n",
      "[120]\ttraining's binary_logloss: 0.586321\n",
      "[121]\ttraining's binary_logloss: 0.586313\n",
      "[122]\ttraining's binary_logloss: 0.586309\n",
      "[123]\ttraining's binary_logloss: 0.586309\n",
      "[124]\ttraining's binary_logloss: 0.586311\n",
      "[125]\ttraining's binary_logloss: 0.586318\n",
      "[126]\ttraining's binary_logloss: 0.586298\n",
      "[127]\ttraining's binary_logloss: 0.586304\n",
      "[128]\ttraining's binary_logloss: 0.586292\n",
      "[129]\ttraining's binary_logloss: 0.586285\n",
      "[130]\ttraining's binary_logloss: 0.586272\n",
      "[131]\ttraining's binary_logloss: 0.586313\n",
      "[132]\ttraining's binary_logloss: 0.586333\n",
      "[133]\ttraining's binary_logloss: 0.586379\n",
      "[134]\ttraining's binary_logloss: 0.586418\n",
      "[135]\ttraining's binary_logloss: 0.586492\n",
      "[136]\ttraining's binary_logloss: 0.586533\n",
      "[137]\ttraining's binary_logloss: 0.586573\n",
      "[138]\ttraining's binary_logloss: 0.586619\n",
      "[139]\ttraining's binary_logloss: 0.586645\n",
      "[140]\ttraining's binary_logloss: 0.586689\n",
      "[141]\ttraining's binary_logloss: 0.586719\n",
      "[142]\ttraining's binary_logloss: 0.586751\n",
      "[143]\ttraining's binary_logloss: 0.586797\n",
      "[144]\ttraining's binary_logloss: 0.586833\n",
      "[145]\ttraining's binary_logloss: 0.58688\n",
      "[146]\ttraining's binary_logloss: 0.586857\n",
      "[147]\ttraining's binary_logloss: 0.586858\n",
      "[148]\ttraining's binary_logloss: 0.586852\n",
      "[149]\ttraining's binary_logloss: 0.586867\n",
      "[150]\ttraining's binary_logloss: 0.586881\n",
      "[151]\ttraining's binary_logloss: 0.586905\n",
      "[152]\ttraining's binary_logloss: 0.586932\n",
      "[153]\ttraining's binary_logloss: 0.586963\n",
      "[154]\ttraining's binary_logloss: 0.586996\n",
      "[155]\ttraining's binary_logloss: 0.58703\n",
      "[156]\ttraining's binary_logloss: 0.58709\n",
      "[157]\ttraining's binary_logloss: 0.587135\n",
      "[158]\ttraining's binary_logloss: 0.587196\n",
      "[159]\ttraining's binary_logloss: 0.587237\n",
      "[160]\ttraining's binary_logloss: 0.58731\n",
      "[161]\ttraining's binary_logloss: 0.587329\n",
      "[162]\ttraining's binary_logloss: 0.587299\n",
      "[163]\ttraining's binary_logloss: 0.587268\n",
      "[164]\ttraining's binary_logloss: 0.587274\n",
      "[165]\ttraining's binary_logloss: 0.587272\n",
      "[166]\ttraining's binary_logloss: 0.587278\n",
      "[167]\ttraining's binary_logloss: 0.587297\n",
      "[168]\ttraining's binary_logloss: 0.587317\n",
      "[169]\ttraining's binary_logloss: 0.587309\n",
      "[170]\ttraining's binary_logloss: 0.587331\n",
      "[171]\ttraining's binary_logloss: 0.587362\n",
      "[172]\ttraining's binary_logloss: 0.58739\n",
      "[173]\ttraining's binary_logloss: 0.587422\n",
      "[174]\ttraining's binary_logloss: 0.587457\n",
      "[175]\ttraining's binary_logloss: 0.587492\n",
      "[176]\ttraining's binary_logloss: 0.587536\n",
      "[177]\ttraining's binary_logloss: 0.58754\n",
      "[178]\ttraining's binary_logloss: 0.587567\n",
      "[179]\ttraining's binary_logloss: 0.587572\n",
      "[180]\ttraining's binary_logloss: 0.587605\n",
      "[181]\ttraining's binary_logloss: 0.587638\n",
      "[182]\ttraining's binary_logloss: 0.587684\n",
      "[183]\ttraining's binary_logloss: 0.587701\n",
      "[184]\ttraining's binary_logloss: 0.587749\n",
      "[185]\ttraining's binary_logloss: 0.587768\n",
      "[186]\ttraining's binary_logloss: 0.587775\n",
      "[187]\ttraining's binary_logloss: 0.587765\n",
      "[188]\ttraining's binary_logloss: 0.587772\n",
      "[189]\ttraining's binary_logloss: 0.587765\n",
      "[190]\ttraining's binary_logloss: 0.587768\n",
      "[191]\ttraining's binary_logloss: 0.587793\n",
      "[192]\ttraining's binary_logloss: 0.587801\n",
      "[193]\ttraining's binary_logloss: 0.587835\n",
      "[194]\ttraining's binary_logloss: 0.587839\n",
      "[195]\ttraining's binary_logloss: 0.587852\n",
      "[196]\ttraining's binary_logloss: 0.587882\n",
      "[197]\ttraining's binary_logloss: 0.587906\n",
      "[198]\ttraining's binary_logloss: 0.587928\n",
      "[199]\ttraining's binary_logloss: 0.587952\n",
      "[200]\ttraining's binary_logloss: 0.587975\n",
      "[201]\ttraining's binary_logloss: 0.587973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[202]\ttraining's binary_logloss: 0.587974\n",
      "[203]\ttraining's binary_logloss: 0.587962\n",
      "[204]\ttraining's binary_logloss: 0.587965\n",
      "[205]\ttraining's binary_logloss: 0.58799\n",
      "[206]\ttraining's binary_logloss: 0.588025\n",
      "[207]\ttraining's binary_logloss: 0.588043\n",
      "[208]\ttraining's binary_logloss: 0.588079\n",
      "[209]\ttraining's binary_logloss: 0.588098\n",
      "[210]\ttraining's binary_logloss: 0.588119\n",
      "[211]\ttraining's binary_logloss: 0.588141\n",
      "[212]\ttraining's binary_logloss: 0.588164\n",
      "[213]\ttraining's binary_logloss: 0.588185\n",
      "[214]\ttraining's binary_logloss: 0.588221\n",
      "[215]\ttraining's binary_logloss: 0.588255\n",
      "[216]\ttraining's binary_logloss: 0.588216\n",
      "[217]\ttraining's binary_logloss: 0.588177\n",
      "[218]\ttraining's binary_logloss: 0.588143\n",
      "[219]\ttraining's binary_logloss: 0.588108\n",
      "[220]\ttraining's binary_logloss: 0.588075\n",
      "[221]\ttraining's binary_logloss: 0.588037\n",
      "[222]\ttraining's binary_logloss: 0.588002\n",
      "[223]\ttraining's binary_logloss: 0.587955\n",
      "[224]\ttraining's binary_logloss: 0.587915\n",
      "[225]\ttraining's binary_logloss: 0.587872\n",
      "[226]\ttraining's binary_logloss: 0.587871\n",
      "[227]\ttraining's binary_logloss: 0.587861\n",
      "[228]\ttraining's binary_logloss: 0.587838\n",
      "[229]\ttraining's binary_logloss: 0.587823\n",
      "[230]\ttraining's binary_logloss: 0.587823\n",
      "[231]\ttraining's binary_logloss: 0.587827\n",
      "[232]\ttraining's binary_logloss: 0.587833\n",
      "[233]\ttraining's binary_logloss: 0.587847\n",
      "[234]\ttraining's binary_logloss: 0.587855\n",
      "[235]\ttraining's binary_logloss: 0.587861\n",
      "[236]\ttraining's binary_logloss: 0.587848\n",
      "[237]\ttraining's binary_logloss: 0.587827\n",
      "[238]\ttraining's binary_logloss: 0.587811\n",
      "[239]\ttraining's binary_logloss: 0.587796\n",
      "[240]\ttraining's binary_logloss: 0.587778\n",
      "[241]\ttraining's binary_logloss: 0.58772\n",
      "[242]\ttraining's binary_logloss: 0.587703\n",
      "[243]\ttraining's binary_logloss: 0.58764\n",
      "[244]\ttraining's binary_logloss: 0.58758\n",
      "[245]\ttraining's binary_logloss: 0.587534\n",
      "[246]\ttraining's binary_logloss: 0.587453\n",
      "[247]\ttraining's binary_logloss: 0.587369\n",
      "[248]\ttraining's binary_logloss: 0.587296\n",
      "[249]\ttraining's binary_logloss: 0.587225\n",
      "[250]\ttraining's binary_logloss: 0.587153\n",
      "[251]\ttraining's binary_logloss: 0.587147\n",
      "[252]\ttraining's binary_logloss: 0.587143\n",
      "[253]\ttraining's binary_logloss: 0.587135\n",
      "[254]\ttraining's binary_logloss: 0.587125\n",
      "[255]\ttraining's binary_logloss: 0.58712\n",
      "[256]\ttraining's binary_logloss: 0.587072\n",
      "[257]\ttraining's binary_logloss: 0.587034\n",
      "[258]\ttraining's binary_logloss: 0.586986\n",
      "[259]\ttraining's binary_logloss: 0.58693\n",
      "[260]\ttraining's binary_logloss: 0.586887\n",
      "[261]\ttraining's binary_logloss: 0.586866\n",
      "[262]\ttraining's binary_logloss: 0.586843\n",
      "[263]\ttraining's binary_logloss: 0.586816\n",
      "[264]\ttraining's binary_logloss: 0.586793\n",
      "[265]\ttraining's binary_logloss: 0.586765\n",
      "[266]\ttraining's binary_logloss: 0.586748\n",
      "[267]\ttraining's binary_logloss: 0.586755\n",
      "[268]\ttraining's binary_logloss: 0.586762\n",
      "[269]\ttraining's binary_logloss: 0.586777\n",
      "[270]\ttraining's binary_logloss: 0.586769\n",
      "[271]\ttraining's binary_logloss: 0.586701\n",
      "[272]\ttraining's binary_logloss: 0.586615\n",
      "[273]\ttraining's binary_logloss: 0.586536\n",
      "[274]\ttraining's binary_logloss: 0.586461\n",
      "[275]\ttraining's binary_logloss: 0.586407\n",
      "[276]\ttraining's binary_logloss: 0.586391\n",
      "[277]\ttraining's binary_logloss: 0.586353\n",
      "[278]\ttraining's binary_logloss: 0.586345\n",
      "[279]\ttraining's binary_logloss: 0.586314\n",
      "[280]\ttraining's binary_logloss: 0.586295\n",
      "[281]\ttraining's binary_logloss: 0.586237\n",
      "[282]\ttraining's binary_logloss: 0.586181\n",
      "[283]\ttraining's binary_logloss: 0.586124\n",
      "[284]\ttraining's binary_logloss: 0.586063\n",
      "[285]\ttraining's binary_logloss: 0.586009\n",
      "[286]\ttraining's binary_logloss: 0.585943\n",
      "[287]\ttraining's binary_logloss: 0.585875\n",
      "[288]\ttraining's binary_logloss: 0.585788\n",
      "[289]\ttraining's binary_logloss: 0.585696\n",
      "[290]\ttraining's binary_logloss: 0.585627\n",
      "[291]\ttraining's binary_logloss: 0.585546\n",
      "[292]\ttraining's binary_logloss: 0.585461\n",
      "[293]\ttraining's binary_logloss: 0.585378\n",
      "[294]\ttraining's binary_logloss: 0.585306\n",
      "[295]\ttraining's binary_logloss: 0.585227\n",
      "[296]\ttraining's binary_logloss: 0.585164\n",
      "[297]\ttraining's binary_logloss: 0.585108\n",
      "[298]\ttraining's binary_logloss: 0.585046\n",
      "[299]\ttraining's binary_logloss: 0.584985\n",
      "[300]\ttraining's binary_logloss: 0.584928\n",
      "[301]\ttraining's binary_logloss: 0.584887\n",
      "[302]\ttraining's binary_logloss: 0.584849\n",
      "[303]\ttraining's binary_logloss: 0.584817\n",
      "[304]\ttraining's binary_logloss: 0.584777\n",
      "[305]\ttraining's binary_logloss: 0.584746\n",
      "[306]\ttraining's binary_logloss: 0.58471\n",
      "[307]\ttraining's binary_logloss: 0.584648\n",
      "[308]\ttraining's binary_logloss: 0.584584\n",
      "[309]\ttraining's binary_logloss: 0.584522\n",
      "[310]\ttraining's binary_logloss: 0.584486\n",
      "[311]\ttraining's binary_logloss: 0.584433\n",
      "[312]\ttraining's binary_logloss: 0.584383\n",
      "[313]\ttraining's binary_logloss: 0.58432\n",
      "[314]\ttraining's binary_logloss: 0.584276\n",
      "[315]\ttraining's binary_logloss: 0.584217\n",
      "[316]\ttraining's binary_logloss: 0.584157\n",
      "[317]\ttraining's binary_logloss: 0.584084\n",
      "[318]\ttraining's binary_logloss: 0.584014\n",
      "[319]\ttraining's binary_logloss: 0.583954\n",
      "[320]\ttraining's binary_logloss: 0.583893\n",
      "[321]\ttraining's binary_logloss: 0.583865\n",
      "[322]\ttraining's binary_logloss: 0.583829\n",
      "[323]\ttraining's binary_logloss: 0.583797\n",
      "[324]\ttraining's binary_logloss: 0.583773\n",
      "[325]\ttraining's binary_logloss: 0.583754\n",
      "[326]\ttraining's binary_logloss: 0.583697\n",
      "[327]\ttraining's binary_logloss: 0.583638\n",
      "[328]\ttraining's binary_logloss: 0.58358\n",
      "[329]\ttraining's binary_logloss: 0.583524\n",
      "[330]\ttraining's binary_logloss: 0.583468\n",
      "[331]\ttraining's binary_logloss: 0.583409\n",
      "[332]\ttraining's binary_logloss: 0.583345\n",
      "[333]\ttraining's binary_logloss: 0.583291\n",
      "[334]\ttraining's binary_logloss: 0.583237\n",
      "[335]\ttraining's binary_logloss: 0.583184\n",
      "[336]\ttraining's binary_logloss: 0.583095\n",
      "[337]\ttraining's binary_logloss: 0.583004\n",
      "[338]\ttraining's binary_logloss: 0.582916\n",
      "[339]\ttraining's binary_logloss: 0.582849\n",
      "[340]\ttraining's binary_logloss: 0.582778\n",
      "[341]\ttraining's binary_logloss: 0.582754\n",
      "[342]\ttraining's binary_logloss: 0.58273\n",
      "[343]\ttraining's binary_logloss: 0.582707\n",
      "[344]\ttraining's binary_logloss: 0.58269\n",
      "[345]\ttraining's binary_logloss: 0.582671\n",
      "[346]\ttraining's binary_logloss: 0.582648\n",
      "[347]\ttraining's binary_logloss: 0.582637\n",
      "[348]\ttraining's binary_logloss: 0.582582\n",
      "[349]\ttraining's binary_logloss: 0.582521\n",
      "[350]\ttraining's binary_logloss: 0.582463\n",
      "[351]\ttraining's binary_logloss: 0.582376\n",
      "[352]\ttraining's binary_logloss: 0.582288\n",
      "[353]\ttraining's binary_logloss: 0.582206\n",
      "[354]\ttraining's binary_logloss: 0.582113\n",
      "[355]\ttraining's binary_logloss: 0.582025\n",
      "[356]\ttraining's binary_logloss: 0.581934\n",
      "[357]\ttraining's binary_logloss: 0.581857\n",
      "[358]\ttraining's binary_logloss: 0.581782\n",
      "[359]\ttraining's binary_logloss: 0.581701\n",
      "[360]\ttraining's binary_logloss: 0.581616\n",
      "[361]\ttraining's binary_logloss: 0.581502\n",
      "[362]\ttraining's binary_logloss: 0.581385\n",
      "[363]\ttraining's binary_logloss: 0.581308\n",
      "[364]\ttraining's binary_logloss: 0.58119\n",
      "[365]\ttraining's binary_logloss: 0.581074\n",
      "[366]\ttraining's binary_logloss: 0.581017\n",
      "[367]\ttraining's binary_logloss: 0.580977\n",
      "[368]\ttraining's binary_logloss: 0.580908\n",
      "[369]\ttraining's binary_logloss: 0.580857\n",
      "[370]\ttraining's binary_logloss: 0.580798\n",
      "[371]\ttraining's binary_logloss: 0.58076\n",
      "[372]\ttraining's binary_logloss: 0.580722\n",
      "[373]\ttraining's binary_logloss: 0.580679\n",
      "[374]\ttraining's binary_logloss: 0.58064\n",
      "[375]\ttraining's binary_logloss: 0.580603\n",
      "[376]\ttraining's binary_logloss: 0.580522\n",
      "[377]\ttraining's binary_logloss: 0.580459\n",
      "[378]\ttraining's binary_logloss: 0.580397\n",
      "[379]\ttraining's binary_logloss: 0.580337\n",
      "[380]\ttraining's binary_logloss: 0.580268\n",
      "[381]\ttraining's binary_logloss: 0.580247\n",
      "[382]\ttraining's binary_logloss: 0.580228\n",
      "[383]\ttraining's binary_logloss: 0.580196\n",
      "[384]\ttraining's binary_logloss: 0.580165\n",
      "[385]\ttraining's binary_logloss: 0.580141\n",
      "[386]\ttraining's binary_logloss: 0.580057\n",
      "[387]\ttraining's binary_logloss: 0.579977\n",
      "[388]\ttraining's binary_logloss: 0.579884\n",
      "[389]\ttraining's binary_logloss: 0.579805\n",
      "[390]\ttraining's binary_logloss: 0.579727\n",
      "[391]\ttraining's binary_logloss: 0.579634\n",
      "[392]\ttraining's binary_logloss: 0.579535\n",
      "[393]\ttraining's binary_logloss: 0.579451\n",
      "[394]\ttraining's binary_logloss: 0.579362\n",
      "[395]\ttraining's binary_logloss: 0.579272\n",
      "[396]\ttraining's binary_logloss: 0.579224\n",
      "[397]\ttraining's binary_logloss: 0.579185\n",
      "[398]\ttraining's binary_logloss: 0.579148\n",
      "[399]\ttraining's binary_logloss: 0.579113\n",
      "[400]\ttraining's binary_logloss: 0.579075\n",
      "[401]\ttraining's binary_logloss: 0.578994\n",
      "[402]\ttraining's binary_logloss: 0.578894\n",
      "[403]\ttraining's binary_logloss: 0.578802\n",
      "[404]\ttraining's binary_logloss: 0.578718\n",
      "[405]\ttraining's binary_logloss: 0.578641\n",
      "[406]\ttraining's binary_logloss: 0.578558\n",
      "[407]\ttraining's binary_logloss: 0.578485\n",
      "[408]\ttraining's binary_logloss: 0.578396\n",
      "[409]\ttraining's binary_logloss: 0.578329\n",
      "[410]\ttraining's binary_logloss: 0.578259\n",
      "[411]\ttraining's binary_logloss: 0.578177\n",
      "[412]\ttraining's binary_logloss: 0.578102\n",
      "[413]\ttraining's binary_logloss: 0.578002\n",
      "[414]\ttraining's binary_logloss: 0.577918\n",
      "[415]\ttraining's binary_logloss: 0.577851\n",
      "[416]\ttraining's binary_logloss: 0.577785\n",
      "[417]\ttraining's binary_logloss: 0.577737\n",
      "[418]\ttraining's binary_logloss: 0.577675\n",
      "[419]\ttraining's binary_logloss: 0.577615\n",
      "[420]\ttraining's binary_logloss: 0.577564\n",
      "[421]\ttraining's binary_logloss: 0.577517\n",
      "[422]\ttraining's binary_logloss: 0.577477\n",
      "[423]\ttraining's binary_logloss: 0.577439\n",
      "[424]\ttraining's binary_logloss: 0.577404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[425]\ttraining's binary_logloss: 0.577368\n",
      "[426]\ttraining's binary_logloss: 0.577287\n",
      "[427]\ttraining's binary_logloss: 0.577201\n",
      "[428]\ttraining's binary_logloss: 0.577131\n",
      "[429]\ttraining's binary_logloss: 0.577056\n",
      "[430]\ttraining's binary_logloss: 0.576983\n",
      "[431]\ttraining's binary_logloss: 0.576886\n",
      "[432]\ttraining's binary_logloss: 0.576806\n",
      "[433]\ttraining's binary_logloss: 0.576716\n",
      "[434]\ttraining's binary_logloss: 0.576617\n",
      "[435]\ttraining's binary_logloss: 0.576537\n",
      "[436]\ttraining's binary_logloss: 0.576478\n",
      "[437]\ttraining's binary_logloss: 0.576421\n",
      "[438]\ttraining's binary_logloss: 0.576364\n",
      "[439]\ttraining's binary_logloss: 0.576313\n",
      "[440]\ttraining's binary_logloss: 0.576267\n",
      "[441]\ttraining's binary_logloss: 0.576213\n",
      "[442]\ttraining's binary_logloss: 0.576159\n",
      "[443]\ttraining's binary_logloss: 0.576087\n",
      "[444]\ttraining's binary_logloss: 0.576029\n",
      "[445]\ttraining's binary_logloss: 0.575972\n",
      "[446]\ttraining's binary_logloss: 0.575897\n",
      "[447]\ttraining's binary_logloss: 0.575823\n",
      "[448]\ttraining's binary_logloss: 0.575743\n",
      "[449]\ttraining's binary_logloss: 0.575672\n",
      "[450]\ttraining's binary_logloss: 0.5756\n",
      "[451]\ttraining's binary_logloss: 0.57555\n",
      "[452]\ttraining's binary_logloss: 0.575501\n",
      "[453]\ttraining's binary_logloss: 0.575457\n",
      "[454]\ttraining's binary_logloss: 0.575411\n",
      "[455]\ttraining's binary_logloss: 0.575361\n",
      "[456]\ttraining's binary_logloss: 0.575298\n",
      "[457]\ttraining's binary_logloss: 0.575241\n",
      "[458]\ttraining's binary_logloss: 0.575187\n",
      "[459]\ttraining's binary_logloss: 0.575118\n",
      "[460]\ttraining's binary_logloss: 0.575063\n",
      "[461]\ttraining's binary_logloss: 0.575009\n",
      "[462]\ttraining's binary_logloss: 0.574942\n",
      "[463]\ttraining's binary_logloss: 0.5749\n",
      "[464]\ttraining's binary_logloss: 0.574823\n",
      "[465]\ttraining's binary_logloss: 0.574781\n",
      "[466]\ttraining's binary_logloss: 0.574706\n",
      "[467]\ttraining's binary_logloss: 0.574628\n",
      "[468]\ttraining's binary_logloss: 0.574546\n",
      "[469]\ttraining's binary_logloss: 0.574471\n",
      "[470]\ttraining's binary_logloss: 0.574397\n",
      "[471]\ttraining's binary_logloss: 0.574354\n",
      "[472]\ttraining's binary_logloss: 0.574325\n",
      "[473]\ttraining's binary_logloss: 0.574284\n",
      "[474]\ttraining's binary_logloss: 0.574241\n",
      "[475]\ttraining's binary_logloss: 0.5742\n",
      "[476]\ttraining's binary_logloss: 0.574112\n",
      "[477]\ttraining's binary_logloss: 0.574024\n",
      "[478]\ttraining's binary_logloss: 0.573956\n",
      "[479]\ttraining's binary_logloss: 0.573886\n",
      "[480]\ttraining's binary_logloss: 0.5738\n",
      "[481]\ttraining's binary_logloss: 0.573721\n",
      "[482]\ttraining's binary_logloss: 0.573646\n",
      "[483]\ttraining's binary_logloss: 0.573573\n",
      "[484]\ttraining's binary_logloss: 0.573498\n",
      "[485]\ttraining's binary_logloss: 0.573431\n",
      "[486]\ttraining's binary_logloss: 0.573335\n",
      "[487]\ttraining's binary_logloss: 0.573225\n",
      "[488]\ttraining's binary_logloss: 0.573142\n",
      "[489]\ttraining's binary_logloss: 0.573028\n",
      "[490]\ttraining's binary_logloss: 0.572928\n",
      "[491]\ttraining's binary_logloss: 0.572849\n",
      "[492]\ttraining's binary_logloss: 0.572775\n",
      "[493]\ttraining's binary_logloss: 0.572698\n",
      "[494]\ttraining's binary_logloss: 0.572621\n",
      "[495]\ttraining's binary_logloss: 0.572536\n",
      "[496]\ttraining's binary_logloss: 0.572453\n",
      "[497]\ttraining's binary_logloss: 0.572383\n",
      "[498]\ttraining's binary_logloss: 0.572302\n",
      "[499]\ttraining's binary_logloss: 0.572212\n",
      "[500]\ttraining's binary_logloss: 0.572118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.617701\n",
      "[2]\ttraining's binary_logloss: 0.616657\n",
      "[3]\ttraining's binary_logloss: 0.615676\n",
      "[4]\ttraining's binary_logloss: 0.614728\n",
      "[5]\ttraining's binary_logloss: 0.613818\n",
      "[6]\ttraining's binary_logloss: 0.612928\n",
      "[7]\ttraining's binary_logloss: 0.612076\n",
      "[8]\ttraining's binary_logloss: 0.611259\n",
      "[9]\ttraining's binary_logloss: 0.61049\n",
      "[10]\ttraining's binary_logloss: 0.609735\n",
      "[11]\ttraining's binary_logloss: 0.608976\n",
      "[12]\ttraining's binary_logloss: 0.608148\n",
      "[13]\ttraining's binary_logloss: 0.60743\n",
      "[14]\ttraining's binary_logloss: 0.606743\n",
      "[15]\ttraining's binary_logloss: 0.605997\n",
      "[16]\ttraining's binary_logloss: 0.605407\n",
      "[17]\ttraining's binary_logloss: 0.604856\n",
      "[18]\ttraining's binary_logloss: 0.604289\n",
      "[19]\ttraining's binary_logloss: 0.603743\n",
      "[20]\ttraining's binary_logloss: 0.603235\n",
      "[21]\ttraining's binary_logloss: 0.602677\n",
      "[22]\ttraining's binary_logloss: 0.602144\n",
      "[23]\ttraining's binary_logloss: 0.601644\n",
      "[24]\ttraining's binary_logloss: 0.601087\n",
      "[25]\ttraining's binary_logloss: 0.600701\n",
      "[26]\ttraining's binary_logloss: 0.600247\n",
      "[27]\ttraining's binary_logloss: 0.599868\n",
      "[28]\ttraining's binary_logloss: 0.599441\n",
      "[29]\ttraining's binary_logloss: 0.59903\n",
      "[30]\ttraining's binary_logloss: 0.59864\n",
      "[31]\ttraining's binary_logloss: 0.598259\n",
      "[32]\ttraining's binary_logloss: 0.597896\n",
      "[33]\ttraining's binary_logloss: 0.597546\n",
      "[34]\ttraining's binary_logloss: 0.597193\n",
      "[35]\ttraining's binary_logloss: 0.596875\n",
      "[36]\ttraining's binary_logloss: 0.596575\n",
      "[37]\ttraining's binary_logloss: 0.596285\n",
      "[38]\ttraining's binary_logloss: 0.596024\n",
      "[39]\ttraining's binary_logloss: 0.595757\n",
      "[40]\ttraining's binary_logloss: 0.595506\n",
      "[41]\ttraining's binary_logloss: 0.595324\n",
      "[42]\ttraining's binary_logloss: 0.595107\n",
      "[43]\ttraining's binary_logloss: 0.594834\n",
      "[44]\ttraining's binary_logloss: 0.594579\n",
      "[45]\ttraining's binary_logloss: 0.594428\n",
      "[46]\ttraining's binary_logloss: 0.594132\n",
      "[47]\ttraining's binary_logloss: 0.593871\n",
      "[48]\ttraining's binary_logloss: 0.5936\n",
      "[49]\ttraining's binary_logloss: 0.59334\n",
      "[50]\ttraining's binary_logloss: 0.593094\n",
      "[51]\ttraining's binary_logloss: 0.592885\n",
      "[52]\ttraining's binary_logloss: 0.592689\n",
      "[53]\ttraining's binary_logloss: 0.592505\n",
      "[54]\ttraining's binary_logloss: 0.592329\n",
      "[55]\ttraining's binary_logloss: 0.592171\n",
      "[56]\ttraining's binary_logloss: 0.592031\n",
      "[57]\ttraining's binary_logloss: 0.591875\n",
      "[58]\ttraining's binary_logloss: 0.591752\n",
      "[59]\ttraining's binary_logloss: 0.591644\n",
      "[60]\ttraining's binary_logloss: 0.591592\n",
      "[61]\ttraining's binary_logloss: 0.591463\n",
      "[62]\ttraining's binary_logloss: 0.591345\n",
      "[63]\ttraining's binary_logloss: 0.591235\n",
      "[64]\ttraining's binary_logloss: 0.591134\n",
      "[65]\ttraining's binary_logloss: 0.591042\n",
      "[66]\ttraining's binary_logloss: 0.590956\n",
      "[67]\ttraining's binary_logloss: 0.590888\n",
      "[68]\ttraining's binary_logloss: 0.590815\n",
      "[69]\ttraining's binary_logloss: 0.590758\n",
      "[70]\ttraining's binary_logloss: 0.590702\n",
      "[71]\ttraining's binary_logloss: 0.590648\n",
      "[72]\ttraining's binary_logloss: 0.590586\n",
      "[73]\ttraining's binary_logloss: 0.590542\n",
      "[74]\ttraining's binary_logloss: 0.590485\n",
      "[75]\ttraining's binary_logloss: 0.590444\n",
      "[76]\ttraining's binary_logloss: 0.590367\n",
      "[77]\ttraining's binary_logloss: 0.590299\n",
      "[78]\ttraining's binary_logloss: 0.590249\n",
      "[79]\ttraining's binary_logloss: 0.59019\n",
      "[80]\ttraining's binary_logloss: 0.590195\n",
      "[81]\ttraining's binary_logloss: 0.590123\n",
      "[82]\ttraining's binary_logloss: 0.590062\n",
      "[83]\ttraining's binary_logloss: 0.590013\n",
      "[84]\ttraining's binary_logloss: 0.589965\n",
      "[85]\ttraining's binary_logloss: 0.58992\n",
      "[86]\ttraining's binary_logloss: 0.58991\n",
      "[87]\ttraining's binary_logloss: 0.589905\n",
      "[88]\ttraining's binary_logloss: 0.589885\n",
      "[89]\ttraining's binary_logloss: 0.589889\n",
      "[90]\ttraining's binary_logloss: 0.589889\n",
      "[91]\ttraining's binary_logloss: 0.589821\n",
      "[92]\ttraining's binary_logloss: 0.58976\n",
      "[93]\ttraining's binary_logloss: 0.589703\n",
      "[94]\ttraining's binary_logloss: 0.589651\n",
      "[95]\ttraining's binary_logloss: 0.589602\n",
      "[96]\ttraining's binary_logloss: 0.589568\n",
      "[97]\ttraining's binary_logloss: 0.589534\n",
      "[98]\ttraining's binary_logloss: 0.589513\n",
      "[99]\ttraining's binary_logloss: 0.589542\n",
      "[100]\ttraining's binary_logloss: 0.589587\n",
      "[101]\ttraining's binary_logloss: 0.589624\n",
      "[102]\ttraining's binary_logloss: 0.589662\n",
      "[103]\ttraining's binary_logloss: 0.589707\n",
      "[104]\ttraining's binary_logloss: 0.589754\n",
      "[105]\ttraining's binary_logloss: 0.589806\n",
      "[106]\ttraining's binary_logloss: 0.589771\n",
      "[107]\ttraining's binary_logloss: 0.589732\n",
      "[108]\ttraining's binary_logloss: 0.589703\n",
      "[109]\ttraining's binary_logloss: 0.589683\n",
      "[110]\ttraining's binary_logloss: 0.589715\n",
      "[111]\ttraining's binary_logloss: 0.589759\n",
      "[112]\ttraining's binary_logloss: 0.589795\n",
      "[113]\ttraining's binary_logloss: 0.589835\n",
      "[114]\ttraining's binary_logloss: 0.589882\n",
      "[115]\ttraining's binary_logloss: 0.5899\n",
      "[116]\ttraining's binary_logloss: 0.589886\n",
      "[117]\ttraining's binary_logloss: 0.589864\n",
      "[118]\ttraining's binary_logloss: 0.58985\n",
      "[119]\ttraining's binary_logloss: 0.589835\n",
      "[120]\ttraining's binary_logloss: 0.589828\n",
      "[121]\ttraining's binary_logloss: 0.589869\n",
      "[122]\ttraining's binary_logloss: 0.589899\n",
      "[123]\ttraining's binary_logloss: 0.58992\n",
      "[124]\ttraining's binary_logloss: 0.589936\n",
      "[125]\ttraining's binary_logloss: 0.589968\n",
      "[126]\ttraining's binary_logloss: 0.589988\n",
      "[127]\ttraining's binary_logloss: 0.590015\n",
      "[128]\ttraining's binary_logloss: 0.590068\n",
      "[129]\ttraining's binary_logloss: 0.590115\n",
      "[130]\ttraining's binary_logloss: 0.59017\n",
      "[131]\ttraining's binary_logloss: 0.590139\n",
      "[132]\ttraining's binary_logloss: 0.590165\n",
      "[133]\ttraining's binary_logloss: 0.590143\n",
      "[134]\ttraining's binary_logloss: 0.590116\n",
      "[135]\ttraining's binary_logloss: 0.590124\n",
      "[136]\ttraining's binary_logloss: 0.59015\n",
      "[137]\ttraining's binary_logloss: 0.590183\n",
      "[138]\ttraining's binary_logloss: 0.59021\n",
      "[139]\ttraining's binary_logloss: 0.590241\n",
      "[140]\ttraining's binary_logloss: 0.590264\n",
      "[141]\ttraining's binary_logloss: 0.590272\n",
      "[142]\ttraining's binary_logloss: 0.590269\n",
      "[143]\ttraining's binary_logloss: 0.590267\n",
      "[144]\ttraining's binary_logloss: 0.590267\n",
      "[145]\ttraining's binary_logloss: 0.590243\n",
      "[146]\ttraining's binary_logloss: 0.590274\n",
      "[147]\ttraining's binary_logloss: 0.590272\n",
      "[148]\ttraining's binary_logloss: 0.590288\n",
      "[149]\ttraining's binary_logloss: 0.590318\n",
      "[150]\ttraining's binary_logloss: 0.590322\n",
      "[151]\ttraining's binary_logloss: 0.590352\n",
      "[152]\ttraining's binary_logloss: 0.590391\n",
      "[153]\ttraining's binary_logloss: 0.590441\n",
      "[154]\ttraining's binary_logloss: 0.590481\n",
      "[155]\ttraining's binary_logloss: 0.59052\n",
      "[156]\ttraining's binary_logloss: 0.590543\n",
      "[157]\ttraining's binary_logloss: 0.590568\n",
      "[158]\ttraining's binary_logloss: 0.590595\n",
      "[159]\ttraining's binary_logloss: 0.590624\n",
      "[160]\ttraining's binary_logloss: 0.590647\n",
      "[161]\ttraining's binary_logloss: 0.590655\n",
      "[162]\ttraining's binary_logloss: 0.590614\n",
      "[163]\ttraining's binary_logloss: 0.590578\n",
      "[164]\ttraining's binary_logloss: 0.590541\n",
      "[165]\ttraining's binary_logloss: 0.590507\n",
      "[166]\ttraining's binary_logloss: 0.590508\n",
      "[167]\ttraining's binary_logloss: 0.590502\n",
      "[168]\ttraining's binary_logloss: 0.590501\n",
      "[169]\ttraining's binary_logloss: 0.590486\n",
      "[170]\ttraining's binary_logloss: 0.590478\n",
      "[171]\ttraining's binary_logloss: 0.590513\n",
      "[172]\ttraining's binary_logloss: 0.590532\n",
      "[173]\ttraining's binary_logloss: 0.590559\n",
      "[174]\ttraining's binary_logloss: 0.590581\n",
      "[175]\ttraining's binary_logloss: 0.590601\n",
      "[176]\ttraining's binary_logloss: 0.590597\n",
      "[177]\ttraining's binary_logloss: 0.590592\n",
      "[178]\ttraining's binary_logloss: 0.590589\n",
      "[179]\ttraining's binary_logloss: 0.590589\n",
      "[180]\ttraining's binary_logloss: 0.590583\n",
      "[181]\ttraining's binary_logloss: 0.590614\n",
      "[182]\ttraining's binary_logloss: 0.590611\n",
      "[183]\ttraining's binary_logloss: 0.590613\n",
      "[184]\ttraining's binary_logloss: 0.590623\n",
      "[185]\ttraining's binary_logloss: 0.590618\n",
      "[186]\ttraining's binary_logloss: 0.590638\n",
      "[187]\ttraining's binary_logloss: 0.590662\n",
      "[188]\ttraining's binary_logloss: 0.590683\n",
      "[189]\ttraining's binary_logloss: 0.590702\n",
      "[190]\ttraining's binary_logloss: 0.590722\n",
      "[191]\ttraining's binary_logloss: 0.59072\n",
      "[192]\ttraining's binary_logloss: 0.590738\n",
      "[193]\ttraining's binary_logloss: 0.590758\n",
      "[194]\ttraining's binary_logloss: 0.590775\n",
      "[195]\ttraining's binary_logloss: 0.59078\n",
      "[196]\ttraining's binary_logloss: 0.590737\n",
      "[197]\ttraining's binary_logloss: 0.590704\n",
      "[198]\ttraining's binary_logloss: 0.590672\n",
      "[199]\ttraining's binary_logloss: 0.590664\n",
      "[200]\ttraining's binary_logloss: 0.590675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[201]\ttraining's binary_logloss: 0.590642\n",
      "[202]\ttraining's binary_logloss: 0.590598\n",
      "[203]\ttraining's binary_logloss: 0.590601\n",
      "[204]\ttraining's binary_logloss: 0.590574\n",
      "[205]\ttraining's binary_logloss: 0.59057\n",
      "[206]\ttraining's binary_logloss: 0.590595\n",
      "[207]\ttraining's binary_logloss: 0.590589\n",
      "[208]\ttraining's binary_logloss: 0.590586\n",
      "[209]\ttraining's binary_logloss: 0.590629\n",
      "[210]\ttraining's binary_logloss: 0.590622\n",
      "[211]\ttraining's binary_logloss: 0.590625\n",
      "[212]\ttraining's binary_logloss: 0.590634\n",
      "[213]\ttraining's binary_logloss: 0.590614\n",
      "[214]\ttraining's binary_logloss: 0.590602\n",
      "[215]\ttraining's binary_logloss: 0.5906\n",
      "[216]\ttraining's binary_logloss: 0.590569\n",
      "[217]\ttraining's binary_logloss: 0.590542\n",
      "[218]\ttraining's binary_logloss: 0.590522\n",
      "[219]\ttraining's binary_logloss: 0.590501\n",
      "[220]\ttraining's binary_logloss: 0.590466\n",
      "[221]\ttraining's binary_logloss: 0.590446\n",
      "[222]\ttraining's binary_logloss: 0.590428\n",
      "[223]\ttraining's binary_logloss: 0.59041\n",
      "[224]\ttraining's binary_logloss: 0.590359\n",
      "[225]\ttraining's binary_logloss: 0.590342\n",
      "[226]\ttraining's binary_logloss: 0.590311\n",
      "[227]\ttraining's binary_logloss: 0.590284\n",
      "[228]\ttraining's binary_logloss: 0.590253\n",
      "[229]\ttraining's binary_logloss: 0.59023\n",
      "[230]\ttraining's binary_logloss: 0.590207\n",
      "[231]\ttraining's binary_logloss: 0.590211\n",
      "[232]\ttraining's binary_logloss: 0.590194\n",
      "[233]\ttraining's binary_logloss: 0.590189\n",
      "[234]\ttraining's binary_logloss: 0.590185\n",
      "[235]\ttraining's binary_logloss: 0.590173\n",
      "[236]\ttraining's binary_logloss: 0.590132\n",
      "[237]\ttraining's binary_logloss: 0.590096\n",
      "[238]\ttraining's binary_logloss: 0.590059\n",
      "[239]\ttraining's binary_logloss: 0.590026\n",
      "[240]\ttraining's binary_logloss: 0.58999\n",
      "[241]\ttraining's binary_logloss: 0.58995\n",
      "[242]\ttraining's binary_logloss: 0.589905\n",
      "[243]\ttraining's binary_logloss: 0.589842\n",
      "[244]\ttraining's binary_logloss: 0.589804\n",
      "[245]\ttraining's binary_logloss: 0.589763\n",
      "[246]\ttraining's binary_logloss: 0.589713\n",
      "[247]\ttraining's binary_logloss: 0.589657\n",
      "[248]\ttraining's binary_logloss: 0.58961\n",
      "[249]\ttraining's binary_logloss: 0.589567\n",
      "[250]\ttraining's binary_logloss: 0.589516\n",
      "[251]\ttraining's binary_logloss: 0.589485\n",
      "[252]\ttraining's binary_logloss: 0.589473\n",
      "[253]\ttraining's binary_logloss: 0.589451\n",
      "[254]\ttraining's binary_logloss: 0.58944\n",
      "[255]\ttraining's binary_logloss: 0.589412\n",
      "[256]\ttraining's binary_logloss: 0.589384\n",
      "[257]\ttraining's binary_logloss: 0.589358\n",
      "[258]\ttraining's binary_logloss: 0.589333\n",
      "[259]\ttraining's binary_logloss: 0.589301\n",
      "[260]\ttraining's binary_logloss: 0.58927\n",
      "[261]\ttraining's binary_logloss: 0.589202\n",
      "[262]\ttraining's binary_logloss: 0.589121\n",
      "[263]\ttraining's binary_logloss: 0.589052\n",
      "[264]\ttraining's binary_logloss: 0.588986\n",
      "[265]\ttraining's binary_logloss: 0.588944\n",
      "[266]\ttraining's binary_logloss: 0.588925\n",
      "[267]\ttraining's binary_logloss: 0.588912\n",
      "[268]\ttraining's binary_logloss: 0.588901\n",
      "[269]\ttraining's binary_logloss: 0.588891\n",
      "[270]\ttraining's binary_logloss: 0.588884\n",
      "[271]\ttraining's binary_logloss: 0.588841\n",
      "[272]\ttraining's binary_logloss: 0.588786\n",
      "[273]\ttraining's binary_logloss: 0.588741\n",
      "[274]\ttraining's binary_logloss: 0.588689\n",
      "[275]\ttraining's binary_logloss: 0.58864\n",
      "[276]\ttraining's binary_logloss: 0.5886\n",
      "[277]\ttraining's binary_logloss: 0.588562\n",
      "[278]\ttraining's binary_logloss: 0.588516\n",
      "[279]\ttraining's binary_logloss: 0.588478\n",
      "[280]\ttraining's binary_logloss: 0.588424\n",
      "[281]\ttraining's binary_logloss: 0.58837\n",
      "[282]\ttraining's binary_logloss: 0.588319\n",
      "[283]\ttraining's binary_logloss: 0.588276\n",
      "[284]\ttraining's binary_logloss: 0.588227\n",
      "[285]\ttraining's binary_logloss: 0.588189\n",
      "[286]\ttraining's binary_logloss: 0.58812\n",
      "[287]\ttraining's binary_logloss: 0.588053\n",
      "[288]\ttraining's binary_logloss: 0.587995\n",
      "[289]\ttraining's binary_logloss: 0.587924\n",
      "[290]\ttraining's binary_logloss: 0.587855\n",
      "[291]\ttraining's binary_logloss: 0.587803\n",
      "[292]\ttraining's binary_logloss: 0.587726\n",
      "[293]\ttraining's binary_logloss: 0.587644\n",
      "[294]\ttraining's binary_logloss: 0.587572\n",
      "[295]\ttraining's binary_logloss: 0.5875\n",
      "[296]\ttraining's binary_logloss: 0.587442\n",
      "[297]\ttraining's binary_logloss: 0.587398\n",
      "[298]\ttraining's binary_logloss: 0.587349\n",
      "[299]\ttraining's binary_logloss: 0.587301\n",
      "[300]\ttraining's binary_logloss: 0.587261\n",
      "[301]\ttraining's binary_logloss: 0.587185\n",
      "[302]\ttraining's binary_logloss: 0.587112\n",
      "[303]\ttraining's binary_logloss: 0.58704\n",
      "[304]\ttraining's binary_logloss: 0.586966\n",
      "[305]\ttraining's binary_logloss: 0.586896\n",
      "[306]\ttraining's binary_logloss: 0.586835\n",
      "[307]\ttraining's binary_logloss: 0.586775\n",
      "[308]\ttraining's binary_logloss: 0.586724\n",
      "[309]\ttraining's binary_logloss: 0.586671\n",
      "[310]\ttraining's binary_logloss: 0.586599\n",
      "[311]\ttraining's binary_logloss: 0.58654\n",
      "[312]\ttraining's binary_logloss: 0.586469\n",
      "[313]\ttraining's binary_logloss: 0.586407\n",
      "[314]\ttraining's binary_logloss: 0.586348\n",
      "[315]\ttraining's binary_logloss: 0.586274\n",
      "[316]\ttraining's binary_logloss: 0.586189\n",
      "[317]\ttraining's binary_logloss: 0.586101\n",
      "[318]\ttraining's binary_logloss: 0.586022\n",
      "[319]\ttraining's binary_logloss: 0.585942\n",
      "[320]\ttraining's binary_logloss: 0.585867\n",
      "[321]\ttraining's binary_logloss: 0.585838\n",
      "[322]\ttraining's binary_logloss: 0.58578\n",
      "[323]\ttraining's binary_logloss: 0.585732\n",
      "[324]\ttraining's binary_logloss: 0.585682\n",
      "[325]\ttraining's binary_logloss: 0.585618\n",
      "[326]\ttraining's binary_logloss: 0.585561\n",
      "[327]\ttraining's binary_logloss: 0.585499\n",
      "[328]\ttraining's binary_logloss: 0.585441\n",
      "[329]\ttraining's binary_logloss: 0.585387\n",
      "[330]\ttraining's binary_logloss: 0.585329\n",
      "[331]\ttraining's binary_logloss: 0.585264\n",
      "[332]\ttraining's binary_logloss: 0.585204\n",
      "[333]\ttraining's binary_logloss: 0.585143\n",
      "[334]\ttraining's binary_logloss: 0.585085\n",
      "[335]\ttraining's binary_logloss: 0.585022\n",
      "[336]\ttraining's binary_logloss: 0.584949\n",
      "[337]\ttraining's binary_logloss: 0.584873\n",
      "[338]\ttraining's binary_logloss: 0.584799\n",
      "[339]\ttraining's binary_logloss: 0.584721\n",
      "[340]\ttraining's binary_logloss: 0.584649\n",
      "[341]\ttraining's binary_logloss: 0.584602\n",
      "[342]\ttraining's binary_logloss: 0.584555\n",
      "[343]\ttraining's binary_logloss: 0.584514\n",
      "[344]\ttraining's binary_logloss: 0.584468\n",
      "[345]\ttraining's binary_logloss: 0.584425\n",
      "[346]\ttraining's binary_logloss: 0.584393\n",
      "[347]\ttraining's binary_logloss: 0.584363\n",
      "[348]\ttraining's binary_logloss: 0.584338\n",
      "[349]\ttraining's binary_logloss: 0.58431\n",
      "[350]\ttraining's binary_logloss: 0.584283\n",
      "[351]\ttraining's binary_logloss: 0.584193\n",
      "[352]\ttraining's binary_logloss: 0.584109\n",
      "[353]\ttraining's binary_logloss: 0.584017\n",
      "[354]\ttraining's binary_logloss: 0.583945\n",
      "[355]\ttraining's binary_logloss: 0.583877\n",
      "[356]\ttraining's binary_logloss: 0.583795\n",
      "[357]\ttraining's binary_logloss: 0.583737\n",
      "[358]\ttraining's binary_logloss: 0.583661\n",
      "[359]\ttraining's binary_logloss: 0.583591\n",
      "[360]\ttraining's binary_logloss: 0.583524\n",
      "[361]\ttraining's binary_logloss: 0.583441\n",
      "[362]\ttraining's binary_logloss: 0.583352\n",
      "[363]\ttraining's binary_logloss: 0.583266\n",
      "[364]\ttraining's binary_logloss: 0.583189\n",
      "[365]\ttraining's binary_logloss: 0.583089\n",
      "[366]\ttraining's binary_logloss: 0.583042\n",
      "[367]\ttraining's binary_logloss: 0.582981\n",
      "[368]\ttraining's binary_logloss: 0.582929\n",
      "[369]\ttraining's binary_logloss: 0.582875\n",
      "[370]\ttraining's binary_logloss: 0.582825\n",
      "[371]\ttraining's binary_logloss: 0.582749\n",
      "[372]\ttraining's binary_logloss: 0.58268\n",
      "[373]\ttraining's binary_logloss: 0.582612\n",
      "[374]\ttraining's binary_logloss: 0.582546\n",
      "[375]\ttraining's binary_logloss: 0.582481\n",
      "[376]\ttraining's binary_logloss: 0.582398\n",
      "[377]\ttraining's binary_logloss: 0.582322\n",
      "[378]\ttraining's binary_logloss: 0.582237\n",
      "[379]\ttraining's binary_logloss: 0.582164\n",
      "[380]\ttraining's binary_logloss: 0.582077\n",
      "[381]\ttraining's binary_logloss: 0.582027\n",
      "[382]\ttraining's binary_logloss: 0.58196\n",
      "[383]\ttraining's binary_logloss: 0.581897\n",
      "[384]\ttraining's binary_logloss: 0.581818\n",
      "[385]\ttraining's binary_logloss: 0.581765\n",
      "[386]\ttraining's binary_logloss: 0.58169\n",
      "[387]\ttraining's binary_logloss: 0.581616\n",
      "[388]\ttraining's binary_logloss: 0.581549\n",
      "[389]\ttraining's binary_logloss: 0.58148\n",
      "[390]\ttraining's binary_logloss: 0.581409\n",
      "[391]\ttraining's binary_logloss: 0.581327\n",
      "[392]\ttraining's binary_logloss: 0.581242\n",
      "[393]\ttraining's binary_logloss: 0.581158\n",
      "[394]\ttraining's binary_logloss: 0.581076\n",
      "[395]\ttraining's binary_logloss: 0.580996\n",
      "[396]\ttraining's binary_logloss: 0.58093\n",
      "[397]\ttraining's binary_logloss: 0.58087\n",
      "[398]\ttraining's binary_logloss: 0.580779\n",
      "[399]\ttraining's binary_logloss: 0.580716\n",
      "[400]\ttraining's binary_logloss: 0.580659\n",
      "[401]\ttraining's binary_logloss: 0.580595\n",
      "[402]\ttraining's binary_logloss: 0.580505\n",
      "[403]\ttraining's binary_logloss: 0.580441\n",
      "[404]\ttraining's binary_logloss: 0.580359\n",
      "[405]\ttraining's binary_logloss: 0.580297\n",
      "[406]\ttraining's binary_logloss: 0.580224\n",
      "[407]\ttraining's binary_logloss: 0.580161\n",
      "[408]\ttraining's binary_logloss: 0.580095\n",
      "[409]\ttraining's binary_logloss: 0.580036\n",
      "[410]\ttraining's binary_logloss: 0.579978\n",
      "[411]\ttraining's binary_logloss: 0.579903\n",
      "[412]\ttraining's binary_logloss: 0.579815\n",
      "[413]\ttraining's binary_logloss: 0.579732\n",
      "[414]\ttraining's binary_logloss: 0.579639\n",
      "[415]\ttraining's binary_logloss: 0.57955\n",
      "[416]\ttraining's binary_logloss: 0.579496\n",
      "[417]\ttraining's binary_logloss: 0.579427\n",
      "[418]\ttraining's binary_logloss: 0.579349\n",
      "[419]\ttraining's binary_logloss: 0.57928\n",
      "[420]\ttraining's binary_logloss: 0.579206\n",
      "[421]\ttraining's binary_logloss: 0.57917\n",
      "[422]\ttraining's binary_logloss: 0.579141\n",
      "[423]\ttraining's binary_logloss: 0.579085\n",
      "[424]\ttraining's binary_logloss: 0.579048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[425]\ttraining's binary_logloss: 0.579016\n",
      "[426]\ttraining's binary_logloss: 0.578942\n",
      "[427]\ttraining's binary_logloss: 0.578866\n",
      "[428]\ttraining's binary_logloss: 0.578791\n",
      "[429]\ttraining's binary_logloss: 0.578716\n",
      "[430]\ttraining's binary_logloss: 0.57863\n",
      "[431]\ttraining's binary_logloss: 0.578553\n",
      "[432]\ttraining's binary_logloss: 0.578483\n",
      "[433]\ttraining's binary_logloss: 0.578416\n",
      "[434]\ttraining's binary_logloss: 0.578343\n",
      "[435]\ttraining's binary_logloss: 0.578269\n",
      "[436]\ttraining's binary_logloss: 0.578205\n",
      "[437]\ttraining's binary_logloss: 0.578136\n",
      "[438]\ttraining's binary_logloss: 0.578078\n",
      "[439]\ttraining's binary_logloss: 0.578008\n",
      "[440]\ttraining's binary_logloss: 0.577936\n",
      "[441]\ttraining's binary_logloss: 0.577845\n",
      "[442]\ttraining's binary_logloss: 0.577759\n",
      "[443]\ttraining's binary_logloss: 0.577671\n",
      "[444]\ttraining's binary_logloss: 0.577584\n",
      "[445]\ttraining's binary_logloss: 0.577501\n",
      "[446]\ttraining's binary_logloss: 0.577439\n",
      "[447]\ttraining's binary_logloss: 0.577393\n",
      "[448]\ttraining's binary_logloss: 0.577325\n",
      "[449]\ttraining's binary_logloss: 0.577237\n",
      "[450]\ttraining's binary_logloss: 0.577171\n",
      "[451]\ttraining's binary_logloss: 0.577136\n",
      "[452]\ttraining's binary_logloss: 0.577113\n",
      "[453]\ttraining's binary_logloss: 0.57708\n",
      "[454]\ttraining's binary_logloss: 0.577049\n",
      "[455]\ttraining's binary_logloss: 0.577017\n",
      "[456]\ttraining's binary_logloss: 0.576924\n",
      "[457]\ttraining's binary_logloss: 0.576842\n",
      "[458]\ttraining's binary_logloss: 0.57675\n",
      "[459]\ttraining's binary_logloss: 0.576684\n",
      "[460]\ttraining's binary_logloss: 0.576587\n",
      "[461]\ttraining's binary_logloss: 0.576546\n",
      "[462]\ttraining's binary_logloss: 0.576508\n",
      "[463]\ttraining's binary_logloss: 0.576466\n",
      "[464]\ttraining's binary_logloss: 0.57643\n",
      "[465]\ttraining's binary_logloss: 0.576392\n",
      "[466]\ttraining's binary_logloss: 0.576307\n",
      "[467]\ttraining's binary_logloss: 0.576214\n",
      "[468]\ttraining's binary_logloss: 0.576123\n",
      "[469]\ttraining's binary_logloss: 0.576041\n",
      "[470]\ttraining's binary_logloss: 0.575962\n",
      "[471]\ttraining's binary_logloss: 0.575902\n",
      "[472]\ttraining's binary_logloss: 0.57584\n",
      "[473]\ttraining's binary_logloss: 0.575781\n",
      "[474]\ttraining's binary_logloss: 0.575722\n",
      "[475]\ttraining's binary_logloss: 0.575665\n",
      "[476]\ttraining's binary_logloss: 0.575587\n",
      "[477]\ttraining's binary_logloss: 0.575501\n",
      "[478]\ttraining's binary_logloss: 0.575407\n",
      "[479]\ttraining's binary_logloss: 0.575302\n",
      "[480]\ttraining's binary_logloss: 0.575215\n",
      "[481]\ttraining's binary_logloss: 0.575126\n",
      "[482]\ttraining's binary_logloss: 0.57505\n",
      "[483]\ttraining's binary_logloss: 0.574972\n",
      "[484]\ttraining's binary_logloss: 0.574898\n",
      "[485]\ttraining's binary_logloss: 0.574817\n",
      "[486]\ttraining's binary_logloss: 0.57475\n",
      "[487]\ttraining's binary_logloss: 0.574687\n",
      "[488]\ttraining's binary_logloss: 0.574629\n",
      "[489]\ttraining's binary_logloss: 0.574572\n",
      "[490]\ttraining's binary_logloss: 0.574504\n",
      "[491]\ttraining's binary_logloss: 0.57441\n",
      "[492]\ttraining's binary_logloss: 0.574303\n",
      "[493]\ttraining's binary_logloss: 0.574197\n",
      "[494]\ttraining's binary_logloss: 0.574099\n",
      "[495]\ttraining's binary_logloss: 0.574002\n",
      "[496]\ttraining's binary_logloss: 0.573879\n",
      "[497]\ttraining's binary_logloss: 0.573746\n",
      "[498]\ttraining's binary_logloss: 0.573629\n",
      "[499]\ttraining's binary_logloss: 0.573485\n",
      "[500]\ttraining's binary_logloss: 0.573372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613828\n",
      "[2]\ttraining's binary_logloss: 0.612893\n",
      "[3]\ttraining's binary_logloss: 0.611894\n",
      "[4]\ttraining's binary_logloss: 0.610918\n",
      "[5]\ttraining's binary_logloss: 0.609983\n",
      "[6]\ttraining's binary_logloss: 0.609129\n",
      "[7]\ttraining's binary_logloss: 0.60831\n",
      "[8]\ttraining's binary_logloss: 0.607474\n",
      "[9]\ttraining's binary_logloss: 0.606701\n",
      "[10]\ttraining's binary_logloss: 0.605964\n",
      "[11]\ttraining's binary_logloss: 0.605238\n",
      "[12]\ttraining's binary_logloss: 0.604541\n",
      "[13]\ttraining's binary_logloss: 0.603838\n",
      "[14]\ttraining's binary_logloss: 0.603236\n",
      "[15]\ttraining's binary_logloss: 0.602542\n",
      "[16]\ttraining's binary_logloss: 0.601883\n",
      "[17]\ttraining's binary_logloss: 0.601261\n",
      "[18]\ttraining's binary_logloss: 0.600645\n",
      "[19]\ttraining's binary_logloss: 0.600052\n",
      "[20]\ttraining's binary_logloss: 0.599476\n",
      "[21]\ttraining's binary_logloss: 0.598991\n",
      "[22]\ttraining's binary_logloss: 0.598509\n",
      "[23]\ttraining's binary_logloss: 0.598058\n",
      "[24]\ttraining's binary_logloss: 0.597634\n",
      "[25]\ttraining's binary_logloss: 0.597231\n",
      "[26]\ttraining's binary_logloss: 0.596777\n",
      "[27]\ttraining's binary_logloss: 0.596373\n",
      "[28]\ttraining's binary_logloss: 0.595978\n",
      "[29]\ttraining's binary_logloss: 0.595562\n",
      "[30]\ttraining's binary_logloss: 0.595203\n",
      "[31]\ttraining's binary_logloss: 0.594859\n",
      "[32]\ttraining's binary_logloss: 0.594463\n",
      "[33]\ttraining's binary_logloss: 0.594221\n",
      "[34]\ttraining's binary_logloss: 0.593895\n",
      "[35]\ttraining's binary_logloss: 0.593602\n",
      "[36]\ttraining's binary_logloss: 0.593277\n",
      "[37]\ttraining's binary_logloss: 0.592961\n",
      "[38]\ttraining's binary_logloss: 0.592699\n",
      "[39]\ttraining's binary_logloss: 0.592419\n",
      "[40]\ttraining's binary_logloss: 0.592151\n",
      "[41]\ttraining's binary_logloss: 0.591927\n",
      "[42]\ttraining's binary_logloss: 0.591604\n",
      "[43]\ttraining's binary_logloss: 0.591447\n",
      "[44]\ttraining's binary_logloss: 0.591258\n",
      "[45]\ttraining's binary_logloss: 0.591085\n",
      "[46]\ttraining's binary_logloss: 0.590839\n",
      "[47]\ttraining's binary_logloss: 0.590615\n",
      "[48]\ttraining's binary_logloss: 0.590391\n",
      "[49]\ttraining's binary_logloss: 0.590175\n",
      "[50]\ttraining's binary_logloss: 0.589956\n",
      "[51]\ttraining's binary_logloss: 0.589691\n",
      "[52]\ttraining's binary_logloss: 0.58953\n",
      "[53]\ttraining's binary_logloss: 0.589407\n",
      "[54]\ttraining's binary_logloss: 0.589172\n",
      "[55]\ttraining's binary_logloss: 0.588949\n",
      "[56]\ttraining's binary_logloss: 0.588806\n",
      "[57]\ttraining's binary_logloss: 0.588716\n",
      "[58]\ttraining's binary_logloss: 0.588621\n",
      "[59]\ttraining's binary_logloss: 0.588504\n",
      "[60]\ttraining's binary_logloss: 0.588416\n",
      "[61]\ttraining's binary_logloss: 0.588387\n",
      "[62]\ttraining's binary_logloss: 0.588417\n",
      "[63]\ttraining's binary_logloss: 0.588284\n",
      "[64]\ttraining's binary_logloss: 0.588168\n",
      "[65]\ttraining's binary_logloss: 0.588054\n",
      "[66]\ttraining's binary_logloss: 0.587959\n",
      "[67]\ttraining's binary_logloss: 0.587859\n",
      "[68]\ttraining's binary_logloss: 0.587745\n",
      "[69]\ttraining's binary_logloss: 0.587659\n",
      "[70]\ttraining's binary_logloss: 0.58756\n",
      "[71]\ttraining's binary_logloss: 0.587452\n",
      "[72]\ttraining's binary_logloss: 0.587355\n",
      "[73]\ttraining's binary_logloss: 0.587339\n",
      "[74]\ttraining's binary_logloss: 0.58732\n",
      "[75]\ttraining's binary_logloss: 0.587253\n",
      "[76]\ttraining's binary_logloss: 0.587217\n",
      "[77]\ttraining's binary_logloss: 0.58716\n",
      "[78]\ttraining's binary_logloss: 0.58711\n",
      "[79]\ttraining's binary_logloss: 0.587067\n",
      "[80]\ttraining's binary_logloss: 0.587092\n",
      "[81]\ttraining's binary_logloss: 0.587084\n",
      "[82]\ttraining's binary_logloss: 0.587082\n",
      "[83]\ttraining's binary_logloss: 0.587086\n",
      "[84]\ttraining's binary_logloss: 0.587094\n",
      "[85]\ttraining's binary_logloss: 0.587121\n",
      "[86]\ttraining's binary_logloss: 0.587146\n",
      "[87]\ttraining's binary_logloss: 0.587165\n",
      "[88]\ttraining's binary_logloss: 0.587181\n",
      "[89]\ttraining's binary_logloss: 0.587197\n",
      "[90]\ttraining's binary_logloss: 0.587177\n",
      "[91]\ttraining's binary_logloss: 0.58719\n",
      "[92]\ttraining's binary_logloss: 0.587215\n",
      "[93]\ttraining's binary_logloss: 0.58724\n",
      "[94]\ttraining's binary_logloss: 0.587273\n",
      "[95]\ttraining's binary_logloss: 0.58732\n",
      "[96]\ttraining's binary_logloss: 0.587375\n",
      "[97]\ttraining's binary_logloss: 0.587367\n",
      "[98]\ttraining's binary_logloss: 0.587425\n",
      "[99]\ttraining's binary_logloss: 0.587476\n",
      "[100]\ttraining's binary_logloss: 0.587541\n",
      "[101]\ttraining's binary_logloss: 0.587545\n",
      "[102]\ttraining's binary_logloss: 0.587568\n",
      "[103]\ttraining's binary_logloss: 0.587583\n",
      "[104]\ttraining's binary_logloss: 0.587605\n",
      "[105]\ttraining's binary_logloss: 0.587629\n",
      "[106]\ttraining's binary_logloss: 0.587649\n",
      "[107]\ttraining's binary_logloss: 0.587654\n",
      "[108]\ttraining's binary_logloss: 0.587663\n",
      "[109]\ttraining's binary_logloss: 0.587717\n",
      "[110]\ttraining's binary_logloss: 0.587743\n",
      "[111]\ttraining's binary_logloss: 0.587761\n",
      "[112]\ttraining's binary_logloss: 0.587783\n",
      "[113]\ttraining's binary_logloss: 0.587807\n",
      "[114]\ttraining's binary_logloss: 0.587842\n",
      "[115]\ttraining's binary_logloss: 0.587873\n",
      "[116]\ttraining's binary_logloss: 0.58787\n",
      "[117]\ttraining's binary_logloss: 0.587865\n",
      "[118]\ttraining's binary_logloss: 0.587854\n",
      "[119]\ttraining's binary_logloss: 0.587883\n",
      "[120]\ttraining's binary_logloss: 0.587889\n",
      "[121]\ttraining's binary_logloss: 0.587915\n",
      "[122]\ttraining's binary_logloss: 0.587946\n",
      "[123]\ttraining's binary_logloss: 0.587975\n",
      "[124]\ttraining's binary_logloss: 0.58802\n",
      "[125]\ttraining's binary_logloss: 0.588054\n",
      "[126]\ttraining's binary_logloss: 0.588067\n",
      "[127]\ttraining's binary_logloss: 0.588082\n",
      "[128]\ttraining's binary_logloss: 0.588102\n",
      "[129]\ttraining's binary_logloss: 0.588122\n",
      "[130]\ttraining's binary_logloss: 0.588132\n",
      "[131]\ttraining's binary_logloss: 0.588218\n",
      "[132]\ttraining's binary_logloss: 0.588277\n",
      "[133]\ttraining's binary_logloss: 0.58835\n",
      "[134]\ttraining's binary_logloss: 0.588413\n",
      "[135]\ttraining's binary_logloss: 0.588479\n",
      "[136]\ttraining's binary_logloss: 0.588481\n",
      "[137]\ttraining's binary_logloss: 0.588464\n",
      "[138]\ttraining's binary_logloss: 0.588451\n",
      "[139]\ttraining's binary_logloss: 0.588476\n",
      "[140]\ttraining's binary_logloss: 0.588491\n",
      "[141]\ttraining's binary_logloss: 0.588518\n",
      "[142]\ttraining's binary_logloss: 0.588558\n",
      "[143]\ttraining's binary_logloss: 0.588595\n",
      "[144]\ttraining's binary_logloss: 0.588636\n",
      "[145]\ttraining's binary_logloss: 0.588618\n",
      "[146]\ttraining's binary_logloss: 0.588619\n",
      "[147]\ttraining's binary_logloss: 0.588653\n",
      "[148]\ttraining's binary_logloss: 0.588691\n",
      "[149]\ttraining's binary_logloss: 0.588737\n",
      "[150]\ttraining's binary_logloss: 0.588785\n",
      "[151]\ttraining's binary_logloss: 0.588837\n",
      "[152]\ttraining's binary_logloss: 0.588897\n",
      "[153]\ttraining's binary_logloss: 0.588967\n",
      "[154]\ttraining's binary_logloss: 0.588998\n",
      "[155]\ttraining's binary_logloss: 0.58906\n",
      "[156]\ttraining's binary_logloss: 0.589069\n",
      "[157]\ttraining's binary_logloss: 0.589079\n",
      "[158]\ttraining's binary_logloss: 0.589091\n",
      "[159]\ttraining's binary_logloss: 0.589106\n",
      "[160]\ttraining's binary_logloss: 0.589147\n",
      "[161]\ttraining's binary_logloss: 0.589202\n",
      "[162]\ttraining's binary_logloss: 0.589245\n",
      "[163]\ttraining's binary_logloss: 0.589255\n",
      "[164]\ttraining's binary_logloss: 0.589269\n",
      "[165]\ttraining's binary_logloss: 0.589283\n",
      "[166]\ttraining's binary_logloss: 0.589287\n",
      "[167]\ttraining's binary_logloss: 0.589294\n",
      "[168]\ttraining's binary_logloss: 0.589336\n",
      "[169]\ttraining's binary_logloss: 0.589385\n",
      "[170]\ttraining's binary_logloss: 0.589417\n",
      "[171]\ttraining's binary_logloss: 0.589402\n",
      "[172]\ttraining's binary_logloss: 0.589404\n",
      "[173]\ttraining's binary_logloss: 0.589426\n",
      "[174]\ttraining's binary_logloss: 0.58942\n",
      "[175]\ttraining's binary_logloss: 0.589413\n",
      "[176]\ttraining's binary_logloss: 0.58946\n",
      "[177]\ttraining's binary_logloss: 0.589479\n",
      "[178]\ttraining's binary_logloss: 0.589504\n",
      "[179]\ttraining's binary_logloss: 0.58954\n",
      "[180]\ttraining's binary_logloss: 0.589562\n",
      "[181]\ttraining's binary_logloss: 0.589579\n",
      "[182]\ttraining's binary_logloss: 0.589639\n",
      "[183]\ttraining's binary_logloss: 0.589667\n",
      "[184]\ttraining's binary_logloss: 0.589703\n",
      "[185]\ttraining's binary_logloss: 0.589745\n",
      "[186]\ttraining's binary_logloss: 0.589804\n",
      "[187]\ttraining's binary_logloss: 0.589869\n",
      "[188]\ttraining's binary_logloss: 0.589926\n",
      "[189]\ttraining's binary_logloss: 0.589972\n",
      "[190]\ttraining's binary_logloss: 0.590035\n",
      "[191]\ttraining's binary_logloss: 0.590061\n",
      "[192]\ttraining's binary_logloss: 0.59009\n",
      "[193]\ttraining's binary_logloss: 0.590117\n",
      "[194]\ttraining's binary_logloss: 0.590149\n",
      "[195]\ttraining's binary_logloss: 0.590173\n",
      "[196]\ttraining's binary_logloss: 0.59014\n",
      "[197]\ttraining's binary_logloss: 0.590141\n",
      "[198]\ttraining's binary_logloss: 0.590144\n",
      "[199]\ttraining's binary_logloss: 0.590108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's binary_logloss: 0.590086\n",
      "[201]\ttraining's binary_logloss: 0.590059\n",
      "[202]\ttraining's binary_logloss: 0.590035\n",
      "[203]\ttraining's binary_logloss: 0.590032\n",
      "[204]\ttraining's binary_logloss: 0.590007\n",
      "[205]\ttraining's binary_logloss: 0.589981\n",
      "[206]\ttraining's binary_logloss: 0.590018\n",
      "[207]\ttraining's binary_logloss: 0.590045\n",
      "[208]\ttraining's binary_logloss: 0.590066\n",
      "[209]\ttraining's binary_logloss: 0.590076\n",
      "[210]\ttraining's binary_logloss: 0.590086\n",
      "[211]\ttraining's binary_logloss: 0.590072\n",
      "[212]\ttraining's binary_logloss: 0.590071\n",
      "[213]\ttraining's binary_logloss: 0.590062\n",
      "[214]\ttraining's binary_logloss: 0.590049\n",
      "[215]\ttraining's binary_logloss: 0.590025\n",
      "[216]\ttraining's binary_logloss: 0.590003\n",
      "[217]\ttraining's binary_logloss: 0.589956\n",
      "[218]\ttraining's binary_logloss: 0.589938\n",
      "[219]\ttraining's binary_logloss: 0.589901\n",
      "[220]\ttraining's binary_logloss: 0.589872\n",
      "[221]\ttraining's binary_logloss: 0.589889\n",
      "[222]\ttraining's binary_logloss: 0.589908\n",
      "[223]\ttraining's binary_logloss: 0.589925\n",
      "[224]\ttraining's binary_logloss: 0.589927\n",
      "[225]\ttraining's binary_logloss: 0.589923\n",
      "[226]\ttraining's binary_logloss: 0.589927\n",
      "[227]\ttraining's binary_logloss: 0.58991\n",
      "[228]\ttraining's binary_logloss: 0.589898\n",
      "[229]\ttraining's binary_logloss: 0.589896\n",
      "[230]\ttraining's binary_logloss: 0.589883\n",
      "[231]\ttraining's binary_logloss: 0.589837\n",
      "[232]\ttraining's binary_logloss: 0.589804\n",
      "[233]\ttraining's binary_logloss: 0.589798\n",
      "[234]\ttraining's binary_logloss: 0.589778\n",
      "[235]\ttraining's binary_logloss: 0.589735\n",
      "[236]\ttraining's binary_logloss: 0.589724\n",
      "[237]\ttraining's binary_logloss: 0.589711\n",
      "[238]\ttraining's binary_logloss: 0.589691\n",
      "[239]\ttraining's binary_logloss: 0.589676\n",
      "[240]\ttraining's binary_logloss: 0.589661\n",
      "[241]\ttraining's binary_logloss: 0.589663\n",
      "[242]\ttraining's binary_logloss: 0.589659\n",
      "[243]\ttraining's binary_logloss: 0.589642\n",
      "[244]\ttraining's binary_logloss: 0.58964\n",
      "[245]\ttraining's binary_logloss: 0.589623\n",
      "[246]\ttraining's binary_logloss: 0.589572\n",
      "[247]\ttraining's binary_logloss: 0.589521\n",
      "[248]\ttraining's binary_logloss: 0.589473\n",
      "[249]\ttraining's binary_logloss: 0.589427\n",
      "[250]\ttraining's binary_logloss: 0.589384\n",
      "[251]\ttraining's binary_logloss: 0.58938\n",
      "[252]\ttraining's binary_logloss: 0.589379\n",
      "[253]\ttraining's binary_logloss: 0.589378\n",
      "[254]\ttraining's binary_logloss: 0.589377\n",
      "[255]\ttraining's binary_logloss: 0.589379\n",
      "[256]\ttraining's binary_logloss: 0.589351\n",
      "[257]\ttraining's binary_logloss: 0.589313\n",
      "[258]\ttraining's binary_logloss: 0.589289\n",
      "[259]\ttraining's binary_logloss: 0.589261\n",
      "[260]\ttraining's binary_logloss: 0.589229\n",
      "[261]\ttraining's binary_logloss: 0.589187\n",
      "[262]\ttraining's binary_logloss: 0.589118\n",
      "[263]\ttraining's binary_logloss: 0.589089\n",
      "[264]\ttraining's binary_logloss: 0.589016\n",
      "[265]\ttraining's binary_logloss: 0.588952\n",
      "[266]\ttraining's binary_logloss: 0.588935\n",
      "[267]\ttraining's binary_logloss: 0.588919\n",
      "[268]\ttraining's binary_logloss: 0.588906\n",
      "[269]\ttraining's binary_logloss: 0.588894\n",
      "[270]\ttraining's binary_logloss: 0.588881\n",
      "[271]\ttraining's binary_logloss: 0.588869\n",
      "[272]\ttraining's binary_logloss: 0.588853\n",
      "[273]\ttraining's binary_logloss: 0.588839\n",
      "[274]\ttraining's binary_logloss: 0.588813\n",
      "[275]\ttraining's binary_logloss: 0.588801\n",
      "[276]\ttraining's binary_logloss: 0.588764\n",
      "[277]\ttraining's binary_logloss: 0.588757\n",
      "[278]\ttraining's binary_logloss: 0.588728\n",
      "[279]\ttraining's binary_logloss: 0.588687\n",
      "[280]\ttraining's binary_logloss: 0.588655\n",
      "[281]\ttraining's binary_logloss: 0.588636\n",
      "[282]\ttraining's binary_logloss: 0.588616\n",
      "[283]\ttraining's binary_logloss: 0.588593\n",
      "[284]\ttraining's binary_logloss: 0.58857\n",
      "[285]\ttraining's binary_logloss: 0.588534\n",
      "[286]\ttraining's binary_logloss: 0.588457\n",
      "[287]\ttraining's binary_logloss: 0.588368\n",
      "[288]\ttraining's binary_logloss: 0.588272\n",
      "[289]\ttraining's binary_logloss: 0.58818\n",
      "[290]\ttraining's binary_logloss: 0.588107\n",
      "[291]\ttraining's binary_logloss: 0.588066\n",
      "[292]\ttraining's binary_logloss: 0.588034\n",
      "[293]\ttraining's binary_logloss: 0.587995\n",
      "[294]\ttraining's binary_logloss: 0.587958\n",
      "[295]\ttraining's binary_logloss: 0.587904\n",
      "[296]\ttraining's binary_logloss: 0.587847\n",
      "[297]\ttraining's binary_logloss: 0.587758\n",
      "[298]\ttraining's binary_logloss: 0.587678\n",
      "[299]\ttraining's binary_logloss: 0.587591\n",
      "[300]\ttraining's binary_logloss: 0.587507\n",
      "[301]\ttraining's binary_logloss: 0.587429\n",
      "[302]\ttraining's binary_logloss: 0.587354\n",
      "[303]\ttraining's binary_logloss: 0.587282\n",
      "[304]\ttraining's binary_logloss: 0.587212\n",
      "[305]\ttraining's binary_logloss: 0.58714\n",
      "[306]\ttraining's binary_logloss: 0.58704\n",
      "[307]\ttraining's binary_logloss: 0.586937\n",
      "[308]\ttraining's binary_logloss: 0.586834\n",
      "[309]\ttraining's binary_logloss: 0.58675\n",
      "[310]\ttraining's binary_logloss: 0.586647\n",
      "[311]\ttraining's binary_logloss: 0.586595\n",
      "[312]\ttraining's binary_logloss: 0.586539\n",
      "[313]\ttraining's binary_logloss: 0.586486\n",
      "[314]\ttraining's binary_logloss: 0.586425\n",
      "[315]\ttraining's binary_logloss: 0.586373\n",
      "[316]\ttraining's binary_logloss: 0.586329\n",
      "[317]\ttraining's binary_logloss: 0.58628\n",
      "[318]\ttraining's binary_logloss: 0.586233\n",
      "[319]\ttraining's binary_logloss: 0.586182\n",
      "[320]\ttraining's binary_logloss: 0.586138\n",
      "[321]\ttraining's binary_logloss: 0.586117\n",
      "[322]\ttraining's binary_logloss: 0.586089\n",
      "[323]\ttraining's binary_logloss: 0.586063\n",
      "[324]\ttraining's binary_logloss: 0.586039\n",
      "[325]\ttraining's binary_logloss: 0.586025\n",
      "[326]\ttraining's binary_logloss: 0.585982\n",
      "[327]\ttraining's binary_logloss: 0.585939\n",
      "[328]\ttraining's binary_logloss: 0.58589\n",
      "[329]\ttraining's binary_logloss: 0.585858\n",
      "[330]\ttraining's binary_logloss: 0.585819\n",
      "[331]\ttraining's binary_logloss: 0.585746\n",
      "[332]\ttraining's binary_logloss: 0.585675\n",
      "[333]\ttraining's binary_logloss: 0.585601\n",
      "[334]\ttraining's binary_logloss: 0.58553\n",
      "[335]\ttraining's binary_logloss: 0.585426\n",
      "[336]\ttraining's binary_logloss: 0.585358\n",
      "[337]\ttraining's binary_logloss: 0.585291\n",
      "[338]\ttraining's binary_logloss: 0.58522\n",
      "[339]\ttraining's binary_logloss: 0.585131\n",
      "[340]\ttraining's binary_logloss: 0.585069\n",
      "[341]\ttraining's binary_logloss: 0.584982\n",
      "[342]\ttraining's binary_logloss: 0.584888\n",
      "[343]\ttraining's binary_logloss: 0.584805\n",
      "[344]\ttraining's binary_logloss: 0.584717\n",
      "[345]\ttraining's binary_logloss: 0.584628\n",
      "[346]\ttraining's binary_logloss: 0.584605\n",
      "[347]\ttraining's binary_logloss: 0.58458\n",
      "[348]\ttraining's binary_logloss: 0.584532\n",
      "[349]\ttraining's binary_logloss: 0.584507\n",
      "[350]\ttraining's binary_logloss: 0.58445\n",
      "[351]\ttraining's binary_logloss: 0.584368\n",
      "[352]\ttraining's binary_logloss: 0.584279\n",
      "[353]\ttraining's binary_logloss: 0.584214\n",
      "[354]\ttraining's binary_logloss: 0.584152\n",
      "[355]\ttraining's binary_logloss: 0.584072\n",
      "[356]\ttraining's binary_logloss: 0.584\n",
      "[357]\ttraining's binary_logloss: 0.583936\n",
      "[358]\ttraining's binary_logloss: 0.583874\n",
      "[359]\ttraining's binary_logloss: 0.583811\n",
      "[360]\ttraining's binary_logloss: 0.583739\n",
      "[361]\ttraining's binary_logloss: 0.583667\n",
      "[362]\ttraining's binary_logloss: 0.583602\n",
      "[363]\ttraining's binary_logloss: 0.58355\n",
      "[364]\ttraining's binary_logloss: 0.583506\n",
      "[365]\ttraining's binary_logloss: 0.583451\n",
      "[366]\ttraining's binary_logloss: 0.583428\n",
      "[367]\ttraining's binary_logloss: 0.583405\n",
      "[368]\ttraining's binary_logloss: 0.583381\n",
      "[369]\ttraining's binary_logloss: 0.583363\n",
      "[370]\ttraining's binary_logloss: 0.583336\n",
      "[371]\ttraining's binary_logloss: 0.583242\n",
      "[372]\ttraining's binary_logloss: 0.583178\n",
      "[373]\ttraining's binary_logloss: 0.583094\n",
      "[374]\ttraining's binary_logloss: 0.58301\n",
      "[375]\ttraining's binary_logloss: 0.582924\n",
      "[376]\ttraining's binary_logloss: 0.582814\n",
      "[377]\ttraining's binary_logloss: 0.582717\n",
      "[378]\ttraining's binary_logloss: 0.582612\n",
      "[379]\ttraining's binary_logloss: 0.582504\n",
      "[380]\ttraining's binary_logloss: 0.58241\n",
      "[381]\ttraining's binary_logloss: 0.582327\n",
      "[382]\ttraining's binary_logloss: 0.582244\n",
      "[383]\ttraining's binary_logloss: 0.582163\n",
      "[384]\ttraining's binary_logloss: 0.582107\n",
      "[385]\ttraining's binary_logloss: 0.582039\n",
      "[386]\ttraining's binary_logloss: 0.58199\n",
      "[387]\ttraining's binary_logloss: 0.58192\n",
      "[388]\ttraining's binary_logloss: 0.581851\n",
      "[389]\ttraining's binary_logloss: 0.581797\n",
      "[390]\ttraining's binary_logloss: 0.581738\n",
      "[391]\ttraining's binary_logloss: 0.5816\n",
      "[392]\ttraining's binary_logloss: 0.581477\n",
      "[393]\ttraining's binary_logloss: 0.581357\n",
      "[394]\ttraining's binary_logloss: 0.581256\n",
      "[395]\ttraining's binary_logloss: 0.581156\n",
      "[396]\ttraining's binary_logloss: 0.581087\n",
      "[397]\ttraining's binary_logloss: 0.58102\n",
      "[398]\ttraining's binary_logloss: 0.580958\n",
      "[399]\ttraining's binary_logloss: 0.580899\n",
      "[400]\ttraining's binary_logloss: 0.580839\n",
      "[401]\ttraining's binary_logloss: 0.580753\n",
      "[402]\ttraining's binary_logloss: 0.580671\n",
      "[403]\ttraining's binary_logloss: 0.580594\n",
      "[404]\ttraining's binary_logloss: 0.580526\n",
      "[405]\ttraining's binary_logloss: 0.580444\n",
      "[406]\ttraining's binary_logloss: 0.580375\n",
      "[407]\ttraining's binary_logloss: 0.580287\n",
      "[408]\ttraining's binary_logloss: 0.580219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[409]\ttraining's binary_logloss: 0.580169\n",
      "[410]\ttraining's binary_logloss: 0.580101\n",
      "[411]\ttraining's binary_logloss: 0.580023\n",
      "[412]\ttraining's binary_logloss: 0.579947\n",
      "[413]\ttraining's binary_logloss: 0.579874\n",
      "[414]\ttraining's binary_logloss: 0.579802\n",
      "[415]\ttraining's binary_logloss: 0.579733\n",
      "[416]\ttraining's binary_logloss: 0.579675\n",
      "[417]\ttraining's binary_logloss: 0.579612\n",
      "[418]\ttraining's binary_logloss: 0.579555\n",
      "[419]\ttraining's binary_logloss: 0.579504\n",
      "[420]\ttraining's binary_logloss: 0.579443\n",
      "[421]\ttraining's binary_logloss: 0.579434\n",
      "[422]\ttraining's binary_logloss: 0.579389\n",
      "[423]\ttraining's binary_logloss: 0.579379\n",
      "[424]\ttraining's binary_logloss: 0.579368\n",
      "[425]\ttraining's binary_logloss: 0.579341\n",
      "[426]\ttraining's binary_logloss: 0.579243\n",
      "[427]\ttraining's binary_logloss: 0.579162\n",
      "[428]\ttraining's binary_logloss: 0.579057\n",
      "[429]\ttraining's binary_logloss: 0.578954\n",
      "[430]\ttraining's binary_logloss: 0.57885\n",
      "[431]\ttraining's binary_logloss: 0.578795\n",
      "[432]\ttraining's binary_logloss: 0.578746\n",
      "[433]\ttraining's binary_logloss: 0.578686\n",
      "[434]\ttraining's binary_logloss: 0.578614\n",
      "[435]\ttraining's binary_logloss: 0.578562\n",
      "[436]\ttraining's binary_logloss: 0.578469\n",
      "[437]\ttraining's binary_logloss: 0.57839\n",
      "[438]\ttraining's binary_logloss: 0.578315\n",
      "[439]\ttraining's binary_logloss: 0.578242\n",
      "[440]\ttraining's binary_logloss: 0.578151\n",
      "[441]\ttraining's binary_logloss: 0.578064\n",
      "[442]\ttraining's binary_logloss: 0.577955\n",
      "[443]\ttraining's binary_logloss: 0.57787\n",
      "[444]\ttraining's binary_logloss: 0.577789\n",
      "[445]\ttraining's binary_logloss: 0.577703\n",
      "[446]\ttraining's binary_logloss: 0.57764\n",
      "[447]\ttraining's binary_logloss: 0.577587\n",
      "[448]\ttraining's binary_logloss: 0.577543\n",
      "[449]\ttraining's binary_logloss: 0.57749\n",
      "[450]\ttraining's binary_logloss: 0.577433\n",
      "[451]\ttraining's binary_logloss: 0.577391\n",
      "[452]\ttraining's binary_logloss: 0.577356\n",
      "[453]\ttraining's binary_logloss: 0.577316\n",
      "[454]\ttraining's binary_logloss: 0.577285\n",
      "[455]\ttraining's binary_logloss: 0.577223\n",
      "[456]\ttraining's binary_logloss: 0.577137\n",
      "[457]\ttraining's binary_logloss: 0.577078\n",
      "[458]\ttraining's binary_logloss: 0.576982\n",
      "[459]\ttraining's binary_logloss: 0.576878\n",
      "[460]\ttraining's binary_logloss: 0.576794\n",
      "[461]\ttraining's binary_logloss: 0.576697\n",
      "[462]\ttraining's binary_logloss: 0.576616\n",
      "[463]\ttraining's binary_logloss: 0.576531\n",
      "[464]\ttraining's binary_logloss: 0.57645\n",
      "[465]\ttraining's binary_logloss: 0.576373\n",
      "[466]\ttraining's binary_logloss: 0.576274\n",
      "[467]\ttraining's binary_logloss: 0.576171\n",
      "[468]\ttraining's binary_logloss: 0.576071\n",
      "[469]\ttraining's binary_logloss: 0.575968\n",
      "[470]\ttraining's binary_logloss: 0.575866\n",
      "[471]\ttraining's binary_logloss: 0.575768\n",
      "[472]\ttraining's binary_logloss: 0.575672\n",
      "[473]\ttraining's binary_logloss: 0.57558\n",
      "[474]\ttraining's binary_logloss: 0.575508\n",
      "[475]\ttraining's binary_logloss: 0.575443\n",
      "[476]\ttraining's binary_logloss: 0.575378\n",
      "[477]\ttraining's binary_logloss: 0.575311\n",
      "[478]\ttraining's binary_logloss: 0.575231\n",
      "[479]\ttraining's binary_logloss: 0.575175\n",
      "[480]\ttraining's binary_logloss: 0.575094\n",
      "[481]\ttraining's binary_logloss: 0.575046\n",
      "[482]\ttraining's binary_logloss: 0.575\n",
      "[483]\ttraining's binary_logloss: 0.574931\n",
      "[484]\ttraining's binary_logloss: 0.574865\n",
      "[485]\ttraining's binary_logloss: 0.5748\n",
      "[486]\ttraining's binary_logloss: 0.57472\n",
      "[487]\ttraining's binary_logloss: 0.574645\n",
      "[488]\ttraining's binary_logloss: 0.574569\n",
      "[489]\ttraining's binary_logloss: 0.574496\n",
      "[490]\ttraining's binary_logloss: 0.574424\n",
      "[491]\ttraining's binary_logloss: 0.574347\n",
      "[492]\ttraining's binary_logloss: 0.574269\n",
      "[493]\ttraining's binary_logloss: 0.574198\n",
      "[494]\ttraining's binary_logloss: 0.574128\n",
      "[495]\ttraining's binary_logloss: 0.574059\n",
      "[496]\ttraining's binary_logloss: 0.573946\n",
      "[497]\ttraining's binary_logloss: 0.573835\n",
      "[498]\ttraining's binary_logloss: 0.57373\n",
      "[499]\ttraining's binary_logloss: 0.573633\n",
      "[500]\ttraining's binary_logloss: 0.573542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614273\n",
      "[2]\ttraining's binary_logloss: 0.613032\n",
      "[3]\ttraining's binary_logloss: 0.611816\n",
      "[4]\ttraining's binary_logloss: 0.61066\n",
      "[5]\ttraining's binary_logloss: 0.609544\n",
      "[6]\ttraining's binary_logloss: 0.608458\n",
      "[7]\ttraining's binary_logloss: 0.607306\n",
      "[8]\ttraining's binary_logloss: 0.606207\n",
      "[9]\ttraining's binary_logloss: 0.605163\n",
      "[10]\ttraining's binary_logloss: 0.604339\n",
      "[11]\ttraining's binary_logloss: 0.603471\n",
      "[12]\ttraining's binary_logloss: 0.602529\n",
      "[13]\ttraining's binary_logloss: 0.601713\n",
      "[14]\ttraining's binary_logloss: 0.600804\n",
      "[15]\ttraining's binary_logloss: 0.599937\n",
      "[16]\ttraining's binary_logloss: 0.599085\n",
      "[17]\ttraining's binary_logloss: 0.598235\n",
      "[18]\ttraining's binary_logloss: 0.597481\n",
      "[19]\ttraining's binary_logloss: 0.596738\n",
      "[20]\ttraining's binary_logloss: 0.596036\n",
      "[21]\ttraining's binary_logloss: 0.595273\n",
      "[22]\ttraining's binary_logloss: 0.594627\n",
      "[23]\ttraining's binary_logloss: 0.593903\n",
      "[24]\ttraining's binary_logloss: 0.593215\n",
      "[25]\ttraining's binary_logloss: 0.592546\n",
      "[26]\ttraining's binary_logloss: 0.591932\n",
      "[27]\ttraining's binary_logloss: 0.591354\n",
      "[28]\ttraining's binary_logloss: 0.590773\n",
      "[29]\ttraining's binary_logloss: 0.590254\n",
      "[30]\ttraining's binary_logloss: 0.589739\n",
      "[31]\ttraining's binary_logloss: 0.589256\n",
      "[32]\ttraining's binary_logloss: 0.588723\n",
      "[33]\ttraining's binary_logloss: 0.588249\n",
      "[34]\ttraining's binary_logloss: 0.587736\n",
      "[35]\ttraining's binary_logloss: 0.587318\n",
      "[36]\ttraining's binary_logloss: 0.586893\n",
      "[37]\ttraining's binary_logloss: 0.586498\n",
      "[38]\ttraining's binary_logloss: 0.586055\n",
      "[39]\ttraining's binary_logloss: 0.585678\n",
      "[40]\ttraining's binary_logloss: 0.585324\n",
      "[41]\ttraining's binary_logloss: 0.584911\n",
      "[42]\ttraining's binary_logloss: 0.584498\n",
      "[43]\ttraining's binary_logloss: 0.584113\n",
      "[44]\ttraining's binary_logloss: 0.583755\n",
      "[45]\ttraining's binary_logloss: 0.583439\n",
      "[46]\ttraining's binary_logloss: 0.583041\n",
      "[47]\ttraining's binary_logloss: 0.582661\n",
      "[48]\ttraining's binary_logloss: 0.582296\n",
      "[49]\ttraining's binary_logloss: 0.581954\n",
      "[50]\ttraining's binary_logloss: 0.581654\n",
      "[51]\ttraining's binary_logloss: 0.581345\n",
      "[52]\ttraining's binary_logloss: 0.581125\n",
      "[53]\ttraining's binary_logloss: 0.580834\n",
      "[54]\ttraining's binary_logloss: 0.580531\n",
      "[55]\ttraining's binary_logloss: 0.580261\n",
      "[56]\ttraining's binary_logloss: 0.580034\n",
      "[57]\ttraining's binary_logloss: 0.579816\n",
      "[58]\ttraining's binary_logloss: 0.579633\n",
      "[59]\ttraining's binary_logloss: 0.579432\n",
      "[60]\ttraining's binary_logloss: 0.579225\n",
      "[61]\ttraining's binary_logloss: 0.579081\n",
      "[62]\ttraining's binary_logloss: 0.578857\n",
      "[63]\ttraining's binary_logloss: 0.578647\n",
      "[64]\ttraining's binary_logloss: 0.578445\n",
      "[65]\ttraining's binary_logloss: 0.578261\n",
      "[66]\ttraining's binary_logloss: 0.578071\n",
      "[67]\ttraining's binary_logloss: 0.577892\n",
      "[68]\ttraining's binary_logloss: 0.577722\n",
      "[69]\ttraining's binary_logloss: 0.577576\n",
      "[70]\ttraining's binary_logloss: 0.577428\n",
      "[71]\ttraining's binary_logloss: 0.577293\n",
      "[72]\ttraining's binary_logloss: 0.577112\n",
      "[73]\ttraining's binary_logloss: 0.576942\n",
      "[74]\ttraining's binary_logloss: 0.576826\n",
      "[75]\ttraining's binary_logloss: 0.576709\n",
      "[76]\ttraining's binary_logloss: 0.576579\n",
      "[77]\ttraining's binary_logloss: 0.576461\n",
      "[78]\ttraining's binary_logloss: 0.57634\n",
      "[79]\ttraining's binary_logloss: 0.576228\n",
      "[80]\ttraining's binary_logloss: 0.576126\n",
      "[81]\ttraining's binary_logloss: 0.575968\n",
      "[82]\ttraining's binary_logloss: 0.575822\n",
      "[83]\ttraining's binary_logloss: 0.575695\n",
      "[84]\ttraining's binary_logloss: 0.57556\n",
      "[85]\ttraining's binary_logloss: 0.575433\n",
      "[86]\ttraining's binary_logloss: 0.575392\n",
      "[87]\ttraining's binary_logloss: 0.57532\n",
      "[88]\ttraining's binary_logloss: 0.575241\n",
      "[89]\ttraining's binary_logloss: 0.575121\n",
      "[90]\ttraining's binary_logloss: 0.575019\n",
      "[91]\ttraining's binary_logloss: 0.57494\n",
      "[92]\ttraining's binary_logloss: 0.574865\n",
      "[93]\ttraining's binary_logloss: 0.57473\n",
      "[94]\ttraining's binary_logloss: 0.574658\n",
      "[95]\ttraining's binary_logloss: 0.574568\n",
      "[96]\ttraining's binary_logloss: 0.574443\n",
      "[97]\ttraining's binary_logloss: 0.574327\n",
      "[98]\ttraining's binary_logloss: 0.574215\n",
      "[99]\ttraining's binary_logloss: 0.57411\n",
      "[100]\ttraining's binary_logloss: 0.574011\n",
      "[101]\ttraining's binary_logloss: 0.57393\n",
      "[102]\ttraining's binary_logloss: 0.573851\n",
      "[103]\ttraining's binary_logloss: 0.573769\n",
      "[104]\ttraining's binary_logloss: 0.573702\n",
      "[105]\ttraining's binary_logloss: 0.573638\n",
      "[106]\ttraining's binary_logloss: 0.573527\n",
      "[107]\ttraining's binary_logloss: 0.573422\n",
      "[108]\ttraining's binary_logloss: 0.573325\n",
      "[109]\ttraining's binary_logloss: 0.573235\n",
      "[110]\ttraining's binary_logloss: 0.573157\n",
      "[111]\ttraining's binary_logloss: 0.573086\n",
      "[112]\ttraining's binary_logloss: 0.572996\n",
      "[113]\ttraining's binary_logloss: 0.572916\n",
      "[114]\ttraining's binary_logloss: 0.572853\n",
      "[115]\ttraining's binary_logloss: 0.572781\n",
      "[116]\ttraining's binary_logloss: 0.572749\n",
      "[117]\ttraining's binary_logloss: 0.572701\n",
      "[118]\ttraining's binary_logloss: 0.572645\n",
      "[119]\ttraining's binary_logloss: 0.5726\n",
      "[120]\ttraining's binary_logloss: 0.572542\n",
      "[121]\ttraining's binary_logloss: 0.572507\n",
      "[122]\ttraining's binary_logloss: 0.57247\n",
      "[123]\ttraining's binary_logloss: 0.572441\n",
      "[124]\ttraining's binary_logloss: 0.572419\n",
      "[125]\ttraining's binary_logloss: 0.572385\n",
      "[126]\ttraining's binary_logloss: 0.572338\n",
      "[127]\ttraining's binary_logloss: 0.572285\n",
      "[128]\ttraining's binary_logloss: 0.572224\n",
      "[129]\ttraining's binary_logloss: 0.572174\n",
      "[130]\ttraining's binary_logloss: 0.572115\n",
      "[131]\ttraining's binary_logloss: 0.572103\n",
      "[132]\ttraining's binary_logloss: 0.572047\n",
      "[133]\ttraining's binary_logloss: 0.571975\n",
      "[134]\ttraining's binary_logloss: 0.57189\n",
      "[135]\ttraining's binary_logloss: 0.571819\n",
      "[136]\ttraining's binary_logloss: 0.571759\n",
      "[137]\ttraining's binary_logloss: 0.57168\n",
      "[138]\ttraining's binary_logloss: 0.571624\n",
      "[139]\ttraining's binary_logloss: 0.571549\n",
      "[140]\ttraining's binary_logloss: 0.571492\n",
      "[141]\ttraining's binary_logloss: 0.571425\n",
      "[142]\ttraining's binary_logloss: 0.571362\n",
      "[143]\ttraining's binary_logloss: 0.571308\n",
      "[144]\ttraining's binary_logloss: 0.571246\n",
      "[145]\ttraining's binary_logloss: 0.571208\n",
      "[146]\ttraining's binary_logloss: 0.571139\n",
      "[147]\ttraining's binary_logloss: 0.571083\n",
      "[148]\ttraining's binary_logloss: 0.571012\n",
      "[149]\ttraining's binary_logloss: 0.570955\n",
      "[150]\ttraining's binary_logloss: 0.570884\n",
      "[151]\ttraining's binary_logloss: 0.570793\n",
      "[152]\ttraining's binary_logloss: 0.570696\n",
      "[153]\ttraining's binary_logloss: 0.570618\n",
      "[154]\ttraining's binary_logloss: 0.57054\n",
      "[155]\ttraining's binary_logloss: 0.570448\n",
      "[156]\ttraining's binary_logloss: 0.570414\n",
      "[157]\ttraining's binary_logloss: 0.570393\n",
      "[158]\ttraining's binary_logloss: 0.57038\n",
      "[159]\ttraining's binary_logloss: 0.570368\n",
      "[160]\ttraining's binary_logloss: 0.57033\n",
      "[161]\ttraining's binary_logloss: 0.570247\n",
      "[162]\ttraining's binary_logloss: 0.570156\n",
      "[163]\ttraining's binary_logloss: 0.570078\n",
      "[164]\ttraining's binary_logloss: 0.570015\n",
      "[165]\ttraining's binary_logloss: 0.569921\n",
      "[166]\ttraining's binary_logloss: 0.569855\n",
      "[167]\ttraining's binary_logloss: 0.569793\n",
      "[168]\ttraining's binary_logloss: 0.569709\n",
      "[169]\ttraining's binary_logloss: 0.569634\n",
      "[170]\ttraining's binary_logloss: 0.569547\n",
      "[171]\ttraining's binary_logloss: 0.569452\n",
      "[172]\ttraining's binary_logloss: 0.569356\n",
      "[173]\ttraining's binary_logloss: 0.569267\n",
      "[174]\ttraining's binary_logloss: 0.569204\n",
      "[175]\ttraining's binary_logloss: 0.569127\n",
      "[176]\ttraining's binary_logloss: 0.569115\n",
      "[177]\ttraining's binary_logloss: 0.569045\n",
      "[178]\ttraining's binary_logloss: 0.568998\n",
      "[179]\ttraining's binary_logloss: 0.568953\n",
      "[180]\ttraining's binary_logloss: 0.568929\n",
      "[181]\ttraining's binary_logloss: 0.568857\n",
      "[182]\ttraining's binary_logloss: 0.568807\n",
      "[183]\ttraining's binary_logloss: 0.568763\n",
      "[184]\ttraining's binary_logloss: 0.568704\n",
      "[185]\ttraining's binary_logloss: 0.568602\n",
      "[186]\ttraining's binary_logloss: 0.568539\n",
      "[187]\ttraining's binary_logloss: 0.568463\n",
      "[188]\ttraining's binary_logloss: 0.568392\n",
      "[189]\ttraining's binary_logloss: 0.568357\n",
      "[190]\ttraining's binary_logloss: 0.5683\n",
      "[191]\ttraining's binary_logloss: 0.568215\n",
      "[192]\ttraining's binary_logloss: 0.56814\n",
      "[193]\ttraining's binary_logloss: 0.568067\n",
      "[194]\ttraining's binary_logloss: 0.567998\n",
      "[195]\ttraining's binary_logloss: 0.567914\n",
      "[196]\ttraining's binary_logloss: 0.567847\n",
      "[197]\ttraining's binary_logloss: 0.567777\n",
      "[198]\ttraining's binary_logloss: 0.567682\n",
      "[199]\ttraining's binary_logloss: 0.567592\n",
      "[200]\ttraining's binary_logloss: 0.567532\n",
      "[201]\ttraining's binary_logloss: 0.567458\n",
      "[202]\ttraining's binary_logloss: 0.567396\n",
      "[203]\ttraining's binary_logloss: 0.56733\n",
      "[204]\ttraining's binary_logloss: 0.567262\n",
      "[205]\ttraining's binary_logloss: 0.567214\n",
      "[206]\ttraining's binary_logloss: 0.567157\n",
      "[207]\ttraining's binary_logloss: 0.56708\n",
      "[208]\ttraining's binary_logloss: 0.567\n",
      "[209]\ttraining's binary_logloss: 0.56693\n",
      "[210]\ttraining's binary_logloss: 0.566867\n",
      "[211]\ttraining's binary_logloss: 0.5668\n",
      "[212]\ttraining's binary_logloss: 0.566708\n",
      "[213]\ttraining's binary_logloss: 0.566622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[214]\ttraining's binary_logloss: 0.56652\n",
      "[215]\ttraining's binary_logloss: 0.566442\n",
      "[216]\ttraining's binary_logloss: 0.566372\n",
      "[217]\ttraining's binary_logloss: 0.566298\n",
      "[218]\ttraining's binary_logloss: 0.566228\n",
      "[219]\ttraining's binary_logloss: 0.566124\n",
      "[220]\ttraining's binary_logloss: 0.566042\n",
      "[221]\ttraining's binary_logloss: 0.565914\n",
      "[222]\ttraining's binary_logloss: 0.56582\n",
      "[223]\ttraining's binary_logloss: 0.565717\n",
      "[224]\ttraining's binary_logloss: 0.565612\n",
      "[225]\ttraining's binary_logloss: 0.565489\n",
      "[226]\ttraining's binary_logloss: 0.565417\n",
      "[227]\ttraining's binary_logloss: 0.565337\n",
      "[228]\ttraining's binary_logloss: 0.56528\n",
      "[229]\ttraining's binary_logloss: 0.565205\n",
      "[230]\ttraining's binary_logloss: 0.56514\n",
      "[231]\ttraining's binary_logloss: 0.565042\n",
      "[232]\ttraining's binary_logloss: 0.564924\n",
      "[233]\ttraining's binary_logloss: 0.564815\n",
      "[234]\ttraining's binary_logloss: 0.564698\n",
      "[235]\ttraining's binary_logloss: 0.564607\n",
      "[236]\ttraining's binary_logloss: 0.564519\n",
      "[237]\ttraining's binary_logloss: 0.564395\n",
      "[238]\ttraining's binary_logloss: 0.564274\n",
      "[239]\ttraining's binary_logloss: 0.564158\n",
      "[240]\ttraining's binary_logloss: 0.564048\n",
      "[241]\ttraining's binary_logloss: 0.563942\n",
      "[242]\ttraining's binary_logloss: 0.563837\n",
      "[243]\ttraining's binary_logloss: 0.563751\n",
      "[244]\ttraining's binary_logloss: 0.563643\n",
      "[245]\ttraining's binary_logloss: 0.56354\n",
      "[246]\ttraining's binary_logloss: 0.5635\n",
      "[247]\ttraining's binary_logloss: 0.563458\n",
      "[248]\ttraining's binary_logloss: 0.563406\n",
      "[249]\ttraining's binary_logloss: 0.563376\n",
      "[250]\ttraining's binary_logloss: 0.563322\n",
      "[251]\ttraining's binary_logloss: 0.563219\n",
      "[252]\ttraining's binary_logloss: 0.563109\n",
      "[253]\ttraining's binary_logloss: 0.563023\n",
      "[254]\ttraining's binary_logloss: 0.56292\n",
      "[255]\ttraining's binary_logloss: 0.562809\n",
      "[256]\ttraining's binary_logloss: 0.562691\n",
      "[257]\ttraining's binary_logloss: 0.562557\n",
      "[258]\ttraining's binary_logloss: 0.562456\n",
      "[259]\ttraining's binary_logloss: 0.562403\n",
      "[260]\ttraining's binary_logloss: 0.56231\n",
      "[261]\ttraining's binary_logloss: 0.562213\n",
      "[262]\ttraining's binary_logloss: 0.562096\n",
      "[263]\ttraining's binary_logloss: 0.561958\n",
      "[264]\ttraining's binary_logloss: 0.561841\n",
      "[265]\ttraining's binary_logloss: 0.561713\n",
      "[266]\ttraining's binary_logloss: 0.561623\n",
      "[267]\ttraining's binary_logloss: 0.561556\n",
      "[268]\ttraining's binary_logloss: 0.561486\n",
      "[269]\ttraining's binary_logloss: 0.561428\n",
      "[270]\ttraining's binary_logloss: 0.561372\n",
      "[271]\ttraining's binary_logloss: 0.561246\n",
      "[272]\ttraining's binary_logloss: 0.56113\n",
      "[273]\ttraining's binary_logloss: 0.561016\n",
      "[274]\ttraining's binary_logloss: 0.560867\n",
      "[275]\ttraining's binary_logloss: 0.560738\n",
      "[276]\ttraining's binary_logloss: 0.560626\n",
      "[277]\ttraining's binary_logloss: 0.560513\n",
      "[278]\ttraining's binary_logloss: 0.560342\n",
      "[279]\ttraining's binary_logloss: 0.560222\n",
      "[280]\ttraining's binary_logloss: 0.560087\n",
      "[281]\ttraining's binary_logloss: 0.559983\n",
      "[282]\ttraining's binary_logloss: 0.559889\n",
      "[283]\ttraining's binary_logloss: 0.55982\n",
      "[284]\ttraining's binary_logloss: 0.559718\n",
      "[285]\ttraining's binary_logloss: 0.559613\n",
      "[286]\ttraining's binary_logloss: 0.559511\n",
      "[287]\ttraining's binary_logloss: 0.559398\n",
      "[288]\ttraining's binary_logloss: 0.559261\n",
      "[289]\ttraining's binary_logloss: 0.559159\n",
      "[290]\ttraining's binary_logloss: 0.559046\n",
      "[291]\ttraining's binary_logloss: 0.558913\n",
      "[292]\ttraining's binary_logloss: 0.558785\n",
      "[293]\ttraining's binary_logloss: 0.558641\n",
      "[294]\ttraining's binary_logloss: 0.558516\n",
      "[295]\ttraining's binary_logloss: 0.558395\n",
      "[296]\ttraining's binary_logloss: 0.558279\n",
      "[297]\ttraining's binary_logloss: 0.55816\n",
      "[298]\ttraining's binary_logloss: 0.558066\n",
      "[299]\ttraining's binary_logloss: 0.557955\n",
      "[300]\ttraining's binary_logloss: 0.557843\n",
      "[301]\ttraining's binary_logloss: 0.557709\n",
      "[302]\ttraining's binary_logloss: 0.557574\n",
      "[303]\ttraining's binary_logloss: 0.557442\n",
      "[304]\ttraining's binary_logloss: 0.557308\n",
      "[305]\ttraining's binary_logloss: 0.557187\n",
      "[306]\ttraining's binary_logloss: 0.557076\n",
      "[307]\ttraining's binary_logloss: 0.55698\n",
      "[308]\ttraining's binary_logloss: 0.556868\n",
      "[309]\ttraining's binary_logloss: 0.556736\n",
      "[310]\ttraining's binary_logloss: 0.556629\n",
      "[311]\ttraining's binary_logloss: 0.556529\n",
      "[312]\ttraining's binary_logloss: 0.556423\n",
      "[313]\ttraining's binary_logloss: 0.556327\n",
      "[314]\ttraining's binary_logloss: 0.556248\n",
      "[315]\ttraining's binary_logloss: 0.556149\n",
      "[316]\ttraining's binary_logloss: 0.555968\n",
      "[317]\ttraining's binary_logloss: 0.555812\n",
      "[318]\ttraining's binary_logloss: 0.555693\n",
      "[319]\ttraining's binary_logloss: 0.555561\n",
      "[320]\ttraining's binary_logloss: 0.555396\n",
      "[321]\ttraining's binary_logloss: 0.555243\n",
      "[322]\ttraining's binary_logloss: 0.555099\n",
      "[323]\ttraining's binary_logloss: 0.554962\n",
      "[324]\ttraining's binary_logloss: 0.554837\n",
      "[325]\ttraining's binary_logloss: 0.5547\n",
      "[326]\ttraining's binary_logloss: 0.554547\n",
      "[327]\ttraining's binary_logloss: 0.554408\n",
      "[328]\ttraining's binary_logloss: 0.554272\n",
      "[329]\ttraining's binary_logloss: 0.554146\n",
      "[330]\ttraining's binary_logloss: 0.554019\n",
      "[331]\ttraining's binary_logloss: 0.553888\n",
      "[332]\ttraining's binary_logloss: 0.553759\n",
      "[333]\ttraining's binary_logloss: 0.553615\n",
      "[334]\ttraining's binary_logloss: 0.553474\n",
      "[335]\ttraining's binary_logloss: 0.553355\n",
      "[336]\ttraining's binary_logloss: 0.553233\n",
      "[337]\ttraining's binary_logloss: 0.553112\n",
      "[338]\ttraining's binary_logloss: 0.553035\n",
      "[339]\ttraining's binary_logloss: 0.552918\n",
      "[340]\ttraining's binary_logloss: 0.552811\n",
      "[341]\ttraining's binary_logloss: 0.552693\n",
      "[342]\ttraining's binary_logloss: 0.552576\n",
      "[343]\ttraining's binary_logloss: 0.552463\n",
      "[344]\ttraining's binary_logloss: 0.552352\n",
      "[345]\ttraining's binary_logloss: 0.552245\n",
      "[346]\ttraining's binary_logloss: 0.552081\n",
      "[347]\ttraining's binary_logloss: 0.551932\n",
      "[348]\ttraining's binary_logloss: 0.551784\n",
      "[349]\ttraining's binary_logloss: 0.551673\n",
      "[350]\ttraining's binary_logloss: 0.551549\n",
      "[351]\ttraining's binary_logloss: 0.551409\n",
      "[352]\ttraining's binary_logloss: 0.551281\n",
      "[353]\ttraining's binary_logloss: 0.551155\n",
      "[354]\ttraining's binary_logloss: 0.55103\n",
      "[355]\ttraining's binary_logloss: 0.550904\n",
      "[356]\ttraining's binary_logloss: 0.550761\n",
      "[357]\ttraining's binary_logloss: 0.55062\n",
      "[358]\ttraining's binary_logloss: 0.550486\n",
      "[359]\ttraining's binary_logloss: 0.550353\n",
      "[360]\ttraining's binary_logloss: 0.550213\n",
      "[361]\ttraining's binary_logloss: 0.550042\n",
      "[362]\ttraining's binary_logloss: 0.549866\n",
      "[363]\ttraining's binary_logloss: 0.549711\n",
      "[364]\ttraining's binary_logloss: 0.549539\n",
      "[365]\ttraining's binary_logloss: 0.549366\n",
      "[366]\ttraining's binary_logloss: 0.549258\n",
      "[367]\ttraining's binary_logloss: 0.549133\n",
      "[368]\ttraining's binary_logloss: 0.549015\n",
      "[369]\ttraining's binary_logloss: 0.548924\n",
      "[370]\ttraining's binary_logloss: 0.548815\n",
      "[371]\ttraining's binary_logloss: 0.548705\n",
      "[372]\ttraining's binary_logloss: 0.548583\n",
      "[373]\ttraining's binary_logloss: 0.548459\n",
      "[374]\ttraining's binary_logloss: 0.548343\n",
      "[375]\ttraining's binary_logloss: 0.548245\n",
      "[376]\ttraining's binary_logloss: 0.548123\n",
      "[377]\ttraining's binary_logloss: 0.547983\n",
      "[378]\ttraining's binary_logloss: 0.547836\n",
      "[379]\ttraining's binary_logloss: 0.547687\n",
      "[380]\ttraining's binary_logloss: 0.547543\n",
      "[381]\ttraining's binary_logloss: 0.547445\n",
      "[382]\ttraining's binary_logloss: 0.547324\n",
      "[383]\ttraining's binary_logloss: 0.547213\n",
      "[384]\ttraining's binary_logloss: 0.547098\n",
      "[385]\ttraining's binary_logloss: 0.547012\n",
      "[386]\ttraining's binary_logloss: 0.546856\n",
      "[387]\ttraining's binary_logloss: 0.546648\n",
      "[388]\ttraining's binary_logloss: 0.546508\n",
      "[389]\ttraining's binary_logloss: 0.546317\n",
      "[390]\ttraining's binary_logloss: 0.54613\n",
      "[391]\ttraining's binary_logloss: 0.545996\n",
      "[392]\ttraining's binary_logloss: 0.545867\n",
      "[393]\ttraining's binary_logloss: 0.545731\n",
      "[394]\ttraining's binary_logloss: 0.545584\n",
      "[395]\ttraining's binary_logloss: 0.545458\n",
      "[396]\ttraining's binary_logloss: 0.545272\n",
      "[397]\ttraining's binary_logloss: 0.545094\n",
      "[398]\ttraining's binary_logloss: 0.544946\n",
      "[399]\ttraining's binary_logloss: 0.544819\n",
      "[400]\ttraining's binary_logloss: 0.544636\n",
      "[401]\ttraining's binary_logloss: 0.544432\n",
      "[402]\ttraining's binary_logloss: 0.544238\n",
      "[403]\ttraining's binary_logloss: 0.544049\n",
      "[404]\ttraining's binary_logloss: 0.543867\n",
      "[405]\ttraining's binary_logloss: 0.5437\n",
      "[406]\ttraining's binary_logloss: 0.54358\n",
      "[407]\ttraining's binary_logloss: 0.543461\n",
      "[408]\ttraining's binary_logloss: 0.543336\n",
      "[409]\ttraining's binary_logloss: 0.543223\n",
      "[410]\ttraining's binary_logloss: 0.543102\n",
      "[411]\ttraining's binary_logloss: 0.542903\n",
      "[412]\ttraining's binary_logloss: 0.54273\n",
      "[413]\ttraining's binary_logloss: 0.542567\n",
      "[414]\ttraining's binary_logloss: 0.542383\n",
      "[415]\ttraining's binary_logloss: 0.542194\n",
      "[416]\ttraining's binary_logloss: 0.542013\n",
      "[417]\ttraining's binary_logloss: 0.541847\n",
      "[418]\ttraining's binary_logloss: 0.541693\n",
      "[419]\ttraining's binary_logloss: 0.541558\n",
      "[420]\ttraining's binary_logloss: 0.541394\n",
      "[421]\ttraining's binary_logloss: 0.541284\n",
      "[422]\ttraining's binary_logloss: 0.541177\n",
      "[423]\ttraining's binary_logloss: 0.541084\n",
      "[424]\ttraining's binary_logloss: 0.540989\n",
      "[425]\ttraining's binary_logloss: 0.540882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[426]\ttraining's binary_logloss: 0.540748\n",
      "[427]\ttraining's binary_logloss: 0.540632\n",
      "[428]\ttraining's binary_logloss: 0.540516\n",
      "[429]\ttraining's binary_logloss: 0.540422\n",
      "[430]\ttraining's binary_logloss: 0.540325\n",
      "[431]\ttraining's binary_logloss: 0.540177\n",
      "[432]\ttraining's binary_logloss: 0.540035\n",
      "[433]\ttraining's binary_logloss: 0.539885\n",
      "[434]\ttraining's binary_logloss: 0.539741\n",
      "[435]\ttraining's binary_logloss: 0.539606\n",
      "[436]\ttraining's binary_logloss: 0.539479\n",
      "[437]\ttraining's binary_logloss: 0.539347\n",
      "[438]\ttraining's binary_logloss: 0.539227\n",
      "[439]\ttraining's binary_logloss: 0.53909\n",
      "[440]\ttraining's binary_logloss: 0.538959\n",
      "[441]\ttraining's binary_logloss: 0.538819\n",
      "[442]\ttraining's binary_logloss: 0.538678\n",
      "[443]\ttraining's binary_logloss: 0.538528\n",
      "[444]\ttraining's binary_logloss: 0.53836\n",
      "[445]\ttraining's binary_logloss: 0.538218\n",
      "[446]\ttraining's binary_logloss: 0.538065\n",
      "[447]\ttraining's binary_logloss: 0.537925\n",
      "[448]\ttraining's binary_logloss: 0.537757\n",
      "[449]\ttraining's binary_logloss: 0.537593\n",
      "[450]\ttraining's binary_logloss: 0.537443\n",
      "[451]\ttraining's binary_logloss: 0.537309\n",
      "[452]\ttraining's binary_logloss: 0.537186\n",
      "[453]\ttraining's binary_logloss: 0.537075\n",
      "[454]\ttraining's binary_logloss: 0.536952\n",
      "[455]\ttraining's binary_logloss: 0.536836\n",
      "[456]\ttraining's binary_logloss: 0.536716\n",
      "[457]\ttraining's binary_logloss: 0.536617\n",
      "[458]\ttraining's binary_logloss: 0.536499\n",
      "[459]\ttraining's binary_logloss: 0.536353\n",
      "[460]\ttraining's binary_logloss: 0.536237\n",
      "[461]\ttraining's binary_logloss: 0.536058\n",
      "[462]\ttraining's binary_logloss: 0.535896\n",
      "[463]\ttraining's binary_logloss: 0.535748\n",
      "[464]\ttraining's binary_logloss: 0.535609\n",
      "[465]\ttraining's binary_logloss: 0.535448\n",
      "[466]\ttraining's binary_logloss: 0.535326\n",
      "[467]\ttraining's binary_logloss: 0.535162\n",
      "[468]\ttraining's binary_logloss: 0.535003\n",
      "[469]\ttraining's binary_logloss: 0.534854\n",
      "[470]\ttraining's binary_logloss: 0.5347\n",
      "[471]\ttraining's binary_logloss: 0.534567\n",
      "[472]\ttraining's binary_logloss: 0.534454\n",
      "[473]\ttraining's binary_logloss: 0.534328\n",
      "[474]\ttraining's binary_logloss: 0.534223\n",
      "[475]\ttraining's binary_logloss: 0.534088\n",
      "[476]\ttraining's binary_logloss: 0.533942\n",
      "[477]\ttraining's binary_logloss: 0.533809\n",
      "[478]\ttraining's binary_logloss: 0.533676\n",
      "[479]\ttraining's binary_logloss: 0.533518\n",
      "[480]\ttraining's binary_logloss: 0.533385\n",
      "[481]\ttraining's binary_logloss: 0.53325\n",
      "[482]\ttraining's binary_logloss: 0.53312\n",
      "[483]\ttraining's binary_logloss: 0.532979\n",
      "[484]\ttraining's binary_logloss: 0.53286\n",
      "[485]\ttraining's binary_logloss: 0.53273\n",
      "[486]\ttraining's binary_logloss: 0.532582\n",
      "[487]\ttraining's binary_logloss: 0.532429\n",
      "[488]\ttraining's binary_logloss: 0.532273\n",
      "[489]\ttraining's binary_logloss: 0.532118\n",
      "[490]\ttraining's binary_logloss: 0.531985\n",
      "[491]\ttraining's binary_logloss: 0.531902\n",
      "[492]\ttraining's binary_logloss: 0.53182\n",
      "[493]\ttraining's binary_logloss: 0.531743\n",
      "[494]\ttraining's binary_logloss: 0.531659\n",
      "[495]\ttraining's binary_logloss: 0.531571\n",
      "[496]\ttraining's binary_logloss: 0.531431\n",
      "[497]\ttraining's binary_logloss: 0.531293\n",
      "[498]\ttraining's binary_logloss: 0.531131\n",
      "[499]\ttraining's binary_logloss: 0.531006\n",
      "[500]\ttraining's binary_logloss: 0.530856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613761\n",
      "[2]\ttraining's binary_logloss: 0.612276\n",
      "[3]\ttraining's binary_logloss: 0.610845\n",
      "[4]\ttraining's binary_logloss: 0.60946\n",
      "[5]\ttraining's binary_logloss: 0.60818\n",
      "[6]\ttraining's binary_logloss: 0.606991\n",
      "[7]\ttraining's binary_logloss: 0.605854\n",
      "[8]\ttraining's binary_logloss: 0.604778\n",
      "[9]\ttraining's binary_logloss: 0.60372\n",
      "[10]\ttraining's binary_logloss: 0.602679\n",
      "[11]\ttraining's binary_logloss: 0.601574\n",
      "[12]\ttraining's binary_logloss: 0.600723\n",
      "[13]\ttraining's binary_logloss: 0.599859\n",
      "[14]\ttraining's binary_logloss: 0.598868\n",
      "[15]\ttraining's binary_logloss: 0.597943\n",
      "[16]\ttraining's binary_logloss: 0.597039\n",
      "[17]\ttraining's binary_logloss: 0.596174\n",
      "[18]\ttraining's binary_logloss: 0.595326\n",
      "[19]\ttraining's binary_logloss: 0.594513\n",
      "[20]\ttraining's binary_logloss: 0.593852\n",
      "[21]\ttraining's binary_logloss: 0.593178\n",
      "[22]\ttraining's binary_logloss: 0.592497\n",
      "[23]\ttraining's binary_logloss: 0.591867\n",
      "[24]\ttraining's binary_logloss: 0.59115\n",
      "[25]\ttraining's binary_logloss: 0.590469\n",
      "[26]\ttraining's binary_logloss: 0.589878\n",
      "[27]\ttraining's binary_logloss: 0.589295\n",
      "[28]\ttraining's binary_logloss: 0.58871\n",
      "[29]\ttraining's binary_logloss: 0.588149\n",
      "[30]\ttraining's binary_logloss: 0.587611\n",
      "[31]\ttraining's binary_logloss: 0.586995\n",
      "[32]\ttraining's binary_logloss: 0.586392\n",
      "[33]\ttraining's binary_logloss: 0.5858\n",
      "[34]\ttraining's binary_logloss: 0.585252\n",
      "[35]\ttraining's binary_logloss: 0.58465\n",
      "[36]\ttraining's binary_logloss: 0.584073\n",
      "[37]\ttraining's binary_logloss: 0.5836\n",
      "[38]\ttraining's binary_logloss: 0.583062\n",
      "[39]\ttraining's binary_logloss: 0.582545\n",
      "[40]\ttraining's binary_logloss: 0.582049\n",
      "[41]\ttraining's binary_logloss: 0.581642\n",
      "[42]\ttraining's binary_logloss: 0.581289\n",
      "[43]\ttraining's binary_logloss: 0.580913\n",
      "[44]\ttraining's binary_logloss: 0.580541\n",
      "[45]\ttraining's binary_logloss: 0.580183\n",
      "[46]\ttraining's binary_logloss: 0.579857\n",
      "[47]\ttraining's binary_logloss: 0.579455\n",
      "[48]\ttraining's binary_logloss: 0.579065\n",
      "[49]\ttraining's binary_logloss: 0.578698\n",
      "[50]\ttraining's binary_logloss: 0.578344\n",
      "[51]\ttraining's binary_logloss: 0.577997\n",
      "[52]\ttraining's binary_logloss: 0.577657\n",
      "[53]\ttraining's binary_logloss: 0.577366\n",
      "[54]\ttraining's binary_logloss: 0.577032\n",
      "[55]\ttraining's binary_logloss: 0.576755\n",
      "[56]\ttraining's binary_logloss: 0.576416\n",
      "[57]\ttraining's binary_logloss: 0.576091\n",
      "[58]\ttraining's binary_logloss: 0.575843\n",
      "[59]\ttraining's binary_logloss: 0.575554\n",
      "[60]\ttraining's binary_logloss: 0.575261\n",
      "[61]\ttraining's binary_logloss: 0.574977\n",
      "[62]\ttraining's binary_logloss: 0.574698\n",
      "[63]\ttraining's binary_logloss: 0.574434\n",
      "[64]\ttraining's binary_logloss: 0.574191\n",
      "[65]\ttraining's binary_logloss: 0.573951\n",
      "[66]\ttraining's binary_logloss: 0.573713\n",
      "[67]\ttraining's binary_logloss: 0.573487\n",
      "[68]\ttraining's binary_logloss: 0.57326\n",
      "[69]\ttraining's binary_logloss: 0.573059\n",
      "[70]\ttraining's binary_logloss: 0.572853\n",
      "[71]\ttraining's binary_logloss: 0.57269\n",
      "[72]\ttraining's binary_logloss: 0.572472\n",
      "[73]\ttraining's binary_logloss: 0.57232\n",
      "[74]\ttraining's binary_logloss: 0.572142\n",
      "[75]\ttraining's binary_logloss: 0.572003\n",
      "[76]\ttraining's binary_logloss: 0.57176\n",
      "[77]\ttraining's binary_logloss: 0.57152\n",
      "[78]\ttraining's binary_logloss: 0.571297\n",
      "[79]\ttraining's binary_logloss: 0.571127\n",
      "[80]\ttraining's binary_logloss: 0.570978\n",
      "[81]\ttraining's binary_logloss: 0.570821\n",
      "[82]\ttraining's binary_logloss: 0.570664\n",
      "[83]\ttraining's binary_logloss: 0.570515\n",
      "[84]\ttraining's binary_logloss: 0.570373\n",
      "[85]\ttraining's binary_logloss: 0.570253\n",
      "[86]\ttraining's binary_logloss: 0.570172\n",
      "[87]\ttraining's binary_logloss: 0.570001\n",
      "[88]\ttraining's binary_logloss: 0.569833\n",
      "[89]\ttraining's binary_logloss: 0.569718\n",
      "[90]\ttraining's binary_logloss: 0.569618\n",
      "[91]\ttraining's binary_logloss: 0.569483\n",
      "[92]\ttraining's binary_logloss: 0.569357\n",
      "[93]\ttraining's binary_logloss: 0.569249\n",
      "[94]\ttraining's binary_logloss: 0.569146\n",
      "[95]\ttraining's binary_logloss: 0.569039\n",
      "[96]\ttraining's binary_logloss: 0.568907\n",
      "[97]\ttraining's binary_logloss: 0.568813\n",
      "[98]\ttraining's binary_logloss: 0.568748\n",
      "[99]\ttraining's binary_logloss: 0.568635\n",
      "[100]\ttraining's binary_logloss: 0.568537\n",
      "[101]\ttraining's binary_logloss: 0.568452\n",
      "[102]\ttraining's binary_logloss: 0.568383\n",
      "[103]\ttraining's binary_logloss: 0.5683\n",
      "[104]\ttraining's binary_logloss: 0.568218\n",
      "[105]\ttraining's binary_logloss: 0.568164\n",
      "[106]\ttraining's binary_logloss: 0.568014\n",
      "[107]\ttraining's binary_logloss: 0.5679\n",
      "[108]\ttraining's binary_logloss: 0.567814\n",
      "[109]\ttraining's binary_logloss: 0.567688\n",
      "[110]\ttraining's binary_logloss: 0.567617\n",
      "[111]\ttraining's binary_logloss: 0.567515\n",
      "[112]\ttraining's binary_logloss: 0.567423\n",
      "[113]\ttraining's binary_logloss: 0.567346\n",
      "[114]\ttraining's binary_logloss: 0.567245\n",
      "[115]\ttraining's binary_logloss: 0.567161\n",
      "[116]\ttraining's binary_logloss: 0.567066\n",
      "[117]\ttraining's binary_logloss: 0.567036\n",
      "[118]\ttraining's binary_logloss: 0.56703\n",
      "[119]\ttraining's binary_logloss: 0.567014\n",
      "[120]\ttraining's binary_logloss: 0.566976\n",
      "[121]\ttraining's binary_logloss: 0.566858\n",
      "[122]\ttraining's binary_logloss: 0.56675\n",
      "[123]\ttraining's binary_logloss: 0.566649\n",
      "[124]\ttraining's binary_logloss: 0.566593\n",
      "[125]\ttraining's binary_logloss: 0.566497\n",
      "[126]\ttraining's binary_logloss: 0.566426\n",
      "[127]\ttraining's binary_logloss: 0.566318\n",
      "[128]\ttraining's binary_logloss: 0.566205\n",
      "[129]\ttraining's binary_logloss: 0.566118\n",
      "[130]\ttraining's binary_logloss: 0.566017\n",
      "[131]\ttraining's binary_logloss: 0.565908\n",
      "[132]\ttraining's binary_logloss: 0.565832\n",
      "[133]\ttraining's binary_logloss: 0.56572\n",
      "[134]\ttraining's binary_logloss: 0.565631\n",
      "[135]\ttraining's binary_logloss: 0.565547\n",
      "[136]\ttraining's binary_logloss: 0.565465\n",
      "[137]\ttraining's binary_logloss: 0.565371\n",
      "[138]\ttraining's binary_logloss: 0.565281\n",
      "[139]\ttraining's binary_logloss: 0.565208\n",
      "[140]\ttraining's binary_logloss: 0.565164\n",
      "[141]\ttraining's binary_logloss: 0.565091\n",
      "[142]\ttraining's binary_logloss: 0.56502\n",
      "[143]\ttraining's binary_logloss: 0.56495\n",
      "[144]\ttraining's binary_logloss: 0.564872\n",
      "[145]\ttraining's binary_logloss: 0.564812\n",
      "[146]\ttraining's binary_logloss: 0.564729\n",
      "[147]\ttraining's binary_logloss: 0.564667\n",
      "[148]\ttraining's binary_logloss: 0.564611\n",
      "[149]\ttraining's binary_logloss: 0.564535\n",
      "[150]\ttraining's binary_logloss: 0.564466\n",
      "[151]\ttraining's binary_logloss: 0.564382\n",
      "[152]\ttraining's binary_logloss: 0.564291\n",
      "[153]\ttraining's binary_logloss: 0.564211\n",
      "[154]\ttraining's binary_logloss: 0.56412\n",
      "[155]\ttraining's binary_logloss: 0.564044\n",
      "[156]\ttraining's binary_logloss: 0.563993\n",
      "[157]\ttraining's binary_logloss: 0.563927\n",
      "[158]\ttraining's binary_logloss: 0.563847\n",
      "[159]\ttraining's binary_logloss: 0.563788\n",
      "[160]\ttraining's binary_logloss: 0.563738\n",
      "[161]\ttraining's binary_logloss: 0.563641\n",
      "[162]\ttraining's binary_logloss: 0.56355\n",
      "[163]\ttraining's binary_logloss: 0.563454\n",
      "[164]\ttraining's binary_logloss: 0.563359\n",
      "[165]\ttraining's binary_logloss: 0.563236\n",
      "[166]\ttraining's binary_logloss: 0.563124\n",
      "[167]\ttraining's binary_logloss: 0.562998\n",
      "[168]\ttraining's binary_logloss: 0.562869\n",
      "[169]\ttraining's binary_logloss: 0.562751\n",
      "[170]\ttraining's binary_logloss: 0.562627\n",
      "[171]\ttraining's binary_logloss: 0.562537\n",
      "[172]\ttraining's binary_logloss: 0.562449\n",
      "[173]\ttraining's binary_logloss: 0.562363\n",
      "[174]\ttraining's binary_logloss: 0.562275\n",
      "[175]\ttraining's binary_logloss: 0.562163\n",
      "[176]\ttraining's binary_logloss: 0.562075\n",
      "[177]\ttraining's binary_logloss: 0.561992\n",
      "[178]\ttraining's binary_logloss: 0.561912\n",
      "[179]\ttraining's binary_logloss: 0.561835\n",
      "[180]\ttraining's binary_logloss: 0.561761\n",
      "[181]\ttraining's binary_logloss: 0.561674\n",
      "[182]\ttraining's binary_logloss: 0.561607\n",
      "[183]\ttraining's binary_logloss: 0.561521\n",
      "[184]\ttraining's binary_logloss: 0.561453\n",
      "[185]\ttraining's binary_logloss: 0.561393\n",
      "[186]\ttraining's binary_logloss: 0.561281\n",
      "[187]\ttraining's binary_logloss: 0.561176\n",
      "[188]\ttraining's binary_logloss: 0.561077\n",
      "[189]\ttraining's binary_logloss: 0.560985\n",
      "[190]\ttraining's binary_logloss: 0.560899\n",
      "[191]\ttraining's binary_logloss: 0.560792\n",
      "[192]\ttraining's binary_logloss: 0.56069\n",
      "[193]\ttraining's binary_logloss: 0.560613\n",
      "[194]\ttraining's binary_logloss: 0.560518\n",
      "[195]\ttraining's binary_logloss: 0.560429\n",
      "[196]\ttraining's binary_logloss: 0.560326\n",
      "[197]\ttraining's binary_logloss: 0.560219\n",
      "[198]\ttraining's binary_logloss: 0.56012\n",
      "[199]\ttraining's binary_logloss: 0.560025\n",
      "[200]\ttraining's binary_logloss: 0.559942\n",
      "[201]\ttraining's binary_logloss: 0.55984\n",
      "[202]\ttraining's binary_logloss: 0.559761\n",
      "[203]\ttraining's binary_logloss: 0.559684\n",
      "[204]\ttraining's binary_logloss: 0.559592\n",
      "[205]\ttraining's binary_logloss: 0.559526\n",
      "[206]\ttraining's binary_logloss: 0.559443\n",
      "[207]\ttraining's binary_logloss: 0.55936\n",
      "[208]\ttraining's binary_logloss: 0.559291\n",
      "[209]\ttraining's binary_logloss: 0.559221\n",
      "[210]\ttraining's binary_logloss: 0.559102\n",
      "[211]\ttraining's binary_logloss: 0.559036\n",
      "[212]\ttraining's binary_logloss: 0.558968\n",
      "[213]\ttraining's binary_logloss: 0.558918\n",
      "[214]\ttraining's binary_logloss: 0.558864\n",
      "[215]\ttraining's binary_logloss: 0.558816\n",
      "[216]\ttraining's binary_logloss: 0.55868\n",
      "[217]\ttraining's binary_logloss: 0.558562\n",
      "[218]\ttraining's binary_logloss: 0.558431\n",
      "[219]\ttraining's binary_logloss: 0.558301\n",
      "[220]\ttraining's binary_logloss: 0.55819\n",
      "[221]\ttraining's binary_logloss: 0.558048\n",
      "[222]\ttraining's binary_logloss: 0.557978\n",
      "[223]\ttraining's binary_logloss: 0.557846\n",
      "[224]\ttraining's binary_logloss: 0.557712\n",
      "[225]\ttraining's binary_logloss: 0.557604\n",
      "[226]\ttraining's binary_logloss: 0.557515\n",
      "[227]\ttraining's binary_logloss: 0.557447\n",
      "[228]\ttraining's binary_logloss: 0.557375\n",
      "[229]\ttraining's binary_logloss: 0.557296\n",
      "[230]\ttraining's binary_logloss: 0.557229\n",
      "[231]\ttraining's binary_logloss: 0.557114\n",
      "[232]\ttraining's binary_logloss: 0.557014\n",
      "[233]\ttraining's binary_logloss: 0.556923\n",
      "[234]\ttraining's binary_logloss: 0.556818\n",
      "[235]\ttraining's binary_logloss: 0.556708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[236]\ttraining's binary_logloss: 0.55658\n",
      "[237]\ttraining's binary_logloss: 0.556452\n",
      "[238]\ttraining's binary_logloss: 0.556331\n",
      "[239]\ttraining's binary_logloss: 0.556206\n",
      "[240]\ttraining's binary_logloss: 0.556076\n",
      "[241]\ttraining's binary_logloss: 0.555959\n",
      "[242]\ttraining's binary_logloss: 0.55587\n",
      "[243]\ttraining's binary_logloss: 0.555758\n",
      "[244]\ttraining's binary_logloss: 0.555649\n",
      "[245]\ttraining's binary_logloss: 0.555544\n",
      "[246]\ttraining's binary_logloss: 0.555425\n",
      "[247]\ttraining's binary_logloss: 0.555317\n",
      "[248]\ttraining's binary_logloss: 0.555214\n",
      "[249]\ttraining's binary_logloss: 0.555102\n",
      "[250]\ttraining's binary_logloss: 0.554962\n",
      "[251]\ttraining's binary_logloss: 0.554875\n",
      "[252]\ttraining's binary_logloss: 0.554772\n",
      "[253]\ttraining's binary_logloss: 0.554684\n",
      "[254]\ttraining's binary_logloss: 0.554599\n",
      "[255]\ttraining's binary_logloss: 0.554522\n",
      "[256]\ttraining's binary_logloss: 0.554407\n",
      "[257]\ttraining's binary_logloss: 0.55426\n",
      "[258]\ttraining's binary_logloss: 0.554133\n",
      "[259]\ttraining's binary_logloss: 0.554006\n",
      "[260]\ttraining's binary_logloss: 0.553878\n",
      "[261]\ttraining's binary_logloss: 0.553774\n",
      "[262]\ttraining's binary_logloss: 0.55366\n",
      "[263]\ttraining's binary_logloss: 0.553562\n",
      "[264]\ttraining's binary_logloss: 0.553477\n",
      "[265]\ttraining's binary_logloss: 0.553385\n",
      "[266]\ttraining's binary_logloss: 0.553295\n",
      "[267]\ttraining's binary_logloss: 0.553232\n",
      "[268]\ttraining's binary_logloss: 0.553182\n",
      "[269]\ttraining's binary_logloss: 0.553124\n",
      "[270]\ttraining's binary_logloss: 0.553065\n",
      "[271]\ttraining's binary_logloss: 0.552899\n",
      "[272]\ttraining's binary_logloss: 0.552755\n",
      "[273]\ttraining's binary_logloss: 0.552603\n",
      "[274]\ttraining's binary_logloss: 0.552459\n",
      "[275]\ttraining's binary_logloss: 0.552299\n",
      "[276]\ttraining's binary_logloss: 0.552131\n",
      "[277]\ttraining's binary_logloss: 0.551976\n",
      "[278]\ttraining's binary_logloss: 0.55182\n",
      "[279]\ttraining's binary_logloss: 0.551666\n",
      "[280]\ttraining's binary_logloss: 0.551506\n",
      "[281]\ttraining's binary_logloss: 0.55138\n",
      "[282]\ttraining's binary_logloss: 0.551258\n",
      "[283]\ttraining's binary_logloss: 0.551148\n",
      "[284]\ttraining's binary_logloss: 0.551025\n",
      "[285]\ttraining's binary_logloss: 0.550897\n",
      "[286]\ttraining's binary_logloss: 0.550768\n",
      "[287]\ttraining's binary_logloss: 0.550656\n",
      "[288]\ttraining's binary_logloss: 0.55054\n",
      "[289]\ttraining's binary_logloss: 0.550396\n",
      "[290]\ttraining's binary_logloss: 0.550265\n",
      "[291]\ttraining's binary_logloss: 0.550121\n",
      "[292]\ttraining's binary_logloss: 0.549982\n",
      "[293]\ttraining's binary_logloss: 0.54983\n",
      "[294]\ttraining's binary_logloss: 0.549696\n",
      "[295]\ttraining's binary_logloss: 0.549568\n",
      "[296]\ttraining's binary_logloss: 0.549456\n",
      "[297]\ttraining's binary_logloss: 0.549359\n",
      "[298]\ttraining's binary_logloss: 0.549263\n",
      "[299]\ttraining's binary_logloss: 0.549165\n",
      "[300]\ttraining's binary_logloss: 0.549076\n",
      "[301]\ttraining's binary_logloss: 0.548962\n",
      "[302]\ttraining's binary_logloss: 0.548819\n",
      "[303]\ttraining's binary_logloss: 0.548669\n",
      "[304]\ttraining's binary_logloss: 0.548527\n",
      "[305]\ttraining's binary_logloss: 0.548384\n",
      "[306]\ttraining's binary_logloss: 0.548277\n",
      "[307]\ttraining's binary_logloss: 0.548143\n",
      "[308]\ttraining's binary_logloss: 0.548011\n",
      "[309]\ttraining's binary_logloss: 0.547893\n",
      "[310]\ttraining's binary_logloss: 0.547764\n",
      "[311]\ttraining's binary_logloss: 0.547661\n",
      "[312]\ttraining's binary_logloss: 0.547552\n",
      "[313]\ttraining's binary_logloss: 0.547436\n",
      "[314]\ttraining's binary_logloss: 0.547327\n",
      "[315]\ttraining's binary_logloss: 0.547225\n",
      "[316]\ttraining's binary_logloss: 0.547101\n",
      "[317]\ttraining's binary_logloss: 0.54699\n",
      "[318]\ttraining's binary_logloss: 0.546865\n",
      "[319]\ttraining's binary_logloss: 0.546744\n",
      "[320]\ttraining's binary_logloss: 0.546631\n",
      "[321]\ttraining's binary_logloss: 0.546516\n",
      "[322]\ttraining's binary_logloss: 0.546419\n",
      "[323]\ttraining's binary_logloss: 0.546301\n",
      "[324]\ttraining's binary_logloss: 0.546193\n",
      "[325]\ttraining's binary_logloss: 0.546072\n",
      "[326]\ttraining's binary_logloss: 0.545933\n",
      "[327]\ttraining's binary_logloss: 0.545811\n",
      "[328]\ttraining's binary_logloss: 0.545686\n",
      "[329]\ttraining's binary_logloss: 0.545546\n",
      "[330]\ttraining's binary_logloss: 0.545409\n",
      "[331]\ttraining's binary_logloss: 0.545258\n",
      "[332]\ttraining's binary_logloss: 0.545109\n",
      "[333]\ttraining's binary_logloss: 0.544974\n",
      "[334]\ttraining's binary_logloss: 0.54482\n",
      "[335]\ttraining's binary_logloss: 0.544674\n",
      "[336]\ttraining's binary_logloss: 0.544558\n",
      "[337]\ttraining's binary_logloss: 0.544423\n",
      "[338]\ttraining's binary_logloss: 0.54429\n",
      "[339]\ttraining's binary_logloss: 0.544175\n",
      "[340]\ttraining's binary_logloss: 0.544048\n",
      "[341]\ttraining's binary_logloss: 0.543932\n",
      "[342]\ttraining's binary_logloss: 0.543823\n",
      "[343]\ttraining's binary_logloss: 0.543716\n",
      "[344]\ttraining's binary_logloss: 0.543621\n",
      "[345]\ttraining's binary_logloss: 0.543527\n",
      "[346]\ttraining's binary_logloss: 0.543405\n",
      "[347]\ttraining's binary_logloss: 0.543274\n",
      "[348]\ttraining's binary_logloss: 0.543141\n",
      "[349]\ttraining's binary_logloss: 0.543039\n",
      "[350]\ttraining's binary_logloss: 0.542946\n",
      "[351]\ttraining's binary_logloss: 0.542781\n",
      "[352]\ttraining's binary_logloss: 0.542633\n",
      "[353]\ttraining's binary_logloss: 0.542491\n",
      "[354]\ttraining's binary_logloss: 0.542348\n",
      "[355]\ttraining's binary_logloss: 0.542192\n",
      "[356]\ttraining's binary_logloss: 0.542006\n",
      "[357]\ttraining's binary_logloss: 0.541843\n",
      "[358]\ttraining's binary_logloss: 0.541678\n",
      "[359]\ttraining's binary_logloss: 0.541511\n",
      "[360]\ttraining's binary_logloss: 0.541351\n",
      "[361]\ttraining's binary_logloss: 0.541197\n",
      "[362]\ttraining's binary_logloss: 0.54104\n",
      "[363]\ttraining's binary_logloss: 0.540892\n",
      "[364]\ttraining's binary_logloss: 0.540724\n",
      "[365]\ttraining's binary_logloss: 0.540546\n",
      "[366]\ttraining's binary_logloss: 0.540402\n",
      "[367]\ttraining's binary_logloss: 0.540278\n",
      "[368]\ttraining's binary_logloss: 0.54015\n",
      "[369]\ttraining's binary_logloss: 0.540004\n",
      "[370]\ttraining's binary_logloss: 0.539879\n",
      "[371]\ttraining's binary_logloss: 0.53978\n",
      "[372]\ttraining's binary_logloss: 0.539671\n",
      "[373]\ttraining's binary_logloss: 0.539571\n",
      "[374]\ttraining's binary_logloss: 0.539476\n",
      "[375]\ttraining's binary_logloss: 0.539395\n",
      "[376]\ttraining's binary_logloss: 0.539235\n",
      "[377]\ttraining's binary_logloss: 0.539097\n",
      "[378]\ttraining's binary_logloss: 0.538974\n",
      "[379]\ttraining's binary_logloss: 0.538828\n",
      "[380]\ttraining's binary_logloss: 0.538678\n",
      "[381]\ttraining's binary_logloss: 0.538582\n",
      "[382]\ttraining's binary_logloss: 0.538496\n",
      "[383]\ttraining's binary_logloss: 0.538387\n",
      "[384]\ttraining's binary_logloss: 0.538313\n",
      "[385]\ttraining's binary_logloss: 0.538214\n",
      "[386]\ttraining's binary_logloss: 0.53804\n",
      "[387]\ttraining's binary_logloss: 0.537862\n",
      "[388]\ttraining's binary_logloss: 0.537702\n",
      "[389]\ttraining's binary_logloss: 0.537549\n",
      "[390]\ttraining's binary_logloss: 0.537401\n",
      "[391]\ttraining's binary_logloss: 0.537253\n",
      "[392]\ttraining's binary_logloss: 0.537098\n",
      "[393]\ttraining's binary_logloss: 0.536947\n",
      "[394]\ttraining's binary_logloss: 0.536813\n",
      "[395]\ttraining's binary_logloss: 0.536671\n",
      "[396]\ttraining's binary_logloss: 0.536535\n",
      "[397]\ttraining's binary_logloss: 0.536426\n",
      "[398]\ttraining's binary_logloss: 0.536313\n",
      "[399]\ttraining's binary_logloss: 0.536184\n",
      "[400]\ttraining's binary_logloss: 0.536055\n",
      "[401]\ttraining's binary_logloss: 0.535923\n",
      "[402]\ttraining's binary_logloss: 0.535764\n",
      "[403]\ttraining's binary_logloss: 0.535597\n",
      "[404]\ttraining's binary_logloss: 0.53545\n",
      "[405]\ttraining's binary_logloss: 0.535287\n",
      "[406]\ttraining's binary_logloss: 0.535155\n",
      "[407]\ttraining's binary_logloss: 0.534998\n",
      "[408]\ttraining's binary_logloss: 0.534866\n",
      "[409]\ttraining's binary_logloss: 0.534744\n",
      "[410]\ttraining's binary_logloss: 0.534625\n",
      "[411]\ttraining's binary_logloss: 0.53444\n",
      "[412]\ttraining's binary_logloss: 0.534273\n",
      "[413]\ttraining's binary_logloss: 0.534111\n",
      "[414]\ttraining's binary_logloss: 0.533969\n",
      "[415]\ttraining's binary_logloss: 0.533824\n",
      "[416]\ttraining's binary_logloss: 0.533709\n",
      "[417]\ttraining's binary_logloss: 0.533588\n",
      "[418]\ttraining's binary_logloss: 0.533447\n",
      "[419]\ttraining's binary_logloss: 0.533329\n",
      "[420]\ttraining's binary_logloss: 0.533186\n",
      "[421]\ttraining's binary_logloss: 0.533036\n",
      "[422]\ttraining's binary_logloss: 0.532952\n",
      "[423]\ttraining's binary_logloss: 0.532808\n",
      "[424]\ttraining's binary_logloss: 0.53267\n",
      "[425]\ttraining's binary_logloss: 0.532559\n",
      "[426]\ttraining's binary_logloss: 0.532413\n",
      "[427]\ttraining's binary_logloss: 0.532311\n",
      "[428]\ttraining's binary_logloss: 0.532173\n",
      "[429]\ttraining's binary_logloss: 0.53204\n",
      "[430]\ttraining's binary_logloss: 0.531933\n",
      "[431]\ttraining's binary_logloss: 0.531777\n",
      "[432]\ttraining's binary_logloss: 0.531604\n",
      "[433]\ttraining's binary_logloss: 0.531426\n",
      "[434]\ttraining's binary_logloss: 0.531252\n",
      "[435]\ttraining's binary_logloss: 0.531082\n",
      "[436]\ttraining's binary_logloss: 0.530926\n",
      "[437]\ttraining's binary_logloss: 0.530787\n",
      "[438]\ttraining's binary_logloss: 0.530629\n",
      "[439]\ttraining's binary_logloss: 0.530465\n",
      "[440]\ttraining's binary_logloss: 0.530308\n",
      "[441]\ttraining's binary_logloss: 0.530198\n",
      "[442]\ttraining's binary_logloss: 0.530065\n",
      "[443]\ttraining's binary_logloss: 0.529953\n",
      "[444]\ttraining's binary_logloss: 0.529821\n",
      "[445]\ttraining's binary_logloss: 0.529713\n",
      "[446]\ttraining's binary_logloss: 0.529561\n",
      "[447]\ttraining's binary_logloss: 0.529415\n",
      "[448]\ttraining's binary_logloss: 0.529257\n",
      "[449]\ttraining's binary_logloss: 0.5291\n",
      "[450]\ttraining's binary_logloss: 0.528967\n",
      "[451]\ttraining's binary_logloss: 0.528835\n",
      "[452]\ttraining's binary_logloss: 0.528724\n",
      "[453]\ttraining's binary_logloss: 0.528616\n",
      "[454]\ttraining's binary_logloss: 0.528512\n",
      "[455]\ttraining's binary_logloss: 0.528407\n",
      "[456]\ttraining's binary_logloss: 0.528285\n",
      "[457]\ttraining's binary_logloss: 0.528159\n",
      "[458]\ttraining's binary_logloss: 0.528042\n",
      "[459]\ttraining's binary_logloss: 0.527937\n",
      "[460]\ttraining's binary_logloss: 0.527823\n",
      "[461]\ttraining's binary_logloss: 0.527651\n",
      "[462]\ttraining's binary_logloss: 0.527481\n",
      "[463]\ttraining's binary_logloss: 0.527313\n",
      "[464]\ttraining's binary_logloss: 0.527149\n",
      "[465]\ttraining's binary_logloss: 0.527006\n",
      "[466]\ttraining's binary_logloss: 0.526856\n",
      "[467]\ttraining's binary_logloss: 0.526718\n",
      "[468]\ttraining's binary_logloss: 0.526568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[469]\ttraining's binary_logloss: 0.52644\n",
      "[470]\ttraining's binary_logloss: 0.526289\n",
      "[471]\ttraining's binary_logloss: 0.526165\n",
      "[472]\ttraining's binary_logloss: 0.526046\n",
      "[473]\ttraining's binary_logloss: 0.525927\n",
      "[474]\ttraining's binary_logloss: 0.525796\n",
      "[475]\ttraining's binary_logloss: 0.525683\n",
      "[476]\ttraining's binary_logloss: 0.525563\n",
      "[477]\ttraining's binary_logloss: 0.52544\n",
      "[478]\ttraining's binary_logloss: 0.52532\n",
      "[479]\ttraining's binary_logloss: 0.525202\n",
      "[480]\ttraining's binary_logloss: 0.525087\n",
      "[481]\ttraining's binary_logloss: 0.524936\n",
      "[482]\ttraining's binary_logloss: 0.524818\n",
      "[483]\ttraining's binary_logloss: 0.524679\n",
      "[484]\ttraining's binary_logloss: 0.524519\n",
      "[485]\ttraining's binary_logloss: 0.524384\n",
      "[486]\ttraining's binary_logloss: 0.524253\n",
      "[487]\ttraining's binary_logloss: 0.524113\n",
      "[488]\ttraining's binary_logloss: 0.523959\n",
      "[489]\ttraining's binary_logloss: 0.523819\n",
      "[490]\ttraining's binary_logloss: 0.523703\n",
      "[491]\ttraining's binary_logloss: 0.523592\n",
      "[492]\ttraining's binary_logloss: 0.523454\n",
      "[493]\ttraining's binary_logloss: 0.523323\n",
      "[494]\ttraining's binary_logloss: 0.523205\n",
      "[495]\ttraining's binary_logloss: 0.523081\n",
      "[496]\ttraining's binary_logloss: 0.522922\n",
      "[497]\ttraining's binary_logloss: 0.522777\n",
      "[498]\ttraining's binary_logloss: 0.522625\n",
      "[499]\ttraining's binary_logloss: 0.522464\n",
      "[500]\ttraining's binary_logloss: 0.522308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613033\n",
      "[2]\ttraining's binary_logloss: 0.611712\n",
      "[3]\ttraining's binary_logloss: 0.610451\n",
      "[4]\ttraining's binary_logloss: 0.609126\n",
      "[5]\ttraining's binary_logloss: 0.607908\n",
      "[6]\ttraining's binary_logloss: 0.606916\n",
      "[7]\ttraining's binary_logloss: 0.605773\n",
      "[8]\ttraining's binary_logloss: 0.604789\n",
      "[9]\ttraining's binary_logloss: 0.603701\n",
      "[10]\ttraining's binary_logloss: 0.602671\n",
      "[11]\ttraining's binary_logloss: 0.601736\n",
      "[12]\ttraining's binary_logloss: 0.600873\n",
      "[13]\ttraining's binary_logloss: 0.599872\n",
      "[14]\ttraining's binary_logloss: 0.598907\n",
      "[15]\ttraining's binary_logloss: 0.597976\n",
      "[16]\ttraining's binary_logloss: 0.59701\n",
      "[17]\ttraining's binary_logloss: 0.596091\n",
      "[18]\ttraining's binary_logloss: 0.595196\n",
      "[19]\ttraining's binary_logloss: 0.594418\n",
      "[20]\ttraining's binary_logloss: 0.593645\n",
      "[21]\ttraining's binary_logloss: 0.59292\n",
      "[22]\ttraining's binary_logloss: 0.592215\n",
      "[23]\ttraining's binary_logloss: 0.591556\n",
      "[24]\ttraining's binary_logloss: 0.590895\n",
      "[25]\ttraining's binary_logloss: 0.590242\n",
      "[26]\ttraining's binary_logloss: 0.589563\n",
      "[27]\ttraining's binary_logloss: 0.589013\n",
      "[28]\ttraining's binary_logloss: 0.58849\n",
      "[29]\ttraining's binary_logloss: 0.587857\n",
      "[30]\ttraining's binary_logloss: 0.587283\n",
      "[31]\ttraining's binary_logloss: 0.586788\n",
      "[32]\ttraining's binary_logloss: 0.586279\n",
      "[33]\ttraining's binary_logloss: 0.585767\n",
      "[34]\ttraining's binary_logloss: 0.585231\n",
      "[35]\ttraining's binary_logloss: 0.584675\n",
      "[36]\ttraining's binary_logloss: 0.584204\n",
      "[37]\ttraining's binary_logloss: 0.583772\n",
      "[38]\ttraining's binary_logloss: 0.583353\n",
      "[39]\ttraining's binary_logloss: 0.582994\n",
      "[40]\ttraining's binary_logloss: 0.582548\n",
      "[41]\ttraining's binary_logloss: 0.582171\n",
      "[42]\ttraining's binary_logloss: 0.581756\n",
      "[43]\ttraining's binary_logloss: 0.581405\n",
      "[44]\ttraining's binary_logloss: 0.580995\n",
      "[45]\ttraining's binary_logloss: 0.580664\n",
      "[46]\ttraining's binary_logloss: 0.58023\n",
      "[47]\ttraining's binary_logloss: 0.579831\n",
      "[48]\ttraining's binary_logloss: 0.579414\n",
      "[49]\ttraining's binary_logloss: 0.579139\n",
      "[50]\ttraining's binary_logloss: 0.578744\n",
      "[51]\ttraining's binary_logloss: 0.578478\n",
      "[52]\ttraining's binary_logloss: 0.578227\n",
      "[53]\ttraining's binary_logloss: 0.577985\n",
      "[54]\ttraining's binary_logloss: 0.577737\n",
      "[55]\ttraining's binary_logloss: 0.577525\n",
      "[56]\ttraining's binary_logloss: 0.577255\n",
      "[57]\ttraining's binary_logloss: 0.576938\n",
      "[58]\ttraining's binary_logloss: 0.576696\n",
      "[59]\ttraining's binary_logloss: 0.576461\n",
      "[60]\ttraining's binary_logloss: 0.576229\n",
      "[61]\ttraining's binary_logloss: 0.576008\n",
      "[62]\ttraining's binary_logloss: 0.575757\n",
      "[63]\ttraining's binary_logloss: 0.575582\n",
      "[64]\ttraining's binary_logloss: 0.575417\n",
      "[65]\ttraining's binary_logloss: 0.57526\n",
      "[66]\ttraining's binary_logloss: 0.575011\n",
      "[67]\ttraining's binary_logloss: 0.574777\n",
      "[68]\ttraining's binary_logloss: 0.574543\n",
      "[69]\ttraining's binary_logloss: 0.574326\n",
      "[70]\ttraining's binary_logloss: 0.574106\n",
      "[71]\ttraining's binary_logloss: 0.573859\n",
      "[72]\ttraining's binary_logloss: 0.573623\n",
      "[73]\ttraining's binary_logloss: 0.573428\n",
      "[74]\ttraining's binary_logloss: 0.573211\n",
      "[75]\ttraining's binary_logloss: 0.573029\n",
      "[76]\ttraining's binary_logloss: 0.572846\n",
      "[77]\ttraining's binary_logloss: 0.5727\n",
      "[78]\ttraining's binary_logloss: 0.572503\n",
      "[79]\ttraining's binary_logloss: 0.572318\n",
      "[80]\ttraining's binary_logloss: 0.57216\n",
      "[81]\ttraining's binary_logloss: 0.571978\n",
      "[82]\ttraining's binary_logloss: 0.571803\n",
      "[83]\ttraining's binary_logloss: 0.571641\n",
      "[84]\ttraining's binary_logloss: 0.571503\n",
      "[85]\ttraining's binary_logloss: 0.571353\n",
      "[86]\ttraining's binary_logloss: 0.571216\n",
      "[87]\ttraining's binary_logloss: 0.571086\n",
      "[88]\ttraining's binary_logloss: 0.570957\n",
      "[89]\ttraining's binary_logloss: 0.570824\n",
      "[90]\ttraining's binary_logloss: 0.570696\n",
      "[91]\ttraining's binary_logloss: 0.570566\n",
      "[92]\ttraining's binary_logloss: 0.570429\n",
      "[93]\ttraining's binary_logloss: 0.570312\n",
      "[94]\ttraining's binary_logloss: 0.570187\n",
      "[95]\ttraining's binary_logloss: 0.570085\n",
      "[96]\ttraining's binary_logloss: 0.570022\n",
      "[97]\ttraining's binary_logloss: 0.569922\n",
      "[98]\ttraining's binary_logloss: 0.569834\n",
      "[99]\ttraining's binary_logloss: 0.569739\n",
      "[100]\ttraining's binary_logloss: 0.569644\n",
      "[101]\ttraining's binary_logloss: 0.56959\n",
      "[102]\ttraining's binary_logloss: 0.569539\n",
      "[103]\ttraining's binary_logloss: 0.569461\n",
      "[104]\ttraining's binary_logloss: 0.569408\n",
      "[105]\ttraining's binary_logloss: 0.569369\n",
      "[106]\ttraining's binary_logloss: 0.56929\n",
      "[107]\ttraining's binary_logloss: 0.569221\n",
      "[108]\ttraining's binary_logloss: 0.569158\n",
      "[109]\ttraining's binary_logloss: 0.569111\n",
      "[110]\ttraining's binary_logloss: 0.56906\n",
      "[111]\ttraining's binary_logloss: 0.569008\n",
      "[112]\ttraining's binary_logloss: 0.568933\n",
      "[113]\ttraining's binary_logloss: 0.568877\n",
      "[114]\ttraining's binary_logloss: 0.568793\n",
      "[115]\ttraining's binary_logloss: 0.568725\n",
      "[116]\ttraining's binary_logloss: 0.568643\n",
      "[117]\ttraining's binary_logloss: 0.568537\n",
      "[118]\ttraining's binary_logloss: 0.568418\n",
      "[119]\ttraining's binary_logloss: 0.56835\n",
      "[120]\ttraining's binary_logloss: 0.568271\n",
      "[121]\ttraining's binary_logloss: 0.568181\n",
      "[122]\ttraining's binary_logloss: 0.568079\n",
      "[123]\ttraining's binary_logloss: 0.567984\n",
      "[124]\ttraining's binary_logloss: 0.567907\n",
      "[125]\ttraining's binary_logloss: 0.567814\n",
      "[126]\ttraining's binary_logloss: 0.56772\n",
      "[127]\ttraining's binary_logloss: 0.567623\n",
      "[128]\ttraining's binary_logloss: 0.567542\n",
      "[129]\ttraining's binary_logloss: 0.567452\n",
      "[130]\ttraining's binary_logloss: 0.567374\n",
      "[131]\ttraining's binary_logloss: 0.567296\n",
      "[132]\ttraining's binary_logloss: 0.567214\n",
      "[133]\ttraining's binary_logloss: 0.567138\n",
      "[134]\ttraining's binary_logloss: 0.567072\n",
      "[135]\ttraining's binary_logloss: 0.567029\n",
      "[136]\ttraining's binary_logloss: 0.566982\n",
      "[137]\ttraining's binary_logloss: 0.566924\n",
      "[138]\ttraining's binary_logloss: 0.566875\n",
      "[139]\ttraining's binary_logloss: 0.566796\n",
      "[140]\ttraining's binary_logloss: 0.566744\n",
      "[141]\ttraining's binary_logloss: 0.566692\n",
      "[142]\ttraining's binary_logloss: 0.566648\n",
      "[143]\ttraining's binary_logloss: 0.566608\n",
      "[144]\ttraining's binary_logloss: 0.566561\n",
      "[145]\ttraining's binary_logloss: 0.566485\n",
      "[146]\ttraining's binary_logloss: 0.56638\n",
      "[147]\ttraining's binary_logloss: 0.566264\n",
      "[148]\ttraining's binary_logloss: 0.566179\n",
      "[149]\ttraining's binary_logloss: 0.566099\n",
      "[150]\ttraining's binary_logloss: 0.56598\n",
      "[151]\ttraining's binary_logloss: 0.565902\n",
      "[152]\ttraining's binary_logloss: 0.565841\n",
      "[153]\ttraining's binary_logloss: 0.565763\n",
      "[154]\ttraining's binary_logloss: 0.565717\n",
      "[155]\ttraining's binary_logloss: 0.56563\n",
      "[156]\ttraining's binary_logloss: 0.565595\n",
      "[157]\ttraining's binary_logloss: 0.565544\n",
      "[158]\ttraining's binary_logloss: 0.565507\n",
      "[159]\ttraining's binary_logloss: 0.565454\n",
      "[160]\ttraining's binary_logloss: 0.565416\n",
      "[161]\ttraining's binary_logloss: 0.565323\n",
      "[162]\ttraining's binary_logloss: 0.565225\n",
      "[163]\ttraining's binary_logloss: 0.565085\n",
      "[164]\ttraining's binary_logloss: 0.56502\n",
      "[165]\ttraining's binary_logloss: 0.564896\n",
      "[166]\ttraining's binary_logloss: 0.564796\n",
      "[167]\ttraining's binary_logloss: 0.564686\n",
      "[168]\ttraining's binary_logloss: 0.564592\n",
      "[169]\ttraining's binary_logloss: 0.56449\n",
      "[170]\ttraining's binary_logloss: 0.564393\n",
      "[171]\ttraining's binary_logloss: 0.564351\n",
      "[172]\ttraining's binary_logloss: 0.56429\n",
      "[173]\ttraining's binary_logloss: 0.564276\n",
      "[174]\ttraining's binary_logloss: 0.564243\n",
      "[175]\ttraining's binary_logloss: 0.564206\n",
      "[176]\ttraining's binary_logloss: 0.564149\n",
      "[177]\ttraining's binary_logloss: 0.564069\n",
      "[178]\ttraining's binary_logloss: 0.563997\n",
      "[179]\ttraining's binary_logloss: 0.563924\n",
      "[180]\ttraining's binary_logloss: 0.563847\n",
      "[181]\ttraining's binary_logloss: 0.563787\n",
      "[182]\ttraining's binary_logloss: 0.563758\n",
      "[183]\ttraining's binary_logloss: 0.56369\n",
      "[184]\ttraining's binary_logloss: 0.563659\n",
      "[185]\ttraining's binary_logloss: 0.563598\n",
      "[186]\ttraining's binary_logloss: 0.563544\n",
      "[187]\ttraining's binary_logloss: 0.563482\n",
      "[188]\ttraining's binary_logloss: 0.563432\n",
      "[189]\ttraining's binary_logloss: 0.563375\n",
      "[190]\ttraining's binary_logloss: 0.563307\n",
      "[191]\ttraining's binary_logloss: 0.563257\n",
      "[192]\ttraining's binary_logloss: 0.563158\n",
      "[193]\ttraining's binary_logloss: 0.563063\n",
      "[194]\ttraining's binary_logloss: 0.562991\n",
      "[195]\ttraining's binary_logloss: 0.562926\n",
      "[196]\ttraining's binary_logloss: 0.56288\n",
      "[197]\ttraining's binary_logloss: 0.562817\n",
      "[198]\ttraining's binary_logloss: 0.562753\n",
      "[199]\ttraining's binary_logloss: 0.562702\n",
      "[200]\ttraining's binary_logloss: 0.56264\n",
      "[201]\ttraining's binary_logloss: 0.562539\n",
      "[202]\ttraining's binary_logloss: 0.562454\n",
      "[203]\ttraining's binary_logloss: 0.562371\n",
      "[204]\ttraining's binary_logloss: 0.562294\n",
      "[205]\ttraining's binary_logloss: 0.562187\n",
      "[206]\ttraining's binary_logloss: 0.56213\n",
      "[207]\ttraining's binary_logloss: 0.562079\n",
      "[208]\ttraining's binary_logloss: 0.562029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[209]\ttraining's binary_logloss: 0.561984\n",
      "[210]\ttraining's binary_logloss: 0.561945\n",
      "[211]\ttraining's binary_logloss: 0.56187\n",
      "[212]\ttraining's binary_logloss: 0.561821\n",
      "[213]\ttraining's binary_logloss: 0.561749\n",
      "[214]\ttraining's binary_logloss: 0.561697\n",
      "[215]\ttraining's binary_logloss: 0.561643\n",
      "[216]\ttraining's binary_logloss: 0.561546\n",
      "[217]\ttraining's binary_logloss: 0.561448\n",
      "[218]\ttraining's binary_logloss: 0.561352\n",
      "[219]\ttraining's binary_logloss: 0.561254\n",
      "[220]\ttraining's binary_logloss: 0.561162\n",
      "[221]\ttraining's binary_logloss: 0.561043\n",
      "[222]\ttraining's binary_logloss: 0.560932\n",
      "[223]\ttraining's binary_logloss: 0.560823\n",
      "[224]\ttraining's binary_logloss: 0.560703\n",
      "[225]\ttraining's binary_logloss: 0.560587\n",
      "[226]\ttraining's binary_logloss: 0.560487\n",
      "[227]\ttraining's binary_logloss: 0.560375\n",
      "[228]\ttraining's binary_logloss: 0.56027\n",
      "[229]\ttraining's binary_logloss: 0.560157\n",
      "[230]\ttraining's binary_logloss: 0.560048\n",
      "[231]\ttraining's binary_logloss: 0.559962\n",
      "[232]\ttraining's binary_logloss: 0.559879\n",
      "[233]\ttraining's binary_logloss: 0.559776\n",
      "[234]\ttraining's binary_logloss: 0.559697\n",
      "[235]\ttraining's binary_logloss: 0.559591\n",
      "[236]\ttraining's binary_logloss: 0.559504\n",
      "[237]\ttraining's binary_logloss: 0.559436\n",
      "[238]\ttraining's binary_logloss: 0.559376\n",
      "[239]\ttraining's binary_logloss: 0.559288\n",
      "[240]\ttraining's binary_logloss: 0.559193\n",
      "[241]\ttraining's binary_logloss: 0.559061\n",
      "[242]\ttraining's binary_logloss: 0.558958\n",
      "[243]\ttraining's binary_logloss: 0.558827\n",
      "[244]\ttraining's binary_logloss: 0.558691\n",
      "[245]\ttraining's binary_logloss: 0.558559\n",
      "[246]\ttraining's binary_logloss: 0.558394\n",
      "[247]\ttraining's binary_logloss: 0.558254\n",
      "[248]\ttraining's binary_logloss: 0.558142\n",
      "[249]\ttraining's binary_logloss: 0.558032\n",
      "[250]\ttraining's binary_logloss: 0.55792\n",
      "[251]\ttraining's binary_logloss: 0.557845\n",
      "[252]\ttraining's binary_logloss: 0.557783\n",
      "[253]\ttraining's binary_logloss: 0.557733\n",
      "[254]\ttraining's binary_logloss: 0.557687\n",
      "[255]\ttraining's binary_logloss: 0.557635\n",
      "[256]\ttraining's binary_logloss: 0.557516\n",
      "[257]\ttraining's binary_logloss: 0.557375\n",
      "[258]\ttraining's binary_logloss: 0.557258\n",
      "[259]\ttraining's binary_logloss: 0.557122\n",
      "[260]\ttraining's binary_logloss: 0.557022\n",
      "[261]\ttraining's binary_logloss: 0.556879\n",
      "[262]\ttraining's binary_logloss: 0.556801\n",
      "[263]\ttraining's binary_logloss: 0.556736\n",
      "[264]\ttraining's binary_logloss: 0.556665\n",
      "[265]\ttraining's binary_logloss: 0.556592\n",
      "[266]\ttraining's binary_logloss: 0.556496\n",
      "[267]\ttraining's binary_logloss: 0.556401\n",
      "[268]\ttraining's binary_logloss: 0.55631\n",
      "[269]\ttraining's binary_logloss: 0.556224\n",
      "[270]\ttraining's binary_logloss: 0.55616\n",
      "[271]\ttraining's binary_logloss: 0.556021\n",
      "[272]\ttraining's binary_logloss: 0.555863\n",
      "[273]\ttraining's binary_logloss: 0.555698\n",
      "[274]\ttraining's binary_logloss: 0.555534\n",
      "[275]\ttraining's binary_logloss: 0.555414\n",
      "[276]\ttraining's binary_logloss: 0.555297\n",
      "[277]\ttraining's binary_logloss: 0.555182\n",
      "[278]\ttraining's binary_logloss: 0.555092\n",
      "[279]\ttraining's binary_logloss: 0.55497\n",
      "[280]\ttraining's binary_logloss: 0.554866\n",
      "[281]\ttraining's binary_logloss: 0.554763\n",
      "[282]\ttraining's binary_logloss: 0.554664\n",
      "[283]\ttraining's binary_logloss: 0.554537\n",
      "[284]\ttraining's binary_logloss: 0.554424\n",
      "[285]\ttraining's binary_logloss: 0.554298\n",
      "[286]\ttraining's binary_logloss: 0.554157\n",
      "[287]\ttraining's binary_logloss: 0.55402\n",
      "[288]\ttraining's binary_logloss: 0.553893\n",
      "[289]\ttraining's binary_logloss: 0.553756\n",
      "[290]\ttraining's binary_logloss: 0.55363\n",
      "[291]\ttraining's binary_logloss: 0.553469\n",
      "[292]\ttraining's binary_logloss: 0.553305\n",
      "[293]\ttraining's binary_logloss: 0.553143\n",
      "[294]\ttraining's binary_logloss: 0.552984\n",
      "[295]\ttraining's binary_logloss: 0.552843\n",
      "[296]\ttraining's binary_logloss: 0.552684\n",
      "[297]\ttraining's binary_logloss: 0.552559\n",
      "[298]\ttraining's binary_logloss: 0.552429\n",
      "[299]\ttraining's binary_logloss: 0.552292\n",
      "[300]\ttraining's binary_logloss: 0.552148\n",
      "[301]\ttraining's binary_logloss: 0.552031\n",
      "[302]\ttraining's binary_logloss: 0.551918\n",
      "[303]\ttraining's binary_logloss: 0.551799\n",
      "[304]\ttraining's binary_logloss: 0.551686\n",
      "[305]\ttraining's binary_logloss: 0.551593\n",
      "[306]\ttraining's binary_logloss: 0.551491\n",
      "[307]\ttraining's binary_logloss: 0.551392\n",
      "[308]\ttraining's binary_logloss: 0.551287\n",
      "[309]\ttraining's binary_logloss: 0.551191\n",
      "[310]\ttraining's binary_logloss: 0.551102\n",
      "[311]\ttraining's binary_logloss: 0.550947\n",
      "[312]\ttraining's binary_logloss: 0.550796\n",
      "[313]\ttraining's binary_logloss: 0.550676\n",
      "[314]\ttraining's binary_logloss: 0.550544\n",
      "[315]\ttraining's binary_logloss: 0.5504\n",
      "[316]\ttraining's binary_logloss: 0.550283\n",
      "[317]\ttraining's binary_logloss: 0.550174\n",
      "[318]\ttraining's binary_logloss: 0.550024\n",
      "[319]\ttraining's binary_logloss: 0.54985\n",
      "[320]\ttraining's binary_logloss: 0.549733\n",
      "[321]\ttraining's binary_logloss: 0.549632\n",
      "[322]\ttraining's binary_logloss: 0.549508\n",
      "[323]\ttraining's binary_logloss: 0.5494\n",
      "[324]\ttraining's binary_logloss: 0.549298\n",
      "[325]\ttraining's binary_logloss: 0.549204\n",
      "[326]\ttraining's binary_logloss: 0.549065\n",
      "[327]\ttraining's binary_logloss: 0.548931\n",
      "[328]\ttraining's binary_logloss: 0.548811\n",
      "[329]\ttraining's binary_logloss: 0.548681\n",
      "[330]\ttraining's binary_logloss: 0.548557\n",
      "[331]\ttraining's binary_logloss: 0.548435\n",
      "[332]\ttraining's binary_logloss: 0.548302\n",
      "[333]\ttraining's binary_logloss: 0.548183\n",
      "[334]\ttraining's binary_logloss: 0.548055\n",
      "[335]\ttraining's binary_logloss: 0.547934\n",
      "[336]\ttraining's binary_logloss: 0.547794\n",
      "[337]\ttraining's binary_logloss: 0.547635\n",
      "[338]\ttraining's binary_logloss: 0.547483\n",
      "[339]\ttraining's binary_logloss: 0.547345\n",
      "[340]\ttraining's binary_logloss: 0.547212\n",
      "[341]\ttraining's binary_logloss: 0.547122\n",
      "[342]\ttraining's binary_logloss: 0.547039\n",
      "[343]\ttraining's binary_logloss: 0.546957\n",
      "[344]\ttraining's binary_logloss: 0.546885\n",
      "[345]\ttraining's binary_logloss: 0.546805\n",
      "[346]\ttraining's binary_logloss: 0.546697\n",
      "[347]\ttraining's binary_logloss: 0.546615\n",
      "[348]\ttraining's binary_logloss: 0.546488\n",
      "[349]\ttraining's binary_logloss: 0.546382\n",
      "[350]\ttraining's binary_logloss: 0.546279\n",
      "[351]\ttraining's binary_logloss: 0.546099\n",
      "[352]\ttraining's binary_logloss: 0.545931\n",
      "[353]\ttraining's binary_logloss: 0.545767\n",
      "[354]\ttraining's binary_logloss: 0.545599\n",
      "[355]\ttraining's binary_logloss: 0.545444\n",
      "[356]\ttraining's binary_logloss: 0.545307\n",
      "[357]\ttraining's binary_logloss: 0.545154\n",
      "[358]\ttraining's binary_logloss: 0.545009\n",
      "[359]\ttraining's binary_logloss: 0.544855\n",
      "[360]\ttraining's binary_logloss: 0.544717\n",
      "[361]\ttraining's binary_logloss: 0.544534\n",
      "[362]\ttraining's binary_logloss: 0.544358\n",
      "[363]\ttraining's binary_logloss: 0.54421\n",
      "[364]\ttraining's binary_logloss: 0.544038\n",
      "[365]\ttraining's binary_logloss: 0.543867\n",
      "[366]\ttraining's binary_logloss: 0.543752\n",
      "[367]\ttraining's binary_logloss: 0.543647\n",
      "[368]\ttraining's binary_logloss: 0.543519\n",
      "[369]\ttraining's binary_logloss: 0.543398\n",
      "[370]\ttraining's binary_logloss: 0.543265\n",
      "[371]\ttraining's binary_logloss: 0.543162\n",
      "[372]\ttraining's binary_logloss: 0.543046\n",
      "[373]\ttraining's binary_logloss: 0.542909\n",
      "[374]\ttraining's binary_logloss: 0.542813\n",
      "[375]\ttraining's binary_logloss: 0.542668\n",
      "[376]\ttraining's binary_logloss: 0.54253\n",
      "[377]\ttraining's binary_logloss: 0.542399\n",
      "[378]\ttraining's binary_logloss: 0.542263\n",
      "[379]\ttraining's binary_logloss: 0.542135\n",
      "[380]\ttraining's binary_logloss: 0.542002\n",
      "[381]\ttraining's binary_logloss: 0.54189\n",
      "[382]\ttraining's binary_logloss: 0.541797\n",
      "[383]\ttraining's binary_logloss: 0.541693\n",
      "[384]\ttraining's binary_logloss: 0.541589\n",
      "[385]\ttraining's binary_logloss: 0.541486\n",
      "[386]\ttraining's binary_logloss: 0.541345\n",
      "[387]\ttraining's binary_logloss: 0.541189\n",
      "[388]\ttraining's binary_logloss: 0.541066\n",
      "[389]\ttraining's binary_logloss: 0.540918\n",
      "[390]\ttraining's binary_logloss: 0.540755\n",
      "[391]\ttraining's binary_logloss: 0.540597\n",
      "[392]\ttraining's binary_logloss: 0.540432\n",
      "[393]\ttraining's binary_logloss: 0.540267\n",
      "[394]\ttraining's binary_logloss: 0.540106\n",
      "[395]\ttraining's binary_logloss: 0.539951\n",
      "[396]\ttraining's binary_logloss: 0.539808\n",
      "[397]\ttraining's binary_logloss: 0.539698\n",
      "[398]\ttraining's binary_logloss: 0.539579\n",
      "[399]\ttraining's binary_logloss: 0.5395\n",
      "[400]\ttraining's binary_logloss: 0.539396\n",
      "[401]\ttraining's binary_logloss: 0.539213\n",
      "[402]\ttraining's binary_logloss: 0.539041\n",
      "[403]\ttraining's binary_logloss: 0.538888\n",
      "[404]\ttraining's binary_logloss: 0.538771\n",
      "[405]\ttraining's binary_logloss: 0.538614\n",
      "[406]\ttraining's binary_logloss: 0.538465\n",
      "[407]\ttraining's binary_logloss: 0.538323\n",
      "[408]\ttraining's binary_logloss: 0.53817\n",
      "[409]\ttraining's binary_logloss: 0.538038\n",
      "[410]\ttraining's binary_logloss: 0.537881\n",
      "[411]\ttraining's binary_logloss: 0.537754\n",
      "[412]\ttraining's binary_logloss: 0.53764\n",
      "[413]\ttraining's binary_logloss: 0.537491\n",
      "[414]\ttraining's binary_logloss: 0.537362\n",
      "[415]\ttraining's binary_logloss: 0.537225\n",
      "[416]\ttraining's binary_logloss: 0.537069\n",
      "[417]\ttraining's binary_logloss: 0.53695\n",
      "[418]\ttraining's binary_logloss: 0.536814\n",
      "[419]\ttraining's binary_logloss: 0.536728\n",
      "[420]\ttraining's binary_logloss: 0.536595\n",
      "[421]\ttraining's binary_logloss: 0.536507\n",
      "[422]\ttraining's binary_logloss: 0.536429\n",
      "[423]\ttraining's binary_logloss: 0.536338\n",
      "[424]\ttraining's binary_logloss: 0.536256\n",
      "[425]\ttraining's binary_logloss: 0.536162\n",
      "[426]\ttraining's binary_logloss: 0.536033\n",
      "[427]\ttraining's binary_logloss: 0.535913\n",
      "[428]\ttraining's binary_logloss: 0.535798\n",
      "[429]\ttraining's binary_logloss: 0.535658\n",
      "[430]\ttraining's binary_logloss: 0.535518\n",
      "[431]\ttraining's binary_logloss: 0.535346\n",
      "[432]\ttraining's binary_logloss: 0.535191\n",
      "[433]\ttraining's binary_logloss: 0.535013\n",
      "[434]\ttraining's binary_logloss: 0.534841\n",
      "[435]\ttraining's binary_logloss: 0.534671\n",
      "[436]\ttraining's binary_logloss: 0.534543\n",
      "[437]\ttraining's binary_logloss: 0.534421\n",
      "[438]\ttraining's binary_logloss: 0.534291\n",
      "[439]\ttraining's binary_logloss: 0.534179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[440]\ttraining's binary_logloss: 0.534071\n",
      "[441]\ttraining's binary_logloss: 0.533929\n",
      "[442]\ttraining's binary_logloss: 0.53379\n",
      "[443]\ttraining's binary_logloss: 0.533657\n",
      "[444]\ttraining's binary_logloss: 0.533523\n",
      "[445]\ttraining's binary_logloss: 0.533399\n",
      "[446]\ttraining's binary_logloss: 0.533259\n",
      "[447]\ttraining's binary_logloss: 0.533136\n",
      "[448]\ttraining's binary_logloss: 0.53298\n",
      "[449]\ttraining's binary_logloss: 0.532823\n",
      "[450]\ttraining's binary_logloss: 0.532669\n",
      "[451]\ttraining's binary_logloss: 0.532551\n",
      "[452]\ttraining's binary_logloss: 0.532456\n",
      "[453]\ttraining's binary_logloss: 0.532353\n",
      "[454]\ttraining's binary_logloss: 0.532248\n",
      "[455]\ttraining's binary_logloss: 0.532148\n",
      "[456]\ttraining's binary_logloss: 0.532014\n",
      "[457]\ttraining's binary_logloss: 0.531882\n",
      "[458]\ttraining's binary_logloss: 0.531756\n",
      "[459]\ttraining's binary_logloss: 0.531617\n",
      "[460]\ttraining's binary_logloss: 0.53149\n",
      "[461]\ttraining's binary_logloss: 0.531371\n",
      "[462]\ttraining's binary_logloss: 0.531268\n",
      "[463]\ttraining's binary_logloss: 0.531162\n",
      "[464]\ttraining's binary_logloss: 0.531006\n",
      "[465]\ttraining's binary_logloss: 0.530898\n",
      "[466]\ttraining's binary_logloss: 0.53075\n",
      "[467]\ttraining's binary_logloss: 0.530617\n",
      "[468]\ttraining's binary_logloss: 0.530478\n",
      "[469]\ttraining's binary_logloss: 0.530349\n",
      "[470]\ttraining's binary_logloss: 0.530211\n",
      "[471]\ttraining's binary_logloss: 0.530104\n",
      "[472]\ttraining's binary_logloss: 0.530005\n",
      "[473]\ttraining's binary_logloss: 0.529884\n",
      "[474]\ttraining's binary_logloss: 0.529792\n",
      "[475]\ttraining's binary_logloss: 0.529698\n",
      "[476]\ttraining's binary_logloss: 0.529535\n",
      "[477]\ttraining's binary_logloss: 0.529371\n",
      "[478]\ttraining's binary_logloss: 0.529219\n",
      "[479]\ttraining's binary_logloss: 0.529082\n",
      "[480]\ttraining's binary_logloss: 0.528955\n",
      "[481]\ttraining's binary_logloss: 0.528814\n",
      "[482]\ttraining's binary_logloss: 0.528675\n",
      "[483]\ttraining's binary_logloss: 0.528543\n",
      "[484]\ttraining's binary_logloss: 0.528415\n",
      "[485]\ttraining's binary_logloss: 0.528292\n",
      "[486]\ttraining's binary_logloss: 0.528124\n",
      "[487]\ttraining's binary_logloss: 0.52797\n",
      "[488]\ttraining's binary_logloss: 0.527795\n",
      "[489]\ttraining's binary_logloss: 0.527641\n",
      "[490]\ttraining's binary_logloss: 0.527456\n",
      "[491]\ttraining's binary_logloss: 0.52732\n",
      "[492]\ttraining's binary_logloss: 0.527182\n",
      "[493]\ttraining's binary_logloss: 0.527048\n",
      "[494]\ttraining's binary_logloss: 0.526926\n",
      "[495]\ttraining's binary_logloss: 0.526775\n",
      "[496]\ttraining's binary_logloss: 0.52661\n",
      "[497]\ttraining's binary_logloss: 0.526471\n",
      "[498]\ttraining's binary_logloss: 0.526353\n",
      "[499]\ttraining's binary_logloss: 0.526198\n",
      "[500]\ttraining's binary_logloss: 0.526058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.617428\n",
      "[2]\ttraining's binary_logloss: 0.616097\n",
      "[3]\ttraining's binary_logloss: 0.614822\n",
      "[4]\ttraining's binary_logloss: 0.613607\n",
      "[5]\ttraining's binary_logloss: 0.612479\n",
      "[6]\ttraining's binary_logloss: 0.611309\n",
      "[7]\ttraining's binary_logloss: 0.610165\n",
      "[8]\ttraining's binary_logloss: 0.609054\n",
      "[9]\ttraining's binary_logloss: 0.608045\n",
      "[10]\ttraining's binary_logloss: 0.607015\n",
      "[11]\ttraining's binary_logloss: 0.606\n",
      "[12]\ttraining's binary_logloss: 0.604991\n",
      "[13]\ttraining's binary_logloss: 0.603996\n",
      "[14]\ttraining's binary_logloss: 0.60302\n",
      "[15]\ttraining's binary_logloss: 0.602101\n",
      "[16]\ttraining's binary_logloss: 0.601278\n",
      "[17]\ttraining's binary_logloss: 0.600485\n",
      "[18]\ttraining's binary_logloss: 0.599733\n",
      "[19]\ttraining's binary_logloss: 0.599004\n",
      "[20]\ttraining's binary_logloss: 0.598268\n",
      "[21]\ttraining's binary_logloss: 0.597492\n",
      "[22]\ttraining's binary_logloss: 0.596755\n",
      "[23]\ttraining's binary_logloss: 0.596081\n",
      "[24]\ttraining's binary_logloss: 0.595332\n",
      "[25]\ttraining's binary_logloss: 0.594775\n",
      "[26]\ttraining's binary_logloss: 0.594127\n",
      "[27]\ttraining's binary_logloss: 0.593552\n",
      "[28]\ttraining's binary_logloss: 0.592933\n",
      "[29]\ttraining's binary_logloss: 0.592347\n",
      "[30]\ttraining's binary_logloss: 0.591782\n",
      "[31]\ttraining's binary_logloss: 0.591194\n",
      "[32]\ttraining's binary_logloss: 0.590628\n",
      "[33]\ttraining's binary_logloss: 0.590084\n",
      "[34]\ttraining's binary_logloss: 0.589572\n",
      "[35]\ttraining's binary_logloss: 0.589101\n",
      "[36]\ttraining's binary_logloss: 0.588663\n",
      "[37]\ttraining's binary_logloss: 0.588213\n",
      "[38]\ttraining's binary_logloss: 0.58778\n",
      "[39]\ttraining's binary_logloss: 0.587347\n",
      "[40]\ttraining's binary_logloss: 0.586939\n",
      "[41]\ttraining's binary_logloss: 0.586607\n",
      "[42]\ttraining's binary_logloss: 0.586152\n",
      "[43]\ttraining's binary_logloss: 0.585816\n",
      "[44]\ttraining's binary_logloss: 0.585483\n",
      "[45]\ttraining's binary_logloss: 0.585066\n",
      "[46]\ttraining's binary_logloss: 0.584666\n",
      "[47]\ttraining's binary_logloss: 0.584332\n",
      "[48]\ttraining's binary_logloss: 0.583956\n",
      "[49]\ttraining's binary_logloss: 0.583601\n",
      "[50]\ttraining's binary_logloss: 0.583275\n",
      "[51]\ttraining's binary_logloss: 0.582976\n",
      "[52]\ttraining's binary_logloss: 0.582636\n",
      "[53]\ttraining's binary_logloss: 0.582309\n",
      "[54]\ttraining's binary_logloss: 0.582047\n",
      "[55]\ttraining's binary_logloss: 0.581724\n",
      "[56]\ttraining's binary_logloss: 0.581463\n",
      "[57]\ttraining's binary_logloss: 0.581175\n",
      "[58]\ttraining's binary_logloss: 0.580934\n",
      "[59]\ttraining's binary_logloss: 0.580711\n",
      "[60]\ttraining's binary_logloss: 0.580497\n",
      "[61]\ttraining's binary_logloss: 0.580257\n",
      "[62]\ttraining's binary_logloss: 0.580038\n",
      "[63]\ttraining's binary_logloss: 0.579836\n",
      "[64]\ttraining's binary_logloss: 0.579644\n",
      "[65]\ttraining's binary_logloss: 0.579436\n",
      "[66]\ttraining's binary_logloss: 0.579181\n",
      "[67]\ttraining's binary_logloss: 0.578937\n",
      "[68]\ttraining's binary_logloss: 0.578708\n",
      "[69]\ttraining's binary_logloss: 0.578505\n",
      "[70]\ttraining's binary_logloss: 0.578317\n",
      "[71]\ttraining's binary_logloss: 0.578108\n",
      "[72]\ttraining's binary_logloss: 0.577942\n",
      "[73]\ttraining's binary_logloss: 0.57774\n",
      "[74]\ttraining's binary_logloss: 0.577581\n",
      "[75]\ttraining's binary_logloss: 0.577436\n",
      "[76]\ttraining's binary_logloss: 0.577314\n",
      "[77]\ttraining's binary_logloss: 0.577201\n",
      "[78]\ttraining's binary_logloss: 0.577075\n",
      "[79]\ttraining's binary_logloss: 0.576861\n",
      "[80]\ttraining's binary_logloss: 0.576739\n",
      "[81]\ttraining's binary_logloss: 0.576545\n",
      "[82]\ttraining's binary_logloss: 0.576382\n",
      "[83]\ttraining's binary_logloss: 0.576218\n",
      "[84]\ttraining's binary_logloss: 0.576046\n",
      "[85]\ttraining's binary_logloss: 0.575899\n",
      "[86]\ttraining's binary_logloss: 0.575787\n",
      "[87]\ttraining's binary_logloss: 0.575703\n",
      "[88]\ttraining's binary_logloss: 0.575619\n",
      "[89]\ttraining's binary_logloss: 0.575507\n",
      "[90]\ttraining's binary_logloss: 0.575409\n",
      "[91]\ttraining's binary_logloss: 0.575226\n",
      "[92]\ttraining's binary_logloss: 0.57505\n",
      "[93]\ttraining's binary_logloss: 0.574879\n",
      "[94]\ttraining's binary_logloss: 0.574722\n",
      "[95]\ttraining's binary_logloss: 0.574574\n",
      "[96]\ttraining's binary_logloss: 0.574467\n",
      "[97]\ttraining's binary_logloss: 0.574368\n",
      "[98]\ttraining's binary_logloss: 0.574283\n",
      "[99]\ttraining's binary_logloss: 0.574196\n",
      "[100]\ttraining's binary_logloss: 0.574126\n",
      "[101]\ttraining's binary_logloss: 0.574048\n",
      "[102]\ttraining's binary_logloss: 0.57396\n",
      "[103]\ttraining's binary_logloss: 0.573875\n",
      "[104]\ttraining's binary_logloss: 0.573797\n",
      "[105]\ttraining's binary_logloss: 0.573722\n",
      "[106]\ttraining's binary_logloss: 0.573608\n",
      "[107]\ttraining's binary_logloss: 0.57349\n",
      "[108]\ttraining's binary_logloss: 0.573358\n",
      "[109]\ttraining's binary_logloss: 0.57325\n",
      "[110]\ttraining's binary_logloss: 0.573183\n",
      "[111]\ttraining's binary_logloss: 0.5731\n",
      "[112]\ttraining's binary_logloss: 0.573018\n",
      "[113]\ttraining's binary_logloss: 0.572938\n",
      "[114]\ttraining's binary_logloss: 0.572863\n",
      "[115]\ttraining's binary_logloss: 0.572805\n",
      "[116]\ttraining's binary_logloss: 0.572689\n",
      "[117]\ttraining's binary_logloss: 0.572585\n",
      "[118]\ttraining's binary_logloss: 0.572493\n",
      "[119]\ttraining's binary_logloss: 0.572397\n",
      "[120]\ttraining's binary_logloss: 0.572296\n",
      "[121]\ttraining's binary_logloss: 0.572214\n",
      "[122]\ttraining's binary_logloss: 0.572135\n",
      "[123]\ttraining's binary_logloss: 0.572062\n",
      "[124]\ttraining's binary_logloss: 0.571988\n",
      "[125]\ttraining's binary_logloss: 0.571947\n",
      "[126]\ttraining's binary_logloss: 0.571861\n",
      "[127]\ttraining's binary_logloss: 0.571762\n",
      "[128]\ttraining's binary_logloss: 0.571661\n",
      "[129]\ttraining's binary_logloss: 0.571612\n",
      "[130]\ttraining's binary_logloss: 0.571542\n",
      "[131]\ttraining's binary_logloss: 0.571415\n",
      "[132]\ttraining's binary_logloss: 0.571341\n",
      "[133]\ttraining's binary_logloss: 0.571229\n",
      "[134]\ttraining's binary_logloss: 0.571121\n",
      "[135]\ttraining's binary_logloss: 0.571022\n",
      "[136]\ttraining's binary_logloss: 0.570918\n",
      "[137]\ttraining's binary_logloss: 0.570828\n",
      "[138]\ttraining's binary_logloss: 0.570717\n",
      "[139]\ttraining's binary_logloss: 0.570643\n",
      "[140]\ttraining's binary_logloss: 0.570549\n",
      "[141]\ttraining's binary_logloss: 0.570427\n",
      "[142]\ttraining's binary_logloss: 0.570317\n",
      "[143]\ttraining's binary_logloss: 0.570249\n",
      "[144]\ttraining's binary_logloss: 0.570149\n",
      "[145]\ttraining's binary_logloss: 0.570002\n",
      "[146]\ttraining's binary_logloss: 0.569923\n",
      "[147]\ttraining's binary_logloss: 0.569793\n",
      "[148]\ttraining's binary_logloss: 0.569688\n",
      "[149]\ttraining's binary_logloss: 0.569584\n",
      "[150]\ttraining's binary_logloss: 0.569469\n",
      "[151]\ttraining's binary_logloss: 0.569415\n",
      "[152]\ttraining's binary_logloss: 0.569372\n",
      "[153]\ttraining's binary_logloss: 0.569327\n",
      "[154]\ttraining's binary_logloss: 0.569277\n",
      "[155]\ttraining's binary_logloss: 0.569221\n",
      "[156]\ttraining's binary_logloss: 0.569111\n",
      "[157]\ttraining's binary_logloss: 0.569018\n",
      "[158]\ttraining's binary_logloss: 0.568949\n",
      "[159]\ttraining's binary_logloss: 0.568881\n",
      "[160]\ttraining's binary_logloss: 0.568814\n",
      "[161]\ttraining's binary_logloss: 0.568752\n",
      "[162]\ttraining's binary_logloss: 0.568631\n",
      "[163]\ttraining's binary_logloss: 0.568524\n",
      "[164]\ttraining's binary_logloss: 0.568427\n",
      "[165]\ttraining's binary_logloss: 0.568333\n",
      "[166]\ttraining's binary_logloss: 0.568232\n",
      "[167]\ttraining's binary_logloss: 0.568143\n",
      "[168]\ttraining's binary_logloss: 0.568024\n",
      "[169]\ttraining's binary_logloss: 0.567916\n",
      "[170]\ttraining's binary_logloss: 0.567827\n",
      "[171]\ttraining's binary_logloss: 0.567752\n",
      "[172]\ttraining's binary_logloss: 0.567675\n",
      "[173]\ttraining's binary_logloss: 0.567619\n",
      "[174]\ttraining's binary_logloss: 0.567554\n",
      "[175]\ttraining's binary_logloss: 0.567482\n",
      "[176]\ttraining's binary_logloss: 0.567397\n",
      "[177]\ttraining's binary_logloss: 0.567314\n",
      "[178]\ttraining's binary_logloss: 0.567218\n",
      "[179]\ttraining's binary_logloss: 0.567144\n",
      "[180]\ttraining's binary_logloss: 0.567054\n",
      "[181]\ttraining's binary_logloss: 0.566973\n",
      "[182]\ttraining's binary_logloss: 0.566885\n",
      "[183]\ttraining's binary_logloss: 0.566777\n",
      "[184]\ttraining's binary_logloss: 0.566696\n",
      "[185]\ttraining's binary_logloss: 0.566589\n",
      "[186]\ttraining's binary_logloss: 0.566543\n",
      "[187]\ttraining's binary_logloss: 0.566508\n",
      "[188]\ttraining's binary_logloss: 0.566459\n",
      "[189]\ttraining's binary_logloss: 0.566396\n",
      "[190]\ttraining's binary_logloss: 0.566345\n",
      "[191]\ttraining's binary_logloss: 0.566269\n",
      "[192]\ttraining's binary_logloss: 0.566181\n",
      "[193]\ttraining's binary_logloss: 0.566086\n",
      "[194]\ttraining's binary_logloss: 0.565986\n",
      "[195]\ttraining's binary_logloss: 0.56592\n",
      "[196]\ttraining's binary_logloss: 0.565783\n",
      "[197]\ttraining's binary_logloss: 0.565656\n",
      "[198]\ttraining's binary_logloss: 0.565529\n",
      "[199]\ttraining's binary_logloss: 0.565434\n",
      "[200]\ttraining's binary_logloss: 0.565334\n",
      "[201]\ttraining's binary_logloss: 0.565222\n",
      "[202]\ttraining's binary_logloss: 0.565092\n",
      "[203]\ttraining's binary_logloss: 0.564986\n",
      "[204]\ttraining's binary_logloss: 0.564886\n",
      "[205]\ttraining's binary_logloss: 0.564789\n",
      "[206]\ttraining's binary_logloss: 0.56473\n",
      "[207]\ttraining's binary_logloss: 0.564617\n",
      "[208]\ttraining's binary_logloss: 0.564565\n",
      "[209]\ttraining's binary_logloss: 0.564505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[210]\ttraining's binary_logloss: 0.56439\n",
      "[211]\ttraining's binary_logloss: 0.564317\n",
      "[212]\ttraining's binary_logloss: 0.564232\n",
      "[213]\ttraining's binary_logloss: 0.564158\n",
      "[214]\ttraining's binary_logloss: 0.564069\n",
      "[215]\ttraining's binary_logloss: 0.564004\n",
      "[216]\ttraining's binary_logloss: 0.563888\n",
      "[217]\ttraining's binary_logloss: 0.563771\n",
      "[218]\ttraining's binary_logloss: 0.563653\n",
      "[219]\ttraining's binary_logloss: 0.563536\n",
      "[220]\ttraining's binary_logloss: 0.563423\n",
      "[221]\ttraining's binary_logloss: 0.563333\n",
      "[222]\ttraining's binary_logloss: 0.56324\n",
      "[223]\ttraining's binary_logloss: 0.563141\n",
      "[224]\ttraining's binary_logloss: 0.563034\n",
      "[225]\ttraining's binary_logloss: 0.562938\n",
      "[226]\ttraining's binary_logloss: 0.562814\n",
      "[227]\ttraining's binary_logloss: 0.562698\n",
      "[228]\ttraining's binary_logloss: 0.562608\n",
      "[229]\ttraining's binary_logloss: 0.562489\n",
      "[230]\ttraining's binary_logloss: 0.562398\n",
      "[231]\ttraining's binary_logloss: 0.562319\n",
      "[232]\ttraining's binary_logloss: 0.562217\n",
      "[233]\ttraining's binary_logloss: 0.562142\n",
      "[234]\ttraining's binary_logloss: 0.562033\n",
      "[235]\ttraining's binary_logloss: 0.56194\n",
      "[236]\ttraining's binary_logloss: 0.561848\n",
      "[237]\ttraining's binary_logloss: 0.561719\n",
      "[238]\ttraining's binary_logloss: 0.561597\n",
      "[239]\ttraining's binary_logloss: 0.561497\n",
      "[240]\ttraining's binary_logloss: 0.561407\n",
      "[241]\ttraining's binary_logloss: 0.56125\n",
      "[242]\ttraining's binary_logloss: 0.561123\n",
      "[243]\ttraining's binary_logloss: 0.560999\n",
      "[244]\ttraining's binary_logloss: 0.56088\n",
      "[245]\ttraining's binary_logloss: 0.560752\n",
      "[246]\ttraining's binary_logloss: 0.560639\n",
      "[247]\ttraining's binary_logloss: 0.560524\n",
      "[248]\ttraining's binary_logloss: 0.560419\n",
      "[249]\ttraining's binary_logloss: 0.560304\n",
      "[250]\ttraining's binary_logloss: 0.560181\n",
      "[251]\ttraining's binary_logloss: 0.560074\n",
      "[252]\ttraining's binary_logloss: 0.559985\n",
      "[253]\ttraining's binary_logloss: 0.559892\n",
      "[254]\ttraining's binary_logloss: 0.55979\n",
      "[255]\ttraining's binary_logloss: 0.559705\n",
      "[256]\ttraining's binary_logloss: 0.559588\n",
      "[257]\ttraining's binary_logloss: 0.559473\n",
      "[258]\ttraining's binary_logloss: 0.559354\n",
      "[259]\ttraining's binary_logloss: 0.559253\n",
      "[260]\ttraining's binary_logloss: 0.559148\n",
      "[261]\ttraining's binary_logloss: 0.558995\n",
      "[262]\ttraining's binary_logloss: 0.558859\n",
      "[263]\ttraining's binary_logloss: 0.558724\n",
      "[264]\ttraining's binary_logloss: 0.558597\n",
      "[265]\ttraining's binary_logloss: 0.558455\n",
      "[266]\ttraining's binary_logloss: 0.558343\n",
      "[267]\ttraining's binary_logloss: 0.558262\n",
      "[268]\ttraining's binary_logloss: 0.558157\n",
      "[269]\ttraining's binary_logloss: 0.558034\n",
      "[270]\ttraining's binary_logloss: 0.557919\n",
      "[271]\ttraining's binary_logloss: 0.557788\n",
      "[272]\ttraining's binary_logloss: 0.557644\n",
      "[273]\ttraining's binary_logloss: 0.557525\n",
      "[274]\ttraining's binary_logloss: 0.55739\n",
      "[275]\ttraining's binary_logloss: 0.557273\n",
      "[276]\ttraining's binary_logloss: 0.557146\n",
      "[277]\ttraining's binary_logloss: 0.557023\n",
      "[278]\ttraining's binary_logloss: 0.556893\n",
      "[279]\ttraining's binary_logloss: 0.556774\n",
      "[280]\ttraining's binary_logloss: 0.556654\n",
      "[281]\ttraining's binary_logloss: 0.556543\n",
      "[282]\ttraining's binary_logloss: 0.556423\n",
      "[283]\ttraining's binary_logloss: 0.556302\n",
      "[284]\ttraining's binary_logloss: 0.556176\n",
      "[285]\ttraining's binary_logloss: 0.556071\n",
      "[286]\ttraining's binary_logloss: 0.55594\n",
      "[287]\ttraining's binary_logloss: 0.555814\n",
      "[288]\ttraining's binary_logloss: 0.555684\n",
      "[289]\ttraining's binary_logloss: 0.555568\n",
      "[290]\ttraining's binary_logloss: 0.555455\n",
      "[291]\ttraining's binary_logloss: 0.555323\n",
      "[292]\ttraining's binary_logloss: 0.555192\n",
      "[293]\ttraining's binary_logloss: 0.555078\n",
      "[294]\ttraining's binary_logloss: 0.554925\n",
      "[295]\ttraining's binary_logloss: 0.554809\n",
      "[296]\ttraining's binary_logloss: 0.55469\n",
      "[297]\ttraining's binary_logloss: 0.554561\n",
      "[298]\ttraining's binary_logloss: 0.554425\n",
      "[299]\ttraining's binary_logloss: 0.554282\n",
      "[300]\ttraining's binary_logloss: 0.554131\n",
      "[301]\ttraining's binary_logloss: 0.55399\n",
      "[302]\ttraining's binary_logloss: 0.553856\n",
      "[303]\ttraining's binary_logloss: 0.553725\n",
      "[304]\ttraining's binary_logloss: 0.553588\n",
      "[305]\ttraining's binary_logloss: 0.553447\n",
      "[306]\ttraining's binary_logloss: 0.553309\n",
      "[307]\ttraining's binary_logloss: 0.553169\n",
      "[308]\ttraining's binary_logloss: 0.553065\n",
      "[309]\ttraining's binary_logloss: 0.552929\n",
      "[310]\ttraining's binary_logloss: 0.552782\n",
      "[311]\ttraining's binary_logloss: 0.552658\n",
      "[312]\ttraining's binary_logloss: 0.552505\n",
      "[313]\ttraining's binary_logloss: 0.552355\n",
      "[314]\ttraining's binary_logloss: 0.552225\n",
      "[315]\ttraining's binary_logloss: 0.552107\n",
      "[316]\ttraining's binary_logloss: 0.551947\n",
      "[317]\ttraining's binary_logloss: 0.551793\n",
      "[318]\ttraining's binary_logloss: 0.551635\n",
      "[319]\ttraining's binary_logloss: 0.551481\n",
      "[320]\ttraining's binary_logloss: 0.551318\n",
      "[321]\ttraining's binary_logloss: 0.551211\n",
      "[322]\ttraining's binary_logloss: 0.551085\n",
      "[323]\ttraining's binary_logloss: 0.550946\n",
      "[324]\ttraining's binary_logloss: 0.550822\n",
      "[325]\ttraining's binary_logloss: 0.550695\n",
      "[326]\ttraining's binary_logloss: 0.550582\n",
      "[327]\ttraining's binary_logloss: 0.550472\n",
      "[328]\ttraining's binary_logloss: 0.550317\n",
      "[329]\ttraining's binary_logloss: 0.550201\n",
      "[330]\ttraining's binary_logloss: 0.550096\n",
      "[331]\ttraining's binary_logloss: 0.549952\n",
      "[332]\ttraining's binary_logloss: 0.5498\n",
      "[333]\ttraining's binary_logloss: 0.549648\n",
      "[334]\ttraining's binary_logloss: 0.549508\n",
      "[335]\ttraining's binary_logloss: 0.549376\n",
      "[336]\ttraining's binary_logloss: 0.549242\n",
      "[337]\ttraining's binary_logloss: 0.549109\n",
      "[338]\ttraining's binary_logloss: 0.548981\n",
      "[339]\ttraining's binary_logloss: 0.548855\n",
      "[340]\ttraining's binary_logloss: 0.548721\n",
      "[341]\ttraining's binary_logloss: 0.548584\n",
      "[342]\ttraining's binary_logloss: 0.548452\n",
      "[343]\ttraining's binary_logloss: 0.548313\n",
      "[344]\ttraining's binary_logloss: 0.548182\n",
      "[345]\ttraining's binary_logloss: 0.548057\n",
      "[346]\ttraining's binary_logloss: 0.547945\n",
      "[347]\ttraining's binary_logloss: 0.547836\n",
      "[348]\ttraining's binary_logloss: 0.547743\n",
      "[349]\ttraining's binary_logloss: 0.547634\n",
      "[350]\ttraining's binary_logloss: 0.547531\n",
      "[351]\ttraining's binary_logloss: 0.547381\n",
      "[352]\ttraining's binary_logloss: 0.547247\n",
      "[353]\ttraining's binary_logloss: 0.547102\n",
      "[354]\ttraining's binary_logloss: 0.546964\n",
      "[355]\ttraining's binary_logloss: 0.546822\n",
      "[356]\ttraining's binary_logloss: 0.546692\n",
      "[357]\ttraining's binary_logloss: 0.546558\n",
      "[358]\ttraining's binary_logloss: 0.546427\n",
      "[359]\ttraining's binary_logloss: 0.546305\n",
      "[360]\ttraining's binary_logloss: 0.546176\n",
      "[361]\ttraining's binary_logloss: 0.546032\n",
      "[362]\ttraining's binary_logloss: 0.545888\n",
      "[363]\ttraining's binary_logloss: 0.545705\n",
      "[364]\ttraining's binary_logloss: 0.545546\n",
      "[365]\ttraining's binary_logloss: 0.545396\n",
      "[366]\ttraining's binary_logloss: 0.545284\n",
      "[367]\ttraining's binary_logloss: 0.545186\n",
      "[368]\ttraining's binary_logloss: 0.54508\n",
      "[369]\ttraining's binary_logloss: 0.544982\n",
      "[370]\ttraining's binary_logloss: 0.544879\n",
      "[371]\ttraining's binary_logloss: 0.544746\n",
      "[372]\ttraining's binary_logloss: 0.544622\n",
      "[373]\ttraining's binary_logloss: 0.544499\n",
      "[374]\ttraining's binary_logloss: 0.544368\n",
      "[375]\ttraining's binary_logloss: 0.54424\n",
      "[376]\ttraining's binary_logloss: 0.544083\n",
      "[377]\ttraining's binary_logloss: 0.54394\n",
      "[378]\ttraining's binary_logloss: 0.543787\n",
      "[379]\ttraining's binary_logloss: 0.543664\n",
      "[380]\ttraining's binary_logloss: 0.543525\n",
      "[381]\ttraining's binary_logloss: 0.543388\n",
      "[382]\ttraining's binary_logloss: 0.543221\n",
      "[383]\ttraining's binary_logloss: 0.543079\n",
      "[384]\ttraining's binary_logloss: 0.54292\n",
      "[385]\ttraining's binary_logloss: 0.542788\n",
      "[386]\ttraining's binary_logloss: 0.54267\n",
      "[387]\ttraining's binary_logloss: 0.542543\n",
      "[388]\ttraining's binary_logloss: 0.542416\n",
      "[389]\ttraining's binary_logloss: 0.542279\n",
      "[390]\ttraining's binary_logloss: 0.542136\n",
      "[391]\ttraining's binary_logloss: 0.541987\n",
      "[392]\ttraining's binary_logloss: 0.541831\n",
      "[393]\ttraining's binary_logloss: 0.541697\n",
      "[394]\ttraining's binary_logloss: 0.541532\n",
      "[395]\ttraining's binary_logloss: 0.541391\n",
      "[396]\ttraining's binary_logloss: 0.541255\n",
      "[397]\ttraining's binary_logloss: 0.541102\n",
      "[398]\ttraining's binary_logloss: 0.54098\n",
      "[399]\ttraining's binary_logloss: 0.540842\n",
      "[400]\ttraining's binary_logloss: 0.540705\n",
      "[401]\ttraining's binary_logloss: 0.540543\n",
      "[402]\ttraining's binary_logloss: 0.540391\n",
      "[403]\ttraining's binary_logloss: 0.540237\n",
      "[404]\ttraining's binary_logloss: 0.540064\n",
      "[405]\ttraining's binary_logloss: 0.539928\n",
      "[406]\ttraining's binary_logloss: 0.539758\n",
      "[407]\ttraining's binary_logloss: 0.5396\n",
      "[408]\ttraining's binary_logloss: 0.539438\n",
      "[409]\ttraining's binary_logloss: 0.539313\n",
      "[410]\ttraining's binary_logloss: 0.53919\n",
      "[411]\ttraining's binary_logloss: 0.539062\n",
      "[412]\ttraining's binary_logloss: 0.538937\n",
      "[413]\ttraining's binary_logloss: 0.538809\n",
      "[414]\ttraining's binary_logloss: 0.538681\n",
      "[415]\ttraining's binary_logloss: 0.538566\n",
      "[416]\ttraining's binary_logloss: 0.538454\n",
      "[417]\ttraining's binary_logloss: 0.538306\n",
      "[418]\ttraining's binary_logloss: 0.538168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[419]\ttraining's binary_logloss: 0.538036\n",
      "[420]\ttraining's binary_logloss: 0.537892\n",
      "[421]\ttraining's binary_logloss: 0.537797\n",
      "[422]\ttraining's binary_logloss: 0.537702\n",
      "[423]\ttraining's binary_logloss: 0.537595\n",
      "[424]\ttraining's binary_logloss: 0.537503\n",
      "[425]\ttraining's binary_logloss: 0.537408\n",
      "[426]\ttraining's binary_logloss: 0.537261\n",
      "[427]\ttraining's binary_logloss: 0.53713\n",
      "[428]\ttraining's binary_logloss: 0.536992\n",
      "[429]\ttraining's binary_logloss: 0.536858\n",
      "[430]\ttraining's binary_logloss: 0.536723\n",
      "[431]\ttraining's binary_logloss: 0.536587\n",
      "[432]\ttraining's binary_logloss: 0.536462\n",
      "[433]\ttraining's binary_logloss: 0.536312\n",
      "[434]\ttraining's binary_logloss: 0.53619\n",
      "[435]\ttraining's binary_logloss: 0.53606\n",
      "[436]\ttraining's binary_logloss: 0.535925\n",
      "[437]\ttraining's binary_logloss: 0.535782\n",
      "[438]\ttraining's binary_logloss: 0.535663\n",
      "[439]\ttraining's binary_logloss: 0.535542\n",
      "[440]\ttraining's binary_logloss: 0.535428\n",
      "[441]\ttraining's binary_logloss: 0.535263\n",
      "[442]\ttraining's binary_logloss: 0.535104\n",
      "[443]\ttraining's binary_logloss: 0.534961\n",
      "[444]\ttraining's binary_logloss: 0.534803\n",
      "[445]\ttraining's binary_logloss: 0.534658\n",
      "[446]\ttraining's binary_logloss: 0.534528\n",
      "[447]\ttraining's binary_logloss: 0.534428\n",
      "[448]\ttraining's binary_logloss: 0.534308\n",
      "[449]\ttraining's binary_logloss: 0.534206\n",
      "[450]\ttraining's binary_logloss: 0.53409\n",
      "[451]\ttraining's binary_logloss: 0.534013\n",
      "[452]\ttraining's binary_logloss: 0.533932\n",
      "[453]\ttraining's binary_logloss: 0.533838\n",
      "[454]\ttraining's binary_logloss: 0.533734\n",
      "[455]\ttraining's binary_logloss: 0.533654\n",
      "[456]\ttraining's binary_logloss: 0.533483\n",
      "[457]\ttraining's binary_logloss: 0.533333\n",
      "[458]\ttraining's binary_logloss: 0.533173\n",
      "[459]\ttraining's binary_logloss: 0.533019\n",
      "[460]\ttraining's binary_logloss: 0.532841\n",
      "[461]\ttraining's binary_logloss: 0.532713\n",
      "[462]\ttraining's binary_logloss: 0.532591\n",
      "[463]\ttraining's binary_logloss: 0.532477\n",
      "[464]\ttraining's binary_logloss: 0.532374\n",
      "[465]\ttraining's binary_logloss: 0.532274\n",
      "[466]\ttraining's binary_logloss: 0.532118\n",
      "[467]\ttraining's binary_logloss: 0.531968\n",
      "[468]\ttraining's binary_logloss: 0.531819\n",
      "[469]\ttraining's binary_logloss: 0.531673\n",
      "[470]\ttraining's binary_logloss: 0.531544\n",
      "[471]\ttraining's binary_logloss: 0.531417\n",
      "[472]\ttraining's binary_logloss: 0.531303\n",
      "[473]\ttraining's binary_logloss: 0.531178\n",
      "[474]\ttraining's binary_logloss: 0.531065\n",
      "[475]\ttraining's binary_logloss: 0.53095\n",
      "[476]\ttraining's binary_logloss: 0.530806\n",
      "[477]\ttraining's binary_logloss: 0.530665\n",
      "[478]\ttraining's binary_logloss: 0.530532\n",
      "[479]\ttraining's binary_logloss: 0.530382\n",
      "[480]\ttraining's binary_logloss: 0.530238\n",
      "[481]\ttraining's binary_logloss: 0.530115\n",
      "[482]\ttraining's binary_logloss: 0.529965\n",
      "[483]\ttraining's binary_logloss: 0.529827\n",
      "[484]\ttraining's binary_logloss: 0.529696\n",
      "[485]\ttraining's binary_logloss: 0.529564\n",
      "[486]\ttraining's binary_logloss: 0.529432\n",
      "[487]\ttraining's binary_logloss: 0.529326\n",
      "[488]\ttraining's binary_logloss: 0.529199\n",
      "[489]\ttraining's binary_logloss: 0.529083\n",
      "[490]\ttraining's binary_logloss: 0.528979\n",
      "[491]\ttraining's binary_logloss: 0.528807\n",
      "[492]\ttraining's binary_logloss: 0.528624\n",
      "[493]\ttraining's binary_logloss: 0.528456\n",
      "[494]\ttraining's binary_logloss: 0.528295\n",
      "[495]\ttraining's binary_logloss: 0.528148\n",
      "[496]\ttraining's binary_logloss: 0.527978\n",
      "[497]\ttraining's binary_logloss: 0.527784\n",
      "[498]\ttraining's binary_logloss: 0.527622\n",
      "[499]\ttraining's binary_logloss: 0.527429\n",
      "[500]\ttraining's binary_logloss: 0.527252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.61348\n",
      "[2]\ttraining's binary_logloss: 0.612193\n",
      "[3]\ttraining's binary_logloss: 0.61092\n",
      "[4]\ttraining's binary_logloss: 0.60965\n",
      "[5]\ttraining's binary_logloss: 0.6084\n",
      "[6]\ttraining's binary_logloss: 0.607296\n",
      "[7]\ttraining's binary_logloss: 0.606236\n",
      "[8]\ttraining's binary_logloss: 0.605133\n",
      "[9]\ttraining's binary_logloss: 0.604113\n",
      "[10]\ttraining's binary_logloss: 0.603136\n",
      "[11]\ttraining's binary_logloss: 0.602133\n",
      "[12]\ttraining's binary_logloss: 0.601233\n",
      "[13]\ttraining's binary_logloss: 0.600348\n",
      "[14]\ttraining's binary_logloss: 0.599515\n",
      "[15]\ttraining's binary_logloss: 0.598641\n",
      "[16]\ttraining's binary_logloss: 0.597772\n",
      "[17]\ttraining's binary_logloss: 0.596936\n",
      "[18]\ttraining's binary_logloss: 0.596092\n",
      "[19]\ttraining's binary_logloss: 0.595331\n",
      "[20]\ttraining's binary_logloss: 0.594562\n",
      "[21]\ttraining's binary_logloss: 0.593805\n",
      "[22]\ttraining's binary_logloss: 0.593108\n",
      "[23]\ttraining's binary_logloss: 0.592396\n",
      "[24]\ttraining's binary_logloss: 0.591734\n",
      "[25]\ttraining's binary_logloss: 0.591096\n",
      "[26]\ttraining's binary_logloss: 0.590483\n",
      "[27]\ttraining's binary_logloss: 0.589876\n",
      "[28]\ttraining's binary_logloss: 0.589309\n",
      "[29]\ttraining's binary_logloss: 0.588716\n",
      "[30]\ttraining's binary_logloss: 0.588163\n",
      "[31]\ttraining's binary_logloss: 0.587608\n",
      "[32]\ttraining's binary_logloss: 0.58705\n",
      "[33]\ttraining's binary_logloss: 0.586591\n",
      "[34]\ttraining's binary_logloss: 0.586079\n",
      "[35]\ttraining's binary_logloss: 0.585654\n",
      "[36]\ttraining's binary_logloss: 0.5852\n",
      "[37]\ttraining's binary_logloss: 0.584714\n",
      "[38]\ttraining's binary_logloss: 0.584289\n",
      "[39]\ttraining's binary_logloss: 0.583871\n",
      "[40]\ttraining's binary_logloss: 0.583497\n",
      "[41]\ttraining's binary_logloss: 0.583095\n",
      "[42]\ttraining's binary_logloss: 0.582664\n",
      "[43]\ttraining's binary_logloss: 0.582335\n",
      "[44]\ttraining's binary_logloss: 0.58199\n",
      "[45]\ttraining's binary_logloss: 0.581662\n",
      "[46]\ttraining's binary_logloss: 0.58131\n",
      "[47]\ttraining's binary_logloss: 0.580948\n",
      "[48]\ttraining's binary_logloss: 0.580566\n",
      "[49]\ttraining's binary_logloss: 0.580233\n",
      "[50]\ttraining's binary_logloss: 0.579882\n",
      "[51]\ttraining's binary_logloss: 0.579628\n",
      "[52]\ttraining's binary_logloss: 0.579397\n",
      "[53]\ttraining's binary_logloss: 0.579188\n",
      "[54]\ttraining's binary_logloss: 0.578931\n",
      "[55]\ttraining's binary_logloss: 0.578722\n",
      "[56]\ttraining's binary_logloss: 0.578445\n",
      "[57]\ttraining's binary_logloss: 0.578244\n",
      "[58]\ttraining's binary_logloss: 0.578042\n",
      "[59]\ttraining's binary_logloss: 0.577836\n",
      "[60]\ttraining's binary_logloss: 0.577586\n",
      "[61]\ttraining's binary_logloss: 0.577338\n",
      "[62]\ttraining's binary_logloss: 0.577152\n",
      "[63]\ttraining's binary_logloss: 0.576889\n",
      "[64]\ttraining's binary_logloss: 0.576627\n",
      "[65]\ttraining's binary_logloss: 0.576432\n",
      "[66]\ttraining's binary_logloss: 0.576176\n",
      "[67]\ttraining's binary_logloss: 0.575921\n",
      "[68]\ttraining's binary_logloss: 0.575679\n",
      "[69]\ttraining's binary_logloss: 0.575437\n",
      "[70]\ttraining's binary_logloss: 0.575214\n",
      "[71]\ttraining's binary_logloss: 0.57496\n",
      "[72]\ttraining's binary_logloss: 0.574727\n",
      "[73]\ttraining's binary_logloss: 0.574504\n",
      "[74]\ttraining's binary_logloss: 0.574349\n",
      "[75]\ttraining's binary_logloss: 0.574135\n",
      "[76]\ttraining's binary_logloss: 0.574016\n",
      "[77]\ttraining's binary_logloss: 0.57389\n",
      "[78]\ttraining's binary_logloss: 0.573768\n",
      "[79]\ttraining's binary_logloss: 0.573658\n",
      "[80]\ttraining's binary_logloss: 0.57357\n",
      "[81]\ttraining's binary_logloss: 0.573437\n",
      "[82]\ttraining's binary_logloss: 0.573315\n",
      "[83]\ttraining's binary_logloss: 0.573199\n",
      "[84]\ttraining's binary_logloss: 0.573078\n",
      "[85]\ttraining's binary_logloss: 0.57297\n",
      "[86]\ttraining's binary_logloss: 0.572849\n",
      "[87]\ttraining's binary_logloss: 0.572728\n",
      "[88]\ttraining's binary_logloss: 0.572649\n",
      "[89]\ttraining's binary_logloss: 0.572535\n",
      "[90]\ttraining's binary_logloss: 0.572426\n",
      "[91]\ttraining's binary_logloss: 0.572335\n",
      "[92]\ttraining's binary_logloss: 0.572247\n",
      "[93]\ttraining's binary_logloss: 0.57216\n",
      "[94]\ttraining's binary_logloss: 0.572074\n",
      "[95]\ttraining's binary_logloss: 0.572001\n",
      "[96]\ttraining's binary_logloss: 0.571923\n",
      "[97]\ttraining's binary_logloss: 0.571869\n",
      "[98]\ttraining's binary_logloss: 0.571807\n",
      "[99]\ttraining's binary_logloss: 0.571753\n",
      "[100]\ttraining's binary_logloss: 0.571675\n",
      "[101]\ttraining's binary_logloss: 0.571584\n",
      "[102]\ttraining's binary_logloss: 0.5715\n",
      "[103]\ttraining's binary_logloss: 0.571408\n",
      "[104]\ttraining's binary_logloss: 0.571333\n",
      "[105]\ttraining's binary_logloss: 0.57126\n",
      "[106]\ttraining's binary_logloss: 0.571197\n",
      "[107]\ttraining's binary_logloss: 0.57112\n",
      "[108]\ttraining's binary_logloss: 0.571032\n",
      "[109]\ttraining's binary_logloss: 0.570975\n",
      "[110]\ttraining's binary_logloss: 0.5709\n",
      "[111]\ttraining's binary_logloss: 0.57082\n",
      "[112]\ttraining's binary_logloss: 0.570746\n",
      "[113]\ttraining's binary_logloss: 0.570672\n",
      "[114]\ttraining's binary_logloss: 0.570609\n",
      "[115]\ttraining's binary_logloss: 0.570511\n",
      "[116]\ttraining's binary_logloss: 0.570409\n",
      "[117]\ttraining's binary_logloss: 0.570318\n",
      "[118]\ttraining's binary_logloss: 0.570236\n",
      "[119]\ttraining's binary_logloss: 0.570144\n",
      "[120]\ttraining's binary_logloss: 0.570084\n",
      "[121]\ttraining's binary_logloss: 0.570028\n",
      "[122]\ttraining's binary_logloss: 0.569968\n",
      "[123]\ttraining's binary_logloss: 0.569916\n",
      "[124]\ttraining's binary_logloss: 0.569842\n",
      "[125]\ttraining's binary_logloss: 0.569788\n",
      "[126]\ttraining's binary_logloss: 0.569689\n",
      "[127]\ttraining's binary_logloss: 0.56959\n",
      "[128]\ttraining's binary_logloss: 0.56953\n",
      "[129]\ttraining's binary_logloss: 0.569445\n",
      "[130]\ttraining's binary_logloss: 0.569373\n",
      "[131]\ttraining's binary_logloss: 0.569359\n",
      "[132]\ttraining's binary_logloss: 0.56933\n",
      "[133]\ttraining's binary_logloss: 0.569309\n",
      "[134]\ttraining's binary_logloss: 0.569279\n",
      "[135]\ttraining's binary_logloss: 0.56927\n",
      "[136]\ttraining's binary_logloss: 0.569201\n",
      "[137]\ttraining's binary_logloss: 0.569152\n",
      "[138]\ttraining's binary_logloss: 0.569095\n",
      "[139]\ttraining's binary_logloss: 0.569024\n",
      "[140]\ttraining's binary_logloss: 0.568951\n",
      "[141]\ttraining's binary_logloss: 0.568876\n",
      "[142]\ttraining's binary_logloss: 0.568814\n",
      "[143]\ttraining's binary_logloss: 0.568745\n",
      "[144]\ttraining's binary_logloss: 0.56868\n",
      "[145]\ttraining's binary_logloss: 0.568565\n",
      "[146]\ttraining's binary_logloss: 0.568517\n",
      "[147]\ttraining's binary_logloss: 0.568488\n",
      "[148]\ttraining's binary_logloss: 0.568438\n",
      "[149]\ttraining's binary_logloss: 0.568346\n",
      "[150]\ttraining's binary_logloss: 0.56831\n",
      "[151]\ttraining's binary_logloss: 0.568267\n",
      "[152]\ttraining's binary_logloss: 0.56821\n",
      "[153]\ttraining's binary_logloss: 0.568139\n",
      "[154]\ttraining's binary_logloss: 0.568053\n",
      "[155]\ttraining's binary_logloss: 0.567988\n",
      "[156]\ttraining's binary_logloss: 0.567911\n",
      "[157]\ttraining's binary_logloss: 0.567859\n",
      "[158]\ttraining's binary_logloss: 0.56777\n",
      "[159]\ttraining's binary_logloss: 0.567715\n",
      "[160]\ttraining's binary_logloss: 0.567658\n",
      "[161]\ttraining's binary_logloss: 0.567608\n",
      "[162]\ttraining's binary_logloss: 0.567563\n",
      "[163]\ttraining's binary_logloss: 0.567495\n",
      "[164]\ttraining's binary_logloss: 0.567427\n",
      "[165]\ttraining's binary_logloss: 0.56735\n",
      "[166]\ttraining's binary_logloss: 0.567254\n",
      "[167]\ttraining's binary_logloss: 0.567161\n",
      "[168]\ttraining's binary_logloss: 0.567106\n",
      "[169]\ttraining's binary_logloss: 0.56702\n",
      "[170]\ttraining's binary_logloss: 0.566953\n",
      "[171]\ttraining's binary_logloss: 0.566879\n",
      "[172]\ttraining's binary_logloss: 0.566808\n",
      "[173]\ttraining's binary_logloss: 0.56672\n",
      "[174]\ttraining's binary_logloss: 0.566647\n",
      "[175]\ttraining's binary_logloss: 0.566576\n",
      "[176]\ttraining's binary_logloss: 0.566525\n",
      "[177]\ttraining's binary_logloss: 0.566447\n",
      "[178]\ttraining's binary_logloss: 0.566378\n",
      "[179]\ttraining's binary_logloss: 0.566299\n",
      "[180]\ttraining's binary_logloss: 0.56622\n",
      "[181]\ttraining's binary_logloss: 0.566149\n",
      "[182]\ttraining's binary_logloss: 0.566111\n",
      "[183]\ttraining's binary_logloss: 0.566049\n",
      "[184]\ttraining's binary_logloss: 0.566\n",
      "[185]\ttraining's binary_logloss: 0.565986\n",
      "[186]\ttraining's binary_logloss: 0.565958\n",
      "[187]\ttraining's binary_logloss: 0.565925\n",
      "[188]\ttraining's binary_logloss: 0.565879\n",
      "[189]\ttraining's binary_logloss: 0.565852\n",
      "[190]\ttraining's binary_logloss: 0.565815\n",
      "[191]\ttraining's binary_logloss: 0.565755\n",
      "[192]\ttraining's binary_logloss: 0.565713\n",
      "[193]\ttraining's binary_logloss: 0.565647\n",
      "[194]\ttraining's binary_logloss: 0.565576\n",
      "[195]\ttraining's binary_logloss: 0.565544\n",
      "[196]\ttraining's binary_logloss: 0.565437\n",
      "[197]\ttraining's binary_logloss: 0.565337\n",
      "[198]\ttraining's binary_logloss: 0.565246\n",
      "[199]\ttraining's binary_logloss: 0.565133\n",
      "[200]\ttraining's binary_logloss: 0.565026\n",
      "[201]\ttraining's binary_logloss: 0.564913\n",
      "[202]\ttraining's binary_logloss: 0.564799\n",
      "[203]\ttraining's binary_logloss: 0.564706\n",
      "[204]\ttraining's binary_logloss: 0.5646\n",
      "[205]\ttraining's binary_logloss: 0.564494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[206]\ttraining's binary_logloss: 0.564402\n",
      "[207]\ttraining's binary_logloss: 0.564351\n",
      "[208]\ttraining's binary_logloss: 0.564276\n",
      "[209]\ttraining's binary_logloss: 0.564207\n",
      "[210]\ttraining's binary_logloss: 0.564113\n",
      "[211]\ttraining's binary_logloss: 0.564013\n",
      "[212]\ttraining's binary_logloss: 0.563893\n",
      "[213]\ttraining's binary_logloss: 0.563777\n",
      "[214]\ttraining's binary_logloss: 0.563675\n",
      "[215]\ttraining's binary_logloss: 0.563574\n",
      "[216]\ttraining's binary_logloss: 0.563439\n",
      "[217]\ttraining's binary_logloss: 0.563316\n",
      "[218]\ttraining's binary_logloss: 0.563193\n",
      "[219]\ttraining's binary_logloss: 0.563079\n",
      "[220]\ttraining's binary_logloss: 0.562965\n",
      "[221]\ttraining's binary_logloss: 0.562882\n",
      "[222]\ttraining's binary_logloss: 0.562799\n",
      "[223]\ttraining's binary_logloss: 0.562722\n",
      "[224]\ttraining's binary_logloss: 0.562638\n",
      "[225]\ttraining's binary_logloss: 0.562511\n",
      "[226]\ttraining's binary_logloss: 0.562425\n",
      "[227]\ttraining's binary_logloss: 0.562301\n",
      "[228]\ttraining's binary_logloss: 0.56221\n",
      "[229]\ttraining's binary_logloss: 0.56213\n",
      "[230]\ttraining's binary_logloss: 0.562057\n",
      "[231]\ttraining's binary_logloss: 0.561921\n",
      "[232]\ttraining's binary_logloss: 0.561793\n",
      "[233]\ttraining's binary_logloss: 0.561688\n",
      "[234]\ttraining's binary_logloss: 0.561577\n",
      "[235]\ttraining's binary_logloss: 0.561458\n",
      "[236]\ttraining's binary_logloss: 0.561351\n",
      "[237]\ttraining's binary_logloss: 0.56126\n",
      "[238]\ttraining's binary_logloss: 0.56119\n",
      "[239]\ttraining's binary_logloss: 0.561078\n",
      "[240]\ttraining's binary_logloss: 0.561005\n",
      "[241]\ttraining's binary_logloss: 0.560905\n",
      "[242]\ttraining's binary_logloss: 0.560823\n",
      "[243]\ttraining's binary_logloss: 0.560732\n",
      "[244]\ttraining's binary_logloss: 0.560632\n",
      "[245]\ttraining's binary_logloss: 0.560559\n",
      "[246]\ttraining's binary_logloss: 0.560434\n",
      "[247]\ttraining's binary_logloss: 0.560321\n",
      "[248]\ttraining's binary_logloss: 0.560201\n",
      "[249]\ttraining's binary_logloss: 0.560085\n",
      "[250]\ttraining's binary_logloss: 0.55998\n",
      "[251]\ttraining's binary_logloss: 0.559871\n",
      "[252]\ttraining's binary_logloss: 0.559772\n",
      "[253]\ttraining's binary_logloss: 0.559663\n",
      "[254]\ttraining's binary_logloss: 0.559571\n",
      "[255]\ttraining's binary_logloss: 0.559494\n",
      "[256]\ttraining's binary_logloss: 0.559384\n",
      "[257]\ttraining's binary_logloss: 0.55927\n",
      "[258]\ttraining's binary_logloss: 0.559182\n",
      "[259]\ttraining's binary_logloss: 0.559089\n",
      "[260]\ttraining's binary_logloss: 0.55899\n",
      "[261]\ttraining's binary_logloss: 0.558882\n",
      "[262]\ttraining's binary_logloss: 0.558733\n",
      "[263]\ttraining's binary_logloss: 0.558604\n",
      "[264]\ttraining's binary_logloss: 0.558464\n",
      "[265]\ttraining's binary_logloss: 0.558319\n",
      "[266]\ttraining's binary_logloss: 0.55822\n",
      "[267]\ttraining's binary_logloss: 0.558121\n",
      "[268]\ttraining's binary_logloss: 0.558025\n",
      "[269]\ttraining's binary_logloss: 0.55791\n",
      "[270]\ttraining's binary_logloss: 0.557823\n",
      "[271]\ttraining's binary_logloss: 0.557745\n",
      "[272]\ttraining's binary_logloss: 0.557663\n",
      "[273]\ttraining's binary_logloss: 0.557582\n",
      "[274]\ttraining's binary_logloss: 0.557472\n",
      "[275]\ttraining's binary_logloss: 0.557374\n",
      "[276]\ttraining's binary_logloss: 0.557243\n",
      "[277]\ttraining's binary_logloss: 0.55716\n",
      "[278]\ttraining's binary_logloss: 0.557047\n",
      "[279]\ttraining's binary_logloss: 0.556934\n",
      "[280]\ttraining's binary_logloss: 0.556819\n",
      "[281]\ttraining's binary_logloss: 0.556728\n",
      "[282]\ttraining's binary_logloss: 0.556613\n",
      "[283]\ttraining's binary_logloss: 0.556514\n",
      "[284]\ttraining's binary_logloss: 0.556407\n",
      "[285]\ttraining's binary_logloss: 0.556299\n",
      "[286]\ttraining's binary_logloss: 0.556118\n",
      "[287]\ttraining's binary_logloss: 0.55594\n",
      "[288]\ttraining's binary_logloss: 0.555757\n",
      "[289]\ttraining's binary_logloss: 0.555594\n",
      "[290]\ttraining's binary_logloss: 0.555422\n",
      "[291]\ttraining's binary_logloss: 0.555286\n",
      "[292]\ttraining's binary_logloss: 0.555152\n",
      "[293]\ttraining's binary_logloss: 0.555032\n",
      "[294]\ttraining's binary_logloss: 0.554937\n",
      "[295]\ttraining's binary_logloss: 0.554824\n",
      "[296]\ttraining's binary_logloss: 0.554674\n",
      "[297]\ttraining's binary_logloss: 0.554525\n",
      "[298]\ttraining's binary_logloss: 0.554374\n",
      "[299]\ttraining's binary_logloss: 0.554212\n",
      "[300]\ttraining's binary_logloss: 0.554046\n",
      "[301]\ttraining's binary_logloss: 0.553912\n",
      "[302]\ttraining's binary_logloss: 0.553776\n",
      "[303]\ttraining's binary_logloss: 0.553635\n",
      "[304]\ttraining's binary_logloss: 0.553497\n",
      "[305]\ttraining's binary_logloss: 0.553356\n",
      "[306]\ttraining's binary_logloss: 0.553191\n",
      "[307]\ttraining's binary_logloss: 0.553026\n",
      "[308]\ttraining's binary_logloss: 0.55285\n",
      "[309]\ttraining's binary_logloss: 0.552696\n",
      "[310]\ttraining's binary_logloss: 0.552524\n",
      "[311]\ttraining's binary_logloss: 0.5524\n",
      "[312]\ttraining's binary_logloss: 0.552279\n",
      "[313]\ttraining's binary_logloss: 0.55216\n",
      "[314]\ttraining's binary_logloss: 0.552065\n",
      "[315]\ttraining's binary_logloss: 0.551941\n",
      "[316]\ttraining's binary_logloss: 0.551817\n",
      "[317]\ttraining's binary_logloss: 0.551698\n",
      "[318]\ttraining's binary_logloss: 0.551586\n",
      "[319]\ttraining's binary_logloss: 0.551482\n",
      "[320]\ttraining's binary_logloss: 0.55136\n",
      "[321]\ttraining's binary_logloss: 0.551268\n",
      "[322]\ttraining's binary_logloss: 0.551185\n",
      "[323]\ttraining's binary_logloss: 0.551094\n",
      "[324]\ttraining's binary_logloss: 0.551019\n",
      "[325]\ttraining's binary_logloss: 0.550934\n",
      "[326]\ttraining's binary_logloss: 0.550835\n",
      "[327]\ttraining's binary_logloss: 0.550743\n",
      "[328]\ttraining's binary_logloss: 0.550658\n",
      "[329]\ttraining's binary_logloss: 0.550577\n",
      "[330]\ttraining's binary_logloss: 0.550481\n",
      "[331]\ttraining's binary_logloss: 0.550331\n",
      "[332]\ttraining's binary_logloss: 0.55016\n",
      "[333]\ttraining's binary_logloss: 0.549995\n",
      "[334]\ttraining's binary_logloss: 0.549858\n",
      "[335]\ttraining's binary_logloss: 0.54969\n",
      "[336]\ttraining's binary_logloss: 0.549525\n",
      "[337]\ttraining's binary_logloss: 0.549365\n",
      "[338]\ttraining's binary_logloss: 0.549227\n",
      "[339]\ttraining's binary_logloss: 0.549059\n",
      "[340]\ttraining's binary_logloss: 0.548911\n",
      "[341]\ttraining's binary_logloss: 0.548751\n",
      "[342]\ttraining's binary_logloss: 0.548604\n",
      "[343]\ttraining's binary_logloss: 0.548433\n",
      "[344]\ttraining's binary_logloss: 0.548278\n",
      "[345]\ttraining's binary_logloss: 0.548122\n",
      "[346]\ttraining's binary_logloss: 0.548044\n",
      "[347]\ttraining's binary_logloss: 0.547941\n",
      "[348]\ttraining's binary_logloss: 0.54786\n",
      "[349]\ttraining's binary_logloss: 0.547803\n",
      "[350]\ttraining's binary_logloss: 0.547712\n",
      "[351]\ttraining's binary_logloss: 0.547544\n",
      "[352]\ttraining's binary_logloss: 0.547388\n",
      "[353]\ttraining's binary_logloss: 0.54724\n",
      "[354]\ttraining's binary_logloss: 0.547065\n",
      "[355]\ttraining's binary_logloss: 0.54689\n",
      "[356]\ttraining's binary_logloss: 0.546749\n",
      "[357]\ttraining's binary_logloss: 0.546621\n",
      "[358]\ttraining's binary_logloss: 0.546487\n",
      "[359]\ttraining's binary_logloss: 0.546363\n",
      "[360]\ttraining's binary_logloss: 0.546236\n",
      "[361]\ttraining's binary_logloss: 0.546095\n",
      "[362]\ttraining's binary_logloss: 0.545961\n",
      "[363]\ttraining's binary_logloss: 0.545828\n",
      "[364]\ttraining's binary_logloss: 0.545698\n",
      "[365]\ttraining's binary_logloss: 0.545568\n",
      "[366]\ttraining's binary_logloss: 0.545484\n",
      "[367]\ttraining's binary_logloss: 0.545379\n",
      "[368]\ttraining's binary_logloss: 0.54529\n",
      "[369]\ttraining's binary_logloss: 0.545162\n",
      "[370]\ttraining's binary_logloss: 0.545048\n",
      "[371]\ttraining's binary_logloss: 0.544899\n",
      "[372]\ttraining's binary_logloss: 0.544762\n",
      "[373]\ttraining's binary_logloss: 0.544614\n",
      "[374]\ttraining's binary_logloss: 0.544469\n",
      "[375]\ttraining's binary_logloss: 0.54433\n",
      "[376]\ttraining's binary_logloss: 0.544173\n",
      "[377]\ttraining's binary_logloss: 0.544015\n",
      "[378]\ttraining's binary_logloss: 0.543835\n",
      "[379]\ttraining's binary_logloss: 0.543657\n",
      "[380]\ttraining's binary_logloss: 0.543497\n",
      "[381]\ttraining's binary_logloss: 0.543379\n",
      "[382]\ttraining's binary_logloss: 0.543242\n",
      "[383]\ttraining's binary_logloss: 0.543131\n",
      "[384]\ttraining's binary_logloss: 0.543008\n",
      "[385]\ttraining's binary_logloss: 0.54288\n",
      "[386]\ttraining's binary_logloss: 0.542756\n",
      "[387]\ttraining's binary_logloss: 0.542614\n",
      "[388]\ttraining's binary_logloss: 0.542464\n",
      "[389]\ttraining's binary_logloss: 0.542361\n",
      "[390]\ttraining's binary_logloss: 0.542244\n",
      "[391]\ttraining's binary_logloss: 0.542035\n",
      "[392]\ttraining's binary_logloss: 0.541841\n",
      "[393]\ttraining's binary_logloss: 0.541669\n",
      "[394]\ttraining's binary_logloss: 0.541515\n",
      "[395]\ttraining's binary_logloss: 0.541318\n",
      "[396]\ttraining's binary_logloss: 0.54118\n",
      "[397]\ttraining's binary_logloss: 0.54102\n",
      "[398]\ttraining's binary_logloss: 0.540846\n",
      "[399]\ttraining's binary_logloss: 0.54068\n",
      "[400]\ttraining's binary_logloss: 0.540558\n",
      "[401]\ttraining's binary_logloss: 0.540442\n",
      "[402]\ttraining's binary_logloss: 0.5403\n",
      "[403]\ttraining's binary_logloss: 0.540156\n",
      "[404]\ttraining's binary_logloss: 0.540006\n",
      "[405]\ttraining's binary_logloss: 0.539858\n",
      "[406]\ttraining's binary_logloss: 0.539691\n",
      "[407]\ttraining's binary_logloss: 0.53955\n",
      "[408]\ttraining's binary_logloss: 0.539437\n",
      "[409]\ttraining's binary_logloss: 0.539321\n",
      "[410]\ttraining's binary_logloss: 0.539198\n",
      "[411]\ttraining's binary_logloss: 0.539056\n",
      "[412]\ttraining's binary_logloss: 0.538911\n",
      "[413]\ttraining's binary_logloss: 0.538767\n",
      "[414]\ttraining's binary_logloss: 0.53863\n",
      "[415]\ttraining's binary_logloss: 0.538503\n",
      "[416]\ttraining's binary_logloss: 0.538331\n",
      "[417]\ttraining's binary_logloss: 0.538192\n",
      "[418]\ttraining's binary_logloss: 0.538056\n",
      "[419]\ttraining's binary_logloss: 0.537945\n",
      "[420]\ttraining's binary_logloss: 0.537807\n",
      "[421]\ttraining's binary_logloss: 0.537706\n",
      "[422]\ttraining's binary_logloss: 0.53762\n",
      "[423]\ttraining's binary_logloss: 0.537535\n",
      "[424]\ttraining's binary_logloss: 0.537454\n",
      "[425]\ttraining's binary_logloss: 0.537378\n",
      "[426]\ttraining's binary_logloss: 0.537215\n",
      "[427]\ttraining's binary_logloss: 0.537083\n",
      "[428]\ttraining's binary_logloss: 0.536902\n",
      "[429]\ttraining's binary_logloss: 0.536724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[430]\ttraining's binary_logloss: 0.536555\n",
      "[431]\ttraining's binary_logloss: 0.53644\n",
      "[432]\ttraining's binary_logloss: 0.536331\n",
      "[433]\ttraining's binary_logloss: 0.536219\n",
      "[434]\ttraining's binary_logloss: 0.536089\n",
      "[435]\ttraining's binary_logloss: 0.535986\n",
      "[436]\ttraining's binary_logloss: 0.535806\n",
      "[437]\ttraining's binary_logloss: 0.535665\n",
      "[438]\ttraining's binary_logloss: 0.535519\n",
      "[439]\ttraining's binary_logloss: 0.53538\n",
      "[440]\ttraining's binary_logloss: 0.53524\n",
      "[441]\ttraining's binary_logloss: 0.535069\n",
      "[442]\ttraining's binary_logloss: 0.534889\n",
      "[443]\ttraining's binary_logloss: 0.534737\n",
      "[444]\ttraining's binary_logloss: 0.534565\n",
      "[445]\ttraining's binary_logloss: 0.534411\n",
      "[446]\ttraining's binary_logloss: 0.534288\n",
      "[447]\ttraining's binary_logloss: 0.534164\n",
      "[448]\ttraining's binary_logloss: 0.534047\n",
      "[449]\ttraining's binary_logloss: 0.533911\n",
      "[450]\ttraining's binary_logloss: 0.533802\n",
      "[451]\ttraining's binary_logloss: 0.533716\n",
      "[452]\ttraining's binary_logloss: 0.533632\n",
      "[453]\ttraining's binary_logloss: 0.533552\n",
      "[454]\ttraining's binary_logloss: 0.533466\n",
      "[455]\ttraining's binary_logloss: 0.533388\n",
      "[456]\ttraining's binary_logloss: 0.533236\n",
      "[457]\ttraining's binary_logloss: 0.533121\n",
      "[458]\ttraining's binary_logloss: 0.532962\n",
      "[459]\ttraining's binary_logloss: 0.532804\n",
      "[460]\ttraining's binary_logloss: 0.532661\n",
      "[461]\ttraining's binary_logloss: 0.532497\n",
      "[462]\ttraining's binary_logloss: 0.532348\n",
      "[463]\ttraining's binary_logloss: 0.53219\n",
      "[464]\ttraining's binary_logloss: 0.532043\n",
      "[465]\ttraining's binary_logloss: 0.531904\n",
      "[466]\ttraining's binary_logloss: 0.531716\n",
      "[467]\ttraining's binary_logloss: 0.531547\n",
      "[468]\ttraining's binary_logloss: 0.531371\n",
      "[469]\ttraining's binary_logloss: 0.531196\n",
      "[470]\ttraining's binary_logloss: 0.531021\n",
      "[471]\ttraining's binary_logloss: 0.530856\n",
      "[472]\ttraining's binary_logloss: 0.530696\n",
      "[473]\ttraining's binary_logloss: 0.530545\n",
      "[474]\ttraining's binary_logloss: 0.530387\n",
      "[475]\ttraining's binary_logloss: 0.530256\n",
      "[476]\ttraining's binary_logloss: 0.530131\n",
      "[477]\ttraining's binary_logloss: 0.530015\n",
      "[478]\ttraining's binary_logloss: 0.529879\n",
      "[479]\ttraining's binary_logloss: 0.529756\n",
      "[480]\ttraining's binary_logloss: 0.529625\n",
      "[481]\ttraining's binary_logloss: 0.529525\n",
      "[482]\ttraining's binary_logloss: 0.529412\n",
      "[483]\ttraining's binary_logloss: 0.529306\n",
      "[484]\ttraining's binary_logloss: 0.529202\n",
      "[485]\ttraining's binary_logloss: 0.529112\n",
      "[486]\ttraining's binary_logloss: 0.528985\n",
      "[487]\ttraining's binary_logloss: 0.528864\n",
      "[488]\ttraining's binary_logloss: 0.528738\n",
      "[489]\ttraining's binary_logloss: 0.528615\n",
      "[490]\ttraining's binary_logloss: 0.528464\n",
      "[491]\ttraining's binary_logloss: 0.528336\n",
      "[492]\ttraining's binary_logloss: 0.528224\n",
      "[493]\ttraining's binary_logloss: 0.528113\n",
      "[494]\ttraining's binary_logloss: 0.52797\n",
      "[495]\ttraining's binary_logloss: 0.527867\n",
      "[496]\ttraining's binary_logloss: 0.527697\n",
      "[497]\ttraining's binary_logloss: 0.527534\n",
      "[498]\ttraining's binary_logloss: 0.527361\n",
      "[499]\ttraining's binary_logloss: 0.527192\n",
      "[500]\ttraining's binary_logloss: 0.527024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614103\n",
      "[2]\ttraining's binary_logloss: 0.612711\n",
      "[3]\ttraining's binary_logloss: 0.611346\n",
      "[4]\ttraining's binary_logloss: 0.610017\n",
      "[5]\ttraining's binary_logloss: 0.608763\n",
      "[6]\ttraining's binary_logloss: 0.607512\n",
      "[7]\ttraining's binary_logloss: 0.606224\n",
      "[8]\ttraining's binary_logloss: 0.604973\n",
      "[9]\ttraining's binary_logloss: 0.603769\n",
      "[10]\ttraining's binary_logloss: 0.602806\n",
      "[11]\ttraining's binary_logloss: 0.601801\n",
      "[12]\ttraining's binary_logloss: 0.600709\n",
      "[13]\ttraining's binary_logloss: 0.599723\n",
      "[14]\ttraining's binary_logloss: 0.598672\n",
      "[15]\ttraining's binary_logloss: 0.597665\n",
      "[16]\ttraining's binary_logloss: 0.596703\n",
      "[17]\ttraining's binary_logloss: 0.595753\n",
      "[18]\ttraining's binary_logloss: 0.594799\n",
      "[19]\ttraining's binary_logloss: 0.593946\n",
      "[20]\ttraining's binary_logloss: 0.593008\n",
      "[21]\ttraining's binary_logloss: 0.592126\n",
      "[22]\ttraining's binary_logloss: 0.591332\n",
      "[23]\ttraining's binary_logloss: 0.590498\n",
      "[24]\ttraining's binary_logloss: 0.589719\n",
      "[25]\ttraining's binary_logloss: 0.588944\n",
      "[26]\ttraining's binary_logloss: 0.588196\n",
      "[27]\ttraining's binary_logloss: 0.587494\n",
      "[28]\ttraining's binary_logloss: 0.586798\n",
      "[29]\ttraining's binary_logloss: 0.586122\n",
      "[30]\ttraining's binary_logloss: 0.585488\n",
      "[31]\ttraining's binary_logloss: 0.584883\n",
      "[32]\ttraining's binary_logloss: 0.584209\n",
      "[33]\ttraining's binary_logloss: 0.583618\n",
      "[34]\ttraining's binary_logloss: 0.582967\n",
      "[35]\ttraining's binary_logloss: 0.582412\n",
      "[36]\ttraining's binary_logloss: 0.58185\n",
      "[37]\ttraining's binary_logloss: 0.581322\n",
      "[38]\ttraining's binary_logloss: 0.58074\n",
      "[39]\ttraining's binary_logloss: 0.580243\n",
      "[40]\ttraining's binary_logloss: 0.579773\n",
      "[41]\ttraining's binary_logloss: 0.579225\n",
      "[42]\ttraining's binary_logloss: 0.578693\n",
      "[43]\ttraining's binary_logloss: 0.578174\n",
      "[44]\ttraining's binary_logloss: 0.577699\n",
      "[45]\ttraining's binary_logloss: 0.57723\n",
      "[46]\ttraining's binary_logloss: 0.576722\n",
      "[47]\ttraining's binary_logloss: 0.576233\n",
      "[48]\ttraining's binary_logloss: 0.575762\n",
      "[49]\ttraining's binary_logloss: 0.575312\n",
      "[50]\ttraining's binary_logloss: 0.574842\n",
      "[51]\ttraining's binary_logloss: 0.574421\n",
      "[52]\ttraining's binary_logloss: 0.574071\n",
      "[53]\ttraining's binary_logloss: 0.57367\n",
      "[54]\ttraining's binary_logloss: 0.573258\n",
      "[55]\ttraining's binary_logloss: 0.5729\n",
      "[56]\ttraining's binary_logloss: 0.572545\n",
      "[57]\ttraining's binary_logloss: 0.572195\n",
      "[58]\ttraining's binary_logloss: 0.57187\n",
      "[59]\ttraining's binary_logloss: 0.571541\n",
      "[60]\ttraining's binary_logloss: 0.571218\n",
      "[61]\ttraining's binary_logloss: 0.570966\n",
      "[62]\ttraining's binary_logloss: 0.570633\n",
      "[63]\ttraining's binary_logloss: 0.570338\n",
      "[64]\ttraining's binary_logloss: 0.570007\n",
      "[65]\ttraining's binary_logloss: 0.569714\n",
      "[66]\ttraining's binary_logloss: 0.569412\n",
      "[67]\ttraining's binary_logloss: 0.569112\n",
      "[68]\ttraining's binary_logloss: 0.568833\n",
      "[69]\ttraining's binary_logloss: 0.568552\n",
      "[70]\ttraining's binary_logloss: 0.568278\n",
      "[71]\ttraining's binary_logloss: 0.568058\n",
      "[72]\ttraining's binary_logloss: 0.5678\n",
      "[73]\ttraining's binary_logloss: 0.567497\n",
      "[74]\ttraining's binary_logloss: 0.567297\n",
      "[75]\ttraining's binary_logloss: 0.567086\n",
      "[76]\ttraining's binary_logloss: 0.566804\n",
      "[77]\ttraining's binary_logloss: 0.56652\n",
      "[78]\ttraining's binary_logloss: 0.566255\n",
      "[79]\ttraining's binary_logloss: 0.566005\n",
      "[80]\ttraining's binary_logloss: 0.565793\n",
      "[81]\ttraining's binary_logloss: 0.565532\n",
      "[82]\ttraining's binary_logloss: 0.565285\n",
      "[83]\ttraining's binary_logloss: 0.565095\n",
      "[84]\ttraining's binary_logloss: 0.564865\n",
      "[85]\ttraining's binary_logloss: 0.564639\n",
      "[86]\ttraining's binary_logloss: 0.564477\n",
      "[87]\ttraining's binary_logloss: 0.564288\n",
      "[88]\ttraining's binary_logloss: 0.564097\n",
      "[89]\ttraining's binary_logloss: 0.563919\n",
      "[90]\ttraining's binary_logloss: 0.563702\n",
      "[91]\ttraining's binary_logloss: 0.563514\n",
      "[92]\ttraining's binary_logloss: 0.563335\n",
      "[93]\ttraining's binary_logloss: 0.563102\n",
      "[94]\ttraining's binary_logloss: 0.562926\n",
      "[95]\ttraining's binary_logloss: 0.562745\n",
      "[96]\ttraining's binary_logloss: 0.56253\n",
      "[97]\ttraining's binary_logloss: 0.562363\n",
      "[98]\ttraining's binary_logloss: 0.562148\n",
      "[99]\ttraining's binary_logloss: 0.561945\n",
      "[100]\ttraining's binary_logloss: 0.56179\n",
      "[101]\ttraining's binary_logloss: 0.561589\n",
      "[102]\ttraining's binary_logloss: 0.561413\n",
      "[103]\ttraining's binary_logloss: 0.561234\n",
      "[104]\ttraining's binary_logloss: 0.561064\n",
      "[105]\ttraining's binary_logloss: 0.560898\n",
      "[106]\ttraining's binary_logloss: 0.560695\n",
      "[107]\ttraining's binary_logloss: 0.560504\n",
      "[108]\ttraining's binary_logloss: 0.560319\n",
      "[109]\ttraining's binary_logloss: 0.56016\n",
      "[110]\ttraining's binary_logloss: 0.560022\n",
      "[111]\ttraining's binary_logloss: 0.559859\n",
      "[112]\ttraining's binary_logloss: 0.559677\n",
      "[113]\ttraining's binary_logloss: 0.559496\n",
      "[114]\ttraining's binary_logloss: 0.559329\n",
      "[115]\ttraining's binary_logloss: 0.559166\n",
      "[116]\ttraining's binary_logloss: 0.559037\n",
      "[117]\ttraining's binary_logloss: 0.558864\n",
      "[118]\ttraining's binary_logloss: 0.558713\n",
      "[119]\ttraining's binary_logloss: 0.558568\n",
      "[120]\ttraining's binary_logloss: 0.558431\n",
      "[121]\ttraining's binary_logloss: 0.558326\n",
      "[122]\ttraining's binary_logloss: 0.558217\n",
      "[123]\ttraining's binary_logloss: 0.558109\n",
      "[124]\ttraining's binary_logloss: 0.557997\n",
      "[125]\ttraining's binary_logloss: 0.557853\n",
      "[126]\ttraining's binary_logloss: 0.5577\n",
      "[127]\ttraining's binary_logloss: 0.557517\n",
      "[128]\ttraining's binary_logloss: 0.557369\n",
      "[129]\ttraining's binary_logloss: 0.557246\n",
      "[130]\ttraining's binary_logloss: 0.557112\n",
      "[131]\ttraining's binary_logloss: 0.557013\n",
      "[132]\ttraining's binary_logloss: 0.556871\n",
      "[133]\ttraining's binary_logloss: 0.556693\n",
      "[134]\ttraining's binary_logloss: 0.556507\n",
      "[135]\ttraining's binary_logloss: 0.556352\n",
      "[136]\ttraining's binary_logloss: 0.5562\n",
      "[137]\ttraining's binary_logloss: 0.556062\n",
      "[138]\ttraining's binary_logloss: 0.555907\n",
      "[139]\ttraining's binary_logloss: 0.555756\n",
      "[140]\ttraining's binary_logloss: 0.555614\n",
      "[141]\ttraining's binary_logloss: 0.555465\n",
      "[142]\ttraining's binary_logloss: 0.555338\n",
      "[143]\ttraining's binary_logloss: 0.555212\n",
      "[144]\ttraining's binary_logloss: 0.555072\n",
      "[145]\ttraining's binary_logloss: 0.554919\n",
      "[146]\ttraining's binary_logloss: 0.554755\n",
      "[147]\ttraining's binary_logloss: 0.554598\n",
      "[148]\ttraining's binary_logloss: 0.554451\n",
      "[149]\ttraining's binary_logloss: 0.554309\n",
      "[150]\ttraining's binary_logloss: 0.554161\n",
      "[151]\ttraining's binary_logloss: 0.553966\n",
      "[152]\ttraining's binary_logloss: 0.553792\n",
      "[153]\ttraining's binary_logloss: 0.553642\n",
      "[154]\ttraining's binary_logloss: 0.553497\n",
      "[155]\ttraining's binary_logloss: 0.5533\n",
      "[156]\ttraining's binary_logloss: 0.553201\n",
      "[157]\ttraining's binary_logloss: 0.553073\n",
      "[158]\ttraining's binary_logloss: 0.552983\n",
      "[159]\ttraining's binary_logloss: 0.552911\n",
      "[160]\ttraining's binary_logloss: 0.552809\n",
      "[161]\ttraining's binary_logloss: 0.552618\n",
      "[162]\ttraining's binary_logloss: 0.552416\n",
      "[163]\ttraining's binary_logloss: 0.552251\n",
      "[164]\ttraining's binary_logloss: 0.552072\n",
      "[165]\ttraining's binary_logloss: 0.551908\n",
      "[166]\ttraining's binary_logloss: 0.551746\n",
      "[167]\ttraining's binary_logloss: 0.551572\n",
      "[168]\ttraining's binary_logloss: 0.551412\n",
      "[169]\ttraining's binary_logloss: 0.551254\n",
      "[170]\ttraining's binary_logloss: 0.551068\n",
      "[171]\ttraining's binary_logloss: 0.550883\n",
      "[172]\ttraining's binary_logloss: 0.550692\n",
      "[173]\ttraining's binary_logloss: 0.550517\n",
      "[174]\ttraining's binary_logloss: 0.550385\n",
      "[175]\ttraining's binary_logloss: 0.550247\n",
      "[176]\ttraining's binary_logloss: 0.550132\n",
      "[177]\ttraining's binary_logloss: 0.549988\n",
      "[178]\ttraining's binary_logloss: 0.549816\n",
      "[179]\ttraining's binary_logloss: 0.549712\n",
      "[180]\ttraining's binary_logloss: 0.549586\n",
      "[181]\ttraining's binary_logloss: 0.549439\n",
      "[182]\ttraining's binary_logloss: 0.549266\n",
      "[183]\ttraining's binary_logloss: 0.549135\n",
      "[184]\ttraining's binary_logloss: 0.548975\n",
      "[185]\ttraining's binary_logloss: 0.548829\n",
      "[186]\ttraining's binary_logloss: 0.548682\n",
      "[187]\ttraining's binary_logloss: 0.548542\n",
      "[188]\ttraining's binary_logloss: 0.548387\n",
      "[189]\ttraining's binary_logloss: 0.548293\n",
      "[190]\ttraining's binary_logloss: 0.548144\n",
      "[191]\ttraining's binary_logloss: 0.547967\n",
      "[192]\ttraining's binary_logloss: 0.547789\n",
      "[193]\ttraining's binary_logloss: 0.547635\n",
      "[194]\ttraining's binary_logloss: 0.547475\n",
      "[195]\ttraining's binary_logloss: 0.547298\n",
      "[196]\ttraining's binary_logloss: 0.547135\n",
      "[197]\ttraining's binary_logloss: 0.54698\n",
      "[198]\ttraining's binary_logloss: 0.546807\n",
      "[199]\ttraining's binary_logloss: 0.546639\n",
      "[200]\ttraining's binary_logloss: 0.546475\n",
      "[201]\ttraining's binary_logloss: 0.546328\n",
      "[202]\ttraining's binary_logloss: 0.546184\n",
      "[203]\ttraining's binary_logloss: 0.546044\n",
      "[204]\ttraining's binary_logloss: 0.545878\n",
      "[205]\ttraining's binary_logloss: 0.545718\n",
      "[206]\ttraining's binary_logloss: 0.545597\n",
      "[207]\ttraining's binary_logloss: 0.545427\n",
      "[208]\ttraining's binary_logloss: 0.545274\n",
      "[209]\ttraining's binary_logloss: 0.545136\n",
      "[210]\ttraining's binary_logloss: 0.544993\n",
      "[211]\ttraining's binary_logloss: 0.544841\n",
      "[212]\ttraining's binary_logloss: 0.544673\n",
      "[213]\ttraining's binary_logloss: 0.544497\n",
      "[214]\ttraining's binary_logloss: 0.544339\n",
      "[215]\ttraining's binary_logloss: 0.544179\n",
      "[216]\ttraining's binary_logloss: 0.54403\n",
      "[217]\ttraining's binary_logloss: 0.543888\n",
      "[218]\ttraining's binary_logloss: 0.543749\n",
      "[219]\ttraining's binary_logloss: 0.543565\n",
      "[220]\ttraining's binary_logloss: 0.543426\n",
      "[221]\ttraining's binary_logloss: 0.543212\n",
      "[222]\ttraining's binary_logloss: 0.543051\n",
      "[223]\ttraining's binary_logloss: 0.542892\n",
      "[224]\ttraining's binary_logloss: 0.542712\n",
      "[225]\ttraining's binary_logloss: 0.542515\n",
      "[226]\ttraining's binary_logloss: 0.542388\n",
      "[227]\ttraining's binary_logloss: 0.542213\n",
      "[228]\ttraining's binary_logloss: 0.542054\n",
      "[229]\ttraining's binary_logloss: 0.541894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[230]\ttraining's binary_logloss: 0.541772\n",
      "[231]\ttraining's binary_logloss: 0.541584\n",
      "[232]\ttraining's binary_logloss: 0.541397\n",
      "[233]\ttraining's binary_logloss: 0.541212\n",
      "[234]\ttraining's binary_logloss: 0.541022\n",
      "[235]\ttraining's binary_logloss: 0.540853\n",
      "[236]\ttraining's binary_logloss: 0.54067\n",
      "[237]\ttraining's binary_logloss: 0.540461\n",
      "[238]\ttraining's binary_logloss: 0.540254\n",
      "[239]\ttraining's binary_logloss: 0.540067\n",
      "[240]\ttraining's binary_logloss: 0.539872\n",
      "[241]\ttraining's binary_logloss: 0.539671\n",
      "[242]\ttraining's binary_logloss: 0.539482\n",
      "[243]\ttraining's binary_logloss: 0.539288\n",
      "[244]\ttraining's binary_logloss: 0.539133\n",
      "[245]\ttraining's binary_logloss: 0.538954\n",
      "[246]\ttraining's binary_logloss: 0.538836\n",
      "[247]\ttraining's binary_logloss: 0.538723\n",
      "[248]\ttraining's binary_logloss: 0.538616\n",
      "[249]\ttraining's binary_logloss: 0.538523\n",
      "[250]\ttraining's binary_logloss: 0.538374\n",
      "[251]\ttraining's binary_logloss: 0.538214\n",
      "[252]\ttraining's binary_logloss: 0.538058\n",
      "[253]\ttraining's binary_logloss: 0.537901\n",
      "[254]\ttraining's binary_logloss: 0.537758\n",
      "[255]\ttraining's binary_logloss: 0.537591\n",
      "[256]\ttraining's binary_logloss: 0.537423\n",
      "[257]\ttraining's binary_logloss: 0.537258\n",
      "[258]\ttraining's binary_logloss: 0.537103\n",
      "[259]\ttraining's binary_logloss: 0.53697\n",
      "[260]\ttraining's binary_logloss: 0.53679\n",
      "[261]\ttraining's binary_logloss: 0.536639\n",
      "[262]\ttraining's binary_logloss: 0.536454\n",
      "[263]\ttraining's binary_logloss: 0.53628\n",
      "[264]\ttraining's binary_logloss: 0.536101\n",
      "[265]\ttraining's binary_logloss: 0.535928\n",
      "[266]\ttraining's binary_logloss: 0.53578\n",
      "[267]\ttraining's binary_logloss: 0.535645\n",
      "[268]\ttraining's binary_logloss: 0.535512\n",
      "[269]\ttraining's binary_logloss: 0.535351\n",
      "[270]\ttraining's binary_logloss: 0.53522\n",
      "[271]\ttraining's binary_logloss: 0.535008\n",
      "[272]\ttraining's binary_logloss: 0.534819\n",
      "[273]\ttraining's binary_logloss: 0.534628\n",
      "[274]\ttraining's binary_logloss: 0.534455\n",
      "[275]\ttraining's binary_logloss: 0.534283\n",
      "[276]\ttraining's binary_logloss: 0.534079\n",
      "[277]\ttraining's binary_logloss: 0.533875\n",
      "[278]\ttraining's binary_logloss: 0.533702\n",
      "[279]\ttraining's binary_logloss: 0.533521\n",
      "[280]\ttraining's binary_logloss: 0.533329\n",
      "[281]\ttraining's binary_logloss: 0.533175\n",
      "[282]\ttraining's binary_logloss: 0.533012\n",
      "[283]\ttraining's binary_logloss: 0.532846\n",
      "[284]\ttraining's binary_logloss: 0.53266\n",
      "[285]\ttraining's binary_logloss: 0.532513\n",
      "[286]\ttraining's binary_logloss: 0.532313\n",
      "[287]\ttraining's binary_logloss: 0.532108\n",
      "[288]\ttraining's binary_logloss: 0.531915\n",
      "[289]\ttraining's binary_logloss: 0.531724\n",
      "[290]\ttraining's binary_logloss: 0.531532\n",
      "[291]\ttraining's binary_logloss: 0.531331\n",
      "[292]\ttraining's binary_logloss: 0.531126\n",
      "[293]\ttraining's binary_logloss: 0.530915\n",
      "[294]\ttraining's binary_logloss: 0.530711\n",
      "[295]\ttraining's binary_logloss: 0.53052\n",
      "[296]\ttraining's binary_logloss: 0.530362\n",
      "[297]\ttraining's binary_logloss: 0.530188\n",
      "[298]\ttraining's binary_logloss: 0.530022\n",
      "[299]\ttraining's binary_logloss: 0.529859\n",
      "[300]\ttraining's binary_logloss: 0.529676\n",
      "[301]\ttraining's binary_logloss: 0.529486\n",
      "[302]\ttraining's binary_logloss: 0.529292\n",
      "[303]\ttraining's binary_logloss: 0.5291\n",
      "[304]\ttraining's binary_logloss: 0.528906\n",
      "[305]\ttraining's binary_logloss: 0.528717\n",
      "[306]\ttraining's binary_logloss: 0.528499\n",
      "[307]\ttraining's binary_logloss: 0.528315\n",
      "[308]\ttraining's binary_logloss: 0.528134\n",
      "[309]\ttraining's binary_logloss: 0.52794\n",
      "[310]\ttraining's binary_logloss: 0.527762\n",
      "[311]\ttraining's binary_logloss: 0.527606\n",
      "[312]\ttraining's binary_logloss: 0.527458\n",
      "[313]\ttraining's binary_logloss: 0.527295\n",
      "[314]\ttraining's binary_logloss: 0.527146\n",
      "[315]\ttraining's binary_logloss: 0.527012\n",
      "[316]\ttraining's binary_logloss: 0.526781\n",
      "[317]\ttraining's binary_logloss: 0.526552\n",
      "[318]\ttraining's binary_logloss: 0.526371\n",
      "[319]\ttraining's binary_logloss: 0.526187\n",
      "[320]\ttraining's binary_logloss: 0.525962\n",
      "[321]\ttraining's binary_logloss: 0.525721\n",
      "[322]\ttraining's binary_logloss: 0.525525\n",
      "[323]\ttraining's binary_logloss: 0.525355\n",
      "[324]\ttraining's binary_logloss: 0.525171\n",
      "[325]\ttraining's binary_logloss: 0.524958\n",
      "[326]\ttraining's binary_logloss: 0.524748\n",
      "[327]\ttraining's binary_logloss: 0.524545\n",
      "[328]\ttraining's binary_logloss: 0.524341\n",
      "[329]\ttraining's binary_logloss: 0.524144\n",
      "[330]\ttraining's binary_logloss: 0.523971\n",
      "[331]\ttraining's binary_logloss: 0.523771\n",
      "[332]\ttraining's binary_logloss: 0.523577\n",
      "[333]\ttraining's binary_logloss: 0.523379\n",
      "[334]\ttraining's binary_logloss: 0.523182\n",
      "[335]\ttraining's binary_logloss: 0.522992\n",
      "[336]\ttraining's binary_logloss: 0.522819\n",
      "[337]\ttraining's binary_logloss: 0.522634\n",
      "[338]\ttraining's binary_logloss: 0.522487\n",
      "[339]\ttraining's binary_logloss: 0.522326\n",
      "[340]\ttraining's binary_logloss: 0.52217\n",
      "[341]\ttraining's binary_logloss: 0.521981\n",
      "[342]\ttraining's binary_logloss: 0.52181\n",
      "[343]\ttraining's binary_logloss: 0.521633\n",
      "[344]\ttraining's binary_logloss: 0.521465\n",
      "[345]\ttraining's binary_logloss: 0.521295\n",
      "[346]\ttraining's binary_logloss: 0.521047\n",
      "[347]\ttraining's binary_logloss: 0.5208\n",
      "[348]\ttraining's binary_logloss: 0.520591\n",
      "[349]\ttraining's binary_logloss: 0.520418\n",
      "[350]\ttraining's binary_logloss: 0.520243\n",
      "[351]\ttraining's binary_logloss: 0.520043\n",
      "[352]\ttraining's binary_logloss: 0.519827\n",
      "[353]\ttraining's binary_logloss: 0.519603\n",
      "[354]\ttraining's binary_logloss: 0.519393\n",
      "[355]\ttraining's binary_logloss: 0.519218\n",
      "[356]\ttraining's binary_logloss: 0.519017\n",
      "[357]\ttraining's binary_logloss: 0.518817\n",
      "[358]\ttraining's binary_logloss: 0.51863\n",
      "[359]\ttraining's binary_logloss: 0.518437\n",
      "[360]\ttraining's binary_logloss: 0.518258\n",
      "[361]\ttraining's binary_logloss: 0.518023\n",
      "[362]\ttraining's binary_logloss: 0.517792\n",
      "[363]\ttraining's binary_logloss: 0.517584\n",
      "[364]\ttraining's binary_logloss: 0.517358\n",
      "[365]\ttraining's binary_logloss: 0.517129\n",
      "[366]\ttraining's binary_logloss: 0.516945\n",
      "[367]\ttraining's binary_logloss: 0.516721\n",
      "[368]\ttraining's binary_logloss: 0.516528\n",
      "[369]\ttraining's binary_logloss: 0.516352\n",
      "[370]\ttraining's binary_logloss: 0.51617\n",
      "[371]\ttraining's binary_logloss: 0.515963\n",
      "[372]\ttraining's binary_logloss: 0.515759\n",
      "[373]\ttraining's binary_logloss: 0.515575\n",
      "[374]\ttraining's binary_logloss: 0.515377\n",
      "[375]\ttraining's binary_logloss: 0.515208\n",
      "[376]\ttraining's binary_logloss: 0.515033\n",
      "[377]\ttraining's binary_logloss: 0.514831\n",
      "[378]\ttraining's binary_logloss: 0.514611\n",
      "[379]\ttraining's binary_logloss: 0.514398\n",
      "[380]\ttraining's binary_logloss: 0.514188\n",
      "[381]\ttraining's binary_logloss: 0.514029\n",
      "[382]\ttraining's binary_logloss: 0.513864\n",
      "[383]\ttraining's binary_logloss: 0.513707\n",
      "[384]\ttraining's binary_logloss: 0.513508\n",
      "[385]\ttraining's binary_logloss: 0.513363\n",
      "[386]\ttraining's binary_logloss: 0.513168\n",
      "[387]\ttraining's binary_logloss: 0.512925\n",
      "[388]\ttraining's binary_logloss: 0.512732\n",
      "[389]\ttraining's binary_logloss: 0.512488\n",
      "[390]\ttraining's binary_logloss: 0.512246\n",
      "[391]\ttraining's binary_logloss: 0.512066\n",
      "[392]\ttraining's binary_logloss: 0.511902\n",
      "[393]\ttraining's binary_logloss: 0.511733\n",
      "[394]\ttraining's binary_logloss: 0.511545\n",
      "[395]\ttraining's binary_logloss: 0.51136\n",
      "[396]\ttraining's binary_logloss: 0.51112\n",
      "[397]\ttraining's binary_logloss: 0.510893\n",
      "[398]\ttraining's binary_logloss: 0.510646\n",
      "[399]\ttraining's binary_logloss: 0.510402\n",
      "[400]\ttraining's binary_logloss: 0.510199\n",
      "[401]\ttraining's binary_logloss: 0.509927\n",
      "[402]\ttraining's binary_logloss: 0.509683\n",
      "[403]\ttraining's binary_logloss: 0.509451\n",
      "[404]\ttraining's binary_logloss: 0.509236\n",
      "[405]\ttraining's binary_logloss: 0.509022\n",
      "[406]\ttraining's binary_logloss: 0.508859\n",
      "[407]\ttraining's binary_logloss: 0.508684\n",
      "[408]\ttraining's binary_logloss: 0.508513\n",
      "[409]\ttraining's binary_logloss: 0.508356\n",
      "[410]\ttraining's binary_logloss: 0.508183\n",
      "[411]\ttraining's binary_logloss: 0.507935\n",
      "[412]\ttraining's binary_logloss: 0.507721\n",
      "[413]\ttraining's binary_logloss: 0.507502\n",
      "[414]\ttraining's binary_logloss: 0.507243\n",
      "[415]\ttraining's binary_logloss: 0.506973\n",
      "[416]\ttraining's binary_logloss: 0.506747\n",
      "[417]\ttraining's binary_logloss: 0.506521\n",
      "[418]\ttraining's binary_logloss: 0.506307\n",
      "[419]\ttraining's binary_logloss: 0.506097\n",
      "[420]\ttraining's binary_logloss: 0.505857\n",
      "[421]\ttraining's binary_logloss: 0.505688\n",
      "[422]\ttraining's binary_logloss: 0.505509\n",
      "[423]\ttraining's binary_logloss: 0.505358\n",
      "[424]\ttraining's binary_logloss: 0.505192\n",
      "[425]\ttraining's binary_logloss: 0.505026\n",
      "[426]\ttraining's binary_logloss: 0.504869\n",
      "[427]\ttraining's binary_logloss: 0.504705\n",
      "[428]\ttraining's binary_logloss: 0.504541\n",
      "[429]\ttraining's binary_logloss: 0.504379\n",
      "[430]\ttraining's binary_logloss: 0.504231\n",
      "[431]\ttraining's binary_logloss: 0.504036\n",
      "[432]\ttraining's binary_logloss: 0.503816\n",
      "[433]\ttraining's binary_logloss: 0.503625\n",
      "[434]\ttraining's binary_logloss: 0.503438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[435]\ttraining's binary_logloss: 0.503263\n",
      "[436]\ttraining's binary_logloss: 0.503049\n",
      "[437]\ttraining's binary_logloss: 0.502851\n",
      "[438]\ttraining's binary_logloss: 0.502711\n",
      "[439]\ttraining's binary_logloss: 0.502535\n",
      "[440]\ttraining's binary_logloss: 0.502341\n",
      "[441]\ttraining's binary_logloss: 0.502164\n",
      "[442]\ttraining's binary_logloss: 0.501944\n",
      "[443]\ttraining's binary_logloss: 0.501752\n",
      "[444]\ttraining's binary_logloss: 0.501541\n",
      "[445]\ttraining's binary_logloss: 0.501327\n",
      "[446]\ttraining's binary_logloss: 0.50111\n",
      "[447]\ttraining's binary_logloss: 0.500895\n",
      "[448]\ttraining's binary_logloss: 0.50067\n",
      "[449]\ttraining's binary_logloss: 0.50046\n",
      "[450]\ttraining's binary_logloss: 0.500239\n",
      "[451]\ttraining's binary_logloss: 0.500067\n",
      "[452]\ttraining's binary_logloss: 0.499891\n",
      "[453]\ttraining's binary_logloss: 0.49972\n",
      "[454]\ttraining's binary_logloss: 0.499534\n",
      "[455]\ttraining's binary_logloss: 0.499346\n",
      "[456]\ttraining's binary_logloss: 0.499154\n",
      "[457]\ttraining's binary_logloss: 0.498972\n",
      "[458]\ttraining's binary_logloss: 0.498797\n",
      "[459]\ttraining's binary_logloss: 0.498589\n",
      "[460]\ttraining's binary_logloss: 0.498416\n",
      "[461]\ttraining's binary_logloss: 0.498203\n",
      "[462]\ttraining's binary_logloss: 0.497981\n",
      "[463]\ttraining's binary_logloss: 0.497771\n",
      "[464]\ttraining's binary_logloss: 0.497581\n",
      "[465]\ttraining's binary_logloss: 0.49735\n",
      "[466]\ttraining's binary_logloss: 0.497174\n",
      "[467]\ttraining's binary_logloss: 0.496949\n",
      "[468]\ttraining's binary_logloss: 0.496744\n",
      "[469]\ttraining's binary_logloss: 0.496529\n",
      "[470]\ttraining's binary_logloss: 0.49636\n",
      "[471]\ttraining's binary_logloss: 0.496191\n",
      "[472]\ttraining's binary_logloss: 0.496036\n",
      "[473]\ttraining's binary_logloss: 0.49583\n",
      "[474]\ttraining's binary_logloss: 0.495664\n",
      "[475]\ttraining's binary_logloss: 0.495482\n",
      "[476]\ttraining's binary_logloss: 0.495262\n",
      "[477]\ttraining's binary_logloss: 0.495055\n",
      "[478]\ttraining's binary_logloss: 0.494864\n",
      "[479]\ttraining's binary_logloss: 0.494671\n",
      "[480]\ttraining's binary_logloss: 0.494478\n",
      "[481]\ttraining's binary_logloss: 0.494277\n",
      "[482]\ttraining's binary_logloss: 0.494114\n",
      "[483]\ttraining's binary_logloss: 0.493951\n",
      "[484]\ttraining's binary_logloss: 0.493783\n",
      "[485]\ttraining's binary_logloss: 0.493609\n",
      "[486]\ttraining's binary_logloss: 0.493433\n",
      "[487]\ttraining's binary_logloss: 0.493227\n",
      "[488]\ttraining's binary_logloss: 0.493022\n",
      "[489]\ttraining's binary_logloss: 0.492832\n",
      "[490]\ttraining's binary_logloss: 0.492648\n",
      "[491]\ttraining's binary_logloss: 0.492516\n",
      "[492]\ttraining's binary_logloss: 0.49238\n",
      "[493]\ttraining's binary_logloss: 0.492245\n",
      "[494]\ttraining's binary_logloss: 0.49212\n",
      "[495]\ttraining's binary_logloss: 0.491996\n",
      "[496]\ttraining's binary_logloss: 0.491818\n",
      "[497]\ttraining's binary_logloss: 0.491619\n",
      "[498]\ttraining's binary_logloss: 0.491435\n",
      "[499]\ttraining's binary_logloss: 0.491253\n",
      "[500]\ttraining's binary_logloss: 0.491073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613595\n",
      "[2]\ttraining's binary_logloss: 0.611937\n",
      "[3]\ttraining's binary_logloss: 0.610313\n",
      "[4]\ttraining's binary_logloss: 0.608761\n",
      "[5]\ttraining's binary_logloss: 0.607272\n",
      "[6]\ttraining's binary_logloss: 0.605937\n",
      "[7]\ttraining's binary_logloss: 0.604632\n",
      "[8]\ttraining's binary_logloss: 0.603405\n",
      "[9]\ttraining's binary_logloss: 0.602205\n",
      "[10]\ttraining's binary_logloss: 0.601004\n",
      "[11]\ttraining's binary_logloss: 0.599755\n",
      "[12]\ttraining's binary_logloss: 0.59874\n",
      "[13]\ttraining's binary_logloss: 0.597731\n",
      "[14]\ttraining's binary_logloss: 0.596609\n",
      "[15]\ttraining's binary_logloss: 0.595556\n",
      "[16]\ttraining's binary_logloss: 0.594466\n",
      "[17]\ttraining's binary_logloss: 0.593441\n",
      "[18]\ttraining's binary_logloss: 0.592427\n",
      "[19]\ttraining's binary_logloss: 0.59145\n",
      "[20]\ttraining's binary_logloss: 0.590637\n",
      "[21]\ttraining's binary_logloss: 0.589814\n",
      "[22]\ttraining's binary_logloss: 0.589003\n",
      "[23]\ttraining's binary_logloss: 0.588235\n",
      "[24]\ttraining's binary_logloss: 0.587391\n",
      "[25]\ttraining's binary_logloss: 0.586567\n",
      "[26]\ttraining's binary_logloss: 0.585823\n",
      "[27]\ttraining's binary_logloss: 0.585079\n",
      "[28]\ttraining's binary_logloss: 0.58434\n",
      "[29]\ttraining's binary_logloss: 0.583642\n",
      "[30]\ttraining's binary_logloss: 0.58294\n",
      "[31]\ttraining's binary_logloss: 0.582183\n",
      "[32]\ttraining's binary_logloss: 0.581452\n",
      "[33]\ttraining's binary_logloss: 0.580717\n",
      "[34]\ttraining's binary_logloss: 0.580024\n",
      "[35]\ttraining's binary_logloss: 0.579304\n",
      "[36]\ttraining's binary_logloss: 0.578585\n",
      "[37]\ttraining's binary_logloss: 0.577963\n",
      "[38]\ttraining's binary_logloss: 0.577286\n",
      "[39]\ttraining's binary_logloss: 0.576633\n",
      "[40]\ttraining's binary_logloss: 0.576\n",
      "[41]\ttraining's binary_logloss: 0.575492\n",
      "[42]\ttraining's binary_logloss: 0.574965\n",
      "[43]\ttraining's binary_logloss: 0.574456\n",
      "[44]\ttraining's binary_logloss: 0.573976\n",
      "[45]\ttraining's binary_logloss: 0.573513\n",
      "[46]\ttraining's binary_logloss: 0.573069\n",
      "[47]\ttraining's binary_logloss: 0.572548\n",
      "[48]\ttraining's binary_logloss: 0.572056\n",
      "[49]\ttraining's binary_logloss: 0.571544\n",
      "[50]\ttraining's binary_logloss: 0.571076\n",
      "[51]\ttraining's binary_logloss: 0.570603\n",
      "[52]\ttraining's binary_logloss: 0.570148\n",
      "[53]\ttraining's binary_logloss: 0.569726\n",
      "[54]\ttraining's binary_logloss: 0.569251\n",
      "[55]\ttraining's binary_logloss: 0.568848\n",
      "[56]\ttraining's binary_logloss: 0.568398\n",
      "[57]\ttraining's binary_logloss: 0.56804\n",
      "[58]\ttraining's binary_logloss: 0.567695\n",
      "[59]\ttraining's binary_logloss: 0.567303\n",
      "[60]\ttraining's binary_logloss: 0.566894\n",
      "[61]\ttraining's binary_logloss: 0.566501\n",
      "[62]\ttraining's binary_logloss: 0.566114\n",
      "[63]\ttraining's binary_logloss: 0.565754\n",
      "[64]\ttraining's binary_logloss: 0.565417\n",
      "[65]\ttraining's binary_logloss: 0.565069\n",
      "[66]\ttraining's binary_logloss: 0.564717\n",
      "[67]\ttraining's binary_logloss: 0.564389\n",
      "[68]\ttraining's binary_logloss: 0.564048\n",
      "[69]\ttraining's binary_logloss: 0.563755\n",
      "[70]\ttraining's binary_logloss: 0.563433\n",
      "[71]\ttraining's binary_logloss: 0.563146\n",
      "[72]\ttraining's binary_logloss: 0.562802\n",
      "[73]\ttraining's binary_logloss: 0.562528\n",
      "[74]\ttraining's binary_logloss: 0.56224\n",
      "[75]\ttraining's binary_logloss: 0.562005\n",
      "[76]\ttraining's binary_logloss: 0.56165\n",
      "[77]\ttraining's binary_logloss: 0.561316\n",
      "[78]\ttraining's binary_logloss: 0.560993\n",
      "[79]\ttraining's binary_logloss: 0.560725\n",
      "[80]\ttraining's binary_logloss: 0.560476\n",
      "[81]\ttraining's binary_logloss: 0.560212\n",
      "[82]\ttraining's binary_logloss: 0.559946\n",
      "[83]\ttraining's binary_logloss: 0.559699\n",
      "[84]\ttraining's binary_logloss: 0.559455\n",
      "[85]\ttraining's binary_logloss: 0.559238\n",
      "[86]\ttraining's binary_logloss: 0.559026\n",
      "[87]\ttraining's binary_logloss: 0.558742\n",
      "[88]\ttraining's binary_logloss: 0.558458\n",
      "[89]\ttraining's binary_logloss: 0.558245\n",
      "[90]\ttraining's binary_logloss: 0.558042\n",
      "[91]\ttraining's binary_logloss: 0.557793\n",
      "[92]\ttraining's binary_logloss: 0.557542\n",
      "[93]\ttraining's binary_logloss: 0.557296\n",
      "[94]\ttraining's binary_logloss: 0.557078\n",
      "[95]\ttraining's binary_logloss: 0.55685\n",
      "[96]\ttraining's binary_logloss: 0.556601\n",
      "[97]\ttraining's binary_logloss: 0.556387\n",
      "[98]\ttraining's binary_logloss: 0.556228\n",
      "[99]\ttraining's binary_logloss: 0.556038\n",
      "[100]\ttraining's binary_logloss: 0.555839\n",
      "[101]\ttraining's binary_logloss: 0.555632\n",
      "[102]\ttraining's binary_logloss: 0.555463\n",
      "[103]\ttraining's binary_logloss: 0.55528\n",
      "[104]\ttraining's binary_logloss: 0.555106\n",
      "[105]\ttraining's binary_logloss: 0.554947\n",
      "[106]\ttraining's binary_logloss: 0.554758\n",
      "[107]\ttraining's binary_logloss: 0.554568\n",
      "[108]\ttraining's binary_logloss: 0.554326\n",
      "[109]\ttraining's binary_logloss: 0.554091\n",
      "[110]\ttraining's binary_logloss: 0.553929\n",
      "[111]\ttraining's binary_logloss: 0.55373\n",
      "[112]\ttraining's binary_logloss: 0.553538\n",
      "[113]\ttraining's binary_logloss: 0.553359\n",
      "[114]\ttraining's binary_logloss: 0.553137\n",
      "[115]\ttraining's binary_logloss: 0.553004\n",
      "[116]\ttraining's binary_logloss: 0.552822\n",
      "[117]\ttraining's binary_logloss: 0.552722\n",
      "[118]\ttraining's binary_logloss: 0.5526\n",
      "[119]\ttraining's binary_logloss: 0.552444\n",
      "[120]\ttraining's binary_logloss: 0.552283\n",
      "[121]\ttraining's binary_logloss: 0.55209\n",
      "[122]\ttraining's binary_logloss: 0.551905\n",
      "[123]\ttraining's binary_logloss: 0.551723\n",
      "[124]\ttraining's binary_logloss: 0.55157\n",
      "[125]\ttraining's binary_logloss: 0.551403\n",
      "[126]\ttraining's binary_logloss: 0.55124\n",
      "[127]\ttraining's binary_logloss: 0.551045\n",
      "[128]\ttraining's binary_logloss: 0.550866\n",
      "[129]\ttraining's binary_logloss: 0.5507\n",
      "[130]\ttraining's binary_logloss: 0.55053\n",
      "[131]\ttraining's binary_logloss: 0.550356\n",
      "[132]\ttraining's binary_logloss: 0.550224\n",
      "[133]\ttraining's binary_logloss: 0.550069\n",
      "[134]\ttraining's binary_logloss: 0.549947\n",
      "[135]\ttraining's binary_logloss: 0.549751\n",
      "[136]\ttraining's binary_logloss: 0.549564\n",
      "[137]\ttraining's binary_logloss: 0.54941\n",
      "[138]\ttraining's binary_logloss: 0.549233\n",
      "[139]\ttraining's binary_logloss: 0.54906\n",
      "[140]\ttraining's binary_logloss: 0.548917\n",
      "[141]\ttraining's binary_logloss: 0.54876\n",
      "[142]\ttraining's binary_logloss: 0.548582\n",
      "[143]\ttraining's binary_logloss: 0.548435\n",
      "[144]\ttraining's binary_logloss: 0.548293\n",
      "[145]\ttraining's binary_logloss: 0.54813\n",
      "[146]\ttraining's binary_logloss: 0.547956\n",
      "[147]\ttraining's binary_logloss: 0.547806\n",
      "[148]\ttraining's binary_logloss: 0.547644\n",
      "[149]\ttraining's binary_logloss: 0.54748\n",
      "[150]\ttraining's binary_logloss: 0.54733\n",
      "[151]\ttraining's binary_logloss: 0.547164\n",
      "[152]\ttraining's binary_logloss: 0.546969\n",
      "[153]\ttraining's binary_logloss: 0.546785\n",
      "[154]\ttraining's binary_logloss: 0.546613\n",
      "[155]\ttraining's binary_logloss: 0.54645\n",
      "[156]\ttraining's binary_logloss: 0.546328\n",
      "[157]\ttraining's binary_logloss: 0.546164\n",
      "[158]\ttraining's binary_logloss: 0.546019\n",
      "[159]\ttraining's binary_logloss: 0.545871\n",
      "[160]\ttraining's binary_logloss: 0.545723\n",
      "[161]\ttraining's binary_logloss: 0.545551\n",
      "[162]\ttraining's binary_logloss: 0.545385\n",
      "[163]\ttraining's binary_logloss: 0.545215\n",
      "[164]\ttraining's binary_logloss: 0.545034\n",
      "[165]\ttraining's binary_logloss: 0.544831\n",
      "[166]\ttraining's binary_logloss: 0.544665\n",
      "[167]\ttraining's binary_logloss: 0.544465\n",
      "[168]\ttraining's binary_logloss: 0.544275\n",
      "[169]\ttraining's binary_logloss: 0.544068\n",
      "[170]\ttraining's binary_logloss: 0.543888\n",
      "[171]\ttraining's binary_logloss: 0.543675\n",
      "[172]\ttraining's binary_logloss: 0.54353\n",
      "[173]\ttraining's binary_logloss: 0.543348\n",
      "[174]\ttraining's binary_logloss: 0.543143\n",
      "[175]\ttraining's binary_logloss: 0.542955\n",
      "[176]\ttraining's binary_logloss: 0.542782\n",
      "[177]\ttraining's binary_logloss: 0.542633\n",
      "[178]\ttraining's binary_logloss: 0.542473\n",
      "[179]\ttraining's binary_logloss: 0.542296\n",
      "[180]\ttraining's binary_logloss: 0.542136\n",
      "[181]\ttraining's binary_logloss: 0.541948\n",
      "[182]\ttraining's binary_logloss: 0.541814\n",
      "[183]\ttraining's binary_logloss: 0.541663\n",
      "[184]\ttraining's binary_logloss: 0.541521\n",
      "[185]\ttraining's binary_logloss: 0.54139\n",
      "[186]\ttraining's binary_logloss: 0.541211\n",
      "[187]\ttraining's binary_logloss: 0.541008\n",
      "[188]\ttraining's binary_logloss: 0.54083\n",
      "[189]\ttraining's binary_logloss: 0.540654\n",
      "[190]\ttraining's binary_logloss: 0.540482\n",
      "[191]\ttraining's binary_logloss: 0.540286\n",
      "[192]\ttraining's binary_logloss: 0.540089\n",
      "[193]\ttraining's binary_logloss: 0.5399\n",
      "[194]\ttraining's binary_logloss: 0.539714\n",
      "[195]\ttraining's binary_logloss: 0.539527\n",
      "[196]\ttraining's binary_logloss: 0.539378\n",
      "[197]\ttraining's binary_logloss: 0.539154\n",
      "[198]\ttraining's binary_logloss: 0.538978\n",
      "[199]\ttraining's binary_logloss: 0.538779\n",
      "[200]\ttraining's binary_logloss: 0.538628\n",
      "[201]\ttraining's binary_logloss: 0.538468\n",
      "[202]\ttraining's binary_logloss: 0.538312\n",
      "[203]\ttraining's binary_logloss: 0.538142\n",
      "[204]\ttraining's binary_logloss: 0.538002\n",
      "[205]\ttraining's binary_logloss: 0.537839\n",
      "[206]\ttraining's binary_logloss: 0.537661\n",
      "[207]\ttraining's binary_logloss: 0.537472\n",
      "[208]\ttraining's binary_logloss: 0.537292\n",
      "[209]\ttraining's binary_logloss: 0.537109\n",
      "[210]\ttraining's binary_logloss: 0.536957\n",
      "[211]\ttraining's binary_logloss: 0.536819\n",
      "[212]\ttraining's binary_logloss: 0.536673\n",
      "[213]\ttraining's binary_logloss: 0.536543\n",
      "[214]\ttraining's binary_logloss: 0.53642\n",
      "[215]\ttraining's binary_logloss: 0.536301\n",
      "[216]\ttraining's binary_logloss: 0.536095\n",
      "[217]\ttraining's binary_logloss: 0.535885\n",
      "[218]\ttraining's binary_logloss: 0.535678\n",
      "[219]\ttraining's binary_logloss: 0.535486\n",
      "[220]\ttraining's binary_logloss: 0.535304\n",
      "[221]\ttraining's binary_logloss: 0.535084\n",
      "[222]\ttraining's binary_logloss: 0.534944\n",
      "[223]\ttraining's binary_logloss: 0.53474\n",
      "[224]\ttraining's binary_logloss: 0.534526\n",
      "[225]\ttraining's binary_logloss: 0.534347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[226]\ttraining's binary_logloss: 0.534185\n",
      "[227]\ttraining's binary_logloss: 0.534039\n",
      "[228]\ttraining's binary_logloss: 0.533897\n",
      "[229]\ttraining's binary_logloss: 0.53374\n",
      "[230]\ttraining's binary_logloss: 0.533578\n",
      "[231]\ttraining's binary_logloss: 0.533414\n",
      "[232]\ttraining's binary_logloss: 0.533228\n",
      "[233]\ttraining's binary_logloss: 0.533089\n",
      "[234]\ttraining's binary_logloss: 0.532939\n",
      "[235]\ttraining's binary_logloss: 0.532748\n",
      "[236]\ttraining's binary_logloss: 0.532544\n",
      "[237]\ttraining's binary_logloss: 0.532356\n",
      "[238]\ttraining's binary_logloss: 0.532174\n",
      "[239]\ttraining's binary_logloss: 0.531995\n",
      "[240]\ttraining's binary_logloss: 0.531782\n",
      "[241]\ttraining's binary_logloss: 0.531608\n",
      "[242]\ttraining's binary_logloss: 0.53143\n",
      "[243]\ttraining's binary_logloss: 0.531256\n",
      "[244]\ttraining's binary_logloss: 0.53108\n",
      "[245]\ttraining's binary_logloss: 0.530879\n",
      "[246]\ttraining's binary_logloss: 0.5307\n",
      "[247]\ttraining's binary_logloss: 0.530517\n",
      "[248]\ttraining's binary_logloss: 0.530314\n",
      "[249]\ttraining's binary_logloss: 0.530145\n",
      "[250]\ttraining's binary_logloss: 0.529942\n",
      "[251]\ttraining's binary_logloss: 0.529806\n",
      "[252]\ttraining's binary_logloss: 0.529643\n",
      "[253]\ttraining's binary_logloss: 0.52948\n",
      "[254]\ttraining's binary_logloss: 0.529324\n",
      "[255]\ttraining's binary_logloss: 0.529169\n",
      "[256]\ttraining's binary_logloss: 0.529015\n",
      "[257]\ttraining's binary_logloss: 0.528799\n",
      "[258]\ttraining's binary_logloss: 0.528602\n",
      "[259]\ttraining's binary_logloss: 0.52841\n",
      "[260]\ttraining's binary_logloss: 0.528227\n",
      "[261]\ttraining's binary_logloss: 0.528057\n",
      "[262]\ttraining's binary_logloss: 0.527894\n",
      "[263]\ttraining's binary_logloss: 0.527726\n",
      "[264]\ttraining's binary_logloss: 0.527576\n",
      "[265]\ttraining's binary_logloss: 0.527416\n",
      "[266]\ttraining's binary_logloss: 0.52725\n",
      "[267]\ttraining's binary_logloss: 0.527136\n",
      "[268]\ttraining's binary_logloss: 0.52703\n",
      "[269]\ttraining's binary_logloss: 0.526908\n",
      "[270]\ttraining's binary_logloss: 0.526806\n",
      "[271]\ttraining's binary_logloss: 0.526575\n",
      "[272]\ttraining's binary_logloss: 0.526338\n",
      "[273]\ttraining's binary_logloss: 0.526119\n",
      "[274]\ttraining's binary_logloss: 0.525906\n",
      "[275]\ttraining's binary_logloss: 0.525682\n",
      "[276]\ttraining's binary_logloss: 0.525456\n",
      "[277]\ttraining's binary_logloss: 0.525188\n",
      "[278]\ttraining's binary_logloss: 0.524982\n",
      "[279]\ttraining's binary_logloss: 0.524791\n",
      "[280]\ttraining's binary_logloss: 0.52456\n",
      "[281]\ttraining's binary_logloss: 0.524367\n",
      "[282]\ttraining's binary_logloss: 0.524176\n",
      "[283]\ttraining's binary_logloss: 0.523994\n",
      "[284]\ttraining's binary_logloss: 0.52381\n",
      "[285]\ttraining's binary_logloss: 0.523646\n",
      "[286]\ttraining's binary_logloss: 0.523474\n",
      "[287]\ttraining's binary_logloss: 0.523303\n",
      "[288]\ttraining's binary_logloss: 0.52313\n",
      "[289]\ttraining's binary_logloss: 0.522917\n",
      "[290]\ttraining's binary_logloss: 0.522742\n",
      "[291]\ttraining's binary_logloss: 0.522521\n",
      "[292]\ttraining's binary_logloss: 0.522326\n",
      "[293]\ttraining's binary_logloss: 0.522125\n",
      "[294]\ttraining's binary_logloss: 0.521898\n",
      "[295]\ttraining's binary_logloss: 0.521701\n",
      "[296]\ttraining's binary_logloss: 0.52153\n",
      "[297]\ttraining's binary_logloss: 0.521361\n",
      "[298]\ttraining's binary_logloss: 0.521194\n",
      "[299]\ttraining's binary_logloss: 0.521025\n",
      "[300]\ttraining's binary_logloss: 0.520896\n",
      "[301]\ttraining's binary_logloss: 0.520714\n",
      "[302]\ttraining's binary_logloss: 0.52049\n",
      "[303]\ttraining's binary_logloss: 0.520295\n",
      "[304]\ttraining's binary_logloss: 0.520089\n",
      "[305]\ttraining's binary_logloss: 0.5199\n",
      "[306]\ttraining's binary_logloss: 0.519705\n",
      "[307]\ttraining's binary_logloss: 0.519494\n",
      "[308]\ttraining's binary_logloss: 0.519338\n",
      "[309]\ttraining's binary_logloss: 0.519154\n",
      "[310]\ttraining's binary_logloss: 0.51897\n",
      "[311]\ttraining's binary_logloss: 0.518809\n",
      "[312]\ttraining's binary_logloss: 0.518638\n",
      "[313]\ttraining's binary_logloss: 0.518476\n",
      "[314]\ttraining's binary_logloss: 0.51833\n",
      "[315]\ttraining's binary_logloss: 0.51817\n",
      "[316]\ttraining's binary_logloss: 0.517988\n",
      "[317]\ttraining's binary_logloss: 0.517825\n",
      "[318]\ttraining's binary_logloss: 0.51765\n",
      "[319]\ttraining's binary_logloss: 0.517463\n",
      "[320]\ttraining's binary_logloss: 0.517295\n",
      "[321]\ttraining's binary_logloss: 0.517118\n",
      "[322]\ttraining's binary_logloss: 0.516959\n",
      "[323]\ttraining's binary_logloss: 0.516784\n",
      "[324]\ttraining's binary_logloss: 0.516607\n",
      "[325]\ttraining's binary_logloss: 0.516443\n",
      "[326]\ttraining's binary_logloss: 0.516249\n",
      "[327]\ttraining's binary_logloss: 0.516052\n",
      "[328]\ttraining's binary_logloss: 0.515842\n",
      "[329]\ttraining's binary_logloss: 0.515582\n",
      "[330]\ttraining's binary_logloss: 0.5154\n",
      "[331]\ttraining's binary_logloss: 0.515204\n",
      "[332]\ttraining's binary_logloss: 0.515014\n",
      "[333]\ttraining's binary_logloss: 0.514819\n",
      "[334]\ttraining's binary_logloss: 0.514637\n",
      "[335]\ttraining's binary_logloss: 0.514448\n",
      "[336]\ttraining's binary_logloss: 0.514278\n",
      "[337]\ttraining's binary_logloss: 0.514102\n",
      "[338]\ttraining's binary_logloss: 0.51391\n",
      "[339]\ttraining's binary_logloss: 0.513732\n",
      "[340]\ttraining's binary_logloss: 0.51355\n",
      "[341]\ttraining's binary_logloss: 0.513375\n",
      "[342]\ttraining's binary_logloss: 0.513209\n",
      "[343]\ttraining's binary_logloss: 0.51306\n",
      "[344]\ttraining's binary_logloss: 0.512907\n",
      "[345]\ttraining's binary_logloss: 0.512745\n",
      "[346]\ttraining's binary_logloss: 0.512561\n",
      "[347]\ttraining's binary_logloss: 0.512386\n",
      "[348]\ttraining's binary_logloss: 0.512223\n",
      "[349]\ttraining's binary_logloss: 0.512048\n",
      "[350]\ttraining's binary_logloss: 0.511883\n",
      "[351]\ttraining's binary_logloss: 0.511657\n",
      "[352]\ttraining's binary_logloss: 0.511429\n",
      "[353]\ttraining's binary_logloss: 0.511223\n",
      "[354]\ttraining's binary_logloss: 0.510975\n",
      "[355]\ttraining's binary_logloss: 0.510739\n",
      "[356]\ttraining's binary_logloss: 0.510533\n",
      "[357]\ttraining's binary_logloss: 0.510299\n",
      "[358]\ttraining's binary_logloss: 0.510077\n",
      "[359]\ttraining's binary_logloss: 0.509854\n",
      "[360]\ttraining's binary_logloss: 0.509642\n",
      "[361]\ttraining's binary_logloss: 0.509434\n",
      "[362]\ttraining's binary_logloss: 0.509239\n",
      "[363]\ttraining's binary_logloss: 0.509038\n",
      "[364]\ttraining's binary_logloss: 0.508822\n",
      "[365]\ttraining's binary_logloss: 0.508627\n",
      "[366]\ttraining's binary_logloss: 0.508406\n",
      "[367]\ttraining's binary_logloss: 0.508212\n",
      "[368]\ttraining's binary_logloss: 0.508031\n",
      "[369]\ttraining's binary_logloss: 0.507839\n",
      "[370]\ttraining's binary_logloss: 0.507667\n",
      "[371]\ttraining's binary_logloss: 0.507499\n",
      "[372]\ttraining's binary_logloss: 0.507342\n",
      "[373]\ttraining's binary_logloss: 0.507176\n",
      "[374]\ttraining's binary_logloss: 0.507028\n",
      "[375]\ttraining's binary_logloss: 0.506908\n",
      "[376]\ttraining's binary_logloss: 0.506708\n",
      "[377]\ttraining's binary_logloss: 0.5065\n",
      "[378]\ttraining's binary_logloss: 0.506325\n",
      "[379]\ttraining's binary_logloss: 0.506124\n",
      "[380]\ttraining's binary_logloss: 0.505903\n",
      "[381]\ttraining's binary_logloss: 0.505743\n",
      "[382]\ttraining's binary_logloss: 0.505591\n",
      "[383]\ttraining's binary_logloss: 0.505415\n",
      "[384]\ttraining's binary_logloss: 0.505262\n",
      "[385]\ttraining's binary_logloss: 0.505119\n",
      "[386]\ttraining's binary_logloss: 0.504906\n",
      "[387]\ttraining's binary_logloss: 0.504693\n",
      "[388]\ttraining's binary_logloss: 0.504489\n",
      "[389]\ttraining's binary_logloss: 0.504294\n",
      "[390]\ttraining's binary_logloss: 0.504099\n",
      "[391]\ttraining's binary_logloss: 0.503895\n",
      "[392]\ttraining's binary_logloss: 0.503706\n",
      "[393]\ttraining's binary_logloss: 0.503504\n",
      "[394]\ttraining's binary_logloss: 0.503332\n",
      "[395]\ttraining's binary_logloss: 0.503131\n",
      "[396]\ttraining's binary_logloss: 0.502936\n",
      "[397]\ttraining's binary_logloss: 0.502734\n",
      "[398]\ttraining's binary_logloss: 0.502547\n",
      "[399]\ttraining's binary_logloss: 0.502361\n",
      "[400]\ttraining's binary_logloss: 0.502188\n",
      "[401]\ttraining's binary_logloss: 0.502016\n",
      "[402]\ttraining's binary_logloss: 0.501828\n",
      "[403]\ttraining's binary_logloss: 0.501641\n",
      "[404]\ttraining's binary_logloss: 0.501463\n",
      "[405]\ttraining's binary_logloss: 0.50131\n",
      "[406]\ttraining's binary_logloss: 0.501132\n",
      "[407]\ttraining's binary_logloss: 0.500947\n",
      "[408]\ttraining's binary_logloss: 0.500773\n",
      "[409]\ttraining's binary_logloss: 0.5006\n",
      "[410]\ttraining's binary_logloss: 0.500415\n",
      "[411]\ttraining's binary_logloss: 0.500178\n",
      "[412]\ttraining's binary_logloss: 0.499976\n",
      "[413]\ttraining's binary_logloss: 0.499769\n",
      "[414]\ttraining's binary_logloss: 0.499553\n",
      "[415]\ttraining's binary_logloss: 0.499353\n",
      "[416]\ttraining's binary_logloss: 0.499158\n",
      "[417]\ttraining's binary_logloss: 0.498974\n",
      "[418]\ttraining's binary_logloss: 0.498796\n",
      "[419]\ttraining's binary_logloss: 0.498601\n",
      "[420]\ttraining's binary_logloss: 0.498408\n",
      "[421]\ttraining's binary_logloss: 0.498203\n",
      "[422]\ttraining's binary_logloss: 0.498061\n",
      "[423]\ttraining's binary_logloss: 0.49784\n",
      "[424]\ttraining's binary_logloss: 0.49762\n",
      "[425]\ttraining's binary_logloss: 0.497429\n",
      "[426]\ttraining's binary_logloss: 0.497234\n",
      "[427]\ttraining's binary_logloss: 0.497079\n",
      "[428]\ttraining's binary_logloss: 0.496891\n",
      "[429]\ttraining's binary_logloss: 0.496702\n",
      "[430]\ttraining's binary_logloss: 0.496523\n",
      "[431]\ttraining's binary_logloss: 0.496333\n",
      "[432]\ttraining's binary_logloss: 0.496147\n",
      "[433]\ttraining's binary_logloss: 0.495932\n",
      "[434]\ttraining's binary_logloss: 0.495721\n",
      "[435]\ttraining's binary_logloss: 0.495482\n",
      "[436]\ttraining's binary_logloss: 0.495245\n",
      "[437]\ttraining's binary_logloss: 0.495044\n",
      "[438]\ttraining's binary_logloss: 0.49482\n",
      "[439]\ttraining's binary_logloss: 0.494586\n",
      "[440]\ttraining's binary_logloss: 0.494364\n",
      "[441]\ttraining's binary_logloss: 0.494153\n",
      "[442]\ttraining's binary_logloss: 0.493961\n",
      "[443]\ttraining's binary_logloss: 0.493764\n",
      "[444]\ttraining's binary_logloss: 0.493564\n",
      "[445]\ttraining's binary_logloss: 0.493366\n",
      "[446]\ttraining's binary_logloss: 0.493146\n",
      "[447]\ttraining's binary_logloss: 0.492936\n",
      "[448]\ttraining's binary_logloss: 0.49271\n",
      "[449]\ttraining's binary_logloss: 0.492477\n",
      "[450]\ttraining's binary_logloss: 0.492276\n",
      "[451]\ttraining's binary_logloss: 0.492064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[452]\ttraining's binary_logloss: 0.49189\n",
      "[453]\ttraining's binary_logloss: 0.491718\n",
      "[454]\ttraining's binary_logloss: 0.491521\n",
      "[455]\ttraining's binary_logloss: 0.491355\n",
      "[456]\ttraining's binary_logloss: 0.491171\n",
      "[457]\ttraining's binary_logloss: 0.491004\n",
      "[458]\ttraining's binary_logloss: 0.490824\n",
      "[459]\ttraining's binary_logloss: 0.490677\n",
      "[460]\ttraining's binary_logloss: 0.49051\n",
      "[461]\ttraining's binary_logloss: 0.490275\n",
      "[462]\ttraining's binary_logloss: 0.490093\n",
      "[463]\ttraining's binary_logloss: 0.489883\n",
      "[464]\ttraining's binary_logloss: 0.489663\n",
      "[465]\ttraining's binary_logloss: 0.489447\n",
      "[466]\ttraining's binary_logloss: 0.489245\n",
      "[467]\ttraining's binary_logloss: 0.489039\n",
      "[468]\ttraining's binary_logloss: 0.488844\n",
      "[469]\ttraining's binary_logloss: 0.488671\n",
      "[470]\ttraining's binary_logloss: 0.488477\n",
      "[471]\ttraining's binary_logloss: 0.488307\n",
      "[472]\ttraining's binary_logloss: 0.488129\n",
      "[473]\ttraining's binary_logloss: 0.487977\n",
      "[474]\ttraining's binary_logloss: 0.487799\n",
      "[475]\ttraining's binary_logloss: 0.48765\n",
      "[476]\ttraining's binary_logloss: 0.487486\n",
      "[477]\ttraining's binary_logloss: 0.487314\n",
      "[478]\ttraining's binary_logloss: 0.487147\n",
      "[479]\ttraining's binary_logloss: 0.486981\n",
      "[480]\ttraining's binary_logloss: 0.48677\n",
      "[481]\ttraining's binary_logloss: 0.486562\n",
      "[482]\ttraining's binary_logloss: 0.486412\n",
      "[483]\ttraining's binary_logloss: 0.486237\n",
      "[484]\ttraining's binary_logloss: 0.486027\n",
      "[485]\ttraining's binary_logloss: 0.485828\n",
      "[486]\ttraining's binary_logloss: 0.485639\n",
      "[487]\ttraining's binary_logloss: 0.485421\n",
      "[488]\ttraining's binary_logloss: 0.485208\n",
      "[489]\ttraining's binary_logloss: 0.484997\n",
      "[490]\ttraining's binary_logloss: 0.484826\n",
      "[491]\ttraining's binary_logloss: 0.484669\n",
      "[492]\ttraining's binary_logloss: 0.484505\n",
      "[493]\ttraining's binary_logloss: 0.484322\n",
      "[494]\ttraining's binary_logloss: 0.484141\n",
      "[495]\ttraining's binary_logloss: 0.483958\n",
      "[496]\ttraining's binary_logloss: 0.48373\n",
      "[497]\ttraining's binary_logloss: 0.483501\n",
      "[498]\ttraining's binary_logloss: 0.483308\n",
      "[499]\ttraining's binary_logloss: 0.483107\n",
      "[500]\ttraining's binary_logloss: 0.48289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.612774\n",
      "[2]\ttraining's binary_logloss: 0.611246\n",
      "[3]\ttraining's binary_logloss: 0.60982\n",
      "[4]\ttraining's binary_logloss: 0.608336\n",
      "[5]\ttraining's binary_logloss: 0.60695\n",
      "[6]\ttraining's binary_logloss: 0.6058\n",
      "[7]\ttraining's binary_logloss: 0.604495\n",
      "[8]\ttraining's binary_logloss: 0.603324\n",
      "[9]\ttraining's binary_logloss: 0.602065\n",
      "[10]\ttraining's binary_logloss: 0.600823\n",
      "[11]\ttraining's binary_logloss: 0.599709\n",
      "[12]\ttraining's binary_logloss: 0.598674\n",
      "[13]\ttraining's binary_logloss: 0.597522\n",
      "[14]\ttraining's binary_logloss: 0.596416\n",
      "[15]\ttraining's binary_logloss: 0.595374\n",
      "[16]\ttraining's binary_logloss: 0.594317\n",
      "[17]\ttraining's binary_logloss: 0.593297\n",
      "[18]\ttraining's binary_logloss: 0.592309\n",
      "[19]\ttraining's binary_logloss: 0.591383\n",
      "[20]\ttraining's binary_logloss: 0.590459\n",
      "[21]\ttraining's binary_logloss: 0.589603\n",
      "[22]\ttraining's binary_logloss: 0.588763\n",
      "[23]\ttraining's binary_logloss: 0.587969\n",
      "[24]\ttraining's binary_logloss: 0.587164\n",
      "[25]\ttraining's binary_logloss: 0.586387\n",
      "[26]\ttraining's binary_logloss: 0.585587\n",
      "[27]\ttraining's binary_logloss: 0.584893\n",
      "[28]\ttraining's binary_logloss: 0.584222\n",
      "[29]\ttraining's binary_logloss: 0.58347\n",
      "[30]\ttraining's binary_logloss: 0.582767\n",
      "[31]\ttraining's binary_logloss: 0.582104\n",
      "[32]\ttraining's binary_logloss: 0.581478\n",
      "[33]\ttraining's binary_logloss: 0.580858\n",
      "[34]\ttraining's binary_logloss: 0.580207\n",
      "[35]\ttraining's binary_logloss: 0.579522\n",
      "[36]\ttraining's binary_logloss: 0.578908\n",
      "[37]\ttraining's binary_logloss: 0.578346\n",
      "[38]\ttraining's binary_logloss: 0.577763\n",
      "[39]\ttraining's binary_logloss: 0.577266\n",
      "[40]\ttraining's binary_logloss: 0.576757\n",
      "[41]\ttraining's binary_logloss: 0.576247\n",
      "[42]\ttraining's binary_logloss: 0.57572\n",
      "[43]\ttraining's binary_logloss: 0.575182\n",
      "[44]\ttraining's binary_logloss: 0.574696\n",
      "[45]\ttraining's binary_logloss: 0.574229\n",
      "[46]\ttraining's binary_logloss: 0.57368\n",
      "[47]\ttraining's binary_logloss: 0.573163\n",
      "[48]\ttraining's binary_logloss: 0.57266\n",
      "[49]\ttraining's binary_logloss: 0.572167\n",
      "[50]\ttraining's binary_logloss: 0.571688\n",
      "[51]\ttraining's binary_logloss: 0.571299\n",
      "[52]\ttraining's binary_logloss: 0.570848\n",
      "[53]\ttraining's binary_logloss: 0.570415\n",
      "[54]\ttraining's binary_logloss: 0.570061\n",
      "[55]\ttraining's binary_logloss: 0.569656\n",
      "[56]\ttraining's binary_logloss: 0.569279\n",
      "[57]\ttraining's binary_logloss: 0.568861\n",
      "[58]\ttraining's binary_logloss: 0.568514\n",
      "[59]\ttraining's binary_logloss: 0.568168\n",
      "[60]\ttraining's binary_logloss: 0.567833\n",
      "[61]\ttraining's binary_logloss: 0.567522\n",
      "[62]\ttraining's binary_logloss: 0.56715\n",
      "[63]\ttraining's binary_logloss: 0.566853\n",
      "[64]\ttraining's binary_logloss: 0.566579\n",
      "[65]\ttraining's binary_logloss: 0.566309\n",
      "[66]\ttraining's binary_logloss: 0.565938\n",
      "[67]\ttraining's binary_logloss: 0.565566\n",
      "[68]\ttraining's binary_logloss: 0.565213\n",
      "[69]\ttraining's binary_logloss: 0.564865\n",
      "[70]\ttraining's binary_logloss: 0.564566\n",
      "[71]\ttraining's binary_logloss: 0.564213\n",
      "[72]\ttraining's binary_logloss: 0.56387\n",
      "[73]\ttraining's binary_logloss: 0.563536\n",
      "[74]\ttraining's binary_logloss: 0.563212\n",
      "[75]\ttraining's binary_logloss: 0.562908\n",
      "[76]\ttraining's binary_logloss: 0.562618\n",
      "[77]\ttraining's binary_logloss: 0.562373\n",
      "[78]\ttraining's binary_logloss: 0.562092\n",
      "[79]\ttraining's binary_logloss: 0.561812\n",
      "[80]\ttraining's binary_logloss: 0.561553\n",
      "[81]\ttraining's binary_logloss: 0.561293\n",
      "[82]\ttraining's binary_logloss: 0.561035\n",
      "[83]\ttraining's binary_logloss: 0.560785\n",
      "[84]\ttraining's binary_logloss: 0.560558\n",
      "[85]\ttraining's binary_logloss: 0.560323\n",
      "[86]\ttraining's binary_logloss: 0.560075\n",
      "[87]\ttraining's binary_logloss: 0.559832\n",
      "[88]\ttraining's binary_logloss: 0.559614\n",
      "[89]\ttraining's binary_logloss: 0.559383\n",
      "[90]\ttraining's binary_logloss: 0.559157\n",
      "[91]\ttraining's binary_logloss: 0.558926\n",
      "[92]\ttraining's binary_logloss: 0.558708\n",
      "[93]\ttraining's binary_logloss: 0.558478\n",
      "[94]\ttraining's binary_logloss: 0.558265\n",
      "[95]\ttraining's binary_logloss: 0.558075\n",
      "[96]\ttraining's binary_logloss: 0.557921\n",
      "[97]\ttraining's binary_logloss: 0.557717\n",
      "[98]\ttraining's binary_logloss: 0.557525\n",
      "[99]\ttraining's binary_logloss: 0.557323\n",
      "[100]\ttraining's binary_logloss: 0.557147\n",
      "[101]\ttraining's binary_logloss: 0.556985\n",
      "[102]\ttraining's binary_logloss: 0.556832\n",
      "[103]\ttraining's binary_logloss: 0.5567\n",
      "[104]\ttraining's binary_logloss: 0.55652\n",
      "[105]\ttraining's binary_logloss: 0.556378\n",
      "[106]\ttraining's binary_logloss: 0.556201\n",
      "[107]\ttraining's binary_logloss: 0.556018\n",
      "[108]\ttraining's binary_logloss: 0.555842\n",
      "[109]\ttraining's binary_logloss: 0.555684\n",
      "[110]\ttraining's binary_logloss: 0.55552\n",
      "[111]\ttraining's binary_logloss: 0.555364\n",
      "[112]\ttraining's binary_logloss: 0.555245\n",
      "[113]\ttraining's binary_logloss: 0.555103\n",
      "[114]\ttraining's binary_logloss: 0.554931\n",
      "[115]\ttraining's binary_logloss: 0.554781\n",
      "[116]\ttraining's binary_logloss: 0.554616\n",
      "[117]\ttraining's binary_logloss: 0.554438\n",
      "[118]\ttraining's binary_logloss: 0.554232\n",
      "[119]\ttraining's binary_logloss: 0.554094\n",
      "[120]\ttraining's binary_logloss: 0.553889\n",
      "[121]\ttraining's binary_logloss: 0.553717\n",
      "[122]\ttraining's binary_logloss: 0.553525\n",
      "[123]\ttraining's binary_logloss: 0.553342\n",
      "[124]\ttraining's binary_logloss: 0.553173\n",
      "[125]\ttraining's binary_logloss: 0.553004\n",
      "[126]\ttraining's binary_logloss: 0.552824\n",
      "[127]\ttraining's binary_logloss: 0.552653\n",
      "[128]\ttraining's binary_logloss: 0.552478\n",
      "[129]\ttraining's binary_logloss: 0.552299\n",
      "[130]\ttraining's binary_logloss: 0.552139\n",
      "[131]\ttraining's binary_logloss: 0.551975\n",
      "[132]\ttraining's binary_logloss: 0.55181\n",
      "[133]\ttraining's binary_logloss: 0.55168\n",
      "[134]\ttraining's binary_logloss: 0.551499\n",
      "[135]\ttraining's binary_logloss: 0.551383\n",
      "[136]\ttraining's binary_logloss: 0.551254\n",
      "[137]\ttraining's binary_logloss: 0.551104\n",
      "[138]\ttraining's binary_logloss: 0.55097\n",
      "[139]\ttraining's binary_logloss: 0.550795\n",
      "[140]\ttraining's binary_logloss: 0.550658\n",
      "[141]\ttraining's binary_logloss: 0.550487\n",
      "[142]\ttraining's binary_logloss: 0.550327\n",
      "[143]\ttraining's binary_logloss: 0.550191\n",
      "[144]\ttraining's binary_logloss: 0.550021\n",
      "[145]\ttraining's binary_logloss: 0.549838\n",
      "[146]\ttraining's binary_logloss: 0.549639\n",
      "[147]\ttraining's binary_logloss: 0.549448\n",
      "[148]\ttraining's binary_logloss: 0.549279\n",
      "[149]\ttraining's binary_logloss: 0.549114\n",
      "[150]\ttraining's binary_logloss: 0.54894\n",
      "[151]\ttraining's binary_logloss: 0.548778\n",
      "[152]\ttraining's binary_logloss: 0.548635\n",
      "[153]\ttraining's binary_logloss: 0.548481\n",
      "[154]\ttraining's binary_logloss: 0.548346\n",
      "[155]\ttraining's binary_logloss: 0.548194\n",
      "[156]\ttraining's binary_logloss: 0.548089\n",
      "[157]\ttraining's binary_logloss: 0.547967\n",
      "[158]\ttraining's binary_logloss: 0.547849\n",
      "[159]\ttraining's binary_logloss: 0.547729\n",
      "[160]\ttraining's binary_logloss: 0.547602\n",
      "[161]\ttraining's binary_logloss: 0.547457\n",
      "[162]\ttraining's binary_logloss: 0.547264\n",
      "[163]\ttraining's binary_logloss: 0.547054\n",
      "[164]\ttraining's binary_logloss: 0.546905\n",
      "[165]\ttraining's binary_logloss: 0.546716\n",
      "[166]\ttraining's binary_logloss: 0.546528\n",
      "[167]\ttraining's binary_logloss: 0.546344\n",
      "[168]\ttraining's binary_logloss: 0.54616\n",
      "[169]\ttraining's binary_logloss: 0.545971\n",
      "[170]\ttraining's binary_logloss: 0.545803\n",
      "[171]\ttraining's binary_logloss: 0.545663\n",
      "[172]\ttraining's binary_logloss: 0.545545\n",
      "[173]\ttraining's binary_logloss: 0.545438\n",
      "[174]\ttraining's binary_logloss: 0.54535\n",
      "[175]\ttraining's binary_logloss: 0.54525\n",
      "[176]\ttraining's binary_logloss: 0.545114\n",
      "[177]\ttraining's binary_logloss: 0.544971\n",
      "[178]\ttraining's binary_logloss: 0.544843\n",
      "[179]\ttraining's binary_logloss: 0.544704\n",
      "[180]\ttraining's binary_logloss: 0.544564\n",
      "[181]\ttraining's binary_logloss: 0.544429\n",
      "[182]\ttraining's binary_logloss: 0.54433\n",
      "[183]\ttraining's binary_logloss: 0.544204\n",
      "[184]\ttraining's binary_logloss: 0.544095\n",
      "[185]\ttraining's binary_logloss: 0.543966\n",
      "[186]\ttraining's binary_logloss: 0.543838\n",
      "[187]\ttraining's binary_logloss: 0.543702\n",
      "[188]\ttraining's binary_logloss: 0.543575\n",
      "[189]\ttraining's binary_logloss: 0.543463\n",
      "[190]\ttraining's binary_logloss: 0.543327\n",
      "[191]\ttraining's binary_logloss: 0.543209\n",
      "[192]\ttraining's binary_logloss: 0.543015\n",
      "[193]\ttraining's binary_logloss: 0.542835\n",
      "[194]\ttraining's binary_logloss: 0.542674\n",
      "[195]\ttraining's binary_logloss: 0.542521\n",
      "[196]\ttraining's binary_logloss: 0.542378\n",
      "[197]\ttraining's binary_logloss: 0.542226\n",
      "[198]\ttraining's binary_logloss: 0.542104\n",
      "[199]\ttraining's binary_logloss: 0.541981\n",
      "[200]\ttraining's binary_logloss: 0.541853\n",
      "[201]\ttraining's binary_logloss: 0.541696\n",
      "[202]\ttraining's binary_logloss: 0.54155\n",
      "[203]\ttraining's binary_logloss: 0.541398\n",
      "[204]\ttraining's binary_logloss: 0.541253\n",
      "[205]\ttraining's binary_logloss: 0.541084\n",
      "[206]\ttraining's binary_logloss: 0.540958\n",
      "[207]\ttraining's binary_logloss: 0.540813\n",
      "[208]\ttraining's binary_logloss: 0.540687\n",
      "[209]\ttraining's binary_logloss: 0.540541\n",
      "[210]\ttraining's binary_logloss: 0.540416\n",
      "[211]\ttraining's binary_logloss: 0.540265\n",
      "[212]\ttraining's binary_logloss: 0.540148\n",
      "[213]\ttraining's binary_logloss: 0.539996\n",
      "[214]\ttraining's binary_logloss: 0.539856\n",
      "[215]\ttraining's binary_logloss: 0.539723\n",
      "[216]\ttraining's binary_logloss: 0.539556\n",
      "[217]\ttraining's binary_logloss: 0.539384\n",
      "[218]\ttraining's binary_logloss: 0.539221\n",
      "[219]\ttraining's binary_logloss: 0.53905\n",
      "[220]\ttraining's binary_logloss: 0.538882\n",
      "[221]\ttraining's binary_logloss: 0.538702\n",
      "[222]\ttraining's binary_logloss: 0.538508\n",
      "[223]\ttraining's binary_logloss: 0.538321\n",
      "[224]\ttraining's binary_logloss: 0.538122\n",
      "[225]\ttraining's binary_logloss: 0.537941\n",
      "[226]\ttraining's binary_logloss: 0.537739\n",
      "[227]\ttraining's binary_logloss: 0.537559\n",
      "[228]\ttraining's binary_logloss: 0.537391\n",
      "[229]\ttraining's binary_logloss: 0.537212\n",
      "[230]\ttraining's binary_logloss: 0.537022\n",
      "[231]\ttraining's binary_logloss: 0.536871\n",
      "[232]\ttraining's binary_logloss: 0.536724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[233]\ttraining's binary_logloss: 0.536589\n",
      "[234]\ttraining's binary_logloss: 0.536446\n",
      "[235]\ttraining's binary_logloss: 0.536285\n",
      "[236]\ttraining's binary_logloss: 0.536124\n",
      "[237]\ttraining's binary_logloss: 0.535967\n",
      "[238]\ttraining's binary_logloss: 0.535826\n",
      "[239]\ttraining's binary_logloss: 0.535689\n",
      "[240]\ttraining's binary_logloss: 0.53551\n",
      "[241]\ttraining's binary_logloss: 0.535299\n",
      "[242]\ttraining's binary_logloss: 0.535124\n",
      "[243]\ttraining's binary_logloss: 0.534928\n",
      "[244]\ttraining's binary_logloss: 0.534734\n",
      "[245]\ttraining's binary_logloss: 0.534547\n",
      "[246]\ttraining's binary_logloss: 0.534374\n",
      "[247]\ttraining's binary_logloss: 0.534171\n",
      "[248]\ttraining's binary_logloss: 0.533974\n",
      "[249]\ttraining's binary_logloss: 0.533783\n",
      "[250]\ttraining's binary_logloss: 0.533596\n",
      "[251]\ttraining's binary_logloss: 0.533429\n",
      "[252]\ttraining's binary_logloss: 0.533288\n",
      "[253]\ttraining's binary_logloss: 0.533169\n",
      "[254]\ttraining's binary_logloss: 0.533035\n",
      "[255]\ttraining's binary_logloss: 0.532928\n",
      "[256]\ttraining's binary_logloss: 0.532746\n",
      "[257]\ttraining's binary_logloss: 0.532511\n",
      "[258]\ttraining's binary_logloss: 0.532338\n",
      "[259]\ttraining's binary_logloss: 0.532135\n",
      "[260]\ttraining's binary_logloss: 0.531955\n",
      "[261]\ttraining's binary_logloss: 0.531779\n",
      "[262]\ttraining's binary_logloss: 0.531626\n",
      "[263]\ttraining's binary_logloss: 0.531498\n",
      "[264]\ttraining's binary_logloss: 0.531352\n",
      "[265]\ttraining's binary_logloss: 0.531211\n",
      "[266]\ttraining's binary_logloss: 0.531087\n",
      "[267]\ttraining's binary_logloss: 0.530891\n",
      "[268]\ttraining's binary_logloss: 0.530706\n",
      "[269]\ttraining's binary_logloss: 0.530524\n",
      "[270]\ttraining's binary_logloss: 0.530374\n",
      "[271]\ttraining's binary_logloss: 0.530157\n",
      "[272]\ttraining's binary_logloss: 0.529916\n",
      "[273]\ttraining's binary_logloss: 0.529695\n",
      "[274]\ttraining's binary_logloss: 0.529478\n",
      "[275]\ttraining's binary_logloss: 0.529305\n",
      "[276]\ttraining's binary_logloss: 0.529106\n",
      "[277]\ttraining's binary_logloss: 0.528915\n",
      "[278]\ttraining's binary_logloss: 0.528747\n",
      "[279]\ttraining's binary_logloss: 0.528547\n",
      "[280]\ttraining's binary_logloss: 0.528377\n",
      "[281]\ttraining's binary_logloss: 0.528176\n",
      "[282]\ttraining's binary_logloss: 0.527987\n",
      "[283]\ttraining's binary_logloss: 0.527781\n",
      "[284]\ttraining's binary_logloss: 0.527587\n",
      "[285]\ttraining's binary_logloss: 0.5274\n",
      "[286]\ttraining's binary_logloss: 0.527188\n",
      "[287]\ttraining's binary_logloss: 0.526973\n",
      "[288]\ttraining's binary_logloss: 0.526764\n",
      "[289]\ttraining's binary_logloss: 0.526545\n",
      "[290]\ttraining's binary_logloss: 0.526352\n",
      "[291]\ttraining's binary_logloss: 0.526137\n",
      "[292]\ttraining's binary_logloss: 0.52592\n",
      "[293]\ttraining's binary_logloss: 0.525711\n",
      "[294]\ttraining's binary_logloss: 0.525494\n",
      "[295]\ttraining's binary_logloss: 0.525286\n",
      "[296]\ttraining's binary_logloss: 0.525062\n",
      "[297]\ttraining's binary_logloss: 0.52486\n",
      "[298]\ttraining's binary_logloss: 0.524658\n",
      "[299]\ttraining's binary_logloss: 0.524469\n",
      "[300]\ttraining's binary_logloss: 0.524264\n",
      "[301]\ttraining's binary_logloss: 0.524086\n",
      "[302]\ttraining's binary_logloss: 0.523888\n",
      "[303]\ttraining's binary_logloss: 0.523726\n",
      "[304]\ttraining's binary_logloss: 0.523494\n",
      "[305]\ttraining's binary_logloss: 0.523311\n",
      "[306]\ttraining's binary_logloss: 0.523113\n",
      "[307]\ttraining's binary_logloss: 0.522929\n",
      "[308]\ttraining's binary_logloss: 0.522741\n",
      "[309]\ttraining's binary_logloss: 0.522586\n",
      "[310]\ttraining's binary_logloss: 0.522411\n",
      "[311]\ttraining's binary_logloss: 0.522212\n",
      "[312]\ttraining's binary_logloss: 0.521958\n",
      "[313]\ttraining's binary_logloss: 0.521776\n",
      "[314]\ttraining's binary_logloss: 0.521593\n",
      "[315]\ttraining's binary_logloss: 0.52138\n",
      "[316]\ttraining's binary_logloss: 0.521192\n",
      "[317]\ttraining's binary_logloss: 0.520985\n",
      "[318]\ttraining's binary_logloss: 0.520763\n",
      "[319]\ttraining's binary_logloss: 0.520519\n",
      "[320]\ttraining's binary_logloss: 0.520344\n",
      "[321]\ttraining's binary_logloss: 0.52014\n",
      "[322]\ttraining's binary_logloss: 0.51996\n",
      "[323]\ttraining's binary_logloss: 0.51978\n",
      "[324]\ttraining's binary_logloss: 0.519618\n",
      "[325]\ttraining's binary_logloss: 0.51946\n",
      "[326]\ttraining's binary_logloss: 0.519258\n",
      "[327]\ttraining's binary_logloss: 0.51905\n",
      "[328]\ttraining's binary_logloss: 0.518826\n",
      "[329]\ttraining's binary_logloss: 0.518597\n",
      "[330]\ttraining's binary_logloss: 0.518381\n",
      "[331]\ttraining's binary_logloss: 0.518189\n",
      "[332]\ttraining's binary_logloss: 0.518\n",
      "[333]\ttraining's binary_logloss: 0.517824\n",
      "[334]\ttraining's binary_logloss: 0.51764\n",
      "[335]\ttraining's binary_logloss: 0.517463\n",
      "[336]\ttraining's binary_logloss: 0.51725\n",
      "[337]\ttraining's binary_logloss: 0.517032\n",
      "[338]\ttraining's binary_logloss: 0.516834\n",
      "[339]\ttraining's binary_logloss: 0.516638\n",
      "[340]\ttraining's binary_logloss: 0.51644\n",
      "[341]\ttraining's binary_logloss: 0.516292\n",
      "[342]\ttraining's binary_logloss: 0.516134\n",
      "[343]\ttraining's binary_logloss: 0.515976\n",
      "[344]\ttraining's binary_logloss: 0.515814\n",
      "[345]\ttraining's binary_logloss: 0.515651\n",
      "[346]\ttraining's binary_logloss: 0.515516\n",
      "[347]\ttraining's binary_logloss: 0.515363\n",
      "[348]\ttraining's binary_logloss: 0.515214\n",
      "[349]\ttraining's binary_logloss: 0.515101\n",
      "[350]\ttraining's binary_logloss: 0.514918\n",
      "[351]\ttraining's binary_logloss: 0.514681\n",
      "[352]\ttraining's binary_logloss: 0.514457\n",
      "[353]\ttraining's binary_logloss: 0.514221\n",
      "[354]\ttraining's binary_logloss: 0.513985\n",
      "[355]\ttraining's binary_logloss: 0.513781\n",
      "[356]\ttraining's binary_logloss: 0.513582\n",
      "[357]\ttraining's binary_logloss: 0.513358\n",
      "[358]\ttraining's binary_logloss: 0.513168\n",
      "[359]\ttraining's binary_logloss: 0.512994\n",
      "[360]\ttraining's binary_logloss: 0.512807\n",
      "[361]\ttraining's binary_logloss: 0.512568\n",
      "[362]\ttraining's binary_logloss: 0.512339\n",
      "[363]\ttraining's binary_logloss: 0.512149\n",
      "[364]\ttraining's binary_logloss: 0.51192\n",
      "[365]\ttraining's binary_logloss: 0.511708\n",
      "[366]\ttraining's binary_logloss: 0.511557\n",
      "[367]\ttraining's binary_logloss: 0.51138\n",
      "[368]\ttraining's binary_logloss: 0.511198\n",
      "[369]\ttraining's binary_logloss: 0.51105\n",
      "[370]\ttraining's binary_logloss: 0.510874\n",
      "[371]\ttraining's binary_logloss: 0.510709\n",
      "[372]\ttraining's binary_logloss: 0.510543\n",
      "[373]\ttraining's binary_logloss: 0.510325\n",
      "[374]\ttraining's binary_logloss: 0.510177\n",
      "[375]\ttraining's binary_logloss: 0.510017\n",
      "[376]\ttraining's binary_logloss: 0.509825\n",
      "[377]\ttraining's binary_logloss: 0.509647\n",
      "[378]\ttraining's binary_logloss: 0.509478\n",
      "[379]\ttraining's binary_logloss: 0.509328\n",
      "[380]\ttraining's binary_logloss: 0.509147\n",
      "[381]\ttraining's binary_logloss: 0.508951\n",
      "[382]\ttraining's binary_logloss: 0.508764\n",
      "[383]\ttraining's binary_logloss: 0.508574\n",
      "[384]\ttraining's binary_logloss: 0.508399\n",
      "[385]\ttraining's binary_logloss: 0.508231\n",
      "[386]\ttraining's binary_logloss: 0.50804\n",
      "[387]\ttraining's binary_logloss: 0.507821\n",
      "[388]\ttraining's binary_logloss: 0.507655\n",
      "[389]\ttraining's binary_logloss: 0.507447\n",
      "[390]\ttraining's binary_logloss: 0.507234\n",
      "[391]\ttraining's binary_logloss: 0.507007\n",
      "[392]\ttraining's binary_logloss: 0.506818\n",
      "[393]\ttraining's binary_logloss: 0.50663\n",
      "[394]\ttraining's binary_logloss: 0.506415\n",
      "[395]\ttraining's binary_logloss: 0.506194\n",
      "[396]\ttraining's binary_logloss: 0.506021\n",
      "[397]\ttraining's binary_logloss: 0.505875\n",
      "[398]\ttraining's binary_logloss: 0.505721\n",
      "[399]\ttraining's binary_logloss: 0.505571\n",
      "[400]\ttraining's binary_logloss: 0.505435\n",
      "[401]\ttraining's binary_logloss: 0.505206\n",
      "[402]\ttraining's binary_logloss: 0.504992\n",
      "[403]\ttraining's binary_logloss: 0.504778\n",
      "[404]\ttraining's binary_logloss: 0.504549\n",
      "[405]\ttraining's binary_logloss: 0.504345\n",
      "[406]\ttraining's binary_logloss: 0.504148\n",
      "[407]\ttraining's binary_logloss: 0.50395\n",
      "[408]\ttraining's binary_logloss: 0.503743\n",
      "[409]\ttraining's binary_logloss: 0.503557\n",
      "[410]\ttraining's binary_logloss: 0.503363\n",
      "[411]\ttraining's binary_logloss: 0.503212\n",
      "[412]\ttraining's binary_logloss: 0.503048\n",
      "[413]\ttraining's binary_logloss: 0.502859\n",
      "[414]\ttraining's binary_logloss: 0.502687\n",
      "[415]\ttraining's binary_logloss: 0.502485\n",
      "[416]\ttraining's binary_logloss: 0.502312\n",
      "[417]\ttraining's binary_logloss: 0.502134\n",
      "[418]\ttraining's binary_logloss: 0.501967\n",
      "[419]\ttraining's binary_logloss: 0.501784\n",
      "[420]\ttraining's binary_logloss: 0.501612\n",
      "[421]\ttraining's binary_logloss: 0.501466\n",
      "[422]\ttraining's binary_logloss: 0.501318\n",
      "[423]\ttraining's binary_logloss: 0.501176\n",
      "[424]\ttraining's binary_logloss: 0.501034\n",
      "[425]\ttraining's binary_logloss: 0.500875\n",
      "[426]\ttraining's binary_logloss: 0.500696\n",
      "[427]\ttraining's binary_logloss: 0.500533\n",
      "[428]\ttraining's binary_logloss: 0.50037\n",
      "[429]\ttraining's binary_logloss: 0.500182\n",
      "[430]\ttraining's binary_logloss: 0.499998\n",
      "[431]\ttraining's binary_logloss: 0.499774\n",
      "[432]\ttraining's binary_logloss: 0.499574\n",
      "[433]\ttraining's binary_logloss: 0.499337\n",
      "[434]\ttraining's binary_logloss: 0.499145\n",
      "[435]\ttraining's binary_logloss: 0.498904\n",
      "[436]\ttraining's binary_logloss: 0.498717\n",
      "[437]\ttraining's binary_logloss: 0.498537\n",
      "[438]\ttraining's binary_logloss: 0.498322\n",
      "[439]\ttraining's binary_logloss: 0.498153\n",
      "[440]\ttraining's binary_logloss: 0.497987\n",
      "[441]\ttraining's binary_logloss: 0.497793\n",
      "[442]\ttraining's binary_logloss: 0.497603\n",
      "[443]\ttraining's binary_logloss: 0.497417\n",
      "[444]\ttraining's binary_logloss: 0.497202\n",
      "[445]\ttraining's binary_logloss: 0.497008\n",
      "[446]\ttraining's binary_logloss: 0.496818\n",
      "[447]\ttraining's binary_logloss: 0.496609\n",
      "[448]\ttraining's binary_logloss: 0.496419\n",
      "[449]\ttraining's binary_logloss: 0.496232\n",
      "[450]\ttraining's binary_logloss: 0.49603\n",
      "[451]\ttraining's binary_logloss: 0.495856\n",
      "[452]\ttraining's binary_logloss: 0.495697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[453]\ttraining's binary_logloss: 0.495528\n",
      "[454]\ttraining's binary_logloss: 0.49536\n",
      "[455]\ttraining's binary_logloss: 0.4952\n",
      "[456]\ttraining's binary_logloss: 0.495007\n",
      "[457]\ttraining's binary_logloss: 0.494813\n",
      "[458]\ttraining's binary_logloss: 0.49461\n",
      "[459]\ttraining's binary_logloss: 0.494422\n",
      "[460]\ttraining's binary_logloss: 0.494225\n",
      "[461]\ttraining's binary_logloss: 0.49403\n",
      "[462]\ttraining's binary_logloss: 0.493849\n",
      "[463]\ttraining's binary_logloss: 0.493676\n",
      "[464]\ttraining's binary_logloss: 0.493547\n",
      "[465]\ttraining's binary_logloss: 0.493391\n",
      "[466]\ttraining's binary_logloss: 0.493176\n",
      "[467]\ttraining's binary_logloss: 0.492974\n",
      "[468]\ttraining's binary_logloss: 0.492784\n",
      "[469]\ttraining's binary_logloss: 0.49256\n",
      "[470]\ttraining's binary_logloss: 0.492388\n",
      "[471]\ttraining's binary_logloss: 0.492227\n",
      "[472]\ttraining's binary_logloss: 0.492078\n",
      "[473]\ttraining's binary_logloss: 0.491934\n",
      "[474]\ttraining's binary_logloss: 0.491795\n",
      "[475]\ttraining's binary_logloss: 0.491655\n",
      "[476]\ttraining's binary_logloss: 0.491455\n",
      "[477]\ttraining's binary_logloss: 0.491251\n",
      "[478]\ttraining's binary_logloss: 0.491051\n",
      "[479]\ttraining's binary_logloss: 0.490875\n",
      "[480]\ttraining's binary_logloss: 0.490681\n",
      "[481]\ttraining's binary_logloss: 0.490491\n",
      "[482]\ttraining's binary_logloss: 0.490303\n",
      "[483]\ttraining's binary_logloss: 0.490133\n",
      "[484]\ttraining's binary_logloss: 0.489952\n",
      "[485]\ttraining's binary_logloss: 0.489771\n",
      "[486]\ttraining's binary_logloss: 0.489527\n",
      "[487]\ttraining's binary_logloss: 0.489324\n",
      "[488]\ttraining's binary_logloss: 0.489115\n",
      "[489]\ttraining's binary_logloss: 0.488904\n",
      "[490]\ttraining's binary_logloss: 0.48868\n",
      "[491]\ttraining's binary_logloss: 0.488497\n",
      "[492]\ttraining's binary_logloss: 0.488318\n",
      "[493]\ttraining's binary_logloss: 0.488132\n",
      "[494]\ttraining's binary_logloss: 0.48795\n",
      "[495]\ttraining's binary_logloss: 0.487744\n",
      "[496]\ttraining's binary_logloss: 0.487536\n",
      "[497]\ttraining's binary_logloss: 0.487366\n",
      "[498]\ttraining's binary_logloss: 0.487195\n",
      "[499]\ttraining's binary_logloss: 0.48702\n",
      "[500]\ttraining's binary_logloss: 0.486848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.617263\n",
      "[2]\ttraining's binary_logloss: 0.615775\n",
      "[3]\ttraining's binary_logloss: 0.614343\n",
      "[4]\ttraining's binary_logloss: 0.612947\n",
      "[5]\ttraining's binary_logloss: 0.611634\n",
      "[6]\ttraining's binary_logloss: 0.61031\n",
      "[7]\ttraining's binary_logloss: 0.609007\n",
      "[8]\ttraining's binary_logloss: 0.607747\n",
      "[9]\ttraining's binary_logloss: 0.60659\n",
      "[10]\ttraining's binary_logloss: 0.605419\n",
      "[11]\ttraining's binary_logloss: 0.604265\n",
      "[12]\ttraining's binary_logloss: 0.603118\n",
      "[13]\ttraining's binary_logloss: 0.602014\n",
      "[14]\ttraining's binary_logloss: 0.600931\n",
      "[15]\ttraining's binary_logloss: 0.599843\n",
      "[16]\ttraining's binary_logloss: 0.598856\n",
      "[17]\ttraining's binary_logloss: 0.597922\n",
      "[18]\ttraining's binary_logloss: 0.597025\n",
      "[19]\ttraining's binary_logloss: 0.596105\n",
      "[20]\ttraining's binary_logloss: 0.595262\n",
      "[21]\ttraining's binary_logloss: 0.59435\n",
      "[22]\ttraining's binary_logloss: 0.593392\n",
      "[23]\ttraining's binary_logloss: 0.59257\n",
      "[24]\ttraining's binary_logloss: 0.591664\n",
      "[25]\ttraining's binary_logloss: 0.590961\n",
      "[26]\ttraining's binary_logloss: 0.590173\n",
      "[27]\ttraining's binary_logloss: 0.589432\n",
      "[28]\ttraining's binary_logloss: 0.588674\n",
      "[29]\ttraining's binary_logloss: 0.58794\n",
      "[30]\ttraining's binary_logloss: 0.587234\n",
      "[31]\ttraining's binary_logloss: 0.586509\n",
      "[32]\ttraining's binary_logloss: 0.585797\n",
      "[33]\ttraining's binary_logloss: 0.585114\n",
      "[34]\ttraining's binary_logloss: 0.584474\n",
      "[35]\ttraining's binary_logloss: 0.583858\n",
      "[36]\ttraining's binary_logloss: 0.583291\n",
      "[37]\ttraining's binary_logloss: 0.582722\n",
      "[38]\ttraining's binary_logloss: 0.582146\n",
      "[39]\ttraining's binary_logloss: 0.58156\n",
      "[40]\ttraining's binary_logloss: 0.580994\n",
      "[41]\ttraining's binary_logloss: 0.580512\n",
      "[42]\ttraining's binary_logloss: 0.580029\n",
      "[43]\ttraining's binary_logloss: 0.579528\n",
      "[44]\ttraining's binary_logloss: 0.579055\n",
      "[45]\ttraining's binary_logloss: 0.578628\n",
      "[46]\ttraining's binary_logloss: 0.578188\n",
      "[47]\ttraining's binary_logloss: 0.577712\n",
      "[48]\ttraining's binary_logloss: 0.577279\n",
      "[49]\ttraining's binary_logloss: 0.576884\n",
      "[50]\ttraining's binary_logloss: 0.576437\n",
      "[51]\ttraining's binary_logloss: 0.575997\n",
      "[52]\ttraining's binary_logloss: 0.575572\n",
      "[53]\ttraining's binary_logloss: 0.575168\n",
      "[54]\ttraining's binary_logloss: 0.574732\n",
      "[55]\ttraining's binary_logloss: 0.574297\n",
      "[56]\ttraining's binary_logloss: 0.573955\n",
      "[57]\ttraining's binary_logloss: 0.573559\n",
      "[58]\ttraining's binary_logloss: 0.573225\n",
      "[59]\ttraining's binary_logloss: 0.572868\n",
      "[60]\ttraining's binary_logloss: 0.572563\n",
      "[61]\ttraining's binary_logloss: 0.572193\n",
      "[62]\ttraining's binary_logloss: 0.571857\n",
      "[63]\ttraining's binary_logloss: 0.571536\n",
      "[64]\ttraining's binary_logloss: 0.571184\n",
      "[65]\ttraining's binary_logloss: 0.570874\n",
      "[66]\ttraining's binary_logloss: 0.570501\n",
      "[67]\ttraining's binary_logloss: 0.570106\n",
      "[68]\ttraining's binary_logloss: 0.569767\n",
      "[69]\ttraining's binary_logloss: 0.569424\n",
      "[70]\ttraining's binary_logloss: 0.569137\n",
      "[71]\ttraining's binary_logloss: 0.568809\n",
      "[72]\ttraining's binary_logloss: 0.568531\n",
      "[73]\ttraining's binary_logloss: 0.568192\n",
      "[74]\ttraining's binary_logloss: 0.567942\n",
      "[75]\ttraining's binary_logloss: 0.567686\n",
      "[76]\ttraining's binary_logloss: 0.567374\n",
      "[77]\ttraining's binary_logloss: 0.567057\n",
      "[78]\ttraining's binary_logloss: 0.566873\n",
      "[79]\ttraining's binary_logloss: 0.566542\n",
      "[80]\ttraining's binary_logloss: 0.566334\n",
      "[81]\ttraining's binary_logloss: 0.566033\n",
      "[82]\ttraining's binary_logloss: 0.56576\n",
      "[83]\ttraining's binary_logloss: 0.565484\n",
      "[84]\ttraining's binary_logloss: 0.565214\n",
      "[85]\ttraining's binary_logloss: 0.564937\n",
      "[86]\ttraining's binary_logloss: 0.564693\n",
      "[87]\ttraining's binary_logloss: 0.564452\n",
      "[88]\ttraining's binary_logloss: 0.564243\n",
      "[89]\ttraining's binary_logloss: 0.564052\n",
      "[90]\ttraining's binary_logloss: 0.563849\n",
      "[91]\ttraining's binary_logloss: 0.563629\n",
      "[92]\ttraining's binary_logloss: 0.563392\n",
      "[93]\ttraining's binary_logloss: 0.563157\n",
      "[94]\ttraining's binary_logloss: 0.562919\n",
      "[95]\ttraining's binary_logloss: 0.562708\n",
      "[96]\ttraining's binary_logloss: 0.562502\n",
      "[97]\ttraining's binary_logloss: 0.562305\n",
      "[98]\ttraining's binary_logloss: 0.562104\n",
      "[99]\ttraining's binary_logloss: 0.561927\n",
      "[100]\ttraining's binary_logloss: 0.561756\n",
      "[101]\ttraining's binary_logloss: 0.561548\n",
      "[102]\ttraining's binary_logloss: 0.561363\n",
      "[103]\ttraining's binary_logloss: 0.561174\n",
      "[104]\ttraining's binary_logloss: 0.561021\n",
      "[105]\ttraining's binary_logloss: 0.560857\n",
      "[106]\ttraining's binary_logloss: 0.56065\n",
      "[107]\ttraining's binary_logloss: 0.560435\n",
      "[108]\ttraining's binary_logloss: 0.560239\n",
      "[109]\ttraining's binary_logloss: 0.560031\n",
      "[110]\ttraining's binary_logloss: 0.55987\n",
      "[111]\ttraining's binary_logloss: 0.559716\n",
      "[112]\ttraining's binary_logloss: 0.55957\n",
      "[113]\ttraining's binary_logloss: 0.559375\n",
      "[114]\ttraining's binary_logloss: 0.559236\n",
      "[115]\ttraining's binary_logloss: 0.559088\n",
      "[116]\ttraining's binary_logloss: 0.5589\n",
      "[117]\ttraining's binary_logloss: 0.558717\n",
      "[118]\ttraining's binary_logloss: 0.55855\n",
      "[119]\ttraining's binary_logloss: 0.558358\n",
      "[120]\ttraining's binary_logloss: 0.558176\n",
      "[121]\ttraining's binary_logloss: 0.558008\n",
      "[122]\ttraining's binary_logloss: 0.557855\n",
      "[123]\ttraining's binary_logloss: 0.557711\n",
      "[124]\ttraining's binary_logloss: 0.557573\n",
      "[125]\ttraining's binary_logloss: 0.557454\n",
      "[126]\ttraining's binary_logloss: 0.557284\n",
      "[127]\ttraining's binary_logloss: 0.557126\n",
      "[128]\ttraining's binary_logloss: 0.556944\n",
      "[129]\ttraining's binary_logloss: 0.556818\n",
      "[130]\ttraining's binary_logloss: 0.556659\n",
      "[131]\ttraining's binary_logloss: 0.55648\n",
      "[132]\ttraining's binary_logloss: 0.556311\n",
      "[133]\ttraining's binary_logloss: 0.55614\n",
      "[134]\ttraining's binary_logloss: 0.555949\n",
      "[135]\ttraining's binary_logloss: 0.555784\n",
      "[136]\ttraining's binary_logloss: 0.555579\n",
      "[137]\ttraining's binary_logloss: 0.555398\n",
      "[138]\ttraining's binary_logloss: 0.555197\n",
      "[139]\ttraining's binary_logloss: 0.555026\n",
      "[140]\ttraining's binary_logloss: 0.554841\n",
      "[141]\ttraining's binary_logloss: 0.554644\n",
      "[142]\ttraining's binary_logloss: 0.554458\n",
      "[143]\ttraining's binary_logloss: 0.554256\n",
      "[144]\ttraining's binary_logloss: 0.55408\n",
      "[145]\ttraining's binary_logloss: 0.553839\n",
      "[146]\ttraining's binary_logloss: 0.553626\n",
      "[147]\ttraining's binary_logloss: 0.5534\n",
      "[148]\ttraining's binary_logloss: 0.553191\n",
      "[149]\ttraining's binary_logloss: 0.552995\n",
      "[150]\ttraining's binary_logloss: 0.552779\n",
      "[151]\ttraining's binary_logloss: 0.552627\n",
      "[152]\ttraining's binary_logloss: 0.552495\n",
      "[153]\ttraining's binary_logloss: 0.552372\n",
      "[154]\ttraining's binary_logloss: 0.552235\n",
      "[155]\ttraining's binary_logloss: 0.5521\n",
      "[156]\ttraining's binary_logloss: 0.551908\n",
      "[157]\ttraining's binary_logloss: 0.551718\n",
      "[158]\ttraining's binary_logloss: 0.551582\n",
      "[159]\ttraining's binary_logloss: 0.5514\n",
      "[160]\ttraining's binary_logloss: 0.551228\n",
      "[161]\ttraining's binary_logloss: 0.551097\n",
      "[162]\ttraining's binary_logloss: 0.550907\n",
      "[163]\ttraining's binary_logloss: 0.550736\n",
      "[164]\ttraining's binary_logloss: 0.550578\n",
      "[165]\ttraining's binary_logloss: 0.550395\n",
      "[166]\ttraining's binary_logloss: 0.550212\n",
      "[167]\ttraining's binary_logloss: 0.550004\n",
      "[168]\ttraining's binary_logloss: 0.549785\n",
      "[169]\ttraining's binary_logloss: 0.549593\n",
      "[170]\ttraining's binary_logloss: 0.549412\n",
      "[171]\ttraining's binary_logloss: 0.549226\n",
      "[172]\ttraining's binary_logloss: 0.549051\n",
      "[173]\ttraining's binary_logloss: 0.548874\n",
      "[174]\ttraining's binary_logloss: 0.548721\n",
      "[175]\ttraining's binary_logloss: 0.548541\n",
      "[176]\ttraining's binary_logloss: 0.548374\n",
      "[177]\ttraining's binary_logloss: 0.548235\n",
      "[178]\ttraining's binary_logloss: 0.548063\n",
      "[179]\ttraining's binary_logloss: 0.54791\n",
      "[180]\ttraining's binary_logloss: 0.547739\n",
      "[181]\ttraining's binary_logloss: 0.54764\n",
      "[182]\ttraining's binary_logloss: 0.547502\n",
      "[183]\ttraining's binary_logloss: 0.547354\n",
      "[184]\ttraining's binary_logloss: 0.5472\n",
      "[185]\ttraining's binary_logloss: 0.547004\n",
      "[186]\ttraining's binary_logloss: 0.54684\n",
      "[187]\ttraining's binary_logloss: 0.5467\n",
      "[188]\ttraining's binary_logloss: 0.546543\n",
      "[189]\ttraining's binary_logloss: 0.546434\n",
      "[190]\ttraining's binary_logloss: 0.54633\n",
      "[191]\ttraining's binary_logloss: 0.54618\n",
      "[192]\ttraining's binary_logloss: 0.545972\n",
      "[193]\ttraining's binary_logloss: 0.545778\n",
      "[194]\ttraining's binary_logloss: 0.545616\n",
      "[195]\ttraining's binary_logloss: 0.545457\n",
      "[196]\ttraining's binary_logloss: 0.54529\n",
      "[197]\ttraining's binary_logloss: 0.545098\n",
      "[198]\ttraining's binary_logloss: 0.544928\n",
      "[199]\ttraining's binary_logloss: 0.544762\n",
      "[200]\ttraining's binary_logloss: 0.544616\n",
      "[201]\ttraining's binary_logloss: 0.544448\n",
      "[202]\ttraining's binary_logloss: 0.54431\n",
      "[203]\ttraining's binary_logloss: 0.544124\n",
      "[204]\ttraining's binary_logloss: 0.543905\n",
      "[205]\ttraining's binary_logloss: 0.543715\n",
      "[206]\ttraining's binary_logloss: 0.543579\n",
      "[207]\ttraining's binary_logloss: 0.543396\n",
      "[208]\ttraining's binary_logloss: 0.543257\n",
      "[209]\ttraining's binary_logloss: 0.543111\n",
      "[210]\ttraining's binary_logloss: 0.542906\n",
      "[211]\ttraining's binary_logloss: 0.542772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[212]\ttraining's binary_logloss: 0.542633\n",
      "[213]\ttraining's binary_logloss: 0.542498\n",
      "[214]\ttraining's binary_logloss: 0.542323\n",
      "[215]\ttraining's binary_logloss: 0.542197\n",
      "[216]\ttraining's binary_logloss: 0.541997\n",
      "[217]\ttraining's binary_logloss: 0.541811\n",
      "[218]\ttraining's binary_logloss: 0.54161\n",
      "[219]\ttraining's binary_logloss: 0.54145\n",
      "[220]\ttraining's binary_logloss: 0.541272\n",
      "[221]\ttraining's binary_logloss: 0.541098\n",
      "[222]\ttraining's binary_logloss: 0.540929\n",
      "[223]\ttraining's binary_logloss: 0.540758\n",
      "[224]\ttraining's binary_logloss: 0.540558\n",
      "[225]\ttraining's binary_logloss: 0.540359\n",
      "[226]\ttraining's binary_logloss: 0.540155\n",
      "[227]\ttraining's binary_logloss: 0.53997\n",
      "[228]\ttraining's binary_logloss: 0.539794\n",
      "[229]\ttraining's binary_logloss: 0.539613\n",
      "[230]\ttraining's binary_logloss: 0.539425\n",
      "[231]\ttraining's binary_logloss: 0.539263\n",
      "[232]\ttraining's binary_logloss: 0.539099\n",
      "[233]\ttraining's binary_logloss: 0.538936\n",
      "[234]\ttraining's binary_logloss: 0.538771\n",
      "[235]\ttraining's binary_logloss: 0.538615\n",
      "[236]\ttraining's binary_logloss: 0.538453\n",
      "[237]\ttraining's binary_logloss: 0.538263\n",
      "[238]\ttraining's binary_logloss: 0.5381\n",
      "[239]\ttraining's binary_logloss: 0.537906\n",
      "[240]\ttraining's binary_logloss: 0.537745\n",
      "[241]\ttraining's binary_logloss: 0.537525\n",
      "[242]\ttraining's binary_logloss: 0.537301\n",
      "[243]\ttraining's binary_logloss: 0.537082\n",
      "[244]\ttraining's binary_logloss: 0.536878\n",
      "[245]\ttraining's binary_logloss: 0.536653\n",
      "[246]\ttraining's binary_logloss: 0.536451\n",
      "[247]\ttraining's binary_logloss: 0.536248\n",
      "[248]\ttraining's binary_logloss: 0.536089\n",
      "[249]\ttraining's binary_logloss: 0.535901\n",
      "[250]\ttraining's binary_logloss: 0.535716\n",
      "[251]\ttraining's binary_logloss: 0.535548\n",
      "[252]\ttraining's binary_logloss: 0.535398\n",
      "[253]\ttraining's binary_logloss: 0.535221\n",
      "[254]\ttraining's binary_logloss: 0.535051\n",
      "[255]\ttraining's binary_logloss: 0.534869\n",
      "[256]\ttraining's binary_logloss: 0.534674\n",
      "[257]\ttraining's binary_logloss: 0.534495\n",
      "[258]\ttraining's binary_logloss: 0.534314\n",
      "[259]\ttraining's binary_logloss: 0.534114\n",
      "[260]\ttraining's binary_logloss: 0.533957\n",
      "[261]\ttraining's binary_logloss: 0.533756\n",
      "[262]\ttraining's binary_logloss: 0.53357\n",
      "[263]\ttraining's binary_logloss: 0.533385\n",
      "[264]\ttraining's binary_logloss: 0.533185\n",
      "[265]\ttraining's binary_logloss: 0.533003\n",
      "[266]\ttraining's binary_logloss: 0.532813\n",
      "[267]\ttraining's binary_logloss: 0.532667\n",
      "[268]\ttraining's binary_logloss: 0.532519\n",
      "[269]\ttraining's binary_logloss: 0.532345\n",
      "[270]\ttraining's binary_logloss: 0.532155\n",
      "[271]\ttraining's binary_logloss: 0.531958\n",
      "[272]\ttraining's binary_logloss: 0.531753\n",
      "[273]\ttraining's binary_logloss: 0.531567\n",
      "[274]\ttraining's binary_logloss: 0.53135\n",
      "[275]\ttraining's binary_logloss: 0.531163\n",
      "[276]\ttraining's binary_logloss: 0.530974\n",
      "[277]\ttraining's binary_logloss: 0.530792\n",
      "[278]\ttraining's binary_logloss: 0.530613\n",
      "[279]\ttraining's binary_logloss: 0.530431\n",
      "[280]\ttraining's binary_logloss: 0.530253\n",
      "[281]\ttraining's binary_logloss: 0.530086\n",
      "[282]\ttraining's binary_logloss: 0.529896\n",
      "[283]\ttraining's binary_logloss: 0.529691\n",
      "[284]\ttraining's binary_logloss: 0.529493\n",
      "[285]\ttraining's binary_logloss: 0.529318\n",
      "[286]\ttraining's binary_logloss: 0.529131\n",
      "[287]\ttraining's binary_logloss: 0.528916\n",
      "[288]\ttraining's binary_logloss: 0.528718\n",
      "[289]\ttraining's binary_logloss: 0.528505\n",
      "[290]\ttraining's binary_logloss: 0.528303\n",
      "[291]\ttraining's binary_logloss: 0.528076\n",
      "[292]\ttraining's binary_logloss: 0.527887\n",
      "[293]\ttraining's binary_logloss: 0.52768\n",
      "[294]\ttraining's binary_logloss: 0.52747\n",
      "[295]\ttraining's binary_logloss: 0.527232\n",
      "[296]\ttraining's binary_logloss: 0.527042\n",
      "[297]\ttraining's binary_logloss: 0.526828\n",
      "[298]\ttraining's binary_logloss: 0.526632\n",
      "[299]\ttraining's binary_logloss: 0.526429\n",
      "[300]\ttraining's binary_logloss: 0.526211\n",
      "[301]\ttraining's binary_logloss: 0.526008\n",
      "[302]\ttraining's binary_logloss: 0.525814\n",
      "[303]\ttraining's binary_logloss: 0.525628\n",
      "[304]\ttraining's binary_logloss: 0.525425\n",
      "[305]\ttraining's binary_logloss: 0.525218\n",
      "[306]\ttraining's binary_logloss: 0.525016\n",
      "[307]\ttraining's binary_logloss: 0.524807\n",
      "[308]\ttraining's binary_logloss: 0.524629\n",
      "[309]\ttraining's binary_logloss: 0.524425\n",
      "[310]\ttraining's binary_logloss: 0.524212\n",
      "[311]\ttraining's binary_logloss: 0.524022\n",
      "[312]\ttraining's binary_logloss: 0.523847\n",
      "[313]\ttraining's binary_logloss: 0.523652\n",
      "[314]\ttraining's binary_logloss: 0.523492\n",
      "[315]\ttraining's binary_logloss: 0.5233\n",
      "[316]\ttraining's binary_logloss: 0.523062\n",
      "[317]\ttraining's binary_logloss: 0.522872\n",
      "[318]\ttraining's binary_logloss: 0.52265\n",
      "[319]\ttraining's binary_logloss: 0.522427\n",
      "[320]\ttraining's binary_logloss: 0.522197\n",
      "[321]\ttraining's binary_logloss: 0.522021\n",
      "[322]\ttraining's binary_logloss: 0.521846\n",
      "[323]\ttraining's binary_logloss: 0.521625\n",
      "[324]\ttraining's binary_logloss: 0.521455\n",
      "[325]\ttraining's binary_logloss: 0.521287\n",
      "[326]\ttraining's binary_logloss: 0.521119\n",
      "[327]\ttraining's binary_logloss: 0.520956\n",
      "[328]\ttraining's binary_logloss: 0.520747\n",
      "[329]\ttraining's binary_logloss: 0.520585\n",
      "[330]\ttraining's binary_logloss: 0.520432\n",
      "[331]\ttraining's binary_logloss: 0.520235\n",
      "[332]\ttraining's binary_logloss: 0.520043\n",
      "[333]\ttraining's binary_logloss: 0.519824\n",
      "[334]\ttraining's binary_logloss: 0.519609\n",
      "[335]\ttraining's binary_logloss: 0.519399\n",
      "[336]\ttraining's binary_logloss: 0.519195\n",
      "[337]\ttraining's binary_logloss: 0.518997\n",
      "[338]\ttraining's binary_logloss: 0.518807\n",
      "[339]\ttraining's binary_logloss: 0.518629\n",
      "[340]\ttraining's binary_logloss: 0.518437\n",
      "[341]\ttraining's binary_logloss: 0.518251\n",
      "[342]\ttraining's binary_logloss: 0.518057\n",
      "[343]\ttraining's binary_logloss: 0.517857\n",
      "[344]\ttraining's binary_logloss: 0.517661\n",
      "[345]\ttraining's binary_logloss: 0.517474\n",
      "[346]\ttraining's binary_logloss: 0.517301\n",
      "[347]\ttraining's binary_logloss: 0.517131\n",
      "[348]\ttraining's binary_logloss: 0.516989\n",
      "[349]\ttraining's binary_logloss: 0.51683\n",
      "[350]\ttraining's binary_logloss: 0.516697\n",
      "[351]\ttraining's binary_logloss: 0.516481\n",
      "[352]\ttraining's binary_logloss: 0.51629\n",
      "[353]\ttraining's binary_logloss: 0.516069\n",
      "[354]\ttraining's binary_logloss: 0.515874\n",
      "[355]\ttraining's binary_logloss: 0.515678\n",
      "[356]\ttraining's binary_logloss: 0.515473\n",
      "[357]\ttraining's binary_logloss: 0.515286\n",
      "[358]\ttraining's binary_logloss: 0.515083\n",
      "[359]\ttraining's binary_logloss: 0.514888\n",
      "[360]\ttraining's binary_logloss: 0.514691\n",
      "[361]\ttraining's binary_logloss: 0.514507\n",
      "[362]\ttraining's binary_logloss: 0.514271\n",
      "[363]\ttraining's binary_logloss: 0.514087\n",
      "[364]\ttraining's binary_logloss: 0.513862\n",
      "[365]\ttraining's binary_logloss: 0.513637\n",
      "[366]\ttraining's binary_logloss: 0.513474\n",
      "[367]\ttraining's binary_logloss: 0.51331\n",
      "[368]\ttraining's binary_logloss: 0.513162\n",
      "[369]\ttraining's binary_logloss: 0.513011\n",
      "[370]\ttraining's binary_logloss: 0.51287\n",
      "[371]\ttraining's binary_logloss: 0.512677\n",
      "[372]\ttraining's binary_logloss: 0.512472\n",
      "[373]\ttraining's binary_logloss: 0.512292\n",
      "[374]\ttraining's binary_logloss: 0.512114\n",
      "[375]\ttraining's binary_logloss: 0.511924\n",
      "[376]\ttraining's binary_logloss: 0.511716\n",
      "[377]\ttraining's binary_logloss: 0.511518\n",
      "[378]\ttraining's binary_logloss: 0.511326\n",
      "[379]\ttraining's binary_logloss: 0.511137\n",
      "[380]\ttraining's binary_logloss: 0.510959\n",
      "[381]\ttraining's binary_logloss: 0.510737\n",
      "[382]\ttraining's binary_logloss: 0.510541\n",
      "[383]\ttraining's binary_logloss: 0.510333\n",
      "[384]\ttraining's binary_logloss: 0.510113\n",
      "[385]\ttraining's binary_logloss: 0.509895\n",
      "[386]\ttraining's binary_logloss: 0.509715\n",
      "[387]\ttraining's binary_logloss: 0.509522\n",
      "[388]\ttraining's binary_logloss: 0.509341\n",
      "[389]\ttraining's binary_logloss: 0.509158\n",
      "[390]\ttraining's binary_logloss: 0.508971\n",
      "[391]\ttraining's binary_logloss: 0.50879\n",
      "[392]\ttraining's binary_logloss: 0.508578\n",
      "[393]\ttraining's binary_logloss: 0.508376\n",
      "[394]\ttraining's binary_logloss: 0.508158\n",
      "[395]\ttraining's binary_logloss: 0.507973\n",
      "[396]\ttraining's binary_logloss: 0.507782\n",
      "[397]\ttraining's binary_logloss: 0.50759\n",
      "[398]\ttraining's binary_logloss: 0.50738\n",
      "[399]\ttraining's binary_logloss: 0.507191\n",
      "[400]\ttraining's binary_logloss: 0.507012\n",
      "[401]\ttraining's binary_logloss: 0.506817\n",
      "[402]\ttraining's binary_logloss: 0.506624\n",
      "[403]\ttraining's binary_logloss: 0.506423\n",
      "[404]\ttraining's binary_logloss: 0.506223\n",
      "[405]\ttraining's binary_logloss: 0.506032\n",
      "[406]\ttraining's binary_logloss: 0.505802\n",
      "[407]\ttraining's binary_logloss: 0.505586\n",
      "[408]\ttraining's binary_logloss: 0.505397\n",
      "[409]\ttraining's binary_logloss: 0.505219\n",
      "[410]\ttraining's binary_logloss: 0.505039\n",
      "[411]\ttraining's binary_logloss: 0.504862\n",
      "[412]\ttraining's binary_logloss: 0.504664\n",
      "[413]\ttraining's binary_logloss: 0.504467\n",
      "[414]\ttraining's binary_logloss: 0.504287\n",
      "[415]\ttraining's binary_logloss: 0.504113\n",
      "[416]\ttraining's binary_logloss: 0.503958\n",
      "[417]\ttraining's binary_logloss: 0.50377\n",
      "[418]\ttraining's binary_logloss: 0.503588\n",
      "[419]\ttraining's binary_logloss: 0.503391\n",
      "[420]\ttraining's binary_logloss: 0.503164\n",
      "[421]\ttraining's binary_logloss: 0.502998\n",
      "[422]\ttraining's binary_logloss: 0.502828\n",
      "[423]\ttraining's binary_logloss: 0.502664\n",
      "[424]\ttraining's binary_logloss: 0.502509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[425]\ttraining's binary_logloss: 0.502351\n",
      "[426]\ttraining's binary_logloss: 0.502165\n",
      "[427]\ttraining's binary_logloss: 0.50198\n",
      "[428]\ttraining's binary_logloss: 0.501786\n",
      "[429]\ttraining's binary_logloss: 0.50161\n",
      "[430]\ttraining's binary_logloss: 0.501419\n",
      "[431]\ttraining's binary_logloss: 0.501218\n",
      "[432]\ttraining's binary_logloss: 0.50102\n",
      "[433]\ttraining's binary_logloss: 0.50082\n",
      "[434]\ttraining's binary_logloss: 0.500655\n",
      "[435]\ttraining's binary_logloss: 0.500453\n",
      "[436]\ttraining's binary_logloss: 0.500285\n",
      "[437]\ttraining's binary_logloss: 0.50007\n",
      "[438]\ttraining's binary_logloss: 0.499876\n",
      "[439]\ttraining's binary_logloss: 0.499689\n",
      "[440]\ttraining's binary_logloss: 0.499533\n",
      "[441]\ttraining's binary_logloss: 0.499313\n",
      "[442]\ttraining's binary_logloss: 0.499125\n",
      "[443]\ttraining's binary_logloss: 0.498932\n",
      "[444]\ttraining's binary_logloss: 0.498732\n",
      "[445]\ttraining's binary_logloss: 0.498504\n",
      "[446]\ttraining's binary_logloss: 0.498305\n",
      "[447]\ttraining's binary_logloss: 0.498145\n",
      "[448]\ttraining's binary_logloss: 0.497952\n",
      "[449]\ttraining's binary_logloss: 0.497757\n",
      "[450]\ttraining's binary_logloss: 0.4976\n",
      "[451]\ttraining's binary_logloss: 0.497448\n",
      "[452]\ttraining's binary_logloss: 0.497314\n",
      "[453]\ttraining's binary_logloss: 0.497148\n",
      "[454]\ttraining's binary_logloss: 0.497013\n",
      "[455]\ttraining's binary_logloss: 0.496871\n",
      "[456]\ttraining's binary_logloss: 0.496625\n",
      "[457]\ttraining's binary_logloss: 0.49642\n",
      "[458]\ttraining's binary_logloss: 0.496188\n",
      "[459]\ttraining's binary_logloss: 0.495973\n",
      "[460]\ttraining's binary_logloss: 0.495745\n",
      "[461]\ttraining's binary_logloss: 0.495571\n",
      "[462]\ttraining's binary_logloss: 0.495396\n",
      "[463]\ttraining's binary_logloss: 0.495243\n",
      "[464]\ttraining's binary_logloss: 0.49507\n",
      "[465]\ttraining's binary_logloss: 0.494913\n",
      "[466]\ttraining's binary_logloss: 0.49469\n",
      "[467]\ttraining's binary_logloss: 0.49447\n",
      "[468]\ttraining's binary_logloss: 0.494256\n",
      "[469]\ttraining's binary_logloss: 0.494062\n",
      "[470]\ttraining's binary_logloss: 0.493834\n",
      "[471]\ttraining's binary_logloss: 0.493672\n",
      "[472]\ttraining's binary_logloss: 0.493524\n",
      "[473]\ttraining's binary_logloss: 0.493365\n",
      "[474]\ttraining's binary_logloss: 0.493205\n",
      "[475]\ttraining's binary_logloss: 0.493035\n",
      "[476]\ttraining's binary_logloss: 0.492835\n",
      "[477]\ttraining's binary_logloss: 0.492635\n",
      "[478]\ttraining's binary_logloss: 0.492447\n",
      "[479]\ttraining's binary_logloss: 0.492262\n",
      "[480]\ttraining's binary_logloss: 0.492094\n",
      "[481]\ttraining's binary_logloss: 0.491907\n",
      "[482]\ttraining's binary_logloss: 0.491721\n",
      "[483]\ttraining's binary_logloss: 0.491563\n",
      "[484]\ttraining's binary_logloss: 0.491396\n",
      "[485]\ttraining's binary_logloss: 0.491231\n",
      "[486]\ttraining's binary_logloss: 0.491024\n",
      "[487]\ttraining's binary_logloss: 0.490828\n",
      "[488]\ttraining's binary_logloss: 0.490655\n",
      "[489]\ttraining's binary_logloss: 0.490463\n",
      "[490]\ttraining's binary_logloss: 0.490282\n",
      "[491]\ttraining's binary_logloss: 0.490066\n",
      "[492]\ttraining's binary_logloss: 0.489813\n",
      "[493]\ttraining's binary_logloss: 0.489566\n",
      "[494]\ttraining's binary_logloss: 0.489353\n",
      "[495]\ttraining's binary_logloss: 0.48914\n",
      "[496]\ttraining's binary_logloss: 0.488915\n",
      "[497]\ttraining's binary_logloss: 0.48871\n",
      "[498]\ttraining's binary_logloss: 0.488508\n",
      "[499]\ttraining's binary_logloss: 0.48829\n",
      "[500]\ttraining's binary_logloss: 0.488084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613308\n",
      "[2]\ttraining's binary_logloss: 0.611821\n",
      "[3]\ttraining's binary_logloss: 0.610341\n",
      "[4]\ttraining's binary_logloss: 0.60889\n",
      "[5]\ttraining's binary_logloss: 0.607451\n",
      "[6]\ttraining's binary_logloss: 0.606187\n",
      "[7]\ttraining's binary_logloss: 0.604958\n",
      "[8]\ttraining's binary_logloss: 0.603702\n",
      "[9]\ttraining's binary_logloss: 0.602536\n",
      "[10]\ttraining's binary_logloss: 0.601376\n",
      "[11]\ttraining's binary_logloss: 0.600229\n",
      "[12]\ttraining's binary_logloss: 0.599211\n",
      "[13]\ttraining's binary_logloss: 0.59819\n",
      "[14]\ttraining's binary_logloss: 0.597214\n",
      "[15]\ttraining's binary_logloss: 0.596145\n",
      "[16]\ttraining's binary_logloss: 0.595145\n",
      "[17]\ttraining's binary_logloss: 0.594183\n",
      "[18]\ttraining's binary_logloss: 0.593223\n",
      "[19]\ttraining's binary_logloss: 0.592316\n",
      "[20]\ttraining's binary_logloss: 0.591424\n",
      "[21]\ttraining's binary_logloss: 0.59053\n",
      "[22]\ttraining's binary_logloss: 0.589673\n",
      "[23]\ttraining's binary_logloss: 0.588811\n",
      "[24]\ttraining's binary_logloss: 0.587987\n",
      "[25]\ttraining's binary_logloss: 0.587191\n",
      "[26]\ttraining's binary_logloss: 0.586451\n",
      "[27]\ttraining's binary_logloss: 0.58566\n",
      "[28]\ttraining's binary_logloss: 0.584955\n",
      "[29]\ttraining's binary_logloss: 0.584189\n",
      "[30]\ttraining's binary_logloss: 0.58348\n",
      "[31]\ttraining's binary_logloss: 0.58283\n",
      "[32]\ttraining's binary_logloss: 0.582141\n",
      "[33]\ttraining's binary_logloss: 0.581557\n",
      "[34]\ttraining's binary_logloss: 0.580902\n",
      "[35]\ttraining's binary_logloss: 0.580334\n",
      "[36]\ttraining's binary_logloss: 0.579788\n",
      "[37]\ttraining's binary_logloss: 0.579185\n",
      "[38]\ttraining's binary_logloss: 0.578615\n",
      "[39]\ttraining's binary_logloss: 0.578061\n",
      "[40]\ttraining's binary_logloss: 0.577531\n",
      "[41]\ttraining's binary_logloss: 0.577011\n",
      "[42]\ttraining's binary_logloss: 0.576463\n",
      "[43]\ttraining's binary_logloss: 0.576004\n",
      "[44]\ttraining's binary_logloss: 0.575531\n",
      "[45]\ttraining's binary_logloss: 0.575079\n",
      "[46]\ttraining's binary_logloss: 0.574599\n",
      "[47]\ttraining's binary_logloss: 0.574187\n",
      "[48]\ttraining's binary_logloss: 0.573694\n",
      "[49]\ttraining's binary_logloss: 0.573242\n",
      "[50]\ttraining's binary_logloss: 0.572808\n",
      "[51]\ttraining's binary_logloss: 0.572393\n",
      "[52]\ttraining's binary_logloss: 0.571954\n",
      "[53]\ttraining's binary_logloss: 0.5716\n",
      "[54]\ttraining's binary_logloss: 0.571197\n",
      "[55]\ttraining's binary_logloss: 0.570839\n",
      "[56]\ttraining's binary_logloss: 0.570479\n",
      "[57]\ttraining's binary_logloss: 0.570168\n",
      "[58]\ttraining's binary_logloss: 0.569844\n",
      "[59]\ttraining's binary_logloss: 0.569523\n",
      "[60]\ttraining's binary_logloss: 0.569155\n",
      "[61]\ttraining's binary_logloss: 0.568823\n",
      "[62]\ttraining's binary_logloss: 0.568525\n",
      "[63]\ttraining's binary_logloss: 0.568134\n",
      "[64]\ttraining's binary_logloss: 0.567749\n",
      "[65]\ttraining's binary_logloss: 0.56739\n",
      "[66]\ttraining's binary_logloss: 0.567029\n",
      "[67]\ttraining's binary_logloss: 0.566674\n",
      "[68]\ttraining's binary_logloss: 0.566318\n",
      "[69]\ttraining's binary_logloss: 0.565974\n",
      "[70]\ttraining's binary_logloss: 0.56565\n",
      "[71]\ttraining's binary_logloss: 0.565296\n",
      "[72]\ttraining's binary_logloss: 0.564948\n",
      "[73]\ttraining's binary_logloss: 0.564673\n",
      "[74]\ttraining's binary_logloss: 0.56438\n",
      "[75]\ttraining's binary_logloss: 0.564074\n",
      "[76]\ttraining's binary_logloss: 0.563831\n",
      "[77]\ttraining's binary_logloss: 0.563574\n",
      "[78]\ttraining's binary_logloss: 0.563331\n",
      "[79]\ttraining's binary_logloss: 0.563102\n",
      "[80]\ttraining's binary_logloss: 0.562919\n",
      "[81]\ttraining's binary_logloss: 0.562671\n",
      "[82]\ttraining's binary_logloss: 0.562434\n",
      "[83]\ttraining's binary_logloss: 0.562201\n",
      "[84]\ttraining's binary_logloss: 0.561963\n",
      "[85]\ttraining's binary_logloss: 0.561752\n",
      "[86]\ttraining's binary_logloss: 0.561543\n",
      "[87]\ttraining's binary_logloss: 0.561324\n",
      "[88]\ttraining's binary_logloss: 0.561134\n",
      "[89]\ttraining's binary_logloss: 0.560944\n",
      "[90]\ttraining's binary_logloss: 0.560756\n",
      "[91]\ttraining's binary_logloss: 0.560541\n",
      "[92]\ttraining's binary_logloss: 0.560374\n",
      "[93]\ttraining's binary_logloss: 0.560133\n",
      "[94]\ttraining's binary_logloss: 0.559888\n",
      "[95]\ttraining's binary_logloss: 0.559721\n",
      "[96]\ttraining's binary_logloss: 0.559546\n",
      "[97]\ttraining's binary_logloss: 0.559385\n",
      "[98]\ttraining's binary_logloss: 0.559212\n",
      "[99]\ttraining's binary_logloss: 0.559063\n",
      "[100]\ttraining's binary_logloss: 0.558882\n",
      "[101]\ttraining's binary_logloss: 0.558681\n",
      "[102]\ttraining's binary_logloss: 0.558493\n",
      "[103]\ttraining's binary_logloss: 0.558288\n",
      "[104]\ttraining's binary_logloss: 0.558102\n",
      "[105]\ttraining's binary_logloss: 0.557929\n",
      "[106]\ttraining's binary_logloss: 0.557751\n",
      "[107]\ttraining's binary_logloss: 0.557547\n",
      "[108]\ttraining's binary_logloss: 0.55736\n",
      "[109]\ttraining's binary_logloss: 0.557218\n",
      "[110]\ttraining's binary_logloss: 0.557041\n",
      "[111]\ttraining's binary_logloss: 0.556872\n",
      "[112]\ttraining's binary_logloss: 0.556697\n",
      "[113]\ttraining's binary_logloss: 0.556525\n",
      "[114]\ttraining's binary_logloss: 0.556367\n",
      "[115]\ttraining's binary_logloss: 0.556195\n",
      "[116]\ttraining's binary_logloss: 0.556033\n",
      "[117]\ttraining's binary_logloss: 0.555864\n",
      "[118]\ttraining's binary_logloss: 0.555678\n",
      "[119]\ttraining's binary_logloss: 0.555505\n",
      "[120]\ttraining's binary_logloss: 0.555373\n",
      "[121]\ttraining's binary_logloss: 0.555216\n",
      "[122]\ttraining's binary_logloss: 0.555065\n",
      "[123]\ttraining's binary_logloss: 0.554904\n",
      "[124]\ttraining's binary_logloss: 0.554768\n",
      "[125]\ttraining's binary_logloss: 0.554629\n",
      "[126]\ttraining's binary_logloss: 0.554481\n",
      "[127]\ttraining's binary_logloss: 0.554322\n",
      "[128]\ttraining's binary_logloss: 0.554184\n",
      "[129]\ttraining's binary_logloss: 0.553989\n",
      "[130]\ttraining's binary_logloss: 0.553841\n",
      "[131]\ttraining's binary_logloss: 0.553717\n",
      "[132]\ttraining's binary_logloss: 0.553585\n",
      "[133]\ttraining's binary_logloss: 0.55346\n",
      "[134]\ttraining's binary_logloss: 0.553327\n",
      "[135]\ttraining's binary_logloss: 0.553222\n",
      "[136]\ttraining's binary_logloss: 0.55307\n",
      "[137]\ttraining's binary_logloss: 0.552905\n",
      "[138]\ttraining's binary_logloss: 0.552762\n",
      "[139]\ttraining's binary_logloss: 0.552601\n",
      "[140]\ttraining's binary_logloss: 0.552422\n",
      "[141]\ttraining's binary_logloss: 0.552268\n",
      "[142]\ttraining's binary_logloss: 0.552109\n",
      "[143]\ttraining's binary_logloss: 0.551955\n",
      "[144]\ttraining's binary_logloss: 0.551806\n",
      "[145]\ttraining's binary_logloss: 0.551606\n",
      "[146]\ttraining's binary_logloss: 0.551398\n",
      "[147]\ttraining's binary_logloss: 0.551269\n",
      "[148]\ttraining's binary_logloss: 0.551059\n",
      "[149]\ttraining's binary_logloss: 0.550844\n",
      "[150]\ttraining's binary_logloss: 0.550714\n",
      "[151]\ttraining's binary_logloss: 0.550558\n",
      "[152]\ttraining's binary_logloss: 0.550405\n",
      "[153]\ttraining's binary_logloss: 0.550258\n",
      "[154]\ttraining's binary_logloss: 0.55009\n",
      "[155]\ttraining's binary_logloss: 0.549942\n",
      "[156]\ttraining's binary_logloss: 0.549797\n",
      "[157]\ttraining's binary_logloss: 0.549622\n",
      "[158]\ttraining's binary_logloss: 0.549452\n",
      "[159]\ttraining's binary_logloss: 0.549286\n",
      "[160]\ttraining's binary_logloss: 0.549129\n",
      "[161]\ttraining's binary_logloss: 0.549012\n",
      "[162]\ttraining's binary_logloss: 0.548888\n",
      "[163]\ttraining's binary_logloss: 0.548756\n",
      "[164]\ttraining's binary_logloss: 0.548616\n",
      "[165]\ttraining's binary_logloss: 0.548451\n",
      "[166]\ttraining's binary_logloss: 0.548264\n",
      "[167]\ttraining's binary_logloss: 0.548067\n",
      "[168]\ttraining's binary_logloss: 0.547946\n",
      "[169]\ttraining's binary_logloss: 0.547772\n",
      "[170]\ttraining's binary_logloss: 0.547627\n",
      "[171]\ttraining's binary_logloss: 0.547477\n",
      "[172]\ttraining's binary_logloss: 0.547339\n",
      "[173]\ttraining's binary_logloss: 0.547176\n",
      "[174]\ttraining's binary_logloss: 0.547032\n",
      "[175]\ttraining's binary_logloss: 0.546899\n",
      "[176]\ttraining's binary_logloss: 0.546754\n",
      "[177]\ttraining's binary_logloss: 0.546607\n",
      "[178]\ttraining's binary_logloss: 0.546459\n",
      "[179]\ttraining's binary_logloss: 0.546305\n",
      "[180]\ttraining's binary_logloss: 0.546156\n",
      "[181]\ttraining's binary_logloss: 0.546034\n",
      "[182]\ttraining's binary_logloss: 0.545902\n",
      "[183]\ttraining's binary_logloss: 0.545753\n",
      "[184]\ttraining's binary_logloss: 0.545634\n",
      "[185]\ttraining's binary_logloss: 0.545499\n",
      "[186]\ttraining's binary_logloss: 0.545404\n",
      "[187]\ttraining's binary_logloss: 0.545281\n",
      "[188]\ttraining's binary_logloss: 0.545164\n",
      "[189]\ttraining's binary_logloss: 0.545067\n",
      "[190]\ttraining's binary_logloss: 0.544965\n",
      "[191]\ttraining's binary_logloss: 0.544838\n",
      "[192]\ttraining's binary_logloss: 0.544705\n",
      "[193]\ttraining's binary_logloss: 0.544574\n",
      "[194]\ttraining's binary_logloss: 0.544432\n",
      "[195]\ttraining's binary_logloss: 0.544281\n",
      "[196]\ttraining's binary_logloss: 0.544096\n",
      "[197]\ttraining's binary_logloss: 0.543921\n",
      "[198]\ttraining's binary_logloss: 0.543739\n",
      "[199]\ttraining's binary_logloss: 0.54355\n",
      "[200]\ttraining's binary_logloss: 0.543357\n",
      "[201]\ttraining's binary_logloss: 0.543187\n",
      "[202]\ttraining's binary_logloss: 0.543007\n",
      "[203]\ttraining's binary_logloss: 0.542821\n",
      "[204]\ttraining's binary_logloss: 0.542659\n",
      "[205]\ttraining's binary_logloss: 0.542499\n",
      "[206]\ttraining's binary_logloss: 0.542352\n",
      "[207]\ttraining's binary_logloss: 0.542246\n",
      "[208]\ttraining's binary_logloss: 0.542106\n",
      "[209]\ttraining's binary_logloss: 0.541972\n",
      "[210]\ttraining's binary_logloss: 0.541783\n",
      "[211]\ttraining's binary_logloss: 0.541616\n",
      "[212]\ttraining's binary_logloss: 0.541455\n",
      "[213]\ttraining's binary_logloss: 0.541283\n",
      "[214]\ttraining's binary_logloss: 0.541104\n",
      "[215]\ttraining's binary_logloss: 0.540939\n",
      "[216]\ttraining's binary_logloss: 0.54074\n",
      "[217]\ttraining's binary_logloss: 0.540522\n",
      "[218]\ttraining's binary_logloss: 0.540338\n",
      "[219]\ttraining's binary_logloss: 0.540145\n",
      "[220]\ttraining's binary_logloss: 0.539964\n",
      "[221]\ttraining's binary_logloss: 0.539745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[222]\ttraining's binary_logloss: 0.539579\n",
      "[223]\ttraining's binary_logloss: 0.539379\n",
      "[224]\ttraining's binary_logloss: 0.539224\n",
      "[225]\ttraining's binary_logloss: 0.539008\n",
      "[226]\ttraining's binary_logloss: 0.538844\n",
      "[227]\ttraining's binary_logloss: 0.538672\n",
      "[228]\ttraining's binary_logloss: 0.538521\n",
      "[229]\ttraining's binary_logloss: 0.53833\n",
      "[230]\ttraining's binary_logloss: 0.538187\n",
      "[231]\ttraining's binary_logloss: 0.537976\n",
      "[232]\ttraining's binary_logloss: 0.537769\n",
      "[233]\ttraining's binary_logloss: 0.537602\n",
      "[234]\ttraining's binary_logloss: 0.537417\n",
      "[235]\ttraining's binary_logloss: 0.537225\n",
      "[236]\ttraining's binary_logloss: 0.537045\n",
      "[237]\ttraining's binary_logloss: 0.536903\n",
      "[238]\ttraining's binary_logloss: 0.536768\n",
      "[239]\ttraining's binary_logloss: 0.536595\n",
      "[240]\ttraining's binary_logloss: 0.536445\n",
      "[241]\ttraining's binary_logloss: 0.536293\n",
      "[242]\ttraining's binary_logloss: 0.536117\n",
      "[243]\ttraining's binary_logloss: 0.535946\n",
      "[244]\ttraining's binary_logloss: 0.535761\n",
      "[245]\ttraining's binary_logloss: 0.535601\n",
      "[246]\ttraining's binary_logloss: 0.535417\n",
      "[247]\ttraining's binary_logloss: 0.535228\n",
      "[248]\ttraining's binary_logloss: 0.535049\n",
      "[249]\ttraining's binary_logloss: 0.53485\n",
      "[250]\ttraining's binary_logloss: 0.534682\n",
      "[251]\ttraining's binary_logloss: 0.534497\n",
      "[252]\ttraining's binary_logloss: 0.534322\n",
      "[253]\ttraining's binary_logloss: 0.534178\n",
      "[254]\ttraining's binary_logloss: 0.534002\n",
      "[255]\ttraining's binary_logloss: 0.533837\n",
      "[256]\ttraining's binary_logloss: 0.533653\n",
      "[257]\ttraining's binary_logloss: 0.533452\n",
      "[258]\ttraining's binary_logloss: 0.533271\n",
      "[259]\ttraining's binary_logloss: 0.533112\n",
      "[260]\ttraining's binary_logloss: 0.532955\n",
      "[261]\ttraining's binary_logloss: 0.532743\n",
      "[262]\ttraining's binary_logloss: 0.532512\n",
      "[263]\ttraining's binary_logloss: 0.532304\n",
      "[264]\ttraining's binary_logloss: 0.532107\n",
      "[265]\ttraining's binary_logloss: 0.531887\n",
      "[266]\ttraining's binary_logloss: 0.531757\n",
      "[267]\ttraining's binary_logloss: 0.531633\n",
      "[268]\ttraining's binary_logloss: 0.531495\n",
      "[269]\ttraining's binary_logloss: 0.531315\n",
      "[270]\ttraining's binary_logloss: 0.531189\n",
      "[271]\ttraining's binary_logloss: 0.531021\n",
      "[272]\ttraining's binary_logloss: 0.530843\n",
      "[273]\ttraining's binary_logloss: 0.530664\n",
      "[274]\ttraining's binary_logloss: 0.530491\n",
      "[275]\ttraining's binary_logloss: 0.530325\n",
      "[276]\ttraining's binary_logloss: 0.530118\n",
      "[277]\ttraining's binary_logloss: 0.52996\n",
      "[278]\ttraining's binary_logloss: 0.529781\n",
      "[279]\ttraining's binary_logloss: 0.529619\n",
      "[280]\ttraining's binary_logloss: 0.529429\n",
      "[281]\ttraining's binary_logloss: 0.529252\n",
      "[282]\ttraining's binary_logloss: 0.529071\n",
      "[283]\ttraining's binary_logloss: 0.528902\n",
      "[284]\ttraining's binary_logloss: 0.528724\n",
      "[285]\ttraining's binary_logloss: 0.528576\n",
      "[286]\ttraining's binary_logloss: 0.528318\n",
      "[287]\ttraining's binary_logloss: 0.528074\n",
      "[288]\ttraining's binary_logloss: 0.527867\n",
      "[289]\ttraining's binary_logloss: 0.527634\n",
      "[290]\ttraining's binary_logloss: 0.527417\n",
      "[291]\ttraining's binary_logloss: 0.527225\n",
      "[292]\ttraining's binary_logloss: 0.527044\n",
      "[293]\ttraining's binary_logloss: 0.526858\n",
      "[294]\ttraining's binary_logloss: 0.526693\n",
      "[295]\ttraining's binary_logloss: 0.526524\n",
      "[296]\ttraining's binary_logloss: 0.526289\n",
      "[297]\ttraining's binary_logloss: 0.526071\n",
      "[298]\ttraining's binary_logloss: 0.525856\n",
      "[299]\ttraining's binary_logloss: 0.525628\n",
      "[300]\ttraining's binary_logloss: 0.525417\n",
      "[301]\ttraining's binary_logloss: 0.525197\n",
      "[302]\ttraining's binary_logloss: 0.524959\n",
      "[303]\ttraining's binary_logloss: 0.524735\n",
      "[304]\ttraining's binary_logloss: 0.524551\n",
      "[305]\ttraining's binary_logloss: 0.524345\n",
      "[306]\ttraining's binary_logloss: 0.5241\n",
      "[307]\ttraining's binary_logloss: 0.523871\n",
      "[308]\ttraining's binary_logloss: 0.523635\n",
      "[309]\ttraining's binary_logloss: 0.523388\n",
      "[310]\ttraining's binary_logloss: 0.523151\n",
      "[311]\ttraining's binary_logloss: 0.522956\n",
      "[312]\ttraining's binary_logloss: 0.522761\n",
      "[313]\ttraining's binary_logloss: 0.522592\n",
      "[314]\ttraining's binary_logloss: 0.522409\n",
      "[315]\ttraining's binary_logloss: 0.522249\n",
      "[316]\ttraining's binary_logloss: 0.522027\n",
      "[317]\ttraining's binary_logloss: 0.521864\n",
      "[318]\ttraining's binary_logloss: 0.521658\n",
      "[319]\ttraining's binary_logloss: 0.521483\n",
      "[320]\ttraining's binary_logloss: 0.521286\n",
      "[321]\ttraining's binary_logloss: 0.521147\n",
      "[322]\ttraining's binary_logloss: 0.521011\n",
      "[323]\ttraining's binary_logloss: 0.520869\n",
      "[324]\ttraining's binary_logloss: 0.520727\n",
      "[325]\ttraining's binary_logloss: 0.520574\n",
      "[326]\ttraining's binary_logloss: 0.520406\n",
      "[327]\ttraining's binary_logloss: 0.520216\n",
      "[328]\ttraining's binary_logloss: 0.520055\n",
      "[329]\ttraining's binary_logloss: 0.519911\n",
      "[330]\ttraining's binary_logloss: 0.519733\n",
      "[331]\ttraining's binary_logloss: 0.519517\n",
      "[332]\ttraining's binary_logloss: 0.519283\n",
      "[333]\ttraining's binary_logloss: 0.519077\n",
      "[334]\ttraining's binary_logloss: 0.518884\n",
      "[335]\ttraining's binary_logloss: 0.518674\n",
      "[336]\ttraining's binary_logloss: 0.518462\n",
      "[337]\ttraining's binary_logloss: 0.518247\n",
      "[338]\ttraining's binary_logloss: 0.518037\n",
      "[339]\ttraining's binary_logloss: 0.517809\n",
      "[340]\ttraining's binary_logloss: 0.517593\n",
      "[341]\ttraining's binary_logloss: 0.517357\n",
      "[342]\ttraining's binary_logloss: 0.51714\n",
      "[343]\ttraining's binary_logloss: 0.516918\n",
      "[344]\ttraining's binary_logloss: 0.516696\n",
      "[345]\ttraining's binary_logloss: 0.516466\n",
      "[346]\ttraining's binary_logloss: 0.51631\n",
      "[347]\ttraining's binary_logloss: 0.51615\n",
      "[348]\ttraining's binary_logloss: 0.515993\n",
      "[349]\ttraining's binary_logloss: 0.515867\n",
      "[350]\ttraining's binary_logloss: 0.515701\n",
      "[351]\ttraining's binary_logloss: 0.515477\n",
      "[352]\ttraining's binary_logloss: 0.515266\n",
      "[353]\ttraining's binary_logloss: 0.515035\n",
      "[354]\ttraining's binary_logloss: 0.514828\n",
      "[355]\ttraining's binary_logloss: 0.51461\n",
      "[356]\ttraining's binary_logloss: 0.514422\n",
      "[357]\ttraining's binary_logloss: 0.514239\n",
      "[358]\ttraining's binary_logloss: 0.514058\n",
      "[359]\ttraining's binary_logloss: 0.513871\n",
      "[360]\ttraining's binary_logloss: 0.513698\n",
      "[361]\ttraining's binary_logloss: 0.513509\n",
      "[362]\ttraining's binary_logloss: 0.513316\n",
      "[363]\ttraining's binary_logloss: 0.513139\n",
      "[364]\ttraining's binary_logloss: 0.512984\n",
      "[365]\ttraining's binary_logloss: 0.51281\n",
      "[366]\ttraining's binary_logloss: 0.51266\n",
      "[367]\ttraining's binary_logloss: 0.512495\n",
      "[368]\ttraining's binary_logloss: 0.512353\n",
      "[369]\ttraining's binary_logloss: 0.512169\n",
      "[370]\ttraining's binary_logloss: 0.512041\n",
      "[371]\ttraining's binary_logloss: 0.511813\n",
      "[372]\ttraining's binary_logloss: 0.511629\n",
      "[373]\ttraining's binary_logloss: 0.511432\n",
      "[374]\ttraining's binary_logloss: 0.511224\n",
      "[375]\ttraining's binary_logloss: 0.51104\n",
      "[376]\ttraining's binary_logloss: 0.510808\n",
      "[377]\ttraining's binary_logloss: 0.510582\n",
      "[378]\ttraining's binary_logloss: 0.510349\n",
      "[379]\ttraining's binary_logloss: 0.510169\n",
      "[380]\ttraining's binary_logloss: 0.510011\n",
      "[381]\ttraining's binary_logloss: 0.509815\n",
      "[382]\ttraining's binary_logloss: 0.509636\n",
      "[383]\ttraining's binary_logloss: 0.509437\n",
      "[384]\ttraining's binary_logloss: 0.509248\n",
      "[385]\ttraining's binary_logloss: 0.509057\n",
      "[386]\ttraining's binary_logloss: 0.50888\n",
      "[387]\ttraining's binary_logloss: 0.508682\n",
      "[388]\ttraining's binary_logloss: 0.508503\n",
      "[389]\ttraining's binary_logloss: 0.50832\n",
      "[390]\ttraining's binary_logloss: 0.508147\n",
      "[391]\ttraining's binary_logloss: 0.507908\n",
      "[392]\ttraining's binary_logloss: 0.507656\n",
      "[393]\ttraining's binary_logloss: 0.507422\n",
      "[394]\ttraining's binary_logloss: 0.507213\n",
      "[395]\ttraining's binary_logloss: 0.506967\n",
      "[396]\ttraining's binary_logloss: 0.506735\n",
      "[397]\ttraining's binary_logloss: 0.506503\n",
      "[398]\ttraining's binary_logloss: 0.506268\n",
      "[399]\ttraining's binary_logloss: 0.506035\n",
      "[400]\ttraining's binary_logloss: 0.505804\n",
      "[401]\ttraining's binary_logloss: 0.505619\n",
      "[402]\ttraining's binary_logloss: 0.505398\n",
      "[403]\ttraining's binary_logloss: 0.50519\n",
      "[404]\ttraining's binary_logloss: 0.504994\n",
      "[405]\ttraining's binary_logloss: 0.504815\n",
      "[406]\ttraining's binary_logloss: 0.504598\n",
      "[407]\ttraining's binary_logloss: 0.504426\n",
      "[408]\ttraining's binary_logloss: 0.50426\n",
      "[409]\ttraining's binary_logloss: 0.504069\n",
      "[410]\ttraining's binary_logloss: 0.503892\n",
      "[411]\ttraining's binary_logloss: 0.503683\n",
      "[412]\ttraining's binary_logloss: 0.503498\n",
      "[413]\ttraining's binary_logloss: 0.503337\n",
      "[414]\ttraining's binary_logloss: 0.503174\n",
      "[415]\ttraining's binary_logloss: 0.503005\n",
      "[416]\ttraining's binary_logloss: 0.502804\n",
      "[417]\ttraining's binary_logloss: 0.502613\n",
      "[418]\ttraining's binary_logloss: 0.502411\n",
      "[419]\ttraining's binary_logloss: 0.502232\n",
      "[420]\ttraining's binary_logloss: 0.502022\n",
      "[421]\ttraining's binary_logloss: 0.501855\n",
      "[422]\ttraining's binary_logloss: 0.501685\n",
      "[423]\ttraining's binary_logloss: 0.501526\n",
      "[424]\ttraining's binary_logloss: 0.501398\n",
      "[425]\ttraining's binary_logloss: 0.501215\n",
      "[426]\ttraining's binary_logloss: 0.500997\n",
      "[427]\ttraining's binary_logloss: 0.500769\n",
      "[428]\ttraining's binary_logloss: 0.500544\n",
      "[429]\ttraining's binary_logloss: 0.500303\n",
      "[430]\ttraining's binary_logloss: 0.500083\n",
      "[431]\ttraining's binary_logloss: 0.499938\n",
      "[432]\ttraining's binary_logloss: 0.499772\n",
      "[433]\ttraining's binary_logloss: 0.499628\n",
      "[434]\ttraining's binary_logloss: 0.499456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[435]\ttraining's binary_logloss: 0.499306\n",
      "[436]\ttraining's binary_logloss: 0.499089\n",
      "[437]\ttraining's binary_logloss: 0.498862\n",
      "[438]\ttraining's binary_logloss: 0.498679\n",
      "[439]\ttraining's binary_logloss: 0.498467\n",
      "[440]\ttraining's binary_logloss: 0.498296\n",
      "[441]\ttraining's binary_logloss: 0.498092\n",
      "[442]\ttraining's binary_logloss: 0.497906\n",
      "[443]\ttraining's binary_logloss: 0.497689\n",
      "[444]\ttraining's binary_logloss: 0.497476\n",
      "[445]\ttraining's binary_logloss: 0.49729\n",
      "[446]\ttraining's binary_logloss: 0.497125\n",
      "[447]\ttraining's binary_logloss: 0.496953\n",
      "[448]\ttraining's binary_logloss: 0.496776\n",
      "[449]\ttraining's binary_logloss: 0.496605\n",
      "[450]\ttraining's binary_logloss: 0.496453\n",
      "[451]\ttraining's binary_logloss: 0.496332\n",
      "[452]\ttraining's binary_logloss: 0.496179\n",
      "[453]\ttraining's binary_logloss: 0.496039\n",
      "[454]\ttraining's binary_logloss: 0.495878\n",
      "[455]\ttraining's binary_logloss: 0.495676\n",
      "[456]\ttraining's binary_logloss: 0.495489\n",
      "[457]\ttraining's binary_logloss: 0.495333\n",
      "[458]\ttraining's binary_logloss: 0.495153\n",
      "[459]\ttraining's binary_logloss: 0.494976\n",
      "[460]\ttraining's binary_logloss: 0.494818\n",
      "[461]\ttraining's binary_logloss: 0.494593\n",
      "[462]\ttraining's binary_logloss: 0.494381\n",
      "[463]\ttraining's binary_logloss: 0.494175\n",
      "[464]\ttraining's binary_logloss: 0.493972\n",
      "[465]\ttraining's binary_logloss: 0.49378\n",
      "[466]\ttraining's binary_logloss: 0.493525\n",
      "[467]\ttraining's binary_logloss: 0.493283\n",
      "[468]\ttraining's binary_logloss: 0.493053\n",
      "[469]\ttraining's binary_logloss: 0.492829\n",
      "[470]\ttraining's binary_logloss: 0.492593\n",
      "[471]\ttraining's binary_logloss: 0.492355\n",
      "[472]\ttraining's binary_logloss: 0.492125\n",
      "[473]\ttraining's binary_logloss: 0.491896\n",
      "[474]\ttraining's binary_logloss: 0.491663\n",
      "[475]\ttraining's binary_logloss: 0.491477\n",
      "[476]\ttraining's binary_logloss: 0.491303\n",
      "[477]\ttraining's binary_logloss: 0.491132\n",
      "[478]\ttraining's binary_logloss: 0.490968\n",
      "[479]\ttraining's binary_logloss: 0.490802\n",
      "[480]\ttraining's binary_logloss: 0.490647\n",
      "[481]\ttraining's binary_logloss: 0.490505\n",
      "[482]\ttraining's binary_logloss: 0.490369\n",
      "[483]\ttraining's binary_logloss: 0.490182\n",
      "[484]\ttraining's binary_logloss: 0.489993\n",
      "[485]\ttraining's binary_logloss: 0.489807\n",
      "[486]\ttraining's binary_logloss: 0.489645\n",
      "[487]\ttraining's binary_logloss: 0.489475\n",
      "[488]\ttraining's binary_logloss: 0.489323\n",
      "[489]\ttraining's binary_logloss: 0.489173\n",
      "[490]\ttraining's binary_logloss: 0.489011\n",
      "[491]\ttraining's binary_logloss: 0.488836\n",
      "[492]\ttraining's binary_logloss: 0.488663\n",
      "[493]\ttraining's binary_logloss: 0.488504\n",
      "[494]\ttraining's binary_logloss: 0.488345\n",
      "[495]\ttraining's binary_logloss: 0.488167\n",
      "[496]\ttraining's binary_logloss: 0.487948\n",
      "[497]\ttraining's binary_logloss: 0.487738\n",
      "[498]\ttraining's binary_logloss: 0.487519\n",
      "[499]\ttraining's binary_logloss: 0.487306\n",
      "[500]\ttraining's binary_logloss: 0.487103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613955\n",
      "[2]\ttraining's binary_logloss: 0.612409\n",
      "[3]\ttraining's binary_logloss: 0.610912\n",
      "[4]\ttraining's binary_logloss: 0.609429\n",
      "[5]\ttraining's binary_logloss: 0.608045\n",
      "[6]\ttraining's binary_logloss: 0.606648\n",
      "[7]\ttraining's binary_logloss: 0.605214\n",
      "[8]\ttraining's binary_logloss: 0.603823\n",
      "[9]\ttraining's binary_logloss: 0.60249\n",
      "[10]\ttraining's binary_logloss: 0.601388\n",
      "[11]\ttraining's binary_logloss: 0.600256\n",
      "[12]\ttraining's binary_logloss: 0.599003\n",
      "[13]\ttraining's binary_logloss: 0.597885\n",
      "[14]\ttraining's binary_logloss: 0.596709\n",
      "[15]\ttraining's binary_logloss: 0.595573\n",
      "[16]\ttraining's binary_logloss: 0.594488\n",
      "[17]\ttraining's binary_logloss: 0.59342\n",
      "[18]\ttraining's binary_logloss: 0.592338\n",
      "[19]\ttraining's binary_logloss: 0.591352\n",
      "[20]\ttraining's binary_logloss: 0.590291\n",
      "[21]\ttraining's binary_logloss: 0.589296\n",
      "[22]\ttraining's binary_logloss: 0.588386\n",
      "[23]\ttraining's binary_logloss: 0.587433\n",
      "[24]\ttraining's binary_logloss: 0.586539\n",
      "[25]\ttraining's binary_logloss: 0.58565\n",
      "[26]\ttraining's binary_logloss: 0.584789\n",
      "[27]\ttraining's binary_logloss: 0.583974\n",
      "[28]\ttraining's binary_logloss: 0.583164\n",
      "[29]\ttraining's binary_logloss: 0.582387\n",
      "[30]\ttraining's binary_logloss: 0.581639\n",
      "[31]\ttraining's binary_logloss: 0.580911\n",
      "[32]\ttraining's binary_logloss: 0.580145\n",
      "[33]\ttraining's binary_logloss: 0.579428\n",
      "[34]\ttraining's binary_logloss: 0.578663\n",
      "[35]\ttraining's binary_logloss: 0.577992\n",
      "[36]\ttraining's binary_logloss: 0.577305\n",
      "[37]\ttraining's binary_logloss: 0.576665\n",
      "[38]\ttraining's binary_logloss: 0.575976\n",
      "[39]\ttraining's binary_logloss: 0.575361\n",
      "[40]\ttraining's binary_logloss: 0.574799\n",
      "[41]\ttraining's binary_logloss: 0.574127\n",
      "[42]\ttraining's binary_logloss: 0.573467\n",
      "[43]\ttraining's binary_logloss: 0.572837\n",
      "[44]\ttraining's binary_logloss: 0.572255\n",
      "[45]\ttraining's binary_logloss: 0.571669\n",
      "[46]\ttraining's binary_logloss: 0.571057\n",
      "[47]\ttraining's binary_logloss: 0.570456\n",
      "[48]\ttraining's binary_logloss: 0.56988\n",
      "[49]\ttraining's binary_logloss: 0.56933\n",
      "[50]\ttraining's binary_logloss: 0.568832\n",
      "[51]\ttraining's binary_logloss: 0.568348\n",
      "[52]\ttraining's binary_logloss: 0.567799\n",
      "[53]\ttraining's binary_logloss: 0.567305\n",
      "[54]\ttraining's binary_logloss: 0.566799\n",
      "[55]\ttraining's binary_logloss: 0.566346\n",
      "[56]\ttraining's binary_logloss: 0.565896\n",
      "[57]\ttraining's binary_logloss: 0.565385\n",
      "[58]\ttraining's binary_logloss: 0.564925\n",
      "[59]\ttraining's binary_logloss: 0.564478\n",
      "[60]\ttraining's binary_logloss: 0.564023\n",
      "[61]\ttraining's binary_logloss: 0.563678\n",
      "[62]\ttraining's binary_logloss: 0.563249\n",
      "[63]\ttraining's binary_logloss: 0.562849\n",
      "[64]\ttraining's binary_logloss: 0.562422\n",
      "[65]\ttraining's binary_logloss: 0.562022\n",
      "[66]\ttraining's binary_logloss: 0.561608\n",
      "[67]\ttraining's binary_logloss: 0.561213\n",
      "[68]\ttraining's binary_logloss: 0.560841\n",
      "[69]\ttraining's binary_logloss: 0.56045\n",
      "[70]\ttraining's binary_logloss: 0.560088\n",
      "[71]\ttraining's binary_logloss: 0.559748\n",
      "[72]\ttraining's binary_logloss: 0.559378\n",
      "[73]\ttraining's binary_logloss: 0.559004\n",
      "[74]\ttraining's binary_logloss: 0.558696\n",
      "[75]\ttraining's binary_logloss: 0.558408\n",
      "[76]\ttraining's binary_logloss: 0.558076\n",
      "[77]\ttraining's binary_logloss: 0.557754\n",
      "[78]\ttraining's binary_logloss: 0.557435\n",
      "[79]\ttraining's binary_logloss: 0.557122\n",
      "[80]\ttraining's binary_logloss: 0.556827\n",
      "[81]\ttraining's binary_logloss: 0.556489\n",
      "[82]\ttraining's binary_logloss: 0.556174\n",
      "[83]\ttraining's binary_logloss: 0.555895\n",
      "[84]\ttraining's binary_logloss: 0.555556\n",
      "[85]\ttraining's binary_logloss: 0.55526\n",
      "[86]\ttraining's binary_logloss: 0.554979\n",
      "[87]\ttraining's binary_logloss: 0.554704\n",
      "[88]\ttraining's binary_logloss: 0.554438\n",
      "[89]\ttraining's binary_logloss: 0.554146\n",
      "[90]\ttraining's binary_logloss: 0.553855\n",
      "[91]\ttraining's binary_logloss: 0.553593\n",
      "[92]\ttraining's binary_logloss: 0.553334\n",
      "[93]\ttraining's binary_logloss: 0.553083\n",
      "[94]\ttraining's binary_logloss: 0.552817\n",
      "[95]\ttraining's binary_logloss: 0.55257\n",
      "[96]\ttraining's binary_logloss: 0.552297\n",
      "[97]\ttraining's binary_logloss: 0.552038\n",
      "[98]\ttraining's binary_logloss: 0.551782\n",
      "[99]\ttraining's binary_logloss: 0.551543\n",
      "[100]\ttraining's binary_logloss: 0.551312\n",
      "[101]\ttraining's binary_logloss: 0.551028\n",
      "[102]\ttraining's binary_logloss: 0.550756\n",
      "[103]\ttraining's binary_logloss: 0.550491\n",
      "[104]\ttraining's binary_logloss: 0.550229\n",
      "[105]\ttraining's binary_logloss: 0.549973\n",
      "[106]\ttraining's binary_logloss: 0.549684\n",
      "[107]\ttraining's binary_logloss: 0.549419\n",
      "[108]\ttraining's binary_logloss: 0.54916\n",
      "[109]\ttraining's binary_logloss: 0.548923\n",
      "[110]\ttraining's binary_logloss: 0.548697\n",
      "[111]\ttraining's binary_logloss: 0.548444\n",
      "[112]\ttraining's binary_logloss: 0.548188\n",
      "[113]\ttraining's binary_logloss: 0.54794\n",
      "[114]\ttraining's binary_logloss: 0.547682\n",
      "[115]\ttraining's binary_logloss: 0.547437\n",
      "[116]\ttraining's binary_logloss: 0.547218\n",
      "[117]\ttraining's binary_logloss: 0.546947\n",
      "[118]\ttraining's binary_logloss: 0.546677\n",
      "[119]\ttraining's binary_logloss: 0.546434\n",
      "[120]\ttraining's binary_logloss: 0.546212\n",
      "[121]\ttraining's binary_logloss: 0.546025\n",
      "[122]\ttraining's binary_logloss: 0.545831\n",
      "[123]\ttraining's binary_logloss: 0.545654\n",
      "[124]\ttraining's binary_logloss: 0.545504\n",
      "[125]\ttraining's binary_logloss: 0.545271\n",
      "[126]\ttraining's binary_logloss: 0.545039\n",
      "[127]\ttraining's binary_logloss: 0.544793\n",
      "[128]\ttraining's binary_logloss: 0.544549\n",
      "[129]\ttraining's binary_logloss: 0.54433\n",
      "[130]\ttraining's binary_logloss: 0.5441\n",
      "[131]\ttraining's binary_logloss: 0.543902\n",
      "[132]\ttraining's binary_logloss: 0.543651\n",
      "[133]\ttraining's binary_logloss: 0.543396\n",
      "[134]\ttraining's binary_logloss: 0.543144\n",
      "[135]\ttraining's binary_logloss: 0.542894\n",
      "[136]\ttraining's binary_logloss: 0.542652\n",
      "[137]\ttraining's binary_logloss: 0.542447\n",
      "[138]\ttraining's binary_logloss: 0.542237\n",
      "[139]\ttraining's binary_logloss: 0.541995\n",
      "[140]\ttraining's binary_logloss: 0.541786\n",
      "[141]\ttraining's binary_logloss: 0.541559\n",
      "[142]\ttraining's binary_logloss: 0.541346\n",
      "[143]\ttraining's binary_logloss: 0.541148\n",
      "[144]\ttraining's binary_logloss: 0.540936\n",
      "[145]\ttraining's binary_logloss: 0.540707\n",
      "[146]\ttraining's binary_logloss: 0.540464\n",
      "[147]\ttraining's binary_logloss: 0.540248\n",
      "[148]\ttraining's binary_logloss: 0.540027\n",
      "[149]\ttraining's binary_logloss: 0.539812\n",
      "[150]\ttraining's binary_logloss: 0.539592\n",
      "[151]\ttraining's binary_logloss: 0.539367\n",
      "[152]\ttraining's binary_logloss: 0.539092\n",
      "[153]\ttraining's binary_logloss: 0.538829\n",
      "[154]\ttraining's binary_logloss: 0.538602\n",
      "[155]\ttraining's binary_logloss: 0.53835\n",
      "[156]\ttraining's binary_logloss: 0.538192\n",
      "[157]\ttraining's binary_logloss: 0.537972\n",
      "[158]\ttraining's binary_logloss: 0.537808\n",
      "[159]\ttraining's binary_logloss: 0.537614\n",
      "[160]\ttraining's binary_logloss: 0.537447\n",
      "[161]\ttraining's binary_logloss: 0.537183\n",
      "[162]\ttraining's binary_logloss: 0.536931\n",
      "[163]\ttraining's binary_logloss: 0.536682\n",
      "[164]\ttraining's binary_logloss: 0.536438\n",
      "[165]\ttraining's binary_logloss: 0.536205\n",
      "[166]\ttraining's binary_logloss: 0.535949\n",
      "[167]\ttraining's binary_logloss: 0.535696\n",
      "[168]\ttraining's binary_logloss: 0.535468\n",
      "[169]\ttraining's binary_logloss: 0.535208\n",
      "[170]\ttraining's binary_logloss: 0.534956\n",
      "[171]\ttraining's binary_logloss: 0.534704\n",
      "[172]\ttraining's binary_logloss: 0.534425\n",
      "[173]\ttraining's binary_logloss: 0.534192\n",
      "[174]\ttraining's binary_logloss: 0.533941\n",
      "[175]\ttraining's binary_logloss: 0.533705\n",
      "[176]\ttraining's binary_logloss: 0.53349\n",
      "[177]\ttraining's binary_logloss: 0.533287\n",
      "[178]\ttraining's binary_logloss: 0.53306\n",
      "[179]\ttraining's binary_logloss: 0.532829\n",
      "[180]\ttraining's binary_logloss: 0.532634\n",
      "[181]\ttraining's binary_logloss: 0.532428\n",
      "[182]\ttraining's binary_logloss: 0.532221\n",
      "[183]\ttraining's binary_logloss: 0.531971\n",
      "[184]\ttraining's binary_logloss: 0.531779\n",
      "[185]\ttraining's binary_logloss: 0.53153\n",
      "[186]\ttraining's binary_logloss: 0.531309\n",
      "[187]\ttraining's binary_logloss: 0.531097\n",
      "[188]\ttraining's binary_logloss: 0.530896\n",
      "[189]\ttraining's binary_logloss: 0.530724\n",
      "[190]\ttraining's binary_logloss: 0.53051\n",
      "[191]\ttraining's binary_logloss: 0.530262\n",
      "[192]\ttraining's binary_logloss: 0.530024\n",
      "[193]\ttraining's binary_logloss: 0.529778\n",
      "[194]\ttraining's binary_logloss: 0.529556\n",
      "[195]\ttraining's binary_logloss: 0.529348\n",
      "[196]\ttraining's binary_logloss: 0.5291\n",
      "[197]\ttraining's binary_logloss: 0.528875\n",
      "[198]\ttraining's binary_logloss: 0.528647\n",
      "[199]\ttraining's binary_logloss: 0.52841\n",
      "[200]\ttraining's binary_logloss: 0.528169\n",
      "[201]\ttraining's binary_logloss: 0.527955\n",
      "[202]\ttraining's binary_logloss: 0.527742\n",
      "[203]\ttraining's binary_logloss: 0.527529\n",
      "[204]\ttraining's binary_logloss: 0.527311\n",
      "[205]\ttraining's binary_logloss: 0.52705\n",
      "[206]\ttraining's binary_logloss: 0.526835\n",
      "[207]\ttraining's binary_logloss: 0.52659\n",
      "[208]\ttraining's binary_logloss: 0.526373\n",
      "[209]\ttraining's binary_logloss: 0.526126\n",
      "[210]\ttraining's binary_logloss: 0.525889\n",
      "[211]\ttraining's binary_logloss: 0.525675\n",
      "[212]\ttraining's binary_logloss: 0.52544\n",
      "[213]\ttraining's binary_logloss: 0.525201\n",
      "[214]\ttraining's binary_logloss: 0.524979\n",
      "[215]\ttraining's binary_logloss: 0.524727\n",
      "[216]\ttraining's binary_logloss: 0.524532\n",
      "[217]\ttraining's binary_logloss: 0.524317\n",
      "[218]\ttraining's binary_logloss: 0.524127\n",
      "[219]\ttraining's binary_logloss: 0.523872\n",
      "[220]\ttraining's binary_logloss: 0.52368\n",
      "[221]\ttraining's binary_logloss: 0.523406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[222]\ttraining's binary_logloss: 0.523198\n",
      "[223]\ttraining's binary_logloss: 0.522971\n",
      "[224]\ttraining's binary_logloss: 0.522716\n",
      "[225]\ttraining's binary_logloss: 0.522469\n",
      "[226]\ttraining's binary_logloss: 0.522242\n",
      "[227]\ttraining's binary_logloss: 0.522048\n",
      "[228]\ttraining's binary_logloss: 0.521833\n",
      "[229]\ttraining's binary_logloss: 0.521625\n",
      "[230]\ttraining's binary_logloss: 0.52142\n",
      "[231]\ttraining's binary_logloss: 0.521213\n",
      "[232]\ttraining's binary_logloss: 0.520947\n",
      "[233]\ttraining's binary_logloss: 0.520703\n",
      "[234]\ttraining's binary_logloss: 0.520438\n",
      "[235]\ttraining's binary_logloss: 0.520226\n",
      "[236]\ttraining's binary_logloss: 0.519958\n",
      "[237]\ttraining's binary_logloss: 0.519695\n",
      "[238]\ttraining's binary_logloss: 0.519419\n",
      "[239]\ttraining's binary_logloss: 0.519147\n",
      "[240]\ttraining's binary_logloss: 0.5189\n",
      "[241]\ttraining's binary_logloss: 0.518655\n",
      "[242]\ttraining's binary_logloss: 0.518401\n",
      "[243]\ttraining's binary_logloss: 0.518137\n",
      "[244]\ttraining's binary_logloss: 0.517914\n",
      "[245]\ttraining's binary_logloss: 0.517662\n",
      "[246]\ttraining's binary_logloss: 0.517458\n",
      "[247]\ttraining's binary_logloss: 0.517282\n",
      "[248]\ttraining's binary_logloss: 0.51711\n",
      "[249]\ttraining's binary_logloss: 0.516901\n",
      "[250]\ttraining's binary_logloss: 0.516681\n",
      "[251]\ttraining's binary_logloss: 0.516475\n",
      "[252]\ttraining's binary_logloss: 0.516263\n",
      "[253]\ttraining's binary_logloss: 0.516045\n",
      "[254]\ttraining's binary_logloss: 0.51583\n",
      "[255]\ttraining's binary_logloss: 0.51559\n",
      "[256]\ttraining's binary_logloss: 0.515376\n",
      "[257]\ttraining's binary_logloss: 0.515138\n",
      "[258]\ttraining's binary_logloss: 0.514911\n",
      "[259]\ttraining's binary_logloss: 0.514703\n",
      "[260]\ttraining's binary_logloss: 0.514439\n",
      "[261]\ttraining's binary_logloss: 0.514213\n",
      "[262]\ttraining's binary_logloss: 0.51397\n",
      "[263]\ttraining's binary_logloss: 0.513723\n",
      "[264]\ttraining's binary_logloss: 0.513504\n",
      "[265]\ttraining's binary_logloss: 0.513262\n",
      "[266]\ttraining's binary_logloss: 0.513011\n",
      "[267]\ttraining's binary_logloss: 0.512793\n",
      "[268]\ttraining's binary_logloss: 0.51254\n",
      "[269]\ttraining's binary_logloss: 0.512304\n",
      "[270]\ttraining's binary_logloss: 0.512072\n",
      "[271]\ttraining's binary_logloss: 0.51181\n",
      "[272]\ttraining's binary_logloss: 0.511551\n",
      "[273]\ttraining's binary_logloss: 0.511318\n",
      "[274]\ttraining's binary_logloss: 0.511076\n",
      "[275]\ttraining's binary_logloss: 0.510835\n",
      "[276]\ttraining's binary_logloss: 0.51057\n",
      "[277]\ttraining's binary_logloss: 0.510317\n",
      "[278]\ttraining's binary_logloss: 0.510056\n",
      "[279]\ttraining's binary_logloss: 0.509817\n",
      "[280]\ttraining's binary_logloss: 0.50956\n",
      "[281]\ttraining's binary_logloss: 0.509383\n",
      "[282]\ttraining's binary_logloss: 0.509146\n",
      "[283]\ttraining's binary_logloss: 0.508927\n",
      "[284]\ttraining's binary_logloss: 0.508668\n",
      "[285]\ttraining's binary_logloss: 0.508447\n",
      "[286]\ttraining's binary_logloss: 0.508192\n",
      "[287]\ttraining's binary_logloss: 0.507945\n",
      "[288]\ttraining's binary_logloss: 0.507694\n",
      "[289]\ttraining's binary_logloss: 0.507439\n",
      "[290]\ttraining's binary_logloss: 0.507194\n",
      "[291]\ttraining's binary_logloss: 0.506914\n",
      "[292]\ttraining's binary_logloss: 0.506668\n",
      "[293]\ttraining's binary_logloss: 0.506398\n",
      "[294]\ttraining's binary_logloss: 0.506131\n",
      "[295]\ttraining's binary_logloss: 0.50587\n",
      "[296]\ttraining's binary_logloss: 0.505611\n",
      "[297]\ttraining's binary_logloss: 0.505358\n",
      "[298]\ttraining's binary_logloss: 0.50515\n",
      "[299]\ttraining's binary_logloss: 0.504906\n",
      "[300]\ttraining's binary_logloss: 0.504661\n",
      "[301]\ttraining's binary_logloss: 0.504413\n",
      "[302]\ttraining's binary_logloss: 0.504139\n",
      "[303]\ttraining's binary_logloss: 0.50389\n",
      "[304]\ttraining's binary_logloss: 0.503648\n",
      "[305]\ttraining's binary_logloss: 0.5034\n",
      "[306]\ttraining's binary_logloss: 0.503185\n",
      "[307]\ttraining's binary_logloss: 0.502936\n",
      "[308]\ttraining's binary_logloss: 0.502699\n",
      "[309]\ttraining's binary_logloss: 0.502447\n",
      "[310]\ttraining's binary_logloss: 0.502208\n",
      "[311]\ttraining's binary_logloss: 0.501987\n",
      "[312]\ttraining's binary_logloss: 0.501755\n",
      "[313]\ttraining's binary_logloss: 0.501546\n",
      "[314]\ttraining's binary_logloss: 0.501345\n",
      "[315]\ttraining's binary_logloss: 0.501132\n",
      "[316]\ttraining's binary_logloss: 0.500869\n",
      "[317]\ttraining's binary_logloss: 0.500588\n",
      "[318]\ttraining's binary_logloss: 0.500349\n",
      "[319]\ttraining's binary_logloss: 0.500113\n",
      "[320]\ttraining's binary_logloss: 0.499877\n",
      "[321]\ttraining's binary_logloss: 0.499572\n",
      "[322]\ttraining's binary_logloss: 0.499297\n",
      "[323]\ttraining's binary_logloss: 0.499075\n",
      "[324]\ttraining's binary_logloss: 0.49884\n",
      "[325]\ttraining's binary_logloss: 0.498568\n",
      "[326]\ttraining's binary_logloss: 0.498292\n",
      "[327]\ttraining's binary_logloss: 0.49803\n",
      "[328]\ttraining's binary_logloss: 0.497757\n",
      "[329]\ttraining's binary_logloss: 0.497492\n",
      "[330]\ttraining's binary_logloss: 0.497288\n",
      "[331]\ttraining's binary_logloss: 0.497032\n",
      "[332]\ttraining's binary_logloss: 0.496784\n",
      "[333]\ttraining's binary_logloss: 0.496538\n",
      "[334]\ttraining's binary_logloss: 0.496292\n",
      "[335]\ttraining's binary_logloss: 0.495986\n",
      "[336]\ttraining's binary_logloss: 0.495771\n",
      "[337]\ttraining's binary_logloss: 0.495558\n",
      "[338]\ttraining's binary_logloss: 0.495355\n",
      "[339]\ttraining's binary_logloss: 0.495082\n",
      "[340]\ttraining's binary_logloss: 0.494885\n",
      "[341]\ttraining's binary_logloss: 0.49463\n",
      "[342]\ttraining's binary_logloss: 0.494378\n",
      "[343]\ttraining's binary_logloss: 0.494154\n",
      "[344]\ttraining's binary_logloss: 0.49391\n",
      "[345]\ttraining's binary_logloss: 0.493654\n",
      "[346]\ttraining's binary_logloss: 0.493385\n",
      "[347]\ttraining's binary_logloss: 0.493146\n",
      "[348]\ttraining's binary_logloss: 0.492903\n",
      "[349]\ttraining's binary_logloss: 0.492682\n",
      "[350]\ttraining's binary_logloss: 0.492433\n",
      "[351]\ttraining's binary_logloss: 0.492192\n",
      "[352]\ttraining's binary_logloss: 0.491963\n",
      "[353]\ttraining's binary_logloss: 0.491698\n",
      "[354]\ttraining's binary_logloss: 0.491433\n",
      "[355]\ttraining's binary_logloss: 0.491212\n",
      "[356]\ttraining's binary_logloss: 0.490968\n",
      "[357]\ttraining's binary_logloss: 0.490729\n",
      "[358]\ttraining's binary_logloss: 0.490501\n",
      "[359]\ttraining's binary_logloss: 0.490286\n",
      "[360]\ttraining's binary_logloss: 0.490065\n",
      "[361]\ttraining's binary_logloss: 0.489811\n",
      "[362]\ttraining's binary_logloss: 0.48955\n",
      "[363]\ttraining's binary_logloss: 0.489285\n",
      "[364]\ttraining's binary_logloss: 0.489031\n",
      "[365]\ttraining's binary_logloss: 0.488789\n",
      "[366]\ttraining's binary_logloss: 0.488558\n",
      "[367]\ttraining's binary_logloss: 0.488312\n",
      "[368]\ttraining's binary_logloss: 0.488059\n",
      "[369]\ttraining's binary_logloss: 0.487812\n",
      "[370]\ttraining's binary_logloss: 0.487587\n",
      "[371]\ttraining's binary_logloss: 0.487312\n",
      "[372]\ttraining's binary_logloss: 0.487049\n",
      "[373]\ttraining's binary_logloss: 0.486832\n",
      "[374]\ttraining's binary_logloss: 0.486625\n",
      "[375]\ttraining's binary_logloss: 0.486416\n",
      "[376]\ttraining's binary_logloss: 0.486173\n",
      "[377]\ttraining's binary_logloss: 0.48594\n",
      "[378]\ttraining's binary_logloss: 0.485679\n",
      "[379]\ttraining's binary_logloss: 0.485441\n",
      "[380]\ttraining's binary_logloss: 0.485211\n",
      "[381]\ttraining's binary_logloss: 0.484972\n",
      "[382]\ttraining's binary_logloss: 0.484738\n",
      "[383]\ttraining's binary_logloss: 0.484524\n",
      "[384]\ttraining's binary_logloss: 0.4843\n",
      "[385]\ttraining's binary_logloss: 0.484071\n",
      "[386]\ttraining's binary_logloss: 0.483746\n",
      "[387]\ttraining's binary_logloss: 0.483444\n",
      "[388]\ttraining's binary_logloss: 0.483132\n",
      "[389]\ttraining's binary_logloss: 0.48282\n",
      "[390]\ttraining's binary_logloss: 0.482537\n",
      "[391]\ttraining's binary_logloss: 0.482314\n",
      "[392]\ttraining's binary_logloss: 0.482085\n",
      "[393]\ttraining's binary_logloss: 0.481863\n",
      "[394]\ttraining's binary_logloss: 0.481625\n",
      "[395]\ttraining's binary_logloss: 0.481397\n",
      "[396]\ttraining's binary_logloss: 0.481162\n",
      "[397]\ttraining's binary_logloss: 0.480916\n",
      "[398]\ttraining's binary_logloss: 0.480687\n",
      "[399]\ttraining's binary_logloss: 0.480455\n",
      "[400]\ttraining's binary_logloss: 0.480219\n",
      "[401]\ttraining's binary_logloss: 0.479901\n",
      "[402]\ttraining's binary_logloss: 0.479613\n",
      "[403]\ttraining's binary_logloss: 0.479344\n",
      "[404]\ttraining's binary_logloss: 0.479045\n",
      "[405]\ttraining's binary_logloss: 0.478792\n",
      "[406]\ttraining's binary_logloss: 0.478575\n",
      "[407]\ttraining's binary_logloss: 0.47837\n",
      "[408]\ttraining's binary_logloss: 0.478161\n",
      "[409]\ttraining's binary_logloss: 0.477952\n",
      "[410]\ttraining's binary_logloss: 0.477743\n",
      "[411]\ttraining's binary_logloss: 0.477463\n",
      "[412]\ttraining's binary_logloss: 0.477221\n",
      "[413]\ttraining's binary_logloss: 0.476991\n",
      "[414]\ttraining's binary_logloss: 0.476728\n",
      "[415]\ttraining's binary_logloss: 0.476459\n",
      "[416]\ttraining's binary_logloss: 0.476195\n",
      "[417]\ttraining's binary_logloss: 0.47597\n",
      "[418]\ttraining's binary_logloss: 0.475747\n",
      "[419]\ttraining's binary_logloss: 0.475534\n",
      "[420]\ttraining's binary_logloss: 0.475269\n",
      "[421]\ttraining's binary_logloss: 0.475049\n",
      "[422]\ttraining's binary_logloss: 0.474831\n",
      "[423]\ttraining's binary_logloss: 0.474622\n",
      "[424]\ttraining's binary_logloss: 0.474428\n",
      "[425]\ttraining's binary_logloss: 0.474228\n",
      "[426]\ttraining's binary_logloss: 0.474036\n",
      "[427]\ttraining's binary_logloss: 0.47385\n",
      "[428]\ttraining's binary_logloss: 0.473668\n",
      "[429]\ttraining's binary_logloss: 0.473471\n",
      "[430]\ttraining's binary_logloss: 0.47328\n",
      "[431]\ttraining's binary_logloss: 0.473042\n",
      "[432]\ttraining's binary_logloss: 0.472804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[433]\ttraining's binary_logloss: 0.472573\n",
      "[434]\ttraining's binary_logloss: 0.472331\n",
      "[435]\ttraining's binary_logloss: 0.472122\n",
      "[436]\ttraining's binary_logloss: 0.47189\n",
      "[437]\ttraining's binary_logloss: 0.471633\n",
      "[438]\ttraining's binary_logloss: 0.471449\n",
      "[439]\ttraining's binary_logloss: 0.471197\n",
      "[440]\ttraining's binary_logloss: 0.470947\n",
      "[441]\ttraining's binary_logloss: 0.470715\n",
      "[442]\ttraining's binary_logloss: 0.470464\n",
      "[443]\ttraining's binary_logloss: 0.470228\n",
      "[444]\ttraining's binary_logloss: 0.469988\n",
      "[445]\ttraining's binary_logloss: 0.469755\n",
      "[446]\ttraining's binary_logloss: 0.46951\n",
      "[447]\ttraining's binary_logloss: 0.469255\n",
      "[448]\ttraining's binary_logloss: 0.469004\n",
      "[449]\ttraining's binary_logloss: 0.468771\n",
      "[450]\ttraining's binary_logloss: 0.468535\n",
      "[451]\ttraining's binary_logloss: 0.468321\n",
      "[452]\ttraining's binary_logloss: 0.468089\n",
      "[453]\ttraining's binary_logloss: 0.467876\n",
      "[454]\ttraining's binary_logloss: 0.467686\n",
      "[455]\ttraining's binary_logloss: 0.467454\n",
      "[456]\ttraining's binary_logloss: 0.4672\n",
      "[457]\ttraining's binary_logloss: 0.467005\n",
      "[458]\ttraining's binary_logloss: 0.466773\n",
      "[459]\ttraining's binary_logloss: 0.46651\n",
      "[460]\ttraining's binary_logloss: 0.466306\n",
      "[461]\ttraining's binary_logloss: 0.466061\n",
      "[462]\ttraining's binary_logloss: 0.465782\n",
      "[463]\ttraining's binary_logloss: 0.465507\n",
      "[464]\ttraining's binary_logloss: 0.465275\n",
      "[465]\ttraining's binary_logloss: 0.465051\n",
      "[466]\ttraining's binary_logloss: 0.464835\n",
      "[467]\ttraining's binary_logloss: 0.46458\n",
      "[468]\ttraining's binary_logloss: 0.464376\n",
      "[469]\ttraining's binary_logloss: 0.464114\n",
      "[470]\ttraining's binary_logloss: 0.46389\n",
      "[471]\ttraining's binary_logloss: 0.463634\n",
      "[472]\ttraining's binary_logloss: 0.463395\n",
      "[473]\ttraining's binary_logloss: 0.463156\n",
      "[474]\ttraining's binary_logloss: 0.462919\n",
      "[475]\ttraining's binary_logloss: 0.462672\n",
      "[476]\ttraining's binary_logloss: 0.462472\n",
      "[477]\ttraining's binary_logloss: 0.462258\n",
      "[478]\ttraining's binary_logloss: 0.462051\n",
      "[479]\ttraining's binary_logloss: 0.461816\n",
      "[480]\ttraining's binary_logloss: 0.461601\n",
      "[481]\ttraining's binary_logloss: 0.461363\n",
      "[482]\ttraining's binary_logloss: 0.461119\n",
      "[483]\ttraining's binary_logloss: 0.460894\n",
      "[484]\ttraining's binary_logloss: 0.460671\n",
      "[485]\ttraining's binary_logloss: 0.460469\n",
      "[486]\ttraining's binary_logloss: 0.460257\n",
      "[487]\ttraining's binary_logloss: 0.460014\n",
      "[488]\ttraining's binary_logloss: 0.459763\n",
      "[489]\ttraining's binary_logloss: 0.459533\n",
      "[490]\ttraining's binary_logloss: 0.459303\n",
      "[491]\ttraining's binary_logloss: 0.459131\n",
      "[492]\ttraining's binary_logloss: 0.458964\n",
      "[493]\ttraining's binary_logloss: 0.458753\n",
      "[494]\ttraining's binary_logloss: 0.458573\n",
      "[495]\ttraining's binary_logloss: 0.458382\n",
      "[496]\ttraining's binary_logloss: 0.458121\n",
      "[497]\ttraining's binary_logloss: 0.457873\n",
      "[498]\ttraining's binary_logloss: 0.45763\n",
      "[499]\ttraining's binary_logloss: 0.4574\n",
      "[500]\ttraining's binary_logloss: 0.457175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613468\n",
      "[2]\ttraining's binary_logloss: 0.611694\n",
      "[3]\ttraining's binary_logloss: 0.609912\n",
      "[4]\ttraining's binary_logloss: 0.608258\n",
      "[5]\ttraining's binary_logloss: 0.606659\n",
      "[6]\ttraining's binary_logloss: 0.605204\n",
      "[7]\ttraining's binary_logloss: 0.603764\n",
      "[8]\ttraining's binary_logloss: 0.602383\n",
      "[9]\ttraining's binary_logloss: 0.601044\n",
      "[10]\ttraining's binary_logloss: 0.599728\n",
      "[11]\ttraining's binary_logloss: 0.598343\n",
      "[12]\ttraining's binary_logloss: 0.59721\n",
      "[13]\ttraining's binary_logloss: 0.596053\n",
      "[14]\ttraining's binary_logloss: 0.594807\n",
      "[15]\ttraining's binary_logloss: 0.593575\n",
      "[16]\ttraining's binary_logloss: 0.592333\n",
      "[17]\ttraining's binary_logloss: 0.591145\n",
      "[18]\ttraining's binary_logloss: 0.589999\n",
      "[19]\ttraining's binary_logloss: 0.588869\n",
      "[20]\ttraining's binary_logloss: 0.587886\n",
      "[21]\ttraining's binary_logloss: 0.586862\n",
      "[22]\ttraining's binary_logloss: 0.585895\n",
      "[23]\ttraining's binary_logloss: 0.585008\n",
      "[24]\ttraining's binary_logloss: 0.584037\n",
      "[25]\ttraining's binary_logloss: 0.583084\n",
      "[26]\ttraining's binary_logloss: 0.582225\n",
      "[27]\ttraining's binary_logloss: 0.58133\n",
      "[28]\ttraining's binary_logloss: 0.580512\n",
      "[29]\ttraining's binary_logloss: 0.57968\n",
      "[30]\ttraining's binary_logloss: 0.578924\n",
      "[31]\ttraining's binary_logloss: 0.578057\n",
      "[32]\ttraining's binary_logloss: 0.577209\n",
      "[33]\ttraining's binary_logloss: 0.576381\n",
      "[34]\ttraining's binary_logloss: 0.575581\n",
      "[35]\ttraining's binary_logloss: 0.574765\n",
      "[36]\ttraining's binary_logloss: 0.573929\n",
      "[37]\ttraining's binary_logloss: 0.573194\n",
      "[38]\ttraining's binary_logloss: 0.572403\n",
      "[39]\ttraining's binary_logloss: 0.571635\n",
      "[40]\ttraining's binary_logloss: 0.570882\n",
      "[41]\ttraining's binary_logloss: 0.570239\n",
      "[42]\ttraining's binary_logloss: 0.569601\n",
      "[43]\ttraining's binary_logloss: 0.569004\n",
      "[44]\ttraining's binary_logloss: 0.568432\n",
      "[45]\ttraining's binary_logloss: 0.567834\n",
      "[46]\ttraining's binary_logloss: 0.567289\n",
      "[47]\ttraining's binary_logloss: 0.566681\n",
      "[48]\ttraining's binary_logloss: 0.566082\n",
      "[49]\ttraining's binary_logloss: 0.565473\n",
      "[50]\ttraining's binary_logloss: 0.564905\n",
      "[51]\ttraining's binary_logloss: 0.564317\n",
      "[52]\ttraining's binary_logloss: 0.563758\n",
      "[53]\ttraining's binary_logloss: 0.563232\n",
      "[54]\ttraining's binary_logloss: 0.562666\n",
      "[55]\ttraining's binary_logloss: 0.562147\n",
      "[56]\ttraining's binary_logloss: 0.561568\n",
      "[57]\ttraining's binary_logloss: 0.561099\n",
      "[58]\ttraining's binary_logloss: 0.560603\n",
      "[59]\ttraining's binary_logloss: 0.560115\n",
      "[60]\ttraining's binary_logloss: 0.559592\n",
      "[61]\ttraining's binary_logloss: 0.559106\n",
      "[62]\ttraining's binary_logloss: 0.558631\n",
      "[63]\ttraining's binary_logloss: 0.558157\n",
      "[64]\ttraining's binary_logloss: 0.5577\n",
      "[65]\ttraining's binary_logloss: 0.557237\n",
      "[66]\ttraining's binary_logloss: 0.556808\n",
      "[67]\ttraining's binary_logloss: 0.556382\n",
      "[68]\ttraining's binary_logloss: 0.555967\n",
      "[69]\ttraining's binary_logloss: 0.555598\n",
      "[70]\ttraining's binary_logloss: 0.55518\n",
      "[71]\ttraining's binary_logloss: 0.554791\n",
      "[72]\ttraining's binary_logloss: 0.554356\n",
      "[73]\ttraining's binary_logloss: 0.553989\n",
      "[74]\ttraining's binary_logloss: 0.553614\n",
      "[75]\ttraining's binary_logloss: 0.553281\n",
      "[76]\ttraining's binary_logloss: 0.552851\n",
      "[77]\ttraining's binary_logloss: 0.552431\n",
      "[78]\ttraining's binary_logloss: 0.552012\n",
      "[79]\ttraining's binary_logloss: 0.551656\n",
      "[80]\ttraining's binary_logloss: 0.551304\n",
      "[81]\ttraining's binary_logloss: 0.550952\n",
      "[82]\ttraining's binary_logloss: 0.550601\n",
      "[83]\ttraining's binary_logloss: 0.550231\n",
      "[84]\ttraining's binary_logloss: 0.549901\n",
      "[85]\ttraining's binary_logloss: 0.549593\n",
      "[86]\ttraining's binary_logloss: 0.549317\n",
      "[87]\ttraining's binary_logloss: 0.548948\n",
      "[88]\ttraining's binary_logloss: 0.548569\n",
      "[89]\ttraining's binary_logloss: 0.548269\n",
      "[90]\ttraining's binary_logloss: 0.547961\n",
      "[91]\ttraining's binary_logloss: 0.547629\n",
      "[92]\ttraining's binary_logloss: 0.547299\n",
      "[93]\ttraining's binary_logloss: 0.546976\n",
      "[94]\ttraining's binary_logloss: 0.546671\n",
      "[95]\ttraining's binary_logloss: 0.546376\n",
      "[96]\ttraining's binary_logloss: 0.546049\n",
      "[97]\ttraining's binary_logloss: 0.545771\n",
      "[98]\ttraining's binary_logloss: 0.545492\n",
      "[99]\ttraining's binary_logloss: 0.545203\n",
      "[100]\ttraining's binary_logloss: 0.54494\n",
      "[101]\ttraining's binary_logloss: 0.54465\n",
      "[102]\ttraining's binary_logloss: 0.544383\n",
      "[103]\ttraining's binary_logloss: 0.544112\n",
      "[104]\ttraining's binary_logloss: 0.543846\n",
      "[105]\ttraining's binary_logloss: 0.543617\n",
      "[106]\ttraining's binary_logloss: 0.543302\n",
      "[107]\ttraining's binary_logloss: 0.542987\n",
      "[108]\ttraining's binary_logloss: 0.542696\n",
      "[109]\ttraining's binary_logloss: 0.542392\n",
      "[110]\ttraining's binary_logloss: 0.542126\n",
      "[111]\ttraining's binary_logloss: 0.54184\n",
      "[112]\ttraining's binary_logloss: 0.541545\n",
      "[113]\ttraining's binary_logloss: 0.54129\n",
      "[114]\ttraining's binary_logloss: 0.540985\n",
      "[115]\ttraining's binary_logloss: 0.540716\n",
      "[116]\ttraining's binary_logloss: 0.540459\n",
      "[117]\ttraining's binary_logloss: 0.540271\n",
      "[118]\ttraining's binary_logloss: 0.540036\n",
      "[119]\ttraining's binary_logloss: 0.539795\n",
      "[120]\ttraining's binary_logloss: 0.539545\n",
      "[121]\ttraining's binary_logloss: 0.539278\n",
      "[122]\ttraining's binary_logloss: 0.539024\n",
      "[123]\ttraining's binary_logloss: 0.538772\n",
      "[124]\ttraining's binary_logloss: 0.538542\n",
      "[125]\ttraining's binary_logloss: 0.538301\n",
      "[126]\ttraining's binary_logloss: 0.538067\n",
      "[127]\ttraining's binary_logloss: 0.537796\n",
      "[128]\ttraining's binary_logloss: 0.537521\n",
      "[129]\ttraining's binary_logloss: 0.537248\n",
      "[130]\ttraining's binary_logloss: 0.53701\n",
      "[131]\ttraining's binary_logloss: 0.536708\n",
      "[132]\ttraining's binary_logloss: 0.536409\n",
      "[133]\ttraining's binary_logloss: 0.53613\n",
      "[134]\ttraining's binary_logloss: 0.535901\n",
      "[135]\ttraining's binary_logloss: 0.535667\n",
      "[136]\ttraining's binary_logloss: 0.535412\n",
      "[137]\ttraining's binary_logloss: 0.535166\n",
      "[138]\ttraining's binary_logloss: 0.534908\n",
      "[139]\ttraining's binary_logloss: 0.534653\n",
      "[140]\ttraining's binary_logloss: 0.53444\n",
      "[141]\ttraining's binary_logloss: 0.534217\n",
      "[142]\ttraining's binary_logloss: 0.533992\n",
      "[143]\ttraining's binary_logloss: 0.533779\n",
      "[144]\ttraining's binary_logloss: 0.533551\n",
      "[145]\ttraining's binary_logloss: 0.533335\n",
      "[146]\ttraining's binary_logloss: 0.533084\n",
      "[147]\ttraining's binary_logloss: 0.532859\n",
      "[148]\ttraining's binary_logloss: 0.532638\n",
      "[149]\ttraining's binary_logloss: 0.532392\n",
      "[150]\ttraining's binary_logloss: 0.532147\n",
      "[151]\ttraining's binary_logloss: 0.53187\n",
      "[152]\ttraining's binary_logloss: 0.531601\n",
      "[153]\ttraining's binary_logloss: 0.531341\n",
      "[154]\ttraining's binary_logloss: 0.531096\n",
      "[155]\ttraining's binary_logloss: 0.530824\n",
      "[156]\ttraining's binary_logloss: 0.530628\n",
      "[157]\ttraining's binary_logloss: 0.530397\n",
      "[158]\ttraining's binary_logloss: 0.530166\n",
      "[159]\ttraining's binary_logloss: 0.529942\n",
      "[160]\ttraining's binary_logloss: 0.529731\n",
      "[161]\ttraining's binary_logloss: 0.529484\n",
      "[162]\ttraining's binary_logloss: 0.529255\n",
      "[163]\ttraining's binary_logloss: 0.528998\n",
      "[164]\ttraining's binary_logloss: 0.528759\n",
      "[165]\ttraining's binary_logloss: 0.52849\n",
      "[166]\ttraining's binary_logloss: 0.528249\n",
      "[167]\ttraining's binary_logloss: 0.52798\n",
      "[168]\ttraining's binary_logloss: 0.527697\n",
      "[169]\ttraining's binary_logloss: 0.527416\n",
      "[170]\ttraining's binary_logloss: 0.527136\n",
      "[171]\ttraining's binary_logloss: 0.526877\n",
      "[172]\ttraining's binary_logloss: 0.526681\n",
      "[173]\ttraining's binary_logloss: 0.526436\n",
      "[174]\ttraining's binary_logloss: 0.526174\n",
      "[175]\ttraining's binary_logloss: 0.525922\n",
      "[176]\ttraining's binary_logloss: 0.525686\n",
      "[177]\ttraining's binary_logloss: 0.525461\n",
      "[178]\ttraining's binary_logloss: 0.525239\n",
      "[179]\ttraining's binary_logloss: 0.524994\n",
      "[180]\ttraining's binary_logloss: 0.52477\n",
      "[181]\ttraining's binary_logloss: 0.524521\n",
      "[182]\ttraining's binary_logloss: 0.524311\n",
      "[183]\ttraining's binary_logloss: 0.524108\n",
      "[184]\ttraining's binary_logloss: 0.523906\n",
      "[185]\ttraining's binary_logloss: 0.52371\n",
      "[186]\ttraining's binary_logloss: 0.523449\n",
      "[187]\ttraining's binary_logloss: 0.523183\n",
      "[188]\ttraining's binary_logloss: 0.522929\n",
      "[189]\ttraining's binary_logloss: 0.522678\n",
      "[190]\ttraining's binary_logloss: 0.522425\n",
      "[191]\ttraining's binary_logloss: 0.522195\n",
      "[192]\ttraining's binary_logloss: 0.521981\n",
      "[193]\ttraining's binary_logloss: 0.521716\n",
      "[194]\ttraining's binary_logloss: 0.521435\n",
      "[195]\ttraining's binary_logloss: 0.521151\n",
      "[196]\ttraining's binary_logloss: 0.52093\n",
      "[197]\ttraining's binary_logloss: 0.520618\n",
      "[198]\ttraining's binary_logloss: 0.52041\n",
      "[199]\ttraining's binary_logloss: 0.520142\n",
      "[200]\ttraining's binary_logloss: 0.519933\n",
      "[201]\ttraining's binary_logloss: 0.519707\n",
      "[202]\ttraining's binary_logloss: 0.51952\n",
      "[203]\ttraining's binary_logloss: 0.519303\n",
      "[204]\ttraining's binary_logloss: 0.519074\n",
      "[205]\ttraining's binary_logloss: 0.518839\n",
      "[206]\ttraining's binary_logloss: 0.518559\n",
      "[207]\ttraining's binary_logloss: 0.518328\n",
      "[208]\ttraining's binary_logloss: 0.5181\n",
      "[209]\ttraining's binary_logloss: 0.517883\n",
      "[210]\ttraining's binary_logloss: 0.517648\n",
      "[211]\ttraining's binary_logloss: 0.517449\n",
      "[212]\ttraining's binary_logloss: 0.517231\n",
      "[213]\ttraining's binary_logloss: 0.517042\n",
      "[214]\ttraining's binary_logloss: 0.516855\n",
      "[215]\ttraining's binary_logloss: 0.516636\n",
      "[216]\ttraining's binary_logloss: 0.516368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[217]\ttraining's binary_logloss: 0.51611\n",
      "[218]\ttraining's binary_logloss: 0.515858\n",
      "[219]\ttraining's binary_logloss: 0.515617\n",
      "[220]\ttraining's binary_logloss: 0.515374\n",
      "[221]\ttraining's binary_logloss: 0.515096\n",
      "[222]\ttraining's binary_logloss: 0.514854\n",
      "[223]\ttraining's binary_logloss: 0.514573\n",
      "[224]\ttraining's binary_logloss: 0.514266\n",
      "[225]\ttraining's binary_logloss: 0.514026\n",
      "[226]\ttraining's binary_logloss: 0.513799\n",
      "[227]\ttraining's binary_logloss: 0.513599\n",
      "[228]\ttraining's binary_logloss: 0.513389\n",
      "[229]\ttraining's binary_logloss: 0.513165\n",
      "[230]\ttraining's binary_logloss: 0.512962\n",
      "[231]\ttraining's binary_logloss: 0.512747\n",
      "[232]\ttraining's binary_logloss: 0.512463\n",
      "[233]\ttraining's binary_logloss: 0.512247\n",
      "[234]\ttraining's binary_logloss: 0.512029\n",
      "[235]\ttraining's binary_logloss: 0.511772\n",
      "[236]\ttraining's binary_logloss: 0.511522\n",
      "[237]\ttraining's binary_logloss: 0.511278\n",
      "[238]\ttraining's binary_logloss: 0.511024\n",
      "[239]\ttraining's binary_logloss: 0.510784\n",
      "[240]\ttraining's binary_logloss: 0.510511\n",
      "[241]\ttraining's binary_logloss: 0.510291\n",
      "[242]\ttraining's binary_logloss: 0.510054\n",
      "[243]\ttraining's binary_logloss: 0.509843\n",
      "[244]\ttraining's binary_logloss: 0.509596\n",
      "[245]\ttraining's binary_logloss: 0.509378\n",
      "[246]\ttraining's binary_logloss: 0.509118\n",
      "[247]\ttraining's binary_logloss: 0.50888\n",
      "[248]\ttraining's binary_logloss: 0.508645\n",
      "[249]\ttraining's binary_logloss: 0.508417\n",
      "[250]\ttraining's binary_logloss: 0.50813\n",
      "[251]\ttraining's binary_logloss: 0.50794\n",
      "[252]\ttraining's binary_logloss: 0.507711\n",
      "[253]\ttraining's binary_logloss: 0.507496\n",
      "[254]\ttraining's binary_logloss: 0.507287\n",
      "[255]\ttraining's binary_logloss: 0.507088\n",
      "[256]\ttraining's binary_logloss: 0.506846\n",
      "[257]\ttraining's binary_logloss: 0.506595\n",
      "[258]\ttraining's binary_logloss: 0.506356\n",
      "[259]\ttraining's binary_logloss: 0.50611\n",
      "[260]\ttraining's binary_logloss: 0.505886\n",
      "[261]\ttraining's binary_logloss: 0.505651\n",
      "[262]\ttraining's binary_logloss: 0.505384\n",
      "[263]\ttraining's binary_logloss: 0.505204\n",
      "[264]\ttraining's binary_logloss: 0.504987\n",
      "[265]\ttraining's binary_logloss: 0.504757\n",
      "[266]\ttraining's binary_logloss: 0.504522\n",
      "[267]\ttraining's binary_logloss: 0.504364\n",
      "[268]\ttraining's binary_logloss: 0.504188\n",
      "[269]\ttraining's binary_logloss: 0.504032\n",
      "[270]\ttraining's binary_logloss: 0.503881\n",
      "[271]\ttraining's binary_logloss: 0.503602\n",
      "[272]\ttraining's binary_logloss: 0.503307\n",
      "[273]\ttraining's binary_logloss: 0.503012\n",
      "[274]\ttraining's binary_logloss: 0.502714\n",
      "[275]\ttraining's binary_logloss: 0.50243\n",
      "[276]\ttraining's binary_logloss: 0.502126\n",
      "[277]\ttraining's binary_logloss: 0.501862\n",
      "[278]\ttraining's binary_logloss: 0.501621\n",
      "[279]\ttraining's binary_logloss: 0.501347\n",
      "[280]\ttraining's binary_logloss: 0.501081\n",
      "[281]\ttraining's binary_logloss: 0.500831\n",
      "[282]\ttraining's binary_logloss: 0.500582\n",
      "[283]\ttraining's binary_logloss: 0.500315\n",
      "[284]\ttraining's binary_logloss: 0.500079\n",
      "[285]\ttraining's binary_logloss: 0.499857\n",
      "[286]\ttraining's binary_logloss: 0.499628\n",
      "[287]\ttraining's binary_logloss: 0.4994\n",
      "[288]\ttraining's binary_logloss: 0.499169\n",
      "[289]\ttraining's binary_logloss: 0.498932\n",
      "[290]\ttraining's binary_logloss: 0.498694\n",
      "[291]\ttraining's binary_logloss: 0.498408\n",
      "[292]\ttraining's binary_logloss: 0.498161\n",
      "[293]\ttraining's binary_logloss: 0.497906\n",
      "[294]\ttraining's binary_logloss: 0.497656\n",
      "[295]\ttraining's binary_logloss: 0.497397\n",
      "[296]\ttraining's binary_logloss: 0.497171\n",
      "[297]\ttraining's binary_logloss: 0.496955\n",
      "[298]\ttraining's binary_logloss: 0.496759\n",
      "[299]\ttraining's binary_logloss: 0.496505\n",
      "[300]\ttraining's binary_logloss: 0.496308\n",
      "[301]\ttraining's binary_logloss: 0.496086\n",
      "[302]\ttraining's binary_logloss: 0.495813\n",
      "[303]\ttraining's binary_logloss: 0.49553\n",
      "[304]\ttraining's binary_logloss: 0.495239\n",
      "[305]\ttraining's binary_logloss: 0.494983\n",
      "[306]\ttraining's binary_logloss: 0.494768\n",
      "[307]\ttraining's binary_logloss: 0.494479\n",
      "[308]\ttraining's binary_logloss: 0.494248\n",
      "[309]\ttraining's binary_logloss: 0.494027\n",
      "[310]\ttraining's binary_logloss: 0.49379\n",
      "[311]\ttraining's binary_logloss: 0.493576\n",
      "[312]\ttraining's binary_logloss: 0.493379\n",
      "[313]\ttraining's binary_logloss: 0.493175\n",
      "[314]\ttraining's binary_logloss: 0.492978\n",
      "[315]\ttraining's binary_logloss: 0.492738\n",
      "[316]\ttraining's binary_logloss: 0.492497\n",
      "[317]\ttraining's binary_logloss: 0.492271\n",
      "[318]\ttraining's binary_logloss: 0.49204\n",
      "[319]\ttraining's binary_logloss: 0.491809\n",
      "[320]\ttraining's binary_logloss: 0.491566\n",
      "[321]\ttraining's binary_logloss: 0.491327\n",
      "[322]\ttraining's binary_logloss: 0.49112\n",
      "[323]\ttraining's binary_logloss: 0.490882\n",
      "[324]\ttraining's binary_logloss: 0.490645\n",
      "[325]\ttraining's binary_logloss: 0.490428\n",
      "[326]\ttraining's binary_logloss: 0.490194\n",
      "[327]\ttraining's binary_logloss: 0.489938\n",
      "[328]\ttraining's binary_logloss: 0.489663\n",
      "[329]\ttraining's binary_logloss: 0.489327\n",
      "[330]\ttraining's binary_logloss: 0.489065\n",
      "[331]\ttraining's binary_logloss: 0.488816\n",
      "[332]\ttraining's binary_logloss: 0.488563\n",
      "[333]\ttraining's binary_logloss: 0.488338\n",
      "[334]\ttraining's binary_logloss: 0.488105\n",
      "[335]\ttraining's binary_logloss: 0.487879\n",
      "[336]\ttraining's binary_logloss: 0.487644\n",
      "[337]\ttraining's binary_logloss: 0.487408\n",
      "[338]\ttraining's binary_logloss: 0.487178\n",
      "[339]\ttraining's binary_logloss: 0.486953\n",
      "[340]\ttraining's binary_logloss: 0.486737\n",
      "[341]\ttraining's binary_logloss: 0.486509\n",
      "[342]\ttraining's binary_logloss: 0.48629\n",
      "[343]\ttraining's binary_logloss: 0.486067\n",
      "[344]\ttraining's binary_logloss: 0.485833\n",
      "[345]\ttraining's binary_logloss: 0.48564\n",
      "[346]\ttraining's binary_logloss: 0.48541\n",
      "[347]\ttraining's binary_logloss: 0.485202\n",
      "[348]\ttraining's binary_logloss: 0.484986\n",
      "[349]\ttraining's binary_logloss: 0.484784\n",
      "[350]\ttraining's binary_logloss: 0.48456\n",
      "[351]\ttraining's binary_logloss: 0.484297\n",
      "[352]\ttraining's binary_logloss: 0.48407\n",
      "[353]\ttraining's binary_logloss: 0.483825\n",
      "[354]\ttraining's binary_logloss: 0.483592\n",
      "[355]\ttraining's binary_logloss: 0.483331\n",
      "[356]\ttraining's binary_logloss: 0.483061\n",
      "[357]\ttraining's binary_logloss: 0.482756\n",
      "[358]\ttraining's binary_logloss: 0.482481\n",
      "[359]\ttraining's binary_logloss: 0.482204\n",
      "[360]\ttraining's binary_logloss: 0.481965\n",
      "[361]\ttraining's binary_logloss: 0.481716\n",
      "[362]\ttraining's binary_logloss: 0.481472\n",
      "[363]\ttraining's binary_logloss: 0.481227\n",
      "[364]\ttraining's binary_logloss: 0.480972\n",
      "[365]\ttraining's binary_logloss: 0.480729\n",
      "[366]\ttraining's binary_logloss: 0.480466\n",
      "[367]\ttraining's binary_logloss: 0.48022\n",
      "[368]\ttraining's binary_logloss: 0.479963\n",
      "[369]\ttraining's binary_logloss: 0.479738\n",
      "[370]\ttraining's binary_logloss: 0.47951\n",
      "[371]\ttraining's binary_logloss: 0.479291\n",
      "[372]\ttraining's binary_logloss: 0.479105\n",
      "[373]\ttraining's binary_logloss: 0.478915\n",
      "[374]\ttraining's binary_logloss: 0.478722\n",
      "[375]\ttraining's binary_logloss: 0.478537\n",
      "[376]\ttraining's binary_logloss: 0.478291\n",
      "[377]\ttraining's binary_logloss: 0.478071\n",
      "[378]\ttraining's binary_logloss: 0.477854\n",
      "[379]\ttraining's binary_logloss: 0.477606\n",
      "[380]\ttraining's binary_logloss: 0.47733\n",
      "[381]\ttraining's binary_logloss: 0.477115\n",
      "[382]\ttraining's binary_logloss: 0.476918\n",
      "[383]\ttraining's binary_logloss: 0.476705\n",
      "[384]\ttraining's binary_logloss: 0.476504\n",
      "[385]\ttraining's binary_logloss: 0.476303\n",
      "[386]\ttraining's binary_logloss: 0.476056\n",
      "[387]\ttraining's binary_logloss: 0.475804\n",
      "[388]\ttraining's binary_logloss: 0.475562\n",
      "[389]\ttraining's binary_logloss: 0.475332\n",
      "[390]\ttraining's binary_logloss: 0.47511\n",
      "[391]\ttraining's binary_logloss: 0.474865\n",
      "[392]\ttraining's binary_logloss: 0.474627\n",
      "[393]\ttraining's binary_logloss: 0.474379\n",
      "[394]\ttraining's binary_logloss: 0.474178\n",
      "[395]\ttraining's binary_logloss: 0.473951\n",
      "[396]\ttraining's binary_logloss: 0.473703\n",
      "[397]\ttraining's binary_logloss: 0.473457\n",
      "[398]\ttraining's binary_logloss: 0.473235\n",
      "[399]\ttraining's binary_logloss: 0.47301\n",
      "[400]\ttraining's binary_logloss: 0.472814\n",
      "[401]\ttraining's binary_logloss: 0.472609\n",
      "[402]\ttraining's binary_logloss: 0.472378\n",
      "[403]\ttraining's binary_logloss: 0.472155\n",
      "[404]\ttraining's binary_logloss: 0.471901\n",
      "[405]\ttraining's binary_logloss: 0.471684\n",
      "[406]\ttraining's binary_logloss: 0.471444\n",
      "[407]\ttraining's binary_logloss: 0.471214\n",
      "[408]\ttraining's binary_logloss: 0.470973\n",
      "[409]\ttraining's binary_logloss: 0.470763\n",
      "[410]\ttraining's binary_logloss: 0.47054\n",
      "[411]\ttraining's binary_logloss: 0.4703\n",
      "[412]\ttraining's binary_logloss: 0.470061\n",
      "[413]\ttraining's binary_logloss: 0.46982\n",
      "[414]\ttraining's binary_logloss: 0.469565\n",
      "[415]\ttraining's binary_logloss: 0.469334\n",
      "[416]\ttraining's binary_logloss: 0.469089\n",
      "[417]\ttraining's binary_logloss: 0.468848\n",
      "[418]\ttraining's binary_logloss: 0.468619\n",
      "[419]\ttraining's binary_logloss: 0.468389\n",
      "[420]\ttraining's binary_logloss: 0.468161\n",
      "[421]\ttraining's binary_logloss: 0.4679\n",
      "[422]\ttraining's binary_logloss: 0.467698\n",
      "[423]\ttraining's binary_logloss: 0.467423\n",
      "[424]\ttraining's binary_logloss: 0.467227\n",
      "[425]\ttraining's binary_logloss: 0.466967\n",
      "[426]\ttraining's binary_logloss: 0.46672\n",
      "[427]\ttraining's binary_logloss: 0.466534\n",
      "[428]\ttraining's binary_logloss: 0.4663\n",
      "[429]\ttraining's binary_logloss: 0.466075\n",
      "[430]\ttraining's binary_logloss: 0.465842\n",
      "[431]\ttraining's binary_logloss: 0.465624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[432]\ttraining's binary_logloss: 0.465381\n",
      "[433]\ttraining's binary_logloss: 0.465142\n",
      "[434]\ttraining's binary_logloss: 0.464892\n",
      "[435]\ttraining's binary_logloss: 0.464642\n",
      "[436]\ttraining's binary_logloss: 0.464361\n",
      "[437]\ttraining's binary_logloss: 0.464075\n",
      "[438]\ttraining's binary_logloss: 0.463808\n",
      "[439]\ttraining's binary_logloss: 0.46355\n",
      "[440]\ttraining's binary_logloss: 0.463282\n",
      "[441]\ttraining's binary_logloss: 0.463047\n",
      "[442]\ttraining's binary_logloss: 0.462822\n",
      "[443]\ttraining's binary_logloss: 0.462606\n",
      "[444]\ttraining's binary_logloss: 0.462355\n",
      "[445]\ttraining's binary_logloss: 0.462117\n",
      "[446]\ttraining's binary_logloss: 0.46182\n",
      "[447]\ttraining's binary_logloss: 0.461565\n",
      "[448]\ttraining's binary_logloss: 0.461294\n",
      "[449]\ttraining's binary_logloss: 0.461001\n",
      "[450]\ttraining's binary_logloss: 0.460787\n",
      "[451]\ttraining's binary_logloss: 0.460598\n",
      "[452]\ttraining's binary_logloss: 0.460383\n",
      "[453]\ttraining's binary_logloss: 0.460152\n",
      "[454]\ttraining's binary_logloss: 0.45994\n",
      "[455]\ttraining's binary_logloss: 0.459715\n",
      "[456]\ttraining's binary_logloss: 0.459505\n",
      "[457]\ttraining's binary_logloss: 0.459265\n",
      "[458]\ttraining's binary_logloss: 0.459067\n",
      "[459]\ttraining's binary_logloss: 0.458857\n",
      "[460]\ttraining's binary_logloss: 0.458673\n",
      "[461]\ttraining's binary_logloss: 0.458357\n",
      "[462]\ttraining's binary_logloss: 0.458082\n",
      "[463]\ttraining's binary_logloss: 0.457845\n",
      "[464]\ttraining's binary_logloss: 0.457611\n",
      "[465]\ttraining's binary_logloss: 0.457358\n",
      "[466]\ttraining's binary_logloss: 0.457123\n",
      "[467]\ttraining's binary_logloss: 0.456888\n",
      "[468]\ttraining's binary_logloss: 0.456652\n",
      "[469]\ttraining's binary_logloss: 0.456417\n",
      "[470]\ttraining's binary_logloss: 0.456172\n",
      "[471]\ttraining's binary_logloss: 0.455962\n",
      "[472]\ttraining's binary_logloss: 0.455763\n",
      "[473]\ttraining's binary_logloss: 0.455573\n",
      "[474]\ttraining's binary_logloss: 0.455368\n",
      "[475]\ttraining's binary_logloss: 0.455162\n",
      "[476]\ttraining's binary_logloss: 0.454901\n",
      "[477]\ttraining's binary_logloss: 0.454633\n",
      "[478]\ttraining's binary_logloss: 0.454382\n",
      "[479]\ttraining's binary_logloss: 0.454118\n",
      "[480]\ttraining's binary_logloss: 0.453856\n",
      "[481]\ttraining's binary_logloss: 0.453653\n",
      "[482]\ttraining's binary_logloss: 0.453399\n",
      "[483]\ttraining's binary_logloss: 0.453171\n",
      "[484]\ttraining's binary_logloss: 0.452954\n",
      "[485]\ttraining's binary_logloss: 0.45275\n",
      "[486]\ttraining's binary_logloss: 0.452512\n",
      "[487]\ttraining's binary_logloss: 0.452268\n",
      "[488]\ttraining's binary_logloss: 0.45201\n",
      "[489]\ttraining's binary_logloss: 0.451746\n",
      "[490]\ttraining's binary_logloss: 0.451533\n",
      "[491]\ttraining's binary_logloss: 0.451334\n",
      "[492]\ttraining's binary_logloss: 0.451129\n",
      "[493]\ttraining's binary_logloss: 0.450904\n",
      "[494]\ttraining's binary_logloss: 0.450698\n",
      "[495]\ttraining's binary_logloss: 0.450496\n",
      "[496]\ttraining's binary_logloss: 0.450257\n",
      "[497]\ttraining's binary_logloss: 0.450005\n",
      "[498]\ttraining's binary_logloss: 0.449773\n",
      "[499]\ttraining's binary_logloss: 0.449528\n",
      "[500]\ttraining's binary_logloss: 0.449287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.612644\n",
      "[2]\ttraining's binary_logloss: 0.610944\n",
      "[3]\ttraining's binary_logloss: 0.609388\n",
      "[4]\ttraining's binary_logloss: 0.607775\n",
      "[5]\ttraining's binary_logloss: 0.606246\n",
      "[6]\ttraining's binary_logloss: 0.604948\n",
      "[7]\ttraining's binary_logloss: 0.603492\n",
      "[8]\ttraining's binary_logloss: 0.602171\n",
      "[9]\ttraining's binary_logloss: 0.60079\n",
      "[10]\ttraining's binary_logloss: 0.599473\n",
      "[11]\ttraining's binary_logloss: 0.598222\n",
      "[12]\ttraining's binary_logloss: 0.597054\n",
      "[13]\ttraining's binary_logloss: 0.595776\n",
      "[14]\ttraining's binary_logloss: 0.594551\n",
      "[15]\ttraining's binary_logloss: 0.593389\n",
      "[16]\ttraining's binary_logloss: 0.592217\n",
      "[17]\ttraining's binary_logloss: 0.591082\n",
      "[18]\ttraining's binary_logloss: 0.589986\n",
      "[19]\ttraining's binary_logloss: 0.58893\n",
      "[20]\ttraining's binary_logloss: 0.587873\n",
      "[21]\ttraining's binary_logloss: 0.5869\n",
      "[22]\ttraining's binary_logloss: 0.58594\n",
      "[23]\ttraining's binary_logloss: 0.585015\n",
      "[24]\ttraining's binary_logloss: 0.584092\n",
      "[25]\ttraining's binary_logloss: 0.583174\n",
      "[26]\ttraining's binary_logloss: 0.58225\n",
      "[27]\ttraining's binary_logloss: 0.581444\n",
      "[28]\ttraining's binary_logloss: 0.580662\n",
      "[29]\ttraining's binary_logloss: 0.579801\n",
      "[30]\ttraining's binary_logloss: 0.578982\n",
      "[31]\ttraining's binary_logloss: 0.578199\n",
      "[32]\ttraining's binary_logloss: 0.577457\n",
      "[33]\ttraining's binary_logloss: 0.576745\n",
      "[34]\ttraining's binary_logloss: 0.57597\n",
      "[35]\ttraining's binary_logloss: 0.575187\n",
      "[36]\ttraining's binary_logloss: 0.574457\n",
      "[37]\ttraining's binary_logloss: 0.573769\n",
      "[38]\ttraining's binary_logloss: 0.573123\n",
      "[39]\ttraining's binary_logloss: 0.572532\n",
      "[40]\ttraining's binary_logloss: 0.571872\n",
      "[41]\ttraining's binary_logloss: 0.571213\n",
      "[42]\ttraining's binary_logloss: 0.570545\n",
      "[43]\ttraining's binary_logloss: 0.56993\n",
      "[44]\ttraining's binary_logloss: 0.569318\n",
      "[45]\ttraining's binary_logloss: 0.568662\n",
      "[46]\ttraining's binary_logloss: 0.568006\n",
      "[47]\ttraining's binary_logloss: 0.567379\n",
      "[48]\ttraining's binary_logloss: 0.566759\n",
      "[49]\ttraining's binary_logloss: 0.566195\n",
      "[50]\ttraining's binary_logloss: 0.565623\n",
      "[51]\ttraining's binary_logloss: 0.565129\n",
      "[52]\ttraining's binary_logloss: 0.564543\n",
      "[53]\ttraining's binary_logloss: 0.563977\n",
      "[54]\ttraining's binary_logloss: 0.563512\n",
      "[55]\ttraining's binary_logloss: 0.562975\n",
      "[56]\ttraining's binary_logloss: 0.562523\n",
      "[57]\ttraining's binary_logloss: 0.562004\n",
      "[58]\ttraining's binary_logloss: 0.561572\n",
      "[59]\ttraining's binary_logloss: 0.561132\n",
      "[60]\ttraining's binary_logloss: 0.560701\n",
      "[61]\ttraining's binary_logloss: 0.56028\n",
      "[62]\ttraining's binary_logloss: 0.559805\n",
      "[63]\ttraining's binary_logloss: 0.559393\n",
      "[64]\ttraining's binary_logloss: 0.558988\n",
      "[65]\ttraining's binary_logloss: 0.558611\n",
      "[66]\ttraining's binary_logloss: 0.558134\n",
      "[67]\ttraining's binary_logloss: 0.557672\n",
      "[68]\ttraining's binary_logloss: 0.557217\n",
      "[69]\ttraining's binary_logloss: 0.556774\n",
      "[70]\ttraining's binary_logloss: 0.556399\n",
      "[71]\ttraining's binary_logloss: 0.555941\n",
      "[72]\ttraining's binary_logloss: 0.555502\n",
      "[73]\ttraining's binary_logloss: 0.555084\n",
      "[74]\ttraining's binary_logloss: 0.554668\n",
      "[75]\ttraining's binary_logloss: 0.554264\n",
      "[76]\ttraining's binary_logloss: 0.553882\n",
      "[77]\ttraining's binary_logloss: 0.553538\n",
      "[78]\ttraining's binary_logloss: 0.553134\n",
      "[79]\ttraining's binary_logloss: 0.55279\n",
      "[80]\ttraining's binary_logloss: 0.552413\n",
      "[81]\ttraining's binary_logloss: 0.552053\n",
      "[82]\ttraining's binary_logloss: 0.551716\n",
      "[83]\ttraining's binary_logloss: 0.551362\n",
      "[84]\ttraining's binary_logloss: 0.551039\n",
      "[85]\ttraining's binary_logloss: 0.550703\n",
      "[86]\ttraining's binary_logloss: 0.550364\n",
      "[87]\ttraining's binary_logloss: 0.550035\n",
      "[88]\ttraining's binary_logloss: 0.54971\n",
      "[89]\ttraining's binary_logloss: 0.54937\n",
      "[90]\ttraining's binary_logloss: 0.549046\n",
      "[91]\ttraining's binary_logloss: 0.548728\n",
      "[92]\ttraining's binary_logloss: 0.548417\n",
      "[93]\ttraining's binary_logloss: 0.548126\n",
      "[94]\ttraining's binary_logloss: 0.547822\n",
      "[95]\ttraining's binary_logloss: 0.547523\n",
      "[96]\ttraining's binary_logloss: 0.54729\n",
      "[97]\ttraining's binary_logloss: 0.547004\n",
      "[98]\ttraining's binary_logloss: 0.546717\n",
      "[99]\ttraining's binary_logloss: 0.546455\n",
      "[100]\ttraining's binary_logloss: 0.546193\n",
      "[101]\ttraining's binary_logloss: 0.545942\n",
      "[102]\ttraining's binary_logloss: 0.545702\n",
      "[103]\ttraining's binary_logloss: 0.545465\n",
      "[104]\ttraining's binary_logloss: 0.545231\n",
      "[105]\ttraining's binary_logloss: 0.544987\n",
      "[106]\ttraining's binary_logloss: 0.544721\n",
      "[107]\ttraining's binary_logloss: 0.544443\n",
      "[108]\ttraining's binary_logloss: 0.544178\n",
      "[109]\ttraining's binary_logloss: 0.543933\n",
      "[110]\ttraining's binary_logloss: 0.543687\n",
      "[111]\ttraining's binary_logloss: 0.543478\n",
      "[112]\ttraining's binary_logloss: 0.54331\n",
      "[113]\ttraining's binary_logloss: 0.543086\n",
      "[114]\ttraining's binary_logloss: 0.542879\n",
      "[115]\ttraining's binary_logloss: 0.542633\n",
      "[116]\ttraining's binary_logloss: 0.54241\n",
      "[117]\ttraining's binary_logloss: 0.542136\n",
      "[118]\ttraining's binary_logloss: 0.54188\n",
      "[119]\ttraining's binary_logloss: 0.541669\n",
      "[120]\ttraining's binary_logloss: 0.541368\n",
      "[121]\ttraining's binary_logloss: 0.541122\n",
      "[122]\ttraining's binary_logloss: 0.540837\n",
      "[123]\ttraining's binary_logloss: 0.540566\n",
      "[124]\ttraining's binary_logloss: 0.540336\n",
      "[125]\ttraining's binary_logloss: 0.540083\n",
      "[126]\ttraining's binary_logloss: 0.539846\n",
      "[127]\ttraining's binary_logloss: 0.539584\n",
      "[128]\ttraining's binary_logloss: 0.539304\n",
      "[129]\ttraining's binary_logloss: 0.539049\n",
      "[130]\ttraining's binary_logloss: 0.538787\n",
      "[131]\ttraining's binary_logloss: 0.538546\n",
      "[132]\ttraining's binary_logloss: 0.538304\n",
      "[133]\ttraining's binary_logloss: 0.538045\n",
      "[134]\ttraining's binary_logloss: 0.537778\n",
      "[135]\ttraining's binary_logloss: 0.537561\n",
      "[136]\ttraining's binary_logloss: 0.537354\n",
      "[137]\ttraining's binary_logloss: 0.537135\n",
      "[138]\ttraining's binary_logloss: 0.536921\n",
      "[139]\ttraining's binary_logloss: 0.536679\n",
      "[140]\ttraining's binary_logloss: 0.536452\n",
      "[141]\ttraining's binary_logloss: 0.536197\n",
      "[142]\ttraining's binary_logloss: 0.53595\n",
      "[143]\ttraining's binary_logloss: 0.535745\n",
      "[144]\ttraining's binary_logloss: 0.535507\n",
      "[145]\ttraining's binary_logloss: 0.535236\n",
      "[146]\ttraining's binary_logloss: 0.534963\n",
      "[147]\ttraining's binary_logloss: 0.534683\n",
      "[148]\ttraining's binary_logloss: 0.534443\n",
      "[149]\ttraining's binary_logloss: 0.534195\n",
      "[150]\ttraining's binary_logloss: 0.533957\n",
      "[151]\ttraining's binary_logloss: 0.533711\n",
      "[152]\ttraining's binary_logloss: 0.533488\n",
      "[153]\ttraining's binary_logloss: 0.533259\n",
      "[154]\ttraining's binary_logloss: 0.533082\n",
      "[155]\ttraining's binary_logloss: 0.532847\n",
      "[156]\ttraining's binary_logloss: 0.532666\n",
      "[157]\ttraining's binary_logloss: 0.532499\n",
      "[158]\ttraining's binary_logloss: 0.532299\n",
      "[159]\ttraining's binary_logloss: 0.532125\n",
      "[160]\ttraining's binary_logloss: 0.531911\n",
      "[161]\ttraining's binary_logloss: 0.531699\n",
      "[162]\ttraining's binary_logloss: 0.531437\n",
      "[163]\ttraining's binary_logloss: 0.531187\n",
      "[164]\ttraining's binary_logloss: 0.530979\n",
      "[165]\ttraining's binary_logloss: 0.530734\n",
      "[166]\ttraining's binary_logloss: 0.53046\n",
      "[167]\ttraining's binary_logloss: 0.530204\n",
      "[168]\ttraining's binary_logloss: 0.529956\n",
      "[169]\ttraining's binary_logloss: 0.529692\n",
      "[170]\ttraining's binary_logloss: 0.529446\n",
      "[171]\ttraining's binary_logloss: 0.529232\n",
      "[172]\ttraining's binary_logloss: 0.529019\n",
      "[173]\ttraining's binary_logloss: 0.528801\n",
      "[174]\ttraining's binary_logloss: 0.528618\n",
      "[175]\ttraining's binary_logloss: 0.528434\n",
      "[176]\ttraining's binary_logloss: 0.528212\n",
      "[177]\ttraining's binary_logloss: 0.527982\n",
      "[178]\ttraining's binary_logloss: 0.527778\n",
      "[179]\ttraining's binary_logloss: 0.527558\n",
      "[180]\ttraining's binary_logloss: 0.527346\n",
      "[181]\ttraining's binary_logloss: 0.527153\n",
      "[182]\ttraining's binary_logloss: 0.526971\n",
      "[183]\ttraining's binary_logloss: 0.526781\n",
      "[184]\ttraining's binary_logloss: 0.526607\n",
      "[185]\ttraining's binary_logloss: 0.526391\n",
      "[186]\ttraining's binary_logloss: 0.526189\n",
      "[187]\ttraining's binary_logloss: 0.525978\n",
      "[188]\ttraining's binary_logloss: 0.525777\n",
      "[189]\ttraining's binary_logloss: 0.525598\n",
      "[190]\ttraining's binary_logloss: 0.525406\n",
      "[191]\ttraining's binary_logloss: 0.525229\n",
      "[192]\ttraining's binary_logloss: 0.524971\n",
      "[193]\ttraining's binary_logloss: 0.524712\n",
      "[194]\ttraining's binary_logloss: 0.524469\n",
      "[195]\ttraining's binary_logloss: 0.524247\n",
      "[196]\ttraining's binary_logloss: 0.524032\n",
      "[197]\ttraining's binary_logloss: 0.523821\n",
      "[198]\ttraining's binary_logloss: 0.523631\n",
      "[199]\ttraining's binary_logloss: 0.523438\n",
      "[200]\ttraining's binary_logloss: 0.523255\n",
      "[201]\ttraining's binary_logloss: 0.523028\n",
      "[202]\ttraining's binary_logloss: 0.522812\n",
      "[203]\ttraining's binary_logloss: 0.522591\n",
      "[204]\ttraining's binary_logloss: 0.522366\n",
      "[205]\ttraining's binary_logloss: 0.522139\n",
      "[206]\ttraining's binary_logloss: 0.521916\n",
      "[207]\ttraining's binary_logloss: 0.521675\n",
      "[208]\ttraining's binary_logloss: 0.521455\n",
      "[209]\ttraining's binary_logloss: 0.521237\n",
      "[210]\ttraining's binary_logloss: 0.521044\n",
      "[211]\ttraining's binary_logloss: 0.520793\n",
      "[212]\ttraining's binary_logloss: 0.52058\n",
      "[213]\ttraining's binary_logloss: 0.520366\n",
      "[214]\ttraining's binary_logloss: 0.520131\n",
      "[215]\ttraining's binary_logloss: 0.519923\n",
      "[216]\ttraining's binary_logloss: 0.519683\n",
      "[217]\ttraining's binary_logloss: 0.519449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[218]\ttraining's binary_logloss: 0.519218\n",
      "[219]\ttraining's binary_logloss: 0.518981\n",
      "[220]\ttraining's binary_logloss: 0.518757\n",
      "[221]\ttraining's binary_logloss: 0.518525\n",
      "[222]\ttraining's binary_logloss: 0.518262\n",
      "[223]\ttraining's binary_logloss: 0.518015\n",
      "[224]\ttraining's binary_logloss: 0.517745\n",
      "[225]\ttraining's binary_logloss: 0.517499\n",
      "[226]\ttraining's binary_logloss: 0.517262\n",
      "[227]\ttraining's binary_logloss: 0.517008\n",
      "[228]\ttraining's binary_logloss: 0.516763\n",
      "[229]\ttraining's binary_logloss: 0.516546\n",
      "[230]\ttraining's binary_logloss: 0.516312\n",
      "[231]\ttraining's binary_logloss: 0.516084\n",
      "[232]\ttraining's binary_logloss: 0.515873\n",
      "[233]\ttraining's binary_logloss: 0.51562\n",
      "[234]\ttraining's binary_logloss: 0.515418\n",
      "[235]\ttraining's binary_logloss: 0.515213\n",
      "[236]\ttraining's binary_logloss: 0.515002\n",
      "[237]\ttraining's binary_logloss: 0.514796\n",
      "[238]\ttraining's binary_logloss: 0.514597\n",
      "[239]\ttraining's binary_logloss: 0.514391\n",
      "[240]\ttraining's binary_logloss: 0.514184\n",
      "[241]\ttraining's binary_logloss: 0.513916\n",
      "[242]\ttraining's binary_logloss: 0.513705\n",
      "[243]\ttraining's binary_logloss: 0.513439\n",
      "[244]\ttraining's binary_logloss: 0.513159\n",
      "[245]\ttraining's binary_logloss: 0.51288\n",
      "[246]\ttraining's binary_logloss: 0.512626\n",
      "[247]\ttraining's binary_logloss: 0.512365\n",
      "[248]\ttraining's binary_logloss: 0.512095\n",
      "[249]\ttraining's binary_logloss: 0.511847\n",
      "[250]\ttraining's binary_logloss: 0.511585\n",
      "[251]\ttraining's binary_logloss: 0.511359\n",
      "[252]\ttraining's binary_logloss: 0.511149\n",
      "[253]\ttraining's binary_logloss: 0.510962\n",
      "[254]\ttraining's binary_logloss: 0.510766\n",
      "[255]\ttraining's binary_logloss: 0.510574\n",
      "[256]\ttraining's binary_logloss: 0.510325\n",
      "[257]\ttraining's binary_logloss: 0.510074\n",
      "[258]\ttraining's binary_logloss: 0.509846\n",
      "[259]\ttraining's binary_logloss: 0.509555\n",
      "[260]\ttraining's binary_logloss: 0.509323\n",
      "[261]\ttraining's binary_logloss: 0.509085\n",
      "[262]\ttraining's binary_logloss: 0.508826\n",
      "[263]\ttraining's binary_logloss: 0.508574\n",
      "[264]\ttraining's binary_logloss: 0.508378\n",
      "[265]\ttraining's binary_logloss: 0.508165\n",
      "[266]\ttraining's binary_logloss: 0.507993\n",
      "[267]\ttraining's binary_logloss: 0.507764\n",
      "[268]\ttraining's binary_logloss: 0.507529\n",
      "[269]\ttraining's binary_logloss: 0.507355\n",
      "[270]\ttraining's binary_logloss: 0.507142\n",
      "[271]\ttraining's binary_logloss: 0.506878\n",
      "[272]\ttraining's binary_logloss: 0.506576\n",
      "[273]\ttraining's binary_logloss: 0.506301\n",
      "[274]\ttraining's binary_logloss: 0.505996\n",
      "[275]\ttraining's binary_logloss: 0.505764\n",
      "[276]\ttraining's binary_logloss: 0.5055\n",
      "[277]\ttraining's binary_logloss: 0.505269\n",
      "[278]\ttraining's binary_logloss: 0.505048\n",
      "[279]\ttraining's binary_logloss: 0.504791\n",
      "[280]\ttraining's binary_logloss: 0.504545\n",
      "[281]\ttraining's binary_logloss: 0.504283\n",
      "[282]\ttraining's binary_logloss: 0.504032\n",
      "[283]\ttraining's binary_logloss: 0.503769\n",
      "[284]\ttraining's binary_logloss: 0.503519\n",
      "[285]\ttraining's binary_logloss: 0.503278\n",
      "[286]\ttraining's binary_logloss: 0.503012\n",
      "[287]\ttraining's binary_logloss: 0.502743\n",
      "[288]\ttraining's binary_logloss: 0.502474\n",
      "[289]\ttraining's binary_logloss: 0.502192\n",
      "[290]\ttraining's binary_logloss: 0.501941\n",
      "[291]\ttraining's binary_logloss: 0.501664\n",
      "[292]\ttraining's binary_logloss: 0.501391\n",
      "[293]\ttraining's binary_logloss: 0.501117\n",
      "[294]\ttraining's binary_logloss: 0.500818\n",
      "[295]\ttraining's binary_logloss: 0.500576\n",
      "[296]\ttraining's binary_logloss: 0.500325\n",
      "[297]\ttraining's binary_logloss: 0.500088\n",
      "[298]\ttraining's binary_logloss: 0.499838\n",
      "[299]\ttraining's binary_logloss: 0.49959\n",
      "[300]\ttraining's binary_logloss: 0.499321\n",
      "[301]\ttraining's binary_logloss: 0.499077\n",
      "[302]\ttraining's binary_logloss: 0.49881\n",
      "[303]\ttraining's binary_logloss: 0.498559\n",
      "[304]\ttraining's binary_logloss: 0.49829\n",
      "[305]\ttraining's binary_logloss: 0.498025\n",
      "[306]\ttraining's binary_logloss: 0.497784\n",
      "[307]\ttraining's binary_logloss: 0.497552\n",
      "[308]\ttraining's binary_logloss: 0.497323\n",
      "[309]\ttraining's binary_logloss: 0.497084\n",
      "[310]\ttraining's binary_logloss: 0.496857\n",
      "[311]\ttraining's binary_logloss: 0.49658\n",
      "[312]\ttraining's binary_logloss: 0.496264\n",
      "[313]\ttraining's binary_logloss: 0.496041\n",
      "[314]\ttraining's binary_logloss: 0.495816\n",
      "[315]\ttraining's binary_logloss: 0.495553\n",
      "[316]\ttraining's binary_logloss: 0.495304\n",
      "[317]\ttraining's binary_logloss: 0.495042\n",
      "[318]\ttraining's binary_logloss: 0.494792\n",
      "[319]\ttraining's binary_logloss: 0.494498\n",
      "[320]\ttraining's binary_logloss: 0.494251\n",
      "[321]\ttraining's binary_logloss: 0.494005\n",
      "[322]\ttraining's binary_logloss: 0.49374\n",
      "[323]\ttraining's binary_logloss: 0.493483\n",
      "[324]\ttraining's binary_logloss: 0.493279\n",
      "[325]\ttraining's binary_logloss: 0.493065\n",
      "[326]\ttraining's binary_logloss: 0.492823\n",
      "[327]\ttraining's binary_logloss: 0.492588\n",
      "[328]\ttraining's binary_logloss: 0.492348\n",
      "[329]\ttraining's binary_logloss: 0.492118\n",
      "[330]\ttraining's binary_logloss: 0.491872\n",
      "[331]\ttraining's binary_logloss: 0.491626\n",
      "[332]\ttraining's binary_logloss: 0.49138\n",
      "[333]\ttraining's binary_logloss: 0.491141\n",
      "[334]\ttraining's binary_logloss: 0.490913\n",
      "[335]\ttraining's binary_logloss: 0.490694\n",
      "[336]\ttraining's binary_logloss: 0.490447\n",
      "[337]\ttraining's binary_logloss: 0.490193\n",
      "[338]\ttraining's binary_logloss: 0.489933\n",
      "[339]\ttraining's binary_logloss: 0.489689\n",
      "[340]\ttraining's binary_logloss: 0.489451\n",
      "[341]\ttraining's binary_logloss: 0.489236\n",
      "[342]\ttraining's binary_logloss: 0.489034\n",
      "[343]\ttraining's binary_logloss: 0.488842\n",
      "[344]\ttraining's binary_logloss: 0.48864\n",
      "[345]\ttraining's binary_logloss: 0.488442\n",
      "[346]\ttraining's binary_logloss: 0.488193\n",
      "[347]\ttraining's binary_logloss: 0.48796\n",
      "[348]\ttraining's binary_logloss: 0.487737\n",
      "[349]\ttraining's binary_logloss: 0.487498\n",
      "[350]\ttraining's binary_logloss: 0.487255\n",
      "[351]\ttraining's binary_logloss: 0.486966\n",
      "[352]\ttraining's binary_logloss: 0.486689\n",
      "[353]\ttraining's binary_logloss: 0.486411\n",
      "[354]\ttraining's binary_logloss: 0.486134\n",
      "[355]\ttraining's binary_logloss: 0.485882\n",
      "[356]\ttraining's binary_logloss: 0.48564\n",
      "[357]\ttraining's binary_logloss: 0.485375\n",
      "[358]\ttraining's binary_logloss: 0.485123\n",
      "[359]\ttraining's binary_logloss: 0.484875\n",
      "[360]\ttraining's binary_logloss: 0.484623\n",
      "[361]\ttraining's binary_logloss: 0.484354\n",
      "[362]\ttraining's binary_logloss: 0.484105\n",
      "[363]\ttraining's binary_logloss: 0.483852\n",
      "[364]\ttraining's binary_logloss: 0.483586\n",
      "[365]\ttraining's binary_logloss: 0.483344\n",
      "[366]\ttraining's binary_logloss: 0.483104\n",
      "[367]\ttraining's binary_logloss: 0.482915\n",
      "[368]\ttraining's binary_logloss: 0.482667\n",
      "[369]\ttraining's binary_logloss: 0.482454\n",
      "[370]\ttraining's binary_logloss: 0.482225\n",
      "[371]\ttraining's binary_logloss: 0.482011\n",
      "[372]\ttraining's binary_logloss: 0.481785\n",
      "[373]\ttraining's binary_logloss: 0.481572\n",
      "[374]\ttraining's binary_logloss: 0.481353\n",
      "[375]\ttraining's binary_logloss: 0.481157\n",
      "[376]\ttraining's binary_logloss: 0.480921\n",
      "[377]\ttraining's binary_logloss: 0.480703\n",
      "[378]\ttraining's binary_logloss: 0.480481\n",
      "[379]\ttraining's binary_logloss: 0.480274\n",
      "[380]\ttraining's binary_logloss: 0.48006\n",
      "[381]\ttraining's binary_logloss: 0.479773\n",
      "[382]\ttraining's binary_logloss: 0.479543\n",
      "[383]\ttraining's binary_logloss: 0.479277\n",
      "[384]\ttraining's binary_logloss: 0.479083\n",
      "[385]\ttraining's binary_logloss: 0.478839\n",
      "[386]\ttraining's binary_logloss: 0.478612\n",
      "[387]\ttraining's binary_logloss: 0.478352\n",
      "[388]\ttraining's binary_logloss: 0.478147\n",
      "[389]\ttraining's binary_logloss: 0.477924\n",
      "[390]\ttraining's binary_logloss: 0.477678\n",
      "[391]\ttraining's binary_logloss: 0.477407\n",
      "[392]\ttraining's binary_logloss: 0.47718\n",
      "[393]\ttraining's binary_logloss: 0.47693\n",
      "[394]\ttraining's binary_logloss: 0.476666\n",
      "[395]\ttraining's binary_logloss: 0.476434\n",
      "[396]\ttraining's binary_logloss: 0.476219\n",
      "[397]\ttraining's binary_logloss: 0.476008\n",
      "[398]\ttraining's binary_logloss: 0.47579\n",
      "[399]\ttraining's binary_logloss: 0.475617\n",
      "[400]\ttraining's binary_logloss: 0.475383\n",
      "[401]\ttraining's binary_logloss: 0.475073\n",
      "[402]\ttraining's binary_logloss: 0.474816\n",
      "[403]\ttraining's binary_logloss: 0.474543\n",
      "[404]\ttraining's binary_logloss: 0.474294\n",
      "[405]\ttraining's binary_logloss: 0.474061\n",
      "[406]\ttraining's binary_logloss: 0.473817\n",
      "[407]\ttraining's binary_logloss: 0.473583\n",
      "[408]\ttraining's binary_logloss: 0.473323\n",
      "[409]\ttraining's binary_logloss: 0.473083\n",
      "[410]\ttraining's binary_logloss: 0.472847\n",
      "[411]\ttraining's binary_logloss: 0.472616\n",
      "[412]\ttraining's binary_logloss: 0.472386\n",
      "[413]\ttraining's binary_logloss: 0.472122\n",
      "[414]\ttraining's binary_logloss: 0.47191\n",
      "[415]\ttraining's binary_logloss: 0.471649\n",
      "[416]\ttraining's binary_logloss: 0.471407\n",
      "[417]\ttraining's binary_logloss: 0.471169\n",
      "[418]\ttraining's binary_logloss: 0.470919\n",
      "[419]\ttraining's binary_logloss: 0.470674\n",
      "[420]\ttraining's binary_logloss: 0.47042\n",
      "[421]\ttraining's binary_logloss: 0.470222\n",
      "[422]\ttraining's binary_logloss: 0.470027\n",
      "[423]\ttraining's binary_logloss: 0.469821\n",
      "[424]\ttraining's binary_logloss: 0.469641\n",
      "[425]\ttraining's binary_logloss: 0.469457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[426]\ttraining's binary_logloss: 0.469245\n",
      "[427]\ttraining's binary_logloss: 0.469005\n",
      "[428]\ttraining's binary_logloss: 0.4688\n",
      "[429]\ttraining's binary_logloss: 0.468544\n",
      "[430]\ttraining's binary_logloss: 0.468312\n",
      "[431]\ttraining's binary_logloss: 0.468052\n",
      "[432]\ttraining's binary_logloss: 0.467795\n",
      "[433]\ttraining's binary_logloss: 0.467503\n",
      "[434]\ttraining's binary_logloss: 0.467232\n",
      "[435]\ttraining's binary_logloss: 0.466979\n",
      "[436]\ttraining's binary_logloss: 0.466767\n",
      "[437]\ttraining's binary_logloss: 0.466556\n",
      "[438]\ttraining's binary_logloss: 0.466335\n",
      "[439]\ttraining's binary_logloss: 0.466126\n",
      "[440]\ttraining's binary_logloss: 0.465925\n",
      "[441]\ttraining's binary_logloss: 0.465669\n",
      "[442]\ttraining's binary_logloss: 0.465419\n",
      "[443]\ttraining's binary_logloss: 0.465179\n",
      "[444]\ttraining's binary_logloss: 0.464932\n",
      "[445]\ttraining's binary_logloss: 0.464692\n",
      "[446]\ttraining's binary_logloss: 0.464443\n",
      "[447]\ttraining's binary_logloss: 0.464201\n",
      "[448]\ttraining's binary_logloss: 0.463963\n",
      "[449]\ttraining's binary_logloss: 0.463738\n",
      "[450]\ttraining's binary_logloss: 0.463504\n",
      "[451]\ttraining's binary_logloss: 0.463273\n",
      "[452]\ttraining's binary_logloss: 0.463077\n",
      "[453]\ttraining's binary_logloss: 0.462871\n",
      "[454]\ttraining's binary_logloss: 0.462674\n",
      "[455]\ttraining's binary_logloss: 0.462463\n",
      "[456]\ttraining's binary_logloss: 0.462238\n",
      "[457]\ttraining's binary_logloss: 0.46199\n",
      "[458]\ttraining's binary_logloss: 0.461724\n",
      "[459]\ttraining's binary_logloss: 0.461499\n",
      "[460]\ttraining's binary_logloss: 0.461292\n",
      "[461]\ttraining's binary_logloss: 0.461093\n",
      "[462]\ttraining's binary_logloss: 0.460817\n",
      "[463]\ttraining's binary_logloss: 0.460606\n",
      "[464]\ttraining's binary_logloss: 0.460398\n",
      "[465]\ttraining's binary_logloss: 0.460125\n",
      "[466]\ttraining's binary_logloss: 0.459868\n",
      "[467]\ttraining's binary_logloss: 0.459633\n",
      "[468]\ttraining's binary_logloss: 0.459434\n",
      "[469]\ttraining's binary_logloss: 0.459176\n",
      "[470]\ttraining's binary_logloss: 0.458953\n",
      "[471]\ttraining's binary_logloss: 0.458763\n",
      "[472]\ttraining's binary_logloss: 0.45857\n",
      "[473]\ttraining's binary_logloss: 0.458376\n",
      "[474]\ttraining's binary_logloss: 0.45821\n",
      "[475]\ttraining's binary_logloss: 0.458011\n",
      "[476]\ttraining's binary_logloss: 0.457756\n",
      "[477]\ttraining's binary_logloss: 0.457522\n",
      "[478]\ttraining's binary_logloss: 0.457285\n",
      "[479]\ttraining's binary_logloss: 0.457044\n",
      "[480]\ttraining's binary_logloss: 0.456807\n",
      "[481]\ttraining's binary_logloss: 0.456594\n",
      "[482]\ttraining's binary_logloss: 0.456397\n",
      "[483]\ttraining's binary_logloss: 0.456189\n",
      "[484]\ttraining's binary_logloss: 0.455985\n",
      "[485]\ttraining's binary_logloss: 0.455781\n",
      "[486]\ttraining's binary_logloss: 0.455502\n",
      "[487]\ttraining's binary_logloss: 0.45525\n",
      "[488]\ttraining's binary_logloss: 0.45498\n",
      "[489]\ttraining's binary_logloss: 0.454727\n",
      "[490]\ttraining's binary_logloss: 0.454466\n",
      "[491]\ttraining's binary_logloss: 0.454242\n",
      "[492]\ttraining's binary_logloss: 0.453985\n",
      "[493]\ttraining's binary_logloss: 0.453757\n",
      "[494]\ttraining's binary_logloss: 0.453541\n",
      "[495]\ttraining's binary_logloss: 0.453288\n",
      "[496]\ttraining's binary_logloss: 0.453027\n",
      "[497]\ttraining's binary_logloss: 0.452821\n",
      "[498]\ttraining's binary_logloss: 0.452612\n",
      "[499]\ttraining's binary_logloss: 0.452417\n",
      "[500]\ttraining's binary_logloss: 0.452199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.617108\n",
      "[2]\ttraining's binary_logloss: 0.615476\n",
      "[3]\ttraining's binary_logloss: 0.613902\n",
      "[4]\ttraining's binary_logloss: 0.61236\n",
      "[5]\ttraining's binary_logloss: 0.610899\n",
      "[6]\ttraining's binary_logloss: 0.609431\n",
      "[7]\ttraining's binary_logloss: 0.607999\n",
      "[8]\ttraining's binary_logloss: 0.606615\n",
      "[9]\ttraining's binary_logloss: 0.605328\n",
      "[10]\ttraining's binary_logloss: 0.604026\n",
      "[11]\ttraining's binary_logloss: 0.60275\n",
      "[12]\ttraining's binary_logloss: 0.601476\n",
      "[13]\ttraining's binary_logloss: 0.600228\n",
      "[14]\ttraining's binary_logloss: 0.599014\n",
      "[15]\ttraining's binary_logloss: 0.597802\n",
      "[16]\ttraining's binary_logloss: 0.59669\n",
      "[17]\ttraining's binary_logloss: 0.595642\n",
      "[18]\ttraining's binary_logloss: 0.594567\n",
      "[19]\ttraining's binary_logloss: 0.593564\n",
      "[20]\ttraining's binary_logloss: 0.592582\n",
      "[21]\ttraining's binary_logloss: 0.59156\n",
      "[22]\ttraining's binary_logloss: 0.59047\n",
      "[23]\ttraining's binary_logloss: 0.589532\n",
      "[24]\ttraining's binary_logloss: 0.588576\n",
      "[25]\ttraining's binary_logloss: 0.587749\n",
      "[26]\ttraining's binary_logloss: 0.586808\n",
      "[27]\ttraining's binary_logloss: 0.585956\n",
      "[28]\ttraining's binary_logloss: 0.585086\n",
      "[29]\ttraining's binary_logloss: 0.584258\n",
      "[30]\ttraining's binary_logloss: 0.583422\n",
      "[31]\ttraining's binary_logloss: 0.582567\n",
      "[32]\ttraining's binary_logloss: 0.581726\n",
      "[33]\ttraining's binary_logloss: 0.580914\n",
      "[34]\ttraining's binary_logloss: 0.580164\n",
      "[35]\ttraining's binary_logloss: 0.57944\n",
      "[36]\ttraining's binary_logloss: 0.578756\n",
      "[37]\ttraining's binary_logloss: 0.578053\n",
      "[38]\ttraining's binary_logloss: 0.577353\n",
      "[39]\ttraining's binary_logloss: 0.576646\n",
      "[40]\ttraining's binary_logloss: 0.575956\n",
      "[41]\ttraining's binary_logloss: 0.575342\n",
      "[42]\ttraining's binary_logloss: 0.574717\n",
      "[43]\ttraining's binary_logloss: 0.574106\n",
      "[44]\ttraining's binary_logloss: 0.573498\n",
      "[45]\ttraining's binary_logloss: 0.572977\n",
      "[46]\ttraining's binary_logloss: 0.572424\n",
      "[47]\ttraining's binary_logloss: 0.571845\n",
      "[48]\ttraining's binary_logloss: 0.571318\n",
      "[49]\ttraining's binary_logloss: 0.570794\n",
      "[50]\ttraining's binary_logloss: 0.570276\n",
      "[51]\ttraining's binary_logloss: 0.569716\n",
      "[52]\ttraining's binary_logloss: 0.569168\n",
      "[53]\ttraining's binary_logloss: 0.56864\n",
      "[54]\ttraining's binary_logloss: 0.568121\n",
      "[55]\ttraining's binary_logloss: 0.567599\n",
      "[56]\ttraining's binary_logloss: 0.567167\n",
      "[57]\ttraining's binary_logloss: 0.56667\n",
      "[58]\ttraining's binary_logloss: 0.566223\n",
      "[59]\ttraining's binary_logloss: 0.565806\n",
      "[60]\ttraining's binary_logloss: 0.565392\n",
      "[61]\ttraining's binary_logloss: 0.564944\n",
      "[62]\ttraining's binary_logloss: 0.564467\n",
      "[63]\ttraining's binary_logloss: 0.564012\n",
      "[64]\ttraining's binary_logloss: 0.563557\n",
      "[65]\ttraining's binary_logloss: 0.563122\n",
      "[66]\ttraining's binary_logloss: 0.562629\n",
      "[67]\ttraining's binary_logloss: 0.56217\n",
      "[68]\ttraining's binary_logloss: 0.561702\n",
      "[69]\ttraining's binary_logloss: 0.561267\n",
      "[70]\ttraining's binary_logloss: 0.56089\n",
      "[71]\ttraining's binary_logloss: 0.560495\n",
      "[72]\ttraining's binary_logloss: 0.560124\n",
      "[73]\ttraining's binary_logloss: 0.559723\n",
      "[74]\ttraining's binary_logloss: 0.559373\n",
      "[75]\ttraining's binary_logloss: 0.559031\n",
      "[76]\ttraining's binary_logloss: 0.558615\n",
      "[77]\ttraining's binary_logloss: 0.558175\n",
      "[78]\ttraining's binary_logloss: 0.557889\n",
      "[79]\ttraining's binary_logloss: 0.557465\n",
      "[80]\ttraining's binary_logloss: 0.557156\n",
      "[81]\ttraining's binary_logloss: 0.556777\n",
      "[82]\ttraining's binary_logloss: 0.556419\n",
      "[83]\ttraining's binary_logloss: 0.556027\n",
      "[84]\ttraining's binary_logloss: 0.555656\n",
      "[85]\ttraining's binary_logloss: 0.55533\n",
      "[86]\ttraining's binary_logloss: 0.555029\n",
      "[87]\ttraining's binary_logloss: 0.554727\n",
      "[88]\ttraining's binary_logloss: 0.55444\n",
      "[89]\ttraining's binary_logloss: 0.554179\n",
      "[90]\ttraining's binary_logloss: 0.553858\n",
      "[91]\ttraining's binary_logloss: 0.553542\n",
      "[92]\ttraining's binary_logloss: 0.553197\n",
      "[93]\ttraining's binary_logloss: 0.552873\n",
      "[94]\ttraining's binary_logloss: 0.552557\n",
      "[95]\ttraining's binary_logloss: 0.552252\n",
      "[96]\ttraining's binary_logloss: 0.55195\n",
      "[97]\ttraining's binary_logloss: 0.551661\n",
      "[98]\ttraining's binary_logloss: 0.551378\n",
      "[99]\ttraining's binary_logloss: 0.551088\n",
      "[100]\ttraining's binary_logloss: 0.550825\n",
      "[101]\ttraining's binary_logloss: 0.550536\n",
      "[102]\ttraining's binary_logloss: 0.550245\n",
      "[103]\ttraining's binary_logloss: 0.549968\n",
      "[104]\ttraining's binary_logloss: 0.549689\n",
      "[105]\ttraining's binary_logloss: 0.549441\n",
      "[106]\ttraining's binary_logloss: 0.549146\n",
      "[107]\ttraining's binary_logloss: 0.54884\n",
      "[108]\ttraining's binary_logloss: 0.548557\n",
      "[109]\ttraining's binary_logloss: 0.548285\n",
      "[110]\ttraining's binary_logloss: 0.548034\n",
      "[111]\ttraining's binary_logloss: 0.547787\n",
      "[112]\ttraining's binary_logloss: 0.547553\n",
      "[113]\ttraining's binary_logloss: 0.547328\n",
      "[114]\ttraining's binary_logloss: 0.547036\n",
      "[115]\ttraining's binary_logloss: 0.54683\n",
      "[116]\ttraining's binary_logloss: 0.546551\n",
      "[117]\ttraining's binary_logloss: 0.546271\n",
      "[118]\ttraining's binary_logloss: 0.546011\n",
      "[119]\ttraining's binary_logloss: 0.545751\n",
      "[120]\ttraining's binary_logloss: 0.545485\n",
      "[121]\ttraining's binary_logloss: 0.545257\n",
      "[122]\ttraining's binary_logloss: 0.545023\n",
      "[123]\ttraining's binary_logloss: 0.544812\n",
      "[124]\ttraining's binary_logloss: 0.544609\n",
      "[125]\ttraining's binary_logloss: 0.54441\n",
      "[126]\ttraining's binary_logloss: 0.544163\n",
      "[127]\ttraining's binary_logloss: 0.54391\n",
      "[128]\ttraining's binary_logloss: 0.54361\n",
      "[129]\ttraining's binary_logloss: 0.543395\n",
      "[130]\ttraining's binary_logloss: 0.543181\n",
      "[131]\ttraining's binary_logloss: 0.542938\n",
      "[132]\ttraining's binary_logloss: 0.542678\n",
      "[133]\ttraining's binary_logloss: 0.542444\n",
      "[134]\ttraining's binary_logloss: 0.542155\n",
      "[135]\ttraining's binary_logloss: 0.541881\n",
      "[136]\ttraining's binary_logloss: 0.541585\n",
      "[137]\ttraining's binary_logloss: 0.541304\n",
      "[138]\ttraining's binary_logloss: 0.54104\n",
      "[139]\ttraining's binary_logloss: 0.54078\n",
      "[140]\ttraining's binary_logloss: 0.540507\n",
      "[141]\ttraining's binary_logloss: 0.540224\n",
      "[142]\ttraining's binary_logloss: 0.539946\n",
      "[143]\ttraining's binary_logloss: 0.539682\n",
      "[144]\ttraining's binary_logloss: 0.539423\n",
      "[145]\ttraining's binary_logloss: 0.539125\n",
      "[146]\ttraining's binary_logloss: 0.538838\n",
      "[147]\ttraining's binary_logloss: 0.538536\n",
      "[148]\ttraining's binary_logloss: 0.538249\n",
      "[149]\ttraining's binary_logloss: 0.537978\n",
      "[150]\ttraining's binary_logloss: 0.537701\n",
      "[151]\ttraining's binary_logloss: 0.537486\n",
      "[152]\ttraining's binary_logloss: 0.53727\n",
      "[153]\ttraining's binary_logloss: 0.537097\n",
      "[154]\ttraining's binary_logloss: 0.536899\n",
      "[155]\ttraining's binary_logloss: 0.5367\n",
      "[156]\ttraining's binary_logloss: 0.536404\n",
      "[157]\ttraining's binary_logloss: 0.536097\n",
      "[158]\ttraining's binary_logloss: 0.535882\n",
      "[159]\ttraining's binary_logloss: 0.535615\n",
      "[160]\ttraining's binary_logloss: 0.535419\n",
      "[161]\ttraining's binary_logloss: 0.535178\n",
      "[162]\ttraining's binary_logloss: 0.534943\n",
      "[163]\ttraining's binary_logloss: 0.534706\n",
      "[164]\ttraining's binary_logloss: 0.534499\n",
      "[165]\ttraining's binary_logloss: 0.534248\n",
      "[166]\ttraining's binary_logloss: 0.533984\n",
      "[167]\ttraining's binary_logloss: 0.533713\n",
      "[168]\ttraining's binary_logloss: 0.533421\n",
      "[169]\ttraining's binary_logloss: 0.533163\n",
      "[170]\ttraining's binary_logloss: 0.532929\n",
      "[171]\ttraining's binary_logloss: 0.532667\n",
      "[172]\ttraining's binary_logloss: 0.532391\n",
      "[173]\ttraining's binary_logloss: 0.532137\n",
      "[174]\ttraining's binary_logloss: 0.531915\n",
      "[175]\ttraining's binary_logloss: 0.531692\n",
      "[176]\ttraining's binary_logloss: 0.531479\n",
      "[177]\ttraining's binary_logloss: 0.531264\n",
      "[178]\ttraining's binary_logloss: 0.531031\n",
      "[179]\ttraining's binary_logloss: 0.530802\n",
      "[180]\ttraining's binary_logloss: 0.530604\n",
      "[181]\ttraining's binary_logloss: 0.530373\n",
      "[182]\ttraining's binary_logloss: 0.530175\n",
      "[183]\ttraining's binary_logloss: 0.529899\n",
      "[184]\ttraining's binary_logloss: 0.529646\n",
      "[185]\ttraining's binary_logloss: 0.529392\n",
      "[186]\ttraining's binary_logloss: 0.529152\n",
      "[187]\ttraining's binary_logloss: 0.528955\n",
      "[188]\ttraining's binary_logloss: 0.528725\n",
      "[189]\ttraining's binary_logloss: 0.528543\n",
      "[190]\ttraining's binary_logloss: 0.52836\n",
      "[191]\ttraining's binary_logloss: 0.52816\n",
      "[192]\ttraining's binary_logloss: 0.527914\n",
      "[193]\ttraining's binary_logloss: 0.527673\n",
      "[194]\ttraining's binary_logloss: 0.527436\n",
      "[195]\ttraining's binary_logloss: 0.527212\n",
      "[196]\ttraining's binary_logloss: 0.52698\n",
      "[197]\ttraining's binary_logloss: 0.52674\n",
      "[198]\ttraining's binary_logloss: 0.526496\n",
      "[199]\ttraining's binary_logloss: 0.526279\n",
      "[200]\ttraining's binary_logloss: 0.526076\n",
      "[201]\ttraining's binary_logloss: 0.52584\n",
      "[202]\ttraining's binary_logloss: 0.525628\n",
      "[203]\ttraining's binary_logloss: 0.525347\n",
      "[204]\ttraining's binary_logloss: 0.525057\n",
      "[205]\ttraining's binary_logloss: 0.524785\n",
      "[206]\ttraining's binary_logloss: 0.524566\n",
      "[207]\ttraining's binary_logloss: 0.52432\n",
      "[208]\ttraining's binary_logloss: 0.524085\n",
      "[209]\ttraining's binary_logloss: 0.523864\n",
      "[210]\ttraining's binary_logloss: 0.523589\n",
      "[211]\ttraining's binary_logloss: 0.523389\n",
      "[212]\ttraining's binary_logloss: 0.523191\n",
      "[213]\ttraining's binary_logloss: 0.522998\n",
      "[214]\ttraining's binary_logloss: 0.522729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[215]\ttraining's binary_logloss: 0.522547\n",
      "[216]\ttraining's binary_logloss: 0.522305\n",
      "[217]\ttraining's binary_logloss: 0.52204\n",
      "[218]\ttraining's binary_logloss: 0.521763\n",
      "[219]\ttraining's binary_logloss: 0.521525\n",
      "[220]\ttraining's binary_logloss: 0.521273\n",
      "[221]\ttraining's binary_logloss: 0.521009\n",
      "[222]\ttraining's binary_logloss: 0.520771\n",
      "[223]\ttraining's binary_logloss: 0.52053\n",
      "[224]\ttraining's binary_logloss: 0.520261\n",
      "[225]\ttraining's binary_logloss: 0.51999\n",
      "[226]\ttraining's binary_logloss: 0.519719\n",
      "[227]\ttraining's binary_logloss: 0.519467\n",
      "[228]\ttraining's binary_logloss: 0.519205\n",
      "[229]\ttraining's binary_logloss: 0.518953\n",
      "[230]\ttraining's binary_logloss: 0.518704\n",
      "[231]\ttraining's binary_logloss: 0.518475\n",
      "[232]\ttraining's binary_logloss: 0.518259\n",
      "[233]\ttraining's binary_logloss: 0.518024\n",
      "[234]\ttraining's binary_logloss: 0.517787\n",
      "[235]\ttraining's binary_logloss: 0.517559\n",
      "[236]\ttraining's binary_logloss: 0.517309\n",
      "[237]\ttraining's binary_logloss: 0.517083\n",
      "[238]\ttraining's binary_logloss: 0.516807\n",
      "[239]\ttraining's binary_logloss: 0.516578\n",
      "[240]\ttraining's binary_logloss: 0.516338\n",
      "[241]\ttraining's binary_logloss: 0.516094\n",
      "[242]\ttraining's binary_logloss: 0.515845\n",
      "[243]\ttraining's binary_logloss: 0.515604\n",
      "[244]\ttraining's binary_logloss: 0.515367\n",
      "[245]\ttraining's binary_logloss: 0.515098\n",
      "[246]\ttraining's binary_logloss: 0.514847\n",
      "[247]\ttraining's binary_logloss: 0.514609\n",
      "[248]\ttraining's binary_logloss: 0.514371\n",
      "[249]\ttraining's binary_logloss: 0.514138\n",
      "[250]\ttraining's binary_logloss: 0.513828\n",
      "[251]\ttraining's binary_logloss: 0.513579\n",
      "[252]\ttraining's binary_logloss: 0.513321\n",
      "[253]\ttraining's binary_logloss: 0.513054\n",
      "[254]\ttraining's binary_logloss: 0.512815\n",
      "[255]\ttraining's binary_logloss: 0.512585\n",
      "[256]\ttraining's binary_logloss: 0.512367\n",
      "[257]\ttraining's binary_logloss: 0.512141\n",
      "[258]\ttraining's binary_logloss: 0.511862\n",
      "[259]\ttraining's binary_logloss: 0.51161\n",
      "[260]\ttraining's binary_logloss: 0.511395\n",
      "[261]\ttraining's binary_logloss: 0.511145\n",
      "[262]\ttraining's binary_logloss: 0.510907\n",
      "[263]\ttraining's binary_logloss: 0.510669\n",
      "[264]\ttraining's binary_logloss: 0.510424\n",
      "[265]\ttraining's binary_logloss: 0.510173\n",
      "[266]\ttraining's binary_logloss: 0.509914\n",
      "[267]\ttraining's binary_logloss: 0.509676\n",
      "[268]\ttraining's binary_logloss: 0.50945\n",
      "[269]\ttraining's binary_logloss: 0.509223\n",
      "[270]\ttraining's binary_logloss: 0.509005\n",
      "[271]\ttraining's binary_logloss: 0.508755\n",
      "[272]\ttraining's binary_logloss: 0.508468\n",
      "[273]\ttraining's binary_logloss: 0.508237\n",
      "[274]\ttraining's binary_logloss: 0.507982\n",
      "[275]\ttraining's binary_logloss: 0.507717\n",
      "[276]\ttraining's binary_logloss: 0.507483\n",
      "[277]\ttraining's binary_logloss: 0.50724\n",
      "[278]\ttraining's binary_logloss: 0.506965\n",
      "[279]\ttraining's binary_logloss: 0.506721\n",
      "[280]\ttraining's binary_logloss: 0.506492\n",
      "[281]\ttraining's binary_logloss: 0.506259\n",
      "[282]\ttraining's binary_logloss: 0.506081\n",
      "[283]\ttraining's binary_logloss: 0.505835\n",
      "[284]\ttraining's binary_logloss: 0.5056\n",
      "[285]\ttraining's binary_logloss: 0.505368\n",
      "[286]\ttraining's binary_logloss: 0.505074\n",
      "[287]\ttraining's binary_logloss: 0.504815\n",
      "[288]\ttraining's binary_logloss: 0.504537\n",
      "[289]\ttraining's binary_logloss: 0.504255\n",
      "[290]\ttraining's binary_logloss: 0.503978\n",
      "[291]\ttraining's binary_logloss: 0.503716\n",
      "[292]\ttraining's binary_logloss: 0.503472\n",
      "[293]\ttraining's binary_logloss: 0.503199\n",
      "[294]\ttraining's binary_logloss: 0.502952\n",
      "[295]\ttraining's binary_logloss: 0.50265\n",
      "[296]\ttraining's binary_logloss: 0.502411\n",
      "[297]\ttraining's binary_logloss: 0.502184\n",
      "[298]\ttraining's binary_logloss: 0.501941\n",
      "[299]\ttraining's binary_logloss: 0.501677\n",
      "[300]\ttraining's binary_logloss: 0.501404\n",
      "[301]\ttraining's binary_logloss: 0.501154\n",
      "[302]\ttraining's binary_logloss: 0.500895\n",
      "[303]\ttraining's binary_logloss: 0.500655\n",
      "[304]\ttraining's binary_logloss: 0.500391\n",
      "[305]\ttraining's binary_logloss: 0.500153\n",
      "[306]\ttraining's binary_logloss: 0.499881\n",
      "[307]\ttraining's binary_logloss: 0.499626\n",
      "[308]\ttraining's binary_logloss: 0.499381\n",
      "[309]\ttraining's binary_logloss: 0.499119\n",
      "[310]\ttraining's binary_logloss: 0.498912\n",
      "[311]\ttraining's binary_logloss: 0.49868\n",
      "[312]\ttraining's binary_logloss: 0.498424\n",
      "[313]\ttraining's binary_logloss: 0.498158\n",
      "[314]\ttraining's binary_logloss: 0.497906\n",
      "[315]\ttraining's binary_logloss: 0.497674\n",
      "[316]\ttraining's binary_logloss: 0.497404\n",
      "[317]\ttraining's binary_logloss: 0.497144\n",
      "[318]\ttraining's binary_logloss: 0.496877\n",
      "[319]\ttraining's binary_logloss: 0.496613\n",
      "[320]\ttraining's binary_logloss: 0.496361\n",
      "[321]\ttraining's binary_logloss: 0.496121\n",
      "[322]\ttraining's binary_logloss: 0.495889\n",
      "[323]\ttraining's binary_logloss: 0.495645\n",
      "[324]\ttraining's binary_logloss: 0.495415\n",
      "[325]\ttraining's binary_logloss: 0.495177\n",
      "[326]\ttraining's binary_logloss: 0.49496\n",
      "[327]\ttraining's binary_logloss: 0.494733\n",
      "[328]\ttraining's binary_logloss: 0.49447\n",
      "[329]\ttraining's binary_logloss: 0.494259\n",
      "[330]\ttraining's binary_logloss: 0.494044\n",
      "[331]\ttraining's binary_logloss: 0.493766\n",
      "[332]\ttraining's binary_logloss: 0.493487\n",
      "[333]\ttraining's binary_logloss: 0.493249\n",
      "[334]\ttraining's binary_logloss: 0.493006\n",
      "[335]\ttraining's binary_logloss: 0.492748\n",
      "[336]\ttraining's binary_logloss: 0.492496\n",
      "[337]\ttraining's binary_logloss: 0.492253\n",
      "[338]\ttraining's binary_logloss: 0.492013\n",
      "[339]\ttraining's binary_logloss: 0.491767\n",
      "[340]\ttraining's binary_logloss: 0.491542\n",
      "[341]\ttraining's binary_logloss: 0.491313\n",
      "[342]\ttraining's binary_logloss: 0.491077\n",
      "[343]\ttraining's binary_logloss: 0.490852\n",
      "[344]\ttraining's binary_logloss: 0.490597\n",
      "[345]\ttraining's binary_logloss: 0.49037\n",
      "[346]\ttraining's binary_logloss: 0.49013\n",
      "[347]\ttraining's binary_logloss: 0.489913\n",
      "[348]\ttraining's binary_logloss: 0.489722\n",
      "[349]\ttraining's binary_logloss: 0.489497\n",
      "[350]\ttraining's binary_logloss: 0.489279\n",
      "[351]\ttraining's binary_logloss: 0.489024\n",
      "[352]\ttraining's binary_logloss: 0.488778\n",
      "[353]\ttraining's binary_logloss: 0.488497\n",
      "[354]\ttraining's binary_logloss: 0.488256\n",
      "[355]\ttraining's binary_logloss: 0.488007\n",
      "[356]\ttraining's binary_logloss: 0.487753\n",
      "[357]\ttraining's binary_logloss: 0.48749\n",
      "[358]\ttraining's binary_logloss: 0.487247\n",
      "[359]\ttraining's binary_logloss: 0.487007\n",
      "[360]\ttraining's binary_logloss: 0.486782\n",
      "[361]\ttraining's binary_logloss: 0.486565\n",
      "[362]\ttraining's binary_logloss: 0.48626\n",
      "[363]\ttraining's binary_logloss: 0.486027\n",
      "[364]\ttraining's binary_logloss: 0.485758\n",
      "[365]\ttraining's binary_logloss: 0.485545\n",
      "[366]\ttraining's binary_logloss: 0.485362\n",
      "[367]\ttraining's binary_logloss: 0.485156\n",
      "[368]\ttraining's binary_logloss: 0.484961\n",
      "[369]\ttraining's binary_logloss: 0.48475\n",
      "[370]\ttraining's binary_logloss: 0.484549\n",
      "[371]\ttraining's binary_logloss: 0.484277\n",
      "[372]\ttraining's binary_logloss: 0.484023\n",
      "[373]\ttraining's binary_logloss: 0.483792\n",
      "[374]\ttraining's binary_logloss: 0.483564\n",
      "[375]\ttraining's binary_logloss: 0.483286\n",
      "[376]\ttraining's binary_logloss: 0.483005\n",
      "[377]\ttraining's binary_logloss: 0.482762\n",
      "[378]\ttraining's binary_logloss: 0.48249\n",
      "[379]\ttraining's binary_logloss: 0.482262\n",
      "[380]\ttraining's binary_logloss: 0.482011\n",
      "[381]\ttraining's binary_logloss: 0.481761\n",
      "[382]\ttraining's binary_logloss: 0.481493\n",
      "[383]\ttraining's binary_logloss: 0.481247\n",
      "[384]\ttraining's binary_logloss: 0.481005\n",
      "[385]\ttraining's binary_logloss: 0.480769\n",
      "[386]\ttraining's binary_logloss: 0.480531\n",
      "[387]\ttraining's binary_logloss: 0.480279\n",
      "[388]\ttraining's binary_logloss: 0.480041\n",
      "[389]\ttraining's binary_logloss: 0.479811\n",
      "[390]\ttraining's binary_logloss: 0.479594\n",
      "[391]\ttraining's binary_logloss: 0.47937\n",
      "[392]\ttraining's binary_logloss: 0.479106\n",
      "[393]\ttraining's binary_logloss: 0.478868\n",
      "[394]\ttraining's binary_logloss: 0.478643\n",
      "[395]\ttraining's binary_logloss: 0.478422\n",
      "[396]\ttraining's binary_logloss: 0.478189\n",
      "[397]\ttraining's binary_logloss: 0.477956\n",
      "[398]\ttraining's binary_logloss: 0.477696\n",
      "[399]\ttraining's binary_logloss: 0.477456\n",
      "[400]\ttraining's binary_logloss: 0.477245\n",
      "[401]\ttraining's binary_logloss: 0.476989\n",
      "[402]\ttraining's binary_logloss: 0.476737\n",
      "[403]\ttraining's binary_logloss: 0.476496\n",
      "[404]\ttraining's binary_logloss: 0.476244\n",
      "[405]\ttraining's binary_logloss: 0.476028\n",
      "[406]\ttraining's binary_logloss: 0.475805\n",
      "[407]\ttraining's binary_logloss: 0.475536\n",
      "[408]\ttraining's binary_logloss: 0.47529\n",
      "[409]\ttraining's binary_logloss: 0.475074\n",
      "[410]\ttraining's binary_logloss: 0.474859\n",
      "[411]\ttraining's binary_logloss: 0.474638\n",
      "[412]\ttraining's binary_logloss: 0.474408\n",
      "[413]\ttraining's binary_logloss: 0.47419\n",
      "[414]\ttraining's binary_logloss: 0.473983\n",
      "[415]\ttraining's binary_logloss: 0.473775\n",
      "[416]\ttraining's binary_logloss: 0.473567\n",
      "[417]\ttraining's binary_logloss: 0.473323\n",
      "[418]\ttraining's binary_logloss: 0.473097\n",
      "[419]\ttraining's binary_logloss: 0.472832\n",
      "[420]\ttraining's binary_logloss: 0.472609\n",
      "[421]\ttraining's binary_logloss: 0.472389\n",
      "[422]\ttraining's binary_logloss: 0.472161\n",
      "[423]\ttraining's binary_logloss: 0.471942\n",
      "[424]\ttraining's binary_logloss: 0.471747\n",
      "[425]\ttraining's binary_logloss: 0.471533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[426]\ttraining's binary_logloss: 0.47131\n",
      "[427]\ttraining's binary_logloss: 0.471106\n",
      "[428]\ttraining's binary_logloss: 0.470897\n",
      "[429]\ttraining's binary_logloss: 0.470688\n",
      "[430]\ttraining's binary_logloss: 0.470476\n",
      "[431]\ttraining's binary_logloss: 0.470208\n",
      "[432]\ttraining's binary_logloss: 0.469955\n",
      "[433]\ttraining's binary_logloss: 0.469693\n",
      "[434]\ttraining's binary_logloss: 0.469455\n",
      "[435]\ttraining's binary_logloss: 0.469249\n",
      "[436]\ttraining's binary_logloss: 0.469005\n",
      "[437]\ttraining's binary_logloss: 0.468763\n",
      "[438]\ttraining's binary_logloss: 0.468527\n",
      "[439]\ttraining's binary_logloss: 0.468294\n",
      "[440]\ttraining's binary_logloss: 0.468096\n",
      "[441]\ttraining's binary_logloss: 0.467835\n",
      "[442]\ttraining's binary_logloss: 0.467589\n",
      "[443]\ttraining's binary_logloss: 0.467334\n",
      "[444]\ttraining's binary_logloss: 0.46707\n",
      "[445]\ttraining's binary_logloss: 0.466844\n",
      "[446]\ttraining's binary_logloss: 0.466654\n",
      "[447]\ttraining's binary_logloss: 0.466461\n",
      "[448]\ttraining's binary_logloss: 0.466228\n",
      "[449]\ttraining's binary_logloss: 0.466012\n",
      "[450]\ttraining's binary_logloss: 0.465819\n",
      "[451]\ttraining's binary_logloss: 0.465655\n",
      "[452]\ttraining's binary_logloss: 0.465489\n",
      "[453]\ttraining's binary_logloss: 0.465283\n",
      "[454]\ttraining's binary_logloss: 0.465053\n",
      "[455]\ttraining's binary_logloss: 0.464879\n",
      "[456]\ttraining's binary_logloss: 0.464589\n",
      "[457]\ttraining's binary_logloss: 0.464327\n",
      "[458]\ttraining's binary_logloss: 0.464051\n",
      "[459]\ttraining's binary_logloss: 0.463794\n",
      "[460]\ttraining's binary_logloss: 0.463535\n",
      "[461]\ttraining's binary_logloss: 0.463299\n",
      "[462]\ttraining's binary_logloss: 0.463104\n",
      "[463]\ttraining's binary_logloss: 0.462908\n",
      "[464]\ttraining's binary_logloss: 0.462681\n",
      "[465]\ttraining's binary_logloss: 0.462464\n",
      "[466]\ttraining's binary_logloss: 0.462219\n",
      "[467]\ttraining's binary_logloss: 0.461988\n",
      "[468]\ttraining's binary_logloss: 0.461758\n",
      "[469]\ttraining's binary_logloss: 0.461476\n",
      "[470]\ttraining's binary_logloss: 0.461254\n",
      "[471]\ttraining's binary_logloss: 0.46105\n",
      "[472]\ttraining's binary_logloss: 0.460851\n",
      "[473]\ttraining's binary_logloss: 0.460648\n",
      "[474]\ttraining's binary_logloss: 0.46045\n",
      "[475]\ttraining's binary_logloss: 0.460251\n",
      "[476]\ttraining's binary_logloss: 0.459991\n",
      "[477]\ttraining's binary_logloss: 0.459744\n",
      "[478]\ttraining's binary_logloss: 0.459508\n",
      "[479]\ttraining's binary_logloss: 0.459271\n",
      "[480]\ttraining's binary_logloss: 0.459025\n",
      "[481]\ttraining's binary_logloss: 0.458806\n",
      "[482]\ttraining's binary_logloss: 0.458604\n",
      "[483]\ttraining's binary_logloss: 0.458371\n",
      "[484]\ttraining's binary_logloss: 0.458165\n",
      "[485]\ttraining's binary_logloss: 0.457959\n",
      "[486]\ttraining's binary_logloss: 0.457699\n",
      "[487]\ttraining's binary_logloss: 0.457444\n",
      "[488]\ttraining's binary_logloss: 0.457184\n",
      "[489]\ttraining's binary_logloss: 0.456956\n",
      "[490]\ttraining's binary_logloss: 0.456726\n",
      "[491]\ttraining's binary_logloss: 0.45651\n",
      "[492]\ttraining's binary_logloss: 0.456202\n",
      "[493]\ttraining's binary_logloss: 0.455908\n",
      "[494]\ttraining's binary_logloss: 0.455651\n",
      "[495]\ttraining's binary_logloss: 0.455392\n",
      "[496]\ttraining's binary_logloss: 0.455136\n",
      "[497]\ttraining's binary_logloss: 0.454879\n",
      "[498]\ttraining's binary_logloss: 0.454628\n",
      "[499]\ttraining's binary_logloss: 0.454396\n",
      "[500]\ttraining's binary_logloss: 0.454131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613172\n",
      "[2]\ttraining's binary_logloss: 0.611538\n",
      "[3]\ttraining's binary_logloss: 0.609942\n",
      "[4]\ttraining's binary_logloss: 0.608332\n",
      "[5]\ttraining's binary_logloss: 0.606827\n",
      "[6]\ttraining's binary_logloss: 0.605427\n",
      "[7]\ttraining's binary_logloss: 0.604053\n",
      "[8]\ttraining's binary_logloss: 0.602644\n",
      "[9]\ttraining's binary_logloss: 0.601348\n",
      "[10]\ttraining's binary_logloss: 0.600051\n",
      "[11]\ttraining's binary_logloss: 0.598776\n",
      "[12]\ttraining's binary_logloss: 0.597635\n",
      "[13]\ttraining's binary_logloss: 0.596456\n",
      "[14]\ttraining's binary_logloss: 0.595384\n",
      "[15]\ttraining's binary_logloss: 0.594207\n",
      "[16]\ttraining's binary_logloss: 0.593062\n",
      "[17]\ttraining's binary_logloss: 0.591947\n",
      "[18]\ttraining's binary_logloss: 0.590855\n",
      "[19]\ttraining's binary_logloss: 0.589791\n",
      "[20]\ttraining's binary_logloss: 0.588758\n",
      "[21]\ttraining's binary_logloss: 0.587727\n",
      "[22]\ttraining's binary_logloss: 0.586758\n",
      "[23]\ttraining's binary_logloss: 0.585777\n",
      "[24]\ttraining's binary_logloss: 0.58482\n",
      "[25]\ttraining's binary_logloss: 0.583912\n",
      "[26]\ttraining's binary_logloss: 0.583024\n",
      "[27]\ttraining's binary_logloss: 0.582191\n",
      "[28]\ttraining's binary_logloss: 0.581336\n",
      "[29]\ttraining's binary_logloss: 0.580464\n",
      "[30]\ttraining's binary_logloss: 0.579621\n",
      "[31]\ttraining's binary_logloss: 0.578871\n",
      "[32]\ttraining's binary_logloss: 0.578088\n",
      "[33]\ttraining's binary_logloss: 0.57738\n",
      "[34]\ttraining's binary_logloss: 0.576634\n",
      "[35]\ttraining's binary_logloss: 0.57594\n",
      "[36]\ttraining's binary_logloss: 0.575214\n",
      "[37]\ttraining's binary_logloss: 0.574495\n",
      "[38]\ttraining's binary_logloss: 0.573783\n",
      "[39]\ttraining's binary_logloss: 0.573098\n",
      "[40]\ttraining's binary_logloss: 0.572451\n",
      "[41]\ttraining's binary_logloss: 0.571807\n",
      "[42]\ttraining's binary_logloss: 0.571181\n",
      "[43]\ttraining's binary_logloss: 0.570588\n",
      "[44]\ttraining's binary_logloss: 0.570004\n",
      "[45]\ttraining's binary_logloss: 0.569416\n",
      "[46]\ttraining's binary_logloss: 0.568826\n",
      "[47]\ttraining's binary_logloss: 0.568313\n",
      "[48]\ttraining's binary_logloss: 0.567678\n",
      "[49]\ttraining's binary_logloss: 0.567091\n",
      "[50]\ttraining's binary_logloss: 0.566566\n",
      "[51]\ttraining's binary_logloss: 0.566027\n",
      "[52]\ttraining's binary_logloss: 0.565477\n",
      "[53]\ttraining's binary_logloss: 0.565033\n",
      "[54]\ttraining's binary_logloss: 0.564519\n",
      "[55]\ttraining's binary_logloss: 0.564048\n",
      "[56]\ttraining's binary_logloss: 0.563575\n",
      "[57]\ttraining's binary_logloss: 0.563164\n",
      "[58]\ttraining's binary_logloss: 0.562676\n",
      "[59]\ttraining's binary_logloss: 0.562239\n",
      "[60]\ttraining's binary_logloss: 0.561827\n",
      "[61]\ttraining's binary_logloss: 0.561399\n",
      "[62]\ttraining's binary_logloss: 0.56101\n",
      "[63]\ttraining's binary_logloss: 0.560488\n",
      "[64]\ttraining's binary_logloss: 0.560001\n",
      "[65]\ttraining's binary_logloss: 0.559543\n",
      "[66]\ttraining's binary_logloss: 0.559077\n",
      "[67]\ttraining's binary_logloss: 0.558616\n",
      "[68]\ttraining's binary_logloss: 0.558147\n",
      "[69]\ttraining's binary_logloss: 0.557703\n",
      "[70]\ttraining's binary_logloss: 0.557285\n",
      "[71]\ttraining's binary_logloss: 0.556826\n",
      "[72]\ttraining's binary_logloss: 0.556372\n",
      "[73]\ttraining's binary_logloss: 0.555917\n",
      "[74]\ttraining's binary_logloss: 0.555502\n",
      "[75]\ttraining's binary_logloss: 0.555106\n",
      "[76]\ttraining's binary_logloss: 0.554786\n",
      "[77]\ttraining's binary_logloss: 0.554467\n",
      "[78]\ttraining's binary_logloss: 0.554157\n",
      "[79]\ttraining's binary_logloss: 0.553853\n",
      "[80]\ttraining's binary_logloss: 0.553594\n",
      "[81]\ttraining's binary_logloss: 0.55326\n",
      "[82]\ttraining's binary_logloss: 0.552914\n",
      "[83]\ttraining's binary_logloss: 0.552588\n",
      "[84]\ttraining's binary_logloss: 0.55226\n",
      "[85]\ttraining's binary_logloss: 0.551938\n",
      "[86]\ttraining's binary_logloss: 0.551637\n",
      "[87]\ttraining's binary_logloss: 0.551328\n",
      "[88]\ttraining's binary_logloss: 0.551073\n",
      "[89]\ttraining's binary_logloss: 0.550774\n",
      "[90]\ttraining's binary_logloss: 0.550491\n",
      "[91]\ttraining's binary_logloss: 0.550156\n",
      "[92]\ttraining's binary_logloss: 0.549889\n",
      "[93]\ttraining's binary_logloss: 0.549551\n",
      "[94]\ttraining's binary_logloss: 0.549262\n",
      "[95]\ttraining's binary_logloss: 0.549006\n",
      "[96]\ttraining's binary_logloss: 0.548728\n",
      "[97]\ttraining's binary_logloss: 0.548465\n",
      "[98]\ttraining's binary_logloss: 0.548202\n",
      "[99]\ttraining's binary_logloss: 0.547933\n",
      "[100]\ttraining's binary_logloss: 0.547675\n",
      "[101]\ttraining's binary_logloss: 0.547376\n",
      "[102]\ttraining's binary_logloss: 0.547073\n",
      "[103]\ttraining's binary_logloss: 0.546796\n",
      "[104]\ttraining's binary_logloss: 0.546539\n",
      "[105]\ttraining's binary_logloss: 0.546263\n",
      "[106]\ttraining's binary_logloss: 0.545984\n",
      "[107]\ttraining's binary_logloss: 0.545719\n",
      "[108]\ttraining's binary_logloss: 0.54545\n",
      "[109]\ttraining's binary_logloss: 0.545184\n",
      "[110]\ttraining's binary_logloss: 0.544918\n",
      "[111]\ttraining's binary_logloss: 0.544664\n",
      "[112]\ttraining's binary_logloss: 0.54439\n",
      "[113]\ttraining's binary_logloss: 0.544119\n",
      "[114]\ttraining's binary_logloss: 0.543918\n",
      "[115]\ttraining's binary_logloss: 0.543694\n",
      "[116]\ttraining's binary_logloss: 0.543444\n",
      "[117]\ttraining's binary_logloss: 0.543229\n",
      "[118]\ttraining's binary_logloss: 0.543016\n",
      "[119]\ttraining's binary_logloss: 0.542767\n",
      "[120]\ttraining's binary_logloss: 0.54256\n",
      "[121]\ttraining's binary_logloss: 0.542333\n",
      "[122]\ttraining's binary_logloss: 0.542057\n",
      "[123]\ttraining's binary_logloss: 0.541818\n",
      "[124]\ttraining's binary_logloss: 0.541596\n",
      "[125]\ttraining's binary_logloss: 0.541371\n",
      "[126]\ttraining's binary_logloss: 0.541093\n",
      "[127]\ttraining's binary_logloss: 0.540806\n",
      "[128]\ttraining's binary_logloss: 0.540547\n",
      "[129]\ttraining's binary_logloss: 0.540279\n",
      "[130]\ttraining's binary_logloss: 0.540054\n",
      "[131]\ttraining's binary_logloss: 0.539842\n",
      "[132]\ttraining's binary_logloss: 0.53962\n",
      "[133]\ttraining's binary_logloss: 0.539403\n",
      "[134]\ttraining's binary_logloss: 0.539185\n",
      "[135]\ttraining's binary_logloss: 0.538978\n",
      "[136]\ttraining's binary_logloss: 0.538763\n",
      "[137]\ttraining's binary_logloss: 0.538513\n",
      "[138]\ttraining's binary_logloss: 0.53827\n",
      "[139]\ttraining's binary_logloss: 0.538058\n",
      "[140]\ttraining's binary_logloss: 0.537856\n",
      "[141]\ttraining's binary_logloss: 0.53762\n",
      "[142]\ttraining's binary_logloss: 0.537366\n",
      "[143]\ttraining's binary_logloss: 0.537136\n",
      "[144]\ttraining's binary_logloss: 0.53692\n",
      "[145]\ttraining's binary_logloss: 0.536654\n",
      "[146]\ttraining's binary_logloss: 0.536404\n",
      "[147]\ttraining's binary_logloss: 0.536151\n",
      "[148]\ttraining's binary_logloss: 0.535877\n",
      "[149]\ttraining's binary_logloss: 0.535586\n",
      "[150]\ttraining's binary_logloss: 0.535371\n",
      "[151]\ttraining's binary_logloss: 0.535124\n",
      "[152]\ttraining's binary_logloss: 0.534898\n",
      "[153]\ttraining's binary_logloss: 0.53466\n",
      "[154]\ttraining's binary_logloss: 0.534465\n",
      "[155]\ttraining's binary_logloss: 0.534256\n",
      "[156]\ttraining's binary_logloss: 0.534026\n",
      "[157]\ttraining's binary_logloss: 0.53381\n",
      "[158]\ttraining's binary_logloss: 0.533602\n",
      "[159]\ttraining's binary_logloss: 0.533372\n",
      "[160]\ttraining's binary_logloss: 0.533143\n",
      "[161]\ttraining's binary_logloss: 0.532929\n",
      "[162]\ttraining's binary_logloss: 0.532691\n",
      "[163]\ttraining's binary_logloss: 0.53247\n",
      "[164]\ttraining's binary_logloss: 0.532245\n",
      "[165]\ttraining's binary_logloss: 0.532009\n",
      "[166]\ttraining's binary_logloss: 0.531746\n",
      "[167]\ttraining's binary_logloss: 0.53149\n",
      "[168]\ttraining's binary_logloss: 0.53132\n",
      "[169]\ttraining's binary_logloss: 0.531101\n",
      "[170]\ttraining's binary_logloss: 0.530894\n",
      "[171]\ttraining's binary_logloss: 0.530676\n",
      "[172]\ttraining's binary_logloss: 0.530473\n",
      "[173]\ttraining's binary_logloss: 0.530241\n",
      "[174]\ttraining's binary_logloss: 0.530031\n",
      "[175]\ttraining's binary_logloss: 0.529805\n",
      "[176]\ttraining's binary_logloss: 0.529597\n",
      "[177]\ttraining's binary_logloss: 0.529373\n",
      "[178]\ttraining's binary_logloss: 0.529133\n",
      "[179]\ttraining's binary_logloss: 0.528911\n",
      "[180]\ttraining's binary_logloss: 0.528692\n",
      "[181]\ttraining's binary_logloss: 0.528487\n",
      "[182]\ttraining's binary_logloss: 0.528282\n",
      "[183]\ttraining's binary_logloss: 0.528075\n",
      "[184]\ttraining's binary_logloss: 0.527887\n",
      "[185]\ttraining's binary_logloss: 0.527688\n",
      "[186]\ttraining's binary_logloss: 0.527521\n",
      "[187]\ttraining's binary_logloss: 0.527335\n",
      "[188]\ttraining's binary_logloss: 0.527148\n",
      "[189]\ttraining's binary_logloss: 0.526978\n",
      "[190]\ttraining's binary_logloss: 0.526814\n",
      "[191]\ttraining's binary_logloss: 0.526617\n",
      "[192]\ttraining's binary_logloss: 0.526408\n",
      "[193]\ttraining's binary_logloss: 0.526213\n",
      "[194]\ttraining's binary_logloss: 0.526009\n",
      "[195]\ttraining's binary_logloss: 0.525757\n",
      "[196]\ttraining's binary_logloss: 0.525508\n",
      "[197]\ttraining's binary_logloss: 0.525265\n",
      "[198]\ttraining's binary_logloss: 0.524995\n",
      "[199]\ttraining's binary_logloss: 0.524769\n",
      "[200]\ttraining's binary_logloss: 0.524544\n",
      "[201]\ttraining's binary_logloss: 0.524305\n",
      "[202]\ttraining's binary_logloss: 0.52407\n",
      "[203]\ttraining's binary_logloss: 0.523826\n",
      "[204]\ttraining's binary_logloss: 0.523589\n",
      "[205]\ttraining's binary_logloss: 0.523353\n",
      "[206]\ttraining's binary_logloss: 0.523179\n",
      "[207]\ttraining's binary_logloss: 0.523002\n",
      "[208]\ttraining's binary_logloss: 0.522783\n",
      "[209]\ttraining's binary_logloss: 0.522594\n",
      "[210]\ttraining's binary_logloss: 0.522393\n",
      "[211]\ttraining's binary_logloss: 0.52214\n",
      "[212]\ttraining's binary_logloss: 0.521922\n",
      "[213]\ttraining's binary_logloss: 0.521694\n",
      "[214]\ttraining's binary_logloss: 0.521444\n",
      "[215]\ttraining's binary_logloss: 0.521212\n",
      "[216]\ttraining's binary_logloss: 0.520958\n",
      "[217]\ttraining's binary_logloss: 0.520673\n",
      "[218]\ttraining's binary_logloss: 0.520424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[219]\ttraining's binary_logloss: 0.520171\n",
      "[220]\ttraining's binary_logloss: 0.519936\n",
      "[221]\ttraining's binary_logloss: 0.519719\n",
      "[222]\ttraining's binary_logloss: 0.519377\n",
      "[223]\ttraining's binary_logloss: 0.519198\n",
      "[224]\ttraining's binary_logloss: 0.518877\n",
      "[225]\ttraining's binary_logloss: 0.51865\n",
      "[226]\ttraining's binary_logloss: 0.51841\n",
      "[227]\ttraining's binary_logloss: 0.518153\n",
      "[228]\ttraining's binary_logloss: 0.517901\n",
      "[229]\ttraining's binary_logloss: 0.517649\n",
      "[230]\ttraining's binary_logloss: 0.517401\n",
      "[231]\ttraining's binary_logloss: 0.517124\n",
      "[232]\ttraining's binary_logloss: 0.516849\n",
      "[233]\ttraining's binary_logloss: 0.516597\n",
      "[234]\ttraining's binary_logloss: 0.516334\n",
      "[235]\ttraining's binary_logloss: 0.516083\n",
      "[236]\ttraining's binary_logloss: 0.515859\n",
      "[237]\ttraining's binary_logloss: 0.515598\n",
      "[238]\ttraining's binary_logloss: 0.515363\n",
      "[239]\ttraining's binary_logloss: 0.515136\n",
      "[240]\ttraining's binary_logloss: 0.514959\n",
      "[241]\ttraining's binary_logloss: 0.514728\n",
      "[242]\ttraining's binary_logloss: 0.514499\n",
      "[243]\ttraining's binary_logloss: 0.514276\n",
      "[244]\ttraining's binary_logloss: 0.514046\n",
      "[245]\ttraining's binary_logloss: 0.513831\n",
      "[246]\ttraining's binary_logloss: 0.513574\n",
      "[247]\ttraining's binary_logloss: 0.513296\n",
      "[248]\ttraining's binary_logloss: 0.513058\n",
      "[249]\ttraining's binary_logloss: 0.512773\n",
      "[250]\ttraining's binary_logloss: 0.512528\n",
      "[251]\ttraining's binary_logloss: 0.512271\n",
      "[252]\ttraining's binary_logloss: 0.512029\n",
      "[253]\ttraining's binary_logloss: 0.511799\n",
      "[254]\ttraining's binary_logloss: 0.511579\n",
      "[255]\ttraining's binary_logloss: 0.511365\n",
      "[256]\ttraining's binary_logloss: 0.511095\n",
      "[257]\ttraining's binary_logloss: 0.510855\n",
      "[258]\ttraining's binary_logloss: 0.510588\n",
      "[259]\ttraining's binary_logloss: 0.510322\n",
      "[260]\ttraining's binary_logloss: 0.510077\n",
      "[261]\ttraining's binary_logloss: 0.5098\n",
      "[262]\ttraining's binary_logloss: 0.509545\n",
      "[263]\ttraining's binary_logloss: 0.509288\n",
      "[264]\ttraining's binary_logloss: 0.509023\n",
      "[265]\ttraining's binary_logloss: 0.508753\n",
      "[266]\ttraining's binary_logloss: 0.508553\n",
      "[267]\ttraining's binary_logloss: 0.508385\n",
      "[268]\ttraining's binary_logloss: 0.508178\n",
      "[269]\ttraining's binary_logloss: 0.508019\n",
      "[270]\ttraining's binary_logloss: 0.507845\n",
      "[271]\ttraining's binary_logloss: 0.507612\n",
      "[272]\ttraining's binary_logloss: 0.50735\n",
      "[273]\ttraining's binary_logloss: 0.507113\n",
      "[274]\ttraining's binary_logloss: 0.506896\n",
      "[275]\ttraining's binary_logloss: 0.506656\n",
      "[276]\ttraining's binary_logloss: 0.506389\n",
      "[277]\ttraining's binary_logloss: 0.506172\n",
      "[278]\ttraining's binary_logloss: 0.505951\n",
      "[279]\ttraining's binary_logloss: 0.505716\n",
      "[280]\ttraining's binary_logloss: 0.505455\n",
      "[281]\ttraining's binary_logloss: 0.505233\n",
      "[282]\ttraining's binary_logloss: 0.504975\n",
      "[283]\ttraining's binary_logloss: 0.504723\n",
      "[284]\ttraining's binary_logloss: 0.504484\n",
      "[285]\ttraining's binary_logloss: 0.504266\n",
      "[286]\ttraining's binary_logloss: 0.503983\n",
      "[287]\ttraining's binary_logloss: 0.503689\n",
      "[288]\ttraining's binary_logloss: 0.50343\n",
      "[289]\ttraining's binary_logloss: 0.503124\n",
      "[290]\ttraining's binary_logloss: 0.502829\n",
      "[291]\ttraining's binary_logloss: 0.50261\n",
      "[292]\ttraining's binary_logloss: 0.502394\n",
      "[293]\ttraining's binary_logloss: 0.502179\n",
      "[294]\ttraining's binary_logloss: 0.501962\n",
      "[295]\ttraining's binary_logloss: 0.501723\n",
      "[296]\ttraining's binary_logloss: 0.501467\n",
      "[297]\ttraining's binary_logloss: 0.501209\n",
      "[298]\ttraining's binary_logloss: 0.500951\n",
      "[299]\ttraining's binary_logloss: 0.500668\n",
      "[300]\ttraining's binary_logloss: 0.500397\n",
      "[301]\ttraining's binary_logloss: 0.500143\n",
      "[302]\ttraining's binary_logloss: 0.499889\n",
      "[303]\ttraining's binary_logloss: 0.499654\n",
      "[304]\ttraining's binary_logloss: 0.499411\n",
      "[305]\ttraining's binary_logloss: 0.499132\n",
      "[306]\ttraining's binary_logloss: 0.498868\n",
      "[307]\ttraining's binary_logloss: 0.498607\n",
      "[308]\ttraining's binary_logloss: 0.49837\n",
      "[309]\ttraining's binary_logloss: 0.498091\n",
      "[310]\ttraining's binary_logloss: 0.497856\n",
      "[311]\ttraining's binary_logloss: 0.497589\n",
      "[312]\ttraining's binary_logloss: 0.497321\n",
      "[313]\ttraining's binary_logloss: 0.497084\n",
      "[314]\ttraining's binary_logloss: 0.49682\n",
      "[315]\ttraining's binary_logloss: 0.496577\n",
      "[316]\ttraining's binary_logloss: 0.496319\n",
      "[317]\ttraining's binary_logloss: 0.496059\n",
      "[318]\ttraining's binary_logloss: 0.495813\n",
      "[319]\ttraining's binary_logloss: 0.495576\n",
      "[320]\ttraining's binary_logloss: 0.495327\n",
      "[321]\ttraining's binary_logloss: 0.495132\n",
      "[322]\ttraining's binary_logloss: 0.494941\n",
      "[323]\ttraining's binary_logloss: 0.494727\n",
      "[324]\ttraining's binary_logloss: 0.49454\n",
      "[325]\ttraining's binary_logloss: 0.494332\n",
      "[326]\ttraining's binary_logloss: 0.494096\n",
      "[327]\ttraining's binary_logloss: 0.493863\n",
      "[328]\ttraining's binary_logloss: 0.493625\n",
      "[329]\ttraining's binary_logloss: 0.493442\n",
      "[330]\ttraining's binary_logloss: 0.49324\n",
      "[331]\ttraining's binary_logloss: 0.492955\n",
      "[332]\ttraining's binary_logloss: 0.492664\n",
      "[333]\ttraining's binary_logloss: 0.492371\n",
      "[334]\ttraining's binary_logloss: 0.492098\n",
      "[335]\ttraining's binary_logloss: 0.491837\n",
      "[336]\ttraining's binary_logloss: 0.491566\n",
      "[337]\ttraining's binary_logloss: 0.4913\n",
      "[338]\ttraining's binary_logloss: 0.491038\n",
      "[339]\ttraining's binary_logloss: 0.490784\n",
      "[340]\ttraining's binary_logloss: 0.490534\n",
      "[341]\ttraining's binary_logloss: 0.49026\n",
      "[342]\ttraining's binary_logloss: 0.490001\n",
      "[343]\ttraining's binary_logloss: 0.489736\n",
      "[344]\ttraining's binary_logloss: 0.489463\n",
      "[345]\ttraining's binary_logloss: 0.489176\n",
      "[346]\ttraining's binary_logloss: 0.488968\n",
      "[347]\ttraining's binary_logloss: 0.488745\n",
      "[348]\ttraining's binary_logloss: 0.488516\n",
      "[349]\ttraining's binary_logloss: 0.488301\n",
      "[350]\ttraining's binary_logloss: 0.488097\n",
      "[351]\ttraining's binary_logloss: 0.487838\n",
      "[352]\ttraining's binary_logloss: 0.487558\n",
      "[353]\ttraining's binary_logloss: 0.487296\n",
      "[354]\ttraining's binary_logloss: 0.487072\n",
      "[355]\ttraining's binary_logloss: 0.486824\n",
      "[356]\ttraining's binary_logloss: 0.486585\n",
      "[357]\ttraining's binary_logloss: 0.486356\n",
      "[358]\ttraining's binary_logloss: 0.486087\n",
      "[359]\ttraining's binary_logloss: 0.485844\n",
      "[360]\ttraining's binary_logloss: 0.485588\n",
      "[361]\ttraining's binary_logloss: 0.485348\n",
      "[362]\ttraining's binary_logloss: 0.485116\n",
      "[363]\ttraining's binary_logloss: 0.48491\n",
      "[364]\ttraining's binary_logloss: 0.484717\n",
      "[365]\ttraining's binary_logloss: 0.484479\n",
      "[366]\ttraining's binary_logloss: 0.484277\n",
      "[367]\ttraining's binary_logloss: 0.484068\n",
      "[368]\ttraining's binary_logloss: 0.483863\n",
      "[369]\ttraining's binary_logloss: 0.483633\n",
      "[370]\ttraining's binary_logloss: 0.483424\n",
      "[371]\ttraining's binary_logloss: 0.483209\n",
      "[372]\ttraining's binary_logloss: 0.482955\n",
      "[373]\ttraining's binary_logloss: 0.482727\n",
      "[374]\ttraining's binary_logloss: 0.482491\n",
      "[375]\ttraining's binary_logloss: 0.482231\n",
      "[376]\ttraining's binary_logloss: 0.481957\n",
      "[377]\ttraining's binary_logloss: 0.481686\n",
      "[378]\ttraining's binary_logloss: 0.481412\n",
      "[379]\ttraining's binary_logloss: 0.481154\n",
      "[380]\ttraining's binary_logloss: 0.480896\n",
      "[381]\ttraining's binary_logloss: 0.480699\n",
      "[382]\ttraining's binary_logloss: 0.480469\n",
      "[383]\ttraining's binary_logloss: 0.480239\n",
      "[384]\ttraining's binary_logloss: 0.480008\n",
      "[385]\ttraining's binary_logloss: 0.479766\n",
      "[386]\ttraining's binary_logloss: 0.479546\n",
      "[387]\ttraining's binary_logloss: 0.479303\n",
      "[388]\ttraining's binary_logloss: 0.479067\n",
      "[389]\ttraining's binary_logloss: 0.478829\n",
      "[390]\ttraining's binary_logloss: 0.47859\n",
      "[391]\ttraining's binary_logloss: 0.478329\n",
      "[392]\ttraining's binary_logloss: 0.47807\n",
      "[393]\ttraining's binary_logloss: 0.477798\n",
      "[394]\ttraining's binary_logloss: 0.477546\n",
      "[395]\ttraining's binary_logloss: 0.477304\n",
      "[396]\ttraining's binary_logloss: 0.477039\n",
      "[397]\ttraining's binary_logloss: 0.476758\n",
      "[398]\ttraining's binary_logloss: 0.476472\n",
      "[399]\ttraining's binary_logloss: 0.4762\n",
      "[400]\ttraining's binary_logloss: 0.475941\n",
      "[401]\ttraining's binary_logloss: 0.475702\n",
      "[402]\ttraining's binary_logloss: 0.475481\n",
      "[403]\ttraining's binary_logloss: 0.475264\n",
      "[404]\ttraining's binary_logloss: 0.47503\n",
      "[405]\ttraining's binary_logloss: 0.474794\n",
      "[406]\ttraining's binary_logloss: 0.47454\n",
      "[407]\ttraining's binary_logloss: 0.474291\n",
      "[408]\ttraining's binary_logloss: 0.474058\n",
      "[409]\ttraining's binary_logloss: 0.473805\n",
      "[410]\ttraining's binary_logloss: 0.473578\n",
      "[411]\ttraining's binary_logloss: 0.473357\n",
      "[412]\ttraining's binary_logloss: 0.473153\n",
      "[413]\ttraining's binary_logloss: 0.472955\n",
      "[414]\ttraining's binary_logloss: 0.472723\n",
      "[415]\ttraining's binary_logloss: 0.472527\n",
      "[416]\ttraining's binary_logloss: 0.472332\n",
      "[417]\ttraining's binary_logloss: 0.472097\n",
      "[418]\ttraining's binary_logloss: 0.471875\n",
      "[419]\ttraining's binary_logloss: 0.471658\n",
      "[420]\ttraining's binary_logloss: 0.471413\n",
      "[421]\ttraining's binary_logloss: 0.471202\n",
      "[422]\ttraining's binary_logloss: 0.470962\n",
      "[423]\ttraining's binary_logloss: 0.470727\n",
      "[424]\ttraining's binary_logloss: 0.47053\n",
      "[425]\ttraining's binary_logloss: 0.470301\n",
      "[426]\ttraining's binary_logloss: 0.470008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[427]\ttraining's binary_logloss: 0.469741\n",
      "[428]\ttraining's binary_logloss: 0.469422\n",
      "[429]\ttraining's binary_logloss: 0.469161\n",
      "[430]\ttraining's binary_logloss: 0.4689\n",
      "[431]\ttraining's binary_logloss: 0.468698\n",
      "[432]\ttraining's binary_logloss: 0.468449\n",
      "[433]\ttraining's binary_logloss: 0.468224\n",
      "[434]\ttraining's binary_logloss: 0.468018\n",
      "[435]\ttraining's binary_logloss: 0.4678\n",
      "[436]\ttraining's binary_logloss: 0.467508\n",
      "[437]\ttraining's binary_logloss: 0.467242\n",
      "[438]\ttraining's binary_logloss: 0.466961\n",
      "[439]\ttraining's binary_logloss: 0.466714\n",
      "[440]\ttraining's binary_logloss: 0.466476\n",
      "[441]\ttraining's binary_logloss: 0.466228\n",
      "[442]\ttraining's binary_logloss: 0.465982\n",
      "[443]\ttraining's binary_logloss: 0.465706\n",
      "[444]\ttraining's binary_logloss: 0.465441\n",
      "[445]\ttraining's binary_logloss: 0.465196\n",
      "[446]\ttraining's binary_logloss: 0.464995\n",
      "[447]\ttraining's binary_logloss: 0.464773\n",
      "[448]\ttraining's binary_logloss: 0.464557\n",
      "[449]\ttraining's binary_logloss: 0.464337\n",
      "[450]\ttraining's binary_logloss: 0.464127\n",
      "[451]\ttraining's binary_logloss: 0.463975\n",
      "[452]\ttraining's binary_logloss: 0.463795\n",
      "[453]\ttraining's binary_logloss: 0.463618\n",
      "[454]\ttraining's binary_logloss: 0.46344\n",
      "[455]\ttraining's binary_logloss: 0.463206\n",
      "[456]\ttraining's binary_logloss: 0.462964\n",
      "[457]\ttraining's binary_logloss: 0.462765\n",
      "[458]\ttraining's binary_logloss: 0.462538\n",
      "[459]\ttraining's binary_logloss: 0.462325\n",
      "[460]\ttraining's binary_logloss: 0.462119\n",
      "[461]\ttraining's binary_logloss: 0.461799\n",
      "[462]\ttraining's binary_logloss: 0.461527\n",
      "[463]\ttraining's binary_logloss: 0.46128\n",
      "[464]\ttraining's binary_logloss: 0.461036\n",
      "[465]\ttraining's binary_logloss: 0.460799\n",
      "[466]\ttraining's binary_logloss: 0.460502\n",
      "[467]\ttraining's binary_logloss: 0.460216\n",
      "[468]\ttraining's binary_logloss: 0.459939\n",
      "[469]\ttraining's binary_logloss: 0.459657\n",
      "[470]\ttraining's binary_logloss: 0.459382\n",
      "[471]\ttraining's binary_logloss: 0.459099\n",
      "[472]\ttraining's binary_logloss: 0.458822\n",
      "[473]\ttraining's binary_logloss: 0.458552\n",
      "[474]\ttraining's binary_logloss: 0.458299\n",
      "[475]\ttraining's binary_logloss: 0.458041\n",
      "[476]\ttraining's binary_logloss: 0.45784\n",
      "[477]\ttraining's binary_logloss: 0.457646\n",
      "[478]\ttraining's binary_logloss: 0.457439\n",
      "[479]\ttraining's binary_logloss: 0.457233\n",
      "[480]\ttraining's binary_logloss: 0.457042\n",
      "[481]\ttraining's binary_logloss: 0.456863\n",
      "[482]\ttraining's binary_logloss: 0.456693\n",
      "[483]\ttraining's binary_logloss: 0.456486\n",
      "[484]\ttraining's binary_logloss: 0.456283\n",
      "[485]\ttraining's binary_logloss: 0.456092\n",
      "[486]\ttraining's binary_logloss: 0.455894\n",
      "[487]\ttraining's binary_logloss: 0.455694\n",
      "[488]\ttraining's binary_logloss: 0.455515\n",
      "[489]\ttraining's binary_logloss: 0.455329\n",
      "[490]\ttraining's binary_logloss: 0.455161\n",
      "[491]\ttraining's binary_logloss: 0.454955\n",
      "[492]\ttraining's binary_logloss: 0.454724\n",
      "[493]\ttraining's binary_logloss: 0.454507\n",
      "[494]\ttraining's binary_logloss: 0.454302\n",
      "[495]\ttraining's binary_logloss: 0.454099\n",
      "[496]\ttraining's binary_logloss: 0.453852\n",
      "[497]\ttraining's binary_logloss: 0.453581\n",
      "[498]\ttraining's binary_logloss: 0.4533\n",
      "[499]\ttraining's binary_logloss: 0.453027\n",
      "[500]\ttraining's binary_logloss: 0.45278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614504\n",
      "[2]\ttraining's binary_logloss: 0.613487\n",
      "[3]\ttraining's binary_logloss: 0.612503\n",
      "[4]\ttraining's binary_logloss: 0.611565\n",
      "[5]\ttraining's binary_logloss: 0.610787\n",
      "[6]\ttraining's binary_logloss: 0.609866\n",
      "[7]\ttraining's binary_logloss: 0.609111\n",
      "[8]\ttraining's binary_logloss: 0.608252\n",
      "[9]\ttraining's binary_logloss: 0.607411\n",
      "[10]\ttraining's binary_logloss: 0.606623\n",
      "[11]\ttraining's binary_logloss: 0.605867\n",
      "[12]\ttraining's binary_logloss: 0.605145\n",
      "[13]\ttraining's binary_logloss: 0.604523\n",
      "[14]\ttraining's binary_logloss: 0.603826\n",
      "[15]\ttraining's binary_logloss: 0.603181\n",
      "[16]\ttraining's binary_logloss: 0.602543\n",
      "[17]\ttraining's binary_logloss: 0.601996\n",
      "[18]\ttraining's binary_logloss: 0.601423\n",
      "[19]\ttraining's binary_logloss: 0.600956\n",
      "[20]\ttraining's binary_logloss: 0.600405\n",
      "[21]\ttraining's binary_logloss: 0.599883\n",
      "[22]\ttraining's binary_logloss: 0.599329\n",
      "[23]\ttraining's binary_logloss: 0.598798\n",
      "[24]\ttraining's binary_logloss: 0.598391\n",
      "[25]\ttraining's binary_logloss: 0.59791\n",
      "[26]\ttraining's binary_logloss: 0.597466\n",
      "[27]\ttraining's binary_logloss: 0.597089\n",
      "[28]\ttraining's binary_logloss: 0.596761\n",
      "[29]\ttraining's binary_logloss: 0.596417\n",
      "[30]\ttraining's binary_logloss: 0.596095\n",
      "[31]\ttraining's binary_logloss: 0.595664\n",
      "[32]\ttraining's binary_logloss: 0.595376\n",
      "[33]\ttraining's binary_logloss: 0.595109\n",
      "[34]\ttraining's binary_logloss: 0.594811\n",
      "[35]\ttraining's binary_logloss: 0.594572\n",
      "[36]\ttraining's binary_logloss: 0.594306\n",
      "[37]\ttraining's binary_logloss: 0.59409\n",
      "[38]\ttraining's binary_logloss: 0.593849\n",
      "[39]\ttraining's binary_logloss: 0.593591\n",
      "[40]\ttraining's binary_logloss: 0.593293\n",
      "[41]\ttraining's binary_logloss: 0.593045\n",
      "[42]\ttraining's binary_logloss: 0.592825\n",
      "[43]\ttraining's binary_logloss: 0.592593\n",
      "[44]\ttraining's binary_logloss: 0.592364\n",
      "[45]\ttraining's binary_logloss: 0.592165\n",
      "[46]\ttraining's binary_logloss: 0.591964\n",
      "[47]\ttraining's binary_logloss: 0.591732\n",
      "[48]\ttraining's binary_logloss: 0.591513\n",
      "[49]\ttraining's binary_logloss: 0.591308\n",
      "[50]\ttraining's binary_logloss: 0.591178\n",
      "[51]\ttraining's binary_logloss: 0.591043\n",
      "[52]\ttraining's binary_logloss: 0.590894\n",
      "[53]\ttraining's binary_logloss: 0.590745\n",
      "[54]\ttraining's binary_logloss: 0.590607\n",
      "[55]\ttraining's binary_logloss: 0.59052\n",
      "[56]\ttraining's binary_logloss: 0.590384\n",
      "[57]\ttraining's binary_logloss: 0.590315\n",
      "[58]\ttraining's binary_logloss: 0.590189\n",
      "[59]\ttraining's binary_logloss: 0.590133\n",
      "[60]\ttraining's binary_logloss: 0.590086\n",
      "[61]\ttraining's binary_logloss: 0.590009\n",
      "[62]\ttraining's binary_logloss: 0.58996\n",
      "[63]\ttraining's binary_logloss: 0.589859\n",
      "[64]\ttraining's binary_logloss: 0.589839\n",
      "[65]\ttraining's binary_logloss: 0.589809\n",
      "[66]\ttraining's binary_logloss: 0.589765\n",
      "[67]\ttraining's binary_logloss: 0.589724\n",
      "[68]\ttraining's binary_logloss: 0.589673\n",
      "[69]\ttraining's binary_logloss: 0.58965\n",
      "[70]\ttraining's binary_logloss: 0.589616\n",
      "[71]\ttraining's binary_logloss: 0.589569\n",
      "[72]\ttraining's binary_logloss: 0.589527\n",
      "[73]\ttraining's binary_logloss: 0.5895\n",
      "[74]\ttraining's binary_logloss: 0.589501\n",
      "[75]\ttraining's binary_logloss: 0.589473\n",
      "[76]\ttraining's binary_logloss: 0.589446\n",
      "[77]\ttraining's binary_logloss: 0.589387\n",
      "[78]\ttraining's binary_logloss: 0.589335\n",
      "[79]\ttraining's binary_logloss: 0.589295\n",
      "[80]\ttraining's binary_logloss: 0.58934\n",
      "[81]\ttraining's binary_logloss: 0.589289\n",
      "[82]\ttraining's binary_logloss: 0.589253\n",
      "[83]\ttraining's binary_logloss: 0.589207\n",
      "[84]\ttraining's binary_logloss: 0.589176\n",
      "[85]\ttraining's binary_logloss: 0.589145\n",
      "[86]\ttraining's binary_logloss: 0.589199\n",
      "[87]\ttraining's binary_logloss: 0.58926\n",
      "[88]\ttraining's binary_logloss: 0.589243\n",
      "[89]\ttraining's binary_logloss: 0.589273\n",
      "[90]\ttraining's binary_logloss: 0.589308\n",
      "[91]\ttraining's binary_logloss: 0.589307\n",
      "[92]\ttraining's binary_logloss: 0.589331\n",
      "[93]\ttraining's binary_logloss: 0.589309\n",
      "[94]\ttraining's binary_logloss: 0.589292\n",
      "[95]\ttraining's binary_logloss: 0.58928\n",
      "[96]\ttraining's binary_logloss: 0.589257\n",
      "[97]\ttraining's binary_logloss: 0.589244\n",
      "[98]\ttraining's binary_logloss: 0.589252\n",
      "[99]\ttraining's binary_logloss: 0.589246\n",
      "[100]\ttraining's binary_logloss: 0.589244\n",
      "[101]\ttraining's binary_logloss: 0.58929\n",
      "[102]\ttraining's binary_logloss: 0.589336\n",
      "[103]\ttraining's binary_logloss: 0.589399\n",
      "[104]\ttraining's binary_logloss: 0.58945\n",
      "[105]\ttraining's binary_logloss: 0.589508\n",
      "[106]\ttraining's binary_logloss: 0.589506\n",
      "[107]\ttraining's binary_logloss: 0.589511\n",
      "[108]\ttraining's binary_logloss: 0.589518\n",
      "[109]\ttraining's binary_logloss: 0.58952\n",
      "[110]\ttraining's binary_logloss: 0.589531\n",
      "[111]\ttraining's binary_logloss: 0.589559\n",
      "[112]\ttraining's binary_logloss: 0.589595\n",
      "[113]\ttraining's binary_logloss: 0.589624\n",
      "[114]\ttraining's binary_logloss: 0.589655\n",
      "[115]\ttraining's binary_logloss: 0.589696\n",
      "[116]\ttraining's binary_logloss: 0.589736\n",
      "[117]\ttraining's binary_logloss: 0.589791\n",
      "[118]\ttraining's binary_logloss: 0.589899\n",
      "[119]\ttraining's binary_logloss: 0.589955\n",
      "[120]\ttraining's binary_logloss: 0.590014\n",
      "[121]\ttraining's binary_logloss: 0.590071\n",
      "[122]\ttraining's binary_logloss: 0.590113\n",
      "[123]\ttraining's binary_logloss: 0.590153\n",
      "[124]\ttraining's binary_logloss: 0.590214\n",
      "[125]\ttraining's binary_logloss: 0.590272\n",
      "[126]\ttraining's binary_logloss: 0.590346\n",
      "[127]\ttraining's binary_logloss: 0.590399\n",
      "[128]\ttraining's binary_logloss: 0.590476\n",
      "[129]\ttraining's binary_logloss: 0.59053\n",
      "[130]\ttraining's binary_logloss: 0.59059\n",
      "[131]\ttraining's binary_logloss: 0.590613\n",
      "[132]\ttraining's binary_logloss: 0.590638\n",
      "[133]\ttraining's binary_logloss: 0.590673\n",
      "[134]\ttraining's binary_logloss: 0.590709\n",
      "[135]\ttraining's binary_logloss: 0.590762\n",
      "[136]\ttraining's binary_logloss: 0.59077\n",
      "[137]\ttraining's binary_logloss: 0.590777\n",
      "[138]\ttraining's binary_logloss: 0.590794\n",
      "[139]\ttraining's binary_logloss: 0.590807\n",
      "[140]\ttraining's binary_logloss: 0.590851\n",
      "[141]\ttraining's binary_logloss: 0.590912\n",
      "[142]\ttraining's binary_logloss: 0.590976\n",
      "[143]\ttraining's binary_logloss: 0.591041\n",
      "[144]\ttraining's binary_logloss: 0.591098\n",
      "[145]\ttraining's binary_logloss: 0.591165\n",
      "[146]\ttraining's binary_logloss: 0.591192\n",
      "[147]\ttraining's binary_logloss: 0.59125\n",
      "[148]\ttraining's binary_logloss: 0.59126\n",
      "[149]\ttraining's binary_logloss: 0.591273\n",
      "[150]\ttraining's binary_logloss: 0.591288\n",
      "[151]\ttraining's binary_logloss: 0.591293\n",
      "[152]\ttraining's binary_logloss: 0.591287\n",
      "[153]\ttraining's binary_logloss: 0.591316\n",
      "[154]\ttraining's binary_logloss: 0.591325\n",
      "[155]\ttraining's binary_logloss: 0.591342\n",
      "[156]\ttraining's binary_logloss: 0.591409\n",
      "[157]\ttraining's binary_logloss: 0.591478\n",
      "[158]\ttraining's binary_logloss: 0.591551\n",
      "[159]\ttraining's binary_logloss: 0.591629\n",
      "[160]\ttraining's binary_logloss: 0.5917\n",
      "[161]\ttraining's binary_logloss: 0.591717\n",
      "[162]\ttraining's binary_logloss: 0.591714\n",
      "[163]\ttraining's binary_logloss: 0.591714\n",
      "[164]\ttraining's binary_logloss: 0.591704\n",
      "[165]\ttraining's binary_logloss: 0.591707\n",
      "[166]\ttraining's binary_logloss: 0.591714\n",
      "[167]\ttraining's binary_logloss: 0.591731\n",
      "[168]\ttraining's binary_logloss: 0.591763\n",
      "[169]\ttraining's binary_logloss: 0.591782\n",
      "[170]\ttraining's binary_logloss: 0.591817\n",
      "[171]\ttraining's binary_logloss: 0.59185\n",
      "[172]\ttraining's binary_logloss: 0.591886\n",
      "[173]\ttraining's binary_logloss: 0.591926\n",
      "[174]\ttraining's binary_logloss: 0.591928\n",
      "[175]\ttraining's binary_logloss: 0.591953\n",
      "[176]\ttraining's binary_logloss: 0.592012\n",
      "[177]\ttraining's binary_logloss: 0.592081\n",
      "[178]\ttraining's binary_logloss: 0.59214\n",
      "[179]\ttraining's binary_logloss: 0.592169\n",
      "[180]\ttraining's binary_logloss: 0.592198\n",
      "[181]\ttraining's binary_logloss: 0.592195\n",
      "[182]\ttraining's binary_logloss: 0.592194\n",
      "[183]\ttraining's binary_logloss: 0.592198\n",
      "[184]\ttraining's binary_logloss: 0.592227\n",
      "[185]\ttraining's binary_logloss: 0.592221\n",
      "[186]\ttraining's binary_logloss: 0.592229\n",
      "[187]\ttraining's binary_logloss: 0.592219\n",
      "[188]\ttraining's binary_logloss: 0.592239\n",
      "[189]\ttraining's binary_logloss: 0.592251\n",
      "[190]\ttraining's binary_logloss: 0.592263\n",
      "[191]\ttraining's binary_logloss: 0.592279\n",
      "[192]\ttraining's binary_logloss: 0.592297\n",
      "[193]\ttraining's binary_logloss: 0.592321\n",
      "[194]\ttraining's binary_logloss: 0.592342\n",
      "[195]\ttraining's binary_logloss: 0.592365\n",
      "[196]\ttraining's binary_logloss: 0.592385\n",
      "[197]\ttraining's binary_logloss: 0.59241\n",
      "[198]\ttraining's binary_logloss: 0.592432\n",
      "[199]\ttraining's binary_logloss: 0.592442\n",
      "[200]\ttraining's binary_logloss: 0.592444\n",
      "[201]\ttraining's binary_logloss: 0.592454\n",
      "[202]\ttraining's binary_logloss: 0.59247\n",
      "[203]\ttraining's binary_logloss: 0.592489\n",
      "[204]\ttraining's binary_logloss: 0.59251\n",
      "[205]\ttraining's binary_logloss: 0.592526\n",
      "[206]\ttraining's binary_logloss: 0.592554\n",
      "[207]\ttraining's binary_logloss: 0.592576\n",
      "[208]\ttraining's binary_logloss: 0.592595\n",
      "[209]\ttraining's binary_logloss: 0.59261\n",
      "[210]\ttraining's binary_logloss: 0.592619\n",
      "[211]\ttraining's binary_logloss: 0.592627\n",
      "[212]\ttraining's binary_logloss: 0.592645\n",
      "[213]\ttraining's binary_logloss: 0.592654\n",
      "[214]\ttraining's binary_logloss: 0.592664\n",
      "[215]\ttraining's binary_logloss: 0.592659\n",
      "[216]\ttraining's binary_logloss: 0.592636\n",
      "[217]\ttraining's binary_logloss: 0.59263\n",
      "[218]\ttraining's binary_logloss: 0.592618\n",
      "[219]\ttraining's binary_logloss: 0.592612\n",
      "[220]\ttraining's binary_logloss: 0.592606\n",
      "[221]\ttraining's binary_logloss: 0.592601\n",
      "[222]\ttraining's binary_logloss: 0.592604\n",
      "[223]\ttraining's binary_logloss: 0.5926\n",
      "[224]\ttraining's binary_logloss: 0.592581\n",
      "[225]\ttraining's binary_logloss: 0.592572\n",
      "[226]\ttraining's binary_logloss: 0.592584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[227]\ttraining's binary_logloss: 0.592592\n",
      "[228]\ttraining's binary_logloss: 0.592607\n",
      "[229]\ttraining's binary_logloss: 0.592614\n",
      "[230]\ttraining's binary_logloss: 0.592628\n",
      "[231]\ttraining's binary_logloss: 0.592593\n",
      "[232]\ttraining's binary_logloss: 0.592564\n",
      "[233]\ttraining's binary_logloss: 0.592542\n",
      "[234]\ttraining's binary_logloss: 0.592517\n",
      "[235]\ttraining's binary_logloss: 0.592493\n",
      "[236]\ttraining's binary_logloss: 0.592462\n",
      "[237]\ttraining's binary_logloss: 0.592419\n",
      "[238]\ttraining's binary_logloss: 0.592378\n",
      "[239]\ttraining's binary_logloss: 0.592342\n",
      "[240]\ttraining's binary_logloss: 0.592309\n",
      "[241]\ttraining's binary_logloss: 0.592299\n",
      "[242]\ttraining's binary_logloss: 0.592291\n",
      "[243]\ttraining's binary_logloss: 0.59227\n",
      "[244]\ttraining's binary_logloss: 0.592261\n",
      "[245]\ttraining's binary_logloss: 0.592256\n",
      "[246]\ttraining's binary_logloss: 0.592298\n",
      "[247]\ttraining's binary_logloss: 0.592342\n",
      "[248]\ttraining's binary_logloss: 0.592363\n",
      "[249]\ttraining's binary_logloss: 0.592377\n",
      "[250]\ttraining's binary_logloss: 0.592421\n",
      "[251]\ttraining's binary_logloss: 0.592396\n",
      "[252]\ttraining's binary_logloss: 0.592348\n",
      "[253]\ttraining's binary_logloss: 0.592314\n",
      "[254]\ttraining's binary_logloss: 0.592278\n",
      "[255]\ttraining's binary_logloss: 0.592245\n",
      "[256]\ttraining's binary_logloss: 0.592222\n",
      "[257]\ttraining's binary_logloss: 0.592208\n",
      "[258]\ttraining's binary_logloss: 0.592197\n",
      "[259]\ttraining's binary_logloss: 0.592179\n",
      "[260]\ttraining's binary_logloss: 0.592147\n",
      "[261]\ttraining's binary_logloss: 0.592113\n",
      "[262]\ttraining's binary_logloss: 0.592098\n",
      "[263]\ttraining's binary_logloss: 0.592066\n",
      "[264]\ttraining's binary_logloss: 0.59203\n",
      "[265]\ttraining's binary_logloss: 0.591993\n",
      "[266]\ttraining's binary_logloss: 0.591994\n",
      "[267]\ttraining's binary_logloss: 0.591998\n",
      "[268]\ttraining's binary_logloss: 0.59201\n",
      "[269]\ttraining's binary_logloss: 0.592012\n",
      "[270]\ttraining's binary_logloss: 0.592024\n",
      "[271]\ttraining's binary_logloss: 0.591975\n",
      "[272]\ttraining's binary_logloss: 0.591937\n",
      "[273]\ttraining's binary_logloss: 0.591896\n",
      "[274]\ttraining's binary_logloss: 0.59185\n",
      "[275]\ttraining's binary_logloss: 0.591815\n",
      "[276]\ttraining's binary_logloss: 0.591766\n",
      "[277]\ttraining's binary_logloss: 0.591717\n",
      "[278]\ttraining's binary_logloss: 0.591677\n",
      "[279]\ttraining's binary_logloss: 0.591646\n",
      "[280]\ttraining's binary_logloss: 0.591603\n",
      "[281]\ttraining's binary_logloss: 0.591584\n",
      "[282]\ttraining's binary_logloss: 0.591569\n",
      "[283]\ttraining's binary_logloss: 0.591544\n",
      "[284]\ttraining's binary_logloss: 0.591521\n",
      "[285]\ttraining's binary_logloss: 0.591506\n",
      "[286]\ttraining's binary_logloss: 0.591455\n",
      "[287]\ttraining's binary_logloss: 0.591407\n",
      "[288]\ttraining's binary_logloss: 0.591373\n",
      "[289]\ttraining's binary_logloss: 0.591323\n",
      "[290]\ttraining's binary_logloss: 0.591272\n",
      "[291]\ttraining's binary_logloss: 0.591216\n",
      "[292]\ttraining's binary_logloss: 0.591159\n",
      "[293]\ttraining's binary_logloss: 0.591111\n",
      "[294]\ttraining's binary_logloss: 0.591061\n",
      "[295]\ttraining's binary_logloss: 0.591015\n",
      "[296]\ttraining's binary_logloss: 0.590986\n",
      "[297]\ttraining's binary_logloss: 0.590957\n",
      "[298]\ttraining's binary_logloss: 0.590927\n",
      "[299]\ttraining's binary_logloss: 0.590902\n",
      "[300]\ttraining's binary_logloss: 0.590877\n",
      "[301]\ttraining's binary_logloss: 0.590827\n",
      "[302]\ttraining's binary_logloss: 0.590768\n",
      "[303]\ttraining's binary_logloss: 0.59072\n",
      "[304]\ttraining's binary_logloss: 0.590668\n",
      "[305]\ttraining's binary_logloss: 0.590614\n",
      "[306]\ttraining's binary_logloss: 0.590597\n",
      "[307]\ttraining's binary_logloss: 0.590561\n",
      "[308]\ttraining's binary_logloss: 0.590538\n",
      "[309]\ttraining's binary_logloss: 0.590502\n",
      "[310]\ttraining's binary_logloss: 0.590456\n",
      "[311]\ttraining's binary_logloss: 0.590441\n",
      "[312]\ttraining's binary_logloss: 0.590431\n",
      "[313]\ttraining's binary_logloss: 0.590422\n",
      "[314]\ttraining's binary_logloss: 0.590396\n",
      "[315]\ttraining's binary_logloss: 0.590384\n",
      "[316]\ttraining's binary_logloss: 0.590314\n",
      "[317]\ttraining's binary_logloss: 0.590235\n",
      "[318]\ttraining's binary_logloss: 0.590174\n",
      "[319]\ttraining's binary_logloss: 0.590115\n",
      "[320]\ttraining's binary_logloss: 0.590033\n",
      "[321]\ttraining's binary_logloss: 0.589968\n",
      "[322]\ttraining's binary_logloss: 0.589898\n",
      "[323]\ttraining's binary_logloss: 0.589824\n",
      "[324]\ttraining's binary_logloss: 0.589754\n",
      "[325]\ttraining's binary_logloss: 0.589695\n",
      "[326]\ttraining's binary_logloss: 0.589637\n",
      "[327]\ttraining's binary_logloss: 0.589579\n",
      "[328]\ttraining's binary_logloss: 0.589518\n",
      "[329]\ttraining's binary_logloss: 0.589473\n",
      "[330]\ttraining's binary_logloss: 0.589423\n",
      "[331]\ttraining's binary_logloss: 0.589343\n",
      "[332]\ttraining's binary_logloss: 0.58928\n",
      "[333]\ttraining's binary_logloss: 0.58921\n",
      "[334]\ttraining's binary_logloss: 0.589132\n",
      "[335]\ttraining's binary_logloss: 0.589053\n",
      "[336]\ttraining's binary_logloss: 0.589016\n",
      "[337]\ttraining's binary_logloss: 0.588984\n",
      "[338]\ttraining's binary_logloss: 0.58895\n",
      "[339]\ttraining's binary_logloss: 0.588913\n",
      "[340]\ttraining's binary_logloss: 0.588873\n",
      "[341]\ttraining's binary_logloss: 0.588854\n",
      "[342]\ttraining's binary_logloss: 0.588831\n",
      "[343]\ttraining's binary_logloss: 0.588806\n",
      "[344]\ttraining's binary_logloss: 0.588788\n",
      "[345]\ttraining's binary_logloss: 0.588771\n",
      "[346]\ttraining's binary_logloss: 0.588696\n",
      "[347]\ttraining's binary_logloss: 0.588624\n",
      "[348]\ttraining's binary_logloss: 0.588572\n",
      "[349]\ttraining's binary_logloss: 0.588537\n",
      "[350]\ttraining's binary_logloss: 0.58847\n",
      "[351]\ttraining's binary_logloss: 0.588399\n",
      "[352]\ttraining's binary_logloss: 0.588322\n",
      "[353]\ttraining's binary_logloss: 0.588258\n",
      "[354]\ttraining's binary_logloss: 0.588194\n",
      "[355]\ttraining's binary_logloss: 0.588119\n",
      "[356]\ttraining's binary_logloss: 0.588032\n",
      "[357]\ttraining's binary_logloss: 0.587962\n",
      "[358]\ttraining's binary_logloss: 0.587877\n",
      "[359]\ttraining's binary_logloss: 0.587796\n",
      "[360]\ttraining's binary_logloss: 0.587713\n",
      "[361]\ttraining's binary_logloss: 0.587601\n",
      "[362]\ttraining's binary_logloss: 0.587492\n",
      "[363]\ttraining's binary_logloss: 0.587391\n",
      "[364]\ttraining's binary_logloss: 0.587278\n",
      "[365]\ttraining's binary_logloss: 0.587175\n",
      "[366]\ttraining's binary_logloss: 0.58713\n",
      "[367]\ttraining's binary_logloss: 0.587087\n",
      "[368]\ttraining's binary_logloss: 0.587045\n",
      "[369]\ttraining's binary_logloss: 0.587006\n",
      "[370]\ttraining's binary_logloss: 0.586943\n",
      "[371]\ttraining's binary_logloss: 0.586897\n",
      "[372]\ttraining's binary_logloss: 0.586866\n",
      "[373]\ttraining's binary_logloss: 0.586823\n",
      "[374]\ttraining's binary_logloss: 0.586785\n",
      "[375]\ttraining's binary_logloss: 0.586743\n",
      "[376]\ttraining's binary_logloss: 0.586669\n",
      "[377]\ttraining's binary_logloss: 0.586597\n",
      "[378]\ttraining's binary_logloss: 0.586545\n",
      "[379]\ttraining's binary_logloss: 0.586475\n",
      "[380]\ttraining's binary_logloss: 0.586407\n",
      "[381]\ttraining's binary_logloss: 0.586396\n",
      "[382]\ttraining's binary_logloss: 0.586363\n",
      "[383]\ttraining's binary_logloss: 0.586338\n",
      "[384]\ttraining's binary_logloss: 0.586326\n",
      "[385]\ttraining's binary_logloss: 0.586313\n",
      "[386]\ttraining's binary_logloss: 0.586208\n",
      "[387]\ttraining's binary_logloss: 0.586093\n",
      "[388]\ttraining's binary_logloss: 0.585961\n",
      "[389]\ttraining's binary_logloss: 0.585835\n",
      "[390]\ttraining's binary_logloss: 0.585705\n",
      "[391]\ttraining's binary_logloss: 0.58564\n",
      "[392]\ttraining's binary_logloss: 0.585564\n",
      "[393]\ttraining's binary_logloss: 0.585491\n",
      "[394]\ttraining's binary_logloss: 0.585418\n",
      "[395]\ttraining's binary_logloss: 0.585346\n",
      "[396]\ttraining's binary_logloss: 0.585281\n",
      "[397]\ttraining's binary_logloss: 0.585207\n",
      "[398]\ttraining's binary_logloss: 0.585112\n",
      "[399]\ttraining's binary_logloss: 0.585052\n",
      "[400]\ttraining's binary_logloss: 0.584974\n",
      "[401]\ttraining's binary_logloss: 0.584875\n",
      "[402]\ttraining's binary_logloss: 0.58479\n",
      "[403]\ttraining's binary_logloss: 0.584718\n",
      "[404]\ttraining's binary_logloss: 0.584596\n",
      "[405]\ttraining's binary_logloss: 0.584483\n",
      "[406]\ttraining's binary_logloss: 0.584429\n",
      "[407]\ttraining's binary_logloss: 0.584373\n",
      "[408]\ttraining's binary_logloss: 0.584313\n",
      "[409]\ttraining's binary_logloss: 0.584247\n",
      "[410]\ttraining's binary_logloss: 0.584195\n",
      "[411]\ttraining's binary_logloss: 0.584102\n",
      "[412]\ttraining's binary_logloss: 0.583996\n",
      "[413]\ttraining's binary_logloss: 0.583896\n",
      "[414]\ttraining's binary_logloss: 0.5838\n",
      "[415]\ttraining's binary_logloss: 0.583683\n",
      "[416]\ttraining's binary_logloss: 0.58361\n",
      "[417]\ttraining's binary_logloss: 0.583524\n",
      "[418]\ttraining's binary_logloss: 0.583433\n",
      "[419]\ttraining's binary_logloss: 0.583364\n",
      "[420]\ttraining's binary_logloss: 0.583279\n",
      "[421]\ttraining's binary_logloss: 0.583249\n",
      "[422]\ttraining's binary_logloss: 0.58322\n",
      "[423]\ttraining's binary_logloss: 0.583192\n",
      "[424]\ttraining's binary_logloss: 0.583163\n",
      "[425]\ttraining's binary_logloss: 0.583137\n",
      "[426]\ttraining's binary_logloss: 0.583093\n",
      "[427]\ttraining's binary_logloss: 0.583039\n",
      "[428]\ttraining's binary_logloss: 0.582987\n",
      "[429]\ttraining's binary_logloss: 0.582939\n",
      "[430]\ttraining's binary_logloss: 0.582897\n",
      "[431]\ttraining's binary_logloss: 0.582823\n",
      "[432]\ttraining's binary_logloss: 0.582752\n",
      "[433]\ttraining's binary_logloss: 0.582659\n",
      "[434]\ttraining's binary_logloss: 0.58255\n",
      "[435]\ttraining's binary_logloss: 0.582474\n",
      "[436]\ttraining's binary_logloss: 0.582411\n",
      "[437]\ttraining's binary_logloss: 0.582357\n",
      "[438]\ttraining's binary_logloss: 0.582319\n",
      "[439]\ttraining's binary_logloss: 0.582266\n",
      "[440]\ttraining's binary_logloss: 0.582221\n",
      "[441]\ttraining's binary_logloss: 0.582144\n",
      "[442]\ttraining's binary_logloss: 0.582069\n",
      "[443]\ttraining's binary_logloss: 0.582005\n",
      "[444]\ttraining's binary_logloss: 0.581923\n",
      "[445]\ttraining's binary_logloss: 0.581853\n",
      "[446]\ttraining's binary_logloss: 0.581787\n",
      "[447]\ttraining's binary_logloss: 0.581716\n",
      "[448]\ttraining's binary_logloss: 0.581652\n",
      "[449]\ttraining's binary_logloss: 0.581599\n",
      "[450]\ttraining's binary_logloss: 0.581511\n",
      "[451]\ttraining's binary_logloss: 0.581456\n",
      "[452]\ttraining's binary_logloss: 0.581391\n",
      "[453]\ttraining's binary_logloss: 0.581349\n",
      "[454]\ttraining's binary_logloss: 0.581283\n",
      "[455]\ttraining's binary_logloss: 0.581229\n",
      "[456]\ttraining's binary_logloss: 0.581162\n",
      "[457]\ttraining's binary_logloss: 0.581095\n",
      "[458]\ttraining's binary_logloss: 0.581024\n",
      "[459]\ttraining's binary_logloss: 0.580957\n",
      "[460]\ttraining's binary_logloss: 0.580889\n",
      "[461]\ttraining's binary_logloss: 0.5808\n",
      "[462]\ttraining's binary_logloss: 0.580718\n",
      "[463]\ttraining's binary_logloss: 0.580625\n",
      "[464]\ttraining's binary_logloss: 0.580535\n",
      "[465]\ttraining's binary_logloss: 0.580453\n",
      "[466]\ttraining's binary_logloss: 0.580382\n",
      "[467]\ttraining's binary_logloss: 0.580317\n",
      "[468]\ttraining's binary_logloss: 0.580253\n",
      "[469]\ttraining's binary_logloss: 0.580202\n",
      "[470]\ttraining's binary_logloss: 0.580137\n",
      "[471]\ttraining's binary_logloss: 0.580093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[472]\ttraining's binary_logloss: 0.580047\n",
      "[473]\ttraining's binary_logloss: 0.580006\n",
      "[474]\ttraining's binary_logloss: 0.579966\n",
      "[475]\ttraining's binary_logloss: 0.579927\n",
      "[476]\ttraining's binary_logloss: 0.579869\n",
      "[477]\ttraining's binary_logloss: 0.579805\n",
      "[478]\ttraining's binary_logloss: 0.579739\n",
      "[479]\ttraining's binary_logloss: 0.579685\n",
      "[480]\ttraining's binary_logloss: 0.579628\n",
      "[481]\ttraining's binary_logloss: 0.579568\n",
      "[482]\ttraining's binary_logloss: 0.579509\n",
      "[483]\ttraining's binary_logloss: 0.579446\n",
      "[484]\ttraining's binary_logloss: 0.579389\n",
      "[485]\ttraining's binary_logloss: 0.579318\n",
      "[486]\ttraining's binary_logloss: 0.579214\n",
      "[487]\ttraining's binary_logloss: 0.579118\n",
      "[488]\ttraining's binary_logloss: 0.579029\n",
      "[489]\ttraining's binary_logloss: 0.578932\n",
      "[490]\ttraining's binary_logloss: 0.578839\n",
      "[491]\ttraining's binary_logloss: 0.578797\n",
      "[492]\ttraining's binary_logloss: 0.578757\n",
      "[493]\ttraining's binary_logloss: 0.578714\n",
      "[494]\ttraining's binary_logloss: 0.578677\n",
      "[495]\ttraining's binary_logloss: 0.578639\n",
      "[496]\ttraining's binary_logloss: 0.578527\n",
      "[497]\ttraining's binary_logloss: 0.57844\n",
      "[498]\ttraining's binary_logloss: 0.578352\n",
      "[499]\ttraining's binary_logloss: 0.578265\n",
      "[500]\ttraining's binary_logloss: 0.578182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614062\n",
      "[2]\ttraining's binary_logloss: 0.612913\n",
      "[3]\ttraining's binary_logloss: 0.611767\n",
      "[4]\ttraining's binary_logloss: 0.610722\n",
      "[5]\ttraining's binary_logloss: 0.609925\n",
      "[6]\ttraining's binary_logloss: 0.609103\n",
      "[7]\ttraining's binary_logloss: 0.608201\n",
      "[8]\ttraining's binary_logloss: 0.607339\n",
      "[9]\ttraining's binary_logloss: 0.606484\n",
      "[10]\ttraining's binary_logloss: 0.605762\n",
      "[11]\ttraining's binary_logloss: 0.60508\n",
      "[12]\ttraining's binary_logloss: 0.604287\n",
      "[13]\ttraining's binary_logloss: 0.603512\n",
      "[14]\ttraining's binary_logloss: 0.602879\n",
      "[15]\ttraining's binary_logloss: 0.602175\n",
      "[16]\ttraining's binary_logloss: 0.601463\n",
      "[17]\ttraining's binary_logloss: 0.600805\n",
      "[18]\ttraining's binary_logloss: 0.60015\n",
      "[19]\ttraining's binary_logloss: 0.599524\n",
      "[20]\ttraining's binary_logloss: 0.598955\n",
      "[21]\ttraining's binary_logloss: 0.598359\n",
      "[22]\ttraining's binary_logloss: 0.59779\n",
      "[23]\ttraining's binary_logloss: 0.597248\n",
      "[24]\ttraining's binary_logloss: 0.596751\n",
      "[25]\ttraining's binary_logloss: 0.596253\n",
      "[26]\ttraining's binary_logloss: 0.595847\n",
      "[27]\ttraining's binary_logloss: 0.595471\n",
      "[28]\ttraining's binary_logloss: 0.595102\n",
      "[29]\ttraining's binary_logloss: 0.594742\n",
      "[30]\ttraining's binary_logloss: 0.59439\n",
      "[31]\ttraining's binary_logloss: 0.59405\n",
      "[32]\ttraining's binary_logloss: 0.593685\n",
      "[33]\ttraining's binary_logloss: 0.593338\n",
      "[34]\ttraining's binary_logloss: 0.593009\n",
      "[35]\ttraining's binary_logloss: 0.592691\n",
      "[36]\ttraining's binary_logloss: 0.592304\n",
      "[37]\ttraining's binary_logloss: 0.592002\n",
      "[38]\ttraining's binary_logloss: 0.59167\n",
      "[39]\ttraining's binary_logloss: 0.591406\n",
      "[40]\ttraining's binary_logloss: 0.591096\n",
      "[41]\ttraining's binary_logloss: 0.590848\n",
      "[42]\ttraining's binary_logloss: 0.590596\n",
      "[43]\ttraining's binary_logloss: 0.590362\n",
      "[44]\ttraining's binary_logloss: 0.590145\n",
      "[45]\ttraining's binary_logloss: 0.589896\n",
      "[46]\ttraining's binary_logloss: 0.589727\n",
      "[47]\ttraining's binary_logloss: 0.589496\n",
      "[48]\ttraining's binary_logloss: 0.589271\n",
      "[49]\ttraining's binary_logloss: 0.589116\n",
      "[50]\ttraining's binary_logloss: 0.58891\n",
      "[51]\ttraining's binary_logloss: 0.588711\n",
      "[52]\ttraining's binary_logloss: 0.588602\n",
      "[53]\ttraining's binary_logloss: 0.588438\n",
      "[54]\ttraining's binary_logloss: 0.588196\n",
      "[55]\ttraining's binary_logloss: 0.588125\n",
      "[56]\ttraining's binary_logloss: 0.587927\n",
      "[57]\ttraining's binary_logloss: 0.587734\n",
      "[58]\ttraining's binary_logloss: 0.587607\n",
      "[59]\ttraining's binary_logloss: 0.587529\n",
      "[60]\ttraining's binary_logloss: 0.587337\n",
      "[61]\ttraining's binary_logloss: 0.587163\n",
      "[62]\ttraining's binary_logloss: 0.587048\n",
      "[63]\ttraining's binary_logloss: 0.586938\n",
      "[64]\ttraining's binary_logloss: 0.586843\n",
      "[65]\ttraining's binary_logloss: 0.586751\n",
      "[66]\ttraining's binary_logloss: 0.586655\n",
      "[67]\ttraining's binary_logloss: 0.58662\n",
      "[68]\ttraining's binary_logloss: 0.586528\n",
      "[69]\ttraining's binary_logloss: 0.586442\n",
      "[70]\ttraining's binary_logloss: 0.586404\n",
      "[71]\ttraining's binary_logloss: 0.58636\n",
      "[72]\ttraining's binary_logloss: 0.586297\n",
      "[73]\ttraining's binary_logloss: 0.586241\n",
      "[74]\ttraining's binary_logloss: 0.586221\n",
      "[75]\ttraining's binary_logloss: 0.586145\n",
      "[76]\ttraining's binary_logloss: 0.586118\n",
      "[77]\ttraining's binary_logloss: 0.586044\n",
      "[78]\ttraining's binary_logloss: 0.586074\n",
      "[79]\ttraining's binary_logloss: 0.585943\n",
      "[80]\ttraining's binary_logloss: 0.585853\n",
      "[81]\ttraining's binary_logloss: 0.585775\n",
      "[82]\ttraining's binary_logloss: 0.585768\n",
      "[83]\ttraining's binary_logloss: 0.5857\n",
      "[84]\ttraining's binary_logloss: 0.585704\n",
      "[85]\ttraining's binary_logloss: 0.585631\n",
      "[86]\ttraining's binary_logloss: 0.585628\n",
      "[87]\ttraining's binary_logloss: 0.585585\n",
      "[88]\ttraining's binary_logloss: 0.585502\n",
      "[89]\ttraining's binary_logloss: 0.585438\n",
      "[90]\ttraining's binary_logloss: 0.585419\n",
      "[91]\ttraining's binary_logloss: 0.585422\n",
      "[92]\ttraining's binary_logloss: 0.585428\n",
      "[93]\ttraining's binary_logloss: 0.585437\n",
      "[94]\ttraining's binary_logloss: 0.585426\n",
      "[95]\ttraining's binary_logloss: 0.585444\n",
      "[96]\ttraining's binary_logloss: 0.585457\n",
      "[97]\ttraining's binary_logloss: 0.585473\n",
      "[98]\ttraining's binary_logloss: 0.58549\n",
      "[99]\ttraining's binary_logloss: 0.585518\n",
      "[100]\ttraining's binary_logloss: 0.585548\n",
      "[101]\ttraining's binary_logloss: 0.58557\n",
      "[102]\ttraining's binary_logloss: 0.585603\n",
      "[103]\ttraining's binary_logloss: 0.585639\n",
      "[104]\ttraining's binary_logloss: 0.585692\n",
      "[105]\ttraining's binary_logloss: 0.5857\n",
      "[106]\ttraining's binary_logloss: 0.585681\n",
      "[107]\ttraining's binary_logloss: 0.585669\n",
      "[108]\ttraining's binary_logloss: 0.58566\n",
      "[109]\ttraining's binary_logloss: 0.585655\n",
      "[110]\ttraining's binary_logloss: 0.585645\n",
      "[111]\ttraining's binary_logloss: 0.585697\n",
      "[112]\ttraining's binary_logloss: 0.585753\n",
      "[113]\ttraining's binary_logloss: 0.58581\n",
      "[114]\ttraining's binary_logloss: 0.58587\n",
      "[115]\ttraining's binary_logloss: 0.585953\n",
      "[116]\ttraining's binary_logloss: 0.585968\n",
      "[117]\ttraining's binary_logloss: 0.585983\n",
      "[118]\ttraining's binary_logloss: 0.586034\n",
      "[119]\ttraining's binary_logloss: 0.586114\n",
      "[120]\ttraining's binary_logloss: 0.586137\n",
      "[121]\ttraining's binary_logloss: 0.586134\n",
      "[122]\ttraining's binary_logloss: 0.586131\n",
      "[123]\ttraining's binary_logloss: 0.586121\n",
      "[124]\ttraining's binary_logloss: 0.586122\n",
      "[125]\ttraining's binary_logloss: 0.586121\n",
      "[126]\ttraining's binary_logloss: 0.586106\n",
      "[127]\ttraining's binary_logloss: 0.5861\n",
      "[128]\ttraining's binary_logloss: 0.586081\n",
      "[129]\ttraining's binary_logloss: 0.586082\n",
      "[130]\ttraining's binary_logloss: 0.586065\n",
      "[131]\ttraining's binary_logloss: 0.586068\n",
      "[132]\ttraining's binary_logloss: 0.586083\n",
      "[133]\ttraining's binary_logloss: 0.586106\n",
      "[134]\ttraining's binary_logloss: 0.586133\n",
      "[135]\ttraining's binary_logloss: 0.586135\n",
      "[136]\ttraining's binary_logloss: 0.586152\n",
      "[137]\ttraining's binary_logloss: 0.586172\n",
      "[138]\ttraining's binary_logloss: 0.586197\n",
      "[139]\ttraining's binary_logloss: 0.586214\n",
      "[140]\ttraining's binary_logloss: 0.586249\n",
      "[141]\ttraining's binary_logloss: 0.586333\n",
      "[142]\ttraining's binary_logloss: 0.586318\n",
      "[143]\ttraining's binary_logloss: 0.586314\n",
      "[144]\ttraining's binary_logloss: 0.586303\n",
      "[145]\ttraining's binary_logloss: 0.586317\n",
      "[146]\ttraining's binary_logloss: 0.586358\n",
      "[147]\ttraining's binary_logloss: 0.586402\n",
      "[148]\ttraining's binary_logloss: 0.586425\n",
      "[149]\ttraining's binary_logloss: 0.586442\n",
      "[150]\ttraining's binary_logloss: 0.586489\n",
      "[151]\ttraining's binary_logloss: 0.586488\n",
      "[152]\ttraining's binary_logloss: 0.586486\n",
      "[153]\ttraining's binary_logloss: 0.586487\n",
      "[154]\ttraining's binary_logloss: 0.586473\n",
      "[155]\ttraining's binary_logloss: 0.586477\n",
      "[156]\ttraining's binary_logloss: 0.586498\n",
      "[157]\ttraining's binary_logloss: 0.586518\n",
      "[158]\ttraining's binary_logloss: 0.586558\n",
      "[159]\ttraining's binary_logloss: 0.586581\n",
      "[160]\ttraining's binary_logloss: 0.586608\n",
      "[161]\ttraining's binary_logloss: 0.586587\n",
      "[162]\ttraining's binary_logloss: 0.58658\n",
      "[163]\ttraining's binary_logloss: 0.586564\n",
      "[164]\ttraining's binary_logloss: 0.58656\n",
      "[165]\ttraining's binary_logloss: 0.586548\n",
      "[166]\ttraining's binary_logloss: 0.586514\n",
      "[167]\ttraining's binary_logloss: 0.586503\n",
      "[168]\ttraining's binary_logloss: 0.586477\n",
      "[169]\ttraining's binary_logloss: 0.586456\n",
      "[170]\ttraining's binary_logloss: 0.586473\n",
      "[171]\ttraining's binary_logloss: 0.586491\n",
      "[172]\ttraining's binary_logloss: 0.586475\n",
      "[173]\ttraining's binary_logloss: 0.586506\n",
      "[174]\ttraining's binary_logloss: 0.586503\n",
      "[175]\ttraining's binary_logloss: 0.586522\n",
      "[176]\ttraining's binary_logloss: 0.586523\n",
      "[177]\ttraining's binary_logloss: 0.586537\n",
      "[178]\ttraining's binary_logloss: 0.586564\n",
      "[179]\ttraining's binary_logloss: 0.586575\n",
      "[180]\ttraining's binary_logloss: 0.586581\n",
      "[181]\ttraining's binary_logloss: 0.586577\n",
      "[182]\ttraining's binary_logloss: 0.586573\n",
      "[183]\ttraining's binary_logloss: 0.586572\n",
      "[184]\ttraining's binary_logloss: 0.586578\n",
      "[185]\ttraining's binary_logloss: 0.586584\n",
      "[186]\ttraining's binary_logloss: 0.586594\n",
      "[187]\ttraining's binary_logloss: 0.586597\n",
      "[188]\ttraining's binary_logloss: 0.586609\n",
      "[189]\ttraining's binary_logloss: 0.586622\n",
      "[190]\ttraining's binary_logloss: 0.586648\n",
      "[191]\ttraining's binary_logloss: 0.586661\n",
      "[192]\ttraining's binary_logloss: 0.586669\n",
      "[193]\ttraining's binary_logloss: 0.586669\n",
      "[194]\ttraining's binary_logloss: 0.586687\n",
      "[195]\ttraining's binary_logloss: 0.586703\n",
      "[196]\ttraining's binary_logloss: 0.586708\n",
      "[197]\ttraining's binary_logloss: 0.586672\n",
      "[198]\ttraining's binary_logloss: 0.586638\n",
      "[199]\ttraining's binary_logloss: 0.586631\n",
      "[200]\ttraining's binary_logloss: 0.586599\n",
      "[201]\ttraining's binary_logloss: 0.586599\n",
      "[202]\ttraining's binary_logloss: 0.586594\n",
      "[203]\ttraining's binary_logloss: 0.586607\n",
      "[204]\ttraining's binary_logloss: 0.586609\n",
      "[205]\ttraining's binary_logloss: 0.586613\n",
      "[206]\ttraining's binary_logloss: 0.586609\n",
      "[207]\ttraining's binary_logloss: 0.586605\n",
      "[208]\ttraining's binary_logloss: 0.586604\n",
      "[209]\ttraining's binary_logloss: 0.586603\n",
      "[210]\ttraining's binary_logloss: 0.586599\n",
      "[211]\ttraining's binary_logloss: 0.586615\n",
      "[212]\ttraining's binary_logloss: 0.586657\n",
      "[213]\ttraining's binary_logloss: 0.586674\n",
      "[214]\ttraining's binary_logloss: 0.586691\n",
      "[215]\ttraining's binary_logloss: 0.586702\n",
      "[216]\ttraining's binary_logloss: 0.586644\n",
      "[217]\ttraining's binary_logloss: 0.586623\n",
      "[218]\ttraining's binary_logloss: 0.586573\n",
      "[219]\ttraining's binary_logloss: 0.586513\n",
      "[220]\ttraining's binary_logloss: 0.586466\n",
      "[221]\ttraining's binary_logloss: 0.586397\n",
      "[222]\ttraining's binary_logloss: 0.586345\n",
      "[223]\ttraining's binary_logloss: 0.586326\n",
      "[224]\ttraining's binary_logloss: 0.586259\n",
      "[225]\ttraining's binary_logloss: 0.586256\n",
      "[226]\ttraining's binary_logloss: 0.586247\n",
      "[227]\ttraining's binary_logloss: 0.586249\n",
      "[228]\ttraining's binary_logloss: 0.586249\n",
      "[229]\ttraining's binary_logloss: 0.586252\n",
      "[230]\ttraining's binary_logloss: 0.586236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[231]\ttraining's binary_logloss: 0.586214\n",
      "[232]\ttraining's binary_logloss: 0.5862\n",
      "[233]\ttraining's binary_logloss: 0.586187\n",
      "[234]\ttraining's binary_logloss: 0.586166\n",
      "[235]\ttraining's binary_logloss: 0.586146\n",
      "[236]\ttraining's binary_logloss: 0.586089\n",
      "[237]\ttraining's binary_logloss: 0.586038\n",
      "[238]\ttraining's binary_logloss: 0.586002\n",
      "[239]\ttraining's binary_logloss: 0.58596\n",
      "[240]\ttraining's binary_logloss: 0.585913\n",
      "[241]\ttraining's binary_logloss: 0.585884\n",
      "[242]\ttraining's binary_logloss: 0.585832\n",
      "[243]\ttraining's binary_logloss: 0.585759\n",
      "[244]\ttraining's binary_logloss: 0.585694\n",
      "[245]\ttraining's binary_logloss: 0.585644\n",
      "[246]\ttraining's binary_logloss: 0.585601\n",
      "[247]\ttraining's binary_logloss: 0.585569\n",
      "[248]\ttraining's binary_logloss: 0.585537\n",
      "[249]\ttraining's binary_logloss: 0.585492\n",
      "[250]\ttraining's binary_logloss: 0.585463\n",
      "[251]\ttraining's binary_logloss: 0.585471\n",
      "[252]\ttraining's binary_logloss: 0.585468\n",
      "[253]\ttraining's binary_logloss: 0.585469\n",
      "[254]\ttraining's binary_logloss: 0.585474\n",
      "[255]\ttraining's binary_logloss: 0.585466\n",
      "[256]\ttraining's binary_logloss: 0.585422\n",
      "[257]\ttraining's binary_logloss: 0.585379\n",
      "[258]\ttraining's binary_logloss: 0.585336\n",
      "[259]\ttraining's binary_logloss: 0.585276\n",
      "[260]\ttraining's binary_logloss: 0.585219\n",
      "[261]\ttraining's binary_logloss: 0.585182\n",
      "[262]\ttraining's binary_logloss: 0.585153\n",
      "[263]\ttraining's binary_logloss: 0.585104\n",
      "[264]\ttraining's binary_logloss: 0.585079\n",
      "[265]\ttraining's binary_logloss: 0.585056\n",
      "[266]\ttraining's binary_logloss: 0.585079\n",
      "[267]\ttraining's binary_logloss: 0.585106\n",
      "[268]\ttraining's binary_logloss: 0.585132\n",
      "[269]\ttraining's binary_logloss: 0.585159\n",
      "[270]\ttraining's binary_logloss: 0.585177\n",
      "[271]\ttraining's binary_logloss: 0.585094\n",
      "[272]\ttraining's binary_logloss: 0.585016\n",
      "[273]\ttraining's binary_logloss: 0.584929\n",
      "[274]\ttraining's binary_logloss: 0.584843\n",
      "[275]\ttraining's binary_logloss: 0.584754\n",
      "[276]\ttraining's binary_logloss: 0.584682\n",
      "[277]\ttraining's binary_logloss: 0.584612\n",
      "[278]\ttraining's binary_logloss: 0.584549\n",
      "[279]\ttraining's binary_logloss: 0.584483\n",
      "[280]\ttraining's binary_logloss: 0.584422\n",
      "[281]\ttraining's binary_logloss: 0.584353\n",
      "[282]\ttraining's binary_logloss: 0.584303\n",
      "[283]\ttraining's binary_logloss: 0.58425\n",
      "[284]\ttraining's binary_logloss: 0.584187\n",
      "[285]\ttraining's binary_logloss: 0.58413\n",
      "[286]\ttraining's binary_logloss: 0.584073\n",
      "[287]\ttraining's binary_logloss: 0.584021\n",
      "[288]\ttraining's binary_logloss: 0.583967\n",
      "[289]\ttraining's binary_logloss: 0.583912\n",
      "[290]\ttraining's binary_logloss: 0.583863\n",
      "[291]\ttraining's binary_logloss: 0.583795\n",
      "[292]\ttraining's binary_logloss: 0.583722\n",
      "[293]\ttraining's binary_logloss: 0.583658\n",
      "[294]\ttraining's binary_logloss: 0.583585\n",
      "[295]\ttraining's binary_logloss: 0.583523\n",
      "[296]\ttraining's binary_logloss: 0.583484\n",
      "[297]\ttraining's binary_logloss: 0.583459\n",
      "[298]\ttraining's binary_logloss: 0.583426\n",
      "[299]\ttraining's binary_logloss: 0.583403\n",
      "[300]\ttraining's binary_logloss: 0.583374\n",
      "[301]\ttraining's binary_logloss: 0.583315\n",
      "[302]\ttraining's binary_logloss: 0.583258\n",
      "[303]\ttraining's binary_logloss: 0.583199\n",
      "[304]\ttraining's binary_logloss: 0.583143\n",
      "[305]\ttraining's binary_logloss: 0.583099\n",
      "[306]\ttraining's binary_logloss: 0.583043\n",
      "[307]\ttraining's binary_logloss: 0.582976\n",
      "[308]\ttraining's binary_logloss: 0.58294\n",
      "[309]\ttraining's binary_logloss: 0.582877\n",
      "[310]\ttraining's binary_logloss: 0.582814\n",
      "[311]\ttraining's binary_logloss: 0.58276\n",
      "[312]\ttraining's binary_logloss: 0.582708\n",
      "[313]\ttraining's binary_logloss: 0.582656\n",
      "[314]\ttraining's binary_logloss: 0.582608\n",
      "[315]\ttraining's binary_logloss: 0.582562\n",
      "[316]\ttraining's binary_logloss: 0.582505\n",
      "[317]\ttraining's binary_logloss: 0.582446\n",
      "[318]\ttraining's binary_logloss: 0.582401\n",
      "[319]\ttraining's binary_logloss: 0.582355\n",
      "[320]\ttraining's binary_logloss: 0.582296\n",
      "[321]\ttraining's binary_logloss: 0.582242\n",
      "[322]\ttraining's binary_logloss: 0.582189\n",
      "[323]\ttraining's binary_logloss: 0.582137\n",
      "[324]\ttraining's binary_logloss: 0.582094\n",
      "[325]\ttraining's binary_logloss: 0.582047\n",
      "[326]\ttraining's binary_logloss: 0.581974\n",
      "[327]\ttraining's binary_logloss: 0.581915\n",
      "[328]\ttraining's binary_logloss: 0.581837\n",
      "[329]\ttraining's binary_logloss: 0.581781\n",
      "[330]\ttraining's binary_logloss: 0.581723\n",
      "[331]\ttraining's binary_logloss: 0.581639\n",
      "[332]\ttraining's binary_logloss: 0.58156\n",
      "[333]\ttraining's binary_logloss: 0.581469\n",
      "[334]\ttraining's binary_logloss: 0.581394\n",
      "[335]\ttraining's binary_logloss: 0.581313\n",
      "[336]\ttraining's binary_logloss: 0.581275\n",
      "[337]\ttraining's binary_logloss: 0.581217\n",
      "[338]\ttraining's binary_logloss: 0.581163\n",
      "[339]\ttraining's binary_logloss: 0.581117\n",
      "[340]\ttraining's binary_logloss: 0.581061\n",
      "[341]\ttraining's binary_logloss: 0.581036\n",
      "[342]\ttraining's binary_logloss: 0.581011\n",
      "[343]\ttraining's binary_logloss: 0.580987\n",
      "[344]\ttraining's binary_logloss: 0.580965\n",
      "[345]\ttraining's binary_logloss: 0.580925\n",
      "[346]\ttraining's binary_logloss: 0.580889\n",
      "[347]\ttraining's binary_logloss: 0.580829\n",
      "[348]\ttraining's binary_logloss: 0.580787\n",
      "[349]\ttraining's binary_logloss: 0.58075\n",
      "[350]\ttraining's binary_logloss: 0.58071\n",
      "[351]\ttraining's binary_logloss: 0.580628\n",
      "[352]\ttraining's binary_logloss: 0.580559\n",
      "[353]\ttraining's binary_logloss: 0.580492\n",
      "[354]\ttraining's binary_logloss: 0.580415\n",
      "[355]\ttraining's binary_logloss: 0.58034\n",
      "[356]\ttraining's binary_logloss: 0.580255\n",
      "[357]\ttraining's binary_logloss: 0.580161\n",
      "[358]\ttraining's binary_logloss: 0.580059\n",
      "[359]\ttraining's binary_logloss: 0.579972\n",
      "[360]\ttraining's binary_logloss: 0.57987\n",
      "[361]\ttraining's binary_logloss: 0.579761\n",
      "[362]\ttraining's binary_logloss: 0.579656\n",
      "[363]\ttraining's binary_logloss: 0.579559\n",
      "[364]\ttraining's binary_logloss: 0.579457\n",
      "[365]\ttraining's binary_logloss: 0.579359\n",
      "[366]\ttraining's binary_logloss: 0.579292\n",
      "[367]\ttraining's binary_logloss: 0.579227\n",
      "[368]\ttraining's binary_logloss: 0.579163\n",
      "[369]\ttraining's binary_logloss: 0.579105\n",
      "[370]\ttraining's binary_logloss: 0.579037\n",
      "[371]\ttraining's binary_logloss: 0.579004\n",
      "[372]\ttraining's binary_logloss: 0.578967\n",
      "[373]\ttraining's binary_logloss: 0.578935\n",
      "[374]\ttraining's binary_logloss: 0.578895\n",
      "[375]\ttraining's binary_logloss: 0.578854\n",
      "[376]\ttraining's binary_logloss: 0.578783\n",
      "[377]\ttraining's binary_logloss: 0.578704\n",
      "[378]\ttraining's binary_logloss: 0.578635\n",
      "[379]\ttraining's binary_logloss: 0.57856\n",
      "[380]\ttraining's binary_logloss: 0.578494\n",
      "[381]\ttraining's binary_logloss: 0.578422\n",
      "[382]\ttraining's binary_logloss: 0.57838\n",
      "[383]\ttraining's binary_logloss: 0.578311\n",
      "[384]\ttraining's binary_logloss: 0.578279\n",
      "[385]\ttraining's binary_logloss: 0.578236\n",
      "[386]\ttraining's binary_logloss: 0.578137\n",
      "[387]\ttraining's binary_logloss: 0.578041\n",
      "[388]\ttraining's binary_logloss: 0.577951\n",
      "[389]\ttraining's binary_logloss: 0.577859\n",
      "[390]\ttraining's binary_logloss: 0.577766\n",
      "[391]\ttraining's binary_logloss: 0.577688\n",
      "[392]\ttraining's binary_logloss: 0.577613\n",
      "[393]\ttraining's binary_logloss: 0.577532\n",
      "[394]\ttraining's binary_logloss: 0.577457\n",
      "[395]\ttraining's binary_logloss: 0.577383\n",
      "[396]\ttraining's binary_logloss: 0.577305\n",
      "[397]\ttraining's binary_logloss: 0.577233\n",
      "[398]\ttraining's binary_logloss: 0.577174\n",
      "[399]\ttraining's binary_logloss: 0.577091\n",
      "[400]\ttraining's binary_logloss: 0.577022\n",
      "[401]\ttraining's binary_logloss: 0.576944\n",
      "[402]\ttraining's binary_logloss: 0.576857\n",
      "[403]\ttraining's binary_logloss: 0.576781\n",
      "[404]\ttraining's binary_logloss: 0.576713\n",
      "[405]\ttraining's binary_logloss: 0.576639\n",
      "[406]\ttraining's binary_logloss: 0.576561\n",
      "[407]\ttraining's binary_logloss: 0.576483\n",
      "[408]\ttraining's binary_logloss: 0.576384\n",
      "[409]\ttraining's binary_logloss: 0.57631\n",
      "[410]\ttraining's binary_logloss: 0.576233\n",
      "[411]\ttraining's binary_logloss: 0.576115\n",
      "[412]\ttraining's binary_logloss: 0.576001\n",
      "[413]\ttraining's binary_logloss: 0.575897\n",
      "[414]\ttraining's binary_logloss: 0.575786\n",
      "[415]\ttraining's binary_logloss: 0.575677\n",
      "[416]\ttraining's binary_logloss: 0.575596\n",
      "[417]\ttraining's binary_logloss: 0.575517\n",
      "[418]\ttraining's binary_logloss: 0.575445\n",
      "[419]\ttraining's binary_logloss: 0.575368\n",
      "[420]\ttraining's binary_logloss: 0.57529\n",
      "[421]\ttraining's binary_logloss: 0.575242\n",
      "[422]\ttraining's binary_logloss: 0.575187\n",
      "[423]\ttraining's binary_logloss: 0.575157\n",
      "[424]\ttraining's binary_logloss: 0.575116\n",
      "[425]\ttraining's binary_logloss: 0.575056\n",
      "[426]\ttraining's binary_logloss: 0.574997\n",
      "[427]\ttraining's binary_logloss: 0.574938\n",
      "[428]\ttraining's binary_logloss: 0.574894\n",
      "[429]\ttraining's binary_logloss: 0.574836\n",
      "[430]\ttraining's binary_logloss: 0.57478\n",
      "[431]\ttraining's binary_logloss: 0.574672\n",
      "[432]\ttraining's binary_logloss: 0.574567\n",
      "[433]\ttraining's binary_logloss: 0.574458\n",
      "[434]\ttraining's binary_logloss: 0.574358\n",
      "[435]\ttraining's binary_logloss: 0.574261\n",
      "[436]\ttraining's binary_logloss: 0.574177\n",
      "[437]\ttraining's binary_logloss: 0.574084\n",
      "[438]\ttraining's binary_logloss: 0.573969\n",
      "[439]\ttraining's binary_logloss: 0.573889\n",
      "[440]\ttraining's binary_logloss: 0.573801\n",
      "[441]\ttraining's binary_logloss: 0.573748\n",
      "[442]\ttraining's binary_logloss: 0.573696\n",
      "[443]\ttraining's binary_logloss: 0.573644\n",
      "[444]\ttraining's binary_logloss: 0.573596\n",
      "[445]\ttraining's binary_logloss: 0.573548\n",
      "[446]\ttraining's binary_logloss: 0.573459\n",
      "[447]\ttraining's binary_logloss: 0.573388\n",
      "[448]\ttraining's binary_logloss: 0.573302\n",
      "[449]\ttraining's binary_logloss: 0.573233\n",
      "[450]\ttraining's binary_logloss: 0.573134\n",
      "[451]\ttraining's binary_logloss: 0.573056\n",
      "[452]\ttraining's binary_logloss: 0.572978\n",
      "[453]\ttraining's binary_logloss: 0.572904\n",
      "[454]\ttraining's binary_logloss: 0.572839\n",
      "[455]\ttraining's binary_logloss: 0.572766\n",
      "[456]\ttraining's binary_logloss: 0.572709\n",
      "[457]\ttraining's binary_logloss: 0.57266\n",
      "[458]\ttraining's binary_logloss: 0.572605\n",
      "[459]\ttraining's binary_logloss: 0.572551\n",
      "[460]\ttraining's binary_logloss: 0.572499\n",
      "[461]\ttraining's binary_logloss: 0.57239\n",
      "[462]\ttraining's binary_logloss: 0.57229\n",
      "[463]\ttraining's binary_logloss: 0.572189\n",
      "[464]\ttraining's binary_logloss: 0.572108\n",
      "[465]\ttraining's binary_logloss: 0.57201\n",
      "[466]\ttraining's binary_logloss: 0.571923\n",
      "[467]\ttraining's binary_logloss: 0.571838\n",
      "[468]\ttraining's binary_logloss: 0.571758\n",
      "[469]\ttraining's binary_logloss: 0.571696\n",
      "[470]\ttraining's binary_logloss: 0.57163\n",
      "[471]\ttraining's binary_logloss: 0.571578\n",
      "[472]\ttraining's binary_logloss: 0.571501\n",
      "[473]\ttraining's binary_logloss: 0.571433\n",
      "[474]\ttraining's binary_logloss: 0.57137\n",
      "[475]\ttraining's binary_logloss: 0.571297\n",
      "[476]\ttraining's binary_logloss: 0.571229\n",
      "[477]\ttraining's binary_logloss: 0.571162\n",
      "[478]\ttraining's binary_logloss: 0.571108\n",
      "[479]\ttraining's binary_logloss: 0.571056\n",
      "[480]\ttraining's binary_logloss: 0.571004\n",
      "[481]\ttraining's binary_logloss: 0.570909\n",
      "[482]\ttraining's binary_logloss: 0.570817\n",
      "[483]\ttraining's binary_logloss: 0.570736\n",
      "[484]\ttraining's binary_logloss: 0.570666\n",
      "[485]\ttraining's binary_logloss: 0.570573\n",
      "[486]\ttraining's binary_logloss: 0.570482\n",
      "[487]\ttraining's binary_logloss: 0.570388\n",
      "[488]\ttraining's binary_logloss: 0.570294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[489]\ttraining's binary_logloss: 0.570216\n",
      "[490]\ttraining's binary_logloss: 0.570141\n",
      "[491]\ttraining's binary_logloss: 0.570069\n",
      "[492]\ttraining's binary_logloss: 0.569999\n",
      "[493]\ttraining's binary_logloss: 0.569931\n",
      "[494]\ttraining's binary_logloss: 0.569877\n",
      "[495]\ttraining's binary_logloss: 0.569822\n",
      "[496]\ttraining's binary_logloss: 0.569721\n",
      "[497]\ttraining's binary_logloss: 0.569625\n",
      "[498]\ttraining's binary_logloss: 0.56954\n",
      "[499]\ttraining's binary_logloss: 0.569461\n",
      "[500]\ttraining's binary_logloss: 0.56935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613304\n",
      "[2]\ttraining's binary_logloss: 0.612283\n",
      "[3]\ttraining's binary_logloss: 0.611278\n",
      "[4]\ttraining's binary_logloss: 0.610315\n",
      "[5]\ttraining's binary_logloss: 0.60939\n",
      "[6]\ttraining's binary_logloss: 0.608569\n",
      "[7]\ttraining's binary_logloss: 0.607745\n",
      "[8]\ttraining's binary_logloss: 0.60693\n",
      "[9]\ttraining's binary_logloss: 0.606038\n",
      "[10]\ttraining's binary_logloss: 0.605303\n",
      "[11]\ttraining's binary_logloss: 0.60445\n",
      "[12]\ttraining's binary_logloss: 0.603633\n",
      "[13]\ttraining's binary_logloss: 0.602851\n",
      "[14]\ttraining's binary_logloss: 0.602186\n",
      "[15]\ttraining's binary_logloss: 0.601513\n",
      "[16]\ttraining's binary_logloss: 0.600793\n",
      "[17]\ttraining's binary_logloss: 0.60023\n",
      "[18]\ttraining's binary_logloss: 0.599563\n",
      "[19]\ttraining's binary_logloss: 0.598928\n",
      "[20]\ttraining's binary_logloss: 0.59831\n",
      "[21]\ttraining's binary_logloss: 0.597678\n",
      "[22]\ttraining's binary_logloss: 0.597211\n",
      "[23]\ttraining's binary_logloss: 0.596691\n",
      "[24]\ttraining's binary_logloss: 0.596126\n",
      "[25]\ttraining's binary_logloss: 0.595586\n",
      "[26]\ttraining's binary_logloss: 0.595166\n",
      "[27]\ttraining's binary_logloss: 0.594764\n",
      "[28]\ttraining's binary_logloss: 0.594383\n",
      "[29]\ttraining's binary_logloss: 0.594015\n",
      "[30]\ttraining's binary_logloss: 0.593645\n",
      "[31]\ttraining's binary_logloss: 0.59323\n",
      "[32]\ttraining's binary_logloss: 0.592819\n",
      "[33]\ttraining's binary_logloss: 0.592427\n",
      "[34]\ttraining's binary_logloss: 0.59225\n",
      "[35]\ttraining's binary_logloss: 0.591892\n",
      "[36]\ttraining's binary_logloss: 0.591643\n",
      "[37]\ttraining's binary_logloss: 0.591357\n",
      "[38]\ttraining's binary_logloss: 0.591097\n",
      "[39]\ttraining's binary_logloss: 0.590895\n",
      "[40]\ttraining's binary_logloss: 0.590596\n",
      "[41]\ttraining's binary_logloss: 0.590375\n",
      "[42]\ttraining's binary_logloss: 0.590178\n",
      "[43]\ttraining's binary_logloss: 0.589983\n",
      "[44]\ttraining's binary_logloss: 0.589761\n",
      "[45]\ttraining's binary_logloss: 0.589581\n",
      "[46]\ttraining's binary_logloss: 0.589383\n",
      "[47]\ttraining's binary_logloss: 0.589115\n",
      "[48]\ttraining's binary_logloss: 0.588931\n",
      "[49]\ttraining's binary_logloss: 0.588685\n",
      "[50]\ttraining's binary_logloss: 0.588456\n",
      "[51]\ttraining's binary_logloss: 0.588304\n",
      "[52]\ttraining's binary_logloss: 0.588105\n",
      "[53]\ttraining's binary_logloss: 0.587919\n",
      "[54]\ttraining's binary_logloss: 0.587752\n",
      "[55]\ttraining's binary_logloss: 0.587569\n",
      "[56]\ttraining's binary_logloss: 0.58734\n",
      "[57]\ttraining's binary_logloss: 0.587122\n",
      "[58]\ttraining's binary_logloss: 0.586917\n",
      "[59]\ttraining's binary_logloss: 0.586721\n",
      "[60]\ttraining's binary_logloss: 0.586625\n",
      "[61]\ttraining's binary_logloss: 0.586484\n",
      "[62]\ttraining's binary_logloss: 0.586426\n",
      "[63]\ttraining's binary_logloss: 0.586292\n",
      "[64]\ttraining's binary_logloss: 0.586214\n",
      "[65]\ttraining's binary_logloss: 0.586187\n",
      "[66]\ttraining's binary_logloss: 0.586102\n",
      "[67]\ttraining's binary_logloss: 0.586076\n",
      "[68]\ttraining's binary_logloss: 0.586002\n",
      "[69]\ttraining's binary_logloss: 0.585939\n",
      "[70]\ttraining's binary_logloss: 0.585884\n",
      "[71]\ttraining's binary_logloss: 0.585823\n",
      "[72]\ttraining's binary_logloss: 0.585796\n",
      "[73]\ttraining's binary_logloss: 0.585783\n",
      "[74]\ttraining's binary_logloss: 0.585738\n",
      "[75]\ttraining's binary_logloss: 0.585676\n",
      "[76]\ttraining's binary_logloss: 0.585565\n",
      "[77]\ttraining's binary_logloss: 0.585486\n",
      "[78]\ttraining's binary_logloss: 0.585496\n",
      "[79]\ttraining's binary_logloss: 0.585435\n",
      "[80]\ttraining's binary_logloss: 0.585411\n",
      "[81]\ttraining's binary_logloss: 0.585338\n",
      "[82]\ttraining's binary_logloss: 0.585281\n",
      "[83]\ttraining's binary_logloss: 0.585262\n",
      "[84]\ttraining's binary_logloss: 0.585211\n",
      "[85]\ttraining's binary_logloss: 0.585173\n",
      "[86]\ttraining's binary_logloss: 0.585158\n",
      "[87]\ttraining's binary_logloss: 0.585154\n",
      "[88]\ttraining's binary_logloss: 0.58515\n",
      "[89]\ttraining's binary_logloss: 0.585154\n",
      "[90]\ttraining's binary_logloss: 0.585162\n",
      "[91]\ttraining's binary_logloss: 0.585127\n",
      "[92]\ttraining's binary_logloss: 0.585167\n",
      "[93]\ttraining's binary_logloss: 0.585177\n",
      "[94]\ttraining's binary_logloss: 0.58513\n",
      "[95]\ttraining's binary_logloss: 0.585088\n",
      "[96]\ttraining's binary_logloss: 0.585153\n",
      "[97]\ttraining's binary_logloss: 0.585219\n",
      "[98]\ttraining's binary_logloss: 0.585204\n",
      "[99]\ttraining's binary_logloss: 0.585181\n",
      "[100]\ttraining's binary_logloss: 0.585167\n",
      "[101]\ttraining's binary_logloss: 0.585225\n",
      "[102]\ttraining's binary_logloss: 0.585265\n",
      "[103]\ttraining's binary_logloss: 0.585334\n",
      "[104]\ttraining's binary_logloss: 0.585406\n",
      "[105]\ttraining's binary_logloss: 0.585481\n",
      "[106]\ttraining's binary_logloss: 0.585455\n",
      "[107]\ttraining's binary_logloss: 0.585529\n",
      "[108]\ttraining's binary_logloss: 0.58551\n",
      "[109]\ttraining's binary_logloss: 0.585584\n",
      "[110]\ttraining's binary_logloss: 0.585635\n",
      "[111]\ttraining's binary_logloss: 0.585647\n",
      "[112]\ttraining's binary_logloss: 0.585679\n",
      "[113]\ttraining's binary_logloss: 0.5857\n",
      "[114]\ttraining's binary_logloss: 0.585726\n",
      "[115]\ttraining's binary_logloss: 0.585756\n",
      "[116]\ttraining's binary_logloss: 0.585738\n",
      "[117]\ttraining's binary_logloss: 0.585729\n",
      "[118]\ttraining's binary_logloss: 0.585754\n",
      "[119]\ttraining's binary_logloss: 0.585746\n",
      "[120]\ttraining's binary_logloss: 0.585773\n",
      "[121]\ttraining's binary_logloss: 0.585823\n",
      "[122]\ttraining's binary_logloss: 0.585813\n",
      "[123]\ttraining's binary_logloss: 0.585819\n",
      "[124]\ttraining's binary_logloss: 0.58582\n",
      "[125]\ttraining's binary_logloss: 0.585821\n",
      "[126]\ttraining's binary_logloss: 0.585798\n",
      "[127]\ttraining's binary_logloss: 0.585777\n",
      "[128]\ttraining's binary_logloss: 0.585794\n",
      "[129]\ttraining's binary_logloss: 0.585782\n",
      "[130]\ttraining's binary_logloss: 0.58577\n",
      "[131]\ttraining's binary_logloss: 0.585808\n",
      "[132]\ttraining's binary_logloss: 0.585817\n",
      "[133]\ttraining's binary_logloss: 0.585859\n",
      "[134]\ttraining's binary_logloss: 0.585903\n",
      "[135]\ttraining's binary_logloss: 0.585951\n",
      "[136]\ttraining's binary_logloss: 0.585981\n",
      "[137]\ttraining's binary_logloss: 0.586014\n",
      "[138]\ttraining's binary_logloss: 0.586057\n",
      "[139]\ttraining's binary_logloss: 0.586102\n",
      "[140]\ttraining's binary_logloss: 0.586139\n",
      "[141]\ttraining's binary_logloss: 0.586172\n",
      "[142]\ttraining's binary_logloss: 0.586207\n",
      "[143]\ttraining's binary_logloss: 0.586264\n",
      "[144]\ttraining's binary_logloss: 0.586303\n",
      "[145]\ttraining's binary_logloss: 0.586344\n",
      "[146]\ttraining's binary_logloss: 0.586324\n",
      "[147]\ttraining's binary_logloss: 0.586331\n",
      "[148]\ttraining's binary_logloss: 0.586315\n",
      "[149]\ttraining's binary_logloss: 0.586325\n",
      "[150]\ttraining's binary_logloss: 0.586312\n",
      "[151]\ttraining's binary_logloss: 0.586315\n",
      "[152]\ttraining's binary_logloss: 0.58636\n",
      "[153]\ttraining's binary_logloss: 0.586387\n",
      "[154]\ttraining's binary_logloss: 0.586392\n",
      "[155]\ttraining's binary_logloss: 0.586423\n",
      "[156]\ttraining's binary_logloss: 0.586488\n",
      "[157]\ttraining's binary_logloss: 0.586556\n",
      "[158]\ttraining's binary_logloss: 0.586588\n",
      "[159]\ttraining's binary_logloss: 0.586627\n",
      "[160]\ttraining's binary_logloss: 0.586668\n",
      "[161]\ttraining's binary_logloss: 0.586633\n",
      "[162]\ttraining's binary_logloss: 0.586609\n",
      "[163]\ttraining's binary_logloss: 0.586612\n",
      "[164]\ttraining's binary_logloss: 0.586625\n",
      "[165]\ttraining's binary_logloss: 0.586631\n",
      "[166]\ttraining's binary_logloss: 0.586647\n",
      "[167]\ttraining's binary_logloss: 0.586666\n",
      "[168]\ttraining's binary_logloss: 0.586657\n",
      "[169]\ttraining's binary_logloss: 0.586675\n",
      "[170]\ttraining's binary_logloss: 0.58667\n",
      "[171]\ttraining's binary_logloss: 0.58673\n",
      "[172]\ttraining's binary_logloss: 0.586767\n",
      "[173]\ttraining's binary_logloss: 0.586803\n",
      "[174]\ttraining's binary_logloss: 0.58684\n",
      "[175]\ttraining's binary_logloss: 0.586861\n",
      "[176]\ttraining's binary_logloss: 0.58687\n",
      "[177]\ttraining's binary_logloss: 0.586898\n",
      "[178]\ttraining's binary_logloss: 0.586925\n",
      "[179]\ttraining's binary_logloss: 0.586961\n",
      "[180]\ttraining's binary_logloss: 0.586967\n",
      "[181]\ttraining's binary_logloss: 0.58699\n",
      "[182]\ttraining's binary_logloss: 0.587012\n",
      "[183]\ttraining's binary_logloss: 0.587034\n",
      "[184]\ttraining's binary_logloss: 0.587064\n",
      "[185]\ttraining's binary_logloss: 0.587114\n",
      "[186]\ttraining's binary_logloss: 0.58711\n",
      "[187]\ttraining's binary_logloss: 0.587121\n",
      "[188]\ttraining's binary_logloss: 0.587118\n",
      "[189]\ttraining's binary_logloss: 0.587118\n",
      "[190]\ttraining's binary_logloss: 0.587143\n",
      "[191]\ttraining's binary_logloss: 0.587178\n",
      "[192]\ttraining's binary_logloss: 0.587208\n",
      "[193]\ttraining's binary_logloss: 0.587218\n",
      "[194]\ttraining's binary_logloss: 0.587245\n",
      "[195]\ttraining's binary_logloss: 0.587259\n",
      "[196]\ttraining's binary_logloss: 0.587282\n",
      "[197]\ttraining's binary_logloss: 0.587305\n",
      "[198]\ttraining's binary_logloss: 0.587325\n",
      "[199]\ttraining's binary_logloss: 0.587343\n",
      "[200]\ttraining's binary_logloss: 0.587361\n",
      "[201]\ttraining's binary_logloss: 0.587359\n",
      "[202]\ttraining's binary_logloss: 0.587381\n",
      "[203]\ttraining's binary_logloss: 0.587383\n",
      "[204]\ttraining's binary_logloss: 0.587413\n",
      "[205]\ttraining's binary_logloss: 0.587418\n",
      "[206]\ttraining's binary_logloss: 0.587447\n",
      "[207]\ttraining's binary_logloss: 0.587467\n",
      "[208]\ttraining's binary_logloss: 0.587495\n",
      "[209]\ttraining's binary_logloss: 0.587534\n",
      "[210]\ttraining's binary_logloss: 0.587563\n",
      "[211]\ttraining's binary_logloss: 0.587592\n",
      "[212]\ttraining's binary_logloss: 0.587616\n",
      "[213]\ttraining's binary_logloss: 0.587644\n",
      "[214]\ttraining's binary_logloss: 0.587677\n",
      "[215]\ttraining's binary_logloss: 0.587712\n",
      "[216]\ttraining's binary_logloss: 0.587672\n",
      "[217]\ttraining's binary_logloss: 0.587633\n",
      "[218]\ttraining's binary_logloss: 0.587616\n",
      "[219]\ttraining's binary_logloss: 0.587578\n",
      "[220]\ttraining's binary_logloss: 0.587542\n",
      "[221]\ttraining's binary_logloss: 0.587505\n",
      "[222]\ttraining's binary_logloss: 0.587469\n",
      "[223]\ttraining's binary_logloss: 0.587436\n",
      "[224]\ttraining's binary_logloss: 0.587395\n",
      "[225]\ttraining's binary_logloss: 0.587362\n",
      "[226]\ttraining's binary_logloss: 0.58734\n",
      "[227]\ttraining's binary_logloss: 0.587326\n",
      "[228]\ttraining's binary_logloss: 0.587312\n",
      "[229]\ttraining's binary_logloss: 0.587285\n",
      "[230]\ttraining's binary_logloss: 0.587277\n",
      "[231]\ttraining's binary_logloss: 0.587284\n",
      "[232]\ttraining's binary_logloss: 0.587295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[233]\ttraining's binary_logloss: 0.587305\n",
      "[234]\ttraining's binary_logloss: 0.587319\n",
      "[235]\ttraining's binary_logloss: 0.587296\n",
      "[236]\ttraining's binary_logloss: 0.58727\n",
      "[237]\ttraining's binary_logloss: 0.587251\n",
      "[238]\ttraining's binary_logloss: 0.587241\n",
      "[239]\ttraining's binary_logloss: 0.58723\n",
      "[240]\ttraining's binary_logloss: 0.587215\n",
      "[241]\ttraining's binary_logloss: 0.587165\n",
      "[242]\ttraining's binary_logloss: 0.587119\n",
      "[243]\ttraining's binary_logloss: 0.5871\n",
      "[244]\ttraining's binary_logloss: 0.587056\n",
      "[245]\ttraining's binary_logloss: 0.587014\n",
      "[246]\ttraining's binary_logloss: 0.586927\n",
      "[247]\ttraining's binary_logloss: 0.586851\n",
      "[248]\ttraining's binary_logloss: 0.586783\n",
      "[249]\ttraining's binary_logloss: 0.586704\n",
      "[250]\ttraining's binary_logloss: 0.586638\n",
      "[251]\ttraining's binary_logloss: 0.586629\n",
      "[252]\ttraining's binary_logloss: 0.586627\n",
      "[253]\ttraining's binary_logloss: 0.586623\n",
      "[254]\ttraining's binary_logloss: 0.586629\n",
      "[255]\ttraining's binary_logloss: 0.586618\n",
      "[256]\ttraining's binary_logloss: 0.586563\n",
      "[257]\ttraining's binary_logloss: 0.586513\n",
      "[258]\ttraining's binary_logloss: 0.586467\n",
      "[259]\ttraining's binary_logloss: 0.586427\n",
      "[260]\ttraining's binary_logloss: 0.586383\n",
      "[261]\ttraining's binary_logloss: 0.586375\n",
      "[262]\ttraining's binary_logloss: 0.586353\n",
      "[263]\ttraining's binary_logloss: 0.586334\n",
      "[264]\ttraining's binary_logloss: 0.586323\n",
      "[265]\ttraining's binary_logloss: 0.586295\n",
      "[266]\ttraining's binary_logloss: 0.586298\n",
      "[267]\ttraining's binary_logloss: 0.586285\n",
      "[268]\ttraining's binary_logloss: 0.586296\n",
      "[269]\ttraining's binary_logloss: 0.586282\n",
      "[270]\ttraining's binary_logloss: 0.586288\n",
      "[271]\ttraining's binary_logloss: 0.586198\n",
      "[272]\ttraining's binary_logloss: 0.586111\n",
      "[273]\ttraining's binary_logloss: 0.586025\n",
      "[274]\ttraining's binary_logloss: 0.585945\n",
      "[275]\ttraining's binary_logloss: 0.585863\n",
      "[276]\ttraining's binary_logloss: 0.585846\n",
      "[277]\ttraining's binary_logloss: 0.585808\n",
      "[278]\ttraining's binary_logloss: 0.585782\n",
      "[279]\ttraining's binary_logloss: 0.585768\n",
      "[280]\ttraining's binary_logloss: 0.585759\n",
      "[281]\ttraining's binary_logloss: 0.585704\n",
      "[282]\ttraining's binary_logloss: 0.585667\n",
      "[283]\ttraining's binary_logloss: 0.585624\n",
      "[284]\ttraining's binary_logloss: 0.585567\n",
      "[285]\ttraining's binary_logloss: 0.585508\n",
      "[286]\ttraining's binary_logloss: 0.585416\n",
      "[287]\ttraining's binary_logloss: 0.58534\n",
      "[288]\ttraining's binary_logloss: 0.58528\n",
      "[289]\ttraining's binary_logloss: 0.585213\n",
      "[290]\ttraining's binary_logloss: 0.585159\n",
      "[291]\ttraining's binary_logloss: 0.585085\n",
      "[292]\ttraining's binary_logloss: 0.585\n",
      "[293]\ttraining's binary_logloss: 0.584927\n",
      "[294]\ttraining's binary_logloss: 0.584856\n",
      "[295]\ttraining's binary_logloss: 0.584781\n",
      "[296]\ttraining's binary_logloss: 0.584733\n",
      "[297]\ttraining's binary_logloss: 0.584685\n",
      "[298]\ttraining's binary_logloss: 0.584642\n",
      "[299]\ttraining's binary_logloss: 0.584598\n",
      "[300]\ttraining's binary_logloss: 0.584557\n",
      "[301]\ttraining's binary_logloss: 0.584517\n",
      "[302]\ttraining's binary_logloss: 0.584479\n",
      "[303]\ttraining's binary_logloss: 0.584442\n",
      "[304]\ttraining's binary_logloss: 0.584396\n",
      "[305]\ttraining's binary_logloss: 0.584362\n",
      "[306]\ttraining's binary_logloss: 0.584329\n",
      "[307]\ttraining's binary_logloss: 0.584305\n",
      "[308]\ttraining's binary_logloss: 0.584255\n",
      "[309]\ttraining's binary_logloss: 0.584197\n",
      "[310]\ttraining's binary_logloss: 0.584169\n",
      "[311]\ttraining's binary_logloss: 0.584117\n",
      "[312]\ttraining's binary_logloss: 0.584058\n",
      "[313]\ttraining's binary_logloss: 0.584001\n",
      "[314]\ttraining's binary_logloss: 0.583967\n",
      "[315]\ttraining's binary_logloss: 0.583915\n",
      "[316]\ttraining's binary_logloss: 0.583835\n",
      "[317]\ttraining's binary_logloss: 0.583768\n",
      "[318]\ttraining's binary_logloss: 0.583697\n",
      "[319]\ttraining's binary_logloss: 0.583632\n",
      "[320]\ttraining's binary_logloss: 0.583564\n",
      "[321]\ttraining's binary_logloss: 0.583535\n",
      "[322]\ttraining's binary_logloss: 0.583505\n",
      "[323]\ttraining's binary_logloss: 0.583483\n",
      "[324]\ttraining's binary_logloss: 0.583457\n",
      "[325]\ttraining's binary_logloss: 0.583429\n",
      "[326]\ttraining's binary_logloss: 0.583385\n",
      "[327]\ttraining's binary_logloss: 0.583322\n",
      "[328]\ttraining's binary_logloss: 0.583278\n",
      "[329]\ttraining's binary_logloss: 0.583212\n",
      "[330]\ttraining's binary_logloss: 0.583159\n",
      "[331]\ttraining's binary_logloss: 0.583103\n",
      "[332]\ttraining's binary_logloss: 0.583049\n",
      "[333]\ttraining's binary_logloss: 0.583009\n",
      "[334]\ttraining's binary_logloss: 0.582971\n",
      "[335]\ttraining's binary_logloss: 0.582899\n",
      "[336]\ttraining's binary_logloss: 0.58282\n",
      "[337]\ttraining's binary_logloss: 0.582735\n",
      "[338]\ttraining's binary_logloss: 0.58266\n",
      "[339]\ttraining's binary_logloss: 0.5826\n",
      "[340]\ttraining's binary_logloss: 0.582533\n",
      "[341]\ttraining's binary_logloss: 0.582515\n",
      "[342]\ttraining's binary_logloss: 0.582499\n",
      "[343]\ttraining's binary_logloss: 0.582484\n",
      "[344]\ttraining's binary_logloss: 0.582471\n",
      "[345]\ttraining's binary_logloss: 0.582454\n",
      "[346]\ttraining's binary_logloss: 0.582431\n",
      "[347]\ttraining's binary_logloss: 0.582396\n",
      "[348]\ttraining's binary_logloss: 0.582371\n",
      "[349]\ttraining's binary_logloss: 0.582333\n",
      "[350]\ttraining's binary_logloss: 0.582321\n",
      "[351]\ttraining's binary_logloss: 0.582231\n",
      "[352]\ttraining's binary_logloss: 0.582156\n",
      "[353]\ttraining's binary_logloss: 0.582077\n",
      "[354]\ttraining's binary_logloss: 0.581983\n",
      "[355]\ttraining's binary_logloss: 0.581902\n",
      "[356]\ttraining's binary_logloss: 0.581821\n",
      "[357]\ttraining's binary_logloss: 0.581744\n",
      "[358]\ttraining's binary_logloss: 0.581675\n",
      "[359]\ttraining's binary_logloss: 0.581605\n",
      "[360]\ttraining's binary_logloss: 0.581537\n",
      "[361]\ttraining's binary_logloss: 0.581443\n",
      "[362]\ttraining's binary_logloss: 0.581335\n",
      "[363]\ttraining's binary_logloss: 0.581243\n",
      "[364]\ttraining's binary_logloss: 0.581143\n",
      "[365]\ttraining's binary_logloss: 0.581043\n",
      "[366]\ttraining's binary_logloss: 0.580987\n",
      "[367]\ttraining's binary_logloss: 0.580927\n",
      "[368]\ttraining's binary_logloss: 0.580873\n",
      "[369]\ttraining's binary_logloss: 0.580819\n",
      "[370]\ttraining's binary_logloss: 0.580769\n",
      "[371]\ttraining's binary_logloss: 0.580736\n",
      "[372]\ttraining's binary_logloss: 0.580704\n",
      "[373]\ttraining's binary_logloss: 0.580674\n",
      "[374]\ttraining's binary_logloss: 0.580643\n",
      "[375]\ttraining's binary_logloss: 0.580615\n",
      "[376]\ttraining's binary_logloss: 0.580562\n",
      "[377]\ttraining's binary_logloss: 0.580505\n",
      "[378]\ttraining's binary_logloss: 0.580442\n",
      "[379]\ttraining's binary_logloss: 0.580384\n",
      "[380]\ttraining's binary_logloss: 0.580307\n",
      "[381]\ttraining's binary_logloss: 0.580293\n",
      "[382]\ttraining's binary_logloss: 0.580274\n",
      "[383]\ttraining's binary_logloss: 0.580254\n",
      "[384]\ttraining's binary_logloss: 0.580235\n",
      "[385]\ttraining's binary_logloss: 0.580205\n",
      "[386]\ttraining's binary_logloss: 0.580124\n",
      "[387]\ttraining's binary_logloss: 0.580049\n",
      "[388]\ttraining's binary_logloss: 0.579972\n",
      "[389]\ttraining's binary_logloss: 0.579878\n",
      "[390]\ttraining's binary_logloss: 0.579807\n",
      "[391]\ttraining's binary_logloss: 0.579718\n",
      "[392]\ttraining's binary_logloss: 0.579629\n",
      "[393]\ttraining's binary_logloss: 0.579543\n",
      "[394]\ttraining's binary_logloss: 0.579448\n",
      "[395]\ttraining's binary_logloss: 0.579355\n",
      "[396]\ttraining's binary_logloss: 0.579288\n",
      "[397]\ttraining's binary_logloss: 0.579225\n",
      "[398]\ttraining's binary_logloss: 0.579163\n",
      "[399]\ttraining's binary_logloss: 0.579126\n",
      "[400]\ttraining's binary_logloss: 0.579082\n",
      "[401]\ttraining's binary_logloss: 0.578993\n",
      "[402]\ttraining's binary_logloss: 0.578905\n",
      "[403]\ttraining's binary_logloss: 0.578817\n",
      "[404]\ttraining's binary_logloss: 0.578741\n",
      "[405]\ttraining's binary_logloss: 0.578661\n",
      "[406]\ttraining's binary_logloss: 0.578594\n",
      "[407]\ttraining's binary_logloss: 0.578519\n",
      "[408]\ttraining's binary_logloss: 0.578445\n",
      "[409]\ttraining's binary_logloss: 0.578374\n",
      "[410]\ttraining's binary_logloss: 0.578312\n",
      "[411]\ttraining's binary_logloss: 0.57824\n",
      "[412]\ttraining's binary_logloss: 0.57817\n",
      "[413]\ttraining's binary_logloss: 0.578098\n",
      "[414]\ttraining's binary_logloss: 0.578008\n",
      "[415]\ttraining's binary_logloss: 0.57794\n",
      "[416]\ttraining's binary_logloss: 0.577868\n",
      "[417]\ttraining's binary_logloss: 0.577797\n",
      "[418]\ttraining's binary_logloss: 0.577736\n",
      "[419]\ttraining's binary_logloss: 0.577669\n",
      "[420]\ttraining's binary_logloss: 0.577602\n",
      "[421]\ttraining's binary_logloss: 0.577563\n",
      "[422]\ttraining's binary_logloss: 0.577526\n",
      "[423]\ttraining's binary_logloss: 0.577504\n",
      "[424]\ttraining's binary_logloss: 0.57748\n",
      "[425]\ttraining's binary_logloss: 0.577449\n",
      "[426]\ttraining's binary_logloss: 0.57737\n",
      "[427]\ttraining's binary_logloss: 0.577304\n",
      "[428]\ttraining's binary_logloss: 0.577236\n",
      "[429]\ttraining's binary_logloss: 0.577169\n",
      "[430]\ttraining's binary_logloss: 0.577099\n",
      "[431]\ttraining's binary_logloss: 0.57701\n",
      "[432]\ttraining's binary_logloss: 0.576927\n",
      "[433]\ttraining's binary_logloss: 0.576835\n",
      "[434]\ttraining's binary_logloss: 0.576726\n",
      "[435]\ttraining's binary_logloss: 0.576636\n",
      "[436]\ttraining's binary_logloss: 0.576578\n",
      "[437]\ttraining's binary_logloss: 0.576537\n",
      "[438]\ttraining's binary_logloss: 0.576496\n",
      "[439]\ttraining's binary_logloss: 0.576457\n",
      "[440]\ttraining's binary_logloss: 0.576419\n",
      "[441]\ttraining's binary_logloss: 0.576363\n",
      "[442]\ttraining's binary_logloss: 0.576306\n",
      "[443]\ttraining's binary_logloss: 0.576254\n",
      "[444]\ttraining's binary_logloss: 0.576184\n",
      "[445]\ttraining's binary_logloss: 0.576119\n",
      "[446]\ttraining's binary_logloss: 0.576037\n",
      "[447]\ttraining's binary_logloss: 0.575967\n",
      "[448]\ttraining's binary_logloss: 0.575897\n",
      "[449]\ttraining's binary_logloss: 0.575812\n",
      "[450]\ttraining's binary_logloss: 0.57574\n",
      "[451]\ttraining's binary_logloss: 0.575696\n",
      "[452]\ttraining's binary_logloss: 0.575658\n",
      "[453]\ttraining's binary_logloss: 0.575614\n",
      "[454]\ttraining's binary_logloss: 0.575571\n",
      "[455]\ttraining's binary_logloss: 0.575532\n",
      "[456]\ttraining's binary_logloss: 0.575475\n",
      "[457]\ttraining's binary_logloss: 0.575416\n",
      "[458]\ttraining's binary_logloss: 0.575358\n",
      "[459]\ttraining's binary_logloss: 0.575297\n",
      "[460]\ttraining's binary_logloss: 0.575255\n",
      "[461]\ttraining's binary_logloss: 0.575193\n",
      "[462]\ttraining's binary_logloss: 0.575141\n",
      "[463]\ttraining's binary_logloss: 0.575087\n",
      "[464]\ttraining's binary_logloss: 0.575041\n",
      "[465]\ttraining's binary_logloss: 0.574984\n",
      "[466]\ttraining's binary_logloss: 0.574918\n",
      "[467]\ttraining's binary_logloss: 0.574831\n",
      "[468]\ttraining's binary_logloss: 0.574763\n",
      "[469]\ttraining's binary_logloss: 0.574676\n",
      "[470]\ttraining's binary_logloss: 0.574592\n",
      "[471]\ttraining's binary_logloss: 0.574564\n",
      "[472]\ttraining's binary_logloss: 0.574512\n",
      "[473]\ttraining's binary_logloss: 0.574458\n",
      "[474]\ttraining's binary_logloss: 0.57443\n",
      "[475]\ttraining's binary_logloss: 0.574379\n",
      "[476]\ttraining's binary_logloss: 0.574292\n",
      "[477]\ttraining's binary_logloss: 0.574206\n",
      "[478]\ttraining's binary_logloss: 0.574111\n",
      "[479]\ttraining's binary_logloss: 0.574047\n",
      "[480]\ttraining's binary_logloss: 0.573976\n",
      "[481]\ttraining's binary_logloss: 0.573906\n",
      "[482]\ttraining's binary_logloss: 0.573834\n",
      "[483]\ttraining's binary_logloss: 0.573768\n",
      "[484]\ttraining's binary_logloss: 0.573667\n",
      "[485]\ttraining's binary_logloss: 0.573598\n",
      "[486]\ttraining's binary_logloss: 0.573493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[487]\ttraining's binary_logloss: 0.573383\n",
      "[488]\ttraining's binary_logloss: 0.573277\n",
      "[489]\ttraining's binary_logloss: 0.573171\n",
      "[490]\ttraining's binary_logloss: 0.573067\n",
      "[491]\ttraining's binary_logloss: 0.57299\n",
      "[492]\ttraining's binary_logloss: 0.572916\n",
      "[493]\ttraining's binary_logloss: 0.572838\n",
      "[494]\ttraining's binary_logloss: 0.572769\n",
      "[495]\ttraining's binary_logloss: 0.572673\n",
      "[496]\ttraining's binary_logloss: 0.572604\n",
      "[497]\ttraining's binary_logloss: 0.57253\n",
      "[498]\ttraining's binary_logloss: 0.572451\n",
      "[499]\ttraining's binary_logloss: 0.572379\n",
      "[500]\ttraining's binary_logloss: 0.572307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.617701\n",
      "[2]\ttraining's binary_logloss: 0.616657\n",
      "[3]\ttraining's binary_logloss: 0.615671\n",
      "[4]\ttraining's binary_logloss: 0.614708\n",
      "[5]\ttraining's binary_logloss: 0.6138\n",
      "[6]\ttraining's binary_logloss: 0.612919\n",
      "[7]\ttraining's binary_logloss: 0.612073\n",
      "[8]\ttraining's binary_logloss: 0.61118\n",
      "[9]\ttraining's binary_logloss: 0.610394\n",
      "[10]\ttraining's binary_logloss: 0.609569\n",
      "[11]\ttraining's binary_logloss: 0.608792\n",
      "[12]\ttraining's binary_logloss: 0.608027\n",
      "[13]\ttraining's binary_logloss: 0.607246\n",
      "[14]\ttraining's binary_logloss: 0.606635\n",
      "[15]\ttraining's binary_logloss: 0.605892\n",
      "[16]\ttraining's binary_logloss: 0.605305\n",
      "[17]\ttraining's binary_logloss: 0.604716\n",
      "[18]\ttraining's binary_logloss: 0.604172\n",
      "[19]\ttraining's binary_logloss: 0.603628\n",
      "[20]\ttraining's binary_logloss: 0.603134\n",
      "[21]\ttraining's binary_logloss: 0.602536\n",
      "[22]\ttraining's binary_logloss: 0.601993\n",
      "[23]\ttraining's binary_logloss: 0.601502\n",
      "[24]\ttraining's binary_logloss: 0.601012\n",
      "[25]\ttraining's binary_logloss: 0.600538\n",
      "[26]\ttraining's binary_logloss: 0.600105\n",
      "[27]\ttraining's binary_logloss: 0.599659\n",
      "[28]\ttraining's binary_logloss: 0.599299\n",
      "[29]\ttraining's binary_logloss: 0.598921\n",
      "[30]\ttraining's binary_logloss: 0.59853\n",
      "[31]\ttraining's binary_logloss: 0.598167\n",
      "[32]\ttraining's binary_logloss: 0.597822\n",
      "[33]\ttraining's binary_logloss: 0.597491\n",
      "[34]\ttraining's binary_logloss: 0.59722\n",
      "[35]\ttraining's binary_logloss: 0.5969\n",
      "[36]\ttraining's binary_logloss: 0.596605\n",
      "[37]\ttraining's binary_logloss: 0.596338\n",
      "[38]\ttraining's binary_logloss: 0.596081\n",
      "[39]\ttraining's binary_logloss: 0.595832\n",
      "[40]\ttraining's binary_logloss: 0.595601\n",
      "[41]\ttraining's binary_logloss: 0.595414\n",
      "[42]\ttraining's binary_logloss: 0.595241\n",
      "[43]\ttraining's binary_logloss: 0.595055\n",
      "[44]\ttraining's binary_logloss: 0.594845\n",
      "[45]\ttraining's binary_logloss: 0.594585\n",
      "[46]\ttraining's binary_logloss: 0.594388\n",
      "[47]\ttraining's binary_logloss: 0.594092\n",
      "[48]\ttraining's binary_logloss: 0.593809\n",
      "[49]\ttraining's binary_logloss: 0.593642\n",
      "[50]\ttraining's binary_logloss: 0.593369\n",
      "[51]\ttraining's binary_logloss: 0.593158\n",
      "[52]\ttraining's binary_logloss: 0.592975\n",
      "[53]\ttraining's binary_logloss: 0.592784\n",
      "[54]\ttraining's binary_logloss: 0.592604\n",
      "[55]\ttraining's binary_logloss: 0.592491\n",
      "[56]\ttraining's binary_logloss: 0.592346\n",
      "[57]\ttraining's binary_logloss: 0.592224\n",
      "[58]\ttraining's binary_logloss: 0.592099\n",
      "[59]\ttraining's binary_logloss: 0.591983\n",
      "[60]\ttraining's binary_logloss: 0.591848\n",
      "[61]\ttraining's binary_logloss: 0.591694\n",
      "[62]\ttraining's binary_logloss: 0.591568\n",
      "[63]\ttraining's binary_logloss: 0.591449\n",
      "[64]\ttraining's binary_logloss: 0.591348\n",
      "[65]\ttraining's binary_logloss: 0.591248\n",
      "[66]\ttraining's binary_logloss: 0.591182\n",
      "[67]\ttraining's binary_logloss: 0.591118\n",
      "[68]\ttraining's binary_logloss: 0.591039\n",
      "[69]\ttraining's binary_logloss: 0.590976\n",
      "[70]\ttraining's binary_logloss: 0.59091\n",
      "[71]\ttraining's binary_logloss: 0.59089\n",
      "[72]\ttraining's binary_logloss: 0.590812\n",
      "[73]\ttraining's binary_logloss: 0.590743\n",
      "[74]\ttraining's binary_logloss: 0.590681\n",
      "[75]\ttraining's binary_logloss: 0.590601\n",
      "[76]\ttraining's binary_logloss: 0.590617\n",
      "[77]\ttraining's binary_logloss: 0.590515\n",
      "[78]\ttraining's binary_logloss: 0.590518\n",
      "[79]\ttraining's binary_logloss: 0.590444\n",
      "[80]\ttraining's binary_logloss: 0.590379\n",
      "[81]\ttraining's binary_logloss: 0.590297\n",
      "[82]\ttraining's binary_logloss: 0.590219\n",
      "[83]\ttraining's binary_logloss: 0.590157\n",
      "[84]\ttraining's binary_logloss: 0.590098\n",
      "[85]\ttraining's binary_logloss: 0.590053\n",
      "[86]\ttraining's binary_logloss: 0.59008\n",
      "[87]\ttraining's binary_logloss: 0.59007\n",
      "[88]\ttraining's binary_logloss: 0.590065\n",
      "[89]\ttraining's binary_logloss: 0.590043\n",
      "[90]\ttraining's binary_logloss: 0.590047\n",
      "[91]\ttraining's binary_logloss: 0.589973\n",
      "[92]\ttraining's binary_logloss: 0.5899\n",
      "[93]\ttraining's binary_logloss: 0.589843\n",
      "[94]\ttraining's binary_logloss: 0.589781\n",
      "[95]\ttraining's binary_logloss: 0.589725\n",
      "[96]\ttraining's binary_logloss: 0.589683\n",
      "[97]\ttraining's binary_logloss: 0.589696\n",
      "[98]\ttraining's binary_logloss: 0.58966\n",
      "[99]\ttraining's binary_logloss: 0.58963\n",
      "[100]\ttraining's binary_logloss: 0.589631\n",
      "[101]\ttraining's binary_logloss: 0.589664\n",
      "[102]\ttraining's binary_logloss: 0.589687\n",
      "[103]\ttraining's binary_logloss: 0.589725\n",
      "[104]\ttraining's binary_logloss: 0.589766\n",
      "[105]\ttraining's binary_logloss: 0.589806\n",
      "[106]\ttraining's binary_logloss: 0.589768\n",
      "[107]\ttraining's binary_logloss: 0.589742\n",
      "[108]\ttraining's binary_logloss: 0.589709\n",
      "[109]\ttraining's binary_logloss: 0.589686\n",
      "[110]\ttraining's binary_logloss: 0.589652\n",
      "[111]\ttraining's binary_logloss: 0.589737\n",
      "[112]\ttraining's binary_logloss: 0.589778\n",
      "[113]\ttraining's binary_logloss: 0.589818\n",
      "[114]\ttraining's binary_logloss: 0.589867\n",
      "[115]\ttraining's binary_logloss: 0.589911\n",
      "[116]\ttraining's binary_logloss: 0.589881\n",
      "[117]\ttraining's binary_logloss: 0.589901\n",
      "[118]\ttraining's binary_logloss: 0.589925\n",
      "[119]\ttraining's binary_logloss: 0.589952\n",
      "[120]\ttraining's binary_logloss: 0.589983\n",
      "[121]\ttraining's binary_logloss: 0.590016\n",
      "[122]\ttraining's binary_logloss: 0.590048\n",
      "[123]\ttraining's binary_logloss: 0.590094\n",
      "[124]\ttraining's binary_logloss: 0.590135\n",
      "[125]\ttraining's binary_logloss: 0.590188\n",
      "[126]\ttraining's binary_logloss: 0.590174\n",
      "[127]\ttraining's binary_logloss: 0.590162\n",
      "[128]\ttraining's binary_logloss: 0.590187\n",
      "[129]\ttraining's binary_logloss: 0.590163\n",
      "[130]\ttraining's binary_logloss: 0.590158\n",
      "[131]\ttraining's binary_logloss: 0.590127\n",
      "[132]\ttraining's binary_logloss: 0.590102\n",
      "[133]\ttraining's binary_logloss: 0.590081\n",
      "[134]\ttraining's binary_logloss: 0.590064\n",
      "[135]\ttraining's binary_logloss: 0.59005\n",
      "[136]\ttraining's binary_logloss: 0.590083\n",
      "[137]\ttraining's binary_logloss: 0.590111\n",
      "[138]\ttraining's binary_logloss: 0.590137\n",
      "[139]\ttraining's binary_logloss: 0.590155\n",
      "[140]\ttraining's binary_logloss: 0.59019\n",
      "[141]\ttraining's binary_logloss: 0.590175\n",
      "[142]\ttraining's binary_logloss: 0.590172\n",
      "[143]\ttraining's binary_logloss: 0.590175\n",
      "[144]\ttraining's binary_logloss: 0.590176\n",
      "[145]\ttraining's binary_logloss: 0.590176\n",
      "[146]\ttraining's binary_logloss: 0.5902\n",
      "[147]\ttraining's binary_logloss: 0.590231\n",
      "[148]\ttraining's binary_logloss: 0.590224\n",
      "[149]\ttraining's binary_logloss: 0.590268\n",
      "[150]\ttraining's binary_logloss: 0.590303\n",
      "[151]\ttraining's binary_logloss: 0.59034\n",
      "[152]\ttraining's binary_logloss: 0.590378\n",
      "[153]\ttraining's binary_logloss: 0.590417\n",
      "[154]\ttraining's binary_logloss: 0.590458\n",
      "[155]\ttraining's binary_logloss: 0.590496\n",
      "[156]\ttraining's binary_logloss: 0.590511\n",
      "[157]\ttraining's binary_logloss: 0.59054\n",
      "[158]\ttraining's binary_logloss: 0.590571\n",
      "[159]\ttraining's binary_logloss: 0.590588\n",
      "[160]\ttraining's binary_logloss: 0.5906\n",
      "[161]\ttraining's binary_logloss: 0.590563\n",
      "[162]\ttraining's binary_logloss: 0.590539\n",
      "[163]\ttraining's binary_logloss: 0.590509\n",
      "[164]\ttraining's binary_logloss: 0.590502\n",
      "[165]\ttraining's binary_logloss: 0.590502\n",
      "[166]\ttraining's binary_logloss: 0.590513\n",
      "[167]\ttraining's binary_logloss: 0.590506\n",
      "[168]\ttraining's binary_logloss: 0.590487\n",
      "[169]\ttraining's binary_logloss: 0.590471\n",
      "[170]\ttraining's binary_logloss: 0.590456\n",
      "[171]\ttraining's binary_logloss: 0.590484\n",
      "[172]\ttraining's binary_logloss: 0.590516\n",
      "[173]\ttraining's binary_logloss: 0.590548\n",
      "[174]\ttraining's binary_logloss: 0.590569\n",
      "[175]\ttraining's binary_logloss: 0.590598\n",
      "[176]\ttraining's binary_logloss: 0.59059\n",
      "[177]\ttraining's binary_logloss: 0.590585\n",
      "[178]\ttraining's binary_logloss: 0.590584\n",
      "[179]\ttraining's binary_logloss: 0.590585\n",
      "[180]\ttraining's binary_logloss: 0.590584\n",
      "[181]\ttraining's binary_logloss: 0.590571\n",
      "[182]\ttraining's binary_logloss: 0.590561\n",
      "[183]\ttraining's binary_logloss: 0.590557\n",
      "[184]\ttraining's binary_logloss: 0.590596\n",
      "[185]\ttraining's binary_logloss: 0.590599\n",
      "[186]\ttraining's binary_logloss: 0.590634\n",
      "[187]\ttraining's binary_logloss: 0.590663\n",
      "[188]\ttraining's binary_logloss: 0.5907\n",
      "[189]\ttraining's binary_logloss: 0.590742\n",
      "[190]\ttraining's binary_logloss: 0.590772\n",
      "[191]\ttraining's binary_logloss: 0.590782\n",
      "[192]\ttraining's binary_logloss: 0.590794\n",
      "[193]\ttraining's binary_logloss: 0.590805\n",
      "[194]\ttraining's binary_logloss: 0.590766\n",
      "[195]\ttraining's binary_logloss: 0.590742\n",
      "[196]\ttraining's binary_logloss: 0.590732\n",
      "[197]\ttraining's binary_logloss: 0.590724\n",
      "[198]\ttraining's binary_logloss: 0.59069\n",
      "[199]\ttraining's binary_logloss: 0.590687\n",
      "[200]\ttraining's binary_logloss: 0.590659\n",
      "[201]\ttraining's binary_logloss: 0.590662\n",
      "[202]\ttraining's binary_logloss: 0.590673\n",
      "[203]\ttraining's binary_logloss: 0.590632\n",
      "[204]\ttraining's binary_logloss: 0.590627\n",
      "[205]\ttraining's binary_logloss: 0.590583\n",
      "[206]\ttraining's binary_logloss: 0.59061\n",
      "[207]\ttraining's binary_logloss: 0.590619\n",
      "[208]\ttraining's binary_logloss: 0.590646\n",
      "[209]\ttraining's binary_logloss: 0.59065\n",
      "[210]\ttraining's binary_logloss: 0.59065\n",
      "[211]\ttraining's binary_logloss: 0.590647\n",
      "[212]\ttraining's binary_logloss: 0.590638\n",
      "[213]\ttraining's binary_logloss: 0.590647\n",
      "[214]\ttraining's binary_logloss: 0.590639\n",
      "[215]\ttraining's binary_logloss: 0.59064\n",
      "[216]\ttraining's binary_logloss: 0.590661\n",
      "[217]\ttraining's binary_logloss: 0.590631\n",
      "[218]\ttraining's binary_logloss: 0.59061\n",
      "[219]\ttraining's binary_logloss: 0.590597\n",
      "[220]\ttraining's binary_logloss: 0.590577\n",
      "[221]\ttraining's binary_logloss: 0.590538\n",
      "[222]\ttraining's binary_logloss: 0.590501\n",
      "[223]\ttraining's binary_logloss: 0.59048\n",
      "[224]\ttraining's binary_logloss: 0.590432\n",
      "[225]\ttraining's binary_logloss: 0.590413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[226]\ttraining's binary_logloss: 0.590382\n",
      "[227]\ttraining's binary_logloss: 0.590366\n",
      "[228]\ttraining's binary_logloss: 0.590338\n",
      "[229]\ttraining's binary_logloss: 0.590307\n",
      "[230]\ttraining's binary_logloss: 0.590283\n",
      "[231]\ttraining's binary_logloss: 0.590279\n",
      "[232]\ttraining's binary_logloss: 0.590289\n",
      "[233]\ttraining's binary_logloss: 0.590301\n",
      "[234]\ttraining's binary_logloss: 0.590302\n",
      "[235]\ttraining's binary_logloss: 0.590295\n",
      "[236]\ttraining's binary_logloss: 0.590259\n",
      "[237]\ttraining's binary_logloss: 0.590223\n",
      "[238]\ttraining's binary_logloss: 0.590187\n",
      "[239]\ttraining's binary_logloss: 0.590158\n",
      "[240]\ttraining's binary_logloss: 0.590121\n",
      "[241]\ttraining's binary_logloss: 0.590068\n",
      "[242]\ttraining's binary_logloss: 0.590018\n",
      "[243]\ttraining's binary_logloss: 0.589954\n",
      "[244]\ttraining's binary_logloss: 0.589902\n",
      "[245]\ttraining's binary_logloss: 0.589867\n",
      "[246]\ttraining's binary_logloss: 0.589811\n",
      "[247]\ttraining's binary_logloss: 0.589768\n",
      "[248]\ttraining's binary_logloss: 0.589726\n",
      "[249]\ttraining's binary_logloss: 0.589672\n",
      "[250]\ttraining's binary_logloss: 0.58961\n",
      "[251]\ttraining's binary_logloss: 0.58958\n",
      "[252]\ttraining's binary_logloss: 0.589568\n",
      "[253]\ttraining's binary_logloss: 0.589553\n",
      "[254]\ttraining's binary_logloss: 0.589542\n",
      "[255]\ttraining's binary_logloss: 0.589523\n",
      "[256]\ttraining's binary_logloss: 0.589472\n",
      "[257]\ttraining's binary_logloss: 0.589445\n",
      "[258]\ttraining's binary_logloss: 0.589408\n",
      "[259]\ttraining's binary_logloss: 0.589368\n",
      "[260]\ttraining's binary_logloss: 0.589334\n",
      "[261]\ttraining's binary_logloss: 0.589259\n",
      "[262]\ttraining's binary_logloss: 0.589193\n",
      "[263]\ttraining's binary_logloss: 0.589131\n",
      "[264]\ttraining's binary_logloss: 0.58907\n",
      "[265]\ttraining's binary_logloss: 0.589011\n",
      "[266]\ttraining's binary_logloss: 0.588986\n",
      "[267]\ttraining's binary_logloss: 0.588971\n",
      "[268]\ttraining's binary_logloss: 0.588949\n",
      "[269]\ttraining's binary_logloss: 0.588938\n",
      "[270]\ttraining's binary_logloss: 0.58892\n",
      "[271]\ttraining's binary_logloss: 0.588881\n",
      "[272]\ttraining's binary_logloss: 0.588837\n",
      "[273]\ttraining's binary_logloss: 0.588794\n",
      "[274]\ttraining's binary_logloss: 0.588751\n",
      "[275]\ttraining's binary_logloss: 0.588712\n",
      "[276]\ttraining's binary_logloss: 0.588652\n",
      "[277]\ttraining's binary_logloss: 0.588602\n",
      "[278]\ttraining's binary_logloss: 0.58857\n",
      "[279]\ttraining's binary_logloss: 0.588521\n",
      "[280]\ttraining's binary_logloss: 0.588481\n",
      "[281]\ttraining's binary_logloss: 0.588432\n",
      "[282]\ttraining's binary_logloss: 0.588385\n",
      "[283]\ttraining's binary_logloss: 0.588341\n",
      "[284]\ttraining's binary_logloss: 0.588296\n",
      "[285]\ttraining's binary_logloss: 0.588253\n",
      "[286]\ttraining's binary_logloss: 0.588191\n",
      "[287]\ttraining's binary_logloss: 0.588133\n",
      "[288]\ttraining's binary_logloss: 0.588078\n",
      "[289]\ttraining's binary_logloss: 0.58803\n",
      "[290]\ttraining's binary_logloss: 0.587978\n",
      "[291]\ttraining's binary_logloss: 0.5879\n",
      "[292]\ttraining's binary_logloss: 0.587825\n",
      "[293]\ttraining's binary_logloss: 0.587789\n",
      "[294]\ttraining's binary_logloss: 0.587722\n",
      "[295]\ttraining's binary_logloss: 0.587651\n",
      "[296]\ttraining's binary_logloss: 0.587611\n",
      "[297]\ttraining's binary_logloss: 0.587565\n",
      "[298]\ttraining's binary_logloss: 0.587518\n",
      "[299]\ttraining's binary_logloss: 0.587478\n",
      "[300]\ttraining's binary_logloss: 0.587433\n",
      "[301]\ttraining's binary_logloss: 0.587362\n",
      "[302]\ttraining's binary_logloss: 0.587303\n",
      "[303]\ttraining's binary_logloss: 0.587233\n",
      "[304]\ttraining's binary_logloss: 0.587151\n",
      "[305]\ttraining's binary_logloss: 0.587076\n",
      "[306]\ttraining's binary_logloss: 0.58702\n",
      "[307]\ttraining's binary_logloss: 0.586965\n",
      "[308]\ttraining's binary_logloss: 0.586888\n",
      "[309]\ttraining's binary_logloss: 0.586829\n",
      "[310]\ttraining's binary_logloss: 0.58678\n",
      "[311]\ttraining's binary_logloss: 0.586718\n",
      "[312]\ttraining's binary_logloss: 0.586661\n",
      "[313]\ttraining's binary_logloss: 0.5866\n",
      "[314]\ttraining's binary_logloss: 0.586542\n",
      "[315]\ttraining's binary_logloss: 0.58649\n",
      "[316]\ttraining's binary_logloss: 0.58641\n",
      "[317]\ttraining's binary_logloss: 0.58633\n",
      "[318]\ttraining's binary_logloss: 0.58625\n",
      "[319]\ttraining's binary_logloss: 0.586172\n",
      "[320]\ttraining's binary_logloss: 0.586082\n",
      "[321]\ttraining's binary_logloss: 0.586013\n",
      "[322]\ttraining's binary_logloss: 0.585983\n",
      "[323]\ttraining's binary_logloss: 0.585916\n",
      "[324]\ttraining's binary_logloss: 0.585858\n",
      "[325]\ttraining's binary_logloss: 0.585827\n",
      "[326]\ttraining's binary_logloss: 0.585785\n",
      "[327]\ttraining's binary_logloss: 0.585732\n",
      "[328]\ttraining's binary_logloss: 0.58568\n",
      "[329]\ttraining's binary_logloss: 0.585636\n",
      "[330]\ttraining's binary_logloss: 0.585582\n",
      "[331]\ttraining's binary_logloss: 0.585521\n",
      "[332]\ttraining's binary_logloss: 0.585466\n",
      "[333]\ttraining's binary_logloss: 0.585412\n",
      "[334]\ttraining's binary_logloss: 0.585353\n",
      "[335]\ttraining's binary_logloss: 0.585297\n",
      "[336]\ttraining's binary_logloss: 0.585223\n",
      "[337]\ttraining's binary_logloss: 0.585152\n",
      "[338]\ttraining's binary_logloss: 0.585071\n",
      "[339]\ttraining's binary_logloss: 0.584989\n",
      "[340]\ttraining's binary_logloss: 0.584917\n",
      "[341]\ttraining's binary_logloss: 0.584867\n",
      "[342]\ttraining's binary_logloss: 0.584818\n",
      "[343]\ttraining's binary_logloss: 0.58477\n",
      "[344]\ttraining's binary_logloss: 0.584726\n",
      "[345]\ttraining's binary_logloss: 0.584684\n",
      "[346]\ttraining's binary_logloss: 0.584653\n",
      "[347]\ttraining's binary_logloss: 0.58462\n",
      "[348]\ttraining's binary_logloss: 0.58459\n",
      "[349]\ttraining's binary_logloss: 0.584559\n",
      "[350]\ttraining's binary_logloss: 0.584529\n",
      "[351]\ttraining's binary_logloss: 0.584442\n",
      "[352]\ttraining's binary_logloss: 0.584356\n",
      "[353]\ttraining's binary_logloss: 0.58429\n",
      "[354]\ttraining's binary_logloss: 0.584216\n",
      "[355]\ttraining's binary_logloss: 0.584132\n",
      "[356]\ttraining's binary_logloss: 0.584059\n",
      "[357]\ttraining's binary_logloss: 0.583986\n",
      "[358]\ttraining's binary_logloss: 0.583914\n",
      "[359]\ttraining's binary_logloss: 0.583845\n",
      "[360]\ttraining's binary_logloss: 0.583759\n",
      "[361]\ttraining's binary_logloss: 0.583685\n",
      "[362]\ttraining's binary_logloss: 0.583599\n",
      "[363]\ttraining's binary_logloss: 0.583515\n",
      "[364]\ttraining's binary_logloss: 0.583422\n",
      "[365]\ttraining's binary_logloss: 0.58333\n",
      "[366]\ttraining's binary_logloss: 0.583279\n",
      "[367]\ttraining's binary_logloss: 0.58322\n",
      "[368]\ttraining's binary_logloss: 0.583167\n",
      "[369]\ttraining's binary_logloss: 0.583125\n",
      "[370]\ttraining's binary_logloss: 0.583083\n",
      "[371]\ttraining's binary_logloss: 0.583018\n",
      "[372]\ttraining's binary_logloss: 0.582954\n",
      "[373]\ttraining's binary_logloss: 0.582894\n",
      "[374]\ttraining's binary_logloss: 0.582833\n",
      "[375]\ttraining's binary_logloss: 0.582774\n",
      "[376]\ttraining's binary_logloss: 0.5827\n",
      "[377]\ttraining's binary_logloss: 0.582626\n",
      "[378]\ttraining's binary_logloss: 0.582553\n",
      "[379]\ttraining's binary_logloss: 0.582483\n",
      "[380]\ttraining's binary_logloss: 0.582415\n",
      "[381]\ttraining's binary_logloss: 0.582361\n",
      "[382]\ttraining's binary_logloss: 0.582311\n",
      "[383]\ttraining's binary_logloss: 0.582239\n",
      "[384]\ttraining's binary_logloss: 0.582187\n",
      "[385]\ttraining's binary_logloss: 0.582129\n",
      "[386]\ttraining's binary_logloss: 0.582048\n",
      "[387]\ttraining's binary_logloss: 0.581978\n",
      "[388]\ttraining's binary_logloss: 0.581906\n",
      "[389]\ttraining's binary_logloss: 0.581839\n",
      "[390]\ttraining's binary_logloss: 0.581762\n",
      "[391]\ttraining's binary_logloss: 0.581678\n",
      "[392]\ttraining's binary_logloss: 0.58159\n",
      "[393]\ttraining's binary_logloss: 0.581513\n",
      "[394]\ttraining's binary_logloss: 0.581413\n",
      "[395]\ttraining's binary_logloss: 0.581317\n",
      "[396]\ttraining's binary_logloss: 0.581236\n",
      "[397]\ttraining's binary_logloss: 0.581176\n",
      "[398]\ttraining's binary_logloss: 0.581113\n",
      "[399]\ttraining's binary_logloss: 0.581041\n",
      "[400]\ttraining's binary_logloss: 0.580997\n",
      "[401]\ttraining's binary_logloss: 0.580924\n",
      "[402]\ttraining's binary_logloss: 0.58085\n",
      "[403]\ttraining's binary_logloss: 0.580777\n",
      "[404]\ttraining's binary_logloss: 0.580709\n",
      "[405]\ttraining's binary_logloss: 0.580627\n",
      "[406]\ttraining's binary_logloss: 0.580565\n",
      "[407]\ttraining's binary_logloss: 0.580503\n",
      "[408]\ttraining's binary_logloss: 0.580445\n",
      "[409]\ttraining's binary_logloss: 0.580387\n",
      "[410]\ttraining's binary_logloss: 0.580332\n",
      "[411]\ttraining's binary_logloss: 0.580229\n",
      "[412]\ttraining's binary_logloss: 0.580141\n",
      "[413]\ttraining's binary_logloss: 0.580055\n",
      "[414]\ttraining's binary_logloss: 0.579971\n",
      "[415]\ttraining's binary_logloss: 0.579889\n",
      "[416]\ttraining's binary_logloss: 0.579816\n",
      "[417]\ttraining's binary_logloss: 0.579754\n",
      "[418]\ttraining's binary_logloss: 0.579682\n",
      "[419]\ttraining's binary_logloss: 0.579619\n",
      "[420]\ttraining's binary_logloss: 0.579555\n",
      "[421]\ttraining's binary_logloss: 0.579523\n",
      "[422]\ttraining's binary_logloss: 0.579495\n",
      "[423]\ttraining's binary_logloss: 0.579477\n",
      "[424]\ttraining's binary_logloss: 0.579449\n",
      "[425]\ttraining's binary_logloss: 0.57943\n",
      "[426]\ttraining's binary_logloss: 0.579348\n",
      "[427]\ttraining's binary_logloss: 0.579267\n",
      "[428]\ttraining's binary_logloss: 0.579189\n",
      "[429]\ttraining's binary_logloss: 0.57912\n",
      "[430]\ttraining's binary_logloss: 0.579048\n",
      "[431]\ttraining's binary_logloss: 0.57897\n",
      "[432]\ttraining's binary_logloss: 0.578891\n",
      "[433]\ttraining's binary_logloss: 0.57882\n",
      "[434]\ttraining's binary_logloss: 0.578752\n",
      "[435]\ttraining's binary_logloss: 0.578674\n",
      "[436]\ttraining's binary_logloss: 0.578614\n",
      "[437]\ttraining's binary_logloss: 0.578566\n",
      "[438]\ttraining's binary_logloss: 0.578516\n",
      "[439]\ttraining's binary_logloss: 0.578456\n",
      "[440]\ttraining's binary_logloss: 0.578398\n",
      "[441]\ttraining's binary_logloss: 0.578323\n",
      "[442]\ttraining's binary_logloss: 0.578237\n",
      "[443]\ttraining's binary_logloss: 0.578152\n",
      "[444]\ttraining's binary_logloss: 0.578075\n",
      "[445]\ttraining's binary_logloss: 0.577997\n",
      "[446]\ttraining's binary_logloss: 0.577935\n",
      "[447]\ttraining's binary_logloss: 0.577866\n",
      "[448]\ttraining's binary_logloss: 0.577806\n",
      "[449]\ttraining's binary_logloss: 0.577742\n",
      "[450]\ttraining's binary_logloss: 0.577692\n",
      "[451]\ttraining's binary_logloss: 0.577656\n",
      "[452]\ttraining's binary_logloss: 0.57762\n",
      "[453]\ttraining's binary_logloss: 0.577586\n",
      "[454]\ttraining's binary_logloss: 0.577553\n",
      "[455]\ttraining's binary_logloss: 0.577522\n",
      "[456]\ttraining's binary_logloss: 0.57744\n",
      "[457]\ttraining's binary_logloss: 0.577357\n",
      "[458]\ttraining's binary_logloss: 0.577261\n",
      "[459]\ttraining's binary_logloss: 0.577179\n",
      "[460]\ttraining's binary_logloss: 0.577087\n",
      "[461]\ttraining's binary_logloss: 0.577024\n",
      "[462]\ttraining's binary_logloss: 0.576969\n",
      "[463]\ttraining's binary_logloss: 0.576907\n",
      "[464]\ttraining's binary_logloss: 0.576861\n",
      "[465]\ttraining's binary_logloss: 0.576808\n",
      "[466]\ttraining's binary_logloss: 0.576719\n",
      "[467]\ttraining's binary_logloss: 0.576628\n",
      "[468]\ttraining's binary_logloss: 0.576539\n",
      "[469]\ttraining's binary_logloss: 0.576454\n",
      "[470]\ttraining's binary_logloss: 0.576361\n",
      "[471]\ttraining's binary_logloss: 0.576299\n",
      "[472]\ttraining's binary_logloss: 0.576239\n",
      "[473]\ttraining's binary_logloss: 0.576179\n",
      "[474]\ttraining's binary_logloss: 0.57612\n",
      "[475]\ttraining's binary_logloss: 0.576068\n",
      "[476]\ttraining's binary_logloss: 0.575978\n",
      "[477]\ttraining's binary_logloss: 0.5759\n",
      "[478]\ttraining's binary_logloss: 0.57582\n",
      "[479]\ttraining's binary_logloss: 0.57574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[480]\ttraining's binary_logloss: 0.575656\n",
      "[481]\ttraining's binary_logloss: 0.575572\n",
      "[482]\ttraining's binary_logloss: 0.57549\n",
      "[483]\ttraining's binary_logloss: 0.575405\n",
      "[484]\ttraining's binary_logloss: 0.575322\n",
      "[485]\ttraining's binary_logloss: 0.575245\n",
      "[486]\ttraining's binary_logloss: 0.575193\n",
      "[487]\ttraining's binary_logloss: 0.575127\n",
      "[488]\ttraining's binary_logloss: 0.575071\n",
      "[489]\ttraining's binary_logloss: 0.57499\n",
      "[490]\ttraining's binary_logloss: 0.574926\n",
      "[491]\ttraining's binary_logloss: 0.574832\n",
      "[492]\ttraining's binary_logloss: 0.574726\n",
      "[493]\ttraining's binary_logloss: 0.574623\n",
      "[494]\ttraining's binary_logloss: 0.57452\n",
      "[495]\ttraining's binary_logloss: 0.574443\n",
      "[496]\ttraining's binary_logloss: 0.574297\n",
      "[497]\ttraining's binary_logloss: 0.574158\n",
      "[498]\ttraining's binary_logloss: 0.57403\n",
      "[499]\ttraining's binary_logloss: 0.573902\n",
      "[500]\ttraining's binary_logloss: 0.573789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613828\n",
      "[2]\ttraining's binary_logloss: 0.612798\n",
      "[3]\ttraining's binary_logloss: 0.611799\n",
      "[4]\ttraining's binary_logloss: 0.610848\n",
      "[5]\ttraining's binary_logloss: 0.609937\n",
      "[6]\ttraining's binary_logloss: 0.609072\n",
      "[7]\ttraining's binary_logloss: 0.608249\n",
      "[8]\ttraining's binary_logloss: 0.607479\n",
      "[9]\ttraining's binary_logloss: 0.606606\n",
      "[10]\ttraining's binary_logloss: 0.605811\n",
      "[11]\ttraining's binary_logloss: 0.605105\n",
      "[12]\ttraining's binary_logloss: 0.604416\n",
      "[13]\ttraining's binary_logloss: 0.603826\n",
      "[14]\ttraining's binary_logloss: 0.603196\n",
      "[15]\ttraining's binary_logloss: 0.602497\n",
      "[16]\ttraining's binary_logloss: 0.601904\n",
      "[17]\ttraining's binary_logloss: 0.601296\n",
      "[18]\ttraining's binary_logloss: 0.60068\n",
      "[19]\ttraining's binary_logloss: 0.60012\n",
      "[20]\ttraining's binary_logloss: 0.599606\n",
      "[21]\ttraining's binary_logloss: 0.599128\n",
      "[22]\ttraining's binary_logloss: 0.598673\n",
      "[23]\ttraining's binary_logloss: 0.598212\n",
      "[24]\ttraining's binary_logloss: 0.597774\n",
      "[25]\ttraining's binary_logloss: 0.597273\n",
      "[26]\ttraining's binary_logloss: 0.596804\n",
      "[27]\ttraining's binary_logloss: 0.59636\n",
      "[28]\ttraining's binary_logloss: 0.595998\n",
      "[29]\ttraining's binary_logloss: 0.595588\n",
      "[30]\ttraining's binary_logloss: 0.595224\n",
      "[31]\ttraining's binary_logloss: 0.594947\n",
      "[32]\ttraining's binary_logloss: 0.594634\n",
      "[33]\ttraining's binary_logloss: 0.5943\n",
      "[34]\ttraining's binary_logloss: 0.594017\n",
      "[35]\ttraining's binary_logloss: 0.593712\n",
      "[36]\ttraining's binary_logloss: 0.593374\n",
      "[37]\ttraining's binary_logloss: 0.593095\n",
      "[38]\ttraining's binary_logloss: 0.592895\n",
      "[39]\ttraining's binary_logloss: 0.592705\n",
      "[40]\ttraining's binary_logloss: 0.592467\n",
      "[41]\ttraining's binary_logloss: 0.592249\n",
      "[42]\ttraining's binary_logloss: 0.592044\n",
      "[43]\ttraining's binary_logloss: 0.591857\n",
      "[44]\ttraining's binary_logloss: 0.59155\n",
      "[45]\ttraining's binary_logloss: 0.591386\n",
      "[46]\ttraining's binary_logloss: 0.591132\n",
      "[47]\ttraining's binary_logloss: 0.590887\n",
      "[48]\ttraining's binary_logloss: 0.590654\n",
      "[49]\ttraining's binary_logloss: 0.590471\n",
      "[50]\ttraining's binary_logloss: 0.590381\n",
      "[51]\ttraining's binary_logloss: 0.59016\n",
      "[52]\ttraining's binary_logloss: 0.589904\n",
      "[53]\ttraining's binary_logloss: 0.589706\n",
      "[54]\ttraining's binary_logloss: 0.589471\n",
      "[55]\ttraining's binary_logloss: 0.589319\n",
      "[56]\ttraining's binary_logloss: 0.589211\n",
      "[57]\ttraining's binary_logloss: 0.589179\n",
      "[58]\ttraining's binary_logloss: 0.589078\n",
      "[59]\ttraining's binary_logloss: 0.588988\n",
      "[60]\ttraining's binary_logloss: 0.588889\n",
      "[61]\ttraining's binary_logloss: 0.588747\n",
      "[62]\ttraining's binary_logloss: 0.588678\n",
      "[63]\ttraining's binary_logloss: 0.588552\n",
      "[64]\ttraining's binary_logloss: 0.588439\n",
      "[65]\ttraining's binary_logloss: 0.588336\n",
      "[66]\ttraining's binary_logloss: 0.588227\n",
      "[67]\ttraining's binary_logloss: 0.58811\n",
      "[68]\ttraining's binary_logloss: 0.587995\n",
      "[69]\ttraining's binary_logloss: 0.587892\n",
      "[70]\ttraining's binary_logloss: 0.587845\n",
      "[71]\ttraining's binary_logloss: 0.587845\n",
      "[72]\ttraining's binary_logloss: 0.58774\n",
      "[73]\ttraining's binary_logloss: 0.587643\n",
      "[74]\ttraining's binary_logloss: 0.587557\n",
      "[75]\ttraining's binary_logloss: 0.587479\n",
      "[76]\ttraining's binary_logloss: 0.587456\n",
      "[77]\ttraining's binary_logloss: 0.58741\n",
      "[78]\ttraining's binary_logloss: 0.587398\n",
      "[79]\ttraining's binary_logloss: 0.587376\n",
      "[80]\ttraining's binary_logloss: 0.587333\n",
      "[81]\ttraining's binary_logloss: 0.587322\n",
      "[82]\ttraining's binary_logloss: 0.587268\n",
      "[83]\ttraining's binary_logloss: 0.587287\n",
      "[84]\ttraining's binary_logloss: 0.587314\n",
      "[85]\ttraining's binary_logloss: 0.587317\n",
      "[86]\ttraining's binary_logloss: 0.587339\n",
      "[87]\ttraining's binary_logloss: 0.587309\n",
      "[88]\ttraining's binary_logloss: 0.587307\n",
      "[89]\ttraining's binary_logloss: 0.587326\n",
      "[90]\ttraining's binary_logloss: 0.587365\n",
      "[91]\ttraining's binary_logloss: 0.587374\n",
      "[92]\ttraining's binary_logloss: 0.587333\n",
      "[93]\ttraining's binary_logloss: 0.587348\n",
      "[94]\ttraining's binary_logloss: 0.587353\n",
      "[95]\ttraining's binary_logloss: 0.587382\n",
      "[96]\ttraining's binary_logloss: 0.587434\n",
      "[97]\ttraining's binary_logloss: 0.587486\n",
      "[98]\ttraining's binary_logloss: 0.587479\n",
      "[99]\ttraining's binary_logloss: 0.587532\n",
      "[100]\ttraining's binary_logloss: 0.587581\n",
      "[101]\ttraining's binary_logloss: 0.587584\n",
      "[102]\ttraining's binary_logloss: 0.587604\n",
      "[103]\ttraining's binary_logloss: 0.587624\n",
      "[104]\ttraining's binary_logloss: 0.58764\n",
      "[105]\ttraining's binary_logloss: 0.587669\n",
      "[106]\ttraining's binary_logloss: 0.587678\n",
      "[107]\ttraining's binary_logloss: 0.587684\n",
      "[108]\ttraining's binary_logloss: 0.587746\n",
      "[109]\ttraining's binary_logloss: 0.587759\n",
      "[110]\ttraining's binary_logloss: 0.587784\n",
      "[111]\ttraining's binary_logloss: 0.587806\n",
      "[112]\ttraining's binary_logloss: 0.58783\n",
      "[113]\ttraining's binary_logloss: 0.587882\n",
      "[114]\ttraining's binary_logloss: 0.587932\n",
      "[115]\ttraining's binary_logloss: 0.587979\n",
      "[116]\ttraining's binary_logloss: 0.587944\n",
      "[117]\ttraining's binary_logloss: 0.587967\n",
      "[118]\ttraining's binary_logloss: 0.58799\n",
      "[119]\ttraining's binary_logloss: 0.587998\n",
      "[120]\ttraining's binary_logloss: 0.588059\n",
      "[121]\ttraining's binary_logloss: 0.58809\n",
      "[122]\ttraining's binary_logloss: 0.588134\n",
      "[123]\ttraining's binary_logloss: 0.588166\n",
      "[124]\ttraining's binary_logloss: 0.588193\n",
      "[125]\ttraining's binary_logloss: 0.588238\n",
      "[126]\ttraining's binary_logloss: 0.588278\n",
      "[127]\ttraining's binary_logloss: 0.588281\n",
      "[128]\ttraining's binary_logloss: 0.588305\n",
      "[129]\ttraining's binary_logloss: 0.588324\n",
      "[130]\ttraining's binary_logloss: 0.588344\n",
      "[131]\ttraining's binary_logloss: 0.588402\n",
      "[132]\ttraining's binary_logloss: 0.588462\n",
      "[133]\ttraining's binary_logloss: 0.588455\n",
      "[134]\ttraining's binary_logloss: 0.5885\n",
      "[135]\ttraining's binary_logloss: 0.588496\n",
      "[136]\ttraining's binary_logloss: 0.588534\n",
      "[137]\ttraining's binary_logloss: 0.588577\n",
      "[138]\ttraining's binary_logloss: 0.588622\n",
      "[139]\ttraining's binary_logloss: 0.588682\n",
      "[140]\ttraining's binary_logloss: 0.588685\n",
      "[141]\ttraining's binary_logloss: 0.588721\n",
      "[142]\ttraining's binary_logloss: 0.588767\n",
      "[143]\ttraining's binary_logloss: 0.588792\n",
      "[144]\ttraining's binary_logloss: 0.588822\n",
      "[145]\ttraining's binary_logloss: 0.588861\n",
      "[146]\ttraining's binary_logloss: 0.588859\n",
      "[147]\ttraining's binary_logloss: 0.58886\n",
      "[148]\ttraining's binary_logloss: 0.588903\n",
      "[149]\ttraining's binary_logloss: 0.588937\n",
      "[150]\ttraining's binary_logloss: 0.588984\n",
      "[151]\ttraining's binary_logloss: 0.589048\n",
      "[152]\ttraining's binary_logloss: 0.58914\n",
      "[153]\ttraining's binary_logloss: 0.589201\n",
      "[154]\ttraining's binary_logloss: 0.589268\n",
      "[155]\ttraining's binary_logloss: 0.589345\n",
      "[156]\ttraining's binary_logloss: 0.589363\n",
      "[157]\ttraining's binary_logloss: 0.589371\n",
      "[158]\ttraining's binary_logloss: 0.58938\n",
      "[159]\ttraining's binary_logloss: 0.589387\n",
      "[160]\ttraining's binary_logloss: 0.589427\n",
      "[161]\ttraining's binary_logloss: 0.589433\n",
      "[162]\ttraining's binary_logloss: 0.589442\n",
      "[163]\ttraining's binary_logloss: 0.589454\n",
      "[164]\ttraining's binary_logloss: 0.589467\n",
      "[165]\ttraining's binary_logloss: 0.589522\n",
      "[166]\ttraining's binary_logloss: 0.589535\n",
      "[167]\ttraining's binary_logloss: 0.589531\n",
      "[168]\ttraining's binary_logloss: 0.589566\n",
      "[169]\ttraining's binary_logloss: 0.589564\n",
      "[170]\ttraining's binary_logloss: 0.589596\n",
      "[171]\ttraining's binary_logloss: 0.589591\n",
      "[172]\ttraining's binary_logloss: 0.589611\n",
      "[173]\ttraining's binary_logloss: 0.589599\n",
      "[174]\ttraining's binary_logloss: 0.58959\n",
      "[175]\ttraining's binary_logloss: 0.589586\n",
      "[176]\ttraining's binary_logloss: 0.589611\n",
      "[177]\ttraining's binary_logloss: 0.589643\n",
      "[178]\ttraining's binary_logloss: 0.589694\n",
      "[179]\ttraining's binary_logloss: 0.589711\n",
      "[180]\ttraining's binary_logloss: 0.589743\n",
      "[181]\ttraining's binary_logloss: 0.589777\n",
      "[182]\ttraining's binary_logloss: 0.589814\n",
      "[183]\ttraining's binary_logloss: 0.589851\n",
      "[184]\ttraining's binary_logloss: 0.589892\n",
      "[185]\ttraining's binary_logloss: 0.589935\n",
      "[186]\ttraining's binary_logloss: 0.589976\n",
      "[187]\ttraining's binary_logloss: 0.590035\n",
      "[188]\ttraining's binary_logloss: 0.590079\n",
      "[189]\ttraining's binary_logloss: 0.590131\n",
      "[190]\ttraining's binary_logloss: 0.590192\n",
      "[191]\ttraining's binary_logloss: 0.590231\n",
      "[192]\ttraining's binary_logloss: 0.590235\n",
      "[193]\ttraining's binary_logloss: 0.590271\n",
      "[194]\ttraining's binary_logloss: 0.590301\n",
      "[195]\ttraining's binary_logloss: 0.590306\n",
      "[196]\ttraining's binary_logloss: 0.590279\n",
      "[197]\ttraining's binary_logloss: 0.590279\n",
      "[198]\ttraining's binary_logloss: 0.590252\n",
      "[199]\ttraining's binary_logloss: 0.590226\n",
      "[200]\ttraining's binary_logloss: 0.590225\n",
      "[201]\ttraining's binary_logloss: 0.59023\n",
      "[202]\ttraining's binary_logloss: 0.590198\n",
      "[203]\ttraining's binary_logloss: 0.590175\n",
      "[204]\ttraining's binary_logloss: 0.590137\n",
      "[205]\ttraining's binary_logloss: 0.590114\n",
      "[206]\ttraining's binary_logloss: 0.590128\n",
      "[207]\ttraining's binary_logloss: 0.590134\n",
      "[208]\ttraining's binary_logloss: 0.590156\n",
      "[209]\ttraining's binary_logloss: 0.590179\n",
      "[210]\ttraining's binary_logloss: 0.590189\n",
      "[211]\ttraining's binary_logloss: 0.590182\n",
      "[212]\ttraining's binary_logloss: 0.590168\n",
      "[213]\ttraining's binary_logloss: 0.590154\n",
      "[214]\ttraining's binary_logloss: 0.590152\n",
      "[215]\ttraining's binary_logloss: 0.590145\n",
      "[216]\ttraining's binary_logloss: 0.590122\n",
      "[217]\ttraining's binary_logloss: 0.5901\n",
      "[218]\ttraining's binary_logloss: 0.590079\n",
      "[219]\ttraining's binary_logloss: 0.590059\n",
      "[220]\ttraining's binary_logloss: 0.590035\n",
      "[221]\ttraining's binary_logloss: 0.590004\n",
      "[222]\ttraining's binary_logloss: 0.590019\n",
      "[223]\ttraining's binary_logloss: 0.590037\n",
      "[224]\ttraining's binary_logloss: 0.590008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[225]\ttraining's binary_logloss: 0.590025\n",
      "[226]\ttraining's binary_logloss: 0.590027\n",
      "[227]\ttraining's binary_logloss: 0.590018\n",
      "[228]\ttraining's binary_logloss: 0.590009\n",
      "[229]\ttraining's binary_logloss: 0.589999\n",
      "[230]\ttraining's binary_logloss: 0.590003\n",
      "[231]\ttraining's binary_logloss: 0.589976\n",
      "[232]\ttraining's binary_logloss: 0.589934\n",
      "[233]\ttraining's binary_logloss: 0.589894\n",
      "[234]\ttraining's binary_logloss: 0.589857\n",
      "[235]\ttraining's binary_logloss: 0.589823\n",
      "[236]\ttraining's binary_logloss: 0.589809\n",
      "[237]\ttraining's binary_logloss: 0.5898\n",
      "[238]\ttraining's binary_logloss: 0.589791\n",
      "[239]\ttraining's binary_logloss: 0.589776\n",
      "[240]\ttraining's binary_logloss: 0.589765\n",
      "[241]\ttraining's binary_logloss: 0.589762\n",
      "[242]\ttraining's binary_logloss: 0.589751\n",
      "[243]\ttraining's binary_logloss: 0.589751\n",
      "[244]\ttraining's binary_logloss: 0.589749\n",
      "[245]\ttraining's binary_logloss: 0.589711\n",
      "[246]\ttraining's binary_logloss: 0.589664\n",
      "[247]\ttraining's binary_logloss: 0.589626\n",
      "[248]\ttraining's binary_logloss: 0.589561\n",
      "[249]\ttraining's binary_logloss: 0.589516\n",
      "[250]\ttraining's binary_logloss: 0.589476\n",
      "[251]\ttraining's binary_logloss: 0.589482\n",
      "[252]\ttraining's binary_logloss: 0.589478\n",
      "[253]\ttraining's binary_logloss: 0.589484\n",
      "[254]\ttraining's binary_logloss: 0.58949\n",
      "[255]\ttraining's binary_logloss: 0.589489\n",
      "[256]\ttraining's binary_logloss: 0.589456\n",
      "[257]\ttraining's binary_logloss: 0.589421\n",
      "[258]\ttraining's binary_logloss: 0.589391\n",
      "[259]\ttraining's binary_logloss: 0.589352\n",
      "[260]\ttraining's binary_logloss: 0.589331\n",
      "[261]\ttraining's binary_logloss: 0.589263\n",
      "[262]\ttraining's binary_logloss: 0.589189\n",
      "[263]\ttraining's binary_logloss: 0.589119\n",
      "[264]\ttraining's binary_logloss: 0.58905\n",
      "[265]\ttraining's binary_logloss: 0.58899\n",
      "[266]\ttraining's binary_logloss: 0.589002\n",
      "[267]\ttraining's binary_logloss: 0.588975\n",
      "[268]\ttraining's binary_logloss: 0.588959\n",
      "[269]\ttraining's binary_logloss: 0.588929\n",
      "[270]\ttraining's binary_logloss: 0.588907\n",
      "[271]\ttraining's binary_logloss: 0.588884\n",
      "[272]\ttraining's binary_logloss: 0.588868\n",
      "[273]\ttraining's binary_logloss: 0.588825\n",
      "[274]\ttraining's binary_logloss: 0.588808\n",
      "[275]\ttraining's binary_logloss: 0.58879\n",
      "[276]\ttraining's binary_logloss: 0.588747\n",
      "[277]\ttraining's binary_logloss: 0.588707\n",
      "[278]\ttraining's binary_logloss: 0.58867\n",
      "[279]\ttraining's binary_logloss: 0.588627\n",
      "[280]\ttraining's binary_logloss: 0.588607\n",
      "[281]\ttraining's binary_logloss: 0.58859\n",
      "[282]\ttraining's binary_logloss: 0.588576\n",
      "[283]\ttraining's binary_logloss: 0.588559\n",
      "[284]\ttraining's binary_logloss: 0.588537\n",
      "[285]\ttraining's binary_logloss: 0.58852\n",
      "[286]\ttraining's binary_logloss: 0.58842\n",
      "[287]\ttraining's binary_logloss: 0.588341\n",
      "[288]\ttraining's binary_logloss: 0.588266\n",
      "[289]\ttraining's binary_logloss: 0.588175\n",
      "[290]\ttraining's binary_logloss: 0.588103\n",
      "[291]\ttraining's binary_logloss: 0.588065\n",
      "[292]\ttraining's binary_logloss: 0.588035\n",
      "[293]\ttraining's binary_logloss: 0.587984\n",
      "[294]\ttraining's binary_logloss: 0.587949\n",
      "[295]\ttraining's binary_logloss: 0.587913\n",
      "[296]\ttraining's binary_logloss: 0.587833\n",
      "[297]\ttraining's binary_logloss: 0.587756\n",
      "[298]\ttraining's binary_logloss: 0.58768\n",
      "[299]\ttraining's binary_logloss: 0.587603\n",
      "[300]\ttraining's binary_logloss: 0.587522\n",
      "[301]\ttraining's binary_logloss: 0.587451\n",
      "[302]\ttraining's binary_logloss: 0.587379\n",
      "[303]\ttraining's binary_logloss: 0.587306\n",
      "[304]\ttraining's binary_logloss: 0.587241\n",
      "[305]\ttraining's binary_logloss: 0.587172\n",
      "[306]\ttraining's binary_logloss: 0.587067\n",
      "[307]\ttraining's binary_logloss: 0.586962\n",
      "[308]\ttraining's binary_logloss: 0.586855\n",
      "[309]\ttraining's binary_logloss: 0.58677\n",
      "[310]\ttraining's binary_logloss: 0.58671\n",
      "[311]\ttraining's binary_logloss: 0.586659\n",
      "[312]\ttraining's binary_logloss: 0.586607\n",
      "[313]\ttraining's binary_logloss: 0.586558\n",
      "[314]\ttraining's binary_logloss: 0.586507\n",
      "[315]\ttraining's binary_logloss: 0.586441\n",
      "[316]\ttraining's binary_logloss: 0.586383\n",
      "[317]\ttraining's binary_logloss: 0.586342\n",
      "[318]\ttraining's binary_logloss: 0.586286\n",
      "[319]\ttraining's binary_logloss: 0.586237\n",
      "[320]\ttraining's binary_logloss: 0.586194\n",
      "[321]\ttraining's binary_logloss: 0.586166\n",
      "[322]\ttraining's binary_logloss: 0.586138\n",
      "[323]\ttraining's binary_logloss: 0.58611\n",
      "[324]\ttraining's binary_logloss: 0.586091\n",
      "[325]\ttraining's binary_logloss: 0.586081\n",
      "[326]\ttraining's binary_logloss: 0.58604\n",
      "[327]\ttraining's binary_logloss: 0.586001\n",
      "[328]\ttraining's binary_logloss: 0.585956\n",
      "[329]\ttraining's binary_logloss: 0.585932\n",
      "[330]\ttraining's binary_logloss: 0.585894\n",
      "[331]\ttraining's binary_logloss: 0.585807\n",
      "[332]\ttraining's binary_logloss: 0.585739\n",
      "[333]\ttraining's binary_logloss: 0.585671\n",
      "[334]\ttraining's binary_logloss: 0.585587\n",
      "[335]\ttraining's binary_logloss: 0.585521\n",
      "[336]\ttraining's binary_logloss: 0.58542\n",
      "[337]\ttraining's binary_logloss: 0.585356\n",
      "[338]\ttraining's binary_logloss: 0.585294\n",
      "[339]\ttraining's binary_logloss: 0.585195\n",
      "[340]\ttraining's binary_logloss: 0.585115\n",
      "[341]\ttraining's binary_logloss: 0.585029\n",
      "[342]\ttraining's binary_logloss: 0.584939\n",
      "[343]\ttraining's binary_logloss: 0.584846\n",
      "[344]\ttraining's binary_logloss: 0.584757\n",
      "[345]\ttraining's binary_logloss: 0.584676\n",
      "[346]\ttraining's binary_logloss: 0.584643\n",
      "[347]\ttraining's binary_logloss: 0.584584\n",
      "[348]\ttraining's binary_logloss: 0.584528\n",
      "[349]\ttraining's binary_logloss: 0.584476\n",
      "[350]\ttraining's binary_logloss: 0.584427\n",
      "[351]\ttraining's binary_logloss: 0.584339\n",
      "[352]\ttraining's binary_logloss: 0.584267\n",
      "[353]\ttraining's binary_logloss: 0.584186\n",
      "[354]\ttraining's binary_logloss: 0.584105\n",
      "[355]\ttraining's binary_logloss: 0.58403\n",
      "[356]\ttraining's binary_logloss: 0.58397\n",
      "[357]\ttraining's binary_logloss: 0.583903\n",
      "[358]\ttraining's binary_logloss: 0.583841\n",
      "[359]\ttraining's binary_logloss: 0.583801\n",
      "[360]\ttraining's binary_logloss: 0.583737\n",
      "[361]\ttraining's binary_logloss: 0.583665\n",
      "[362]\ttraining's binary_logloss: 0.583612\n",
      "[363]\ttraining's binary_logloss: 0.583559\n",
      "[364]\ttraining's binary_logloss: 0.58351\n",
      "[365]\ttraining's binary_logloss: 0.583452\n",
      "[366]\ttraining's binary_logloss: 0.583429\n",
      "[367]\ttraining's binary_logloss: 0.583408\n",
      "[368]\ttraining's binary_logloss: 0.58339\n",
      "[369]\ttraining's binary_logloss: 0.58337\n",
      "[370]\ttraining's binary_logloss: 0.583353\n",
      "[371]\ttraining's binary_logloss: 0.583296\n",
      "[372]\ttraining's binary_logloss: 0.583222\n",
      "[373]\ttraining's binary_logloss: 0.583172\n",
      "[374]\ttraining's binary_logloss: 0.583126\n",
      "[375]\ttraining's binary_logloss: 0.583023\n",
      "[376]\ttraining's binary_logloss: 0.582923\n",
      "[377]\ttraining's binary_logloss: 0.582828\n",
      "[378]\ttraining's binary_logloss: 0.582727\n",
      "[379]\ttraining's binary_logloss: 0.582635\n",
      "[380]\ttraining's binary_logloss: 0.582538\n",
      "[381]\ttraining's binary_logloss: 0.582452\n",
      "[382]\ttraining's binary_logloss: 0.582388\n",
      "[383]\ttraining's binary_logloss: 0.582304\n",
      "[384]\ttraining's binary_logloss: 0.582246\n",
      "[385]\ttraining's binary_logloss: 0.582163\n",
      "[386]\ttraining's binary_logloss: 0.5821\n",
      "[387]\ttraining's binary_logloss: 0.582037\n",
      "[388]\ttraining's binary_logloss: 0.581985\n",
      "[389]\ttraining's binary_logloss: 0.581935\n",
      "[390]\ttraining's binary_logloss: 0.58187\n",
      "[391]\ttraining's binary_logloss: 0.581743\n",
      "[392]\ttraining's binary_logloss: 0.581618\n",
      "[393]\ttraining's binary_logloss: 0.581496\n",
      "[394]\ttraining's binary_logloss: 0.581376\n",
      "[395]\ttraining's binary_logloss: 0.581259\n",
      "[396]\ttraining's binary_logloss: 0.581202\n",
      "[397]\ttraining's binary_logloss: 0.58114\n",
      "[398]\ttraining's binary_logloss: 0.581079\n",
      "[399]\ttraining's binary_logloss: 0.58099\n",
      "[400]\ttraining's binary_logloss: 0.5809\n",
      "[401]\ttraining's binary_logloss: 0.580817\n",
      "[402]\ttraining's binary_logloss: 0.580737\n",
      "[403]\ttraining's binary_logloss: 0.580658\n",
      "[404]\ttraining's binary_logloss: 0.580586\n",
      "[405]\ttraining's binary_logloss: 0.580522\n",
      "[406]\ttraining's binary_logloss: 0.580458\n",
      "[407]\ttraining's binary_logloss: 0.580395\n",
      "[408]\ttraining's binary_logloss: 0.580328\n",
      "[409]\ttraining's binary_logloss: 0.580277\n",
      "[410]\ttraining's binary_logloss: 0.58023\n",
      "[411]\ttraining's binary_logloss: 0.58016\n",
      "[412]\ttraining's binary_logloss: 0.580093\n",
      "[413]\ttraining's binary_logloss: 0.580032\n",
      "[414]\ttraining's binary_logloss: 0.579976\n",
      "[415]\ttraining's binary_logloss: 0.579915\n",
      "[416]\ttraining's binary_logloss: 0.579858\n",
      "[417]\ttraining's binary_logloss: 0.579802\n",
      "[418]\ttraining's binary_logloss: 0.579748\n",
      "[419]\ttraining's binary_logloss: 0.579678\n",
      "[420]\ttraining's binary_logloss: 0.579627\n",
      "[421]\ttraining's binary_logloss: 0.579611\n",
      "[422]\ttraining's binary_logloss: 0.579603\n",
      "[423]\ttraining's binary_logloss: 0.579585\n",
      "[424]\ttraining's binary_logloss: 0.57958\n",
      "[425]\ttraining's binary_logloss: 0.57957\n",
      "[426]\ttraining's binary_logloss: 0.57946\n",
      "[427]\ttraining's binary_logloss: 0.579349\n",
      "[428]\ttraining's binary_logloss: 0.579241\n",
      "[429]\ttraining's binary_logloss: 0.579138\n",
      "[430]\ttraining's binary_logloss: 0.57903\n",
      "[431]\ttraining's binary_logloss: 0.578977\n",
      "[432]\ttraining's binary_logloss: 0.578909\n",
      "[433]\ttraining's binary_logloss: 0.578871\n",
      "[434]\ttraining's binary_logloss: 0.578822\n",
      "[435]\ttraining's binary_logloss: 0.578772\n",
      "[436]\ttraining's binary_logloss: 0.578679\n",
      "[437]\ttraining's binary_logloss: 0.578602\n",
      "[438]\ttraining's binary_logloss: 0.578505\n",
      "[439]\ttraining's binary_logloss: 0.578431\n",
      "[440]\ttraining's binary_logloss: 0.57834\n",
      "[441]\ttraining's binary_logloss: 0.578267\n",
      "[442]\ttraining's binary_logloss: 0.578172\n",
      "[443]\ttraining's binary_logloss: 0.578076\n",
      "[444]\ttraining's binary_logloss: 0.577986\n",
      "[445]\ttraining's binary_logloss: 0.577917\n",
      "[446]\ttraining's binary_logloss: 0.577859\n",
      "[447]\ttraining's binary_logloss: 0.577804\n",
      "[448]\ttraining's binary_logloss: 0.577747\n",
      "[449]\ttraining's binary_logloss: 0.577703\n",
      "[450]\ttraining's binary_logloss: 0.577648\n",
      "[451]\ttraining's binary_logloss: 0.577602\n",
      "[452]\ttraining's binary_logloss: 0.57756\n",
      "[453]\ttraining's binary_logloss: 0.577516\n",
      "[454]\ttraining's binary_logloss: 0.577474\n",
      "[455]\ttraining's binary_logloss: 0.577439\n",
      "[456]\ttraining's binary_logloss: 0.577373\n",
      "[457]\ttraining's binary_logloss: 0.577289\n",
      "[458]\ttraining's binary_logloss: 0.577226\n",
      "[459]\ttraining's binary_logloss: 0.577169\n",
      "[460]\ttraining's binary_logloss: 0.577111\n",
      "[461]\ttraining's binary_logloss: 0.577038\n",
      "[462]\ttraining's binary_logloss: 0.576959\n",
      "[463]\ttraining's binary_logloss: 0.576873\n",
      "[464]\ttraining's binary_logloss: 0.576808\n",
      "[465]\ttraining's binary_logloss: 0.57674\n",
      "[466]\ttraining's binary_logloss: 0.576647\n",
      "[467]\ttraining's binary_logloss: 0.576553\n",
      "[468]\ttraining's binary_logloss: 0.576457\n",
      "[469]\ttraining's binary_logloss: 0.576353\n",
      "[470]\ttraining's binary_logloss: 0.576267\n",
      "[471]\ttraining's binary_logloss: 0.576203\n",
      "[472]\ttraining's binary_logloss: 0.576138\n",
      "[473]\ttraining's binary_logloss: 0.576077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[474]\ttraining's binary_logloss: 0.576018\n",
      "[475]\ttraining's binary_logloss: 0.575948\n",
      "[476]\ttraining's binary_logloss: 0.575884\n",
      "[477]\ttraining's binary_logloss: 0.575823\n",
      "[478]\ttraining's binary_logloss: 0.575764\n",
      "[479]\ttraining's binary_logloss: 0.575698\n",
      "[480]\ttraining's binary_logloss: 0.575641\n",
      "[481]\ttraining's binary_logloss: 0.575564\n",
      "[482]\ttraining's binary_logloss: 0.575492\n",
      "[483]\ttraining's binary_logloss: 0.575419\n",
      "[484]\ttraining's binary_logloss: 0.575345\n",
      "[485]\ttraining's binary_logloss: 0.575273\n",
      "[486]\ttraining's binary_logloss: 0.575208\n",
      "[487]\ttraining's binary_logloss: 0.575135\n",
      "[488]\ttraining's binary_logloss: 0.575066\n",
      "[489]\ttraining's binary_logloss: 0.57499\n",
      "[490]\ttraining's binary_logloss: 0.574926\n",
      "[491]\ttraining's binary_logloss: 0.574849\n",
      "[492]\ttraining's binary_logloss: 0.574768\n",
      "[493]\ttraining's binary_logloss: 0.574695\n",
      "[494]\ttraining's binary_logloss: 0.574638\n",
      "[495]\ttraining's binary_logloss: 0.574554\n",
      "[496]\ttraining's binary_logloss: 0.574442\n",
      "[497]\ttraining's binary_logloss: 0.574338\n",
      "[498]\ttraining's binary_logloss: 0.574232\n",
      "[499]\ttraining's binary_logloss: 0.574132\n",
      "[500]\ttraining's binary_logloss: 0.574033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614273\n",
      "[2]\ttraining's binary_logloss: 0.613032\n",
      "[3]\ttraining's binary_logloss: 0.611817\n",
      "[4]\ttraining's binary_logloss: 0.610663\n",
      "[5]\ttraining's binary_logloss: 0.609598\n",
      "[6]\ttraining's binary_logloss: 0.608435\n",
      "[7]\ttraining's binary_logloss: 0.607342\n",
      "[8]\ttraining's binary_logloss: 0.606251\n",
      "[9]\ttraining's binary_logloss: 0.605176\n",
      "[10]\ttraining's binary_logloss: 0.604161\n",
      "[11]\ttraining's binary_logloss: 0.603172\n",
      "[12]\ttraining's binary_logloss: 0.602213\n",
      "[13]\ttraining's binary_logloss: 0.601354\n",
      "[14]\ttraining's binary_logloss: 0.600468\n",
      "[15]\ttraining's binary_logloss: 0.599635\n",
      "[16]\ttraining's binary_logloss: 0.598762\n",
      "[17]\ttraining's binary_logloss: 0.597992\n",
      "[18]\ttraining's binary_logloss: 0.597246\n",
      "[19]\ttraining's binary_logloss: 0.59653\n",
      "[20]\ttraining's binary_logloss: 0.595741\n",
      "[21]\ttraining's binary_logloss: 0.595005\n",
      "[22]\ttraining's binary_logloss: 0.594285\n",
      "[23]\ttraining's binary_logloss: 0.593586\n",
      "[24]\ttraining's binary_logloss: 0.592972\n",
      "[25]\ttraining's binary_logloss: 0.592352\n",
      "[26]\ttraining's binary_logloss: 0.591742\n",
      "[27]\ttraining's binary_logloss: 0.591156\n",
      "[28]\ttraining's binary_logloss: 0.590625\n",
      "[29]\ttraining's binary_logloss: 0.59008\n",
      "[30]\ttraining's binary_logloss: 0.589556\n",
      "[31]\ttraining's binary_logloss: 0.588956\n",
      "[32]\ttraining's binary_logloss: 0.588488\n",
      "[33]\ttraining's binary_logloss: 0.588058\n",
      "[34]\ttraining's binary_logloss: 0.587612\n",
      "[35]\ttraining's binary_logloss: 0.587185\n",
      "[36]\ttraining's binary_logloss: 0.586782\n",
      "[37]\ttraining's binary_logloss: 0.586432\n",
      "[38]\ttraining's binary_logloss: 0.586045\n",
      "[39]\ttraining's binary_logloss: 0.585724\n",
      "[40]\ttraining's binary_logloss: 0.585368\n",
      "[41]\ttraining's binary_logloss: 0.584945\n",
      "[42]\ttraining's binary_logloss: 0.584546\n",
      "[43]\ttraining's binary_logloss: 0.584163\n",
      "[44]\ttraining's binary_logloss: 0.583768\n",
      "[45]\ttraining's binary_logloss: 0.583397\n",
      "[46]\ttraining's binary_logloss: 0.583067\n",
      "[47]\ttraining's binary_logloss: 0.582691\n",
      "[48]\ttraining's binary_logloss: 0.582319\n",
      "[49]\ttraining's binary_logloss: 0.581971\n",
      "[50]\ttraining's binary_logloss: 0.581706\n",
      "[51]\ttraining's binary_logloss: 0.58143\n",
      "[52]\ttraining's binary_logloss: 0.581149\n",
      "[53]\ttraining's binary_logloss: 0.580877\n",
      "[54]\ttraining's binary_logloss: 0.580622\n",
      "[55]\ttraining's binary_logloss: 0.580422\n",
      "[56]\ttraining's binary_logloss: 0.580213\n",
      "[57]\ttraining's binary_logloss: 0.579994\n",
      "[58]\ttraining's binary_logloss: 0.579737\n",
      "[59]\ttraining's binary_logloss: 0.579543\n",
      "[60]\ttraining's binary_logloss: 0.579346\n",
      "[61]\ttraining's binary_logloss: 0.579139\n",
      "[62]\ttraining's binary_logloss: 0.578969\n",
      "[63]\ttraining's binary_logloss: 0.578762\n",
      "[64]\ttraining's binary_logloss: 0.578595\n",
      "[65]\ttraining's binary_logloss: 0.578441\n",
      "[66]\ttraining's binary_logloss: 0.578259\n",
      "[67]\ttraining's binary_logloss: 0.578093\n",
      "[68]\ttraining's binary_logloss: 0.577929\n",
      "[69]\ttraining's binary_logloss: 0.577767\n",
      "[70]\ttraining's binary_logloss: 0.577613\n",
      "[71]\ttraining's binary_logloss: 0.577506\n",
      "[72]\ttraining's binary_logloss: 0.577388\n",
      "[73]\ttraining's binary_logloss: 0.577264\n",
      "[74]\ttraining's binary_logloss: 0.577145\n",
      "[75]\ttraining's binary_logloss: 0.57704\n",
      "[76]\ttraining's binary_logloss: 0.576925\n",
      "[77]\ttraining's binary_logloss: 0.576824\n",
      "[78]\ttraining's binary_logloss: 0.576717\n",
      "[79]\ttraining's binary_logloss: 0.576604\n",
      "[80]\ttraining's binary_logloss: 0.576519\n",
      "[81]\ttraining's binary_logloss: 0.57636\n",
      "[82]\ttraining's binary_logloss: 0.576234\n",
      "[83]\ttraining's binary_logloss: 0.576092\n",
      "[84]\ttraining's binary_logloss: 0.575963\n",
      "[85]\ttraining's binary_logloss: 0.575841\n",
      "[86]\ttraining's binary_logloss: 0.575782\n",
      "[87]\ttraining's binary_logloss: 0.575681\n",
      "[88]\ttraining's binary_logloss: 0.575605\n",
      "[89]\ttraining's binary_logloss: 0.575528\n",
      "[90]\ttraining's binary_logloss: 0.575451\n",
      "[91]\ttraining's binary_logloss: 0.575367\n",
      "[92]\ttraining's binary_logloss: 0.5753\n",
      "[93]\ttraining's binary_logloss: 0.57523\n",
      "[94]\ttraining's binary_logloss: 0.575168\n",
      "[95]\ttraining's binary_logloss: 0.575105\n",
      "[96]\ttraining's binary_logloss: 0.575015\n",
      "[97]\ttraining's binary_logloss: 0.574926\n",
      "[98]\ttraining's binary_logloss: 0.574795\n",
      "[99]\ttraining's binary_logloss: 0.574671\n",
      "[100]\ttraining's binary_logloss: 0.574595\n",
      "[101]\ttraining's binary_logloss: 0.57452\n",
      "[102]\ttraining's binary_logloss: 0.574442\n",
      "[103]\ttraining's binary_logloss: 0.574377\n",
      "[104]\ttraining's binary_logloss: 0.574314\n",
      "[105]\ttraining's binary_logloss: 0.574249\n",
      "[106]\ttraining's binary_logloss: 0.574157\n",
      "[107]\ttraining's binary_logloss: 0.574104\n",
      "[108]\ttraining's binary_logloss: 0.574016\n",
      "[109]\ttraining's binary_logloss: 0.57393\n",
      "[110]\ttraining's binary_logloss: 0.573829\n",
      "[111]\ttraining's binary_logloss: 0.573748\n",
      "[112]\ttraining's binary_logloss: 0.573671\n",
      "[113]\ttraining's binary_logloss: 0.573616\n",
      "[114]\ttraining's binary_logloss: 0.573536\n",
      "[115]\ttraining's binary_logloss: 0.573475\n",
      "[116]\ttraining's binary_logloss: 0.57341\n",
      "[117]\ttraining's binary_logloss: 0.573352\n",
      "[118]\ttraining's binary_logloss: 0.573302\n",
      "[119]\ttraining's binary_logloss: 0.57326\n",
      "[120]\ttraining's binary_logloss: 0.573216\n",
      "[121]\ttraining's binary_logloss: 0.573142\n",
      "[122]\ttraining's binary_logloss: 0.573106\n",
      "[123]\ttraining's binary_logloss: 0.573076\n",
      "[124]\ttraining's binary_logloss: 0.573054\n",
      "[125]\ttraining's binary_logloss: 0.573036\n",
      "[126]\ttraining's binary_logloss: 0.57298\n",
      "[127]\ttraining's binary_logloss: 0.572926\n",
      "[128]\ttraining's binary_logloss: 0.572878\n",
      "[129]\ttraining's binary_logloss: 0.572831\n",
      "[130]\ttraining's binary_logloss: 0.57277\n",
      "[131]\ttraining's binary_logloss: 0.572685\n",
      "[132]\ttraining's binary_logloss: 0.572605\n",
      "[133]\ttraining's binary_logloss: 0.572521\n",
      "[134]\ttraining's binary_logloss: 0.572447\n",
      "[135]\ttraining's binary_logloss: 0.572339\n",
      "[136]\ttraining's binary_logloss: 0.572268\n",
      "[137]\ttraining's binary_logloss: 0.572197\n",
      "[138]\ttraining's binary_logloss: 0.572138\n",
      "[139]\ttraining's binary_logloss: 0.572072\n",
      "[140]\ttraining's binary_logloss: 0.572015\n",
      "[141]\ttraining's binary_logloss: 0.571955\n",
      "[142]\ttraining's binary_logloss: 0.5719\n",
      "[143]\ttraining's binary_logloss: 0.571851\n",
      "[144]\ttraining's binary_logloss: 0.571791\n",
      "[145]\ttraining's binary_logloss: 0.571726\n",
      "[146]\ttraining's binary_logloss: 0.571629\n",
      "[147]\ttraining's binary_logloss: 0.571575\n",
      "[148]\ttraining's binary_logloss: 0.571508\n",
      "[149]\ttraining's binary_logloss: 0.571425\n",
      "[150]\ttraining's binary_logloss: 0.571364\n",
      "[151]\ttraining's binary_logloss: 0.571262\n",
      "[152]\ttraining's binary_logloss: 0.571157\n",
      "[153]\ttraining's binary_logloss: 0.571058\n",
      "[154]\ttraining's binary_logloss: 0.570963\n",
      "[155]\ttraining's binary_logloss: 0.570881\n",
      "[156]\ttraining's binary_logloss: 0.570864\n",
      "[157]\ttraining's binary_logloss: 0.570829\n",
      "[158]\ttraining's binary_logloss: 0.570838\n",
      "[159]\ttraining's binary_logloss: 0.570809\n",
      "[160]\ttraining's binary_logloss: 0.570773\n",
      "[161]\ttraining's binary_logloss: 0.570676\n",
      "[162]\ttraining's binary_logloss: 0.570588\n",
      "[163]\ttraining's binary_logloss: 0.570519\n",
      "[164]\ttraining's binary_logloss: 0.570452\n",
      "[165]\ttraining's binary_logloss: 0.570367\n",
      "[166]\ttraining's binary_logloss: 0.570307\n",
      "[167]\ttraining's binary_logloss: 0.570203\n",
      "[168]\ttraining's binary_logloss: 0.570142\n",
      "[169]\ttraining's binary_logloss: 0.570075\n",
      "[170]\ttraining's binary_logloss: 0.570002\n",
      "[171]\ttraining's binary_logloss: 0.569915\n",
      "[172]\ttraining's binary_logloss: 0.569835\n",
      "[173]\ttraining's binary_logloss: 0.569761\n",
      "[174]\ttraining's binary_logloss: 0.569735\n",
      "[175]\ttraining's binary_logloss: 0.569671\n",
      "[176]\ttraining's binary_logloss: 0.569589\n",
      "[177]\ttraining's binary_logloss: 0.569544\n",
      "[178]\ttraining's binary_logloss: 0.569517\n",
      "[179]\ttraining's binary_logloss: 0.569445\n",
      "[180]\ttraining's binary_logloss: 0.569366\n",
      "[181]\ttraining's binary_logloss: 0.56931\n",
      "[182]\ttraining's binary_logloss: 0.56925\n",
      "[183]\ttraining's binary_logloss: 0.569188\n",
      "[184]\ttraining's binary_logloss: 0.569109\n",
      "[185]\ttraining's binary_logloss: 0.569031\n",
      "[186]\ttraining's binary_logloss: 0.568967\n",
      "[187]\ttraining's binary_logloss: 0.568884\n",
      "[188]\ttraining's binary_logloss: 0.568826\n",
      "[189]\ttraining's binary_logloss: 0.568765\n",
      "[190]\ttraining's binary_logloss: 0.568696\n",
      "[191]\ttraining's binary_logloss: 0.568621\n",
      "[192]\ttraining's binary_logloss: 0.568548\n",
      "[193]\ttraining's binary_logloss: 0.568485\n",
      "[194]\ttraining's binary_logloss: 0.568406\n",
      "[195]\ttraining's binary_logloss: 0.568351\n",
      "[196]\ttraining's binary_logloss: 0.568307\n",
      "[197]\ttraining's binary_logloss: 0.568216\n",
      "[198]\ttraining's binary_logloss: 0.568128\n",
      "[199]\ttraining's binary_logloss: 0.568046\n",
      "[200]\ttraining's binary_logloss: 0.567994\n",
      "[201]\ttraining's binary_logloss: 0.567929\n",
      "[202]\ttraining's binary_logloss: 0.567867\n",
      "[203]\ttraining's binary_logloss: 0.56781\n",
      "[204]\ttraining's binary_logloss: 0.567773\n",
      "[205]\ttraining's binary_logloss: 0.567676\n",
      "[206]\ttraining's binary_logloss: 0.567589\n",
      "[207]\ttraining's binary_logloss: 0.567505\n",
      "[208]\ttraining's binary_logloss: 0.567437\n",
      "[209]\ttraining's binary_logloss: 0.567364\n",
      "[210]\ttraining's binary_logloss: 0.567283\n",
      "[211]\ttraining's binary_logloss: 0.567192\n",
      "[212]\ttraining's binary_logloss: 0.56712\n",
      "[213]\ttraining's binary_logloss: 0.567034\n",
      "[214]\ttraining's binary_logloss: 0.56695\n",
      "[215]\ttraining's binary_logloss: 0.566881\n",
      "[216]\ttraining's binary_logloss: 0.566783\n",
      "[217]\ttraining's binary_logloss: 0.566712\n",
      "[218]\ttraining's binary_logloss: 0.5666\n",
      "[219]\ttraining's binary_logloss: 0.566543\n",
      "[220]\ttraining's binary_logloss: 0.566454\n",
      "[221]\ttraining's binary_logloss: 0.566333\n",
      "[222]\ttraining's binary_logloss: 0.566234\n",
      "[223]\ttraining's binary_logloss: 0.566133\n",
      "[224]\ttraining's binary_logloss: 0.566023\n",
      "[225]\ttraining's binary_logloss: 0.565903\n",
      "[226]\ttraining's binary_logloss: 0.56582\n",
      "[227]\ttraining's binary_logloss: 0.565753\n",
      "[228]\ttraining's binary_logloss: 0.565695\n",
      "[229]\ttraining's binary_logloss: 0.565632\n",
      "[230]\ttraining's binary_logloss: 0.56557\n",
      "[231]\ttraining's binary_logloss: 0.565454\n",
      "[232]\ttraining's binary_logloss: 0.565327\n",
      "[233]\ttraining's binary_logloss: 0.565236\n",
      "[234]\ttraining's binary_logloss: 0.565133\n",
      "[235]\ttraining's binary_logloss: 0.56502\n",
      "[236]\ttraining's binary_logloss: 0.564893\n",
      "[237]\ttraining's binary_logloss: 0.564769\n",
      "[238]\ttraining's binary_logloss: 0.564648\n",
      "[239]\ttraining's binary_logloss: 0.564534\n",
      "[240]\ttraining's binary_logloss: 0.564405\n",
      "[241]\ttraining's binary_logloss: 0.564276\n",
      "[242]\ttraining's binary_logloss: 0.56416\n",
      "[243]\ttraining's binary_logloss: 0.56406\n",
      "[244]\ttraining's binary_logloss: 0.563945\n",
      "[245]\ttraining's binary_logloss: 0.563855\n",
      "[246]\ttraining's binary_logloss: 0.563796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[247]\ttraining's binary_logloss: 0.563747\n",
      "[248]\ttraining's binary_logloss: 0.563701\n",
      "[249]\ttraining's binary_logloss: 0.563661\n",
      "[250]\ttraining's binary_logloss: 0.563619\n",
      "[251]\ttraining's binary_logloss: 0.563505\n",
      "[252]\ttraining's binary_logloss: 0.563394\n",
      "[253]\ttraining's binary_logloss: 0.563308\n",
      "[254]\ttraining's binary_logloss: 0.56322\n",
      "[255]\ttraining's binary_logloss: 0.563115\n",
      "[256]\ttraining's binary_logloss: 0.562996\n",
      "[257]\ttraining's binary_logloss: 0.562893\n",
      "[258]\ttraining's binary_logloss: 0.562783\n",
      "[259]\ttraining's binary_logloss: 0.562671\n",
      "[260]\ttraining's binary_logloss: 0.562576\n",
      "[261]\ttraining's binary_logloss: 0.562461\n",
      "[262]\ttraining's binary_logloss: 0.562363\n",
      "[263]\ttraining's binary_logloss: 0.562255\n",
      "[264]\ttraining's binary_logloss: 0.562179\n",
      "[265]\ttraining's binary_logloss: 0.562074\n",
      "[266]\ttraining's binary_logloss: 0.562018\n",
      "[267]\ttraining's binary_logloss: 0.561949\n",
      "[268]\ttraining's binary_logloss: 0.561877\n",
      "[269]\ttraining's binary_logloss: 0.561809\n",
      "[270]\ttraining's binary_logloss: 0.561727\n",
      "[271]\ttraining's binary_logloss: 0.561619\n",
      "[272]\ttraining's binary_logloss: 0.561493\n",
      "[273]\ttraining's binary_logloss: 0.561382\n",
      "[274]\ttraining's binary_logloss: 0.561261\n",
      "[275]\ttraining's binary_logloss: 0.561159\n",
      "[276]\ttraining's binary_logloss: 0.561033\n",
      "[277]\ttraining's binary_logloss: 0.560908\n",
      "[278]\ttraining's binary_logloss: 0.560778\n",
      "[279]\ttraining's binary_logloss: 0.560666\n",
      "[280]\ttraining's binary_logloss: 0.560532\n",
      "[281]\ttraining's binary_logloss: 0.560434\n",
      "[282]\ttraining's binary_logloss: 0.560335\n",
      "[283]\ttraining's binary_logloss: 0.560229\n",
      "[284]\ttraining's binary_logloss: 0.560137\n",
      "[285]\ttraining's binary_logloss: 0.56006\n",
      "[286]\ttraining's binary_logloss: 0.559932\n",
      "[287]\ttraining's binary_logloss: 0.559822\n",
      "[288]\ttraining's binary_logloss: 0.559705\n",
      "[289]\ttraining's binary_logloss: 0.559579\n",
      "[290]\ttraining's binary_logloss: 0.559446\n",
      "[291]\ttraining's binary_logloss: 0.559317\n",
      "[292]\ttraining's binary_logloss: 0.559186\n",
      "[293]\ttraining's binary_logloss: 0.559043\n",
      "[294]\ttraining's binary_logloss: 0.558919\n",
      "[295]\ttraining's binary_logloss: 0.558794\n",
      "[296]\ttraining's binary_logloss: 0.558688\n",
      "[297]\ttraining's binary_logloss: 0.558601\n",
      "[298]\ttraining's binary_logloss: 0.558505\n",
      "[299]\ttraining's binary_logloss: 0.558407\n",
      "[300]\ttraining's binary_logloss: 0.558326\n",
      "[301]\ttraining's binary_logloss: 0.558176\n",
      "[302]\ttraining's binary_logloss: 0.558035\n",
      "[303]\ttraining's binary_logloss: 0.557908\n",
      "[304]\ttraining's binary_logloss: 0.557773\n",
      "[305]\ttraining's binary_logloss: 0.557645\n",
      "[306]\ttraining's binary_logloss: 0.557535\n",
      "[307]\ttraining's binary_logloss: 0.557414\n",
      "[308]\ttraining's binary_logloss: 0.5573\n",
      "[309]\ttraining's binary_logloss: 0.557196\n",
      "[310]\ttraining's binary_logloss: 0.557077\n",
      "[311]\ttraining's binary_logloss: 0.556985\n",
      "[312]\ttraining's binary_logloss: 0.556884\n",
      "[313]\ttraining's binary_logloss: 0.556805\n",
      "[314]\ttraining's binary_logloss: 0.556738\n",
      "[315]\ttraining's binary_logloss: 0.556621\n",
      "[316]\ttraining's binary_logloss: 0.556479\n",
      "[317]\ttraining's binary_logloss: 0.556338\n",
      "[318]\ttraining's binary_logloss: 0.5562\n",
      "[319]\ttraining's binary_logloss: 0.556064\n",
      "[320]\ttraining's binary_logloss: 0.555909\n",
      "[321]\ttraining's binary_logloss: 0.555785\n",
      "[322]\ttraining's binary_logloss: 0.555642\n",
      "[323]\ttraining's binary_logloss: 0.555511\n",
      "[324]\ttraining's binary_logloss: 0.555376\n",
      "[325]\ttraining's binary_logloss: 0.555241\n",
      "[326]\ttraining's binary_logloss: 0.555088\n",
      "[327]\ttraining's binary_logloss: 0.55495\n",
      "[328]\ttraining's binary_logloss: 0.554808\n",
      "[329]\ttraining's binary_logloss: 0.554671\n",
      "[330]\ttraining's binary_logloss: 0.554525\n",
      "[331]\ttraining's binary_logloss: 0.554356\n",
      "[332]\ttraining's binary_logloss: 0.554219\n",
      "[333]\ttraining's binary_logloss: 0.554078\n",
      "[334]\ttraining's binary_logloss: 0.553943\n",
      "[335]\ttraining's binary_logloss: 0.553808\n",
      "[336]\ttraining's binary_logloss: 0.553683\n",
      "[337]\ttraining's binary_logloss: 0.553587\n",
      "[338]\ttraining's binary_logloss: 0.553502\n",
      "[339]\ttraining's binary_logloss: 0.553426\n",
      "[340]\ttraining's binary_logloss: 0.553304\n",
      "[341]\ttraining's binary_logloss: 0.553223\n",
      "[342]\ttraining's binary_logloss: 0.553119\n",
      "[343]\ttraining's binary_logloss: 0.553018\n",
      "[344]\ttraining's binary_logloss: 0.552934\n",
      "[345]\ttraining's binary_logloss: 0.552851\n",
      "[346]\ttraining's binary_logloss: 0.552709\n",
      "[347]\ttraining's binary_logloss: 0.552596\n",
      "[348]\ttraining's binary_logloss: 0.552453\n",
      "[349]\ttraining's binary_logloss: 0.552314\n",
      "[350]\ttraining's binary_logloss: 0.552203\n",
      "[351]\ttraining's binary_logloss: 0.552054\n",
      "[352]\ttraining's binary_logloss: 0.551921\n",
      "[353]\ttraining's binary_logloss: 0.551799\n",
      "[354]\ttraining's binary_logloss: 0.551674\n",
      "[355]\ttraining's binary_logloss: 0.55156\n",
      "[356]\ttraining's binary_logloss: 0.551395\n",
      "[357]\ttraining's binary_logloss: 0.551243\n",
      "[358]\ttraining's binary_logloss: 0.551092\n",
      "[359]\ttraining's binary_logloss: 0.550957\n",
      "[360]\ttraining's binary_logloss: 0.550809\n",
      "[361]\ttraining's binary_logloss: 0.550644\n",
      "[362]\ttraining's binary_logloss: 0.550482\n",
      "[363]\ttraining's binary_logloss: 0.550323\n",
      "[364]\ttraining's binary_logloss: 0.55016\n",
      "[365]\ttraining's binary_logloss: 0.550013\n",
      "[366]\ttraining's binary_logloss: 0.549905\n",
      "[367]\ttraining's binary_logloss: 0.549792\n",
      "[368]\ttraining's binary_logloss: 0.549658\n",
      "[369]\ttraining's binary_logloss: 0.54955\n",
      "[370]\ttraining's binary_logloss: 0.549434\n",
      "[371]\ttraining's binary_logloss: 0.549315\n",
      "[372]\ttraining's binary_logloss: 0.549206\n",
      "[373]\ttraining's binary_logloss: 0.549094\n",
      "[374]\ttraining's binary_logloss: 0.548983\n",
      "[375]\ttraining's binary_logloss: 0.548875\n",
      "[376]\ttraining's binary_logloss: 0.548718\n",
      "[377]\ttraining's binary_logloss: 0.548565\n",
      "[378]\ttraining's binary_logloss: 0.548454\n",
      "[379]\ttraining's binary_logloss: 0.548304\n",
      "[380]\ttraining's binary_logloss: 0.548163\n",
      "[381]\ttraining's binary_logloss: 0.548097\n",
      "[382]\ttraining's binary_logloss: 0.548007\n",
      "[383]\ttraining's binary_logloss: 0.547933\n",
      "[384]\ttraining's binary_logloss: 0.547847\n",
      "[385]\ttraining's binary_logloss: 0.547764\n",
      "[386]\ttraining's binary_logloss: 0.547602\n",
      "[387]\ttraining's binary_logloss: 0.547405\n",
      "[388]\ttraining's binary_logloss: 0.547227\n",
      "[389]\ttraining's binary_logloss: 0.54706\n",
      "[390]\ttraining's binary_logloss: 0.546852\n",
      "[391]\ttraining's binary_logloss: 0.546714\n",
      "[392]\ttraining's binary_logloss: 0.546575\n",
      "[393]\ttraining's binary_logloss: 0.546438\n",
      "[394]\ttraining's binary_logloss: 0.546299\n",
      "[395]\ttraining's binary_logloss: 0.546164\n",
      "[396]\ttraining's binary_logloss: 0.546021\n",
      "[397]\ttraining's binary_logloss: 0.545879\n",
      "[398]\ttraining's binary_logloss: 0.545732\n",
      "[399]\ttraining's binary_logloss: 0.545594\n",
      "[400]\ttraining's binary_logloss: 0.545457\n",
      "[401]\ttraining's binary_logloss: 0.545295\n",
      "[402]\ttraining's binary_logloss: 0.54514\n",
      "[403]\ttraining's binary_logloss: 0.545006\n",
      "[404]\ttraining's binary_logloss: 0.544813\n",
      "[405]\ttraining's binary_logloss: 0.544641\n",
      "[406]\ttraining's binary_logloss: 0.544527\n",
      "[407]\ttraining's binary_logloss: 0.544413\n",
      "[408]\ttraining's binary_logloss: 0.544307\n",
      "[409]\ttraining's binary_logloss: 0.54419\n",
      "[410]\ttraining's binary_logloss: 0.544072\n",
      "[411]\ttraining's binary_logloss: 0.54392\n",
      "[412]\ttraining's binary_logloss: 0.543728\n",
      "[413]\ttraining's binary_logloss: 0.543546\n",
      "[414]\ttraining's binary_logloss: 0.543365\n",
      "[415]\ttraining's binary_logloss: 0.543178\n",
      "[416]\ttraining's binary_logloss: 0.543029\n",
      "[417]\ttraining's binary_logloss: 0.542883\n",
      "[418]\ttraining's binary_logloss: 0.542742\n",
      "[419]\ttraining's binary_logloss: 0.542606\n",
      "[420]\ttraining's binary_logloss: 0.542483\n",
      "[421]\ttraining's binary_logloss: 0.542373\n",
      "[422]\ttraining's binary_logloss: 0.54226\n",
      "[423]\ttraining's binary_logloss: 0.542173\n",
      "[424]\ttraining's binary_logloss: 0.542079\n",
      "[425]\ttraining's binary_logloss: 0.541971\n",
      "[426]\ttraining's binary_logloss: 0.541844\n",
      "[427]\ttraining's binary_logloss: 0.541742\n",
      "[428]\ttraining's binary_logloss: 0.541635\n",
      "[429]\ttraining's binary_logloss: 0.541534\n",
      "[430]\ttraining's binary_logloss: 0.541447\n",
      "[431]\ttraining's binary_logloss: 0.541271\n",
      "[432]\ttraining's binary_logloss: 0.541114\n",
      "[433]\ttraining's binary_logloss: 0.540933\n",
      "[434]\ttraining's binary_logloss: 0.54076\n",
      "[435]\ttraining's binary_logloss: 0.540591\n",
      "[436]\ttraining's binary_logloss: 0.540458\n",
      "[437]\ttraining's binary_logloss: 0.54032\n",
      "[438]\ttraining's binary_logloss: 0.540232\n",
      "[439]\ttraining's binary_logloss: 0.540118\n",
      "[440]\ttraining's binary_logloss: 0.539998\n",
      "[441]\ttraining's binary_logloss: 0.539824\n",
      "[442]\ttraining's binary_logloss: 0.539664\n",
      "[443]\ttraining's binary_logloss: 0.539543\n",
      "[444]\ttraining's binary_logloss: 0.539395\n",
      "[445]\ttraining's binary_logloss: 0.539242\n",
      "[446]\ttraining's binary_logloss: 0.539113\n",
      "[447]\ttraining's binary_logloss: 0.538961\n",
      "[448]\ttraining's binary_logloss: 0.538831\n",
      "[449]\ttraining's binary_logloss: 0.538682\n",
      "[450]\ttraining's binary_logloss: 0.53856\n",
      "[451]\ttraining's binary_logloss: 0.538448\n",
      "[452]\ttraining's binary_logloss: 0.538321\n",
      "[453]\ttraining's binary_logloss: 0.538173\n",
      "[454]\ttraining's binary_logloss: 0.538038\n",
      "[455]\ttraining's binary_logloss: 0.537888\n",
      "[456]\ttraining's binary_logloss: 0.537764\n",
      "[457]\ttraining's binary_logloss: 0.537647\n",
      "[458]\ttraining's binary_logloss: 0.537526\n",
      "[459]\ttraining's binary_logloss: 0.537408\n",
      "[460]\ttraining's binary_logloss: 0.537295\n",
      "[461]\ttraining's binary_logloss: 0.537129\n",
      "[462]\ttraining's binary_logloss: 0.53697\n",
      "[463]\ttraining's binary_logloss: 0.536803\n",
      "[464]\ttraining's binary_logloss: 0.536665\n",
      "[465]\ttraining's binary_logloss: 0.536509\n",
      "[466]\ttraining's binary_logloss: 0.536346\n",
      "[467]\ttraining's binary_logloss: 0.536186\n",
      "[468]\ttraining's binary_logloss: 0.536037\n",
      "[469]\ttraining's binary_logloss: 0.53592\n",
      "[470]\ttraining's binary_logloss: 0.535772\n",
      "[471]\ttraining's binary_logloss: 0.535649\n",
      "[472]\ttraining's binary_logloss: 0.535531\n",
      "[473]\ttraining's binary_logloss: 0.535401\n",
      "[474]\ttraining's binary_logloss: 0.535286\n",
      "[475]\ttraining's binary_logloss: 0.535178\n",
      "[476]\ttraining's binary_logloss: 0.535041\n",
      "[477]\ttraining's binary_logloss: 0.534916\n",
      "[478]\ttraining's binary_logloss: 0.534787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[479]\ttraining's binary_logloss: 0.53467\n",
      "[480]\ttraining's binary_logloss: 0.534568\n",
      "[481]\ttraining's binary_logloss: 0.534436\n",
      "[482]\ttraining's binary_logloss: 0.534311\n",
      "[483]\ttraining's binary_logloss: 0.53419\n",
      "[484]\ttraining's binary_logloss: 0.534071\n",
      "[485]\ttraining's binary_logloss: 0.53396\n",
      "[486]\ttraining's binary_logloss: 0.533796\n",
      "[487]\ttraining's binary_logloss: 0.533643\n",
      "[488]\ttraining's binary_logloss: 0.533492\n",
      "[489]\ttraining's binary_logloss: 0.533335\n",
      "[490]\ttraining's binary_logloss: 0.533181\n",
      "[491]\ttraining's binary_logloss: 0.533076\n",
      "[492]\ttraining's binary_logloss: 0.532977\n",
      "[493]\ttraining's binary_logloss: 0.532889\n",
      "[494]\ttraining's binary_logloss: 0.532805\n",
      "[495]\ttraining's binary_logloss: 0.532721\n",
      "[496]\ttraining's binary_logloss: 0.532568\n",
      "[497]\ttraining's binary_logloss: 0.532449\n",
      "[498]\ttraining's binary_logloss: 0.532314\n",
      "[499]\ttraining's binary_logloss: 0.532191\n",
      "[500]\ttraining's binary_logloss: 0.532079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613752\n",
      "[2]\ttraining's binary_logloss: 0.612334\n",
      "[3]\ttraining's binary_logloss: 0.610924\n",
      "[4]\ttraining's binary_logloss: 0.609525\n",
      "[5]\ttraining's binary_logloss: 0.608428\n",
      "[6]\ttraining's binary_logloss: 0.607366\n",
      "[7]\ttraining's binary_logloss: 0.606175\n",
      "[8]\ttraining's binary_logloss: 0.605078\n",
      "[9]\ttraining's binary_logloss: 0.604016\n",
      "[10]\ttraining's binary_logloss: 0.603081\n",
      "[11]\ttraining's binary_logloss: 0.602075\n",
      "[12]\ttraining's binary_logloss: 0.601005\n",
      "[13]\ttraining's binary_logloss: 0.599971\n",
      "[14]\ttraining's binary_logloss: 0.599135\n",
      "[15]\ttraining's binary_logloss: 0.598213\n",
      "[16]\ttraining's binary_logloss: 0.597307\n",
      "[17]\ttraining's binary_logloss: 0.596409\n",
      "[18]\ttraining's binary_logloss: 0.595574\n",
      "[19]\ttraining's binary_logloss: 0.594768\n",
      "[20]\ttraining's binary_logloss: 0.594078\n",
      "[21]\ttraining's binary_logloss: 0.593306\n",
      "[22]\ttraining's binary_logloss: 0.592561\n",
      "[23]\ttraining's binary_logloss: 0.591848\n",
      "[24]\ttraining's binary_logloss: 0.591133\n",
      "[25]\ttraining's binary_logloss: 0.590471\n",
      "[26]\ttraining's binary_logloss: 0.589864\n",
      "[27]\ttraining's binary_logloss: 0.589304\n",
      "[28]\ttraining's binary_logloss: 0.588768\n",
      "[29]\ttraining's binary_logloss: 0.588219\n",
      "[30]\ttraining's binary_logloss: 0.587674\n",
      "[31]\ttraining's binary_logloss: 0.587153\n",
      "[32]\ttraining's binary_logloss: 0.586545\n",
      "[33]\ttraining's binary_logloss: 0.585979\n",
      "[34]\ttraining's binary_logloss: 0.585444\n",
      "[35]\ttraining's binary_logloss: 0.584906\n",
      "[36]\ttraining's binary_logloss: 0.584351\n",
      "[37]\ttraining's binary_logloss: 0.583853\n",
      "[38]\ttraining's binary_logloss: 0.583367\n",
      "[39]\ttraining's binary_logloss: 0.582912\n",
      "[40]\ttraining's binary_logloss: 0.582455\n",
      "[41]\ttraining's binary_logloss: 0.582066\n",
      "[42]\ttraining's binary_logloss: 0.581689\n",
      "[43]\ttraining's binary_logloss: 0.5813\n",
      "[44]\ttraining's binary_logloss: 0.580931\n",
      "[45]\ttraining's binary_logloss: 0.580557\n",
      "[46]\ttraining's binary_logloss: 0.580208\n",
      "[47]\ttraining's binary_logloss: 0.579811\n",
      "[48]\ttraining's binary_logloss: 0.579429\n",
      "[49]\ttraining's binary_logloss: 0.579137\n",
      "[50]\ttraining's binary_logloss: 0.578778\n",
      "[51]\ttraining's binary_logloss: 0.578397\n",
      "[52]\ttraining's binary_logloss: 0.57812\n",
      "[53]\ttraining's binary_logloss: 0.577766\n",
      "[54]\ttraining's binary_logloss: 0.577445\n",
      "[55]\ttraining's binary_logloss: 0.577195\n",
      "[56]\ttraining's binary_logloss: 0.57688\n",
      "[57]\ttraining's binary_logloss: 0.57658\n",
      "[58]\ttraining's binary_logloss: 0.576273\n",
      "[59]\ttraining's binary_logloss: 0.576043\n",
      "[60]\ttraining's binary_logloss: 0.575755\n",
      "[61]\ttraining's binary_logloss: 0.575467\n",
      "[62]\ttraining's binary_logloss: 0.575188\n",
      "[63]\ttraining's binary_logloss: 0.574919\n",
      "[64]\ttraining's binary_logloss: 0.574667\n",
      "[65]\ttraining's binary_logloss: 0.574428\n",
      "[66]\ttraining's binary_logloss: 0.574217\n",
      "[67]\ttraining's binary_logloss: 0.574032\n",
      "[68]\ttraining's binary_logloss: 0.573824\n",
      "[69]\ttraining's binary_logloss: 0.573625\n",
      "[70]\ttraining's binary_logloss: 0.57346\n",
      "[71]\ttraining's binary_logloss: 0.573277\n",
      "[72]\ttraining's binary_logloss: 0.573094\n",
      "[73]\ttraining's binary_logloss: 0.572917\n",
      "[74]\ttraining's binary_logloss: 0.572777\n",
      "[75]\ttraining's binary_logloss: 0.572663\n",
      "[76]\ttraining's binary_logloss: 0.572503\n",
      "[77]\ttraining's binary_logloss: 0.572312\n",
      "[78]\ttraining's binary_logloss: 0.57221\n",
      "[79]\ttraining's binary_logloss: 0.571969\n",
      "[80]\ttraining's binary_logloss: 0.571748\n",
      "[81]\ttraining's binary_logloss: 0.571581\n",
      "[82]\ttraining's binary_logloss: 0.57146\n",
      "[83]\ttraining's binary_logloss: 0.571283\n",
      "[84]\ttraining's binary_logloss: 0.571145\n",
      "[85]\ttraining's binary_logloss: 0.570966\n",
      "[86]\ttraining's binary_logloss: 0.570827\n",
      "[87]\ttraining's binary_logloss: 0.570664\n",
      "[88]\ttraining's binary_logloss: 0.570476\n",
      "[89]\ttraining's binary_logloss: 0.570308\n",
      "[90]\ttraining's binary_logloss: 0.570175\n",
      "[91]\ttraining's binary_logloss: 0.570057\n",
      "[92]\ttraining's binary_logloss: 0.569935\n",
      "[93]\ttraining's binary_logloss: 0.569829\n",
      "[94]\ttraining's binary_logloss: 0.569704\n",
      "[95]\ttraining's binary_logloss: 0.56961\n",
      "[96]\ttraining's binary_logloss: 0.569473\n",
      "[97]\ttraining's binary_logloss: 0.569335\n",
      "[98]\ttraining's binary_logloss: 0.569244\n",
      "[99]\ttraining's binary_logloss: 0.56915\n",
      "[100]\ttraining's binary_logloss: 0.569039\n",
      "[101]\ttraining's binary_logloss: 0.568947\n",
      "[102]\ttraining's binary_logloss: 0.568864\n",
      "[103]\ttraining's binary_logloss: 0.568787\n",
      "[104]\ttraining's binary_logloss: 0.568716\n",
      "[105]\ttraining's binary_logloss: 0.568609\n",
      "[106]\ttraining's binary_logloss: 0.568466\n",
      "[107]\ttraining's binary_logloss: 0.568356\n",
      "[108]\ttraining's binary_logloss: 0.568223\n",
      "[109]\ttraining's binary_logloss: 0.568097\n",
      "[110]\ttraining's binary_logloss: 0.567984\n",
      "[111]\ttraining's binary_logloss: 0.567884\n",
      "[112]\ttraining's binary_logloss: 0.567799\n",
      "[113]\ttraining's binary_logloss: 0.567701\n",
      "[114]\ttraining's binary_logloss: 0.567618\n",
      "[115]\ttraining's binary_logloss: 0.567533\n",
      "[116]\ttraining's binary_logloss: 0.567475\n",
      "[117]\ttraining's binary_logloss: 0.567393\n",
      "[118]\ttraining's binary_logloss: 0.567325\n",
      "[119]\ttraining's binary_logloss: 0.567298\n",
      "[120]\ttraining's binary_logloss: 0.567253\n",
      "[121]\ttraining's binary_logloss: 0.567163\n",
      "[122]\ttraining's binary_logloss: 0.567086\n",
      "[123]\ttraining's binary_logloss: 0.566993\n",
      "[124]\ttraining's binary_logloss: 0.566906\n",
      "[125]\ttraining's binary_logloss: 0.566834\n",
      "[126]\ttraining's binary_logloss: 0.566729\n",
      "[127]\ttraining's binary_logloss: 0.566634\n",
      "[128]\ttraining's binary_logloss: 0.56653\n",
      "[129]\ttraining's binary_logloss: 0.56644\n",
      "[130]\ttraining's binary_logloss: 0.566343\n",
      "[131]\ttraining's binary_logloss: 0.566223\n",
      "[132]\ttraining's binary_logloss: 0.566112\n",
      "[133]\ttraining's binary_logloss: 0.566046\n",
      "[134]\ttraining's binary_logloss: 0.565959\n",
      "[135]\ttraining's binary_logloss: 0.565882\n",
      "[136]\ttraining's binary_logloss: 0.565831\n",
      "[137]\ttraining's binary_logloss: 0.565743\n",
      "[138]\ttraining's binary_logloss: 0.565679\n",
      "[139]\ttraining's binary_logloss: 0.565617\n",
      "[140]\ttraining's binary_logloss: 0.565562\n",
      "[141]\ttraining's binary_logloss: 0.565534\n",
      "[142]\ttraining's binary_logloss: 0.56547\n",
      "[143]\ttraining's binary_logloss: 0.565392\n",
      "[144]\ttraining's binary_logloss: 0.56534\n",
      "[145]\ttraining's binary_logloss: 0.565249\n",
      "[146]\ttraining's binary_logloss: 0.565185\n",
      "[147]\ttraining's binary_logloss: 0.565128\n",
      "[148]\ttraining's binary_logloss: 0.565047\n",
      "[149]\ttraining's binary_logloss: 0.564989\n",
      "[150]\ttraining's binary_logloss: 0.564945\n",
      "[151]\ttraining's binary_logloss: 0.564871\n",
      "[152]\ttraining's binary_logloss: 0.564773\n",
      "[153]\ttraining's binary_logloss: 0.564713\n",
      "[154]\ttraining's binary_logloss: 0.564632\n",
      "[155]\ttraining's binary_logloss: 0.564543\n",
      "[156]\ttraining's binary_logloss: 0.564466\n",
      "[157]\ttraining's binary_logloss: 0.564395\n",
      "[158]\ttraining's binary_logloss: 0.564333\n",
      "[159]\ttraining's binary_logloss: 0.564262\n",
      "[160]\ttraining's binary_logloss: 0.564235\n",
      "[161]\ttraining's binary_logloss: 0.564132\n",
      "[162]\ttraining's binary_logloss: 0.564038\n",
      "[163]\ttraining's binary_logloss: 0.563952\n",
      "[164]\ttraining's binary_logloss: 0.563839\n",
      "[165]\ttraining's binary_logloss: 0.563765\n",
      "[166]\ttraining's binary_logloss: 0.563652\n",
      "[167]\ttraining's binary_logloss: 0.563548\n",
      "[168]\ttraining's binary_logloss: 0.563446\n",
      "[169]\ttraining's binary_logloss: 0.563343\n",
      "[170]\ttraining's binary_logloss: 0.563274\n",
      "[171]\ttraining's binary_logloss: 0.563171\n",
      "[172]\ttraining's binary_logloss: 0.56305\n",
      "[173]\ttraining's binary_logloss: 0.562944\n",
      "[174]\ttraining's binary_logloss: 0.562836\n",
      "[175]\ttraining's binary_logloss: 0.562767\n",
      "[176]\ttraining's binary_logloss: 0.562691\n",
      "[177]\ttraining's binary_logloss: 0.562619\n",
      "[178]\ttraining's binary_logloss: 0.562562\n",
      "[179]\ttraining's binary_logloss: 0.56249\n",
      "[180]\ttraining's binary_logloss: 0.562425\n",
      "[181]\ttraining's binary_logloss: 0.56236\n",
      "[182]\ttraining's binary_logloss: 0.562298\n",
      "[183]\ttraining's binary_logloss: 0.562238\n",
      "[184]\ttraining's binary_logloss: 0.562182\n",
      "[185]\ttraining's binary_logloss: 0.562139\n",
      "[186]\ttraining's binary_logloss: 0.562049\n",
      "[187]\ttraining's binary_logloss: 0.561941\n",
      "[188]\ttraining's binary_logloss: 0.56185\n",
      "[189]\ttraining's binary_logloss: 0.561762\n",
      "[190]\ttraining's binary_logloss: 0.561676\n",
      "[191]\ttraining's binary_logloss: 0.561589\n",
      "[192]\ttraining's binary_logloss: 0.561499\n",
      "[193]\ttraining's binary_logloss: 0.561434\n",
      "[194]\ttraining's binary_logloss: 0.561358\n",
      "[195]\ttraining's binary_logloss: 0.561257\n",
      "[196]\ttraining's binary_logloss: 0.561162\n",
      "[197]\ttraining's binary_logloss: 0.56106\n",
      "[198]\ttraining's binary_logloss: 0.560953\n",
      "[199]\ttraining's binary_logloss: 0.560896\n",
      "[200]\ttraining's binary_logloss: 0.560787\n",
      "[201]\ttraining's binary_logloss: 0.560696\n",
      "[202]\ttraining's binary_logloss: 0.560618\n",
      "[203]\ttraining's binary_logloss: 0.560521\n",
      "[204]\ttraining's binary_logloss: 0.560431\n",
      "[205]\ttraining's binary_logloss: 0.560342\n",
      "[206]\ttraining's binary_logloss: 0.560262\n",
      "[207]\ttraining's binary_logloss: 0.560188\n",
      "[208]\ttraining's binary_logloss: 0.560109\n",
      "[209]\ttraining's binary_logloss: 0.560025\n",
      "[210]\ttraining's binary_logloss: 0.559936\n",
      "[211]\ttraining's binary_logloss: 0.559884\n",
      "[212]\ttraining's binary_logloss: 0.559817\n",
      "[213]\ttraining's binary_logloss: 0.55976\n",
      "[214]\ttraining's binary_logloss: 0.559707\n",
      "[215]\ttraining's binary_logloss: 0.559657\n",
      "[216]\ttraining's binary_logloss: 0.559512\n",
      "[217]\ttraining's binary_logloss: 0.559408\n",
      "[218]\ttraining's binary_logloss: 0.559294\n",
      "[219]\ttraining's binary_logloss: 0.559168\n",
      "[220]\ttraining's binary_logloss: 0.559036\n",
      "[221]\ttraining's binary_logloss: 0.558889\n",
      "[222]\ttraining's binary_logloss: 0.558777\n",
      "[223]\ttraining's binary_logloss: 0.558671\n",
      "[224]\ttraining's binary_logloss: 0.558523\n",
      "[225]\ttraining's binary_logloss: 0.558421\n",
      "[226]\ttraining's binary_logloss: 0.558313\n",
      "[227]\ttraining's binary_logloss: 0.55824\n",
      "[228]\ttraining's binary_logloss: 0.558176\n",
      "[229]\ttraining's binary_logloss: 0.558109\n",
      "[230]\ttraining's binary_logloss: 0.557994\n",
      "[231]\ttraining's binary_logloss: 0.5579\n",
      "[232]\ttraining's binary_logloss: 0.557801\n",
      "[233]\ttraining's binary_logloss: 0.557714\n",
      "[234]\ttraining's binary_logloss: 0.55763\n",
      "[235]\ttraining's binary_logloss: 0.557534\n",
      "[236]\ttraining's binary_logloss: 0.557413\n",
      "[237]\ttraining's binary_logloss: 0.557294\n",
      "[238]\ttraining's binary_logloss: 0.557211\n",
      "[239]\ttraining's binary_logloss: 0.5571\n",
      "[240]\ttraining's binary_logloss: 0.556977\n",
      "[241]\ttraining's binary_logloss: 0.55688\n",
      "[242]\ttraining's binary_logloss: 0.556768\n",
      "[243]\ttraining's binary_logloss: 0.556653\n",
      "[244]\ttraining's binary_logloss: 0.55654\n",
      "[245]\ttraining's binary_logloss: 0.556427\n",
      "[246]\ttraining's binary_logloss: 0.556313\n",
      "[247]\ttraining's binary_logloss: 0.556194\n",
      "[248]\ttraining's binary_logloss: 0.556059\n",
      "[249]\ttraining's binary_logloss: 0.555949\n",
      "[250]\ttraining's binary_logloss: 0.555838\n",
      "[251]\ttraining's binary_logloss: 0.555742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[252]\ttraining's binary_logloss: 0.555657\n",
      "[253]\ttraining's binary_logloss: 0.555597\n",
      "[254]\ttraining's binary_logloss: 0.555512\n",
      "[255]\ttraining's binary_logloss: 0.555425\n",
      "[256]\ttraining's binary_logloss: 0.55529\n",
      "[257]\ttraining's binary_logloss: 0.555137\n",
      "[258]\ttraining's binary_logloss: 0.555011\n",
      "[259]\ttraining's binary_logloss: 0.554875\n",
      "[260]\ttraining's binary_logloss: 0.554743\n",
      "[261]\ttraining's binary_logloss: 0.554641\n",
      "[262]\ttraining's binary_logloss: 0.554524\n",
      "[263]\ttraining's binary_logloss: 0.554444\n",
      "[264]\ttraining's binary_logloss: 0.554347\n",
      "[265]\ttraining's binary_logloss: 0.55425\n",
      "[266]\ttraining's binary_logloss: 0.554187\n",
      "[267]\ttraining's binary_logloss: 0.554133\n",
      "[268]\ttraining's binary_logloss: 0.554098\n",
      "[269]\ttraining's binary_logloss: 0.554066\n",
      "[270]\ttraining's binary_logloss: 0.554026\n",
      "[271]\ttraining's binary_logloss: 0.553869\n",
      "[272]\ttraining's binary_logloss: 0.553722\n",
      "[273]\ttraining's binary_logloss: 0.55357\n",
      "[274]\ttraining's binary_logloss: 0.553428\n",
      "[275]\ttraining's binary_logloss: 0.553287\n",
      "[276]\ttraining's binary_logloss: 0.553128\n",
      "[277]\ttraining's binary_logloss: 0.55297\n",
      "[278]\ttraining's binary_logloss: 0.552845\n",
      "[279]\ttraining's binary_logloss: 0.552696\n",
      "[280]\ttraining's binary_logloss: 0.552569\n",
      "[281]\ttraining's binary_logloss: 0.552447\n",
      "[282]\ttraining's binary_logloss: 0.552326\n",
      "[283]\ttraining's binary_logloss: 0.552208\n",
      "[284]\ttraining's binary_logloss: 0.552089\n",
      "[285]\ttraining's binary_logloss: 0.55198\n",
      "[286]\ttraining's binary_logloss: 0.551833\n",
      "[287]\ttraining's binary_logloss: 0.551732\n",
      "[288]\ttraining's binary_logloss: 0.5516\n",
      "[289]\ttraining's binary_logloss: 0.551453\n",
      "[290]\ttraining's binary_logloss: 0.551357\n",
      "[291]\ttraining's binary_logloss: 0.551212\n",
      "[292]\ttraining's binary_logloss: 0.551069\n",
      "[293]\ttraining's binary_logloss: 0.55093\n",
      "[294]\ttraining's binary_logloss: 0.550779\n",
      "[295]\ttraining's binary_logloss: 0.550653\n",
      "[296]\ttraining's binary_logloss: 0.550553\n",
      "[297]\ttraining's binary_logloss: 0.550463\n",
      "[298]\ttraining's binary_logloss: 0.550367\n",
      "[299]\ttraining's binary_logloss: 0.550277\n",
      "[300]\ttraining's binary_logloss: 0.550195\n",
      "[301]\ttraining's binary_logloss: 0.550035\n",
      "[302]\ttraining's binary_logloss: 0.549892\n",
      "[303]\ttraining's binary_logloss: 0.549759\n",
      "[304]\ttraining's binary_logloss: 0.549603\n",
      "[305]\ttraining's binary_logloss: 0.549469\n",
      "[306]\ttraining's binary_logloss: 0.549359\n",
      "[307]\ttraining's binary_logloss: 0.549248\n",
      "[308]\ttraining's binary_logloss: 0.54915\n",
      "[309]\ttraining's binary_logloss: 0.549051\n",
      "[310]\ttraining's binary_logloss: 0.548924\n",
      "[311]\ttraining's binary_logloss: 0.548821\n",
      "[312]\ttraining's binary_logloss: 0.548714\n",
      "[313]\ttraining's binary_logloss: 0.548572\n",
      "[314]\ttraining's binary_logloss: 0.548479\n",
      "[315]\ttraining's binary_logloss: 0.54838\n",
      "[316]\ttraining's binary_logloss: 0.548252\n",
      "[317]\ttraining's binary_logloss: 0.548132\n",
      "[318]\ttraining's binary_logloss: 0.548025\n",
      "[319]\ttraining's binary_logloss: 0.547913\n",
      "[320]\ttraining's binary_logloss: 0.547796\n",
      "[321]\ttraining's binary_logloss: 0.547683\n",
      "[322]\ttraining's binary_logloss: 0.547571\n",
      "[323]\ttraining's binary_logloss: 0.547463\n",
      "[324]\ttraining's binary_logloss: 0.547354\n",
      "[325]\ttraining's binary_logloss: 0.547244\n",
      "[326]\ttraining's binary_logloss: 0.547071\n",
      "[327]\ttraining's binary_logloss: 0.546948\n",
      "[328]\ttraining's binary_logloss: 0.546779\n",
      "[329]\ttraining's binary_logloss: 0.54667\n",
      "[330]\ttraining's binary_logloss: 0.546551\n",
      "[331]\ttraining's binary_logloss: 0.546412\n",
      "[332]\ttraining's binary_logloss: 0.546292\n",
      "[333]\ttraining's binary_logloss: 0.546162\n",
      "[334]\ttraining's binary_logloss: 0.545995\n",
      "[335]\ttraining's binary_logloss: 0.545856\n",
      "[336]\ttraining's binary_logloss: 0.545712\n",
      "[337]\ttraining's binary_logloss: 0.545574\n",
      "[338]\ttraining's binary_logloss: 0.545463\n",
      "[339]\ttraining's binary_logloss: 0.545362\n",
      "[340]\ttraining's binary_logloss: 0.545253\n",
      "[341]\ttraining's binary_logloss: 0.545154\n",
      "[342]\ttraining's binary_logloss: 0.545046\n",
      "[343]\ttraining's binary_logloss: 0.544959\n",
      "[344]\ttraining's binary_logloss: 0.544877\n",
      "[345]\ttraining's binary_logloss: 0.544757\n",
      "[346]\ttraining's binary_logloss: 0.544644\n",
      "[347]\ttraining's binary_logloss: 0.544522\n",
      "[348]\ttraining's binary_logloss: 0.544404\n",
      "[349]\ttraining's binary_logloss: 0.544288\n",
      "[350]\ttraining's binary_logloss: 0.544175\n",
      "[351]\ttraining's binary_logloss: 0.544031\n",
      "[352]\ttraining's binary_logloss: 0.543897\n",
      "[353]\ttraining's binary_logloss: 0.543753\n",
      "[354]\ttraining's binary_logloss: 0.543605\n",
      "[355]\ttraining's binary_logloss: 0.543449\n",
      "[356]\ttraining's binary_logloss: 0.54329\n",
      "[357]\ttraining's binary_logloss: 0.543102\n",
      "[358]\ttraining's binary_logloss: 0.542928\n",
      "[359]\ttraining's binary_logloss: 0.542779\n",
      "[360]\ttraining's binary_logloss: 0.542615\n",
      "[361]\ttraining's binary_logloss: 0.542474\n",
      "[362]\ttraining's binary_logloss: 0.542333\n",
      "[363]\ttraining's binary_logloss: 0.542171\n",
      "[364]\ttraining's binary_logloss: 0.542031\n",
      "[365]\ttraining's binary_logloss: 0.541886\n",
      "[366]\ttraining's binary_logloss: 0.541727\n",
      "[367]\ttraining's binary_logloss: 0.541579\n",
      "[368]\ttraining's binary_logloss: 0.541452\n",
      "[369]\ttraining's binary_logloss: 0.541321\n",
      "[370]\ttraining's binary_logloss: 0.541168\n",
      "[371]\ttraining's binary_logloss: 0.541071\n",
      "[372]\ttraining's binary_logloss: 0.540968\n",
      "[373]\ttraining's binary_logloss: 0.540867\n",
      "[374]\ttraining's binary_logloss: 0.540771\n",
      "[375]\ttraining's binary_logloss: 0.540684\n",
      "[376]\ttraining's binary_logloss: 0.540545\n",
      "[377]\ttraining's binary_logloss: 0.540409\n",
      "[378]\ttraining's binary_logloss: 0.540284\n",
      "[379]\ttraining's binary_logloss: 0.540152\n",
      "[380]\ttraining's binary_logloss: 0.540031\n",
      "[381]\ttraining's binary_logloss: 0.539939\n",
      "[382]\ttraining's binary_logloss: 0.539851\n",
      "[383]\ttraining's binary_logloss: 0.539775\n",
      "[384]\ttraining's binary_logloss: 0.539699\n",
      "[385]\ttraining's binary_logloss: 0.539611\n",
      "[386]\ttraining's binary_logloss: 0.539467\n",
      "[387]\ttraining's binary_logloss: 0.539317\n",
      "[388]\ttraining's binary_logloss: 0.539162\n",
      "[389]\ttraining's binary_logloss: 0.539005\n",
      "[390]\ttraining's binary_logloss: 0.538876\n",
      "[391]\ttraining's binary_logloss: 0.538738\n",
      "[392]\ttraining's binary_logloss: 0.538597\n",
      "[393]\ttraining's binary_logloss: 0.53847\n",
      "[394]\ttraining's binary_logloss: 0.538337\n",
      "[395]\ttraining's binary_logloss: 0.538208\n",
      "[396]\ttraining's binary_logloss: 0.538061\n",
      "[397]\ttraining's binary_logloss: 0.537946\n",
      "[398]\ttraining's binary_logloss: 0.537812\n",
      "[399]\ttraining's binary_logloss: 0.537682\n",
      "[400]\ttraining's binary_logloss: 0.537561\n",
      "[401]\ttraining's binary_logloss: 0.53743\n",
      "[402]\ttraining's binary_logloss: 0.537285\n",
      "[403]\ttraining's binary_logloss: 0.537153\n",
      "[404]\ttraining's binary_logloss: 0.537039\n",
      "[405]\ttraining's binary_logloss: 0.536906\n",
      "[406]\ttraining's binary_logloss: 0.536768\n",
      "[407]\ttraining's binary_logloss: 0.536638\n",
      "[408]\ttraining's binary_logloss: 0.536506\n",
      "[409]\ttraining's binary_logloss: 0.536384\n",
      "[410]\ttraining's binary_logloss: 0.536251\n",
      "[411]\ttraining's binary_logloss: 0.536069\n",
      "[412]\ttraining's binary_logloss: 0.535931\n",
      "[413]\ttraining's binary_logloss: 0.53577\n",
      "[414]\ttraining's binary_logloss: 0.535588\n",
      "[415]\ttraining's binary_logloss: 0.535452\n",
      "[416]\ttraining's binary_logloss: 0.535334\n",
      "[417]\ttraining's binary_logloss: 0.535198\n",
      "[418]\ttraining's binary_logloss: 0.535053\n",
      "[419]\ttraining's binary_logloss: 0.534913\n",
      "[420]\ttraining's binary_logloss: 0.534789\n",
      "[421]\ttraining's binary_logloss: 0.534648\n",
      "[422]\ttraining's binary_logloss: 0.534515\n",
      "[423]\ttraining's binary_logloss: 0.534414\n",
      "[424]\ttraining's binary_logloss: 0.534302\n",
      "[425]\ttraining's binary_logloss: 0.53419\n",
      "[426]\ttraining's binary_logloss: 0.53407\n",
      "[427]\ttraining's binary_logloss: 0.533944\n",
      "[428]\ttraining's binary_logloss: 0.533829\n",
      "[429]\ttraining's binary_logloss: 0.533711\n",
      "[430]\ttraining's binary_logloss: 0.533568\n",
      "[431]\ttraining's binary_logloss: 0.533418\n",
      "[432]\ttraining's binary_logloss: 0.533274\n",
      "[433]\ttraining's binary_logloss: 0.533134\n",
      "[434]\ttraining's binary_logloss: 0.532993\n",
      "[435]\ttraining's binary_logloss: 0.53282\n",
      "[436]\ttraining's binary_logloss: 0.532652\n",
      "[437]\ttraining's binary_logloss: 0.532483\n",
      "[438]\ttraining's binary_logloss: 0.532304\n",
      "[439]\ttraining's binary_logloss: 0.532151\n",
      "[440]\ttraining's binary_logloss: 0.531989\n",
      "[441]\ttraining's binary_logloss: 0.531861\n",
      "[442]\ttraining's binary_logloss: 0.531732\n",
      "[443]\ttraining's binary_logloss: 0.531611\n",
      "[444]\ttraining's binary_logloss: 0.531482\n",
      "[445]\ttraining's binary_logloss: 0.531371\n",
      "[446]\ttraining's binary_logloss: 0.531218\n",
      "[447]\ttraining's binary_logloss: 0.531067\n",
      "[448]\ttraining's binary_logloss: 0.530915\n",
      "[449]\ttraining's binary_logloss: 0.53076\n",
      "[450]\ttraining's binary_logloss: 0.530617\n",
      "[451]\ttraining's binary_logloss: 0.53047\n",
      "[452]\ttraining's binary_logloss: 0.530311\n",
      "[453]\ttraining's binary_logloss: 0.530183\n",
      "[454]\ttraining's binary_logloss: 0.530058\n",
      "[455]\ttraining's binary_logloss: 0.52994\n",
      "[456]\ttraining's binary_logloss: 0.529822\n",
      "[457]\ttraining's binary_logloss: 0.529714\n",
      "[458]\ttraining's binary_logloss: 0.529586\n",
      "[459]\ttraining's binary_logloss: 0.529457\n",
      "[460]\ttraining's binary_logloss: 0.529349\n",
      "[461]\ttraining's binary_logloss: 0.529193\n",
      "[462]\ttraining's binary_logloss: 0.52905\n",
      "[463]\ttraining's binary_logloss: 0.528899\n",
      "[464]\ttraining's binary_logloss: 0.528732\n",
      "[465]\ttraining's binary_logloss: 0.528613\n",
      "[466]\ttraining's binary_logloss: 0.528461\n",
      "[467]\ttraining's binary_logloss: 0.528302\n",
      "[468]\ttraining's binary_logloss: 0.528147\n",
      "[469]\ttraining's binary_logloss: 0.528006\n",
      "[470]\ttraining's binary_logloss: 0.527862\n",
      "[471]\ttraining's binary_logloss: 0.527764\n",
      "[472]\ttraining's binary_logloss: 0.527647\n",
      "[473]\ttraining's binary_logloss: 0.527516\n",
      "[474]\ttraining's binary_logloss: 0.527405\n",
      "[475]\ttraining's binary_logloss: 0.527297\n",
      "[476]\ttraining's binary_logloss: 0.527153\n",
      "[477]\ttraining's binary_logloss: 0.527035\n",
      "[478]\ttraining's binary_logloss: 0.526921\n",
      "[479]\ttraining's binary_logloss: 0.526773\n",
      "[480]\ttraining's binary_logloss: 0.526672\n",
      "[481]\ttraining's binary_logloss: 0.526549\n",
      "[482]\ttraining's binary_logloss: 0.526422\n",
      "[483]\ttraining's binary_logloss: 0.526264\n",
      "[484]\ttraining's binary_logloss: 0.52613\n",
      "[485]\ttraining's binary_logloss: 0.526008\n",
      "[486]\ttraining's binary_logloss: 0.525855\n",
      "[487]\ttraining's binary_logloss: 0.525705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[488]\ttraining's binary_logloss: 0.525528\n",
      "[489]\ttraining's binary_logloss: 0.525384\n",
      "[490]\ttraining's binary_logloss: 0.525251\n",
      "[491]\ttraining's binary_logloss: 0.525124\n",
      "[492]\ttraining's binary_logloss: 0.525009\n",
      "[493]\ttraining's binary_logloss: 0.524895\n",
      "[494]\ttraining's binary_logloss: 0.524774\n",
      "[495]\ttraining's binary_logloss: 0.524665\n",
      "[496]\ttraining's binary_logloss: 0.524483\n",
      "[497]\ttraining's binary_logloss: 0.524335\n",
      "[498]\ttraining's binary_logloss: 0.524191\n",
      "[499]\ttraining's binary_logloss: 0.524047\n",
      "[500]\ttraining's binary_logloss: 0.523902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613033\n",
      "[2]\ttraining's binary_logloss: 0.611725\n",
      "[3]\ttraining's binary_logloss: 0.610468\n",
      "[4]\ttraining's binary_logloss: 0.609246\n",
      "[5]\ttraining's binary_logloss: 0.608083\n",
      "[6]\ttraining's binary_logloss: 0.60702\n",
      "[7]\ttraining's binary_logloss: 0.605884\n",
      "[8]\ttraining's binary_logloss: 0.604787\n",
      "[9]\ttraining's binary_logloss: 0.603683\n",
      "[10]\ttraining's binary_logloss: 0.602613\n",
      "[11]\ttraining's binary_logloss: 0.601557\n",
      "[12]\ttraining's binary_logloss: 0.600545\n",
      "[13]\ttraining's binary_logloss: 0.599581\n",
      "[14]\ttraining's binary_logloss: 0.598666\n",
      "[15]\ttraining's binary_logloss: 0.597788\n",
      "[16]\ttraining's binary_logloss: 0.596862\n",
      "[17]\ttraining's binary_logloss: 0.596055\n",
      "[18]\ttraining's binary_logloss: 0.595169\n",
      "[19]\ttraining's binary_logloss: 0.594351\n",
      "[20]\ttraining's binary_logloss: 0.593522\n",
      "[21]\ttraining's binary_logloss: 0.592793\n",
      "[22]\ttraining's binary_logloss: 0.592134\n",
      "[23]\ttraining's binary_logloss: 0.591461\n",
      "[24]\ttraining's binary_logloss: 0.590815\n",
      "[25]\ttraining's binary_logloss: 0.590189\n",
      "[26]\ttraining's binary_logloss: 0.58957\n",
      "[27]\ttraining's binary_logloss: 0.58898\n",
      "[28]\ttraining's binary_logloss: 0.588402\n",
      "[29]\ttraining's binary_logloss: 0.587806\n",
      "[30]\ttraining's binary_logloss: 0.587216\n",
      "[31]\ttraining's binary_logloss: 0.586662\n",
      "[32]\ttraining's binary_logloss: 0.586087\n",
      "[33]\ttraining's binary_logloss: 0.585556\n",
      "[34]\ttraining's binary_logloss: 0.585201\n",
      "[35]\ttraining's binary_logloss: 0.584684\n",
      "[36]\ttraining's binary_logloss: 0.584256\n",
      "[37]\ttraining's binary_logloss: 0.58375\n",
      "[38]\ttraining's binary_logloss: 0.583273\n",
      "[39]\ttraining's binary_logloss: 0.582892\n",
      "[40]\ttraining's binary_logloss: 0.582451\n",
      "[41]\ttraining's binary_logloss: 0.581974\n",
      "[42]\ttraining's binary_logloss: 0.581608\n",
      "[43]\ttraining's binary_logloss: 0.581165\n",
      "[44]\ttraining's binary_logloss: 0.580791\n",
      "[45]\ttraining's binary_logloss: 0.580402\n",
      "[46]\ttraining's binary_logloss: 0.580013\n",
      "[47]\ttraining's binary_logloss: 0.579627\n",
      "[48]\ttraining's binary_logloss: 0.57926\n",
      "[49]\ttraining's binary_logloss: 0.578911\n",
      "[50]\ttraining's binary_logloss: 0.578572\n",
      "[51]\ttraining's binary_logloss: 0.578257\n",
      "[52]\ttraining's binary_logloss: 0.577931\n",
      "[53]\ttraining's binary_logloss: 0.577618\n",
      "[54]\ttraining's binary_logloss: 0.577287\n",
      "[55]\ttraining's binary_logloss: 0.577003\n",
      "[56]\ttraining's binary_logloss: 0.576746\n",
      "[57]\ttraining's binary_logloss: 0.576482\n",
      "[58]\ttraining's binary_logloss: 0.576245\n",
      "[59]\ttraining's binary_logloss: 0.576015\n",
      "[60]\ttraining's binary_logloss: 0.575792\n",
      "[61]\ttraining's binary_logloss: 0.575604\n",
      "[62]\ttraining's binary_logloss: 0.575426\n",
      "[63]\ttraining's binary_logloss: 0.57513\n",
      "[64]\ttraining's binary_logloss: 0.574974\n",
      "[65]\ttraining's binary_logloss: 0.574734\n",
      "[66]\ttraining's binary_logloss: 0.574503\n",
      "[67]\ttraining's binary_logloss: 0.574304\n",
      "[68]\ttraining's binary_logloss: 0.574081\n",
      "[69]\ttraining's binary_logloss: 0.573885\n",
      "[70]\ttraining's binary_logloss: 0.573682\n",
      "[71]\ttraining's binary_logloss: 0.573449\n",
      "[72]\ttraining's binary_logloss: 0.57327\n",
      "[73]\ttraining's binary_logloss: 0.573119\n",
      "[74]\ttraining's binary_logloss: 0.57291\n",
      "[75]\ttraining's binary_logloss: 0.57272\n",
      "[76]\ttraining's binary_logloss: 0.572521\n",
      "[77]\ttraining's binary_logloss: 0.572331\n",
      "[78]\ttraining's binary_logloss: 0.572243\n",
      "[79]\ttraining's binary_logloss: 0.572109\n",
      "[80]\ttraining's binary_logloss: 0.571987\n",
      "[81]\ttraining's binary_logloss: 0.571817\n",
      "[82]\ttraining's binary_logloss: 0.57165\n",
      "[83]\ttraining's binary_logloss: 0.571529\n",
      "[84]\ttraining's binary_logloss: 0.571364\n",
      "[85]\ttraining's binary_logloss: 0.571231\n",
      "[86]\ttraining's binary_logloss: 0.571096\n",
      "[87]\ttraining's binary_logloss: 0.570942\n",
      "[88]\ttraining's binary_logloss: 0.570828\n",
      "[89]\ttraining's binary_logloss: 0.570723\n",
      "[90]\ttraining's binary_logloss: 0.570605\n",
      "[91]\ttraining's binary_logloss: 0.570491\n",
      "[92]\ttraining's binary_logloss: 0.570402\n",
      "[93]\ttraining's binary_logloss: 0.57033\n",
      "[94]\ttraining's binary_logloss: 0.570192\n",
      "[95]\ttraining's binary_logloss: 0.57007\n",
      "[96]\ttraining's binary_logloss: 0.570009\n",
      "[97]\ttraining's binary_logloss: 0.569926\n",
      "[98]\ttraining's binary_logloss: 0.569869\n",
      "[99]\ttraining's binary_logloss: 0.569806\n",
      "[100]\ttraining's binary_logloss: 0.569724\n",
      "[101]\ttraining's binary_logloss: 0.569666\n",
      "[102]\ttraining's binary_logloss: 0.569621\n",
      "[103]\ttraining's binary_logloss: 0.569585\n",
      "[104]\ttraining's binary_logloss: 0.56953\n",
      "[105]\ttraining's binary_logloss: 0.569497\n",
      "[106]\ttraining's binary_logloss: 0.569411\n",
      "[107]\ttraining's binary_logloss: 0.569352\n",
      "[108]\ttraining's binary_logloss: 0.569286\n",
      "[109]\ttraining's binary_logloss: 0.569271\n",
      "[110]\ttraining's binary_logloss: 0.569222\n",
      "[111]\ttraining's binary_logloss: 0.569128\n",
      "[112]\ttraining's binary_logloss: 0.569051\n",
      "[113]\ttraining's binary_logloss: 0.568973\n",
      "[114]\ttraining's binary_logloss: 0.568907\n",
      "[115]\ttraining's binary_logloss: 0.568857\n",
      "[116]\ttraining's binary_logloss: 0.568762\n",
      "[117]\ttraining's binary_logloss: 0.568691\n",
      "[118]\ttraining's binary_logloss: 0.568624\n",
      "[119]\ttraining's binary_logloss: 0.568556\n",
      "[120]\ttraining's binary_logloss: 0.56845\n",
      "[121]\ttraining's binary_logloss: 0.568375\n",
      "[122]\ttraining's binary_logloss: 0.568282\n",
      "[123]\ttraining's binary_logloss: 0.568193\n",
      "[124]\ttraining's binary_logloss: 0.568119\n",
      "[125]\ttraining's binary_logloss: 0.568036\n",
      "[126]\ttraining's binary_logloss: 0.567932\n",
      "[127]\ttraining's binary_logloss: 0.567831\n",
      "[128]\ttraining's binary_logloss: 0.567769\n",
      "[129]\ttraining's binary_logloss: 0.567679\n",
      "[130]\ttraining's binary_logloss: 0.567609\n",
      "[131]\ttraining's binary_logloss: 0.567544\n",
      "[132]\ttraining's binary_logloss: 0.567466\n",
      "[133]\ttraining's binary_logloss: 0.567401\n",
      "[134]\ttraining's binary_logloss: 0.567316\n",
      "[135]\ttraining's binary_logloss: 0.567262\n",
      "[136]\ttraining's binary_logloss: 0.567213\n",
      "[137]\ttraining's binary_logloss: 0.567169\n",
      "[138]\ttraining's binary_logloss: 0.567124\n",
      "[139]\ttraining's binary_logloss: 0.567074\n",
      "[140]\ttraining's binary_logloss: 0.567021\n",
      "[141]\ttraining's binary_logloss: 0.566956\n",
      "[142]\ttraining's binary_logloss: 0.566904\n",
      "[143]\ttraining's binary_logloss: 0.566872\n",
      "[144]\ttraining's binary_logloss: 0.566805\n",
      "[145]\ttraining's binary_logloss: 0.566723\n",
      "[146]\ttraining's binary_logloss: 0.56663\n",
      "[147]\ttraining's binary_logloss: 0.566534\n",
      "[148]\ttraining's binary_logloss: 0.56644\n",
      "[149]\ttraining's binary_logloss: 0.566343\n",
      "[150]\ttraining's binary_logloss: 0.566262\n",
      "[151]\ttraining's binary_logloss: 0.566203\n",
      "[152]\ttraining's binary_logloss: 0.566163\n",
      "[153]\ttraining's binary_logloss: 0.566075\n",
      "[154]\ttraining's binary_logloss: 0.566026\n",
      "[155]\ttraining's binary_logloss: 0.565956\n",
      "[156]\ttraining's binary_logloss: 0.565919\n",
      "[157]\ttraining's binary_logloss: 0.565883\n",
      "[158]\ttraining's binary_logloss: 0.565839\n",
      "[159]\ttraining's binary_logloss: 0.565793\n",
      "[160]\ttraining's binary_logloss: 0.565755\n",
      "[161]\ttraining's binary_logloss: 0.565625\n",
      "[162]\ttraining's binary_logloss: 0.565509\n",
      "[163]\ttraining's binary_logloss: 0.565393\n",
      "[164]\ttraining's binary_logloss: 0.565282\n",
      "[165]\ttraining's binary_logloss: 0.56516\n",
      "[166]\ttraining's binary_logloss: 0.565049\n",
      "[167]\ttraining's binary_logloss: 0.564945\n",
      "[168]\ttraining's binary_logloss: 0.564852\n",
      "[169]\ttraining's binary_logloss: 0.564771\n",
      "[170]\ttraining's binary_logloss: 0.564662\n",
      "[171]\ttraining's binary_logloss: 0.564644\n",
      "[172]\ttraining's binary_logloss: 0.564635\n",
      "[173]\ttraining's binary_logloss: 0.56461\n",
      "[174]\ttraining's binary_logloss: 0.564572\n",
      "[175]\ttraining's binary_logloss: 0.564527\n",
      "[176]\ttraining's binary_logloss: 0.564488\n",
      "[177]\ttraining's binary_logloss: 0.564453\n",
      "[178]\ttraining's binary_logloss: 0.564414\n",
      "[179]\ttraining's binary_logloss: 0.564358\n",
      "[180]\ttraining's binary_logloss: 0.564328\n",
      "[181]\ttraining's binary_logloss: 0.564269\n",
      "[182]\ttraining's binary_logloss: 0.564196\n",
      "[183]\ttraining's binary_logloss: 0.564142\n",
      "[184]\ttraining's binary_logloss: 0.564087\n",
      "[185]\ttraining's binary_logloss: 0.564048\n",
      "[186]\ttraining's binary_logloss: 0.563984\n",
      "[187]\ttraining's binary_logloss: 0.563928\n",
      "[188]\ttraining's binary_logloss: 0.563877\n",
      "[189]\ttraining's binary_logloss: 0.563833\n",
      "[190]\ttraining's binary_logloss: 0.563775\n",
      "[191]\ttraining's binary_logloss: 0.563699\n",
      "[192]\ttraining's binary_logloss: 0.563603\n",
      "[193]\ttraining's binary_logloss: 0.563527\n",
      "[194]\ttraining's binary_logloss: 0.563481\n",
      "[195]\ttraining's binary_logloss: 0.563446\n",
      "[196]\ttraining's binary_logloss: 0.563398\n",
      "[197]\ttraining's binary_logloss: 0.563327\n",
      "[198]\ttraining's binary_logloss: 0.563285\n",
      "[199]\ttraining's binary_logloss: 0.563214\n",
      "[200]\ttraining's binary_logloss: 0.563166\n",
      "[201]\ttraining's binary_logloss: 0.563065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[202]\ttraining's binary_logloss: 0.562979\n",
      "[203]\ttraining's binary_logloss: 0.562889\n",
      "[204]\ttraining's binary_logloss: 0.562813\n",
      "[205]\ttraining's binary_logloss: 0.562736\n",
      "[206]\ttraining's binary_logloss: 0.562692\n",
      "[207]\ttraining's binary_logloss: 0.562655\n",
      "[208]\ttraining's binary_logloss: 0.562598\n",
      "[209]\ttraining's binary_logloss: 0.56256\n",
      "[210]\ttraining's binary_logloss: 0.562508\n",
      "[211]\ttraining's binary_logloss: 0.56246\n",
      "[212]\ttraining's binary_logloss: 0.562398\n",
      "[213]\ttraining's binary_logloss: 0.56234\n",
      "[214]\ttraining's binary_logloss: 0.562293\n",
      "[215]\ttraining's binary_logloss: 0.562216\n",
      "[216]\ttraining's binary_logloss: 0.562101\n",
      "[217]\ttraining's binary_logloss: 0.561999\n",
      "[218]\ttraining's binary_logloss: 0.561917\n",
      "[219]\ttraining's binary_logloss: 0.561805\n",
      "[220]\ttraining's binary_logloss: 0.561697\n",
      "[221]\ttraining's binary_logloss: 0.561585\n",
      "[222]\ttraining's binary_logloss: 0.561464\n",
      "[223]\ttraining's binary_logloss: 0.561348\n",
      "[224]\ttraining's binary_logloss: 0.561239\n",
      "[225]\ttraining's binary_logloss: 0.561139\n",
      "[226]\ttraining's binary_logloss: 0.561025\n",
      "[227]\ttraining's binary_logloss: 0.560924\n",
      "[228]\ttraining's binary_logloss: 0.560818\n",
      "[229]\ttraining's binary_logloss: 0.560718\n",
      "[230]\ttraining's binary_logloss: 0.560609\n",
      "[231]\ttraining's binary_logloss: 0.560527\n",
      "[232]\ttraining's binary_logloss: 0.560444\n",
      "[233]\ttraining's binary_logloss: 0.560369\n",
      "[234]\ttraining's binary_logloss: 0.560312\n",
      "[235]\ttraining's binary_logloss: 0.560257\n",
      "[236]\ttraining's binary_logloss: 0.560163\n",
      "[237]\ttraining's binary_logloss: 0.560047\n",
      "[238]\ttraining's binary_logloss: 0.559956\n",
      "[239]\ttraining's binary_logloss: 0.559875\n",
      "[240]\ttraining's binary_logloss: 0.559763\n",
      "[241]\ttraining's binary_logloss: 0.559654\n",
      "[242]\ttraining's binary_logloss: 0.559547\n",
      "[243]\ttraining's binary_logloss: 0.559448\n",
      "[244]\ttraining's binary_logloss: 0.559349\n",
      "[245]\ttraining's binary_logloss: 0.559245\n",
      "[246]\ttraining's binary_logloss: 0.559083\n",
      "[247]\ttraining's binary_logloss: 0.55892\n",
      "[248]\ttraining's binary_logloss: 0.558769\n",
      "[249]\ttraining's binary_logloss: 0.558616\n",
      "[250]\ttraining's binary_logloss: 0.55849\n",
      "[251]\ttraining's binary_logloss: 0.558442\n",
      "[252]\ttraining's binary_logloss: 0.558385\n",
      "[253]\ttraining's binary_logloss: 0.558337\n",
      "[254]\ttraining's binary_logloss: 0.558284\n",
      "[255]\ttraining's binary_logloss: 0.558238\n",
      "[256]\ttraining's binary_logloss: 0.558097\n",
      "[257]\ttraining's binary_logloss: 0.557991\n",
      "[258]\ttraining's binary_logloss: 0.557899\n",
      "[259]\ttraining's binary_logloss: 0.557791\n",
      "[260]\ttraining's binary_logloss: 0.5577\n",
      "[261]\ttraining's binary_logloss: 0.557618\n",
      "[262]\ttraining's binary_logloss: 0.557542\n",
      "[263]\ttraining's binary_logloss: 0.557467\n",
      "[264]\ttraining's binary_logloss: 0.557355\n",
      "[265]\ttraining's binary_logloss: 0.557291\n",
      "[266]\ttraining's binary_logloss: 0.557218\n",
      "[267]\ttraining's binary_logloss: 0.557146\n",
      "[268]\ttraining's binary_logloss: 0.557074\n",
      "[269]\ttraining's binary_logloss: 0.556995\n",
      "[270]\ttraining's binary_logloss: 0.556907\n",
      "[271]\ttraining's binary_logloss: 0.556739\n",
      "[272]\ttraining's binary_logloss: 0.556589\n",
      "[273]\ttraining's binary_logloss: 0.556428\n",
      "[274]\ttraining's binary_logloss: 0.556264\n",
      "[275]\ttraining's binary_logloss: 0.556108\n",
      "[276]\ttraining's binary_logloss: 0.555998\n",
      "[277]\ttraining's binary_logloss: 0.555891\n",
      "[278]\ttraining's binary_logloss: 0.555778\n",
      "[279]\ttraining's binary_logloss: 0.555683\n",
      "[280]\ttraining's binary_logloss: 0.555599\n",
      "[281]\ttraining's binary_logloss: 0.555497\n",
      "[282]\ttraining's binary_logloss: 0.555402\n",
      "[283]\ttraining's binary_logloss: 0.555283\n",
      "[284]\ttraining's binary_logloss: 0.555184\n",
      "[285]\ttraining's binary_logloss: 0.555059\n",
      "[286]\ttraining's binary_logloss: 0.554916\n",
      "[287]\ttraining's binary_logloss: 0.554787\n",
      "[288]\ttraining's binary_logloss: 0.554655\n",
      "[289]\ttraining's binary_logloss: 0.554531\n",
      "[290]\ttraining's binary_logloss: 0.554407\n",
      "[291]\ttraining's binary_logloss: 0.554254\n",
      "[292]\ttraining's binary_logloss: 0.55409\n",
      "[293]\ttraining's binary_logloss: 0.55393\n",
      "[294]\ttraining's binary_logloss: 0.553784\n",
      "[295]\ttraining's binary_logloss: 0.55363\n",
      "[296]\ttraining's binary_logloss: 0.553501\n",
      "[297]\ttraining's binary_logloss: 0.553393\n",
      "[298]\ttraining's binary_logloss: 0.553289\n",
      "[299]\ttraining's binary_logloss: 0.553184\n",
      "[300]\ttraining's binary_logloss: 0.553078\n",
      "[301]\ttraining's binary_logloss: 0.552981\n",
      "[302]\ttraining's binary_logloss: 0.552864\n",
      "[303]\ttraining's binary_logloss: 0.552757\n",
      "[304]\ttraining's binary_logloss: 0.552648\n",
      "[305]\ttraining's binary_logloss: 0.552532\n",
      "[306]\ttraining's binary_logloss: 0.552439\n",
      "[307]\ttraining's binary_logloss: 0.552343\n",
      "[308]\ttraining's binary_logloss: 0.552245\n",
      "[309]\ttraining's binary_logloss: 0.552109\n",
      "[310]\ttraining's binary_logloss: 0.552009\n",
      "[311]\ttraining's binary_logloss: 0.551884\n",
      "[312]\ttraining's binary_logloss: 0.551759\n",
      "[313]\ttraining's binary_logloss: 0.551637\n",
      "[314]\ttraining's binary_logloss: 0.551518\n",
      "[315]\ttraining's binary_logloss: 0.551382\n",
      "[316]\ttraining's binary_logloss: 0.55126\n",
      "[317]\ttraining's binary_logloss: 0.551134\n",
      "[318]\ttraining's binary_logloss: 0.551001\n",
      "[319]\ttraining's binary_logloss: 0.550875\n",
      "[320]\ttraining's binary_logloss: 0.550753\n",
      "[321]\ttraining's binary_logloss: 0.550646\n",
      "[322]\ttraining's binary_logloss: 0.550544\n",
      "[323]\ttraining's binary_logloss: 0.550416\n",
      "[324]\ttraining's binary_logloss: 0.550309\n",
      "[325]\ttraining's binary_logloss: 0.550183\n",
      "[326]\ttraining's binary_logloss: 0.550075\n",
      "[327]\ttraining's binary_logloss: 0.549913\n",
      "[328]\ttraining's binary_logloss: 0.549815\n",
      "[329]\ttraining's binary_logloss: 0.549663\n",
      "[330]\ttraining's binary_logloss: 0.549541\n",
      "[331]\ttraining's binary_logloss: 0.549408\n",
      "[332]\ttraining's binary_logloss: 0.549277\n",
      "[333]\ttraining's binary_logloss: 0.549137\n",
      "[334]\ttraining's binary_logloss: 0.549019\n",
      "[335]\ttraining's binary_logloss: 0.548895\n",
      "[336]\ttraining's binary_logloss: 0.548724\n",
      "[337]\ttraining's binary_logloss: 0.54855\n",
      "[338]\ttraining's binary_logloss: 0.548389\n",
      "[339]\ttraining's binary_logloss: 0.548239\n",
      "[340]\ttraining's binary_logloss: 0.548087\n",
      "[341]\ttraining's binary_logloss: 0.547998\n",
      "[342]\ttraining's binary_logloss: 0.547908\n",
      "[343]\ttraining's binary_logloss: 0.547824\n",
      "[344]\ttraining's binary_logloss: 0.547749\n",
      "[345]\ttraining's binary_logloss: 0.547654\n",
      "[346]\ttraining's binary_logloss: 0.547556\n",
      "[347]\ttraining's binary_logloss: 0.547458\n",
      "[348]\ttraining's binary_logloss: 0.547365\n",
      "[349]\ttraining's binary_logloss: 0.547262\n",
      "[350]\ttraining's binary_logloss: 0.547163\n",
      "[351]\ttraining's binary_logloss: 0.546998\n",
      "[352]\ttraining's binary_logloss: 0.546874\n",
      "[353]\ttraining's binary_logloss: 0.546731\n",
      "[354]\ttraining's binary_logloss: 0.546562\n",
      "[355]\ttraining's binary_logloss: 0.54641\n",
      "[356]\ttraining's binary_logloss: 0.54625\n",
      "[357]\ttraining's binary_logloss: 0.546098\n",
      "[358]\ttraining's binary_logloss: 0.545937\n",
      "[359]\ttraining's binary_logloss: 0.545785\n",
      "[360]\ttraining's binary_logloss: 0.545639\n",
      "[361]\ttraining's binary_logloss: 0.545464\n",
      "[362]\ttraining's binary_logloss: 0.545297\n",
      "[363]\ttraining's binary_logloss: 0.545127\n",
      "[364]\ttraining's binary_logloss: 0.544976\n",
      "[365]\ttraining's binary_logloss: 0.544835\n",
      "[366]\ttraining's binary_logloss: 0.544708\n",
      "[367]\ttraining's binary_logloss: 0.54459\n",
      "[368]\ttraining's binary_logloss: 0.544472\n",
      "[369]\ttraining's binary_logloss: 0.544356\n",
      "[370]\ttraining's binary_logloss: 0.544238\n",
      "[371]\ttraining's binary_logloss: 0.544115\n",
      "[372]\ttraining's binary_logloss: 0.544017\n",
      "[373]\ttraining's binary_logloss: 0.543921\n",
      "[374]\ttraining's binary_logloss: 0.543835\n",
      "[375]\ttraining's binary_logloss: 0.543756\n",
      "[376]\ttraining's binary_logloss: 0.543623\n",
      "[377]\ttraining's binary_logloss: 0.543494\n",
      "[378]\ttraining's binary_logloss: 0.543386\n",
      "[379]\ttraining's binary_logloss: 0.543273\n",
      "[380]\ttraining's binary_logloss: 0.543147\n",
      "[381]\ttraining's binary_logloss: 0.543017\n",
      "[382]\ttraining's binary_logloss: 0.542935\n",
      "[383]\ttraining's binary_logloss: 0.54281\n",
      "[384]\ttraining's binary_logloss: 0.542713\n",
      "[385]\ttraining's binary_logloss: 0.542606\n",
      "[386]\ttraining's binary_logloss: 0.542448\n",
      "[387]\ttraining's binary_logloss: 0.542293\n",
      "[388]\ttraining's binary_logloss: 0.542135\n",
      "[389]\ttraining's binary_logloss: 0.541975\n",
      "[390]\ttraining's binary_logloss: 0.541835\n",
      "[391]\ttraining's binary_logloss: 0.541702\n",
      "[392]\ttraining's binary_logloss: 0.541541\n",
      "[393]\ttraining's binary_logloss: 0.541392\n",
      "[394]\ttraining's binary_logloss: 0.541251\n",
      "[395]\ttraining's binary_logloss: 0.541078\n",
      "[396]\ttraining's binary_logloss: 0.540946\n",
      "[397]\ttraining's binary_logloss: 0.54082\n",
      "[398]\ttraining's binary_logloss: 0.540695\n",
      "[399]\ttraining's binary_logloss: 0.540576\n",
      "[400]\ttraining's binary_logloss: 0.540458\n",
      "[401]\ttraining's binary_logloss: 0.540264\n",
      "[402]\ttraining's binary_logloss: 0.540063\n",
      "[403]\ttraining's binary_logloss: 0.539929\n",
      "[404]\ttraining's binary_logloss: 0.539762\n",
      "[405]\ttraining's binary_logloss: 0.5396\n",
      "[406]\ttraining's binary_logloss: 0.539478\n",
      "[407]\ttraining's binary_logloss: 0.539337\n",
      "[408]\ttraining's binary_logloss: 0.539203\n",
      "[409]\ttraining's binary_logloss: 0.539069\n",
      "[410]\ttraining's binary_logloss: 0.53894\n",
      "[411]\ttraining's binary_logloss: 0.538802\n",
      "[412]\ttraining's binary_logloss: 0.538689\n",
      "[413]\ttraining's binary_logloss: 0.538555\n",
      "[414]\ttraining's binary_logloss: 0.538414\n",
      "[415]\ttraining's binary_logloss: 0.538297\n",
      "[416]\ttraining's binary_logloss: 0.538169\n",
      "[417]\ttraining's binary_logloss: 0.538045\n",
      "[418]\ttraining's binary_logloss: 0.537912\n",
      "[419]\ttraining's binary_logloss: 0.537815\n",
      "[420]\ttraining's binary_logloss: 0.537714\n",
      "[421]\ttraining's binary_logloss: 0.537632\n",
      "[422]\ttraining's binary_logloss: 0.537552\n",
      "[423]\ttraining's binary_logloss: 0.537466\n",
      "[424]\ttraining's binary_logloss: 0.5374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[425]\ttraining's binary_logloss: 0.537322\n",
      "[426]\ttraining's binary_logloss: 0.537196\n",
      "[427]\ttraining's binary_logloss: 0.537079\n",
      "[428]\ttraining's binary_logloss: 0.536965\n",
      "[429]\ttraining's binary_logloss: 0.536857\n",
      "[430]\ttraining's binary_logloss: 0.536714\n",
      "[431]\ttraining's binary_logloss: 0.536546\n",
      "[432]\ttraining's binary_logloss: 0.536408\n",
      "[433]\ttraining's binary_logloss: 0.536234\n",
      "[434]\ttraining's binary_logloss: 0.536047\n",
      "[435]\ttraining's binary_logloss: 0.535887\n",
      "[436]\ttraining's binary_logloss: 0.535758\n",
      "[437]\ttraining's binary_logloss: 0.535644\n",
      "[438]\ttraining's binary_logloss: 0.535536\n",
      "[439]\ttraining's binary_logloss: 0.535438\n",
      "[440]\ttraining's binary_logloss: 0.53533\n",
      "[441]\ttraining's binary_logloss: 0.535199\n",
      "[442]\ttraining's binary_logloss: 0.535062\n",
      "[443]\ttraining's binary_logloss: 0.534917\n",
      "[444]\ttraining's binary_logloss: 0.534781\n",
      "[445]\ttraining's binary_logloss: 0.534645\n",
      "[446]\ttraining's binary_logloss: 0.534489\n",
      "[447]\ttraining's binary_logloss: 0.534343\n",
      "[448]\ttraining's binary_logloss: 0.53419\n",
      "[449]\ttraining's binary_logloss: 0.534041\n",
      "[450]\ttraining's binary_logloss: 0.5339\n",
      "[451]\ttraining's binary_logloss: 0.533788\n",
      "[452]\ttraining's binary_logloss: 0.533678\n",
      "[453]\ttraining's binary_logloss: 0.533568\n",
      "[454]\ttraining's binary_logloss: 0.533456\n",
      "[455]\ttraining's binary_logloss: 0.533353\n",
      "[456]\ttraining's binary_logloss: 0.533225\n",
      "[457]\ttraining's binary_logloss: 0.533104\n",
      "[458]\ttraining's binary_logloss: 0.532972\n",
      "[459]\ttraining's binary_logloss: 0.532851\n",
      "[460]\ttraining's binary_logloss: 0.532726\n",
      "[461]\ttraining's binary_logloss: 0.532586\n",
      "[462]\ttraining's binary_logloss: 0.53247\n",
      "[463]\ttraining's binary_logloss: 0.532369\n",
      "[464]\ttraining's binary_logloss: 0.532246\n",
      "[465]\ttraining's binary_logloss: 0.532122\n",
      "[466]\ttraining's binary_logloss: 0.532005\n",
      "[467]\ttraining's binary_logloss: 0.531875\n",
      "[468]\ttraining's binary_logloss: 0.531743\n",
      "[469]\ttraining's binary_logloss: 0.531592\n",
      "[470]\ttraining's binary_logloss: 0.531427\n",
      "[471]\ttraining's binary_logloss: 0.531343\n",
      "[472]\ttraining's binary_logloss: 0.531233\n",
      "[473]\ttraining's binary_logloss: 0.531135\n",
      "[474]\ttraining's binary_logloss: 0.531045\n",
      "[475]\ttraining's binary_logloss: 0.530952\n",
      "[476]\ttraining's binary_logloss: 0.530793\n",
      "[477]\ttraining's binary_logloss: 0.530639\n",
      "[478]\ttraining's binary_logloss: 0.530507\n",
      "[479]\ttraining's binary_logloss: 0.530386\n",
      "[480]\ttraining's binary_logloss: 0.530233\n",
      "[481]\ttraining's binary_logloss: 0.530097\n",
      "[482]\ttraining's binary_logloss: 0.529964\n",
      "[483]\ttraining's binary_logloss: 0.529824\n",
      "[484]\ttraining's binary_logloss: 0.529668\n",
      "[485]\ttraining's binary_logloss: 0.529543\n",
      "[486]\ttraining's binary_logloss: 0.529376\n",
      "[487]\ttraining's binary_logloss: 0.529205\n",
      "[488]\ttraining's binary_logloss: 0.529045\n",
      "[489]\ttraining's binary_logloss: 0.528878\n",
      "[490]\ttraining's binary_logloss: 0.528715\n",
      "[491]\ttraining's binary_logloss: 0.528587\n",
      "[492]\ttraining's binary_logloss: 0.528458\n",
      "[493]\ttraining's binary_logloss: 0.528335\n",
      "[494]\ttraining's binary_logloss: 0.52821\n",
      "[495]\ttraining's binary_logloss: 0.528055\n",
      "[496]\ttraining's binary_logloss: 0.527901\n",
      "[497]\ttraining's binary_logloss: 0.527755\n",
      "[498]\ttraining's binary_logloss: 0.527574\n",
      "[499]\ttraining's binary_logloss: 0.527434\n",
      "[500]\ttraining's binary_logloss: 0.527306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.617439\n",
      "[2]\ttraining's binary_logloss: 0.616123\n",
      "[3]\ttraining's binary_logloss: 0.614849\n",
      "[4]\ttraining's binary_logloss: 0.613659\n",
      "[5]\ttraining's binary_logloss: 0.612461\n",
      "[6]\ttraining's binary_logloss: 0.611287\n",
      "[7]\ttraining's binary_logloss: 0.610151\n",
      "[8]\ttraining's binary_logloss: 0.60902\n",
      "[9]\ttraining's binary_logloss: 0.607951\n",
      "[10]\ttraining's binary_logloss: 0.606884\n",
      "[11]\ttraining's binary_logloss: 0.605829\n",
      "[12]\ttraining's binary_logloss: 0.604847\n",
      "[13]\ttraining's binary_logloss: 0.603896\n",
      "[14]\ttraining's binary_logloss: 0.603049\n",
      "[15]\ttraining's binary_logloss: 0.602079\n",
      "[16]\ttraining's binary_logloss: 0.601257\n",
      "[17]\ttraining's binary_logloss: 0.600482\n",
      "[18]\ttraining's binary_logloss: 0.599768\n",
      "[19]\ttraining's binary_logloss: 0.599038\n",
      "[20]\ttraining's binary_logloss: 0.598338\n",
      "[21]\ttraining's binary_logloss: 0.597561\n",
      "[22]\ttraining's binary_logloss: 0.596839\n",
      "[23]\ttraining's binary_logloss: 0.596196\n",
      "[24]\ttraining's binary_logloss: 0.595445\n",
      "[25]\ttraining's binary_logloss: 0.594774\n",
      "[26]\ttraining's binary_logloss: 0.594228\n",
      "[27]\ttraining's binary_logloss: 0.593594\n",
      "[28]\ttraining's binary_logloss: 0.59303\n",
      "[29]\ttraining's binary_logloss: 0.592528\n",
      "[30]\ttraining's binary_logloss: 0.591943\n",
      "[31]\ttraining's binary_logloss: 0.591355\n",
      "[32]\ttraining's binary_logloss: 0.590801\n",
      "[33]\ttraining's binary_logloss: 0.590254\n",
      "[34]\ttraining's binary_logloss: 0.58977\n",
      "[35]\ttraining's binary_logloss: 0.589262\n",
      "[36]\ttraining's binary_logloss: 0.588789\n",
      "[37]\ttraining's binary_logloss: 0.588316\n",
      "[38]\ttraining's binary_logloss: 0.587885\n",
      "[39]\ttraining's binary_logloss: 0.587464\n",
      "[40]\ttraining's binary_logloss: 0.587002\n",
      "[41]\ttraining's binary_logloss: 0.586535\n",
      "[42]\ttraining's binary_logloss: 0.586074\n",
      "[43]\ttraining's binary_logloss: 0.585765\n",
      "[44]\ttraining's binary_logloss: 0.585394\n",
      "[45]\ttraining's binary_logloss: 0.584987\n",
      "[46]\ttraining's binary_logloss: 0.58465\n",
      "[47]\ttraining's binary_logloss: 0.584312\n",
      "[48]\ttraining's binary_logloss: 0.583983\n",
      "[49]\ttraining's binary_logloss: 0.583652\n",
      "[50]\ttraining's binary_logloss: 0.583338\n",
      "[51]\ttraining's binary_logloss: 0.582984\n",
      "[52]\ttraining's binary_logloss: 0.582637\n",
      "[53]\ttraining's binary_logloss: 0.582308\n",
      "[54]\ttraining's binary_logloss: 0.582003\n",
      "[55]\ttraining's binary_logloss: 0.581751\n",
      "[56]\ttraining's binary_logloss: 0.581487\n",
      "[57]\ttraining's binary_logloss: 0.581236\n",
      "[58]\ttraining's binary_logloss: 0.58101\n",
      "[59]\ttraining's binary_logloss: 0.580781\n",
      "[60]\ttraining's binary_logloss: 0.580547\n",
      "[61]\ttraining's binary_logloss: 0.580282\n",
      "[62]\ttraining's binary_logloss: 0.580074\n",
      "[63]\ttraining's binary_logloss: 0.579845\n",
      "[64]\ttraining's binary_logloss: 0.579608\n",
      "[65]\ttraining's binary_logloss: 0.579393\n",
      "[66]\ttraining's binary_logloss: 0.579178\n",
      "[67]\ttraining's binary_logloss: 0.578982\n",
      "[68]\ttraining's binary_logloss: 0.578743\n",
      "[69]\ttraining's binary_logloss: 0.578536\n",
      "[70]\ttraining's binary_logloss: 0.578313\n",
      "[71]\ttraining's binary_logloss: 0.57816\n",
      "[72]\ttraining's binary_logloss: 0.577943\n",
      "[73]\ttraining's binary_logloss: 0.577753\n",
      "[74]\ttraining's binary_logloss: 0.577567\n",
      "[75]\ttraining's binary_logloss: 0.577388\n",
      "[76]\ttraining's binary_logloss: 0.577292\n",
      "[77]\ttraining's binary_logloss: 0.577094\n",
      "[78]\ttraining's binary_logloss: 0.576956\n",
      "[79]\ttraining's binary_logloss: 0.57675\n",
      "[80]\ttraining's binary_logloss: 0.576567\n",
      "[81]\ttraining's binary_logloss: 0.576384\n",
      "[82]\ttraining's binary_logloss: 0.576182\n",
      "[83]\ttraining's binary_logloss: 0.576041\n",
      "[84]\ttraining's binary_logloss: 0.57589\n",
      "[85]\ttraining's binary_logloss: 0.575733\n",
      "[86]\ttraining's binary_logloss: 0.575649\n",
      "[87]\ttraining's binary_logloss: 0.575531\n",
      "[88]\ttraining's binary_logloss: 0.57543\n",
      "[89]\ttraining's binary_logloss: 0.575316\n",
      "[90]\ttraining's binary_logloss: 0.575217\n",
      "[91]\ttraining's binary_logloss: 0.575084\n",
      "[92]\ttraining's binary_logloss: 0.574904\n",
      "[93]\ttraining's binary_logloss: 0.574743\n",
      "[94]\ttraining's binary_logloss: 0.574631\n",
      "[95]\ttraining's binary_logloss: 0.574463\n",
      "[96]\ttraining's binary_logloss: 0.574372\n",
      "[97]\ttraining's binary_logloss: 0.574318\n",
      "[98]\ttraining's binary_logloss: 0.574242\n",
      "[99]\ttraining's binary_logloss: 0.574153\n",
      "[100]\ttraining's binary_logloss: 0.574061\n",
      "[101]\ttraining's binary_logloss: 0.573991\n",
      "[102]\ttraining's binary_logloss: 0.573928\n",
      "[103]\ttraining's binary_logloss: 0.573854\n",
      "[104]\ttraining's binary_logloss: 0.573792\n",
      "[105]\ttraining's binary_logloss: 0.573718\n",
      "[106]\ttraining's binary_logloss: 0.573638\n",
      "[107]\ttraining's binary_logloss: 0.573521\n",
      "[108]\ttraining's binary_logloss: 0.5734\n",
      "[109]\ttraining's binary_logloss: 0.573316\n",
      "[110]\ttraining's binary_logloss: 0.573227\n",
      "[111]\ttraining's binary_logloss: 0.573199\n",
      "[112]\ttraining's binary_logloss: 0.573132\n",
      "[113]\ttraining's binary_logloss: 0.573055\n",
      "[114]\ttraining's binary_logloss: 0.573001\n",
      "[115]\ttraining's binary_logloss: 0.572946\n",
      "[116]\ttraining's binary_logloss: 0.572818\n",
      "[117]\ttraining's binary_logloss: 0.572726\n",
      "[118]\ttraining's binary_logloss: 0.572636\n",
      "[119]\ttraining's binary_logloss: 0.572555\n",
      "[120]\ttraining's binary_logloss: 0.572503\n",
      "[121]\ttraining's binary_logloss: 0.57242\n",
      "[122]\ttraining's binary_logloss: 0.572344\n",
      "[123]\ttraining's binary_logloss: 0.572271\n",
      "[124]\ttraining's binary_logloss: 0.572226\n",
      "[125]\ttraining's binary_logloss: 0.572159\n",
      "[126]\ttraining's binary_logloss: 0.572041\n",
      "[127]\ttraining's binary_logloss: 0.571952\n",
      "[128]\ttraining's binary_logloss: 0.57187\n",
      "[129]\ttraining's binary_logloss: 0.571743\n",
      "[130]\ttraining's binary_logloss: 0.57167\n",
      "[131]\ttraining's binary_logloss: 0.571548\n",
      "[132]\ttraining's binary_logloss: 0.571434\n",
      "[133]\ttraining's binary_logloss: 0.571339\n",
      "[134]\ttraining's binary_logloss: 0.571245\n",
      "[135]\ttraining's binary_logloss: 0.571136\n",
      "[136]\ttraining's binary_logloss: 0.571061\n",
      "[137]\ttraining's binary_logloss: 0.570965\n",
      "[138]\ttraining's binary_logloss: 0.570876\n",
      "[139]\ttraining's binary_logloss: 0.570782\n",
      "[140]\ttraining's binary_logloss: 0.570714\n",
      "[141]\ttraining's binary_logloss: 0.570619\n",
      "[142]\ttraining's binary_logloss: 0.570532\n",
      "[143]\ttraining's binary_logloss: 0.570414\n",
      "[144]\ttraining's binary_logloss: 0.570307\n",
      "[145]\ttraining's binary_logloss: 0.570211\n",
      "[146]\ttraining's binary_logloss: 0.570193\n",
      "[147]\ttraining's binary_logloss: 0.570079\n",
      "[148]\ttraining's binary_logloss: 0.569963\n",
      "[149]\ttraining's binary_logloss: 0.569896\n",
      "[150]\ttraining's binary_logloss: 0.569781\n",
      "[151]\ttraining's binary_logloss: 0.569735\n",
      "[152]\ttraining's binary_logloss: 0.569699\n",
      "[153]\ttraining's binary_logloss: 0.569643\n",
      "[154]\ttraining's binary_logloss: 0.569593\n",
      "[155]\ttraining's binary_logloss: 0.569554\n",
      "[156]\ttraining's binary_logloss: 0.569491\n",
      "[157]\ttraining's binary_logloss: 0.569395\n",
      "[158]\ttraining's binary_logloss: 0.569333\n",
      "[159]\ttraining's binary_logloss: 0.569237\n",
      "[160]\ttraining's binary_logloss: 0.56916\n",
      "[161]\ttraining's binary_logloss: 0.569064\n",
      "[162]\ttraining's binary_logloss: 0.568976\n",
      "[163]\ttraining's binary_logloss: 0.56888\n",
      "[164]\ttraining's binary_logloss: 0.568814\n",
      "[165]\ttraining's binary_logloss: 0.568723\n",
      "[166]\ttraining's binary_logloss: 0.568633\n",
      "[167]\ttraining's binary_logloss: 0.568541\n",
      "[168]\ttraining's binary_logloss: 0.56845\n",
      "[169]\ttraining's binary_logloss: 0.568335\n",
      "[170]\ttraining's binary_logloss: 0.568241\n",
      "[171]\ttraining's binary_logloss: 0.568174\n",
      "[172]\ttraining's binary_logloss: 0.568112\n",
      "[173]\ttraining's binary_logloss: 0.568051\n",
      "[174]\ttraining's binary_logloss: 0.56798\n",
      "[175]\ttraining's binary_logloss: 0.56793\n",
      "[176]\ttraining's binary_logloss: 0.567831\n",
      "[177]\ttraining's binary_logloss: 0.567744\n",
      "[178]\ttraining's binary_logloss: 0.567665\n",
      "[179]\ttraining's binary_logloss: 0.567598\n",
      "[180]\ttraining's binary_logloss: 0.567525\n",
      "[181]\ttraining's binary_logloss: 0.567445\n",
      "[182]\ttraining's binary_logloss: 0.567347\n",
      "[183]\ttraining's binary_logloss: 0.567248\n",
      "[184]\ttraining's binary_logloss: 0.567188\n",
      "[185]\ttraining's binary_logloss: 0.567112\n",
      "[186]\ttraining's binary_logloss: 0.567069\n",
      "[187]\ttraining's binary_logloss: 0.567038\n",
      "[188]\ttraining's binary_logloss: 0.566992\n",
      "[189]\ttraining's binary_logloss: 0.566957\n",
      "[190]\ttraining's binary_logloss: 0.566898\n",
      "[191]\ttraining's binary_logloss: 0.566822\n",
      "[192]\ttraining's binary_logloss: 0.566766\n",
      "[193]\ttraining's binary_logloss: 0.566673\n",
      "[194]\ttraining's binary_logloss: 0.566582\n",
      "[195]\ttraining's binary_logloss: 0.566487\n",
      "[196]\ttraining's binary_logloss: 0.566352\n",
      "[197]\ttraining's binary_logloss: 0.566241\n",
      "[198]\ttraining's binary_logloss: 0.56614\n",
      "[199]\ttraining's binary_logloss: 0.566063\n",
      "[200]\ttraining's binary_logloss: 0.565963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[201]\ttraining's binary_logloss: 0.565834\n",
      "[202]\ttraining's binary_logloss: 0.565725\n",
      "[203]\ttraining's binary_logloss: 0.565616\n",
      "[204]\ttraining's binary_logloss: 0.565509\n",
      "[205]\ttraining's binary_logloss: 0.565427\n",
      "[206]\ttraining's binary_logloss: 0.56536\n",
      "[207]\ttraining's binary_logloss: 0.565315\n",
      "[208]\ttraining's binary_logloss: 0.565267\n",
      "[209]\ttraining's binary_logloss: 0.565213\n",
      "[210]\ttraining's binary_logloss: 0.565169\n",
      "[211]\ttraining's binary_logloss: 0.565085\n",
      "[212]\ttraining's binary_logloss: 0.565009\n",
      "[213]\ttraining's binary_logloss: 0.564949\n",
      "[214]\ttraining's binary_logloss: 0.564859\n",
      "[215]\ttraining's binary_logloss: 0.564765\n",
      "[216]\ttraining's binary_logloss: 0.564713\n",
      "[217]\ttraining's binary_logloss: 0.564592\n",
      "[218]\ttraining's binary_logloss: 0.564488\n",
      "[219]\ttraining's binary_logloss: 0.564407\n",
      "[220]\ttraining's binary_logloss: 0.56433\n",
      "[221]\ttraining's binary_logloss: 0.56423\n",
      "[222]\ttraining's binary_logloss: 0.564133\n",
      "[223]\ttraining's binary_logloss: 0.564038\n",
      "[224]\ttraining's binary_logloss: 0.563949\n",
      "[225]\ttraining's binary_logloss: 0.563858\n",
      "[226]\ttraining's binary_logloss: 0.563737\n",
      "[227]\ttraining's binary_logloss: 0.563636\n",
      "[228]\ttraining's binary_logloss: 0.563528\n",
      "[229]\ttraining's binary_logloss: 0.563408\n",
      "[230]\ttraining's binary_logloss: 0.563316\n",
      "[231]\ttraining's binary_logloss: 0.563231\n",
      "[232]\ttraining's binary_logloss: 0.563148\n",
      "[233]\ttraining's binary_logloss: 0.563052\n",
      "[234]\ttraining's binary_logloss: 0.562958\n",
      "[235]\ttraining's binary_logloss: 0.562866\n",
      "[236]\ttraining's binary_logloss: 0.562753\n",
      "[237]\ttraining's binary_logloss: 0.562645\n",
      "[238]\ttraining's binary_logloss: 0.562495\n",
      "[239]\ttraining's binary_logloss: 0.562391\n",
      "[240]\ttraining's binary_logloss: 0.562266\n",
      "[241]\ttraining's binary_logloss: 0.562127\n",
      "[242]\ttraining's binary_logloss: 0.562011\n",
      "[243]\ttraining's binary_logloss: 0.56189\n",
      "[244]\ttraining's binary_logloss: 0.561792\n",
      "[245]\ttraining's binary_logloss: 0.561676\n",
      "[246]\ttraining's binary_logloss: 0.56155\n",
      "[247]\ttraining's binary_logloss: 0.561437\n",
      "[248]\ttraining's binary_logloss: 0.561326\n",
      "[249]\ttraining's binary_logloss: 0.561167\n",
      "[250]\ttraining's binary_logloss: 0.561023\n",
      "[251]\ttraining's binary_logloss: 0.560916\n",
      "[252]\ttraining's binary_logloss: 0.560831\n",
      "[253]\ttraining's binary_logloss: 0.560743\n",
      "[254]\ttraining's binary_logloss: 0.560644\n",
      "[255]\ttraining's binary_logloss: 0.56054\n",
      "[256]\ttraining's binary_logloss: 0.560424\n",
      "[257]\ttraining's binary_logloss: 0.560314\n",
      "[258]\ttraining's binary_logloss: 0.560212\n",
      "[259]\ttraining's binary_logloss: 0.560107\n",
      "[260]\ttraining's binary_logloss: 0.560001\n",
      "[261]\ttraining's binary_logloss: 0.559868\n",
      "[262]\ttraining's binary_logloss: 0.559744\n",
      "[263]\ttraining's binary_logloss: 0.559622\n",
      "[264]\ttraining's binary_logloss: 0.559509\n",
      "[265]\ttraining's binary_logloss: 0.559393\n",
      "[266]\ttraining's binary_logloss: 0.559288\n",
      "[267]\ttraining's binary_logloss: 0.559189\n",
      "[268]\ttraining's binary_logloss: 0.559115\n",
      "[269]\ttraining's binary_logloss: 0.559012\n",
      "[270]\ttraining's binary_logloss: 0.558941\n",
      "[271]\ttraining's binary_logloss: 0.558808\n",
      "[272]\ttraining's binary_logloss: 0.558673\n",
      "[273]\ttraining's binary_logloss: 0.558537\n",
      "[274]\ttraining's binary_logloss: 0.55841\n",
      "[275]\ttraining's binary_logloss: 0.558288\n",
      "[276]\ttraining's binary_logloss: 0.558162\n",
      "[277]\ttraining's binary_logloss: 0.558045\n",
      "[278]\ttraining's binary_logloss: 0.557933\n",
      "[279]\ttraining's binary_logloss: 0.55782\n",
      "[280]\ttraining's binary_logloss: 0.557692\n",
      "[281]\ttraining's binary_logloss: 0.557567\n",
      "[282]\ttraining's binary_logloss: 0.557471\n",
      "[283]\ttraining's binary_logloss: 0.557366\n",
      "[284]\ttraining's binary_logloss: 0.557265\n",
      "[285]\ttraining's binary_logloss: 0.557152\n",
      "[286]\ttraining's binary_logloss: 0.55702\n",
      "[287]\ttraining's binary_logloss: 0.556893\n",
      "[288]\ttraining's binary_logloss: 0.556771\n",
      "[289]\ttraining's binary_logloss: 0.556664\n",
      "[290]\ttraining's binary_logloss: 0.556554\n",
      "[291]\ttraining's binary_logloss: 0.55642\n",
      "[292]\ttraining's binary_logloss: 0.556294\n",
      "[293]\ttraining's binary_logloss: 0.55617\n",
      "[294]\ttraining's binary_logloss: 0.556042\n",
      "[295]\ttraining's binary_logloss: 0.555907\n",
      "[296]\ttraining's binary_logloss: 0.555771\n",
      "[297]\ttraining's binary_logloss: 0.555646\n",
      "[298]\ttraining's binary_logloss: 0.555508\n",
      "[299]\ttraining's binary_logloss: 0.555371\n",
      "[300]\ttraining's binary_logloss: 0.555255\n",
      "[301]\ttraining's binary_logloss: 0.55511\n",
      "[302]\ttraining's binary_logloss: 0.554966\n",
      "[303]\ttraining's binary_logloss: 0.554843\n",
      "[304]\ttraining's binary_logloss: 0.554702\n",
      "[305]\ttraining's binary_logloss: 0.55455\n",
      "[306]\ttraining's binary_logloss: 0.554405\n",
      "[307]\ttraining's binary_logloss: 0.554257\n",
      "[308]\ttraining's binary_logloss: 0.554118\n",
      "[309]\ttraining's binary_logloss: 0.554002\n",
      "[310]\ttraining's binary_logloss: 0.553882\n",
      "[311]\ttraining's binary_logloss: 0.553733\n",
      "[312]\ttraining's binary_logloss: 0.553593\n",
      "[313]\ttraining's binary_logloss: 0.553461\n",
      "[314]\ttraining's binary_logloss: 0.553333\n",
      "[315]\ttraining's binary_logloss: 0.553205\n",
      "[316]\ttraining's binary_logloss: 0.553066\n",
      "[317]\ttraining's binary_logloss: 0.552926\n",
      "[318]\ttraining's binary_logloss: 0.552786\n",
      "[319]\ttraining's binary_logloss: 0.552658\n",
      "[320]\ttraining's binary_logloss: 0.552524\n",
      "[321]\ttraining's binary_logloss: 0.552401\n",
      "[322]\ttraining's binary_logloss: 0.55229\n",
      "[323]\ttraining's binary_logloss: 0.552164\n",
      "[324]\ttraining's binary_logloss: 0.552045\n",
      "[325]\ttraining's binary_logloss: 0.551895\n",
      "[326]\ttraining's binary_logloss: 0.551798\n",
      "[327]\ttraining's binary_logloss: 0.551692\n",
      "[328]\ttraining's binary_logloss: 0.55158\n",
      "[329]\ttraining's binary_logloss: 0.551481\n",
      "[330]\ttraining's binary_logloss: 0.551367\n",
      "[331]\ttraining's binary_logloss: 0.551244\n",
      "[332]\ttraining's binary_logloss: 0.551112\n",
      "[333]\ttraining's binary_logloss: 0.550981\n",
      "[334]\ttraining's binary_logloss: 0.550838\n",
      "[335]\ttraining's binary_logloss: 0.550715\n",
      "[336]\ttraining's binary_logloss: 0.550563\n",
      "[337]\ttraining's binary_logloss: 0.550417\n",
      "[338]\ttraining's binary_logloss: 0.550272\n",
      "[339]\ttraining's binary_logloss: 0.55013\n",
      "[340]\ttraining's binary_logloss: 0.549997\n",
      "[341]\ttraining's binary_logloss: 0.54988\n",
      "[342]\ttraining's binary_logloss: 0.549751\n",
      "[343]\ttraining's binary_logloss: 0.549641\n",
      "[344]\ttraining's binary_logloss: 0.549509\n",
      "[345]\ttraining's binary_logloss: 0.549382\n",
      "[346]\ttraining's binary_logloss: 0.549283\n",
      "[347]\ttraining's binary_logloss: 0.549191\n",
      "[348]\ttraining's binary_logloss: 0.549083\n",
      "[349]\ttraining's binary_logloss: 0.548974\n",
      "[350]\ttraining's binary_logloss: 0.548905\n",
      "[351]\ttraining's binary_logloss: 0.548759\n",
      "[352]\ttraining's binary_logloss: 0.548622\n",
      "[353]\ttraining's binary_logloss: 0.548458\n",
      "[354]\ttraining's binary_logloss: 0.548299\n",
      "[355]\ttraining's binary_logloss: 0.548152\n",
      "[356]\ttraining's binary_logloss: 0.548025\n",
      "[357]\ttraining's binary_logloss: 0.547889\n",
      "[358]\ttraining's binary_logloss: 0.547768\n",
      "[359]\ttraining's binary_logloss: 0.547639\n",
      "[360]\ttraining's binary_logloss: 0.547506\n",
      "[361]\ttraining's binary_logloss: 0.547355\n",
      "[362]\ttraining's binary_logloss: 0.547203\n",
      "[363]\ttraining's binary_logloss: 0.547048\n",
      "[364]\ttraining's binary_logloss: 0.546898\n",
      "[365]\ttraining's binary_logloss: 0.54676\n",
      "[366]\ttraining's binary_logloss: 0.546671\n",
      "[367]\ttraining's binary_logloss: 0.546577\n",
      "[368]\ttraining's binary_logloss: 0.546442\n",
      "[369]\ttraining's binary_logloss: 0.546349\n",
      "[370]\ttraining's binary_logloss: 0.546223\n",
      "[371]\ttraining's binary_logloss: 0.546105\n",
      "[372]\ttraining's binary_logloss: 0.545984\n",
      "[373]\ttraining's binary_logloss: 0.545853\n",
      "[374]\ttraining's binary_logloss: 0.545737\n",
      "[375]\ttraining's binary_logloss: 0.54561\n",
      "[376]\ttraining's binary_logloss: 0.54547\n",
      "[377]\ttraining's binary_logloss: 0.545318\n",
      "[378]\ttraining's binary_logloss: 0.545172\n",
      "[379]\ttraining's binary_logloss: 0.545047\n",
      "[380]\ttraining's binary_logloss: 0.544897\n",
      "[381]\ttraining's binary_logloss: 0.544756\n",
      "[382]\ttraining's binary_logloss: 0.544611\n",
      "[383]\ttraining's binary_logloss: 0.544487\n",
      "[384]\ttraining's binary_logloss: 0.544353\n",
      "[385]\ttraining's binary_logloss: 0.54424\n",
      "[386]\ttraining's binary_logloss: 0.544092\n",
      "[387]\ttraining's binary_logloss: 0.543954\n",
      "[388]\ttraining's binary_logloss: 0.543817\n",
      "[389]\ttraining's binary_logloss: 0.543686\n",
      "[390]\ttraining's binary_logloss: 0.543551\n",
      "[391]\ttraining's binary_logloss: 0.543412\n",
      "[392]\ttraining's binary_logloss: 0.543286\n",
      "[393]\ttraining's binary_logloss: 0.543154\n",
      "[394]\ttraining's binary_logloss: 0.543028\n",
      "[395]\ttraining's binary_logloss: 0.542872\n",
      "[396]\ttraining's binary_logloss: 0.542735\n",
      "[397]\ttraining's binary_logloss: 0.542598\n",
      "[398]\ttraining's binary_logloss: 0.542462\n",
      "[399]\ttraining's binary_logloss: 0.542306\n",
      "[400]\ttraining's binary_logloss: 0.54218\n",
      "[401]\ttraining's binary_logloss: 0.542036\n",
      "[402]\ttraining's binary_logloss: 0.541869\n",
      "[403]\ttraining's binary_logloss: 0.541736\n",
      "[404]\ttraining's binary_logloss: 0.541574\n",
      "[405]\ttraining's binary_logloss: 0.541445\n",
      "[406]\ttraining's binary_logloss: 0.541295\n",
      "[407]\ttraining's binary_logloss: 0.541148\n",
      "[408]\ttraining's binary_logloss: 0.541006\n",
      "[409]\ttraining's binary_logloss: 0.540877\n",
      "[410]\ttraining's binary_logloss: 0.540755\n",
      "[411]\ttraining's binary_logloss: 0.540621\n",
      "[412]\ttraining's binary_logloss: 0.540472\n",
      "[413]\ttraining's binary_logloss: 0.540324\n",
      "[414]\ttraining's binary_logloss: 0.540192\n",
      "[415]\ttraining's binary_logloss: 0.540053\n",
      "[416]\ttraining's binary_logloss: 0.539923\n",
      "[417]\ttraining's binary_logloss: 0.539811\n",
      "[418]\ttraining's binary_logloss: 0.539681\n",
      "[419]\ttraining's binary_logloss: 0.539555\n",
      "[420]\ttraining's binary_logloss: 0.539407\n",
      "[421]\ttraining's binary_logloss: 0.539305\n",
      "[422]\ttraining's binary_logloss: 0.539199\n",
      "[423]\ttraining's binary_logloss: 0.539125\n",
      "[424]\ttraining's binary_logloss: 0.539031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[425]\ttraining's binary_logloss: 0.538943\n",
      "[426]\ttraining's binary_logloss: 0.538812\n",
      "[427]\ttraining's binary_logloss: 0.538683\n",
      "[428]\ttraining's binary_logloss: 0.538556\n",
      "[429]\ttraining's binary_logloss: 0.538434\n",
      "[430]\ttraining's binary_logloss: 0.538321\n",
      "[431]\ttraining's binary_logloss: 0.538178\n",
      "[432]\ttraining's binary_logloss: 0.538047\n",
      "[433]\ttraining's binary_logloss: 0.537892\n",
      "[434]\ttraining's binary_logloss: 0.537752\n",
      "[435]\ttraining's binary_logloss: 0.537624\n",
      "[436]\ttraining's binary_logloss: 0.537526\n",
      "[437]\ttraining's binary_logloss: 0.537387\n",
      "[438]\ttraining's binary_logloss: 0.537263\n",
      "[439]\ttraining's binary_logloss: 0.537162\n",
      "[440]\ttraining's binary_logloss: 0.537058\n",
      "[441]\ttraining's binary_logloss: 0.536915\n",
      "[442]\ttraining's binary_logloss: 0.536769\n",
      "[443]\ttraining's binary_logloss: 0.536617\n",
      "[444]\ttraining's binary_logloss: 0.536476\n",
      "[445]\ttraining's binary_logloss: 0.536335\n",
      "[446]\ttraining's binary_logloss: 0.536188\n",
      "[447]\ttraining's binary_logloss: 0.536052\n",
      "[448]\ttraining's binary_logloss: 0.535938\n",
      "[449]\ttraining's binary_logloss: 0.535798\n",
      "[450]\ttraining's binary_logloss: 0.535684\n",
      "[451]\ttraining's binary_logloss: 0.5356\n",
      "[452]\ttraining's binary_logloss: 0.535514\n",
      "[453]\ttraining's binary_logloss: 0.535404\n",
      "[454]\ttraining's binary_logloss: 0.535328\n",
      "[455]\ttraining's binary_logloss: 0.535225\n",
      "[456]\ttraining's binary_logloss: 0.535062\n",
      "[457]\ttraining's binary_logloss: 0.534909\n",
      "[458]\ttraining's binary_logloss: 0.534733\n",
      "[459]\ttraining's binary_logloss: 0.534604\n",
      "[460]\ttraining's binary_logloss: 0.534434\n",
      "[461]\ttraining's binary_logloss: 0.534302\n",
      "[462]\ttraining's binary_logloss: 0.534191\n",
      "[463]\ttraining's binary_logloss: 0.53406\n",
      "[464]\ttraining's binary_logloss: 0.533923\n",
      "[465]\ttraining's binary_logloss: 0.533811\n",
      "[466]\ttraining's binary_logloss: 0.533636\n",
      "[467]\ttraining's binary_logloss: 0.533461\n",
      "[468]\ttraining's binary_logloss: 0.533316\n",
      "[469]\ttraining's binary_logloss: 0.533148\n",
      "[470]\ttraining's binary_logloss: 0.532979\n",
      "[471]\ttraining's binary_logloss: 0.532865\n",
      "[472]\ttraining's binary_logloss: 0.532737\n",
      "[473]\ttraining's binary_logloss: 0.532619\n",
      "[474]\ttraining's binary_logloss: 0.5325\n",
      "[475]\ttraining's binary_logloss: 0.53239\n",
      "[476]\ttraining's binary_logloss: 0.532238\n",
      "[477]\ttraining's binary_logloss: 0.532108\n",
      "[478]\ttraining's binary_logloss: 0.531956\n",
      "[479]\ttraining's binary_logloss: 0.531826\n",
      "[480]\ttraining's binary_logloss: 0.531676\n",
      "[481]\ttraining's binary_logloss: 0.531538\n",
      "[482]\ttraining's binary_logloss: 0.531393\n",
      "[483]\ttraining's binary_logloss: 0.53125\n",
      "[484]\ttraining's binary_logloss: 0.531125\n",
      "[485]\ttraining's binary_logloss: 0.53098\n",
      "[486]\ttraining's binary_logloss: 0.530829\n",
      "[487]\ttraining's binary_logloss: 0.530721\n",
      "[488]\ttraining's binary_logloss: 0.530621\n",
      "[489]\ttraining's binary_logloss: 0.530499\n",
      "[490]\ttraining's binary_logloss: 0.530364\n",
      "[491]\ttraining's binary_logloss: 0.530187\n",
      "[492]\ttraining's binary_logloss: 0.530015\n",
      "[493]\ttraining's binary_logloss: 0.529858\n",
      "[494]\ttraining's binary_logloss: 0.529712\n",
      "[495]\ttraining's binary_logloss: 0.529531\n",
      "[496]\ttraining's binary_logloss: 0.529335\n",
      "[497]\ttraining's binary_logloss: 0.529146\n",
      "[498]\ttraining's binary_logloss: 0.528953\n",
      "[499]\ttraining's binary_logloss: 0.528775\n",
      "[500]\ttraining's binary_logloss: 0.528578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613486\n",
      "[2]\ttraining's binary_logloss: 0.612135\n",
      "[3]\ttraining's binary_logloss: 0.610852\n",
      "[4]\ttraining's binary_logloss: 0.609579\n",
      "[5]\ttraining's binary_logloss: 0.608361\n",
      "[6]\ttraining's binary_logloss: 0.607153\n",
      "[7]\ttraining's binary_logloss: 0.606004\n",
      "[8]\ttraining's binary_logloss: 0.604878\n",
      "[9]\ttraining's binary_logloss: 0.603931\n",
      "[10]\ttraining's binary_logloss: 0.6029\n",
      "[11]\ttraining's binary_logloss: 0.601937\n",
      "[12]\ttraining's binary_logloss: 0.600981\n",
      "[13]\ttraining's binary_logloss: 0.600107\n",
      "[14]\ttraining's binary_logloss: 0.599224\n",
      "[15]\ttraining's binary_logloss: 0.598349\n",
      "[16]\ttraining's binary_logloss: 0.597569\n",
      "[17]\ttraining's binary_logloss: 0.596766\n",
      "[18]\ttraining's binary_logloss: 0.595985\n",
      "[19]\ttraining's binary_logloss: 0.595211\n",
      "[20]\ttraining's binary_logloss: 0.594445\n",
      "[21]\ttraining's binary_logloss: 0.593701\n",
      "[22]\ttraining's binary_logloss: 0.592982\n",
      "[23]\ttraining's binary_logloss: 0.592282\n",
      "[24]\ttraining's binary_logloss: 0.591615\n",
      "[25]\ttraining's binary_logloss: 0.590958\n",
      "[26]\ttraining's binary_logloss: 0.590321\n",
      "[27]\ttraining's binary_logloss: 0.589694\n",
      "[28]\ttraining's binary_logloss: 0.589162\n",
      "[29]\ttraining's binary_logloss: 0.5886\n",
      "[30]\ttraining's binary_logloss: 0.588047\n",
      "[31]\ttraining's binary_logloss: 0.587601\n",
      "[32]\ttraining's binary_logloss: 0.587061\n",
      "[33]\ttraining's binary_logloss: 0.586578\n",
      "[34]\ttraining's binary_logloss: 0.586068\n",
      "[35]\ttraining's binary_logloss: 0.585629\n",
      "[36]\ttraining's binary_logloss: 0.585232\n",
      "[37]\ttraining's binary_logloss: 0.584753\n",
      "[38]\ttraining's binary_logloss: 0.584365\n",
      "[39]\ttraining's binary_logloss: 0.58398\n",
      "[40]\ttraining's binary_logloss: 0.583568\n",
      "[41]\ttraining's binary_logloss: 0.583194\n",
      "[42]\ttraining's binary_logloss: 0.582782\n",
      "[43]\ttraining's binary_logloss: 0.582375\n",
      "[44]\ttraining's binary_logloss: 0.581968\n",
      "[45]\ttraining's binary_logloss: 0.581647\n",
      "[46]\ttraining's binary_logloss: 0.581243\n",
      "[47]\ttraining's binary_logloss: 0.580872\n",
      "[48]\ttraining's binary_logloss: 0.58055\n",
      "[49]\ttraining's binary_logloss: 0.58023\n",
      "[50]\ttraining's binary_logloss: 0.57998\n",
      "[51]\ttraining's binary_logloss: 0.579685\n",
      "[52]\ttraining's binary_logloss: 0.579423\n",
      "[53]\ttraining's binary_logloss: 0.57915\n",
      "[54]\ttraining's binary_logloss: 0.578873\n",
      "[55]\ttraining's binary_logloss: 0.578658\n",
      "[56]\ttraining's binary_logloss: 0.578466\n",
      "[57]\ttraining's binary_logloss: 0.578184\n",
      "[58]\ttraining's binary_logloss: 0.577909\n",
      "[59]\ttraining's binary_logloss: 0.577649\n",
      "[60]\ttraining's binary_logloss: 0.577412\n",
      "[61]\ttraining's binary_logloss: 0.577133\n",
      "[62]\ttraining's binary_logloss: 0.576962\n",
      "[63]\ttraining's binary_logloss: 0.576709\n",
      "[64]\ttraining's binary_logloss: 0.576468\n",
      "[65]\ttraining's binary_logloss: 0.576234\n",
      "[66]\ttraining's binary_logloss: 0.575993\n",
      "[67]\ttraining's binary_logloss: 0.575765\n",
      "[68]\ttraining's binary_logloss: 0.575534\n",
      "[69]\ttraining's binary_logloss: 0.575319\n",
      "[70]\ttraining's binary_logloss: 0.575154\n",
      "[71]\ttraining's binary_logloss: 0.574998\n",
      "[72]\ttraining's binary_logloss: 0.574753\n",
      "[73]\ttraining's binary_logloss: 0.574532\n",
      "[74]\ttraining's binary_logloss: 0.574312\n",
      "[75]\ttraining's binary_logloss: 0.574103\n",
      "[76]\ttraining's binary_logloss: 0.573979\n",
      "[77]\ttraining's binary_logloss: 0.57382\n",
      "[78]\ttraining's binary_logloss: 0.5737\n",
      "[79]\ttraining's binary_logloss: 0.57359\n",
      "[80]\ttraining's binary_logloss: 0.573489\n",
      "[81]\ttraining's binary_logloss: 0.573356\n",
      "[82]\ttraining's binary_logloss: 0.573191\n",
      "[83]\ttraining's binary_logloss: 0.573071\n",
      "[84]\ttraining's binary_logloss: 0.572996\n",
      "[85]\ttraining's binary_logloss: 0.572881\n",
      "[86]\ttraining's binary_logloss: 0.572772\n",
      "[87]\ttraining's binary_logloss: 0.572649\n",
      "[88]\ttraining's binary_logloss: 0.572543\n",
      "[89]\ttraining's binary_logloss: 0.572429\n",
      "[90]\ttraining's binary_logloss: 0.572342\n",
      "[91]\ttraining's binary_logloss: 0.572245\n",
      "[92]\ttraining's binary_logloss: 0.572076\n",
      "[93]\ttraining's binary_logloss: 0.571989\n",
      "[94]\ttraining's binary_logloss: 0.571909\n",
      "[95]\ttraining's binary_logloss: 0.571829\n",
      "[96]\ttraining's binary_logloss: 0.571759\n",
      "[97]\ttraining's binary_logloss: 0.5717\n",
      "[98]\ttraining's binary_logloss: 0.571627\n",
      "[99]\ttraining's binary_logloss: 0.571572\n",
      "[100]\ttraining's binary_logloss: 0.571509\n",
      "[101]\ttraining's binary_logloss: 0.571419\n",
      "[102]\ttraining's binary_logloss: 0.571333\n",
      "[103]\ttraining's binary_logloss: 0.571252\n",
      "[104]\ttraining's binary_logloss: 0.57118\n",
      "[105]\ttraining's binary_logloss: 0.571124\n",
      "[106]\ttraining's binary_logloss: 0.571045\n",
      "[107]\ttraining's binary_logloss: 0.570963\n",
      "[108]\ttraining's binary_logloss: 0.570905\n",
      "[109]\ttraining's binary_logloss: 0.570829\n",
      "[110]\ttraining's binary_logloss: 0.570764\n",
      "[111]\ttraining's binary_logloss: 0.570698\n",
      "[112]\ttraining's binary_logloss: 0.570631\n",
      "[113]\ttraining's binary_logloss: 0.57058\n",
      "[114]\ttraining's binary_logloss: 0.570549\n",
      "[115]\ttraining's binary_logloss: 0.570491\n",
      "[116]\ttraining's binary_logloss: 0.570389\n",
      "[117]\ttraining's binary_logloss: 0.570308\n",
      "[118]\ttraining's binary_logloss: 0.57026\n",
      "[119]\ttraining's binary_logloss: 0.570184\n",
      "[120]\ttraining's binary_logloss: 0.570162\n",
      "[121]\ttraining's binary_logloss: 0.570097\n",
      "[122]\ttraining's binary_logloss: 0.570045\n",
      "[123]\ttraining's binary_logloss: 0.570001\n",
      "[124]\ttraining's binary_logloss: 0.569937\n",
      "[125]\ttraining's binary_logloss: 0.56989\n",
      "[126]\ttraining's binary_logloss: 0.569829\n",
      "[127]\ttraining's binary_logloss: 0.569755\n",
      "[128]\ttraining's binary_logloss: 0.569683\n",
      "[129]\ttraining's binary_logloss: 0.56962\n",
      "[130]\ttraining's binary_logloss: 0.569559\n",
      "[131]\ttraining's binary_logloss: 0.569503\n",
      "[132]\ttraining's binary_logloss: 0.569475\n",
      "[133]\ttraining's binary_logloss: 0.569461\n",
      "[134]\ttraining's binary_logloss: 0.569446\n",
      "[135]\ttraining's binary_logloss: 0.569356\n",
      "[136]\ttraining's binary_logloss: 0.569287\n",
      "[137]\ttraining's binary_logloss: 0.569226\n",
      "[138]\ttraining's binary_logloss: 0.569169\n",
      "[139]\ttraining's binary_logloss: 0.569115\n",
      "[140]\ttraining's binary_logloss: 0.569033\n",
      "[141]\ttraining's binary_logloss: 0.568964\n",
      "[142]\ttraining's binary_logloss: 0.568899\n",
      "[143]\ttraining's binary_logloss: 0.568821\n",
      "[144]\ttraining's binary_logloss: 0.568756\n",
      "[145]\ttraining's binary_logloss: 0.568723\n",
      "[146]\ttraining's binary_logloss: 0.568609\n",
      "[147]\ttraining's binary_logloss: 0.568505\n",
      "[148]\ttraining's binary_logloss: 0.568453\n",
      "[149]\ttraining's binary_logloss: 0.568353\n",
      "[150]\ttraining's binary_logloss: 0.568323\n",
      "[151]\ttraining's binary_logloss: 0.56829\n",
      "[152]\ttraining's binary_logloss: 0.568252\n",
      "[153]\ttraining's binary_logloss: 0.568195\n",
      "[154]\ttraining's binary_logloss: 0.568129\n",
      "[155]\ttraining's binary_logloss: 0.568112\n",
      "[156]\ttraining's binary_logloss: 0.568008\n",
      "[157]\ttraining's binary_logloss: 0.567916\n",
      "[158]\ttraining's binary_logloss: 0.567841\n",
      "[159]\ttraining's binary_logloss: 0.567739\n",
      "[160]\ttraining's binary_logloss: 0.567692\n",
      "[161]\ttraining's binary_logloss: 0.567613\n",
      "[162]\ttraining's binary_logloss: 0.567543\n",
      "[163]\ttraining's binary_logloss: 0.567456\n",
      "[164]\ttraining's binary_logloss: 0.567376\n",
      "[165]\ttraining's binary_logloss: 0.567314\n",
      "[166]\ttraining's binary_logloss: 0.567244\n",
      "[167]\ttraining's binary_logloss: 0.567138\n",
      "[168]\ttraining's binary_logloss: 0.567086\n",
      "[169]\ttraining's binary_logloss: 0.567025\n",
      "[170]\ttraining's binary_logloss: 0.566945\n",
      "[171]\ttraining's binary_logloss: 0.566868\n",
      "[172]\ttraining's binary_logloss: 0.566787\n",
      "[173]\ttraining's binary_logloss: 0.56672\n",
      "[174]\ttraining's binary_logloss: 0.566659\n",
      "[175]\ttraining's binary_logloss: 0.566606\n",
      "[176]\ttraining's binary_logloss: 0.56653\n",
      "[177]\ttraining's binary_logloss: 0.566449\n",
      "[178]\ttraining's binary_logloss: 0.5664\n",
      "[179]\ttraining's binary_logloss: 0.566341\n",
      "[180]\ttraining's binary_logloss: 0.566281\n",
      "[181]\ttraining's binary_logloss: 0.566217\n",
      "[182]\ttraining's binary_logloss: 0.566164\n",
      "[183]\ttraining's binary_logloss: 0.566107\n",
      "[184]\ttraining's binary_logloss: 0.566036\n",
      "[185]\ttraining's binary_logloss: 0.565964\n",
      "[186]\ttraining's binary_logloss: 0.565943\n",
      "[187]\ttraining's binary_logloss: 0.565912\n",
      "[188]\ttraining's binary_logloss: 0.565868\n",
      "[189]\ttraining's binary_logloss: 0.565843\n",
      "[190]\ttraining's binary_logloss: 0.565817\n",
      "[191]\ttraining's binary_logloss: 0.565768\n",
      "[192]\ttraining's binary_logloss: 0.565728\n",
      "[193]\ttraining's binary_logloss: 0.565651\n",
      "[194]\ttraining's binary_logloss: 0.565583\n",
      "[195]\ttraining's binary_logloss: 0.5655\n",
      "[196]\ttraining's binary_logloss: 0.565402\n",
      "[197]\ttraining's binary_logloss: 0.565298\n",
      "[198]\ttraining's binary_logloss: 0.565203\n",
      "[199]\ttraining's binary_logloss: 0.5651\n",
      "[200]\ttraining's binary_logloss: 0.565009\n",
      "[201]\ttraining's binary_logloss: 0.564909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[202]\ttraining's binary_logloss: 0.564804\n",
      "[203]\ttraining's binary_logloss: 0.564707\n",
      "[204]\ttraining's binary_logloss: 0.564576\n",
      "[205]\ttraining's binary_logloss: 0.564489\n",
      "[206]\ttraining's binary_logloss: 0.564406\n",
      "[207]\ttraining's binary_logloss: 0.564319\n",
      "[208]\ttraining's binary_logloss: 0.564258\n",
      "[209]\ttraining's binary_logloss: 0.564189\n",
      "[210]\ttraining's binary_logloss: 0.564103\n",
      "[211]\ttraining's binary_logloss: 0.563998\n",
      "[212]\ttraining's binary_logloss: 0.563888\n",
      "[213]\ttraining's binary_logloss: 0.563787\n",
      "[214]\ttraining's binary_logloss: 0.56369\n",
      "[215]\ttraining's binary_logloss: 0.563593\n",
      "[216]\ttraining's binary_logloss: 0.563466\n",
      "[217]\ttraining's binary_logloss: 0.563325\n",
      "[218]\ttraining's binary_logloss: 0.563199\n",
      "[219]\ttraining's binary_logloss: 0.563094\n",
      "[220]\ttraining's binary_logloss: 0.563007\n",
      "[221]\ttraining's binary_logloss: 0.562882\n",
      "[222]\ttraining's binary_logloss: 0.562814\n",
      "[223]\ttraining's binary_logloss: 0.562739\n",
      "[224]\ttraining's binary_logloss: 0.562627\n",
      "[225]\ttraining's binary_logloss: 0.562568\n",
      "[226]\ttraining's binary_logloss: 0.562461\n",
      "[227]\ttraining's binary_logloss: 0.562381\n",
      "[228]\ttraining's binary_logloss: 0.562295\n",
      "[229]\ttraining's binary_logloss: 0.562222\n",
      "[230]\ttraining's binary_logloss: 0.562144\n",
      "[231]\ttraining's binary_logloss: 0.562029\n",
      "[232]\ttraining's binary_logloss: 0.561901\n",
      "[233]\ttraining's binary_logloss: 0.561776\n",
      "[234]\ttraining's binary_logloss: 0.561635\n",
      "[235]\ttraining's binary_logloss: 0.56157\n",
      "[236]\ttraining's binary_logloss: 0.561485\n",
      "[237]\ttraining's binary_logloss: 0.561393\n",
      "[238]\ttraining's binary_logloss: 0.56132\n",
      "[239]\ttraining's binary_logloss: 0.561242\n",
      "[240]\ttraining's binary_logloss: 0.561165\n",
      "[241]\ttraining's binary_logloss: 0.561081\n",
      "[242]\ttraining's binary_logloss: 0.560995\n",
      "[243]\ttraining's binary_logloss: 0.560881\n",
      "[244]\ttraining's binary_logloss: 0.560803\n",
      "[245]\ttraining's binary_logloss: 0.560716\n",
      "[246]\ttraining's binary_logloss: 0.560596\n",
      "[247]\ttraining's binary_logloss: 0.560487\n",
      "[248]\ttraining's binary_logloss: 0.560363\n",
      "[249]\ttraining's binary_logloss: 0.560255\n",
      "[250]\ttraining's binary_logloss: 0.560143\n",
      "[251]\ttraining's binary_logloss: 0.560065\n",
      "[252]\ttraining's binary_logloss: 0.559956\n",
      "[253]\ttraining's binary_logloss: 0.559847\n",
      "[254]\ttraining's binary_logloss: 0.559757\n",
      "[255]\ttraining's binary_logloss: 0.559664\n",
      "[256]\ttraining's binary_logloss: 0.559549\n",
      "[257]\ttraining's binary_logloss: 0.559438\n",
      "[258]\ttraining's binary_logloss: 0.55933\n",
      "[259]\ttraining's binary_logloss: 0.55922\n",
      "[260]\ttraining's binary_logloss: 0.559148\n",
      "[261]\ttraining's binary_logloss: 0.559009\n",
      "[262]\ttraining's binary_logloss: 0.558863\n",
      "[263]\ttraining's binary_logloss: 0.55872\n",
      "[264]\ttraining's binary_logloss: 0.558581\n",
      "[265]\ttraining's binary_logloss: 0.558467\n",
      "[266]\ttraining's binary_logloss: 0.558433\n",
      "[267]\ttraining's binary_logloss: 0.558354\n",
      "[268]\ttraining's binary_logloss: 0.558282\n",
      "[269]\ttraining's binary_logloss: 0.558219\n",
      "[270]\ttraining's binary_logloss: 0.558136\n",
      "[271]\ttraining's binary_logloss: 0.558023\n",
      "[272]\ttraining's binary_logloss: 0.557929\n",
      "[273]\ttraining's binary_logloss: 0.557815\n",
      "[274]\ttraining's binary_logloss: 0.557723\n",
      "[275]\ttraining's binary_logloss: 0.557594\n",
      "[276]\ttraining's binary_logloss: 0.55748\n",
      "[277]\ttraining's binary_logloss: 0.557357\n",
      "[278]\ttraining's binary_logloss: 0.557241\n",
      "[279]\ttraining's binary_logloss: 0.557127\n",
      "[280]\ttraining's binary_logloss: 0.557063\n",
      "[281]\ttraining's binary_logloss: 0.556964\n",
      "[282]\ttraining's binary_logloss: 0.55685\n",
      "[283]\ttraining's binary_logloss: 0.556774\n",
      "[284]\ttraining's binary_logloss: 0.556689\n",
      "[285]\ttraining's binary_logloss: 0.556572\n",
      "[286]\ttraining's binary_logloss: 0.556399\n",
      "[287]\ttraining's binary_logloss: 0.556273\n",
      "[288]\ttraining's binary_logloss: 0.556136\n",
      "[289]\ttraining's binary_logloss: 0.555968\n",
      "[290]\ttraining's binary_logloss: 0.555798\n",
      "[291]\ttraining's binary_logloss: 0.555717\n",
      "[292]\ttraining's binary_logloss: 0.555609\n",
      "[293]\ttraining's binary_logloss: 0.55551\n",
      "[294]\ttraining's binary_logloss: 0.555411\n",
      "[295]\ttraining's binary_logloss: 0.555301\n",
      "[296]\ttraining's binary_logloss: 0.555148\n",
      "[297]\ttraining's binary_logloss: 0.55499\n",
      "[298]\ttraining's binary_logloss: 0.554871\n",
      "[299]\ttraining's binary_logloss: 0.554727\n",
      "[300]\ttraining's binary_logloss: 0.554565\n",
      "[301]\ttraining's binary_logloss: 0.554402\n",
      "[302]\ttraining's binary_logloss: 0.554254\n",
      "[303]\ttraining's binary_logloss: 0.554102\n",
      "[304]\ttraining's binary_logloss: 0.553977\n",
      "[305]\ttraining's binary_logloss: 0.553852\n",
      "[306]\ttraining's binary_logloss: 0.553699\n",
      "[307]\ttraining's binary_logloss: 0.553552\n",
      "[308]\ttraining's binary_logloss: 0.553394\n",
      "[309]\ttraining's binary_logloss: 0.553235\n",
      "[310]\ttraining's binary_logloss: 0.553074\n",
      "[311]\ttraining's binary_logloss: 0.552951\n",
      "[312]\ttraining's binary_logloss: 0.552833\n",
      "[313]\ttraining's binary_logloss: 0.552715\n",
      "[314]\ttraining's binary_logloss: 0.552616\n",
      "[315]\ttraining's binary_logloss: 0.552501\n",
      "[316]\ttraining's binary_logloss: 0.552368\n",
      "[317]\ttraining's binary_logloss: 0.552244\n",
      "[318]\ttraining's binary_logloss: 0.552143\n",
      "[319]\ttraining's binary_logloss: 0.552049\n",
      "[320]\ttraining's binary_logloss: 0.551907\n",
      "[321]\ttraining's binary_logloss: 0.551825\n",
      "[322]\ttraining's binary_logloss: 0.551708\n",
      "[323]\ttraining's binary_logloss: 0.551596\n",
      "[324]\ttraining's binary_logloss: 0.551484\n",
      "[325]\ttraining's binary_logloss: 0.551398\n",
      "[326]\ttraining's binary_logloss: 0.551316\n",
      "[327]\ttraining's binary_logloss: 0.551216\n",
      "[328]\ttraining's binary_logloss: 0.551119\n",
      "[329]\ttraining's binary_logloss: 0.55103\n",
      "[330]\ttraining's binary_logloss: 0.550907\n",
      "[331]\ttraining's binary_logloss: 0.550751\n",
      "[332]\ttraining's binary_logloss: 0.550617\n",
      "[333]\ttraining's binary_logloss: 0.55046\n",
      "[334]\ttraining's binary_logloss: 0.550296\n",
      "[335]\ttraining's binary_logloss: 0.550159\n",
      "[336]\ttraining's binary_logloss: 0.549994\n",
      "[337]\ttraining's binary_logloss: 0.549852\n",
      "[338]\ttraining's binary_logloss: 0.549731\n",
      "[339]\ttraining's binary_logloss: 0.549586\n",
      "[340]\ttraining's binary_logloss: 0.549426\n",
      "[341]\ttraining's binary_logloss: 0.549261\n",
      "[342]\ttraining's binary_logloss: 0.549095\n",
      "[343]\ttraining's binary_logloss: 0.548934\n",
      "[344]\ttraining's binary_logloss: 0.548758\n",
      "[345]\ttraining's binary_logloss: 0.548616\n",
      "[346]\ttraining's binary_logloss: 0.548527\n",
      "[347]\ttraining's binary_logloss: 0.548413\n",
      "[348]\ttraining's binary_logloss: 0.548312\n",
      "[349]\ttraining's binary_logloss: 0.548218\n",
      "[350]\ttraining's binary_logloss: 0.548143\n",
      "[351]\ttraining's binary_logloss: 0.548004\n",
      "[352]\ttraining's binary_logloss: 0.547869\n",
      "[353]\ttraining's binary_logloss: 0.547742\n",
      "[354]\ttraining's binary_logloss: 0.547612\n",
      "[355]\ttraining's binary_logloss: 0.547463\n",
      "[356]\ttraining's binary_logloss: 0.547343\n",
      "[357]\ttraining's binary_logloss: 0.547228\n",
      "[358]\ttraining's binary_logloss: 0.547107\n",
      "[359]\ttraining's binary_logloss: 0.546987\n",
      "[360]\ttraining's binary_logloss: 0.546859\n",
      "[361]\ttraining's binary_logloss: 0.54673\n",
      "[362]\ttraining's binary_logloss: 0.546605\n",
      "[363]\ttraining's binary_logloss: 0.546484\n",
      "[364]\ttraining's binary_logloss: 0.546345\n",
      "[365]\ttraining's binary_logloss: 0.546239\n",
      "[366]\ttraining's binary_logloss: 0.546132\n",
      "[367]\ttraining's binary_logloss: 0.54603\n",
      "[368]\ttraining's binary_logloss: 0.545951\n",
      "[369]\ttraining's binary_logloss: 0.545842\n",
      "[370]\ttraining's binary_logloss: 0.545711\n",
      "[371]\ttraining's binary_logloss: 0.545578\n",
      "[372]\ttraining's binary_logloss: 0.545446\n",
      "[373]\ttraining's binary_logloss: 0.545314\n",
      "[374]\ttraining's binary_logloss: 0.545206\n",
      "[375]\ttraining's binary_logloss: 0.545055\n",
      "[376]\ttraining's binary_logloss: 0.544867\n",
      "[377]\ttraining's binary_logloss: 0.544699\n",
      "[378]\ttraining's binary_logloss: 0.544514\n",
      "[379]\ttraining's binary_logloss: 0.54435\n",
      "[380]\ttraining's binary_logloss: 0.544198\n",
      "[381]\ttraining's binary_logloss: 0.544068\n",
      "[382]\ttraining's binary_logloss: 0.54393\n",
      "[383]\ttraining's binary_logloss: 0.543808\n",
      "[384]\ttraining's binary_logloss: 0.543675\n",
      "[385]\ttraining's binary_logloss: 0.54357\n",
      "[386]\ttraining's binary_logloss: 0.543468\n",
      "[387]\ttraining's binary_logloss: 0.543355\n",
      "[388]\ttraining's binary_logloss: 0.543234\n",
      "[389]\ttraining's binary_logloss: 0.543098\n",
      "[390]\ttraining's binary_logloss: 0.542974\n",
      "[391]\ttraining's binary_logloss: 0.542799\n",
      "[392]\ttraining's binary_logloss: 0.542611\n",
      "[393]\ttraining's binary_logloss: 0.542427\n",
      "[394]\ttraining's binary_logloss: 0.542265\n",
      "[395]\ttraining's binary_logloss: 0.542085\n",
      "[396]\ttraining's binary_logloss: 0.541922\n",
      "[397]\ttraining's binary_logloss: 0.541741\n",
      "[398]\ttraining's binary_logloss: 0.541567\n",
      "[399]\ttraining's binary_logloss: 0.541393\n",
      "[400]\ttraining's binary_logloss: 0.54123\n",
      "[401]\ttraining's binary_logloss: 0.541084\n",
      "[402]\ttraining's binary_logloss: 0.540943\n",
      "[403]\ttraining's binary_logloss: 0.540807\n",
      "[404]\ttraining's binary_logloss: 0.540677\n",
      "[405]\ttraining's binary_logloss: 0.54055\n",
      "[406]\ttraining's binary_logloss: 0.540439\n",
      "[407]\ttraining's binary_logloss: 0.540328\n",
      "[408]\ttraining's binary_logloss: 0.540218\n",
      "[409]\ttraining's binary_logloss: 0.540105\n",
      "[410]\ttraining's binary_logloss: 0.539996\n",
      "[411]\ttraining's binary_logloss: 0.53986\n",
      "[412]\ttraining's binary_logloss: 0.539727\n",
      "[413]\ttraining's binary_logloss: 0.539608\n",
      "[414]\ttraining's binary_logloss: 0.539502\n",
      "[415]\ttraining's binary_logloss: 0.539372\n",
      "[416]\ttraining's binary_logloss: 0.539244\n",
      "[417]\ttraining's binary_logloss: 0.539114\n",
      "[418]\ttraining's binary_logloss: 0.538999\n",
      "[419]\ttraining's binary_logloss: 0.53886\n",
      "[420]\ttraining's binary_logloss: 0.538735\n",
      "[421]\ttraining's binary_logloss: 0.538648\n",
      "[422]\ttraining's binary_logloss: 0.538576\n",
      "[423]\ttraining's binary_logloss: 0.538502\n",
      "[424]\ttraining's binary_logloss: 0.538431\n",
      "[425]\ttraining's binary_logloss: 0.538335\n",
      "[426]\ttraining's binary_logloss: 0.538141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[427]\ttraining's binary_logloss: 0.537972\n",
      "[428]\ttraining's binary_logloss: 0.537799\n",
      "[429]\ttraining's binary_logloss: 0.537617\n",
      "[430]\ttraining's binary_logloss: 0.537443\n",
      "[431]\ttraining's binary_logloss: 0.537329\n",
      "[432]\ttraining's binary_logloss: 0.537209\n",
      "[433]\ttraining's binary_logloss: 0.537104\n",
      "[434]\ttraining's binary_logloss: 0.537005\n",
      "[435]\ttraining's binary_logloss: 0.536905\n",
      "[436]\ttraining's binary_logloss: 0.536753\n",
      "[437]\ttraining's binary_logloss: 0.536596\n",
      "[438]\ttraining's binary_logloss: 0.536485\n",
      "[439]\ttraining's binary_logloss: 0.536334\n",
      "[440]\ttraining's binary_logloss: 0.536185\n",
      "[441]\ttraining's binary_logloss: 0.536032\n",
      "[442]\ttraining's binary_logloss: 0.535898\n",
      "[443]\ttraining's binary_logloss: 0.53575\n",
      "[444]\ttraining's binary_logloss: 0.535613\n",
      "[445]\ttraining's binary_logloss: 0.535485\n",
      "[446]\ttraining's binary_logloss: 0.535369\n",
      "[447]\ttraining's binary_logloss: 0.535262\n",
      "[448]\ttraining's binary_logloss: 0.535157\n",
      "[449]\ttraining's binary_logloss: 0.535052\n",
      "[450]\ttraining's binary_logloss: 0.534938\n",
      "[451]\ttraining's binary_logloss: 0.534864\n",
      "[452]\ttraining's binary_logloss: 0.534784\n",
      "[453]\ttraining's binary_logloss: 0.534707\n",
      "[454]\ttraining's binary_logloss: 0.534621\n",
      "[455]\ttraining's binary_logloss: 0.534534\n",
      "[456]\ttraining's binary_logloss: 0.534383\n",
      "[457]\ttraining's binary_logloss: 0.534253\n",
      "[458]\ttraining's binary_logloss: 0.534133\n",
      "[459]\ttraining's binary_logloss: 0.533993\n",
      "[460]\ttraining's binary_logloss: 0.533887\n",
      "[461]\ttraining's binary_logloss: 0.533752\n",
      "[462]\ttraining's binary_logloss: 0.533605\n",
      "[463]\ttraining's binary_logloss: 0.533465\n",
      "[464]\ttraining's binary_logloss: 0.533341\n",
      "[465]\ttraining's binary_logloss: 0.533201\n",
      "[466]\ttraining's binary_logloss: 0.533051\n",
      "[467]\ttraining's binary_logloss: 0.532874\n",
      "[468]\ttraining's binary_logloss: 0.532714\n",
      "[469]\ttraining's binary_logloss: 0.532592\n",
      "[470]\ttraining's binary_logloss: 0.532447\n",
      "[471]\ttraining's binary_logloss: 0.532279\n",
      "[472]\ttraining's binary_logloss: 0.532134\n",
      "[473]\ttraining's binary_logloss: 0.531973\n",
      "[474]\ttraining's binary_logloss: 0.531849\n",
      "[475]\ttraining's binary_logloss: 0.53171\n",
      "[476]\ttraining's binary_logloss: 0.531588\n",
      "[477]\ttraining's binary_logloss: 0.531466\n",
      "[478]\ttraining's binary_logloss: 0.531351\n",
      "[479]\ttraining's binary_logloss: 0.531227\n",
      "[480]\ttraining's binary_logloss: 0.531114\n",
      "[481]\ttraining's binary_logloss: 0.531007\n",
      "[482]\ttraining's binary_logloss: 0.530898\n",
      "[483]\ttraining's binary_logloss: 0.530789\n",
      "[484]\ttraining's binary_logloss: 0.530683\n",
      "[485]\ttraining's binary_logloss: 0.530575\n",
      "[486]\ttraining's binary_logloss: 0.530458\n",
      "[487]\ttraining's binary_logloss: 0.53033\n",
      "[488]\ttraining's binary_logloss: 0.530222\n",
      "[489]\ttraining's binary_logloss: 0.530075\n",
      "[490]\ttraining's binary_logloss: 0.529957\n",
      "[491]\ttraining's binary_logloss: 0.529833\n",
      "[492]\ttraining's binary_logloss: 0.529709\n",
      "[493]\ttraining's binary_logloss: 0.529596\n",
      "[494]\ttraining's binary_logloss: 0.529479\n",
      "[495]\ttraining's binary_logloss: 0.529337\n",
      "[496]\ttraining's binary_logloss: 0.529171\n",
      "[497]\ttraining's binary_logloss: 0.529011\n",
      "[498]\ttraining's binary_logloss: 0.528831\n",
      "[499]\ttraining's binary_logloss: 0.528634\n",
      "[500]\ttraining's binary_logloss: 0.528478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614111\n",
      "[2]\ttraining's binary_logloss: 0.61272\n",
      "[3]\ttraining's binary_logloss: 0.611351\n",
      "[4]\ttraining's binary_logloss: 0.610022\n",
      "[5]\ttraining's binary_logloss: 0.608785\n",
      "[6]\ttraining's binary_logloss: 0.607465\n",
      "[7]\ttraining's binary_logloss: 0.606241\n",
      "[8]\ttraining's binary_logloss: 0.605004\n",
      "[9]\ttraining's binary_logloss: 0.603787\n",
      "[10]\ttraining's binary_logloss: 0.602615\n",
      "[11]\ttraining's binary_logloss: 0.601485\n",
      "[12]\ttraining's binary_logloss: 0.600372\n",
      "[13]\ttraining's binary_logloss: 0.599362\n",
      "[14]\ttraining's binary_logloss: 0.598339\n",
      "[15]\ttraining's binary_logloss: 0.597343\n",
      "[16]\ttraining's binary_logloss: 0.596342\n",
      "[17]\ttraining's binary_logloss: 0.595388\n",
      "[18]\ttraining's binary_logloss: 0.59447\n",
      "[19]\ttraining's binary_logloss: 0.593541\n",
      "[20]\ttraining's binary_logloss: 0.592685\n",
      "[21]\ttraining's binary_logloss: 0.591812\n",
      "[22]\ttraining's binary_logloss: 0.59098\n",
      "[23]\ttraining's binary_logloss: 0.590166\n",
      "[24]\ttraining's binary_logloss: 0.589408\n",
      "[25]\ttraining's binary_logloss: 0.588674\n",
      "[26]\ttraining's binary_logloss: 0.587931\n",
      "[27]\ttraining's binary_logloss: 0.58723\n",
      "[28]\ttraining's binary_logloss: 0.586564\n",
      "[29]\ttraining's binary_logloss: 0.585902\n",
      "[30]\ttraining's binary_logloss: 0.58524\n",
      "[31]\ttraining's binary_logloss: 0.584517\n",
      "[32]\ttraining's binary_logloss: 0.583915\n",
      "[33]\ttraining's binary_logloss: 0.583346\n",
      "[34]\ttraining's binary_logloss: 0.582766\n",
      "[35]\ttraining's binary_logloss: 0.582164\n",
      "[36]\ttraining's binary_logloss: 0.581639\n",
      "[37]\ttraining's binary_logloss: 0.58116\n",
      "[38]\ttraining's binary_logloss: 0.580651\n",
      "[39]\ttraining's binary_logloss: 0.580202\n",
      "[40]\ttraining's binary_logloss: 0.57973\n",
      "[41]\ttraining's binary_logloss: 0.579166\n",
      "[42]\ttraining's binary_logloss: 0.578656\n",
      "[43]\ttraining's binary_logloss: 0.578148\n",
      "[44]\ttraining's binary_logloss: 0.577621\n",
      "[45]\ttraining's binary_logloss: 0.577144\n",
      "[46]\ttraining's binary_logloss: 0.576698\n",
      "[47]\ttraining's binary_logloss: 0.576205\n",
      "[48]\ttraining's binary_logloss: 0.575723\n",
      "[49]\ttraining's binary_logloss: 0.575249\n",
      "[50]\ttraining's binary_logloss: 0.574836\n",
      "[51]\ttraining's binary_logloss: 0.574465\n",
      "[52]\ttraining's binary_logloss: 0.574093\n",
      "[53]\ttraining's binary_logloss: 0.573717\n",
      "[54]\ttraining's binary_logloss: 0.573351\n",
      "[55]\ttraining's binary_logloss: 0.573031\n",
      "[56]\ttraining's binary_logloss: 0.572689\n",
      "[57]\ttraining's binary_logloss: 0.572364\n",
      "[58]\ttraining's binary_logloss: 0.571985\n",
      "[59]\ttraining's binary_logloss: 0.571689\n",
      "[60]\ttraining's binary_logloss: 0.571377\n",
      "[61]\ttraining's binary_logloss: 0.571038\n",
      "[62]\ttraining's binary_logloss: 0.570722\n",
      "[63]\ttraining's binary_logloss: 0.57044\n",
      "[64]\ttraining's binary_logloss: 0.570144\n",
      "[65]\ttraining's binary_logloss: 0.569883\n",
      "[66]\ttraining's binary_logloss: 0.569589\n",
      "[67]\ttraining's binary_logloss: 0.569315\n",
      "[68]\ttraining's binary_logloss: 0.569032\n",
      "[69]\ttraining's binary_logloss: 0.568764\n",
      "[70]\ttraining's binary_logloss: 0.568527\n",
      "[71]\ttraining's binary_logloss: 0.56832\n",
      "[72]\ttraining's binary_logloss: 0.568102\n",
      "[73]\ttraining's binary_logloss: 0.567912\n",
      "[74]\ttraining's binary_logloss: 0.567729\n",
      "[75]\ttraining's binary_logloss: 0.567536\n",
      "[76]\ttraining's binary_logloss: 0.567313\n",
      "[77]\ttraining's binary_logloss: 0.567104\n",
      "[78]\ttraining's binary_logloss: 0.566882\n",
      "[79]\ttraining's binary_logloss: 0.566647\n",
      "[80]\ttraining's binary_logloss: 0.566446\n",
      "[81]\ttraining's binary_logloss: 0.566199\n",
      "[82]\ttraining's binary_logloss: 0.565982\n",
      "[83]\ttraining's binary_logloss: 0.565754\n",
      "[84]\ttraining's binary_logloss: 0.565525\n",
      "[85]\ttraining's binary_logloss: 0.565315\n",
      "[86]\ttraining's binary_logloss: 0.565149\n",
      "[87]\ttraining's binary_logloss: 0.564917\n",
      "[88]\ttraining's binary_logloss: 0.564721\n",
      "[89]\ttraining's binary_logloss: 0.564582\n",
      "[90]\ttraining's binary_logloss: 0.564399\n",
      "[91]\ttraining's binary_logloss: 0.564221\n",
      "[92]\ttraining's binary_logloss: 0.564036\n",
      "[93]\ttraining's binary_logloss: 0.563876\n",
      "[94]\ttraining's binary_logloss: 0.563723\n",
      "[95]\ttraining's binary_logloss: 0.563579\n",
      "[96]\ttraining's binary_logloss: 0.563398\n",
      "[97]\ttraining's binary_logloss: 0.563204\n",
      "[98]\ttraining's binary_logloss: 0.562967\n",
      "[99]\ttraining's binary_logloss: 0.562806\n",
      "[100]\ttraining's binary_logloss: 0.562644\n",
      "[101]\ttraining's binary_logloss: 0.562476\n",
      "[102]\ttraining's binary_logloss: 0.562292\n",
      "[103]\ttraining's binary_logloss: 0.562121\n",
      "[104]\ttraining's binary_logloss: 0.561962\n",
      "[105]\ttraining's binary_logloss: 0.561802\n",
      "[106]\ttraining's binary_logloss: 0.56163\n",
      "[107]\ttraining's binary_logloss: 0.561473\n",
      "[108]\ttraining's binary_logloss: 0.561275\n",
      "[109]\ttraining's binary_logloss: 0.561092\n",
      "[110]\ttraining's binary_logloss: 0.560905\n",
      "[111]\ttraining's binary_logloss: 0.560757\n",
      "[112]\ttraining's binary_logloss: 0.560599\n",
      "[113]\ttraining's binary_logloss: 0.560452\n",
      "[114]\ttraining's binary_logloss: 0.56028\n",
      "[115]\ttraining's binary_logloss: 0.56013\n",
      "[116]\ttraining's binary_logloss: 0.559982\n",
      "[117]\ttraining's binary_logloss: 0.559847\n",
      "[118]\ttraining's binary_logloss: 0.559714\n",
      "[119]\ttraining's binary_logloss: 0.559587\n",
      "[120]\ttraining's binary_logloss: 0.559454\n",
      "[121]\ttraining's binary_logloss: 0.559312\n",
      "[122]\ttraining's binary_logloss: 0.559195\n",
      "[123]\ttraining's binary_logloss: 0.559072\n",
      "[124]\ttraining's binary_logloss: 0.558961\n",
      "[125]\ttraining's binary_logloss: 0.558869\n",
      "[126]\ttraining's binary_logloss: 0.558741\n",
      "[127]\ttraining's binary_logloss: 0.558571\n",
      "[128]\ttraining's binary_logloss: 0.558399\n",
      "[129]\ttraining's binary_logloss: 0.558229\n",
      "[130]\ttraining's binary_logloss: 0.558071\n",
      "[131]\ttraining's binary_logloss: 0.557928\n",
      "[132]\ttraining's binary_logloss: 0.557784\n",
      "[133]\ttraining's binary_logloss: 0.557613\n",
      "[134]\ttraining's binary_logloss: 0.557444\n",
      "[135]\ttraining's binary_logloss: 0.557299\n",
      "[136]\ttraining's binary_logloss: 0.557164\n",
      "[137]\ttraining's binary_logloss: 0.556998\n",
      "[138]\ttraining's binary_logloss: 0.556842\n",
      "[139]\ttraining's binary_logloss: 0.556696\n",
      "[140]\ttraining's binary_logloss: 0.556564\n",
      "[141]\ttraining's binary_logloss: 0.556408\n",
      "[142]\ttraining's binary_logloss: 0.556257\n",
      "[143]\ttraining's binary_logloss: 0.556109\n",
      "[144]\ttraining's binary_logloss: 0.55594\n",
      "[145]\ttraining's binary_logloss: 0.555799\n",
      "[146]\ttraining's binary_logloss: 0.555644\n",
      "[147]\ttraining's binary_logloss: 0.555503\n",
      "[148]\ttraining's binary_logloss: 0.555355\n",
      "[149]\ttraining's binary_logloss: 0.555217\n",
      "[150]\ttraining's binary_logloss: 0.555083\n",
      "[151]\ttraining's binary_logloss: 0.554912\n",
      "[152]\ttraining's binary_logloss: 0.554744\n",
      "[153]\ttraining's binary_logloss: 0.554578\n",
      "[154]\ttraining's binary_logloss: 0.554371\n",
      "[155]\ttraining's binary_logloss: 0.554203\n",
      "[156]\ttraining's binary_logloss: 0.55411\n",
      "[157]\ttraining's binary_logloss: 0.553977\n",
      "[158]\ttraining's binary_logloss: 0.553901\n",
      "[159]\ttraining's binary_logloss: 0.553831\n",
      "[160]\ttraining's binary_logloss: 0.553714\n",
      "[161]\ttraining's binary_logloss: 0.55353\n",
      "[162]\ttraining's binary_logloss: 0.553371\n",
      "[163]\ttraining's binary_logloss: 0.553183\n",
      "[164]\ttraining's binary_logloss: 0.553014\n",
      "[165]\ttraining's binary_logloss: 0.552858\n",
      "[166]\ttraining's binary_logloss: 0.552696\n",
      "[167]\ttraining's binary_logloss: 0.552516\n",
      "[168]\ttraining's binary_logloss: 0.552346\n",
      "[169]\ttraining's binary_logloss: 0.552206\n",
      "[170]\ttraining's binary_logloss: 0.552035\n",
      "[171]\ttraining's binary_logloss: 0.551915\n",
      "[172]\ttraining's binary_logloss: 0.551746\n",
      "[173]\ttraining's binary_logloss: 0.551602\n",
      "[174]\ttraining's binary_logloss: 0.551497\n",
      "[175]\ttraining's binary_logloss: 0.551356\n",
      "[176]\ttraining's binary_logloss: 0.551245\n",
      "[177]\ttraining's binary_logloss: 0.551087\n",
      "[178]\ttraining's binary_logloss: 0.550959\n",
      "[179]\ttraining's binary_logloss: 0.550851\n",
      "[180]\ttraining's binary_logloss: 0.550738\n",
      "[181]\ttraining's binary_logloss: 0.550629\n",
      "[182]\ttraining's binary_logloss: 0.550496\n",
      "[183]\ttraining's binary_logloss: 0.550367\n",
      "[184]\ttraining's binary_logloss: 0.550201\n",
      "[185]\ttraining's binary_logloss: 0.550075\n",
      "[186]\ttraining's binary_logloss: 0.549936\n",
      "[187]\ttraining's binary_logloss: 0.549805\n",
      "[188]\ttraining's binary_logloss: 0.549665\n",
      "[189]\ttraining's binary_logloss: 0.549543\n",
      "[190]\ttraining's binary_logloss: 0.549425\n",
      "[191]\ttraining's binary_logloss: 0.549276\n",
      "[192]\ttraining's binary_logloss: 0.549124\n",
      "[193]\ttraining's binary_logloss: 0.548997\n",
      "[194]\ttraining's binary_logloss: 0.548847\n",
      "[195]\ttraining's binary_logloss: 0.548692\n",
      "[196]\ttraining's binary_logloss: 0.548527\n",
      "[197]\ttraining's binary_logloss: 0.548354\n",
      "[198]\ttraining's binary_logloss: 0.548196\n",
      "[199]\ttraining's binary_logloss: 0.54805\n",
      "[200]\ttraining's binary_logloss: 0.547924\n",
      "[201]\ttraining's binary_logloss: 0.547785\n",
      "[202]\ttraining's binary_logloss: 0.547645\n",
      "[203]\ttraining's binary_logloss: 0.547492\n",
      "[204]\ttraining's binary_logloss: 0.547348\n",
      "[205]\ttraining's binary_logloss: 0.547237\n",
      "[206]\ttraining's binary_logloss: 0.547113\n",
      "[207]\ttraining's binary_logloss: 0.546951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[208]\ttraining's binary_logloss: 0.546829\n",
      "[209]\ttraining's binary_logloss: 0.546709\n",
      "[210]\ttraining's binary_logloss: 0.546539\n",
      "[211]\ttraining's binary_logloss: 0.546392\n",
      "[212]\ttraining's binary_logloss: 0.546249\n",
      "[213]\ttraining's binary_logloss: 0.54609\n",
      "[214]\ttraining's binary_logloss: 0.545935\n",
      "[215]\ttraining's binary_logloss: 0.545779\n",
      "[216]\ttraining's binary_logloss: 0.545598\n",
      "[217]\ttraining's binary_logloss: 0.545473\n",
      "[218]\ttraining's binary_logloss: 0.545274\n",
      "[219]\ttraining's binary_logloss: 0.545155\n",
      "[220]\ttraining's binary_logloss: 0.545025\n",
      "[221]\ttraining's binary_logloss: 0.544828\n",
      "[222]\ttraining's binary_logloss: 0.544659\n",
      "[223]\ttraining's binary_logloss: 0.544492\n",
      "[224]\ttraining's binary_logloss: 0.544315\n",
      "[225]\ttraining's binary_logloss: 0.54414\n",
      "[226]\ttraining's binary_logloss: 0.543984\n",
      "[227]\ttraining's binary_logloss: 0.543808\n",
      "[228]\ttraining's binary_logloss: 0.543684\n",
      "[229]\ttraining's binary_logloss: 0.543512\n",
      "[230]\ttraining's binary_logloss: 0.543354\n",
      "[231]\ttraining's binary_logloss: 0.54315\n",
      "[232]\ttraining's binary_logloss: 0.542932\n",
      "[233]\ttraining's binary_logloss: 0.542766\n",
      "[234]\ttraining's binary_logloss: 0.542578\n",
      "[235]\ttraining's binary_logloss: 0.542402\n",
      "[236]\ttraining's binary_logloss: 0.542208\n",
      "[237]\ttraining's binary_logloss: 0.542\n",
      "[238]\ttraining's binary_logloss: 0.541799\n",
      "[239]\ttraining's binary_logloss: 0.541613\n",
      "[240]\ttraining's binary_logloss: 0.541419\n",
      "[241]\ttraining's binary_logloss: 0.541225\n",
      "[242]\ttraining's binary_logloss: 0.541047\n",
      "[243]\ttraining's binary_logloss: 0.540862\n",
      "[244]\ttraining's binary_logloss: 0.540688\n",
      "[245]\ttraining's binary_logloss: 0.540518\n",
      "[246]\ttraining's binary_logloss: 0.540419\n",
      "[247]\ttraining's binary_logloss: 0.540329\n",
      "[248]\ttraining's binary_logloss: 0.540205\n",
      "[249]\ttraining's binary_logloss: 0.540062\n",
      "[250]\ttraining's binary_logloss: 0.539955\n",
      "[251]\ttraining's binary_logloss: 0.539763\n",
      "[252]\ttraining's binary_logloss: 0.539572\n",
      "[253]\ttraining's binary_logloss: 0.53939\n",
      "[254]\ttraining's binary_logloss: 0.539203\n",
      "[255]\ttraining's binary_logloss: 0.539056\n",
      "[256]\ttraining's binary_logloss: 0.538915\n",
      "[257]\ttraining's binary_logloss: 0.538788\n",
      "[258]\ttraining's binary_logloss: 0.538628\n",
      "[259]\ttraining's binary_logloss: 0.538495\n",
      "[260]\ttraining's binary_logloss: 0.538359\n",
      "[261]\ttraining's binary_logloss: 0.538174\n",
      "[262]\ttraining's binary_logloss: 0.538013\n",
      "[263]\ttraining's binary_logloss: 0.537847\n",
      "[264]\ttraining's binary_logloss: 0.537668\n",
      "[265]\ttraining's binary_logloss: 0.537474\n",
      "[266]\ttraining's binary_logloss: 0.537315\n",
      "[267]\ttraining's binary_logloss: 0.537179\n",
      "[268]\ttraining's binary_logloss: 0.537005\n",
      "[269]\ttraining's binary_logloss: 0.536847\n",
      "[270]\ttraining's binary_logloss: 0.536695\n",
      "[271]\ttraining's binary_logloss: 0.536483\n",
      "[272]\ttraining's binary_logloss: 0.536305\n",
      "[273]\ttraining's binary_logloss: 0.536144\n",
      "[274]\ttraining's binary_logloss: 0.535973\n",
      "[275]\ttraining's binary_logloss: 0.535806\n",
      "[276]\ttraining's binary_logloss: 0.53562\n",
      "[277]\ttraining's binary_logloss: 0.535441\n",
      "[278]\ttraining's binary_logloss: 0.535257\n",
      "[279]\ttraining's binary_logloss: 0.535083\n",
      "[280]\ttraining's binary_logloss: 0.534883\n",
      "[281]\ttraining's binary_logloss: 0.534684\n",
      "[282]\ttraining's binary_logloss: 0.534553\n",
      "[283]\ttraining's binary_logloss: 0.534411\n",
      "[284]\ttraining's binary_logloss: 0.534207\n",
      "[285]\ttraining's binary_logloss: 0.534081\n",
      "[286]\ttraining's binary_logloss: 0.533879\n",
      "[287]\ttraining's binary_logloss: 0.533679\n",
      "[288]\ttraining's binary_logloss: 0.533518\n",
      "[289]\ttraining's binary_logloss: 0.533338\n",
      "[290]\ttraining's binary_logloss: 0.533147\n",
      "[291]\ttraining's binary_logloss: 0.53294\n",
      "[292]\ttraining's binary_logloss: 0.532732\n",
      "[293]\ttraining's binary_logloss: 0.532513\n",
      "[294]\ttraining's binary_logloss: 0.53232\n",
      "[295]\ttraining's binary_logloss: 0.532127\n",
      "[296]\ttraining's binary_logloss: 0.531948\n",
      "[297]\ttraining's binary_logloss: 0.531777\n",
      "[298]\ttraining's binary_logloss: 0.531625\n",
      "[299]\ttraining's binary_logloss: 0.531433\n",
      "[300]\ttraining's binary_logloss: 0.531272\n",
      "[301]\ttraining's binary_logloss: 0.531079\n",
      "[302]\ttraining's binary_logloss: 0.530894\n",
      "[303]\ttraining's binary_logloss: 0.530711\n",
      "[304]\ttraining's binary_logloss: 0.530513\n",
      "[305]\ttraining's binary_logloss: 0.530338\n",
      "[306]\ttraining's binary_logloss: 0.530173\n",
      "[307]\ttraining's binary_logloss: 0.529977\n",
      "[308]\ttraining's binary_logloss: 0.529806\n",
      "[309]\ttraining's binary_logloss: 0.529635\n",
      "[310]\ttraining's binary_logloss: 0.529478\n",
      "[311]\ttraining's binary_logloss: 0.529304\n",
      "[312]\ttraining's binary_logloss: 0.529134\n",
      "[313]\ttraining's binary_logloss: 0.528977\n",
      "[314]\ttraining's binary_logloss: 0.528851\n",
      "[315]\ttraining's binary_logloss: 0.528699\n",
      "[316]\ttraining's binary_logloss: 0.528489\n",
      "[317]\ttraining's binary_logloss: 0.528275\n",
      "[318]\ttraining's binary_logloss: 0.528108\n",
      "[319]\ttraining's binary_logloss: 0.527921\n",
      "[320]\ttraining's binary_logloss: 0.52771\n",
      "[321]\ttraining's binary_logloss: 0.527494\n",
      "[322]\ttraining's binary_logloss: 0.527312\n",
      "[323]\ttraining's binary_logloss: 0.527114\n",
      "[324]\ttraining's binary_logloss: 0.526926\n",
      "[325]\ttraining's binary_logloss: 0.526735\n",
      "[326]\ttraining's binary_logloss: 0.526502\n",
      "[327]\ttraining's binary_logloss: 0.526294\n",
      "[328]\ttraining's binary_logloss: 0.526085\n",
      "[329]\ttraining's binary_logloss: 0.525875\n",
      "[330]\ttraining's binary_logloss: 0.525676\n",
      "[331]\ttraining's binary_logloss: 0.525443\n",
      "[332]\ttraining's binary_logloss: 0.525245\n",
      "[333]\ttraining's binary_logloss: 0.525043\n",
      "[334]\ttraining's binary_logloss: 0.524848\n",
      "[335]\ttraining's binary_logloss: 0.524654\n",
      "[336]\ttraining's binary_logloss: 0.524497\n",
      "[337]\ttraining's binary_logloss: 0.524347\n",
      "[338]\ttraining's binary_logloss: 0.524194\n",
      "[339]\ttraining's binary_logloss: 0.524066\n",
      "[340]\ttraining's binary_logloss: 0.523916\n",
      "[341]\ttraining's binary_logloss: 0.523781\n",
      "[342]\ttraining's binary_logloss: 0.52361\n",
      "[343]\ttraining's binary_logloss: 0.523425\n",
      "[344]\ttraining's binary_logloss: 0.52325\n",
      "[345]\ttraining's binary_logloss: 0.523113\n",
      "[346]\ttraining's binary_logloss: 0.522929\n",
      "[347]\ttraining's binary_logloss: 0.522711\n",
      "[348]\ttraining's binary_logloss: 0.522529\n",
      "[349]\ttraining's binary_logloss: 0.522309\n",
      "[350]\ttraining's binary_logloss: 0.522108\n",
      "[351]\ttraining's binary_logloss: 0.521916\n",
      "[352]\ttraining's binary_logloss: 0.521723\n",
      "[353]\ttraining's binary_logloss: 0.521525\n",
      "[354]\ttraining's binary_logloss: 0.521347\n",
      "[355]\ttraining's binary_logloss: 0.521194\n",
      "[356]\ttraining's binary_logloss: 0.520972\n",
      "[357]\ttraining's binary_logloss: 0.520758\n",
      "[358]\ttraining's binary_logloss: 0.520539\n",
      "[359]\ttraining's binary_logloss: 0.520342\n",
      "[360]\ttraining's binary_logloss: 0.520155\n",
      "[361]\ttraining's binary_logloss: 0.519923\n",
      "[362]\ttraining's binary_logloss: 0.519701\n",
      "[363]\ttraining's binary_logloss: 0.519464\n",
      "[364]\ttraining's binary_logloss: 0.519247\n",
      "[365]\ttraining's binary_logloss: 0.519033\n",
      "[366]\ttraining's binary_logloss: 0.518853\n",
      "[367]\ttraining's binary_logloss: 0.518683\n",
      "[368]\ttraining's binary_logloss: 0.518503\n",
      "[369]\ttraining's binary_logloss: 0.518336\n",
      "[370]\ttraining's binary_logloss: 0.518179\n",
      "[371]\ttraining's binary_logloss: 0.517993\n",
      "[372]\ttraining's binary_logloss: 0.517841\n",
      "[373]\ttraining's binary_logloss: 0.517707\n",
      "[374]\ttraining's binary_logloss: 0.517527\n",
      "[375]\ttraining's binary_logloss: 0.517349\n",
      "[376]\ttraining's binary_logloss: 0.517169\n",
      "[377]\ttraining's binary_logloss: 0.516989\n",
      "[378]\ttraining's binary_logloss: 0.516796\n",
      "[379]\ttraining's binary_logloss: 0.516626\n",
      "[380]\ttraining's binary_logloss: 0.516457\n",
      "[381]\ttraining's binary_logloss: 0.516314\n",
      "[382]\ttraining's binary_logloss: 0.516165\n",
      "[383]\ttraining's binary_logloss: 0.51603\n",
      "[384]\ttraining's binary_logloss: 0.515871\n",
      "[385]\ttraining's binary_logloss: 0.515705\n",
      "[386]\ttraining's binary_logloss: 0.515493\n",
      "[387]\ttraining's binary_logloss: 0.515239\n",
      "[388]\ttraining's binary_logloss: 0.515006\n",
      "[389]\ttraining's binary_logloss: 0.514789\n",
      "[390]\ttraining's binary_logloss: 0.514572\n",
      "[391]\ttraining's binary_logloss: 0.514404\n",
      "[392]\ttraining's binary_logloss: 0.514229\n",
      "[393]\ttraining's binary_logloss: 0.51405\n",
      "[394]\ttraining's binary_logloss: 0.513881\n",
      "[395]\ttraining's binary_logloss: 0.513704\n",
      "[396]\ttraining's binary_logloss: 0.513498\n",
      "[397]\ttraining's binary_logloss: 0.513308\n",
      "[398]\ttraining's binary_logloss: 0.513115\n",
      "[399]\ttraining's binary_logloss: 0.512933\n",
      "[400]\ttraining's binary_logloss: 0.512718\n",
      "[401]\ttraining's binary_logloss: 0.512473\n",
      "[402]\ttraining's binary_logloss: 0.512236\n",
      "[403]\ttraining's binary_logloss: 0.51199\n",
      "[404]\ttraining's binary_logloss: 0.51175\n",
      "[405]\ttraining's binary_logloss: 0.511485\n",
      "[406]\ttraining's binary_logloss: 0.511316\n",
      "[407]\ttraining's binary_logloss: 0.511151\n",
      "[408]\ttraining's binary_logloss: 0.51099\n",
      "[409]\ttraining's binary_logloss: 0.510814\n",
      "[410]\ttraining's binary_logloss: 0.510646\n",
      "[411]\ttraining's binary_logloss: 0.510466\n",
      "[412]\ttraining's binary_logloss: 0.510208\n",
      "[413]\ttraining's binary_logloss: 0.509964\n",
      "[414]\ttraining's binary_logloss: 0.509708\n",
      "[415]\ttraining's binary_logloss: 0.509467\n",
      "[416]\ttraining's binary_logloss: 0.509268\n",
      "[417]\ttraining's binary_logloss: 0.509096\n",
      "[418]\ttraining's binary_logloss: 0.508901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[419]\ttraining's binary_logloss: 0.508711\n",
      "[420]\ttraining's binary_logloss: 0.508542\n",
      "[421]\ttraining's binary_logloss: 0.508405\n",
      "[422]\ttraining's binary_logloss: 0.508254\n",
      "[423]\ttraining's binary_logloss: 0.508091\n",
      "[424]\ttraining's binary_logloss: 0.507903\n",
      "[425]\ttraining's binary_logloss: 0.507732\n",
      "[426]\ttraining's binary_logloss: 0.507569\n",
      "[427]\ttraining's binary_logloss: 0.507427\n",
      "[428]\ttraining's binary_logloss: 0.507258\n",
      "[429]\ttraining's binary_logloss: 0.5071\n",
      "[430]\ttraining's binary_logloss: 0.50694\n",
      "[431]\ttraining's binary_logloss: 0.506733\n",
      "[432]\ttraining's binary_logloss: 0.506518\n",
      "[433]\ttraining's binary_logloss: 0.506334\n",
      "[434]\ttraining's binary_logloss: 0.506106\n",
      "[435]\ttraining's binary_logloss: 0.505891\n",
      "[436]\ttraining's binary_logloss: 0.505727\n",
      "[437]\ttraining's binary_logloss: 0.505566\n",
      "[438]\ttraining's binary_logloss: 0.505412\n",
      "[439]\ttraining's binary_logloss: 0.505249\n",
      "[440]\ttraining's binary_logloss: 0.505072\n",
      "[441]\ttraining's binary_logloss: 0.504859\n",
      "[442]\ttraining's binary_logloss: 0.504623\n",
      "[443]\ttraining's binary_logloss: 0.504464\n",
      "[444]\ttraining's binary_logloss: 0.504238\n",
      "[445]\ttraining's binary_logloss: 0.504011\n",
      "[446]\ttraining's binary_logloss: 0.503835\n",
      "[447]\ttraining's binary_logloss: 0.503647\n",
      "[448]\ttraining's binary_logloss: 0.503483\n",
      "[449]\ttraining's binary_logloss: 0.503306\n",
      "[450]\ttraining's binary_logloss: 0.503163\n",
      "[451]\ttraining's binary_logloss: 0.502957\n",
      "[452]\ttraining's binary_logloss: 0.502761\n",
      "[453]\ttraining's binary_logloss: 0.50258\n",
      "[454]\ttraining's binary_logloss: 0.502398\n",
      "[455]\ttraining's binary_logloss: 0.502188\n",
      "[456]\ttraining's binary_logloss: 0.501993\n",
      "[457]\ttraining's binary_logloss: 0.501834\n",
      "[458]\ttraining's binary_logloss: 0.501656\n",
      "[459]\ttraining's binary_logloss: 0.501482\n",
      "[460]\ttraining's binary_logloss: 0.501296\n",
      "[461]\ttraining's binary_logloss: 0.501076\n",
      "[462]\ttraining's binary_logloss: 0.500886\n",
      "[463]\ttraining's binary_logloss: 0.5007\n",
      "[464]\ttraining's binary_logloss: 0.500493\n",
      "[465]\ttraining's binary_logloss: 0.50029\n",
      "[466]\ttraining's binary_logloss: 0.50009\n",
      "[467]\ttraining's binary_logloss: 0.499892\n",
      "[468]\ttraining's binary_logloss: 0.499693\n",
      "[469]\ttraining's binary_logloss: 0.499538\n",
      "[470]\ttraining's binary_logloss: 0.499361\n",
      "[471]\ttraining's binary_logloss: 0.499183\n",
      "[472]\ttraining's binary_logloss: 0.499003\n",
      "[473]\ttraining's binary_logloss: 0.498826\n",
      "[474]\ttraining's binary_logloss: 0.49866\n",
      "[475]\ttraining's binary_logloss: 0.498478\n",
      "[476]\ttraining's binary_logloss: 0.498292\n",
      "[477]\ttraining's binary_logloss: 0.498098\n",
      "[478]\ttraining's binary_logloss: 0.497917\n",
      "[479]\ttraining's binary_logloss: 0.497755\n",
      "[480]\ttraining's binary_logloss: 0.497593\n",
      "[481]\ttraining's binary_logloss: 0.497416\n",
      "[482]\ttraining's binary_logloss: 0.497268\n",
      "[483]\ttraining's binary_logloss: 0.49709\n",
      "[484]\ttraining's binary_logloss: 0.496925\n",
      "[485]\ttraining's binary_logloss: 0.49675\n",
      "[486]\ttraining's binary_logloss: 0.496535\n",
      "[487]\ttraining's binary_logloss: 0.496337\n",
      "[488]\ttraining's binary_logloss: 0.496144\n",
      "[489]\ttraining's binary_logloss: 0.495946\n",
      "[490]\ttraining's binary_logloss: 0.495751\n",
      "[491]\ttraining's binary_logloss: 0.49561\n",
      "[492]\ttraining's binary_logloss: 0.495474\n",
      "[493]\ttraining's binary_logloss: 0.495357\n",
      "[494]\ttraining's binary_logloss: 0.495206\n",
      "[495]\ttraining's binary_logloss: 0.495081\n",
      "[496]\ttraining's binary_logloss: 0.494886\n",
      "[497]\ttraining's binary_logloss: 0.494706\n",
      "[498]\ttraining's binary_logloss: 0.494526\n",
      "[499]\ttraining's binary_logloss: 0.49435\n",
      "[500]\ttraining's binary_logloss: 0.494181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613603\n",
      "[2]\ttraining's binary_logloss: 0.61198\n",
      "[3]\ttraining's binary_logloss: 0.610405\n",
      "[4]\ttraining's binary_logloss: 0.608864\n",
      "[5]\ttraining's binary_logloss: 0.60758\n",
      "[6]\ttraining's binary_logloss: 0.606346\n",
      "[7]\ttraining's binary_logloss: 0.604997\n",
      "[8]\ttraining's binary_logloss: 0.60375\n",
      "[9]\ttraining's binary_logloss: 0.602534\n",
      "[10]\ttraining's binary_logloss: 0.601463\n",
      "[11]\ttraining's binary_logloss: 0.600291\n",
      "[12]\ttraining's binary_logloss: 0.599086\n",
      "[13]\ttraining's binary_logloss: 0.597903\n",
      "[14]\ttraining's binary_logloss: 0.596909\n",
      "[15]\ttraining's binary_logloss: 0.595806\n",
      "[16]\ttraining's binary_logloss: 0.594745\n",
      "[17]\ttraining's binary_logloss: 0.593713\n",
      "[18]\ttraining's binary_logloss: 0.592702\n",
      "[19]\ttraining's binary_logloss: 0.591749\n",
      "[20]\ttraining's binary_logloss: 0.59091\n",
      "[21]\ttraining's binary_logloss: 0.590009\n",
      "[22]\ttraining's binary_logloss: 0.58913\n",
      "[23]\ttraining's binary_logloss: 0.588286\n",
      "[24]\ttraining's binary_logloss: 0.587415\n",
      "[25]\ttraining's binary_logloss: 0.586602\n",
      "[26]\ttraining's binary_logloss: 0.585862\n",
      "[27]\ttraining's binary_logloss: 0.585134\n",
      "[28]\ttraining's binary_logloss: 0.584422\n",
      "[29]\ttraining's binary_logloss: 0.583739\n",
      "[30]\ttraining's binary_logloss: 0.58306\n",
      "[31]\ttraining's binary_logloss: 0.582405\n",
      "[32]\ttraining's binary_logloss: 0.581672\n",
      "[33]\ttraining's binary_logloss: 0.580977\n",
      "[34]\ttraining's binary_logloss: 0.580302\n",
      "[35]\ttraining's binary_logloss: 0.579625\n",
      "[36]\ttraining's binary_logloss: 0.578915\n",
      "[37]\ttraining's binary_logloss: 0.578267\n",
      "[38]\ttraining's binary_logloss: 0.577661\n",
      "[39]\ttraining's binary_logloss: 0.577066\n",
      "[40]\ttraining's binary_logloss: 0.576479\n",
      "[41]\ttraining's binary_logloss: 0.575972\n",
      "[42]\ttraining's binary_logloss: 0.575481\n",
      "[43]\ttraining's binary_logloss: 0.574983\n",
      "[44]\ttraining's binary_logloss: 0.574528\n",
      "[45]\ttraining's binary_logloss: 0.574069\n",
      "[46]\ttraining's binary_logloss: 0.573606\n",
      "[47]\ttraining's binary_logloss: 0.573065\n",
      "[48]\ttraining's binary_logloss: 0.572543\n",
      "[49]\ttraining's binary_logloss: 0.572136\n",
      "[50]\ttraining's binary_logloss: 0.571644\n",
      "[51]\ttraining's binary_logloss: 0.571129\n",
      "[52]\ttraining's binary_logloss: 0.570706\n",
      "[53]\ttraining's binary_logloss: 0.57021\n",
      "[54]\ttraining's binary_logloss: 0.569762\n",
      "[55]\ttraining's binary_logloss: 0.569366\n",
      "[56]\ttraining's binary_logloss: 0.568931\n",
      "[57]\ttraining's binary_logloss: 0.568493\n",
      "[58]\ttraining's binary_logloss: 0.568082\n",
      "[59]\ttraining's binary_logloss: 0.567717\n",
      "[60]\ttraining's binary_logloss: 0.567294\n",
      "[61]\ttraining's binary_logloss: 0.566896\n",
      "[62]\ttraining's binary_logloss: 0.566495\n",
      "[63]\ttraining's binary_logloss: 0.566125\n",
      "[64]\ttraining's binary_logloss: 0.56578\n",
      "[65]\ttraining's binary_logloss: 0.565446\n",
      "[66]\ttraining's binary_logloss: 0.565119\n",
      "[67]\ttraining's binary_logloss: 0.564825\n",
      "[68]\ttraining's binary_logloss: 0.564516\n",
      "[69]\ttraining's binary_logloss: 0.564204\n",
      "[70]\ttraining's binary_logloss: 0.563925\n",
      "[71]\ttraining's binary_logloss: 0.563647\n",
      "[72]\ttraining's binary_logloss: 0.563343\n",
      "[73]\ttraining's binary_logloss: 0.563047\n",
      "[74]\ttraining's binary_logloss: 0.562797\n",
      "[75]\ttraining's binary_logloss: 0.562555\n",
      "[76]\ttraining's binary_logloss: 0.56228\n",
      "[77]\ttraining's binary_logloss: 0.562002\n",
      "[78]\ttraining's binary_logloss: 0.561801\n",
      "[79]\ttraining's binary_logloss: 0.561479\n",
      "[80]\ttraining's binary_logloss: 0.561162\n",
      "[81]\ttraining's binary_logloss: 0.56092\n",
      "[82]\ttraining's binary_logloss: 0.560683\n",
      "[83]\ttraining's binary_logloss: 0.560403\n",
      "[84]\ttraining's binary_logloss: 0.560195\n",
      "[85]\ttraining's binary_logloss: 0.559939\n",
      "[86]\ttraining's binary_logloss: 0.559705\n",
      "[87]\ttraining's binary_logloss: 0.559427\n",
      "[88]\ttraining's binary_logloss: 0.559148\n",
      "[89]\ttraining's binary_logloss: 0.558879\n",
      "[90]\ttraining's binary_logloss: 0.558618\n",
      "[91]\ttraining's binary_logloss: 0.55838\n",
      "[92]\ttraining's binary_logloss: 0.558153\n",
      "[93]\ttraining's binary_logloss: 0.557915\n",
      "[94]\ttraining's binary_logloss: 0.557684\n",
      "[95]\ttraining's binary_logloss: 0.557485\n",
      "[96]\ttraining's binary_logloss: 0.557269\n",
      "[97]\ttraining's binary_logloss: 0.55704\n",
      "[98]\ttraining's binary_logloss: 0.556815\n",
      "[99]\ttraining's binary_logloss: 0.55662\n",
      "[100]\ttraining's binary_logloss: 0.556419\n",
      "[101]\ttraining's binary_logloss: 0.55623\n",
      "[102]\ttraining's binary_logloss: 0.556048\n",
      "[103]\ttraining's binary_logloss: 0.555855\n",
      "[104]\ttraining's binary_logloss: 0.555668\n",
      "[105]\ttraining's binary_logloss: 0.555508\n",
      "[106]\ttraining's binary_logloss: 0.555319\n",
      "[107]\ttraining's binary_logloss: 0.555136\n",
      "[108]\ttraining's binary_logloss: 0.554974\n",
      "[109]\ttraining's binary_logloss: 0.554769\n",
      "[110]\ttraining's binary_logloss: 0.554552\n",
      "[111]\ttraining's binary_logloss: 0.554349\n",
      "[112]\ttraining's binary_logloss: 0.554154\n",
      "[113]\ttraining's binary_logloss: 0.553959\n",
      "[114]\ttraining's binary_logloss: 0.553759\n",
      "[115]\ttraining's binary_logloss: 0.553556\n",
      "[116]\ttraining's binary_logloss: 0.553372\n",
      "[117]\ttraining's binary_logloss: 0.553192\n",
      "[118]\ttraining's binary_logloss: 0.553028\n",
      "[119]\ttraining's binary_logloss: 0.55288\n",
      "[120]\ttraining's binary_logloss: 0.55272\n",
      "[121]\ttraining's binary_logloss: 0.552556\n",
      "[122]\ttraining's binary_logloss: 0.552369\n",
      "[123]\ttraining's binary_logloss: 0.552182\n",
      "[124]\ttraining's binary_logloss: 0.552009\n",
      "[125]\ttraining's binary_logloss: 0.551861\n",
      "[126]\ttraining's binary_logloss: 0.551653\n",
      "[127]\ttraining's binary_logloss: 0.55146\n",
      "[128]\ttraining's binary_logloss: 0.55126\n",
      "[129]\ttraining's binary_logloss: 0.551077\n",
      "[130]\ttraining's binary_logloss: 0.550907\n",
      "[131]\ttraining's binary_logloss: 0.550721\n",
      "[132]\ttraining's binary_logloss: 0.550562\n",
      "[133]\ttraining's binary_logloss: 0.550418\n",
      "[134]\ttraining's binary_logloss: 0.550257\n",
      "[135]\ttraining's binary_logloss: 0.550087\n",
      "[136]\ttraining's binary_logloss: 0.549937\n",
      "[137]\ttraining's binary_logloss: 0.549765\n",
      "[138]\ttraining's binary_logloss: 0.549603\n",
      "[139]\ttraining's binary_logloss: 0.549438\n",
      "[140]\ttraining's binary_logloss: 0.549286\n",
      "[141]\ttraining's binary_logloss: 0.54915\n",
      "[142]\ttraining's binary_logloss: 0.548993\n",
      "[143]\ttraining's binary_logloss: 0.548836\n",
      "[144]\ttraining's binary_logloss: 0.548667\n",
      "[145]\ttraining's binary_logloss: 0.54852\n",
      "[146]\ttraining's binary_logloss: 0.548353\n",
      "[147]\ttraining's binary_logloss: 0.548192\n",
      "[148]\ttraining's binary_logloss: 0.548033\n",
      "[149]\ttraining's binary_logloss: 0.547877\n",
      "[150]\ttraining's binary_logloss: 0.547734\n",
      "[151]\ttraining's binary_logloss: 0.547551\n",
      "[152]\ttraining's binary_logloss: 0.547367\n",
      "[153]\ttraining's binary_logloss: 0.547228\n",
      "[154]\ttraining's binary_logloss: 0.547058\n",
      "[155]\ttraining's binary_logloss: 0.546885\n",
      "[156]\ttraining's binary_logloss: 0.546721\n",
      "[157]\ttraining's binary_logloss: 0.546561\n",
      "[158]\ttraining's binary_logloss: 0.54642\n",
      "[159]\ttraining's binary_logloss: 0.546269\n",
      "[160]\ttraining's binary_logloss: 0.546159\n",
      "[161]\ttraining's binary_logloss: 0.545963\n",
      "[162]\ttraining's binary_logloss: 0.545798\n",
      "[163]\ttraining's binary_logloss: 0.545618\n",
      "[164]\ttraining's binary_logloss: 0.545439\n",
      "[165]\ttraining's binary_logloss: 0.545272\n",
      "[166]\ttraining's binary_logloss: 0.545071\n",
      "[167]\ttraining's binary_logloss: 0.544914\n",
      "[168]\ttraining's binary_logloss: 0.544742\n",
      "[169]\ttraining's binary_logloss: 0.544552\n",
      "[170]\ttraining's binary_logloss: 0.544396\n",
      "[171]\ttraining's binary_logloss: 0.544207\n",
      "[172]\ttraining's binary_logloss: 0.544024\n",
      "[173]\ttraining's binary_logloss: 0.543854\n",
      "[174]\ttraining's binary_logloss: 0.543681\n",
      "[175]\ttraining's binary_logloss: 0.543511\n",
      "[176]\ttraining's binary_logloss: 0.54337\n",
      "[177]\ttraining's binary_logloss: 0.54323\n",
      "[178]\ttraining's binary_logloss: 0.543093\n",
      "[179]\ttraining's binary_logloss: 0.542956\n",
      "[180]\ttraining's binary_logloss: 0.54281\n",
      "[181]\ttraining's binary_logloss: 0.5427\n",
      "[182]\ttraining's binary_logloss: 0.542585\n",
      "[183]\ttraining's binary_logloss: 0.542483\n",
      "[184]\ttraining's binary_logloss: 0.542365\n",
      "[185]\ttraining's binary_logloss: 0.542258\n",
      "[186]\ttraining's binary_logloss: 0.542069\n",
      "[187]\ttraining's binary_logloss: 0.541874\n",
      "[188]\ttraining's binary_logloss: 0.541686\n",
      "[189]\ttraining's binary_logloss: 0.54151\n",
      "[190]\ttraining's binary_logloss: 0.541343\n",
      "[191]\ttraining's binary_logloss: 0.541192\n",
      "[192]\ttraining's binary_logloss: 0.541048\n",
      "[193]\ttraining's binary_logloss: 0.540892\n",
      "[194]\ttraining's binary_logloss: 0.540769\n",
      "[195]\ttraining's binary_logloss: 0.540613\n",
      "[196]\ttraining's binary_logloss: 0.540435\n",
      "[197]\ttraining's binary_logloss: 0.540249\n",
      "[198]\ttraining's binary_logloss: 0.540064\n",
      "[199]\ttraining's binary_logloss: 0.53993\n",
      "[200]\ttraining's binary_logloss: 0.539768\n",
      "[201]\ttraining's binary_logloss: 0.539577\n",
      "[202]\ttraining's binary_logloss: 0.539438\n",
      "[203]\ttraining's binary_logloss: 0.539258\n",
      "[204]\ttraining's binary_logloss: 0.539083\n",
      "[205]\ttraining's binary_logloss: 0.538912\n",
      "[206]\ttraining's binary_logloss: 0.538735\n",
      "[207]\ttraining's binary_logloss: 0.538594\n",
      "[208]\ttraining's binary_logloss: 0.538418\n",
      "[209]\ttraining's binary_logloss: 0.538242\n",
      "[210]\ttraining's binary_logloss: 0.538078\n",
      "[211]\ttraining's binary_logloss: 0.537956\n",
      "[212]\ttraining's binary_logloss: 0.537836\n",
      "[213]\ttraining's binary_logloss: 0.537706\n",
      "[214]\ttraining's binary_logloss: 0.537581\n",
      "[215]\ttraining's binary_logloss: 0.537454\n",
      "[216]\ttraining's binary_logloss: 0.537272\n",
      "[217]\ttraining's binary_logloss: 0.537114\n",
      "[218]\ttraining's binary_logloss: 0.536925\n",
      "[219]\ttraining's binary_logloss: 0.53673\n",
      "[220]\ttraining's binary_logloss: 0.53654\n",
      "[221]\ttraining's binary_logloss: 0.536311\n",
      "[222]\ttraining's binary_logloss: 0.536145\n",
      "[223]\ttraining's binary_logloss: 0.535957\n",
      "[224]\ttraining's binary_logloss: 0.535736\n",
      "[225]\ttraining's binary_logloss: 0.535598\n",
      "[226]\ttraining's binary_logloss: 0.53542\n",
      "[227]\ttraining's binary_logloss: 0.535274\n",
      "[228]\ttraining's binary_logloss: 0.535142\n",
      "[229]\ttraining's binary_logloss: 0.535019\n",
      "[230]\ttraining's binary_logloss: 0.534853\n",
      "[231]\ttraining's binary_logloss: 0.534664\n",
      "[232]\ttraining's binary_logloss: 0.534502\n",
      "[233]\ttraining's binary_logloss: 0.534325\n",
      "[234]\ttraining's binary_logloss: 0.534153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[235]\ttraining's binary_logloss: 0.533984\n",
      "[236]\ttraining's binary_logloss: 0.533782\n",
      "[237]\ttraining's binary_logloss: 0.533597\n",
      "[238]\ttraining's binary_logloss: 0.53344\n",
      "[239]\ttraining's binary_logloss: 0.533246\n",
      "[240]\ttraining's binary_logloss: 0.533051\n",
      "[241]\ttraining's binary_logloss: 0.532889\n",
      "[242]\ttraining's binary_logloss: 0.53271\n",
      "[243]\ttraining's binary_logloss: 0.532534\n",
      "[244]\ttraining's binary_logloss: 0.532351\n",
      "[245]\ttraining's binary_logloss: 0.53219\n",
      "[246]\ttraining's binary_logloss: 0.532033\n",
      "[247]\ttraining's binary_logloss: 0.531859\n",
      "[248]\ttraining's binary_logloss: 0.531658\n",
      "[249]\ttraining's binary_logloss: 0.531484\n",
      "[250]\ttraining's binary_logloss: 0.531335\n",
      "[251]\ttraining's binary_logloss: 0.531159\n",
      "[252]\ttraining's binary_logloss: 0.531001\n",
      "[253]\ttraining's binary_logloss: 0.530845\n",
      "[254]\ttraining's binary_logloss: 0.530695\n",
      "[255]\ttraining's binary_logloss: 0.53055\n",
      "[256]\ttraining's binary_logloss: 0.530326\n",
      "[257]\ttraining's binary_logloss: 0.530132\n",
      "[258]\ttraining's binary_logloss: 0.529911\n",
      "[259]\ttraining's binary_logloss: 0.529715\n",
      "[260]\ttraining's binary_logloss: 0.529522\n",
      "[261]\ttraining's binary_logloss: 0.529338\n",
      "[262]\ttraining's binary_logloss: 0.529159\n",
      "[263]\ttraining's binary_logloss: 0.529016\n",
      "[264]\ttraining's binary_logloss: 0.528838\n",
      "[265]\ttraining's binary_logloss: 0.528669\n",
      "[266]\ttraining's binary_logloss: 0.528552\n",
      "[267]\ttraining's binary_logloss: 0.528404\n",
      "[268]\ttraining's binary_logloss: 0.52828\n",
      "[269]\ttraining's binary_logloss: 0.52819\n",
      "[270]\ttraining's binary_logloss: 0.528076\n",
      "[271]\ttraining's binary_logloss: 0.527847\n",
      "[272]\ttraining's binary_logloss: 0.527619\n",
      "[273]\ttraining's binary_logloss: 0.527411\n",
      "[274]\ttraining's binary_logloss: 0.527209\n",
      "[275]\ttraining's binary_logloss: 0.527014\n",
      "[276]\ttraining's binary_logloss: 0.526792\n",
      "[277]\ttraining's binary_logloss: 0.52658\n",
      "[278]\ttraining's binary_logloss: 0.526343\n",
      "[279]\ttraining's binary_logloss: 0.526139\n",
      "[280]\ttraining's binary_logloss: 0.525937\n",
      "[281]\ttraining's binary_logloss: 0.525731\n",
      "[282]\ttraining's binary_logloss: 0.525516\n",
      "[283]\ttraining's binary_logloss: 0.525325\n",
      "[284]\ttraining's binary_logloss: 0.525142\n",
      "[285]\ttraining's binary_logloss: 0.524961\n",
      "[286]\ttraining's binary_logloss: 0.524789\n",
      "[287]\ttraining's binary_logloss: 0.52461\n",
      "[288]\ttraining's binary_logloss: 0.524417\n",
      "[289]\ttraining's binary_logloss: 0.524202\n",
      "[290]\ttraining's binary_logloss: 0.524028\n",
      "[291]\ttraining's binary_logloss: 0.523836\n",
      "[292]\ttraining's binary_logloss: 0.523655\n",
      "[293]\ttraining's binary_logloss: 0.523454\n",
      "[294]\ttraining's binary_logloss: 0.523286\n",
      "[295]\ttraining's binary_logloss: 0.523103\n",
      "[296]\ttraining's binary_logloss: 0.522946\n",
      "[297]\ttraining's binary_logloss: 0.522781\n",
      "[298]\ttraining's binary_logloss: 0.522633\n",
      "[299]\ttraining's binary_logloss: 0.522504\n",
      "[300]\ttraining's binary_logloss: 0.522364\n",
      "[301]\ttraining's binary_logloss: 0.522145\n",
      "[302]\ttraining's binary_logloss: 0.521923\n",
      "[303]\ttraining's binary_logloss: 0.521727\n",
      "[304]\ttraining's binary_logloss: 0.521495\n",
      "[305]\ttraining's binary_logloss: 0.52131\n",
      "[306]\ttraining's binary_logloss: 0.521123\n",
      "[307]\ttraining's binary_logloss: 0.520951\n",
      "[308]\ttraining's binary_logloss: 0.520776\n",
      "[309]\ttraining's binary_logloss: 0.520607\n",
      "[310]\ttraining's binary_logloss: 0.520415\n",
      "[311]\ttraining's binary_logloss: 0.520217\n",
      "[312]\ttraining's binary_logloss: 0.520058\n",
      "[313]\ttraining's binary_logloss: 0.519921\n",
      "[314]\ttraining's binary_logloss: 0.519753\n",
      "[315]\ttraining's binary_logloss: 0.519597\n",
      "[316]\ttraining's binary_logloss: 0.519421\n",
      "[317]\ttraining's binary_logloss: 0.519228\n",
      "[318]\ttraining's binary_logloss: 0.519071\n",
      "[319]\ttraining's binary_logloss: 0.5189\n",
      "[320]\ttraining's binary_logloss: 0.51873\n",
      "[321]\ttraining's binary_logloss: 0.518556\n",
      "[322]\ttraining's binary_logloss: 0.518371\n",
      "[323]\ttraining's binary_logloss: 0.518205\n",
      "[324]\ttraining's binary_logloss: 0.518025\n",
      "[325]\ttraining's binary_logloss: 0.517875\n",
      "[326]\ttraining's binary_logloss: 0.517627\n",
      "[327]\ttraining's binary_logloss: 0.517434\n",
      "[328]\ttraining's binary_logloss: 0.517183\n",
      "[329]\ttraining's binary_logloss: 0.516984\n",
      "[330]\ttraining's binary_logloss: 0.516803\n",
      "[331]\ttraining's binary_logloss: 0.516613\n",
      "[332]\ttraining's binary_logloss: 0.516428\n",
      "[333]\ttraining's binary_logloss: 0.516247\n",
      "[334]\ttraining's binary_logloss: 0.516083\n",
      "[335]\ttraining's binary_logloss: 0.515889\n",
      "[336]\ttraining's binary_logloss: 0.515691\n",
      "[337]\ttraining's binary_logloss: 0.515512\n",
      "[338]\ttraining's binary_logloss: 0.515335\n",
      "[339]\ttraining's binary_logloss: 0.51515\n",
      "[340]\ttraining's binary_logloss: 0.51497\n",
      "[341]\ttraining's binary_logloss: 0.514793\n",
      "[342]\ttraining's binary_logloss: 0.514623\n",
      "[343]\ttraining's binary_logloss: 0.514446\n",
      "[344]\ttraining's binary_logloss: 0.514294\n",
      "[345]\ttraining's binary_logloss: 0.514143\n",
      "[346]\ttraining's binary_logloss: 0.513961\n",
      "[347]\ttraining's binary_logloss: 0.513788\n",
      "[348]\ttraining's binary_logloss: 0.513611\n",
      "[349]\ttraining's binary_logloss: 0.513439\n",
      "[350]\ttraining's binary_logloss: 0.513252\n",
      "[351]\ttraining's binary_logloss: 0.513059\n",
      "[352]\ttraining's binary_logloss: 0.51288\n",
      "[353]\ttraining's binary_logloss: 0.512685\n",
      "[354]\ttraining's binary_logloss: 0.512503\n",
      "[355]\ttraining's binary_logloss: 0.512317\n",
      "[356]\ttraining's binary_logloss: 0.512119\n",
      "[357]\ttraining's binary_logloss: 0.511879\n",
      "[358]\ttraining's binary_logloss: 0.511665\n",
      "[359]\ttraining's binary_logloss: 0.511462\n",
      "[360]\ttraining's binary_logloss: 0.511243\n",
      "[361]\ttraining's binary_logloss: 0.511022\n",
      "[362]\ttraining's binary_logloss: 0.510809\n",
      "[363]\ttraining's binary_logloss: 0.510591\n",
      "[364]\ttraining's binary_logloss: 0.510386\n",
      "[365]\ttraining's binary_logloss: 0.510195\n",
      "[366]\ttraining's binary_logloss: 0.509982\n",
      "[367]\ttraining's binary_logloss: 0.509804\n",
      "[368]\ttraining's binary_logloss: 0.509604\n",
      "[369]\ttraining's binary_logloss: 0.50942\n",
      "[370]\ttraining's binary_logloss: 0.509213\n",
      "[371]\ttraining's binary_logloss: 0.509056\n",
      "[372]\ttraining's binary_logloss: 0.508908\n",
      "[373]\ttraining's binary_logloss: 0.508755\n",
      "[374]\ttraining's binary_logloss: 0.508606\n",
      "[375]\ttraining's binary_logloss: 0.508461\n",
      "[376]\ttraining's binary_logloss: 0.508273\n",
      "[377]\ttraining's binary_logloss: 0.508096\n",
      "[378]\ttraining's binary_logloss: 0.507918\n",
      "[379]\ttraining's binary_logloss: 0.507762\n",
      "[380]\ttraining's binary_logloss: 0.507598\n",
      "[381]\ttraining's binary_logloss: 0.507448\n",
      "[382]\ttraining's binary_logloss: 0.507276\n",
      "[383]\ttraining's binary_logloss: 0.507119\n",
      "[384]\ttraining's binary_logloss: 0.506996\n",
      "[385]\ttraining's binary_logloss: 0.50684\n",
      "[386]\ttraining's binary_logloss: 0.506647\n",
      "[387]\ttraining's binary_logloss: 0.506444\n",
      "[388]\ttraining's binary_logloss: 0.506231\n",
      "[389]\ttraining's binary_logloss: 0.506016\n",
      "[390]\ttraining's binary_logloss: 0.505825\n",
      "[391]\ttraining's binary_logloss: 0.505631\n",
      "[392]\ttraining's binary_logloss: 0.505442\n",
      "[393]\ttraining's binary_logloss: 0.505262\n",
      "[394]\ttraining's binary_logloss: 0.505078\n",
      "[395]\ttraining's binary_logloss: 0.504923\n",
      "[396]\ttraining's binary_logloss: 0.504727\n",
      "[397]\ttraining's binary_logloss: 0.504538\n",
      "[398]\ttraining's binary_logloss: 0.504349\n",
      "[399]\ttraining's binary_logloss: 0.50417\n",
      "[400]\ttraining's binary_logloss: 0.504002\n",
      "[401]\ttraining's binary_logloss: 0.503782\n",
      "[402]\ttraining's binary_logloss: 0.50361\n",
      "[403]\ttraining's binary_logloss: 0.503435\n",
      "[404]\ttraining's binary_logloss: 0.503259\n",
      "[405]\ttraining's binary_logloss: 0.503067\n",
      "[406]\ttraining's binary_logloss: 0.502893\n",
      "[407]\ttraining's binary_logloss: 0.502716\n",
      "[408]\ttraining's binary_logloss: 0.50255\n",
      "[409]\ttraining's binary_logloss: 0.502381\n",
      "[410]\ttraining's binary_logloss: 0.502199\n",
      "[411]\ttraining's binary_logloss: 0.501962\n",
      "[412]\ttraining's binary_logloss: 0.501764\n",
      "[413]\ttraining's binary_logloss: 0.501555\n",
      "[414]\ttraining's binary_logloss: 0.501359\n",
      "[415]\ttraining's binary_logloss: 0.501173\n",
      "[416]\ttraining's binary_logloss: 0.501002\n",
      "[417]\ttraining's binary_logloss: 0.500833\n",
      "[418]\ttraining's binary_logloss: 0.500653\n",
      "[419]\ttraining's binary_logloss: 0.500497\n",
      "[420]\ttraining's binary_logloss: 0.500342\n",
      "[421]\ttraining's binary_logloss: 0.500156\n",
      "[422]\ttraining's binary_logloss: 0.499994\n",
      "[423]\ttraining's binary_logloss: 0.499838\n",
      "[424]\ttraining's binary_logloss: 0.499682\n",
      "[425]\ttraining's binary_logloss: 0.499528\n",
      "[426]\ttraining's binary_logloss: 0.499362\n",
      "[427]\ttraining's binary_logloss: 0.499169\n",
      "[428]\ttraining's binary_logloss: 0.499\n",
      "[429]\ttraining's binary_logloss: 0.498787\n",
      "[430]\ttraining's binary_logloss: 0.498601\n",
      "[431]\ttraining's binary_logloss: 0.498399\n",
      "[432]\ttraining's binary_logloss: 0.498157\n",
      "[433]\ttraining's binary_logloss: 0.497957\n",
      "[434]\ttraining's binary_logloss: 0.497707\n",
      "[435]\ttraining's binary_logloss: 0.497484\n",
      "[436]\ttraining's binary_logloss: 0.497245\n",
      "[437]\ttraining's binary_logloss: 0.49702\n",
      "[438]\ttraining's binary_logloss: 0.496784\n",
      "[439]\ttraining's binary_logloss: 0.496591\n",
      "[440]\ttraining's binary_logloss: 0.496367\n",
      "[441]\ttraining's binary_logloss: 0.496176\n",
      "[442]\ttraining's binary_logloss: 0.495958\n",
      "[443]\ttraining's binary_logloss: 0.495765\n",
      "[444]\ttraining's binary_logloss: 0.495554\n",
      "[445]\ttraining's binary_logloss: 0.495379\n",
      "[446]\ttraining's binary_logloss: 0.495192\n",
      "[447]\ttraining's binary_logloss: 0.494971\n",
      "[448]\ttraining's binary_logloss: 0.494769\n",
      "[449]\ttraining's binary_logloss: 0.494561\n",
      "[450]\ttraining's binary_logloss: 0.494346\n",
      "[451]\ttraining's binary_logloss: 0.494167\n",
      "[452]\ttraining's binary_logloss: 0.493996\n",
      "[453]\ttraining's binary_logloss: 0.493833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[454]\ttraining's binary_logloss: 0.49365\n",
      "[455]\ttraining's binary_logloss: 0.493488\n",
      "[456]\ttraining's binary_logloss: 0.49329\n",
      "[457]\ttraining's binary_logloss: 0.493128\n",
      "[458]\ttraining's binary_logloss: 0.492933\n",
      "[459]\ttraining's binary_logloss: 0.492754\n",
      "[460]\ttraining's binary_logloss: 0.492585\n",
      "[461]\ttraining's binary_logloss: 0.492359\n",
      "[462]\ttraining's binary_logloss: 0.492161\n",
      "[463]\ttraining's binary_logloss: 0.491954\n",
      "[464]\ttraining's binary_logloss: 0.491742\n",
      "[465]\ttraining's binary_logloss: 0.49156\n",
      "[466]\ttraining's binary_logloss: 0.491362\n",
      "[467]\ttraining's binary_logloss: 0.491156\n",
      "[468]\ttraining's binary_logloss: 0.490956\n",
      "[469]\ttraining's binary_logloss: 0.490753\n",
      "[470]\ttraining's binary_logloss: 0.490546\n",
      "[471]\ttraining's binary_logloss: 0.490389\n",
      "[472]\ttraining's binary_logloss: 0.490225\n",
      "[473]\ttraining's binary_logloss: 0.490057\n",
      "[474]\ttraining's binary_logloss: 0.489895\n",
      "[475]\ttraining's binary_logloss: 0.489755\n",
      "[476]\ttraining's binary_logloss: 0.489543\n",
      "[477]\ttraining's binary_logloss: 0.489362\n",
      "[478]\ttraining's binary_logloss: 0.489146\n",
      "[479]\ttraining's binary_logloss: 0.488975\n",
      "[480]\ttraining's binary_logloss: 0.48881\n",
      "[481]\ttraining's binary_logloss: 0.488634\n",
      "[482]\ttraining's binary_logloss: 0.488456\n",
      "[483]\ttraining's binary_logloss: 0.488291\n",
      "[484]\ttraining's binary_logloss: 0.488114\n",
      "[485]\ttraining's binary_logloss: 0.487953\n",
      "[486]\ttraining's binary_logloss: 0.487741\n",
      "[487]\ttraining's binary_logloss: 0.487527\n",
      "[488]\ttraining's binary_logloss: 0.487339\n",
      "[489]\ttraining's binary_logloss: 0.487132\n",
      "[490]\ttraining's binary_logloss: 0.486955\n",
      "[491]\ttraining's binary_logloss: 0.486788\n",
      "[492]\ttraining's binary_logloss: 0.486631\n",
      "[493]\ttraining's binary_logloss: 0.486473\n",
      "[494]\ttraining's binary_logloss: 0.486325\n",
      "[495]\ttraining's binary_logloss: 0.486171\n",
      "[496]\ttraining's binary_logloss: 0.48597\n",
      "[497]\ttraining's binary_logloss: 0.485782\n",
      "[498]\ttraining's binary_logloss: 0.485576\n",
      "[499]\ttraining's binary_logloss: 0.485381\n",
      "[500]\ttraining's binary_logloss: 0.485186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.61278\n",
      "[2]\ttraining's binary_logloss: 0.61129\n",
      "[3]\ttraining's binary_logloss: 0.60985\n",
      "[4]\ttraining's binary_logloss: 0.608456\n",
      "[5]\ttraining's binary_logloss: 0.6071\n",
      "[6]\ttraining's binary_logloss: 0.605883\n",
      "[7]\ttraining's binary_logloss: 0.604572\n",
      "[8]\ttraining's binary_logloss: 0.603347\n",
      "[9]\ttraining's binary_logloss: 0.602075\n",
      "[10]\ttraining's binary_logloss: 0.600897\n",
      "[11]\ttraining's binary_logloss: 0.599711\n",
      "[12]\ttraining's binary_logloss: 0.598566\n",
      "[13]\ttraining's binary_logloss: 0.597459\n",
      "[14]\ttraining's binary_logloss: 0.596513\n",
      "[15]\ttraining's binary_logloss: 0.595463\n",
      "[16]\ttraining's binary_logloss: 0.594469\n",
      "[17]\ttraining's binary_logloss: 0.593514\n",
      "[18]\ttraining's binary_logloss: 0.592491\n",
      "[19]\ttraining's binary_logloss: 0.59155\n",
      "[20]\ttraining's binary_logloss: 0.590637\n",
      "[21]\ttraining's binary_logloss: 0.58976\n",
      "[22]\ttraining's binary_logloss: 0.588957\n",
      "[23]\ttraining's binary_logloss: 0.588145\n",
      "[24]\ttraining's binary_logloss: 0.58735\n",
      "[25]\ttraining's binary_logloss: 0.586597\n",
      "[26]\ttraining's binary_logloss: 0.585778\n",
      "[27]\ttraining's binary_logloss: 0.585052\n",
      "[28]\ttraining's binary_logloss: 0.584343\n",
      "[29]\ttraining's binary_logloss: 0.583671\n",
      "[30]\ttraining's binary_logloss: 0.582964\n",
      "[31]\ttraining's binary_logloss: 0.582268\n",
      "[32]\ttraining's binary_logloss: 0.581605\n",
      "[33]\ttraining's binary_logloss: 0.580971\n",
      "[34]\ttraining's binary_logloss: 0.580474\n",
      "[35]\ttraining's binary_logloss: 0.579823\n",
      "[36]\ttraining's binary_logloss: 0.579222\n",
      "[37]\ttraining's binary_logloss: 0.578608\n",
      "[38]\ttraining's binary_logloss: 0.578016\n",
      "[39]\ttraining's binary_logloss: 0.577503\n",
      "[40]\ttraining's binary_logloss: 0.576944\n",
      "[41]\ttraining's binary_logloss: 0.576394\n",
      "[42]\ttraining's binary_logloss: 0.575864\n",
      "[43]\ttraining's binary_logloss: 0.575343\n",
      "[44]\ttraining's binary_logloss: 0.574796\n",
      "[45]\ttraining's binary_logloss: 0.574285\n",
      "[46]\ttraining's binary_logloss: 0.57377\n",
      "[47]\ttraining's binary_logloss: 0.573271\n",
      "[48]\ttraining's binary_logloss: 0.572773\n",
      "[49]\ttraining's binary_logloss: 0.572308\n",
      "[50]\ttraining's binary_logloss: 0.571849\n",
      "[51]\ttraining's binary_logloss: 0.571406\n",
      "[52]\ttraining's binary_logloss: 0.570984\n",
      "[53]\ttraining's binary_logloss: 0.570557\n",
      "[54]\ttraining's binary_logloss: 0.570135\n",
      "[55]\ttraining's binary_logloss: 0.569749\n",
      "[56]\ttraining's binary_logloss: 0.569396\n",
      "[57]\ttraining's binary_logloss: 0.569011\n",
      "[58]\ttraining's binary_logloss: 0.568686\n",
      "[59]\ttraining's binary_logloss: 0.568377\n",
      "[60]\ttraining's binary_logloss: 0.568039\n",
      "[61]\ttraining's binary_logloss: 0.567721\n",
      "[62]\ttraining's binary_logloss: 0.567416\n",
      "[63]\ttraining's binary_logloss: 0.567091\n",
      "[64]\ttraining's binary_logloss: 0.566819\n",
      "[65]\ttraining's binary_logloss: 0.566564\n",
      "[66]\ttraining's binary_logloss: 0.566207\n",
      "[67]\ttraining's binary_logloss: 0.56589\n",
      "[68]\ttraining's binary_logloss: 0.565588\n",
      "[69]\ttraining's binary_logloss: 0.565295\n",
      "[70]\ttraining's binary_logloss: 0.56497\n",
      "[71]\ttraining's binary_logloss: 0.564678\n",
      "[72]\ttraining's binary_logloss: 0.564406\n",
      "[73]\ttraining's binary_logloss: 0.564131\n",
      "[74]\ttraining's binary_logloss: 0.563819\n",
      "[75]\ttraining's binary_logloss: 0.563567\n",
      "[76]\ttraining's binary_logloss: 0.563268\n",
      "[77]\ttraining's binary_logloss: 0.562974\n",
      "[78]\ttraining's binary_logloss: 0.562782\n",
      "[79]\ttraining's binary_logloss: 0.562544\n",
      "[80]\ttraining's binary_logloss: 0.562318\n",
      "[81]\ttraining's binary_logloss: 0.562068\n",
      "[82]\ttraining's binary_logloss: 0.561803\n",
      "[83]\ttraining's binary_logloss: 0.561551\n",
      "[84]\ttraining's binary_logloss: 0.561285\n",
      "[85]\ttraining's binary_logloss: 0.561052\n",
      "[86]\ttraining's binary_logloss: 0.560823\n",
      "[87]\ttraining's binary_logloss: 0.560579\n",
      "[88]\ttraining's binary_logloss: 0.560365\n",
      "[89]\ttraining's binary_logloss: 0.560163\n",
      "[90]\ttraining's binary_logloss: 0.559929\n",
      "[91]\ttraining's binary_logloss: 0.559715\n",
      "[92]\ttraining's binary_logloss: 0.559516\n",
      "[93]\ttraining's binary_logloss: 0.559343\n",
      "[94]\ttraining's binary_logloss: 0.559113\n",
      "[95]\ttraining's binary_logloss: 0.558893\n",
      "[96]\ttraining's binary_logloss: 0.558709\n",
      "[97]\ttraining's binary_logloss: 0.558492\n",
      "[98]\ttraining's binary_logloss: 0.558331\n",
      "[99]\ttraining's binary_logloss: 0.558175\n",
      "[100]\ttraining's binary_logloss: 0.55798\n",
      "[101]\ttraining's binary_logloss: 0.557792\n",
      "[102]\ttraining's binary_logloss: 0.557659\n",
      "[103]\ttraining's binary_logloss: 0.557478\n",
      "[104]\ttraining's binary_logloss: 0.557344\n",
      "[105]\ttraining's binary_logloss: 0.557204\n",
      "[106]\ttraining's binary_logloss: 0.557011\n",
      "[107]\ttraining's binary_logloss: 0.556838\n",
      "[108]\ttraining's binary_logloss: 0.55667\n",
      "[109]\ttraining's binary_logloss: 0.556561\n",
      "[110]\ttraining's binary_logloss: 0.556411\n",
      "[111]\ttraining's binary_logloss: 0.556253\n",
      "[112]\ttraining's binary_logloss: 0.556112\n",
      "[113]\ttraining's binary_logloss: 0.555985\n",
      "[114]\ttraining's binary_logloss: 0.555822\n",
      "[115]\ttraining's binary_logloss: 0.555696\n",
      "[116]\ttraining's binary_logloss: 0.55549\n",
      "[117]\ttraining's binary_logloss: 0.555287\n",
      "[118]\ttraining's binary_logloss: 0.555123\n",
      "[119]\ttraining's binary_logloss: 0.554929\n",
      "[120]\ttraining's binary_logloss: 0.554775\n",
      "[121]\ttraining's binary_logloss: 0.554638\n",
      "[122]\ttraining's binary_logloss: 0.554455\n",
      "[123]\ttraining's binary_logloss: 0.554283\n",
      "[124]\ttraining's binary_logloss: 0.554114\n",
      "[125]\ttraining's binary_logloss: 0.553951\n",
      "[126]\ttraining's binary_logloss: 0.553765\n",
      "[127]\ttraining's binary_logloss: 0.553561\n",
      "[128]\ttraining's binary_logloss: 0.553405\n",
      "[129]\ttraining's binary_logloss: 0.553223\n",
      "[130]\ttraining's binary_logloss: 0.553074\n",
      "[131]\ttraining's binary_logloss: 0.552916\n",
      "[132]\ttraining's binary_logloss: 0.55275\n",
      "[133]\ttraining's binary_logloss: 0.552607\n",
      "[134]\ttraining's binary_logloss: 0.552441\n",
      "[135]\ttraining's binary_logloss: 0.55231\n",
      "[136]\ttraining's binary_logloss: 0.552155\n",
      "[137]\ttraining's binary_logloss: 0.55202\n",
      "[138]\ttraining's binary_logloss: 0.551877\n",
      "[139]\ttraining's binary_logloss: 0.551732\n",
      "[140]\ttraining's binary_logloss: 0.551588\n",
      "[141]\ttraining's binary_logloss: 0.55143\n",
      "[142]\ttraining's binary_logloss: 0.551232\n",
      "[143]\ttraining's binary_logloss: 0.551076\n",
      "[144]\ttraining's binary_logloss: 0.5509\n",
      "[145]\ttraining's binary_logloss: 0.550713\n",
      "[146]\ttraining's binary_logloss: 0.550534\n",
      "[147]\ttraining's binary_logloss: 0.550356\n",
      "[148]\ttraining's binary_logloss: 0.550194\n",
      "[149]\ttraining's binary_logloss: 0.550027\n",
      "[150]\ttraining's binary_logloss: 0.54979\n",
      "[151]\ttraining's binary_logloss: 0.549606\n",
      "[152]\ttraining's binary_logloss: 0.549467\n",
      "[153]\ttraining's binary_logloss: 0.549293\n",
      "[154]\ttraining's binary_logloss: 0.549146\n",
      "[155]\ttraining's binary_logloss: 0.548994\n",
      "[156]\ttraining's binary_logloss: 0.548871\n",
      "[157]\ttraining's binary_logloss: 0.548741\n",
      "[158]\ttraining's binary_logloss: 0.548631\n",
      "[159]\ttraining's binary_logloss: 0.548514\n",
      "[160]\ttraining's binary_logloss: 0.548406\n",
      "[161]\ttraining's binary_logloss: 0.548193\n",
      "[162]\ttraining's binary_logloss: 0.547984\n",
      "[163]\ttraining's binary_logloss: 0.547799\n",
      "[164]\ttraining's binary_logloss: 0.547584\n",
      "[165]\ttraining's binary_logloss: 0.547389\n",
      "[166]\ttraining's binary_logloss: 0.547211\n",
      "[167]\ttraining's binary_logloss: 0.547022\n",
      "[168]\ttraining's binary_logloss: 0.546856\n",
      "[169]\ttraining's binary_logloss: 0.546701\n",
      "[170]\ttraining's binary_logloss: 0.546513\n",
      "[171]\ttraining's binary_logloss: 0.546369\n",
      "[172]\ttraining's binary_logloss: 0.546262\n",
      "[173]\ttraining's binary_logloss: 0.546123\n",
      "[174]\ttraining's binary_logloss: 0.546016\n",
      "[175]\ttraining's binary_logloss: 0.545876\n",
      "[176]\ttraining's binary_logloss: 0.545733\n",
      "[177]\ttraining's binary_logloss: 0.545607\n",
      "[178]\ttraining's binary_logloss: 0.545494\n",
      "[179]\ttraining's binary_logloss: 0.545352\n",
      "[180]\ttraining's binary_logloss: 0.54524\n",
      "[181]\ttraining's binary_logloss: 0.545095\n",
      "[182]\ttraining's binary_logloss: 0.544951\n",
      "[183]\ttraining's binary_logloss: 0.544816\n",
      "[184]\ttraining's binary_logloss: 0.544687\n",
      "[185]\ttraining's binary_logloss: 0.54457\n",
      "[186]\ttraining's binary_logloss: 0.544444\n",
      "[187]\ttraining's binary_logloss: 0.544332\n",
      "[188]\ttraining's binary_logloss: 0.544228\n",
      "[189]\ttraining's binary_logloss: 0.544133\n",
      "[190]\ttraining's binary_logloss: 0.544021\n",
      "[191]\ttraining's binary_logloss: 0.543852\n",
      "[192]\ttraining's binary_logloss: 0.543697\n",
      "[193]\ttraining's binary_logloss: 0.543536\n",
      "[194]\ttraining's binary_logloss: 0.54341\n",
      "[195]\ttraining's binary_logloss: 0.543238\n",
      "[196]\ttraining's binary_logloss: 0.543125\n",
      "[197]\ttraining's binary_logloss: 0.542995\n",
      "[198]\ttraining's binary_logloss: 0.542877\n",
      "[199]\ttraining's binary_logloss: 0.542758\n",
      "[200]\ttraining's binary_logloss: 0.542653\n",
      "[201]\ttraining's binary_logloss: 0.542484\n",
      "[202]\ttraining's binary_logloss: 0.54233\n",
      "[203]\ttraining's binary_logloss: 0.542164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[204]\ttraining's binary_logloss: 0.541999\n",
      "[205]\ttraining's binary_logloss: 0.541854\n",
      "[206]\ttraining's binary_logloss: 0.541719\n",
      "[207]\ttraining's binary_logloss: 0.541616\n",
      "[208]\ttraining's binary_logloss: 0.541485\n",
      "[209]\ttraining's binary_logloss: 0.541353\n",
      "[210]\ttraining's binary_logloss: 0.541212\n",
      "[211]\ttraining's binary_logloss: 0.54106\n",
      "[212]\ttraining's binary_logloss: 0.540915\n",
      "[213]\ttraining's binary_logloss: 0.540759\n",
      "[214]\ttraining's binary_logloss: 0.540609\n",
      "[215]\ttraining's binary_logloss: 0.540483\n",
      "[216]\ttraining's binary_logloss: 0.540315\n",
      "[217]\ttraining's binary_logloss: 0.54011\n",
      "[218]\ttraining's binary_logloss: 0.539918\n",
      "[219]\ttraining's binary_logloss: 0.539748\n",
      "[220]\ttraining's binary_logloss: 0.539588\n",
      "[221]\ttraining's binary_logloss: 0.539401\n",
      "[222]\ttraining's binary_logloss: 0.539225\n",
      "[223]\ttraining's binary_logloss: 0.539051\n",
      "[224]\ttraining's binary_logloss: 0.538874\n",
      "[225]\ttraining's binary_logloss: 0.538712\n",
      "[226]\ttraining's binary_logloss: 0.538538\n",
      "[227]\ttraining's binary_logloss: 0.538374\n",
      "[228]\ttraining's binary_logloss: 0.538211\n",
      "[229]\ttraining's binary_logloss: 0.538026\n",
      "[230]\ttraining's binary_logloss: 0.537875\n",
      "[231]\ttraining's binary_logloss: 0.537716\n",
      "[232]\ttraining's binary_logloss: 0.537578\n",
      "[233]\ttraining's binary_logloss: 0.537421\n",
      "[234]\ttraining's binary_logloss: 0.537298\n",
      "[235]\ttraining's binary_logloss: 0.53715\n",
      "[236]\ttraining's binary_logloss: 0.537004\n",
      "[237]\ttraining's binary_logloss: 0.536829\n",
      "[238]\ttraining's binary_logloss: 0.536668\n",
      "[239]\ttraining's binary_logloss: 0.536527\n",
      "[240]\ttraining's binary_logloss: 0.536356\n",
      "[241]\ttraining's binary_logloss: 0.536169\n",
      "[242]\ttraining's binary_logloss: 0.535995\n",
      "[243]\ttraining's binary_logloss: 0.535849\n",
      "[244]\ttraining's binary_logloss: 0.535679\n",
      "[245]\ttraining's binary_logloss: 0.535514\n",
      "[246]\ttraining's binary_logloss: 0.535274\n",
      "[247]\ttraining's binary_logloss: 0.535025\n",
      "[248]\ttraining's binary_logloss: 0.534843\n",
      "[249]\ttraining's binary_logloss: 0.534635\n",
      "[250]\ttraining's binary_logloss: 0.534451\n",
      "[251]\ttraining's binary_logloss: 0.534306\n",
      "[252]\ttraining's binary_logloss: 0.534183\n",
      "[253]\ttraining's binary_logloss: 0.534069\n",
      "[254]\ttraining's binary_logloss: 0.533934\n",
      "[255]\ttraining's binary_logloss: 0.533823\n",
      "[256]\ttraining's binary_logloss: 0.533617\n",
      "[257]\ttraining's binary_logloss: 0.533444\n",
      "[258]\ttraining's binary_logloss: 0.53328\n",
      "[259]\ttraining's binary_logloss: 0.533115\n",
      "[260]\ttraining's binary_logloss: 0.532962\n",
      "[261]\ttraining's binary_logloss: 0.532809\n",
      "[262]\ttraining's binary_logloss: 0.532653\n",
      "[263]\ttraining's binary_logloss: 0.532512\n",
      "[264]\ttraining's binary_logloss: 0.532376\n",
      "[265]\ttraining's binary_logloss: 0.532254\n",
      "[266]\ttraining's binary_logloss: 0.532106\n",
      "[267]\ttraining's binary_logloss: 0.531986\n",
      "[268]\ttraining's binary_logloss: 0.531856\n",
      "[269]\ttraining's binary_logloss: 0.531723\n",
      "[270]\ttraining's binary_logloss: 0.531593\n",
      "[271]\ttraining's binary_logloss: 0.531362\n",
      "[272]\ttraining's binary_logloss: 0.531157\n",
      "[273]\ttraining's binary_logloss: 0.5309\n",
      "[274]\ttraining's binary_logloss: 0.530715\n",
      "[275]\ttraining's binary_logloss: 0.530505\n",
      "[276]\ttraining's binary_logloss: 0.530328\n",
      "[277]\ttraining's binary_logloss: 0.530155\n",
      "[278]\ttraining's binary_logloss: 0.52999\n",
      "[279]\ttraining's binary_logloss: 0.529831\n",
      "[280]\ttraining's binary_logloss: 0.529657\n",
      "[281]\ttraining's binary_logloss: 0.52947\n",
      "[282]\ttraining's binary_logloss: 0.529301\n",
      "[283]\ttraining's binary_logloss: 0.529099\n",
      "[284]\ttraining's binary_logloss: 0.528931\n",
      "[285]\ttraining's binary_logloss: 0.528753\n",
      "[286]\ttraining's binary_logloss: 0.528543\n",
      "[287]\ttraining's binary_logloss: 0.528337\n",
      "[288]\ttraining's binary_logloss: 0.528133\n",
      "[289]\ttraining's binary_logloss: 0.52793\n",
      "[290]\ttraining's binary_logloss: 0.527731\n",
      "[291]\ttraining's binary_logloss: 0.527521\n",
      "[292]\ttraining's binary_logloss: 0.527314\n",
      "[293]\ttraining's binary_logloss: 0.527084\n",
      "[294]\ttraining's binary_logloss: 0.526883\n",
      "[295]\ttraining's binary_logloss: 0.526684\n",
      "[296]\ttraining's binary_logloss: 0.526472\n",
      "[297]\ttraining's binary_logloss: 0.52628\n",
      "[298]\ttraining's binary_logloss: 0.526104\n",
      "[299]\ttraining's binary_logloss: 0.525929\n",
      "[300]\ttraining's binary_logloss: 0.525751\n",
      "[301]\ttraining's binary_logloss: 0.525555\n",
      "[302]\ttraining's binary_logloss: 0.525362\n",
      "[303]\ttraining's binary_logloss: 0.525197\n",
      "[304]\ttraining's binary_logloss: 0.524985\n",
      "[305]\ttraining's binary_logloss: 0.524784\n",
      "[306]\ttraining's binary_logloss: 0.524613\n",
      "[307]\ttraining's binary_logloss: 0.524417\n",
      "[308]\ttraining's binary_logloss: 0.524243\n",
      "[309]\ttraining's binary_logloss: 0.524094\n",
      "[310]\ttraining's binary_logloss: 0.523887\n",
      "[311]\ttraining's binary_logloss: 0.523686\n",
      "[312]\ttraining's binary_logloss: 0.523506\n",
      "[313]\ttraining's binary_logloss: 0.523309\n",
      "[314]\ttraining's binary_logloss: 0.523144\n",
      "[315]\ttraining's binary_logloss: 0.522944\n",
      "[316]\ttraining's binary_logloss: 0.522758\n",
      "[317]\ttraining's binary_logloss: 0.522556\n",
      "[318]\ttraining's binary_logloss: 0.522364\n",
      "[319]\ttraining's binary_logloss: 0.522183\n",
      "[320]\ttraining's binary_logloss: 0.522001\n",
      "[321]\ttraining's binary_logloss: 0.521806\n",
      "[322]\ttraining's binary_logloss: 0.521609\n",
      "[323]\ttraining's binary_logloss: 0.521432\n",
      "[324]\ttraining's binary_logloss: 0.521242\n",
      "[325]\ttraining's binary_logloss: 0.521064\n",
      "[326]\ttraining's binary_logloss: 0.520886\n",
      "[327]\ttraining's binary_logloss: 0.5207\n",
      "[328]\ttraining's binary_logloss: 0.520507\n",
      "[329]\ttraining's binary_logloss: 0.520313\n",
      "[330]\ttraining's binary_logloss: 0.520131\n",
      "[331]\ttraining's binary_logloss: 0.519951\n",
      "[332]\ttraining's binary_logloss: 0.519779\n",
      "[333]\ttraining's binary_logloss: 0.519603\n",
      "[334]\ttraining's binary_logloss: 0.519389\n",
      "[335]\ttraining's binary_logloss: 0.519187\n",
      "[336]\ttraining's binary_logloss: 0.518959\n",
      "[337]\ttraining's binary_logloss: 0.518733\n",
      "[338]\ttraining's binary_logloss: 0.518519\n",
      "[339]\ttraining's binary_logloss: 0.518293\n",
      "[340]\ttraining's binary_logloss: 0.518082\n",
      "[341]\ttraining's binary_logloss: 0.51791\n",
      "[342]\ttraining's binary_logloss: 0.517771\n",
      "[343]\ttraining's binary_logloss: 0.517631\n",
      "[344]\ttraining's binary_logloss: 0.517496\n",
      "[345]\ttraining's binary_logloss: 0.517352\n",
      "[346]\ttraining's binary_logloss: 0.517182\n",
      "[347]\ttraining's binary_logloss: 0.517017\n",
      "[348]\ttraining's binary_logloss: 0.516846\n",
      "[349]\ttraining's binary_logloss: 0.516684\n",
      "[350]\ttraining's binary_logloss: 0.516534\n",
      "[351]\ttraining's binary_logloss: 0.516316\n",
      "[352]\ttraining's binary_logloss: 0.516112\n",
      "[353]\ttraining's binary_logloss: 0.515915\n",
      "[354]\ttraining's binary_logloss: 0.515692\n",
      "[355]\ttraining's binary_logloss: 0.515483\n",
      "[356]\ttraining's binary_logloss: 0.515278\n",
      "[357]\ttraining's binary_logloss: 0.515065\n",
      "[358]\ttraining's binary_logloss: 0.514885\n",
      "[359]\ttraining's binary_logloss: 0.514692\n",
      "[360]\ttraining's binary_logloss: 0.514485\n",
      "[361]\ttraining's binary_logloss: 0.51427\n",
      "[362]\ttraining's binary_logloss: 0.514038\n",
      "[363]\ttraining's binary_logloss: 0.513826\n",
      "[364]\ttraining's binary_logloss: 0.513619\n",
      "[365]\ttraining's binary_logloss: 0.513412\n",
      "[366]\ttraining's binary_logloss: 0.513199\n",
      "[367]\ttraining's binary_logloss: 0.513011\n",
      "[368]\ttraining's binary_logloss: 0.512823\n",
      "[369]\ttraining's binary_logloss: 0.512643\n",
      "[370]\ttraining's binary_logloss: 0.512503\n",
      "[371]\ttraining's binary_logloss: 0.512343\n",
      "[372]\ttraining's binary_logloss: 0.512193\n",
      "[373]\ttraining's binary_logloss: 0.512055\n",
      "[374]\ttraining's binary_logloss: 0.511914\n",
      "[375]\ttraining's binary_logloss: 0.511793\n",
      "[376]\ttraining's binary_logloss: 0.511606\n",
      "[377]\ttraining's binary_logloss: 0.511418\n",
      "[378]\ttraining's binary_logloss: 0.511237\n",
      "[379]\ttraining's binary_logloss: 0.511054\n",
      "[380]\ttraining's binary_logloss: 0.510854\n",
      "[381]\ttraining's binary_logloss: 0.51067\n",
      "[382]\ttraining's binary_logloss: 0.510496\n",
      "[383]\ttraining's binary_logloss: 0.510309\n",
      "[384]\ttraining's binary_logloss: 0.510162\n",
      "[385]\ttraining's binary_logloss: 0.510011\n",
      "[386]\ttraining's binary_logloss: 0.509812\n",
      "[387]\ttraining's binary_logloss: 0.509603\n",
      "[388]\ttraining's binary_logloss: 0.509384\n",
      "[389]\ttraining's binary_logloss: 0.509176\n",
      "[390]\ttraining's binary_logloss: 0.509011\n",
      "[391]\ttraining's binary_logloss: 0.508804\n",
      "[392]\ttraining's binary_logloss: 0.508603\n",
      "[393]\ttraining's binary_logloss: 0.508401\n",
      "[394]\ttraining's binary_logloss: 0.508211\n",
      "[395]\ttraining's binary_logloss: 0.507989\n",
      "[396]\ttraining's binary_logloss: 0.507791\n",
      "[397]\ttraining's binary_logloss: 0.5076\n",
      "[398]\ttraining's binary_logloss: 0.50739\n",
      "[399]\ttraining's binary_logloss: 0.507209\n",
      "[400]\ttraining's binary_logloss: 0.507027\n",
      "[401]\ttraining's binary_logloss: 0.506798\n",
      "[402]\ttraining's binary_logloss: 0.506596\n",
      "[403]\ttraining's binary_logloss: 0.506401\n",
      "[404]\ttraining's binary_logloss: 0.506171\n",
      "[405]\ttraining's binary_logloss: 0.505922\n",
      "[406]\ttraining's binary_logloss: 0.505735\n",
      "[407]\ttraining's binary_logloss: 0.505554\n",
      "[408]\ttraining's binary_logloss: 0.505364\n",
      "[409]\ttraining's binary_logloss: 0.505185\n",
      "[410]\ttraining's binary_logloss: 0.505009\n",
      "[411]\ttraining's binary_logloss: 0.504836\n",
      "[412]\ttraining's binary_logloss: 0.50464\n",
      "[413]\ttraining's binary_logloss: 0.504457\n",
      "[414]\ttraining's binary_logloss: 0.50428\n",
      "[415]\ttraining's binary_logloss: 0.504108\n",
      "[416]\ttraining's binary_logloss: 0.503939\n",
      "[417]\ttraining's binary_logloss: 0.503794\n",
      "[418]\ttraining's binary_logloss: 0.503594\n",
      "[419]\ttraining's binary_logloss: 0.503433\n",
      "[420]\ttraining's binary_logloss: 0.503245\n",
      "[421]\ttraining's binary_logloss: 0.503087\n",
      "[422]\ttraining's binary_logloss: 0.502949\n",
      "[423]\ttraining's binary_logloss: 0.502828\n",
      "[424]\ttraining's binary_logloss: 0.502706\n",
      "[425]\ttraining's binary_logloss: 0.502549\n",
      "[426]\ttraining's binary_logloss: 0.50234\n",
      "[427]\ttraining's binary_logloss: 0.502195\n",
      "[428]\ttraining's binary_logloss: 0.502035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[429]\ttraining's binary_logloss: 0.501878\n",
      "[430]\ttraining's binary_logloss: 0.501728\n",
      "[431]\ttraining's binary_logloss: 0.501486\n",
      "[432]\ttraining's binary_logloss: 0.501298\n",
      "[433]\ttraining's binary_logloss: 0.501058\n",
      "[434]\ttraining's binary_logloss: 0.50082\n",
      "[435]\ttraining's binary_logloss: 0.500622\n",
      "[436]\ttraining's binary_logloss: 0.500451\n",
      "[437]\ttraining's binary_logloss: 0.500277\n",
      "[438]\ttraining's binary_logloss: 0.500128\n",
      "[439]\ttraining's binary_logloss: 0.499977\n",
      "[440]\ttraining's binary_logloss: 0.499833\n",
      "[441]\ttraining's binary_logloss: 0.499619\n",
      "[442]\ttraining's binary_logloss: 0.499418\n",
      "[443]\ttraining's binary_logloss: 0.499214\n",
      "[444]\ttraining's binary_logloss: 0.499017\n",
      "[445]\ttraining's binary_logloss: 0.498832\n",
      "[446]\ttraining's binary_logloss: 0.498623\n",
      "[447]\ttraining's binary_logloss: 0.498456\n",
      "[448]\ttraining's binary_logloss: 0.498256\n",
      "[449]\ttraining's binary_logloss: 0.498055\n",
      "[450]\ttraining's binary_logloss: 0.497856\n",
      "[451]\ttraining's binary_logloss: 0.497687\n",
      "[452]\ttraining's binary_logloss: 0.497517\n",
      "[453]\ttraining's binary_logloss: 0.497349\n",
      "[454]\ttraining's binary_logloss: 0.49718\n",
      "[455]\ttraining's binary_logloss: 0.497043\n",
      "[456]\ttraining's binary_logloss: 0.496874\n",
      "[457]\ttraining's binary_logloss: 0.496713\n",
      "[458]\ttraining's binary_logloss: 0.496538\n",
      "[459]\ttraining's binary_logloss: 0.496382\n",
      "[460]\ttraining's binary_logloss: 0.496239\n",
      "[461]\ttraining's binary_logloss: 0.496064\n",
      "[462]\ttraining's binary_logloss: 0.495907\n",
      "[463]\ttraining's binary_logloss: 0.495756\n",
      "[464]\ttraining's binary_logloss: 0.495568\n",
      "[465]\ttraining's binary_logloss: 0.495373\n",
      "[466]\ttraining's binary_logloss: 0.495203\n",
      "[467]\ttraining's binary_logloss: 0.495011\n",
      "[468]\ttraining's binary_logloss: 0.494837\n",
      "[469]\ttraining's binary_logloss: 0.49466\n",
      "[470]\ttraining's binary_logloss: 0.494474\n",
      "[471]\ttraining's binary_logloss: 0.49435\n",
      "[472]\ttraining's binary_logloss: 0.494197\n",
      "[473]\ttraining's binary_logloss: 0.494059\n",
      "[474]\ttraining's binary_logloss: 0.49393\n",
      "[475]\ttraining's binary_logloss: 0.493796\n",
      "[476]\ttraining's binary_logloss: 0.49358\n",
      "[477]\ttraining's binary_logloss: 0.493395\n",
      "[478]\ttraining's binary_logloss: 0.493219\n",
      "[479]\ttraining's binary_logloss: 0.493037\n",
      "[480]\ttraining's binary_logloss: 0.492827\n",
      "[481]\ttraining's binary_logloss: 0.49264\n",
      "[482]\ttraining's binary_logloss: 0.492466\n",
      "[483]\ttraining's binary_logloss: 0.492273\n",
      "[484]\ttraining's binary_logloss: 0.492096\n",
      "[485]\ttraining's binary_logloss: 0.49191\n",
      "[486]\ttraining's binary_logloss: 0.491706\n",
      "[487]\ttraining's binary_logloss: 0.491488\n",
      "[488]\ttraining's binary_logloss: 0.491284\n",
      "[489]\ttraining's binary_logloss: 0.491068\n",
      "[490]\ttraining's binary_logloss: 0.490856\n",
      "[491]\ttraining's binary_logloss: 0.490673\n",
      "[492]\ttraining's binary_logloss: 0.490496\n",
      "[493]\ttraining's binary_logloss: 0.490321\n",
      "[494]\ttraining's binary_logloss: 0.490149\n",
      "[495]\ttraining's binary_logloss: 0.489935\n",
      "[496]\ttraining's binary_logloss: 0.489745\n",
      "[497]\ttraining's binary_logloss: 0.489559\n",
      "[498]\ttraining's binary_logloss: 0.489335\n",
      "[499]\ttraining's binary_logloss: 0.489158\n",
      "[500]\ttraining's binary_logloss: 0.489002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.617265\n",
      "[2]\ttraining's binary_logloss: 0.615794\n",
      "[3]\ttraining's binary_logloss: 0.614376\n",
      "[4]\ttraining's binary_logloss: 0.613028\n",
      "[5]\ttraining's binary_logloss: 0.61168\n",
      "[6]\ttraining's binary_logloss: 0.610342\n",
      "[7]\ttraining's binary_logloss: 0.609054\n",
      "[8]\ttraining's binary_logloss: 0.60778\n",
      "[9]\ttraining's binary_logloss: 0.60656\n",
      "[10]\ttraining's binary_logloss: 0.60534\n",
      "[11]\ttraining's binary_logloss: 0.604159\n",
      "[12]\ttraining's binary_logloss: 0.603073\n",
      "[13]\ttraining's binary_logloss: 0.601912\n",
      "[14]\ttraining's binary_logloss: 0.600959\n",
      "[15]\ttraining's binary_logloss: 0.599854\n",
      "[16]\ttraining's binary_logloss: 0.598877\n",
      "[17]\ttraining's binary_logloss: 0.597951\n",
      "[18]\ttraining's binary_logloss: 0.597083\n",
      "[19]\ttraining's binary_logloss: 0.596198\n",
      "[20]\ttraining's binary_logloss: 0.595333\n",
      "[21]\ttraining's binary_logloss: 0.594447\n",
      "[22]\ttraining's binary_logloss: 0.593611\n",
      "[23]\ttraining's binary_logloss: 0.592794\n",
      "[24]\ttraining's binary_logloss: 0.591974\n",
      "[25]\ttraining's binary_logloss: 0.591198\n",
      "[26]\ttraining's binary_logloss: 0.590477\n",
      "[27]\ttraining's binary_logloss: 0.589744\n",
      "[28]\ttraining's binary_logloss: 0.589034\n",
      "[29]\ttraining's binary_logloss: 0.588418\n",
      "[30]\ttraining's binary_logloss: 0.587719\n",
      "[31]\ttraining's binary_logloss: 0.586997\n",
      "[32]\ttraining's binary_logloss: 0.5863\n",
      "[33]\ttraining's binary_logloss: 0.585614\n",
      "[34]\ttraining's binary_logloss: 0.584986\n",
      "[35]\ttraining's binary_logloss: 0.584341\n",
      "[36]\ttraining's binary_logloss: 0.58372\n",
      "[37]\ttraining's binary_logloss: 0.583142\n",
      "[38]\ttraining's binary_logloss: 0.582559\n",
      "[39]\ttraining's binary_logloss: 0.581987\n",
      "[40]\ttraining's binary_logloss: 0.581434\n",
      "[41]\ttraining's binary_logloss: 0.580821\n",
      "[42]\ttraining's binary_logloss: 0.580354\n",
      "[43]\ttraining's binary_logloss: 0.579783\n",
      "[44]\ttraining's binary_logloss: 0.57928\n",
      "[45]\ttraining's binary_logloss: 0.578839\n",
      "[46]\ttraining's binary_logloss: 0.578375\n",
      "[47]\ttraining's binary_logloss: 0.57794\n",
      "[48]\ttraining's binary_logloss: 0.577474\n",
      "[49]\ttraining's binary_logloss: 0.577031\n",
      "[50]\ttraining's binary_logloss: 0.576566\n",
      "[51]\ttraining's binary_logloss: 0.57609\n",
      "[52]\ttraining's binary_logloss: 0.575594\n",
      "[53]\ttraining's binary_logloss: 0.575157\n",
      "[54]\ttraining's binary_logloss: 0.574761\n",
      "[55]\ttraining's binary_logloss: 0.574396\n",
      "[56]\ttraining's binary_logloss: 0.574044\n",
      "[57]\ttraining's binary_logloss: 0.573684\n",
      "[58]\ttraining's binary_logloss: 0.573367\n",
      "[59]\ttraining's binary_logloss: 0.573024\n",
      "[60]\ttraining's binary_logloss: 0.572704\n",
      "[61]\ttraining's binary_logloss: 0.572337\n",
      "[62]\ttraining's binary_logloss: 0.572024\n",
      "[63]\ttraining's binary_logloss: 0.571691\n",
      "[64]\ttraining's binary_logloss: 0.571372\n",
      "[65]\ttraining's binary_logloss: 0.571067\n",
      "[66]\ttraining's binary_logloss: 0.570732\n",
      "[67]\ttraining's binary_logloss: 0.570436\n",
      "[68]\ttraining's binary_logloss: 0.570086\n",
      "[69]\ttraining's binary_logloss: 0.569763\n",
      "[70]\ttraining's binary_logloss: 0.569428\n",
      "[71]\ttraining's binary_logloss: 0.569173\n",
      "[72]\ttraining's binary_logloss: 0.568827\n",
      "[73]\ttraining's binary_logloss: 0.568513\n",
      "[74]\ttraining's binary_logloss: 0.568196\n",
      "[75]\ttraining's binary_logloss: 0.567885\n",
      "[76]\ttraining's binary_logloss: 0.5677\n",
      "[77]\ttraining's binary_logloss: 0.567405\n",
      "[78]\ttraining's binary_logloss: 0.567181\n",
      "[79]\ttraining's binary_logloss: 0.566899\n",
      "[80]\ttraining's binary_logloss: 0.566591\n",
      "[81]\ttraining's binary_logloss: 0.566319\n",
      "[82]\ttraining's binary_logloss: 0.566049\n",
      "[83]\ttraining's binary_logloss: 0.565806\n",
      "[84]\ttraining's binary_logloss: 0.565549\n",
      "[85]\ttraining's binary_logloss: 0.565308\n",
      "[86]\ttraining's binary_logloss: 0.565123\n",
      "[87]\ttraining's binary_logloss: 0.564902\n",
      "[88]\ttraining's binary_logloss: 0.564687\n",
      "[89]\ttraining's binary_logloss: 0.564478\n",
      "[90]\ttraining's binary_logloss: 0.564281\n",
      "[91]\ttraining's binary_logloss: 0.564055\n",
      "[92]\ttraining's binary_logloss: 0.563841\n",
      "[93]\ttraining's binary_logloss: 0.563585\n",
      "[94]\ttraining's binary_logloss: 0.563368\n",
      "[95]\ttraining's binary_logloss: 0.563141\n",
      "[96]\ttraining's binary_logloss: 0.562976\n",
      "[97]\ttraining's binary_logloss: 0.562843\n",
      "[98]\ttraining's binary_logloss: 0.562652\n",
      "[99]\ttraining's binary_logloss: 0.562446\n",
      "[100]\ttraining's binary_logloss: 0.562244\n",
      "[101]\ttraining's binary_logloss: 0.56205\n",
      "[102]\ttraining's binary_logloss: 0.561879\n",
      "[103]\ttraining's binary_logloss: 0.561675\n",
      "[104]\ttraining's binary_logloss: 0.561504\n",
      "[105]\ttraining's binary_logloss: 0.561334\n",
      "[106]\ttraining's binary_logloss: 0.561152\n",
      "[107]\ttraining's binary_logloss: 0.560944\n",
      "[108]\ttraining's binary_logloss: 0.560725\n",
      "[109]\ttraining's binary_logloss: 0.560546\n",
      "[110]\ttraining's binary_logloss: 0.56036\n",
      "[111]\ttraining's binary_logloss: 0.560241\n",
      "[112]\ttraining's binary_logloss: 0.560051\n",
      "[113]\ttraining's binary_logloss: 0.559853\n",
      "[114]\ttraining's binary_logloss: 0.559739\n",
      "[115]\ttraining's binary_logloss: 0.559564\n",
      "[116]\ttraining's binary_logloss: 0.55936\n",
      "[117]\ttraining's binary_logloss: 0.559148\n",
      "[118]\ttraining's binary_logloss: 0.558981\n",
      "[119]\ttraining's binary_logloss: 0.558803\n",
      "[120]\ttraining's binary_logloss: 0.558665\n",
      "[121]\ttraining's binary_logloss: 0.558522\n",
      "[122]\ttraining's binary_logloss: 0.558376\n",
      "[123]\ttraining's binary_logloss: 0.558235\n",
      "[124]\ttraining's binary_logloss: 0.558057\n",
      "[125]\ttraining's binary_logloss: 0.557934\n",
      "[126]\ttraining's binary_logloss: 0.557716\n",
      "[127]\ttraining's binary_logloss: 0.557544\n",
      "[128]\ttraining's binary_logloss: 0.557367\n",
      "[129]\ttraining's binary_logloss: 0.557196\n",
      "[130]\ttraining's binary_logloss: 0.557049\n",
      "[131]\ttraining's binary_logloss: 0.556839\n",
      "[132]\ttraining's binary_logloss: 0.556678\n",
      "[133]\ttraining's binary_logloss: 0.556521\n",
      "[134]\ttraining's binary_logloss: 0.556345\n",
      "[135]\ttraining's binary_logloss: 0.556183\n",
      "[136]\ttraining's binary_logloss: 0.555976\n",
      "[137]\ttraining's binary_logloss: 0.555791\n",
      "[138]\ttraining's binary_logloss: 0.555633\n",
      "[139]\ttraining's binary_logloss: 0.555435\n",
      "[140]\ttraining's binary_logloss: 0.555277\n",
      "[141]\ttraining's binary_logloss: 0.555106\n",
      "[142]\ttraining's binary_logloss: 0.554943\n",
      "[143]\ttraining's binary_logloss: 0.55476\n",
      "[144]\ttraining's binary_logloss: 0.554555\n",
      "[145]\ttraining's binary_logloss: 0.554375\n",
      "[146]\ttraining's binary_logloss: 0.55427\n",
      "[147]\ttraining's binary_logloss: 0.554071\n",
      "[148]\ttraining's binary_logloss: 0.55386\n",
      "[149]\ttraining's binary_logloss: 0.553724\n",
      "[150]\ttraining's binary_logloss: 0.553535\n",
      "[151]\ttraining's binary_logloss: 0.553399\n",
      "[152]\ttraining's binary_logloss: 0.553266\n",
      "[153]\ttraining's binary_logloss: 0.553152\n",
      "[154]\ttraining's binary_logloss: 0.553001\n",
      "[155]\ttraining's binary_logloss: 0.552881\n",
      "[156]\ttraining's binary_logloss: 0.552679\n",
      "[157]\ttraining's binary_logloss: 0.552491\n",
      "[158]\ttraining's binary_logloss: 0.552335\n",
      "[159]\ttraining's binary_logloss: 0.552145\n",
      "[160]\ttraining's binary_logloss: 0.551971\n",
      "[161]\ttraining's binary_logloss: 0.551804\n",
      "[162]\ttraining's binary_logloss: 0.551651\n",
      "[163]\ttraining's binary_logloss: 0.551485\n",
      "[164]\ttraining's binary_logloss: 0.551356\n",
      "[165]\ttraining's binary_logloss: 0.551196\n",
      "[166]\ttraining's binary_logloss: 0.551049\n",
      "[167]\ttraining's binary_logloss: 0.550878\n",
      "[168]\ttraining's binary_logloss: 0.550676\n",
      "[169]\ttraining's binary_logloss: 0.550469\n",
      "[170]\ttraining's binary_logloss: 0.550267\n",
      "[171]\ttraining's binary_logloss: 0.550099\n",
      "[172]\ttraining's binary_logloss: 0.549941\n",
      "[173]\ttraining's binary_logloss: 0.549798\n",
      "[174]\ttraining's binary_logloss: 0.549657\n",
      "[175]\ttraining's binary_logloss: 0.549506\n",
      "[176]\ttraining's binary_logloss: 0.54934\n",
      "[177]\ttraining's binary_logloss: 0.549184\n",
      "[178]\ttraining's binary_logloss: 0.549008\n",
      "[179]\ttraining's binary_logloss: 0.548869\n",
      "[180]\ttraining's binary_logloss: 0.548701\n",
      "[181]\ttraining's binary_logloss: 0.548541\n",
      "[182]\ttraining's binary_logloss: 0.548359\n",
      "[183]\ttraining's binary_logloss: 0.548168\n",
      "[184]\ttraining's binary_logloss: 0.54802\n",
      "[185]\ttraining's binary_logloss: 0.54784\n",
      "[186]\ttraining's binary_logloss: 0.547717\n",
      "[187]\ttraining's binary_logloss: 0.547578\n",
      "[188]\ttraining's binary_logloss: 0.547428\n",
      "[189]\ttraining's binary_logloss: 0.547319\n",
      "[190]\ttraining's binary_logloss: 0.547185\n",
      "[191]\ttraining's binary_logloss: 0.547006\n",
      "[192]\ttraining's binary_logloss: 0.546833\n",
      "[193]\ttraining's binary_logloss: 0.546683\n",
      "[194]\ttraining's binary_logloss: 0.546527\n",
      "[195]\ttraining's binary_logloss: 0.54635\n",
      "[196]\ttraining's binary_logloss: 0.546151\n",
      "[197]\ttraining's binary_logloss: 0.545951\n",
      "[198]\ttraining's binary_logloss: 0.545795\n",
      "[199]\ttraining's binary_logloss: 0.545622\n",
      "[200]\ttraining's binary_logloss: 0.545454\n",
      "[201]\ttraining's binary_logloss: 0.545275\n",
      "[202]\ttraining's binary_logloss: 0.545126\n",
      "[203]\ttraining's binary_logloss: 0.544942\n",
      "[204]\ttraining's binary_logloss: 0.544767\n",
      "[205]\ttraining's binary_logloss: 0.544625\n",
      "[206]\ttraining's binary_logloss: 0.544495\n",
      "[207]\ttraining's binary_logloss: 0.544372\n",
      "[208]\ttraining's binary_logloss: 0.544237\n",
      "[209]\ttraining's binary_logloss: 0.544091\n",
      "[210]\ttraining's binary_logloss: 0.543967\n",
      "[211]\ttraining's binary_logloss: 0.543841\n",
      "[212]\ttraining's binary_logloss: 0.543701\n",
      "[213]\ttraining's binary_logloss: 0.543549\n",
      "[214]\ttraining's binary_logloss: 0.543385\n",
      "[215]\ttraining's binary_logloss: 0.543276\n",
      "[216]\ttraining's binary_logloss: 0.543089\n",
      "[217]\ttraining's binary_logloss: 0.542893\n",
      "[218]\ttraining's binary_logloss: 0.542689\n",
      "[219]\ttraining's binary_logloss: 0.542529\n",
      "[220]\ttraining's binary_logloss: 0.542333\n",
      "[221]\ttraining's binary_logloss: 0.542147\n",
      "[222]\ttraining's binary_logloss: 0.54195\n",
      "[223]\ttraining's binary_logloss: 0.541761\n",
      "[224]\ttraining's binary_logloss: 0.541574\n",
      "[225]\ttraining's binary_logloss: 0.541409\n",
      "[226]\ttraining's binary_logloss: 0.541216\n",
      "[227]\ttraining's binary_logloss: 0.541031\n",
      "[228]\ttraining's binary_logloss: 0.540837\n",
      "[229]\ttraining's binary_logloss: 0.540653\n",
      "[230]\ttraining's binary_logloss: 0.540479\n",
      "[231]\ttraining's binary_logloss: 0.540321\n",
      "[232]\ttraining's binary_logloss: 0.540176\n",
      "[233]\ttraining's binary_logloss: 0.540036\n",
      "[234]\ttraining's binary_logloss: 0.539888\n",
      "[235]\ttraining's binary_logloss: 0.539736\n",
      "[236]\ttraining's binary_logloss: 0.539567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[237]\ttraining's binary_logloss: 0.539418\n",
      "[238]\ttraining's binary_logloss: 0.539252\n",
      "[239]\ttraining's binary_logloss: 0.539092\n",
      "[240]\ttraining's binary_logloss: 0.538938\n",
      "[241]\ttraining's binary_logloss: 0.538748\n",
      "[242]\ttraining's binary_logloss: 0.538558\n",
      "[243]\ttraining's binary_logloss: 0.538369\n",
      "[244]\ttraining's binary_logloss: 0.538187\n",
      "[245]\ttraining's binary_logloss: 0.538015\n",
      "[246]\ttraining's binary_logloss: 0.537825\n",
      "[247]\ttraining's binary_logloss: 0.537606\n",
      "[248]\ttraining's binary_logloss: 0.537393\n",
      "[249]\ttraining's binary_logloss: 0.53721\n",
      "[250]\ttraining's binary_logloss: 0.536999\n",
      "[251]\ttraining's binary_logloss: 0.53682\n",
      "[252]\ttraining's binary_logloss: 0.53664\n",
      "[253]\ttraining's binary_logloss: 0.536468\n",
      "[254]\ttraining's binary_logloss: 0.536299\n",
      "[255]\ttraining's binary_logloss: 0.536118\n",
      "[256]\ttraining's binary_logloss: 0.535966\n",
      "[257]\ttraining's binary_logloss: 0.535816\n",
      "[258]\ttraining's binary_logloss: 0.535627\n",
      "[259]\ttraining's binary_logloss: 0.535446\n",
      "[260]\ttraining's binary_logloss: 0.535282\n",
      "[261]\ttraining's binary_logloss: 0.535092\n",
      "[262]\ttraining's binary_logloss: 0.534921\n",
      "[263]\ttraining's binary_logloss: 0.534733\n",
      "[264]\ttraining's binary_logloss: 0.534561\n",
      "[265]\ttraining's binary_logloss: 0.534383\n",
      "[266]\ttraining's binary_logloss: 0.534227\n",
      "[267]\ttraining's binary_logloss: 0.53405\n",
      "[268]\ttraining's binary_logloss: 0.533899\n",
      "[269]\ttraining's binary_logloss: 0.533723\n",
      "[270]\ttraining's binary_logloss: 0.533552\n",
      "[271]\ttraining's binary_logloss: 0.53336\n",
      "[272]\ttraining's binary_logloss: 0.533156\n",
      "[273]\ttraining's binary_logloss: 0.532941\n",
      "[274]\ttraining's binary_logloss: 0.532758\n",
      "[275]\ttraining's binary_logloss: 0.532575\n",
      "[276]\ttraining's binary_logloss: 0.532384\n",
      "[277]\ttraining's binary_logloss: 0.532183\n",
      "[278]\ttraining's binary_logloss: 0.531992\n",
      "[279]\ttraining's binary_logloss: 0.531802\n",
      "[280]\ttraining's binary_logloss: 0.531596\n",
      "[281]\ttraining's binary_logloss: 0.531426\n",
      "[282]\ttraining's binary_logloss: 0.531252\n",
      "[283]\ttraining's binary_logloss: 0.531069\n",
      "[284]\ttraining's binary_logloss: 0.530899\n",
      "[285]\ttraining's binary_logloss: 0.530746\n",
      "[286]\ttraining's binary_logloss: 0.530577\n",
      "[287]\ttraining's binary_logloss: 0.530389\n",
      "[288]\ttraining's binary_logloss: 0.530223\n",
      "[289]\ttraining's binary_logloss: 0.530028\n",
      "[290]\ttraining's binary_logloss: 0.529839\n",
      "[291]\ttraining's binary_logloss: 0.52967\n",
      "[292]\ttraining's binary_logloss: 0.529478\n",
      "[293]\ttraining's binary_logloss: 0.529274\n",
      "[294]\ttraining's binary_logloss: 0.529097\n",
      "[295]\ttraining's binary_logloss: 0.528892\n",
      "[296]\ttraining's binary_logloss: 0.528701\n",
      "[297]\ttraining's binary_logloss: 0.528522\n",
      "[298]\ttraining's binary_logloss: 0.528346\n",
      "[299]\ttraining's binary_logloss: 0.52814\n",
      "[300]\ttraining's binary_logloss: 0.527957\n",
      "[301]\ttraining's binary_logloss: 0.527757\n",
      "[302]\ttraining's binary_logloss: 0.527557\n",
      "[303]\ttraining's binary_logloss: 0.527361\n",
      "[304]\ttraining's binary_logloss: 0.527151\n",
      "[305]\ttraining's binary_logloss: 0.52694\n",
      "[306]\ttraining's binary_logloss: 0.526736\n",
      "[307]\ttraining's binary_logloss: 0.526532\n",
      "[308]\ttraining's binary_logloss: 0.526332\n",
      "[309]\ttraining's binary_logloss: 0.526168\n",
      "[310]\ttraining's binary_logloss: 0.525989\n",
      "[311]\ttraining's binary_logloss: 0.525785\n",
      "[312]\ttraining's binary_logloss: 0.525589\n",
      "[313]\ttraining's binary_logloss: 0.525399\n",
      "[314]\ttraining's binary_logloss: 0.525205\n",
      "[315]\ttraining's binary_logloss: 0.525018\n",
      "[316]\ttraining's binary_logloss: 0.524822\n",
      "[317]\ttraining's binary_logloss: 0.524611\n",
      "[318]\ttraining's binary_logloss: 0.524406\n",
      "[319]\ttraining's binary_logloss: 0.524195\n",
      "[320]\ttraining's binary_logloss: 0.524004\n",
      "[321]\ttraining's binary_logloss: 0.523817\n",
      "[322]\ttraining's binary_logloss: 0.523652\n",
      "[323]\ttraining's binary_logloss: 0.523474\n",
      "[324]\ttraining's binary_logloss: 0.523309\n",
      "[325]\ttraining's binary_logloss: 0.523146\n",
      "[326]\ttraining's binary_logloss: 0.522977\n",
      "[327]\ttraining's binary_logloss: 0.522805\n",
      "[328]\ttraining's binary_logloss: 0.522624\n",
      "[329]\ttraining's binary_logloss: 0.522448\n",
      "[330]\ttraining's binary_logloss: 0.522281\n",
      "[331]\ttraining's binary_logloss: 0.522083\n",
      "[332]\ttraining's binary_logloss: 0.521885\n",
      "[333]\ttraining's binary_logloss: 0.521673\n",
      "[334]\ttraining's binary_logloss: 0.521487\n",
      "[335]\ttraining's binary_logloss: 0.521276\n",
      "[336]\ttraining's binary_logloss: 0.521078\n",
      "[337]\ttraining's binary_logloss: 0.520893\n",
      "[338]\ttraining's binary_logloss: 0.52069\n",
      "[339]\ttraining's binary_logloss: 0.5205\n",
      "[340]\ttraining's binary_logloss: 0.520319\n",
      "[341]\ttraining's binary_logloss: 0.520153\n",
      "[342]\ttraining's binary_logloss: 0.519977\n",
      "[343]\ttraining's binary_logloss: 0.519809\n",
      "[344]\ttraining's binary_logloss: 0.519675\n",
      "[345]\ttraining's binary_logloss: 0.51951\n",
      "[346]\ttraining's binary_logloss: 0.519347\n",
      "[347]\ttraining's binary_logloss: 0.51917\n",
      "[348]\ttraining's binary_logloss: 0.519015\n",
      "[349]\ttraining's binary_logloss: 0.518854\n",
      "[350]\ttraining's binary_logloss: 0.518709\n",
      "[351]\ttraining's binary_logloss: 0.518497\n",
      "[352]\ttraining's binary_logloss: 0.518306\n",
      "[353]\ttraining's binary_logloss: 0.518095\n",
      "[354]\ttraining's binary_logloss: 0.517873\n",
      "[355]\ttraining's binary_logloss: 0.517684\n",
      "[356]\ttraining's binary_logloss: 0.517505\n",
      "[357]\ttraining's binary_logloss: 0.517305\n",
      "[358]\ttraining's binary_logloss: 0.5171\n",
      "[359]\ttraining's binary_logloss: 0.516899\n",
      "[360]\ttraining's binary_logloss: 0.516717\n",
      "[361]\ttraining's binary_logloss: 0.516525\n",
      "[362]\ttraining's binary_logloss: 0.51632\n",
      "[363]\ttraining's binary_logloss: 0.51612\n",
      "[364]\ttraining's binary_logloss: 0.515924\n",
      "[365]\ttraining's binary_logloss: 0.515673\n",
      "[366]\ttraining's binary_logloss: 0.515526\n",
      "[367]\ttraining's binary_logloss: 0.515344\n",
      "[368]\ttraining's binary_logloss: 0.515157\n",
      "[369]\ttraining's binary_logloss: 0.514982\n",
      "[370]\ttraining's binary_logloss: 0.514812\n",
      "[371]\ttraining's binary_logloss: 0.514608\n",
      "[372]\ttraining's binary_logloss: 0.514407\n",
      "[373]\ttraining's binary_logloss: 0.514221\n",
      "[374]\ttraining's binary_logloss: 0.514027\n",
      "[375]\ttraining's binary_logloss: 0.513856\n",
      "[376]\ttraining's binary_logloss: 0.51364\n",
      "[377]\ttraining's binary_logloss: 0.51343\n",
      "[378]\ttraining's binary_logloss: 0.513222\n",
      "[379]\ttraining's binary_logloss: 0.513046\n",
      "[380]\ttraining's binary_logloss: 0.512848\n",
      "[381]\ttraining's binary_logloss: 0.512665\n",
      "[382]\ttraining's binary_logloss: 0.512489\n",
      "[383]\ttraining's binary_logloss: 0.512296\n",
      "[384]\ttraining's binary_logloss: 0.512112\n",
      "[385]\ttraining's binary_logloss: 0.511922\n",
      "[386]\ttraining's binary_logloss: 0.511719\n",
      "[387]\ttraining's binary_logloss: 0.511559\n",
      "[388]\ttraining's binary_logloss: 0.51135\n",
      "[389]\ttraining's binary_logloss: 0.511154\n",
      "[390]\ttraining's binary_logloss: 0.51095\n",
      "[391]\ttraining's binary_logloss: 0.510761\n",
      "[392]\ttraining's binary_logloss: 0.510575\n",
      "[393]\ttraining's binary_logloss: 0.510385\n",
      "[394]\ttraining's binary_logloss: 0.510198\n",
      "[395]\ttraining's binary_logloss: 0.510004\n",
      "[396]\ttraining's binary_logloss: 0.509812\n",
      "[397]\ttraining's binary_logloss: 0.509624\n",
      "[398]\ttraining's binary_logloss: 0.509431\n",
      "[399]\ttraining's binary_logloss: 0.509241\n",
      "[400]\ttraining's binary_logloss: 0.509061\n",
      "[401]\ttraining's binary_logloss: 0.508851\n",
      "[402]\ttraining's binary_logloss: 0.508657\n",
      "[403]\ttraining's binary_logloss: 0.508448\n",
      "[404]\ttraining's binary_logloss: 0.508267\n",
      "[405]\ttraining's binary_logloss: 0.50808\n",
      "[406]\ttraining's binary_logloss: 0.507902\n",
      "[407]\ttraining's binary_logloss: 0.507721\n",
      "[408]\ttraining's binary_logloss: 0.507527\n",
      "[409]\ttraining's binary_logloss: 0.507325\n",
      "[410]\ttraining's binary_logloss: 0.507157\n",
      "[411]\ttraining's binary_logloss: 0.506996\n",
      "[412]\ttraining's binary_logloss: 0.506806\n",
      "[413]\ttraining's binary_logloss: 0.506625\n",
      "[414]\ttraining's binary_logloss: 0.50644\n",
      "[415]\ttraining's binary_logloss: 0.506251\n",
      "[416]\ttraining's binary_logloss: 0.506044\n",
      "[417]\ttraining's binary_logloss: 0.50586\n",
      "[418]\ttraining's binary_logloss: 0.50565\n",
      "[419]\ttraining's binary_logloss: 0.505468\n",
      "[420]\ttraining's binary_logloss: 0.505272\n",
      "[421]\ttraining's binary_logloss: 0.505117\n",
      "[422]\ttraining's binary_logloss: 0.50496\n",
      "[423]\ttraining's binary_logloss: 0.504795\n",
      "[424]\ttraining's binary_logloss: 0.50464\n",
      "[425]\ttraining's binary_logloss: 0.504485\n",
      "[426]\ttraining's binary_logloss: 0.504296\n",
      "[427]\ttraining's binary_logloss: 0.504108\n",
      "[428]\ttraining's binary_logloss: 0.503941\n",
      "[429]\ttraining's binary_logloss: 0.503754\n",
      "[430]\ttraining's binary_logloss: 0.503584\n",
      "[431]\ttraining's binary_logloss: 0.503418\n",
      "[432]\ttraining's binary_logloss: 0.503232\n",
      "[433]\ttraining's binary_logloss: 0.503028\n",
      "[434]\ttraining's binary_logloss: 0.502827\n",
      "[435]\ttraining's binary_logloss: 0.502607\n",
      "[436]\ttraining's binary_logloss: 0.502427\n",
      "[437]\ttraining's binary_logloss: 0.502243\n",
      "[438]\ttraining's binary_logloss: 0.50205\n",
      "[439]\ttraining's binary_logloss: 0.501891\n",
      "[440]\ttraining's binary_logloss: 0.501717\n",
      "[441]\ttraining's binary_logloss: 0.501529\n",
      "[442]\ttraining's binary_logloss: 0.501343\n",
      "[443]\ttraining's binary_logloss: 0.501152\n",
      "[444]\ttraining's binary_logloss: 0.500971\n",
      "[445]\ttraining's binary_logloss: 0.500787\n",
      "[446]\ttraining's binary_logloss: 0.50058\n",
      "[447]\ttraining's binary_logloss: 0.500377\n",
      "[448]\ttraining's binary_logloss: 0.500201\n",
      "[449]\ttraining's binary_logloss: 0.500021\n",
      "[450]\ttraining's binary_logloss: 0.499821\n",
      "[451]\ttraining's binary_logloss: 0.499653\n",
      "[452]\ttraining's binary_logloss: 0.499517\n",
      "[453]\ttraining's binary_logloss: 0.499353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[454]\ttraining's binary_logloss: 0.499223\n",
      "[455]\ttraining's binary_logloss: 0.49906\n",
      "[456]\ttraining's binary_logloss: 0.498862\n",
      "[457]\ttraining's binary_logloss: 0.498656\n",
      "[458]\ttraining's binary_logloss: 0.498413\n",
      "[459]\ttraining's binary_logloss: 0.498217\n",
      "[460]\ttraining's binary_logloss: 0.497991\n",
      "[461]\ttraining's binary_logloss: 0.497797\n",
      "[462]\ttraining's binary_logloss: 0.497655\n",
      "[463]\ttraining's binary_logloss: 0.497472\n",
      "[464]\ttraining's binary_logloss: 0.497301\n",
      "[465]\ttraining's binary_logloss: 0.497154\n",
      "[466]\ttraining's binary_logloss: 0.496919\n",
      "[467]\ttraining's binary_logloss: 0.496712\n",
      "[468]\ttraining's binary_logloss: 0.496468\n",
      "[469]\ttraining's binary_logloss: 0.496234\n",
      "[470]\ttraining's binary_logloss: 0.496004\n",
      "[471]\ttraining's binary_logloss: 0.495821\n",
      "[472]\ttraining's binary_logloss: 0.495651\n",
      "[473]\ttraining's binary_logloss: 0.495469\n",
      "[474]\ttraining's binary_logloss: 0.495299\n",
      "[475]\ttraining's binary_logloss: 0.495132\n",
      "[476]\ttraining's binary_logloss: 0.494916\n",
      "[477]\ttraining's binary_logloss: 0.4947\n",
      "[478]\ttraining's binary_logloss: 0.494494\n",
      "[479]\ttraining's binary_logloss: 0.494292\n",
      "[480]\ttraining's binary_logloss: 0.494095\n",
      "[481]\ttraining's binary_logloss: 0.493921\n",
      "[482]\ttraining's binary_logloss: 0.493733\n",
      "[483]\ttraining's binary_logloss: 0.493567\n",
      "[484]\ttraining's binary_logloss: 0.493405\n",
      "[485]\ttraining's binary_logloss: 0.493233\n",
      "[486]\ttraining's binary_logloss: 0.493058\n",
      "[487]\ttraining's binary_logloss: 0.492887\n",
      "[488]\ttraining's binary_logloss: 0.492736\n",
      "[489]\ttraining's binary_logloss: 0.492557\n",
      "[490]\ttraining's binary_logloss: 0.492358\n",
      "[491]\ttraining's binary_logloss: 0.492133\n",
      "[492]\ttraining's binary_logloss: 0.491907\n",
      "[493]\ttraining's binary_logloss: 0.491679\n",
      "[494]\ttraining's binary_logloss: 0.49146\n",
      "[495]\ttraining's binary_logloss: 0.491232\n",
      "[496]\ttraining's binary_logloss: 0.490986\n",
      "[497]\ttraining's binary_logloss: 0.490779\n",
      "[498]\ttraining's binary_logloss: 0.490559\n",
      "[499]\ttraining's binary_logloss: 0.490368\n",
      "[500]\ttraining's binary_logloss: 0.490147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613314\n",
      "[2]\ttraining's binary_logloss: 0.611819\n",
      "[3]\ttraining's binary_logloss: 0.610374\n",
      "[4]\ttraining's binary_logloss: 0.608935\n",
      "[5]\ttraining's binary_logloss: 0.607519\n",
      "[6]\ttraining's binary_logloss: 0.606157\n",
      "[7]\ttraining's binary_logloss: 0.604845\n",
      "[8]\ttraining's binary_logloss: 0.603544\n",
      "[9]\ttraining's binary_logloss: 0.602346\n",
      "[10]\ttraining's binary_logloss: 0.601148\n",
      "[11]\ttraining's binary_logloss: 0.600009\n",
      "[12]\ttraining's binary_logloss: 0.598921\n",
      "[13]\ttraining's binary_logloss: 0.59789\n",
      "[14]\ttraining's binary_logloss: 0.596861\n",
      "[15]\ttraining's binary_logloss: 0.595821\n",
      "[16]\ttraining's binary_logloss: 0.594902\n",
      "[17]\ttraining's binary_logloss: 0.593961\n",
      "[18]\ttraining's binary_logloss: 0.593038\n",
      "[19]\ttraining's binary_logloss: 0.592119\n",
      "[20]\ttraining's binary_logloss: 0.591227\n",
      "[21]\ttraining's binary_logloss: 0.590329\n",
      "[22]\ttraining's binary_logloss: 0.589479\n",
      "[23]\ttraining's binary_logloss: 0.588659\n",
      "[24]\ttraining's binary_logloss: 0.587859\n",
      "[25]\ttraining's binary_logloss: 0.587044\n",
      "[26]\ttraining's binary_logloss: 0.58626\n",
      "[27]\ttraining's binary_logloss: 0.585537\n",
      "[28]\ttraining's binary_logloss: 0.584842\n",
      "[29]\ttraining's binary_logloss: 0.584176\n",
      "[30]\ttraining's binary_logloss: 0.583485\n",
      "[31]\ttraining's binary_logloss: 0.582906\n",
      "[32]\ttraining's binary_logloss: 0.582229\n",
      "[33]\ttraining's binary_logloss: 0.581618\n",
      "[34]\ttraining's binary_logloss: 0.580983\n",
      "[35]\ttraining's binary_logloss: 0.58041\n",
      "[36]\ttraining's binary_logloss: 0.579834\n",
      "[37]\ttraining's binary_logloss: 0.579268\n",
      "[38]\ttraining's binary_logloss: 0.578755\n",
      "[39]\ttraining's binary_logloss: 0.578243\n",
      "[40]\ttraining's binary_logloss: 0.577718\n",
      "[41]\ttraining's binary_logloss: 0.577208\n",
      "[42]\ttraining's binary_logloss: 0.576711\n",
      "[43]\ttraining's binary_logloss: 0.576171\n",
      "[44]\ttraining's binary_logloss: 0.575628\n",
      "[45]\ttraining's binary_logloss: 0.575162\n",
      "[46]\ttraining's binary_logloss: 0.574617\n",
      "[47]\ttraining's binary_logloss: 0.57412\n",
      "[48]\ttraining's binary_logloss: 0.573673\n",
      "[49]\ttraining's binary_logloss: 0.573233\n",
      "[50]\ttraining's binary_logloss: 0.572872\n",
      "[51]\ttraining's binary_logloss: 0.572455\n",
      "[52]\ttraining's binary_logloss: 0.572075\n",
      "[53]\ttraining's binary_logloss: 0.571683\n",
      "[54]\ttraining's binary_logloss: 0.5713\n",
      "[55]\ttraining's binary_logloss: 0.570945\n",
      "[56]\ttraining's binary_logloss: 0.570648\n",
      "[57]\ttraining's binary_logloss: 0.570257\n",
      "[58]\ttraining's binary_logloss: 0.569859\n",
      "[59]\ttraining's binary_logloss: 0.569478\n",
      "[60]\ttraining's binary_logloss: 0.569136\n",
      "[61]\ttraining's binary_logloss: 0.568741\n",
      "[62]\ttraining's binary_logloss: 0.568455\n",
      "[63]\ttraining's binary_logloss: 0.568095\n",
      "[64]\ttraining's binary_logloss: 0.567752\n",
      "[65]\ttraining's binary_logloss: 0.567396\n",
      "[66]\ttraining's binary_logloss: 0.567051\n",
      "[67]\ttraining's binary_logloss: 0.566721\n",
      "[68]\ttraining's binary_logloss: 0.56641\n",
      "[69]\ttraining's binary_logloss: 0.566047\n",
      "[70]\ttraining's binary_logloss: 0.565784\n",
      "[71]\ttraining's binary_logloss: 0.565497\n",
      "[72]\ttraining's binary_logloss: 0.565142\n",
      "[73]\ttraining's binary_logloss: 0.564811\n",
      "[74]\ttraining's binary_logloss: 0.564471\n",
      "[75]\ttraining's binary_logloss: 0.564153\n",
      "[76]\ttraining's binary_logloss: 0.563937\n",
      "[77]\ttraining's binary_logloss: 0.563678\n",
      "[78]\ttraining's binary_logloss: 0.563473\n",
      "[79]\ttraining's binary_logloss: 0.563271\n",
      "[80]\ttraining's binary_logloss: 0.563071\n",
      "[81]\ttraining's binary_logloss: 0.562834\n",
      "[82]\ttraining's binary_logloss: 0.562572\n",
      "[83]\ttraining's binary_logloss: 0.562351\n",
      "[84]\ttraining's binary_logloss: 0.562208\n",
      "[85]\ttraining's binary_logloss: 0.56198\n",
      "[86]\ttraining's binary_logloss: 0.561771\n",
      "[87]\ttraining's binary_logloss: 0.561562\n",
      "[88]\ttraining's binary_logloss: 0.561365\n",
      "[89]\ttraining's binary_logloss: 0.561178\n",
      "[90]\ttraining's binary_logloss: 0.561016\n",
      "[91]\ttraining's binary_logloss: 0.560827\n",
      "[92]\ttraining's binary_logloss: 0.560626\n",
      "[93]\ttraining's binary_logloss: 0.560432\n",
      "[94]\ttraining's binary_logloss: 0.560287\n",
      "[95]\ttraining's binary_logloss: 0.560079\n",
      "[96]\ttraining's binary_logloss: 0.559902\n",
      "[97]\ttraining's binary_logloss: 0.55974\n",
      "[98]\ttraining's binary_logloss: 0.55956\n",
      "[99]\ttraining's binary_logloss: 0.559403\n",
      "[100]\ttraining's binary_logloss: 0.559252\n",
      "[101]\ttraining's binary_logloss: 0.559068\n",
      "[102]\ttraining's binary_logloss: 0.558854\n",
      "[103]\ttraining's binary_logloss: 0.558704\n",
      "[104]\ttraining's binary_logloss: 0.5585\n",
      "[105]\ttraining's binary_logloss: 0.558337\n",
      "[106]\ttraining's binary_logloss: 0.558205\n",
      "[107]\ttraining's binary_logloss: 0.558066\n",
      "[108]\ttraining's binary_logloss: 0.557976\n",
      "[109]\ttraining's binary_logloss: 0.557788\n",
      "[110]\ttraining's binary_logloss: 0.557602\n",
      "[111]\ttraining's binary_logloss: 0.557449\n",
      "[112]\ttraining's binary_logloss: 0.557296\n",
      "[113]\ttraining's binary_logloss: 0.557147\n",
      "[114]\ttraining's binary_logloss: 0.556997\n",
      "[115]\ttraining's binary_logloss: 0.556823\n",
      "[116]\ttraining's binary_logloss: 0.556661\n",
      "[117]\ttraining's binary_logloss: 0.556484\n",
      "[118]\ttraining's binary_logloss: 0.556345\n",
      "[119]\ttraining's binary_logloss: 0.556191\n",
      "[120]\ttraining's binary_logloss: 0.556076\n",
      "[121]\ttraining's binary_logloss: 0.55592\n",
      "[122]\ttraining's binary_logloss: 0.555787\n",
      "[123]\ttraining's binary_logloss: 0.555643\n",
      "[124]\ttraining's binary_logloss: 0.555495\n",
      "[125]\ttraining's binary_logloss: 0.555351\n",
      "[126]\ttraining's binary_logloss: 0.555196\n",
      "[127]\ttraining's binary_logloss: 0.555055\n",
      "[128]\ttraining's binary_logloss: 0.554911\n",
      "[129]\ttraining's binary_logloss: 0.554751\n",
      "[130]\ttraining's binary_logloss: 0.554607\n",
      "[131]\ttraining's binary_logloss: 0.554474\n",
      "[132]\ttraining's binary_logloss: 0.554372\n",
      "[133]\ttraining's binary_logloss: 0.554253\n",
      "[134]\ttraining's binary_logloss: 0.554135\n",
      "[135]\ttraining's binary_logloss: 0.554038\n",
      "[136]\ttraining's binary_logloss: 0.553903\n",
      "[137]\ttraining's binary_logloss: 0.553749\n",
      "[138]\ttraining's binary_logloss: 0.553612\n",
      "[139]\ttraining's binary_logloss: 0.55344\n",
      "[140]\ttraining's binary_logloss: 0.553287\n",
      "[141]\ttraining's binary_logloss: 0.553144\n",
      "[142]\ttraining's binary_logloss: 0.553002\n",
      "[143]\ttraining's binary_logloss: 0.552863\n",
      "[144]\ttraining's binary_logloss: 0.552726\n",
      "[145]\ttraining's binary_logloss: 0.552583\n",
      "[146]\ttraining's binary_logloss: 0.552377\n",
      "[147]\ttraining's binary_logloss: 0.552186\n",
      "[148]\ttraining's binary_logloss: 0.552042\n",
      "[149]\ttraining's binary_logloss: 0.551907\n",
      "[150]\ttraining's binary_logloss: 0.551785\n",
      "[151]\ttraining's binary_logloss: 0.551697\n",
      "[152]\ttraining's binary_logloss: 0.551596\n",
      "[153]\ttraining's binary_logloss: 0.551509\n",
      "[154]\ttraining's binary_logloss: 0.551403\n",
      "[155]\ttraining's binary_logloss: 0.551286\n",
      "[156]\ttraining's binary_logloss: 0.551127\n",
      "[157]\ttraining's binary_logloss: 0.55097\n",
      "[158]\ttraining's binary_logloss: 0.550814\n",
      "[159]\ttraining's binary_logloss: 0.55066\n",
      "[160]\ttraining's binary_logloss: 0.550541\n",
      "[161]\ttraining's binary_logloss: 0.55038\n",
      "[162]\ttraining's binary_logloss: 0.550232\n",
      "[163]\ttraining's binary_logloss: 0.550082\n",
      "[164]\ttraining's binary_logloss: 0.549943\n",
      "[165]\ttraining's binary_logloss: 0.54981\n",
      "[166]\ttraining's binary_logloss: 0.549675\n",
      "[167]\ttraining's binary_logloss: 0.54948\n",
      "[168]\ttraining's binary_logloss: 0.549343\n",
      "[169]\ttraining's binary_logloss: 0.549151\n",
      "[170]\ttraining's binary_logloss: 0.54899\n",
      "[171]\ttraining's binary_logloss: 0.548837\n",
      "[172]\ttraining's binary_logloss: 0.548667\n",
      "[173]\ttraining's binary_logloss: 0.548541\n",
      "[174]\ttraining's binary_logloss: 0.5484\n",
      "[175]\ttraining's binary_logloss: 0.548246\n",
      "[176]\ttraining's binary_logloss: 0.548072\n",
      "[177]\ttraining's binary_logloss: 0.547905\n",
      "[178]\ttraining's binary_logloss: 0.547763\n",
      "[179]\ttraining's binary_logloss: 0.547613\n",
      "[180]\ttraining's binary_logloss: 0.54747\n",
      "[181]\ttraining's binary_logloss: 0.547338\n",
      "[182]\ttraining's binary_logloss: 0.547214\n",
      "[183]\ttraining's binary_logloss: 0.547061\n",
      "[184]\ttraining's binary_logloss: 0.546928\n",
      "[185]\ttraining's binary_logloss: 0.546801\n",
      "[186]\ttraining's binary_logloss: 0.546699\n",
      "[187]\ttraining's binary_logloss: 0.546596\n",
      "[188]\ttraining's binary_logloss: 0.546455\n",
      "[189]\ttraining's binary_logloss: 0.546373\n",
      "[190]\ttraining's binary_logloss: 0.546267\n",
      "[191]\ttraining's binary_logloss: 0.546132\n",
      "[192]\ttraining's binary_logloss: 0.546022\n",
      "[193]\ttraining's binary_logloss: 0.545903\n",
      "[194]\ttraining's binary_logloss: 0.545781\n",
      "[195]\ttraining's binary_logloss: 0.545614\n",
      "[196]\ttraining's binary_logloss: 0.545457\n",
      "[197]\ttraining's binary_logloss: 0.545306\n",
      "[198]\ttraining's binary_logloss: 0.545126\n",
      "[199]\ttraining's binary_logloss: 0.544952\n",
      "[200]\ttraining's binary_logloss: 0.544801\n",
      "[201]\ttraining's binary_logloss: 0.544627\n",
      "[202]\ttraining's binary_logloss: 0.544464\n",
      "[203]\ttraining's binary_logloss: 0.544313\n",
      "[204]\ttraining's binary_logloss: 0.544118\n",
      "[205]\ttraining's binary_logloss: 0.543953\n",
      "[206]\ttraining's binary_logloss: 0.543806\n",
      "[207]\ttraining's binary_logloss: 0.54367\n",
      "[208]\ttraining's binary_logloss: 0.543516\n",
      "[209]\ttraining's binary_logloss: 0.543386\n",
      "[210]\ttraining's binary_logloss: 0.543211\n",
      "[211]\ttraining's binary_logloss: 0.543052\n",
      "[212]\ttraining's binary_logloss: 0.542869\n",
      "[213]\ttraining's binary_logloss: 0.542707\n",
      "[214]\ttraining's binary_logloss: 0.542544\n",
      "[215]\ttraining's binary_logloss: 0.542383\n",
      "[216]\ttraining's binary_logloss: 0.542194\n",
      "[217]\ttraining's binary_logloss: 0.541993\n",
      "[218]\ttraining's binary_logloss: 0.541813\n",
      "[219]\ttraining's binary_logloss: 0.541646\n",
      "[220]\ttraining's binary_logloss: 0.541503\n",
      "[221]\ttraining's binary_logloss: 0.541309\n",
      "[222]\ttraining's binary_logloss: 0.541153\n",
      "[223]\ttraining's binary_logloss: 0.541004\n",
      "[224]\ttraining's binary_logloss: 0.54083\n",
      "[225]\ttraining's binary_logloss: 0.540684\n",
      "[226]\ttraining's binary_logloss: 0.540503\n",
      "[227]\ttraining's binary_logloss: 0.540328\n",
      "[228]\ttraining's binary_logloss: 0.540153\n",
      "[229]\ttraining's binary_logloss: 0.53998\n",
      "[230]\ttraining's binary_logloss: 0.539833\n",
      "[231]\ttraining's binary_logloss: 0.539653\n",
      "[232]\ttraining's binary_logloss: 0.539457\n",
      "[233]\ttraining's binary_logloss: 0.539273\n",
      "[234]\ttraining's binary_logloss: 0.539083\n",
      "[235]\ttraining's binary_logloss: 0.538915\n",
      "[236]\ttraining's binary_logloss: 0.538753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[237]\ttraining's binary_logloss: 0.538599\n",
      "[238]\ttraining's binary_logloss: 0.538445\n",
      "[239]\ttraining's binary_logloss: 0.53829\n",
      "[240]\ttraining's binary_logloss: 0.538147\n",
      "[241]\ttraining's binary_logloss: 0.537961\n",
      "[242]\ttraining's binary_logloss: 0.537815\n",
      "[243]\ttraining's binary_logloss: 0.53764\n",
      "[244]\ttraining's binary_logloss: 0.537485\n",
      "[245]\ttraining's binary_logloss: 0.537335\n",
      "[246]\ttraining's binary_logloss: 0.537145\n",
      "[247]\ttraining's binary_logloss: 0.536954\n",
      "[248]\ttraining's binary_logloss: 0.536743\n",
      "[249]\ttraining's binary_logloss: 0.536575\n",
      "[250]\ttraining's binary_logloss: 0.536403\n",
      "[251]\ttraining's binary_logloss: 0.536246\n",
      "[252]\ttraining's binary_logloss: 0.536071\n",
      "[253]\ttraining's binary_logloss: 0.535868\n",
      "[254]\ttraining's binary_logloss: 0.535713\n",
      "[255]\ttraining's binary_logloss: 0.535532\n",
      "[256]\ttraining's binary_logloss: 0.535362\n",
      "[257]\ttraining's binary_logloss: 0.535193\n",
      "[258]\ttraining's binary_logloss: 0.534997\n",
      "[259]\ttraining's binary_logloss: 0.53482\n",
      "[260]\ttraining's binary_logloss: 0.534652\n",
      "[261]\ttraining's binary_logloss: 0.534455\n",
      "[262]\ttraining's binary_logloss: 0.534259\n",
      "[263]\ttraining's binary_logloss: 0.534062\n",
      "[264]\ttraining's binary_logloss: 0.533881\n",
      "[265]\ttraining's binary_logloss: 0.533705\n",
      "[266]\ttraining's binary_logloss: 0.533565\n",
      "[267]\ttraining's binary_logloss: 0.533443\n",
      "[268]\ttraining's binary_logloss: 0.533314\n",
      "[269]\ttraining's binary_logloss: 0.533188\n",
      "[270]\ttraining's binary_logloss: 0.533041\n",
      "[271]\ttraining's binary_logloss: 0.532876\n",
      "[272]\ttraining's binary_logloss: 0.532676\n",
      "[273]\ttraining's binary_logloss: 0.532492\n",
      "[274]\ttraining's binary_logloss: 0.532311\n",
      "[275]\ttraining's binary_logloss: 0.532134\n",
      "[276]\ttraining's binary_logloss: 0.531961\n",
      "[277]\ttraining's binary_logloss: 0.531772\n",
      "[278]\ttraining's binary_logloss: 0.531581\n",
      "[279]\ttraining's binary_logloss: 0.531395\n",
      "[280]\ttraining's binary_logloss: 0.531235\n",
      "[281]\ttraining's binary_logloss: 0.531047\n",
      "[282]\ttraining's binary_logloss: 0.530889\n",
      "[283]\ttraining's binary_logloss: 0.530727\n",
      "[284]\ttraining's binary_logloss: 0.530574\n",
      "[285]\ttraining's binary_logloss: 0.530383\n",
      "[286]\ttraining's binary_logloss: 0.530176\n",
      "[287]\ttraining's binary_logloss: 0.529978\n",
      "[288]\ttraining's binary_logloss: 0.529763\n",
      "[289]\ttraining's binary_logloss: 0.529552\n",
      "[290]\ttraining's binary_logloss: 0.529342\n",
      "[291]\ttraining's binary_logloss: 0.529191\n",
      "[292]\ttraining's binary_logloss: 0.529025\n",
      "[293]\ttraining's binary_logloss: 0.528858\n",
      "[294]\ttraining's binary_logloss: 0.528701\n",
      "[295]\ttraining's binary_logloss: 0.528538\n",
      "[296]\ttraining's binary_logloss: 0.528293\n",
      "[297]\ttraining's binary_logloss: 0.528091\n",
      "[298]\ttraining's binary_logloss: 0.527887\n",
      "[299]\ttraining's binary_logloss: 0.527683\n",
      "[300]\ttraining's binary_logloss: 0.527469\n",
      "[301]\ttraining's binary_logloss: 0.527269\n",
      "[302]\ttraining's binary_logloss: 0.52706\n",
      "[303]\ttraining's binary_logloss: 0.526863\n",
      "[304]\ttraining's binary_logloss: 0.526677\n",
      "[305]\ttraining's binary_logloss: 0.526488\n",
      "[306]\ttraining's binary_logloss: 0.526275\n",
      "[307]\ttraining's binary_logloss: 0.526058\n",
      "[308]\ttraining's binary_logloss: 0.525849\n",
      "[309]\ttraining's binary_logloss: 0.525641\n",
      "[310]\ttraining's binary_logloss: 0.525455\n",
      "[311]\ttraining's binary_logloss: 0.525267\n",
      "[312]\ttraining's binary_logloss: 0.525068\n",
      "[313]\ttraining's binary_logloss: 0.524894\n",
      "[314]\ttraining's binary_logloss: 0.524743\n",
      "[315]\ttraining's binary_logloss: 0.524554\n",
      "[316]\ttraining's binary_logloss: 0.524344\n",
      "[317]\ttraining's binary_logloss: 0.524137\n",
      "[318]\ttraining's binary_logloss: 0.523935\n",
      "[319]\ttraining's binary_logloss: 0.523752\n",
      "[320]\ttraining's binary_logloss: 0.523573\n",
      "[321]\ttraining's binary_logloss: 0.523419\n",
      "[322]\ttraining's binary_logloss: 0.523246\n",
      "[323]\ttraining's binary_logloss: 0.52309\n",
      "[324]\ttraining's binary_logloss: 0.522939\n",
      "[325]\ttraining's binary_logloss: 0.522792\n",
      "[326]\ttraining's binary_logloss: 0.522638\n",
      "[327]\ttraining's binary_logloss: 0.522498\n",
      "[328]\ttraining's binary_logloss: 0.522302\n",
      "[329]\ttraining's binary_logloss: 0.522148\n",
      "[330]\ttraining's binary_logloss: 0.522001\n",
      "[331]\ttraining's binary_logloss: 0.521784\n",
      "[332]\ttraining's binary_logloss: 0.521589\n",
      "[333]\ttraining's binary_logloss: 0.521395\n",
      "[334]\ttraining's binary_logloss: 0.521211\n",
      "[335]\ttraining's binary_logloss: 0.521018\n",
      "[336]\ttraining's binary_logloss: 0.520822\n",
      "[337]\ttraining's binary_logloss: 0.520619\n",
      "[338]\ttraining's binary_logloss: 0.520432\n",
      "[339]\ttraining's binary_logloss: 0.520238\n",
      "[340]\ttraining's binary_logloss: 0.520041\n",
      "[341]\ttraining's binary_logloss: 0.519831\n",
      "[342]\ttraining's binary_logloss: 0.519611\n",
      "[343]\ttraining's binary_logloss: 0.519404\n",
      "[344]\ttraining's binary_logloss: 0.519184\n",
      "[345]\ttraining's binary_logloss: 0.519005\n",
      "[346]\ttraining's binary_logloss: 0.518854\n",
      "[347]\ttraining's binary_logloss: 0.518663\n",
      "[348]\ttraining's binary_logloss: 0.518484\n",
      "[349]\ttraining's binary_logloss: 0.518307\n",
      "[350]\ttraining's binary_logloss: 0.518158\n",
      "[351]\ttraining's binary_logloss: 0.517955\n",
      "[352]\ttraining's binary_logloss: 0.51777\n",
      "[353]\ttraining's binary_logloss: 0.517578\n",
      "[354]\ttraining's binary_logloss: 0.517344\n",
      "[355]\ttraining's binary_logloss: 0.51714\n",
      "[356]\ttraining's binary_logloss: 0.516959\n",
      "[357]\ttraining's binary_logloss: 0.51676\n",
      "[358]\ttraining's binary_logloss: 0.516578\n",
      "[359]\ttraining's binary_logloss: 0.516398\n",
      "[360]\ttraining's binary_logloss: 0.516209\n",
      "[361]\ttraining's binary_logloss: 0.516027\n",
      "[362]\ttraining's binary_logloss: 0.515849\n",
      "[363]\ttraining's binary_logloss: 0.515674\n",
      "[364]\ttraining's binary_logloss: 0.51551\n",
      "[365]\ttraining's binary_logloss: 0.515317\n",
      "[366]\ttraining's binary_logloss: 0.515188\n",
      "[367]\ttraining's binary_logloss: 0.515058\n",
      "[368]\ttraining's binary_logloss: 0.514918\n",
      "[369]\ttraining's binary_logloss: 0.514771\n",
      "[370]\ttraining's binary_logloss: 0.514631\n",
      "[371]\ttraining's binary_logloss: 0.514449\n",
      "[372]\ttraining's binary_logloss: 0.51426\n",
      "[373]\ttraining's binary_logloss: 0.514064\n",
      "[374]\ttraining's binary_logloss: 0.513872\n",
      "[375]\ttraining's binary_logloss: 0.513679\n",
      "[376]\ttraining's binary_logloss: 0.513434\n",
      "[377]\ttraining's binary_logloss: 0.513229\n",
      "[378]\ttraining's binary_logloss: 0.513023\n",
      "[379]\ttraining's binary_logloss: 0.512796\n",
      "[380]\ttraining's binary_logloss: 0.512627\n",
      "[381]\ttraining's binary_logloss: 0.512435\n",
      "[382]\ttraining's binary_logloss: 0.512263\n",
      "[383]\ttraining's binary_logloss: 0.512083\n",
      "[384]\ttraining's binary_logloss: 0.511903\n",
      "[385]\ttraining's binary_logloss: 0.511746\n",
      "[386]\ttraining's binary_logloss: 0.511543\n",
      "[387]\ttraining's binary_logloss: 0.51137\n",
      "[388]\ttraining's binary_logloss: 0.511188\n",
      "[389]\ttraining's binary_logloss: 0.51097\n",
      "[390]\ttraining's binary_logloss: 0.510809\n",
      "[391]\ttraining's binary_logloss: 0.510589\n",
      "[392]\ttraining's binary_logloss: 0.510362\n",
      "[393]\ttraining's binary_logloss: 0.510141\n",
      "[394]\ttraining's binary_logloss: 0.509914\n",
      "[395]\ttraining's binary_logloss: 0.509693\n",
      "[396]\ttraining's binary_logloss: 0.50949\n",
      "[397]\ttraining's binary_logloss: 0.509248\n",
      "[398]\ttraining's binary_logloss: 0.509017\n",
      "[399]\ttraining's binary_logloss: 0.508788\n",
      "[400]\ttraining's binary_logloss: 0.508617\n",
      "[401]\ttraining's binary_logloss: 0.508414\n",
      "[402]\ttraining's binary_logloss: 0.508194\n",
      "[403]\ttraining's binary_logloss: 0.507995\n",
      "[404]\ttraining's binary_logloss: 0.507804\n",
      "[405]\ttraining's binary_logloss: 0.50761\n",
      "[406]\ttraining's binary_logloss: 0.507441\n",
      "[407]\ttraining's binary_logloss: 0.507275\n",
      "[408]\ttraining's binary_logloss: 0.507111\n",
      "[409]\ttraining's binary_logloss: 0.506924\n",
      "[410]\ttraining's binary_logloss: 0.506741\n",
      "[411]\ttraining's binary_logloss: 0.506515\n",
      "[412]\ttraining's binary_logloss: 0.506297\n",
      "[413]\ttraining's binary_logloss: 0.506062\n",
      "[414]\ttraining's binary_logloss: 0.505874\n",
      "[415]\ttraining's binary_logloss: 0.505698\n",
      "[416]\ttraining's binary_logloss: 0.505509\n",
      "[417]\ttraining's binary_logloss: 0.505334\n",
      "[418]\ttraining's binary_logloss: 0.505144\n",
      "[419]\ttraining's binary_logloss: 0.504975\n",
      "[420]\ttraining's binary_logloss: 0.504816\n",
      "[421]\ttraining's binary_logloss: 0.504675\n",
      "[422]\ttraining's binary_logloss: 0.504544\n",
      "[423]\ttraining's binary_logloss: 0.504371\n",
      "[424]\ttraining's binary_logloss: 0.504258\n",
      "[425]\ttraining's binary_logloss: 0.504102\n",
      "[426]\ttraining's binary_logloss: 0.503861\n",
      "[427]\ttraining's binary_logloss: 0.503632\n",
      "[428]\ttraining's binary_logloss: 0.503397\n",
      "[429]\ttraining's binary_logloss: 0.503161\n",
      "[430]\ttraining's binary_logloss: 0.502939\n",
      "[431]\ttraining's binary_logloss: 0.502786\n",
      "[432]\ttraining's binary_logloss: 0.502606\n",
      "[433]\ttraining's binary_logloss: 0.502468\n",
      "[434]\ttraining's binary_logloss: 0.502263\n",
      "[435]\ttraining's binary_logloss: 0.502104\n",
      "[436]\ttraining's binary_logloss: 0.501908\n",
      "[437]\ttraining's binary_logloss: 0.501685\n",
      "[438]\ttraining's binary_logloss: 0.501517\n",
      "[439]\ttraining's binary_logloss: 0.501297\n",
      "[440]\ttraining's binary_logloss: 0.5011\n",
      "[441]\ttraining's binary_logloss: 0.500891\n",
      "[442]\ttraining's binary_logloss: 0.50067\n",
      "[443]\ttraining's binary_logloss: 0.50048\n",
      "[444]\ttraining's binary_logloss: 0.500241\n",
      "[445]\ttraining's binary_logloss: 0.500041\n",
      "[446]\ttraining's binary_logloss: 0.499869\n",
      "[447]\ttraining's binary_logloss: 0.499724\n",
      "[448]\ttraining's binary_logloss: 0.499569\n",
      "[449]\ttraining's binary_logloss: 0.499389\n",
      "[450]\ttraining's binary_logloss: 0.499242\n",
      "[451]\ttraining's binary_logloss: 0.499125\n",
      "[452]\ttraining's binary_logloss: 0.498964\n",
      "[453]\ttraining's binary_logloss: 0.498822\n",
      "[454]\ttraining's binary_logloss: 0.498668\n",
      "[455]\ttraining's binary_logloss: 0.49849\n",
      "[456]\ttraining's binary_logloss: 0.498312\n",
      "[457]\ttraining's binary_logloss: 0.498139\n",
      "[458]\ttraining's binary_logloss: 0.497965\n",
      "[459]\ttraining's binary_logloss: 0.497792\n",
      "[460]\ttraining's binary_logloss: 0.497604\n",
      "[461]\ttraining's binary_logloss: 0.49742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[462]\ttraining's binary_logloss: 0.497204\n",
      "[463]\ttraining's binary_logloss: 0.496989\n",
      "[464]\ttraining's binary_logloss: 0.496809\n",
      "[465]\ttraining's binary_logloss: 0.496596\n",
      "[466]\ttraining's binary_logloss: 0.496392\n",
      "[467]\ttraining's binary_logloss: 0.496163\n",
      "[468]\ttraining's binary_logloss: 0.495966\n",
      "[469]\ttraining's binary_logloss: 0.495771\n",
      "[470]\ttraining's binary_logloss: 0.495588\n",
      "[471]\ttraining's binary_logloss: 0.495356\n",
      "[472]\ttraining's binary_logloss: 0.495144\n",
      "[473]\ttraining's binary_logloss: 0.494929\n",
      "[474]\ttraining's binary_logloss: 0.494739\n",
      "[475]\ttraining's binary_logloss: 0.494557\n",
      "[476]\ttraining's binary_logloss: 0.494386\n",
      "[477]\ttraining's binary_logloss: 0.494212\n",
      "[478]\ttraining's binary_logloss: 0.494032\n",
      "[479]\ttraining's binary_logloss: 0.493852\n",
      "[480]\ttraining's binary_logloss: 0.49366\n",
      "[481]\ttraining's binary_logloss: 0.493517\n",
      "[482]\ttraining's binary_logloss: 0.493375\n",
      "[483]\ttraining's binary_logloss: 0.493224\n",
      "[484]\ttraining's binary_logloss: 0.493093\n",
      "[485]\ttraining's binary_logloss: 0.492927\n",
      "[486]\ttraining's binary_logloss: 0.492767\n",
      "[487]\ttraining's binary_logloss: 0.492625\n",
      "[488]\ttraining's binary_logloss: 0.49246\n",
      "[489]\ttraining's binary_logloss: 0.492285\n",
      "[490]\ttraining's binary_logloss: 0.492147\n",
      "[491]\ttraining's binary_logloss: 0.491948\n",
      "[492]\ttraining's binary_logloss: 0.491786\n",
      "[493]\ttraining's binary_logloss: 0.491605\n",
      "[494]\ttraining's binary_logloss: 0.491393\n",
      "[495]\ttraining's binary_logloss: 0.491229\n",
      "[496]\ttraining's binary_logloss: 0.490992\n",
      "[497]\ttraining's binary_logloss: 0.490779\n",
      "[498]\ttraining's binary_logloss: 0.490589\n",
      "[499]\ttraining's binary_logloss: 0.490379\n",
      "[500]\ttraining's binary_logloss: 0.490141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613982\n",
      "[2]\ttraining's binary_logloss: 0.612444\n",
      "[3]\ttraining's binary_logloss: 0.61095\n",
      "[4]\ttraining's binary_logloss: 0.609469\n",
      "[5]\ttraining's binary_logloss: 0.608062\n",
      "[6]\ttraining's binary_logloss: 0.606609\n",
      "[7]\ttraining's binary_logloss: 0.605251\n",
      "[8]\ttraining's binary_logloss: 0.603882\n",
      "[9]\ttraining's binary_logloss: 0.602552\n",
      "[10]\ttraining's binary_logloss: 0.60126\n",
      "[11]\ttraining's binary_logloss: 0.600008\n",
      "[12]\ttraining's binary_logloss: 0.598772\n",
      "[13]\ttraining's binary_logloss: 0.597604\n",
      "[14]\ttraining's binary_logloss: 0.59647\n",
      "[15]\ttraining's binary_logloss: 0.595347\n",
      "[16]\ttraining's binary_logloss: 0.594211\n",
      "[17]\ttraining's binary_logloss: 0.593125\n",
      "[18]\ttraining's binary_logloss: 0.592042\n",
      "[19]\ttraining's binary_logloss: 0.590961\n",
      "[20]\ttraining's binary_logloss: 0.589918\n",
      "[21]\ttraining's binary_logloss: 0.588935\n",
      "[22]\ttraining's binary_logloss: 0.587995\n",
      "[23]\ttraining's binary_logloss: 0.587087\n",
      "[24]\ttraining's binary_logloss: 0.586236\n",
      "[25]\ttraining's binary_logloss: 0.585396\n",
      "[26]\ttraining's binary_logloss: 0.584535\n",
      "[27]\ttraining's binary_logloss: 0.583706\n",
      "[28]\ttraining's binary_logloss: 0.582926\n",
      "[29]\ttraining's binary_logloss: 0.582133\n",
      "[30]\ttraining's binary_logloss: 0.581368\n",
      "[31]\ttraining's binary_logloss: 0.580539\n",
      "[32]\ttraining's binary_logloss: 0.579823\n",
      "[33]\ttraining's binary_logloss: 0.579136\n",
      "[34]\ttraining's binary_logloss: 0.578426\n",
      "[35]\ttraining's binary_logloss: 0.577706\n",
      "[36]\ttraining's binary_logloss: 0.577088\n",
      "[37]\ttraining's binary_logloss: 0.576478\n",
      "[38]\ttraining's binary_logloss: 0.575852\n",
      "[39]\ttraining's binary_logloss: 0.575284\n",
      "[40]\ttraining's binary_logloss: 0.574668\n",
      "[41]\ttraining's binary_logloss: 0.573997\n",
      "[42]\ttraining's binary_logloss: 0.573368\n",
      "[43]\ttraining's binary_logloss: 0.572767\n",
      "[44]\ttraining's binary_logloss: 0.572121\n",
      "[45]\ttraining's binary_logloss: 0.571559\n",
      "[46]\ttraining's binary_logloss: 0.571003\n",
      "[47]\ttraining's binary_logloss: 0.570411\n",
      "[48]\ttraining's binary_logloss: 0.569863\n",
      "[49]\ttraining's binary_logloss: 0.56928\n",
      "[50]\ttraining's binary_logloss: 0.568802\n",
      "[51]\ttraining's binary_logloss: 0.568332\n",
      "[52]\ttraining's binary_logloss: 0.567893\n",
      "[53]\ttraining's binary_logloss: 0.567451\n",
      "[54]\ttraining's binary_logloss: 0.566991\n",
      "[55]\ttraining's binary_logloss: 0.566482\n",
      "[56]\ttraining's binary_logloss: 0.56603\n",
      "[57]\ttraining's binary_logloss: 0.565604\n",
      "[58]\ttraining's binary_logloss: 0.565103\n",
      "[59]\ttraining's binary_logloss: 0.56467\n",
      "[60]\ttraining's binary_logloss: 0.564232\n",
      "[61]\ttraining's binary_logloss: 0.563798\n",
      "[62]\ttraining's binary_logloss: 0.563377\n",
      "[63]\ttraining's binary_logloss: 0.563019\n",
      "[64]\ttraining's binary_logloss: 0.562621\n",
      "[65]\ttraining's binary_logloss: 0.562302\n",
      "[66]\ttraining's binary_logloss: 0.561914\n",
      "[67]\ttraining's binary_logloss: 0.561535\n",
      "[68]\ttraining's binary_logloss: 0.561152\n",
      "[69]\ttraining's binary_logloss: 0.560788\n",
      "[70]\ttraining's binary_logloss: 0.560437\n",
      "[71]\ttraining's binary_logloss: 0.560118\n",
      "[72]\ttraining's binary_logloss: 0.559809\n",
      "[73]\ttraining's binary_logloss: 0.559511\n",
      "[74]\ttraining's binary_logloss: 0.559243\n",
      "[75]\ttraining's binary_logloss: 0.55894\n",
      "[76]\ttraining's binary_logloss: 0.558606\n",
      "[77]\ttraining's binary_logloss: 0.558304\n",
      "[78]\ttraining's binary_logloss: 0.557987\n",
      "[79]\ttraining's binary_logloss: 0.557655\n",
      "[80]\ttraining's binary_logloss: 0.557386\n",
      "[81]\ttraining's binary_logloss: 0.557043\n",
      "[82]\ttraining's binary_logloss: 0.556783\n",
      "[83]\ttraining's binary_logloss: 0.556456\n",
      "[84]\ttraining's binary_logloss: 0.556149\n",
      "[85]\ttraining's binary_logloss: 0.555853\n",
      "[86]\ttraining's binary_logloss: 0.555594\n",
      "[87]\ttraining's binary_logloss: 0.555264\n",
      "[88]\ttraining's binary_logloss: 0.554953\n",
      "[89]\ttraining's binary_logloss: 0.554667\n",
      "[90]\ttraining's binary_logloss: 0.554411\n",
      "[91]\ttraining's binary_logloss: 0.554149\n",
      "[92]\ttraining's binary_logloss: 0.553892\n",
      "[93]\ttraining's binary_logloss: 0.553643\n",
      "[94]\ttraining's binary_logloss: 0.553403\n",
      "[95]\ttraining's binary_logloss: 0.553177\n",
      "[96]\ttraining's binary_logloss: 0.552892\n",
      "[97]\ttraining's binary_logloss: 0.552621\n",
      "[98]\ttraining's binary_logloss: 0.552306\n",
      "[99]\ttraining's binary_logloss: 0.552062\n",
      "[100]\ttraining's binary_logloss: 0.551816\n",
      "[101]\ttraining's binary_logloss: 0.551575\n",
      "[102]\ttraining's binary_logloss: 0.551303\n",
      "[103]\ttraining's binary_logloss: 0.551023\n",
      "[104]\ttraining's binary_logloss: 0.550765\n",
      "[105]\ttraining's binary_logloss: 0.550522\n",
      "[106]\ttraining's binary_logloss: 0.550255\n",
      "[107]\ttraining's binary_logloss: 0.550022\n",
      "[108]\ttraining's binary_logloss: 0.549742\n",
      "[109]\ttraining's binary_logloss: 0.549475\n",
      "[110]\ttraining's binary_logloss: 0.549219\n",
      "[111]\ttraining's binary_logloss: 0.548968\n",
      "[112]\ttraining's binary_logloss: 0.548735\n",
      "[113]\ttraining's binary_logloss: 0.548515\n",
      "[114]\ttraining's binary_logloss: 0.548276\n",
      "[115]\ttraining's binary_logloss: 0.548033\n",
      "[116]\ttraining's binary_logloss: 0.547776\n",
      "[117]\ttraining's binary_logloss: 0.54756\n",
      "[118]\ttraining's binary_logloss: 0.54734\n",
      "[119]\ttraining's binary_logloss: 0.54712\n",
      "[120]\ttraining's binary_logloss: 0.546911\n",
      "[121]\ttraining's binary_logloss: 0.5467\n",
      "[122]\ttraining's binary_logloss: 0.546515\n",
      "[123]\ttraining's binary_logloss: 0.546313\n",
      "[124]\ttraining's binary_logloss: 0.546174\n",
      "[125]\ttraining's binary_logloss: 0.546011\n",
      "[126]\ttraining's binary_logloss: 0.545797\n",
      "[127]\ttraining's binary_logloss: 0.545547\n",
      "[128]\ttraining's binary_logloss: 0.545351\n",
      "[129]\ttraining's binary_logloss: 0.545094\n",
      "[130]\ttraining's binary_logloss: 0.54485\n",
      "[131]\ttraining's binary_logloss: 0.544633\n",
      "[132]\ttraining's binary_logloss: 0.544414\n",
      "[133]\ttraining's binary_logloss: 0.54413\n",
      "[134]\ttraining's binary_logloss: 0.543896\n",
      "[135]\ttraining's binary_logloss: 0.543664\n",
      "[136]\ttraining's binary_logloss: 0.54346\n",
      "[137]\ttraining's binary_logloss: 0.543235\n",
      "[138]\ttraining's binary_logloss: 0.543\n",
      "[139]\ttraining's binary_logloss: 0.542787\n",
      "[140]\ttraining's binary_logloss: 0.542566\n",
      "[141]\ttraining's binary_logloss: 0.542352\n",
      "[142]\ttraining's binary_logloss: 0.54212\n",
      "[143]\ttraining's binary_logloss: 0.541843\n",
      "[144]\ttraining's binary_logloss: 0.541566\n",
      "[145]\ttraining's binary_logloss: 0.541332\n",
      "[146]\ttraining's binary_logloss: 0.541098\n",
      "[147]\ttraining's binary_logloss: 0.540847\n",
      "[148]\ttraining's binary_logloss: 0.540637\n",
      "[149]\ttraining's binary_logloss: 0.540422\n",
      "[150]\ttraining's binary_logloss: 0.540213\n",
      "[151]\ttraining's binary_logloss: 0.53998\n",
      "[152]\ttraining's binary_logloss: 0.53975\n",
      "[153]\ttraining's binary_logloss: 0.539538\n",
      "[154]\ttraining's binary_logloss: 0.539324\n",
      "[155]\ttraining's binary_logloss: 0.539109\n",
      "[156]\ttraining's binary_logloss: 0.538955\n",
      "[157]\ttraining's binary_logloss: 0.538798\n",
      "[158]\ttraining's binary_logloss: 0.53867\n",
      "[159]\ttraining's binary_logloss: 0.538527\n",
      "[160]\ttraining's binary_logloss: 0.53837\n",
      "[161]\ttraining's binary_logloss: 0.538089\n",
      "[162]\ttraining's binary_logloss: 0.53786\n",
      "[163]\ttraining's binary_logloss: 0.53762\n",
      "[164]\ttraining's binary_logloss: 0.537389\n",
      "[165]\ttraining's binary_logloss: 0.537159\n",
      "[166]\ttraining's binary_logloss: 0.536918\n",
      "[167]\ttraining's binary_logloss: 0.536674\n",
      "[168]\ttraining's binary_logloss: 0.536422\n",
      "[169]\ttraining's binary_logloss: 0.536199\n",
      "[170]\ttraining's binary_logloss: 0.53596\n",
      "[171]\ttraining's binary_logloss: 0.535729\n",
      "[172]\ttraining's binary_logloss: 0.535468\n",
      "[173]\ttraining's binary_logloss: 0.535232\n",
      "[174]\ttraining's binary_logloss: 0.535\n",
      "[175]\ttraining's binary_logloss: 0.534767\n",
      "[176]\ttraining's binary_logloss: 0.534539\n",
      "[177]\ttraining's binary_logloss: 0.534329\n",
      "[178]\ttraining's binary_logloss: 0.534128\n",
      "[179]\ttraining's binary_logloss: 0.533918\n",
      "[180]\ttraining's binary_logloss: 0.533749\n",
      "[181]\ttraining's binary_logloss: 0.533563\n",
      "[182]\ttraining's binary_logloss: 0.533383\n",
      "[183]\ttraining's binary_logloss: 0.533174\n",
      "[184]\ttraining's binary_logloss: 0.532919\n",
      "[185]\ttraining's binary_logloss: 0.532697\n",
      "[186]\ttraining's binary_logloss: 0.532488\n",
      "[187]\ttraining's binary_logloss: 0.532321\n",
      "[188]\ttraining's binary_logloss: 0.53209\n",
      "[189]\ttraining's binary_logloss: 0.531928\n",
      "[190]\ttraining's binary_logloss: 0.531734\n",
      "[191]\ttraining's binary_logloss: 0.531513\n",
      "[192]\ttraining's binary_logloss: 0.531282\n",
      "[193]\ttraining's binary_logloss: 0.53107\n",
      "[194]\ttraining's binary_logloss: 0.530856\n",
      "[195]\ttraining's binary_logloss: 0.530635\n",
      "[196]\ttraining's binary_logloss: 0.530399\n",
      "[197]\ttraining's binary_logloss: 0.530142\n",
      "[198]\ttraining's binary_logloss: 0.529914\n",
      "[199]\ttraining's binary_logloss: 0.529681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's binary_logloss: 0.529484\n",
      "[201]\ttraining's binary_logloss: 0.529278\n",
      "[202]\ttraining's binary_logloss: 0.529101\n",
      "[203]\ttraining's binary_logloss: 0.528912\n",
      "[204]\ttraining's binary_logloss: 0.528693\n",
      "[205]\ttraining's binary_logloss: 0.528489\n",
      "[206]\ttraining's binary_logloss: 0.528284\n",
      "[207]\ttraining's binary_logloss: 0.528052\n",
      "[208]\ttraining's binary_logloss: 0.527861\n",
      "[209]\ttraining's binary_logloss: 0.527643\n",
      "[210]\ttraining's binary_logloss: 0.527431\n",
      "[211]\ttraining's binary_logloss: 0.527209\n",
      "[212]\ttraining's binary_logloss: 0.526996\n",
      "[213]\ttraining's binary_logloss: 0.526792\n",
      "[214]\ttraining's binary_logloss: 0.526578\n",
      "[215]\ttraining's binary_logloss: 0.526354\n",
      "[216]\ttraining's binary_logloss: 0.526118\n",
      "[217]\ttraining's binary_logloss: 0.525924\n",
      "[218]\ttraining's binary_logloss: 0.525709\n",
      "[219]\ttraining's binary_logloss: 0.525532\n",
      "[220]\ttraining's binary_logloss: 0.525365\n",
      "[221]\ttraining's binary_logloss: 0.525101\n",
      "[222]\ttraining's binary_logloss: 0.524863\n",
      "[223]\ttraining's binary_logloss: 0.524631\n",
      "[224]\ttraining's binary_logloss: 0.524397\n",
      "[225]\ttraining's binary_logloss: 0.524142\n",
      "[226]\ttraining's binary_logloss: 0.523951\n",
      "[227]\ttraining's binary_logloss: 0.523772\n",
      "[228]\ttraining's binary_logloss: 0.523561\n",
      "[229]\ttraining's binary_logloss: 0.523358\n",
      "[230]\ttraining's binary_logloss: 0.523126\n",
      "[231]\ttraining's binary_logloss: 0.522866\n",
      "[232]\ttraining's binary_logloss: 0.522614\n",
      "[233]\ttraining's binary_logloss: 0.522392\n",
      "[234]\ttraining's binary_logloss: 0.522147\n",
      "[235]\ttraining's binary_logloss: 0.521943\n",
      "[236]\ttraining's binary_logloss: 0.521703\n",
      "[237]\ttraining's binary_logloss: 0.521432\n",
      "[238]\ttraining's binary_logloss: 0.521174\n",
      "[239]\ttraining's binary_logloss: 0.520928\n",
      "[240]\ttraining's binary_logloss: 0.520684\n",
      "[241]\ttraining's binary_logloss: 0.520441\n",
      "[242]\ttraining's binary_logloss: 0.520215\n",
      "[243]\ttraining's binary_logloss: 0.519991\n",
      "[244]\ttraining's binary_logloss: 0.519775\n",
      "[245]\ttraining's binary_logloss: 0.519552\n",
      "[246]\ttraining's binary_logloss: 0.519369\n",
      "[247]\ttraining's binary_logloss: 0.519185\n",
      "[248]\ttraining's binary_logloss: 0.518993\n",
      "[249]\ttraining's binary_logloss: 0.518786\n",
      "[250]\ttraining's binary_logloss: 0.518597\n",
      "[251]\ttraining's binary_logloss: 0.518381\n",
      "[252]\ttraining's binary_logloss: 0.518122\n",
      "[253]\ttraining's binary_logloss: 0.517866\n",
      "[254]\ttraining's binary_logloss: 0.517591\n",
      "[255]\ttraining's binary_logloss: 0.517361\n",
      "[256]\ttraining's binary_logloss: 0.51717\n",
      "[257]\ttraining's binary_logloss: 0.51696\n",
      "[258]\ttraining's binary_logloss: 0.516764\n",
      "[259]\ttraining's binary_logloss: 0.516582\n",
      "[260]\ttraining's binary_logloss: 0.516404\n",
      "[261]\ttraining's binary_logloss: 0.51616\n",
      "[262]\ttraining's binary_logloss: 0.515955\n",
      "[263]\ttraining's binary_logloss: 0.515686\n",
      "[264]\ttraining's binary_logloss: 0.515457\n",
      "[265]\ttraining's binary_logloss: 0.515246\n",
      "[266]\ttraining's binary_logloss: 0.515037\n",
      "[267]\ttraining's binary_logloss: 0.514885\n",
      "[268]\ttraining's binary_logloss: 0.514651\n",
      "[269]\ttraining's binary_logloss: 0.514438\n",
      "[270]\ttraining's binary_logloss: 0.514219\n",
      "[271]\ttraining's binary_logloss: 0.513931\n",
      "[272]\ttraining's binary_logloss: 0.513701\n",
      "[273]\ttraining's binary_logloss: 0.513451\n",
      "[274]\ttraining's binary_logloss: 0.513198\n",
      "[275]\ttraining's binary_logloss: 0.512976\n",
      "[276]\ttraining's binary_logloss: 0.512715\n",
      "[277]\ttraining's binary_logloss: 0.512483\n",
      "[278]\ttraining's binary_logloss: 0.512239\n",
      "[279]\ttraining's binary_logloss: 0.511976\n",
      "[280]\ttraining's binary_logloss: 0.511738\n",
      "[281]\ttraining's binary_logloss: 0.511501\n",
      "[282]\ttraining's binary_logloss: 0.51131\n",
      "[283]\ttraining's binary_logloss: 0.51107\n",
      "[284]\ttraining's binary_logloss: 0.51084\n",
      "[285]\ttraining's binary_logloss: 0.510653\n",
      "[286]\ttraining's binary_logloss: 0.510401\n",
      "[287]\ttraining's binary_logloss: 0.510145\n",
      "[288]\ttraining's binary_logloss: 0.509931\n",
      "[289]\ttraining's binary_logloss: 0.509685\n",
      "[290]\ttraining's binary_logloss: 0.509449\n",
      "[291]\ttraining's binary_logloss: 0.509183\n",
      "[292]\ttraining's binary_logloss: 0.508921\n",
      "[293]\ttraining's binary_logloss: 0.508676\n",
      "[294]\ttraining's binary_logloss: 0.508416\n",
      "[295]\ttraining's binary_logloss: 0.508154\n",
      "[296]\ttraining's binary_logloss: 0.507926\n",
      "[297]\ttraining's binary_logloss: 0.507683\n",
      "[298]\ttraining's binary_logloss: 0.507437\n",
      "[299]\ttraining's binary_logloss: 0.507173\n",
      "[300]\ttraining's binary_logloss: 0.506954\n",
      "[301]\ttraining's binary_logloss: 0.50668\n",
      "[302]\ttraining's binary_logloss: 0.506412\n",
      "[303]\ttraining's binary_logloss: 0.506154\n",
      "[304]\ttraining's binary_logloss: 0.50589\n",
      "[305]\ttraining's binary_logloss: 0.505644\n",
      "[306]\ttraining's binary_logloss: 0.505447\n",
      "[307]\ttraining's binary_logloss: 0.505199\n",
      "[308]\ttraining's binary_logloss: 0.504965\n",
      "[309]\ttraining's binary_logloss: 0.504721\n",
      "[310]\ttraining's binary_logloss: 0.504524\n",
      "[311]\ttraining's binary_logloss: 0.504294\n",
      "[312]\ttraining's binary_logloss: 0.504084\n",
      "[313]\ttraining's binary_logloss: 0.503863\n",
      "[314]\ttraining's binary_logloss: 0.503663\n",
      "[315]\ttraining's binary_logloss: 0.503444\n",
      "[316]\ttraining's binary_logloss: 0.503161\n",
      "[317]\ttraining's binary_logloss: 0.502919\n",
      "[318]\ttraining's binary_logloss: 0.502667\n",
      "[319]\ttraining's binary_logloss: 0.502417\n",
      "[320]\ttraining's binary_logloss: 0.502144\n",
      "[321]\ttraining's binary_logloss: 0.501878\n",
      "[322]\ttraining's binary_logloss: 0.501615\n",
      "[323]\ttraining's binary_logloss: 0.501351\n",
      "[324]\ttraining's binary_logloss: 0.501086\n",
      "[325]\ttraining's binary_logloss: 0.500835\n",
      "[326]\ttraining's binary_logloss: 0.500556\n",
      "[327]\ttraining's binary_logloss: 0.50029\n",
      "[328]\ttraining's binary_logloss: 0.500041\n",
      "[329]\ttraining's binary_logloss: 0.499804\n",
      "[330]\ttraining's binary_logloss: 0.499538\n",
      "[331]\ttraining's binary_logloss: 0.499244\n",
      "[332]\ttraining's binary_logloss: 0.499007\n",
      "[333]\ttraining's binary_logloss: 0.498782\n",
      "[334]\ttraining's binary_logloss: 0.498554\n",
      "[335]\ttraining's binary_logloss: 0.498328\n",
      "[336]\ttraining's binary_logloss: 0.498122\n",
      "[337]\ttraining's binary_logloss: 0.497935\n",
      "[338]\ttraining's binary_logloss: 0.497729\n",
      "[339]\ttraining's binary_logloss: 0.497535\n",
      "[340]\ttraining's binary_logloss: 0.497323\n",
      "[341]\ttraining's binary_logloss: 0.497115\n",
      "[342]\ttraining's binary_logloss: 0.496917\n",
      "[343]\ttraining's binary_logloss: 0.496692\n",
      "[344]\ttraining's binary_logloss: 0.496512\n",
      "[345]\ttraining's binary_logloss: 0.496307\n",
      "[346]\ttraining's binary_logloss: 0.496054\n",
      "[347]\ttraining's binary_logloss: 0.495817\n",
      "[348]\ttraining's binary_logloss: 0.49558\n",
      "[349]\ttraining's binary_logloss: 0.495372\n",
      "[350]\ttraining's binary_logloss: 0.495132\n",
      "[351]\ttraining's binary_logloss: 0.494873\n",
      "[352]\ttraining's binary_logloss: 0.494644\n",
      "[353]\ttraining's binary_logloss: 0.494406\n",
      "[354]\ttraining's binary_logloss: 0.494189\n",
      "[355]\ttraining's binary_logloss: 0.493961\n",
      "[356]\ttraining's binary_logloss: 0.493701\n",
      "[357]\ttraining's binary_logloss: 0.493449\n",
      "[358]\ttraining's binary_logloss: 0.493171\n",
      "[359]\ttraining's binary_logloss: 0.492935\n",
      "[360]\ttraining's binary_logloss: 0.492684\n",
      "[361]\ttraining's binary_logloss: 0.49242\n",
      "[362]\ttraining's binary_logloss: 0.492138\n",
      "[363]\ttraining's binary_logloss: 0.491872\n",
      "[364]\ttraining's binary_logloss: 0.491616\n",
      "[365]\ttraining's binary_logloss: 0.491351\n",
      "[366]\ttraining's binary_logloss: 0.491118\n",
      "[367]\ttraining's binary_logloss: 0.490901\n",
      "[368]\ttraining's binary_logloss: 0.490666\n",
      "[369]\ttraining's binary_logloss: 0.490442\n",
      "[370]\ttraining's binary_logloss: 0.490203\n",
      "[371]\ttraining's binary_logloss: 0.489981\n",
      "[372]\ttraining's binary_logloss: 0.489788\n",
      "[373]\ttraining's binary_logloss: 0.489606\n",
      "[374]\ttraining's binary_logloss: 0.48938\n",
      "[375]\ttraining's binary_logloss: 0.489154\n",
      "[376]\ttraining's binary_logloss: 0.488933\n",
      "[377]\ttraining's binary_logloss: 0.488695\n",
      "[378]\ttraining's binary_logloss: 0.488452\n",
      "[379]\ttraining's binary_logloss: 0.488248\n",
      "[380]\ttraining's binary_logloss: 0.488049\n",
      "[381]\ttraining's binary_logloss: 0.487892\n",
      "[382]\ttraining's binary_logloss: 0.487695\n",
      "[383]\ttraining's binary_logloss: 0.487501\n",
      "[384]\ttraining's binary_logloss: 0.48729\n",
      "[385]\ttraining's binary_logloss: 0.487093\n",
      "[386]\ttraining's binary_logloss: 0.486836\n",
      "[387]\ttraining's binary_logloss: 0.486529\n",
      "[388]\ttraining's binary_logloss: 0.486258\n",
      "[389]\ttraining's binary_logloss: 0.486003\n",
      "[390]\ttraining's binary_logloss: 0.48575\n",
      "[391]\ttraining's binary_logloss: 0.485536\n",
      "[392]\ttraining's binary_logloss: 0.4853\n",
      "[393]\ttraining's binary_logloss: 0.485066\n",
      "[394]\ttraining's binary_logloss: 0.484828\n",
      "[395]\ttraining's binary_logloss: 0.484597\n",
      "[396]\ttraining's binary_logloss: 0.484359\n",
      "[397]\ttraining's binary_logloss: 0.484117\n",
      "[398]\ttraining's binary_logloss: 0.483841\n",
      "[399]\ttraining's binary_logloss: 0.483609\n",
      "[400]\ttraining's binary_logloss: 0.483357\n",
      "[401]\ttraining's binary_logloss: 0.483081\n",
      "[402]\ttraining's binary_logloss: 0.482824\n",
      "[403]\ttraining's binary_logloss: 0.482538\n",
      "[404]\ttraining's binary_logloss: 0.482296\n",
      "[405]\ttraining's binary_logloss: 0.482021\n",
      "[406]\ttraining's binary_logloss: 0.481781\n",
      "[407]\ttraining's binary_logloss: 0.481556\n",
      "[408]\ttraining's binary_logloss: 0.481337\n",
      "[409]\ttraining's binary_logloss: 0.481127\n",
      "[410]\ttraining's binary_logloss: 0.480905\n",
      "[411]\ttraining's binary_logloss: 0.480675\n",
      "[412]\ttraining's binary_logloss: 0.480424\n",
      "[413]\ttraining's binary_logloss: 0.480169\n",
      "[414]\ttraining's binary_logloss: 0.479907\n",
      "[415]\ttraining's binary_logloss: 0.479649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[416]\ttraining's binary_logloss: 0.479418\n",
      "[417]\ttraining's binary_logloss: 0.479187\n",
      "[418]\ttraining's binary_logloss: 0.47892\n",
      "[419]\ttraining's binary_logloss: 0.478688\n",
      "[420]\ttraining's binary_logloss: 0.478436\n",
      "[421]\ttraining's binary_logloss: 0.47824\n",
      "[422]\ttraining's binary_logloss: 0.478018\n",
      "[423]\ttraining's binary_logloss: 0.477805\n",
      "[424]\ttraining's binary_logloss: 0.477595\n",
      "[425]\ttraining's binary_logloss: 0.477379\n",
      "[426]\ttraining's binary_logloss: 0.477215\n",
      "[427]\ttraining's binary_logloss: 0.477016\n",
      "[428]\ttraining's binary_logloss: 0.476819\n",
      "[429]\ttraining's binary_logloss: 0.476623\n",
      "[430]\ttraining's binary_logloss: 0.476427\n",
      "[431]\ttraining's binary_logloss: 0.476177\n",
      "[432]\ttraining's binary_logloss: 0.475922\n",
      "[433]\ttraining's binary_logloss: 0.475685\n",
      "[434]\ttraining's binary_logloss: 0.47542\n",
      "[435]\ttraining's binary_logloss: 0.47517\n",
      "[436]\ttraining's binary_logloss: 0.474956\n",
      "[437]\ttraining's binary_logloss: 0.474748\n",
      "[438]\ttraining's binary_logloss: 0.474571\n",
      "[439]\ttraining's binary_logloss: 0.474374\n",
      "[440]\ttraining's binary_logloss: 0.474178\n",
      "[441]\ttraining's binary_logloss: 0.473918\n",
      "[442]\ttraining's binary_logloss: 0.473667\n",
      "[443]\ttraining's binary_logloss: 0.473449\n",
      "[444]\ttraining's binary_logloss: 0.473209\n",
      "[445]\ttraining's binary_logloss: 0.472988\n",
      "[446]\ttraining's binary_logloss: 0.472747\n",
      "[447]\ttraining's binary_logloss: 0.472509\n",
      "[448]\ttraining's binary_logloss: 0.472275\n",
      "[449]\ttraining's binary_logloss: 0.472038\n",
      "[450]\ttraining's binary_logloss: 0.471809\n",
      "[451]\ttraining's binary_logloss: 0.471581\n",
      "[452]\ttraining's binary_logloss: 0.471362\n",
      "[453]\ttraining's binary_logloss: 0.471142\n",
      "[454]\ttraining's binary_logloss: 0.47092\n",
      "[455]\ttraining's binary_logloss: 0.470687\n",
      "[456]\ttraining's binary_logloss: 0.47046\n",
      "[457]\ttraining's binary_logloss: 0.470243\n",
      "[458]\ttraining's binary_logloss: 0.470015\n",
      "[459]\ttraining's binary_logloss: 0.469784\n",
      "[460]\ttraining's binary_logloss: 0.469568\n",
      "[461]\ttraining's binary_logloss: 0.469323\n",
      "[462]\ttraining's binary_logloss: 0.469073\n",
      "[463]\ttraining's binary_logloss: 0.46882\n",
      "[464]\ttraining's binary_logloss: 0.46858\n",
      "[465]\ttraining's binary_logloss: 0.468337\n",
      "[466]\ttraining's binary_logloss: 0.468096\n",
      "[467]\ttraining's binary_logloss: 0.467877\n",
      "[468]\ttraining's binary_logloss: 0.467644\n",
      "[469]\ttraining's binary_logloss: 0.467432\n",
      "[470]\ttraining's binary_logloss: 0.467175\n",
      "[471]\ttraining's binary_logloss: 0.466966\n",
      "[472]\ttraining's binary_logloss: 0.466747\n",
      "[473]\ttraining's binary_logloss: 0.466548\n",
      "[474]\ttraining's binary_logloss: 0.466324\n",
      "[475]\ttraining's binary_logloss: 0.466124\n",
      "[476]\ttraining's binary_logloss: 0.465918\n",
      "[477]\ttraining's binary_logloss: 0.465696\n",
      "[478]\ttraining's binary_logloss: 0.465473\n",
      "[479]\ttraining's binary_logloss: 0.465242\n",
      "[480]\ttraining's binary_logloss: 0.465048\n",
      "[481]\ttraining's binary_logloss: 0.464812\n",
      "[482]\ttraining's binary_logloss: 0.464597\n",
      "[483]\ttraining's binary_logloss: 0.464373\n",
      "[484]\ttraining's binary_logloss: 0.464137\n",
      "[485]\ttraining's binary_logloss: 0.463926\n",
      "[486]\ttraining's binary_logloss: 0.463666\n",
      "[487]\ttraining's binary_logloss: 0.463416\n",
      "[488]\ttraining's binary_logloss: 0.463173\n",
      "[489]\ttraining's binary_logloss: 0.462943\n",
      "[490]\ttraining's binary_logloss: 0.462692\n",
      "[491]\ttraining's binary_logloss: 0.462533\n",
      "[492]\ttraining's binary_logloss: 0.462348\n",
      "[493]\ttraining's binary_logloss: 0.462159\n",
      "[494]\ttraining's binary_logloss: 0.461991\n",
      "[495]\ttraining's binary_logloss: 0.461826\n",
      "[496]\ttraining's binary_logloss: 0.461576\n",
      "[497]\ttraining's binary_logloss: 0.46136\n",
      "[498]\ttraining's binary_logloss: 0.461147\n",
      "[499]\ttraining's binary_logloss: 0.460924\n",
      "[500]\ttraining's binary_logloss: 0.460703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613475\n",
      "[2]\ttraining's binary_logloss: 0.6117\n",
      "[3]\ttraining's binary_logloss: 0.609999\n",
      "[4]\ttraining's binary_logloss: 0.608314\n",
      "[5]\ttraining's binary_logloss: 0.606872\n",
      "[6]\ttraining's binary_logloss: 0.605519\n",
      "[7]\ttraining's binary_logloss: 0.604099\n",
      "[8]\ttraining's binary_logloss: 0.602739\n",
      "[9]\ttraining's binary_logloss: 0.601396\n",
      "[10]\ttraining's binary_logloss: 0.600212\n",
      "[11]\ttraining's binary_logloss: 0.598936\n",
      "[12]\ttraining's binary_logloss: 0.597603\n",
      "[13]\ttraining's binary_logloss: 0.596308\n",
      "[14]\ttraining's binary_logloss: 0.595184\n",
      "[15]\ttraining's binary_logloss: 0.593956\n",
      "[16]\ttraining's binary_logloss: 0.592721\n",
      "[17]\ttraining's binary_logloss: 0.59157\n",
      "[18]\ttraining's binary_logloss: 0.590392\n",
      "[19]\ttraining's binary_logloss: 0.589309\n",
      "[20]\ttraining's binary_logloss: 0.588306\n",
      "[21]\ttraining's binary_logloss: 0.587286\n",
      "[22]\ttraining's binary_logloss: 0.586299\n",
      "[23]\ttraining's binary_logloss: 0.585337\n",
      "[24]\ttraining's binary_logloss: 0.584355\n",
      "[25]\ttraining's binary_logloss: 0.583431\n",
      "[26]\ttraining's binary_logloss: 0.582556\n",
      "[27]\ttraining's binary_logloss: 0.581689\n",
      "[28]\ttraining's binary_logloss: 0.580894\n",
      "[29]\ttraining's binary_logloss: 0.580103\n",
      "[30]\ttraining's binary_logloss: 0.579287\n",
      "[31]\ttraining's binary_logloss: 0.578494\n",
      "[32]\ttraining's binary_logloss: 0.57763\n",
      "[33]\ttraining's binary_logloss: 0.576814\n",
      "[34]\ttraining's binary_logloss: 0.576001\n",
      "[35]\ttraining's binary_logloss: 0.575203\n",
      "[36]\ttraining's binary_logloss: 0.574415\n",
      "[37]\ttraining's binary_logloss: 0.573653\n",
      "[38]\ttraining's binary_logloss: 0.572973\n",
      "[39]\ttraining's binary_logloss: 0.572277\n",
      "[40]\ttraining's binary_logloss: 0.571574\n",
      "[41]\ttraining's binary_logloss: 0.570959\n",
      "[42]\ttraining's binary_logloss: 0.570315\n",
      "[43]\ttraining's binary_logloss: 0.569739\n",
      "[44]\ttraining's binary_logloss: 0.569185\n",
      "[45]\ttraining's binary_logloss: 0.568619\n",
      "[46]\ttraining's binary_logloss: 0.568071\n",
      "[47]\ttraining's binary_logloss: 0.567451\n",
      "[48]\ttraining's binary_logloss: 0.566826\n",
      "[49]\ttraining's binary_logloss: 0.566331\n",
      "[50]\ttraining's binary_logloss: 0.565727\n",
      "[51]\ttraining's binary_logloss: 0.565095\n",
      "[52]\ttraining's binary_logloss: 0.564563\n",
      "[53]\ttraining's binary_logloss: 0.564004\n",
      "[54]\ttraining's binary_logloss: 0.563455\n",
      "[55]\ttraining's binary_logloss: 0.562973\n",
      "[56]\ttraining's binary_logloss: 0.562451\n",
      "[57]\ttraining's binary_logloss: 0.56191\n",
      "[58]\ttraining's binary_logloss: 0.561406\n",
      "[59]\ttraining's binary_logloss: 0.560948\n",
      "[60]\ttraining's binary_logloss: 0.560426\n",
      "[61]\ttraining's binary_logloss: 0.559929\n",
      "[62]\ttraining's binary_logloss: 0.559472\n",
      "[63]\ttraining's binary_logloss: 0.558999\n",
      "[64]\ttraining's binary_logloss: 0.558567\n",
      "[65]\ttraining's binary_logloss: 0.558129\n",
      "[66]\ttraining's binary_logloss: 0.557722\n",
      "[67]\ttraining's binary_logloss: 0.557308\n",
      "[68]\ttraining's binary_logloss: 0.556892\n",
      "[69]\ttraining's binary_logloss: 0.55649\n",
      "[70]\ttraining's binary_logloss: 0.556126\n",
      "[71]\ttraining's binary_logloss: 0.555746\n",
      "[72]\ttraining's binary_logloss: 0.555361\n",
      "[73]\ttraining's binary_logloss: 0.554974\n",
      "[74]\ttraining's binary_logloss: 0.554624\n",
      "[75]\ttraining's binary_logloss: 0.55431\n",
      "[76]\ttraining's binary_logloss: 0.553952\n",
      "[77]\ttraining's binary_logloss: 0.553597\n",
      "[78]\ttraining's binary_logloss: 0.553304\n",
      "[79]\ttraining's binary_logloss: 0.552906\n",
      "[80]\ttraining's binary_logloss: 0.552512\n",
      "[81]\ttraining's binary_logloss: 0.552131\n",
      "[82]\ttraining's binary_logloss: 0.55184\n",
      "[83]\ttraining's binary_logloss: 0.55147\n",
      "[84]\ttraining's binary_logloss: 0.551114\n",
      "[85]\ttraining's binary_logloss: 0.550771\n",
      "[86]\ttraining's binary_logloss: 0.550449\n",
      "[87]\ttraining's binary_logloss: 0.550088\n",
      "[88]\ttraining's binary_logloss: 0.54971\n",
      "[89]\ttraining's binary_logloss: 0.549342\n",
      "[90]\ttraining's binary_logloss: 0.548988\n",
      "[91]\ttraining's binary_logloss: 0.548659\n",
      "[92]\ttraining's binary_logloss: 0.548331\n",
      "[93]\ttraining's binary_logloss: 0.548016\n",
      "[94]\ttraining's binary_logloss: 0.547715\n",
      "[95]\ttraining's binary_logloss: 0.547405\n",
      "[96]\ttraining's binary_logloss: 0.547083\n",
      "[97]\ttraining's binary_logloss: 0.546759\n",
      "[98]\ttraining's binary_logloss: 0.546479\n",
      "[99]\ttraining's binary_logloss: 0.546236\n",
      "[100]\ttraining's binary_logloss: 0.545951\n",
      "[101]\ttraining's binary_logloss: 0.54568\n",
      "[102]\ttraining's binary_logloss: 0.54541\n",
      "[103]\ttraining's binary_logloss: 0.545127\n",
      "[104]\ttraining's binary_logloss: 0.54487\n",
      "[105]\ttraining's binary_logloss: 0.544607\n",
      "[106]\ttraining's binary_logloss: 0.544277\n",
      "[107]\ttraining's binary_logloss: 0.544002\n",
      "[108]\ttraining's binary_logloss: 0.543729\n",
      "[109]\ttraining's binary_logloss: 0.543436\n",
      "[110]\ttraining's binary_logloss: 0.543145\n",
      "[111]\ttraining's binary_logloss: 0.542858\n",
      "[112]\ttraining's binary_logloss: 0.542579\n",
      "[113]\ttraining's binary_logloss: 0.542307\n",
      "[114]\ttraining's binary_logloss: 0.542046\n",
      "[115]\ttraining's binary_logloss: 0.541814\n",
      "[116]\ttraining's binary_logloss: 0.54154\n",
      "[117]\ttraining's binary_logloss: 0.541289\n",
      "[118]\ttraining's binary_logloss: 0.541047\n",
      "[119]\ttraining's binary_logloss: 0.54082\n",
      "[120]\ttraining's binary_logloss: 0.540585\n",
      "[121]\ttraining's binary_logloss: 0.540333\n",
      "[122]\ttraining's binary_logloss: 0.540045\n",
      "[123]\ttraining's binary_logloss: 0.5398\n",
      "[124]\ttraining's binary_logloss: 0.539557\n",
      "[125]\ttraining's binary_logloss: 0.539313\n",
      "[126]\ttraining's binary_logloss: 0.539054\n",
      "[127]\ttraining's binary_logloss: 0.538773\n",
      "[128]\ttraining's binary_logloss: 0.538498\n",
      "[129]\ttraining's binary_logloss: 0.538258\n",
      "[130]\ttraining's binary_logloss: 0.53804\n",
      "[131]\ttraining's binary_logloss: 0.537788\n",
      "[132]\ttraining's binary_logloss: 0.537553\n",
      "[133]\ttraining's binary_logloss: 0.53733\n",
      "[134]\ttraining's binary_logloss: 0.537113\n",
      "[135]\ttraining's binary_logloss: 0.536863\n",
      "[136]\ttraining's binary_logloss: 0.536628\n",
      "[137]\ttraining's binary_logloss: 0.536375\n",
      "[138]\ttraining's binary_logloss: 0.536135\n",
      "[139]\ttraining's binary_logloss: 0.535901\n",
      "[140]\ttraining's binary_logloss: 0.535692\n",
      "[141]\ttraining's binary_logloss: 0.535497\n",
      "[142]\ttraining's binary_logloss: 0.535284\n",
      "[143]\ttraining's binary_logloss: 0.535048\n",
      "[144]\ttraining's binary_logloss: 0.534833\n",
      "[145]\ttraining's binary_logloss: 0.534606\n",
      "[146]\ttraining's binary_logloss: 0.534369\n",
      "[147]\ttraining's binary_logloss: 0.534132\n",
      "[148]\ttraining's binary_logloss: 0.533898\n",
      "[149]\ttraining's binary_logloss: 0.533675\n",
      "[150]\ttraining's binary_logloss: 0.53346\n",
      "[151]\ttraining's binary_logloss: 0.533179\n",
      "[152]\ttraining's binary_logloss: 0.532915\n",
      "[153]\ttraining's binary_logloss: 0.532664\n",
      "[154]\ttraining's binary_logloss: 0.532416\n",
      "[155]\ttraining's binary_logloss: 0.532178\n",
      "[156]\ttraining's binary_logloss: 0.531955\n",
      "[157]\ttraining's binary_logloss: 0.531729\n",
      "[158]\ttraining's binary_logloss: 0.531507\n",
      "[159]\ttraining's binary_logloss: 0.531283\n",
      "[160]\ttraining's binary_logloss: 0.531107\n",
      "[161]\ttraining's binary_logloss: 0.530833\n",
      "[162]\ttraining's binary_logloss: 0.530585\n",
      "[163]\ttraining's binary_logloss: 0.530349\n",
      "[164]\ttraining's binary_logloss: 0.530075\n",
      "[165]\ttraining's binary_logloss: 0.529856\n",
      "[166]\ttraining's binary_logloss: 0.529581\n",
      "[167]\ttraining's binary_logloss: 0.529353\n",
      "[168]\ttraining's binary_logloss: 0.529098\n",
      "[169]\ttraining's binary_logloss: 0.52884\n",
      "[170]\ttraining's binary_logloss: 0.528632\n",
      "[171]\ttraining's binary_logloss: 0.528387\n",
      "[172]\ttraining's binary_logloss: 0.528124\n",
      "[173]\ttraining's binary_logloss: 0.527892\n",
      "[174]\ttraining's binary_logloss: 0.527676\n",
      "[175]\ttraining's binary_logloss: 0.527446\n",
      "[176]\ttraining's binary_logloss: 0.527238\n",
      "[177]\ttraining's binary_logloss: 0.527013\n",
      "[178]\ttraining's binary_logloss: 0.526766\n",
      "[179]\ttraining's binary_logloss: 0.526557\n",
      "[180]\ttraining's binary_logloss: 0.52637\n",
      "[181]\ttraining's binary_logloss: 0.526217\n",
      "[182]\ttraining's binary_logloss: 0.526014\n",
      "[183]\ttraining's binary_logloss: 0.52585\n",
      "[184]\ttraining's binary_logloss: 0.525627\n",
      "[185]\ttraining's binary_logloss: 0.525433\n",
      "[186]\ttraining's binary_logloss: 0.525183\n",
      "[187]\ttraining's binary_logloss: 0.524897\n",
      "[188]\ttraining's binary_logloss: 0.524625\n",
      "[189]\ttraining's binary_logloss: 0.524365\n",
      "[190]\ttraining's binary_logloss: 0.524151\n",
      "[191]\ttraining's binary_logloss: 0.523946\n",
      "[192]\ttraining's binary_logloss: 0.523722\n",
      "[193]\ttraining's binary_logloss: 0.523515\n",
      "[194]\ttraining's binary_logloss: 0.523283\n",
      "[195]\ttraining's binary_logloss: 0.523087\n",
      "[196]\ttraining's binary_logloss: 0.522843\n",
      "[197]\ttraining's binary_logloss: 0.522591\n",
      "[198]\ttraining's binary_logloss: 0.522372\n",
      "[199]\ttraining's binary_logloss: 0.522191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's binary_logloss: 0.521953\n",
      "[201]\ttraining's binary_logloss: 0.521721\n",
      "[202]\ttraining's binary_logloss: 0.521533\n",
      "[203]\ttraining's binary_logloss: 0.521285\n",
      "[204]\ttraining's binary_logloss: 0.521051\n",
      "[205]\ttraining's binary_logloss: 0.520832\n",
      "[206]\ttraining's binary_logloss: 0.520574\n",
      "[207]\ttraining's binary_logloss: 0.520324\n",
      "[208]\ttraining's binary_logloss: 0.52011\n",
      "[209]\ttraining's binary_logloss: 0.519881\n",
      "[210]\ttraining's binary_logloss: 0.51966\n",
      "[211]\ttraining's binary_logloss: 0.519448\n",
      "[212]\ttraining's binary_logloss: 0.519251\n",
      "[213]\ttraining's binary_logloss: 0.519039\n",
      "[214]\ttraining's binary_logloss: 0.518858\n",
      "[215]\ttraining's binary_logloss: 0.518668\n",
      "[216]\ttraining's binary_logloss: 0.518391\n",
      "[217]\ttraining's binary_logloss: 0.518175\n",
      "[218]\ttraining's binary_logloss: 0.517925\n",
      "[219]\ttraining's binary_logloss: 0.517686\n",
      "[220]\ttraining's binary_logloss: 0.517427\n",
      "[221]\ttraining's binary_logloss: 0.517132\n",
      "[222]\ttraining's binary_logloss: 0.516909\n",
      "[223]\ttraining's binary_logloss: 0.516673\n",
      "[224]\ttraining's binary_logloss: 0.516382\n",
      "[225]\ttraining's binary_logloss: 0.516173\n",
      "[226]\ttraining's binary_logloss: 0.515919\n",
      "[227]\ttraining's binary_logloss: 0.515735\n",
      "[228]\ttraining's binary_logloss: 0.515554\n",
      "[229]\ttraining's binary_logloss: 0.515371\n",
      "[230]\ttraining's binary_logloss: 0.515131\n",
      "[231]\ttraining's binary_logloss: 0.514862\n",
      "[232]\ttraining's binary_logloss: 0.514657\n",
      "[233]\ttraining's binary_logloss: 0.514457\n",
      "[234]\ttraining's binary_logloss: 0.514218\n",
      "[235]\ttraining's binary_logloss: 0.513969\n",
      "[236]\ttraining's binary_logloss: 0.513711\n",
      "[237]\ttraining's binary_logloss: 0.513465\n",
      "[238]\ttraining's binary_logloss: 0.513259\n",
      "[239]\ttraining's binary_logloss: 0.512992\n",
      "[240]\ttraining's binary_logloss: 0.512737\n",
      "[241]\ttraining's binary_logloss: 0.512484\n",
      "[242]\ttraining's binary_logloss: 0.512249\n",
      "[243]\ttraining's binary_logloss: 0.51201\n",
      "[244]\ttraining's binary_logloss: 0.511769\n",
      "[245]\ttraining's binary_logloss: 0.511537\n",
      "[246]\ttraining's binary_logloss: 0.511285\n",
      "[247]\ttraining's binary_logloss: 0.511049\n",
      "[248]\ttraining's binary_logloss: 0.510831\n",
      "[249]\ttraining's binary_logloss: 0.510612\n",
      "[250]\ttraining's binary_logloss: 0.510404\n",
      "[251]\ttraining's binary_logloss: 0.510156\n",
      "[252]\ttraining's binary_logloss: 0.509959\n",
      "[253]\ttraining's binary_logloss: 0.509756\n",
      "[254]\ttraining's binary_logloss: 0.509552\n",
      "[255]\ttraining's binary_logloss: 0.509343\n",
      "[256]\ttraining's binary_logloss: 0.509097\n",
      "[257]\ttraining's binary_logloss: 0.508806\n",
      "[258]\ttraining's binary_logloss: 0.508559\n",
      "[259]\ttraining's binary_logloss: 0.50832\n",
      "[260]\ttraining's binary_logloss: 0.508101\n",
      "[261]\ttraining's binary_logloss: 0.507871\n",
      "[262]\ttraining's binary_logloss: 0.50762\n",
      "[263]\ttraining's binary_logloss: 0.507429\n",
      "[264]\ttraining's binary_logloss: 0.507189\n",
      "[265]\ttraining's binary_logloss: 0.506953\n",
      "[266]\ttraining's binary_logloss: 0.50676\n",
      "[267]\ttraining's binary_logloss: 0.506535\n",
      "[268]\ttraining's binary_logloss: 0.506372\n",
      "[269]\ttraining's binary_logloss: 0.506213\n",
      "[270]\ttraining's binary_logloss: 0.506036\n",
      "[271]\ttraining's binary_logloss: 0.505761\n",
      "[272]\ttraining's binary_logloss: 0.505483\n",
      "[273]\ttraining's binary_logloss: 0.505224\n",
      "[274]\ttraining's binary_logloss: 0.50499\n",
      "[275]\ttraining's binary_logloss: 0.504721\n",
      "[276]\ttraining's binary_logloss: 0.504465\n",
      "[277]\ttraining's binary_logloss: 0.504213\n",
      "[278]\ttraining's binary_logloss: 0.503936\n",
      "[279]\ttraining's binary_logloss: 0.503637\n",
      "[280]\ttraining's binary_logloss: 0.50337\n",
      "[281]\ttraining's binary_logloss: 0.503109\n",
      "[282]\ttraining's binary_logloss: 0.502857\n",
      "[283]\ttraining's binary_logloss: 0.502612\n",
      "[284]\ttraining's binary_logloss: 0.502372\n",
      "[285]\ttraining's binary_logloss: 0.502135\n",
      "[286]\ttraining's binary_logloss: 0.501888\n",
      "[287]\ttraining's binary_logloss: 0.50162\n",
      "[288]\ttraining's binary_logloss: 0.501355\n",
      "[289]\ttraining's binary_logloss: 0.501121\n",
      "[290]\ttraining's binary_logloss: 0.500888\n",
      "[291]\ttraining's binary_logloss: 0.500653\n",
      "[292]\ttraining's binary_logloss: 0.500368\n",
      "[293]\ttraining's binary_logloss: 0.50012\n",
      "[294]\ttraining's binary_logloss: 0.499896\n",
      "[295]\ttraining's binary_logloss: 0.499613\n",
      "[296]\ttraining's binary_logloss: 0.499406\n",
      "[297]\ttraining's binary_logloss: 0.499194\n",
      "[298]\ttraining's binary_logloss: 0.498998\n",
      "[299]\ttraining's binary_logloss: 0.498788\n",
      "[300]\ttraining's binary_logloss: 0.498596\n",
      "[301]\ttraining's binary_logloss: 0.498299\n",
      "[302]\ttraining's binary_logloss: 0.498021\n",
      "[303]\ttraining's binary_logloss: 0.49777\n",
      "[304]\ttraining's binary_logloss: 0.497489\n",
      "[305]\ttraining's binary_logloss: 0.497246\n",
      "[306]\ttraining's binary_logloss: 0.497012\n",
      "[307]\ttraining's binary_logloss: 0.496756\n",
      "[308]\ttraining's binary_logloss: 0.496514\n",
      "[309]\ttraining's binary_logloss: 0.496257\n",
      "[310]\ttraining's binary_logloss: 0.496051\n",
      "[311]\ttraining's binary_logloss: 0.495829\n",
      "[312]\ttraining's binary_logloss: 0.495618\n",
      "[313]\ttraining's binary_logloss: 0.495402\n",
      "[314]\ttraining's binary_logloss: 0.495188\n",
      "[315]\ttraining's binary_logloss: 0.494982\n",
      "[316]\ttraining's binary_logloss: 0.494765\n",
      "[317]\ttraining's binary_logloss: 0.494525\n",
      "[318]\ttraining's binary_logloss: 0.494319\n",
      "[319]\ttraining's binary_logloss: 0.494094\n",
      "[320]\ttraining's binary_logloss: 0.493877\n",
      "[321]\ttraining's binary_logloss: 0.493618\n",
      "[322]\ttraining's binary_logloss: 0.493381\n",
      "[323]\ttraining's binary_logloss: 0.493164\n",
      "[324]\ttraining's binary_logloss: 0.492968\n",
      "[325]\ttraining's binary_logloss: 0.492751\n",
      "[326]\ttraining's binary_logloss: 0.492473\n",
      "[327]\ttraining's binary_logloss: 0.492208\n",
      "[328]\ttraining's binary_logloss: 0.491902\n",
      "[329]\ttraining's binary_logloss: 0.491639\n",
      "[330]\ttraining's binary_logloss: 0.491395\n",
      "[331]\ttraining's binary_logloss: 0.49114\n",
      "[332]\ttraining's binary_logloss: 0.490913\n",
      "[333]\ttraining's binary_logloss: 0.49068\n",
      "[334]\ttraining's binary_logloss: 0.490453\n",
      "[335]\ttraining's binary_logloss: 0.490208\n",
      "[336]\ttraining's binary_logloss: 0.489917\n",
      "[337]\ttraining's binary_logloss: 0.489692\n",
      "[338]\ttraining's binary_logloss: 0.489478\n",
      "[339]\ttraining's binary_logloss: 0.489251\n",
      "[340]\ttraining's binary_logloss: 0.489019\n",
      "[341]\ttraining's binary_logloss: 0.488767\n",
      "[342]\ttraining's binary_logloss: 0.48852\n",
      "[343]\ttraining's binary_logloss: 0.488314\n",
      "[344]\ttraining's binary_logloss: 0.488086\n",
      "[345]\ttraining's binary_logloss: 0.487863\n",
      "[346]\ttraining's binary_logloss: 0.487622\n",
      "[347]\ttraining's binary_logloss: 0.487403\n",
      "[348]\ttraining's binary_logloss: 0.487195\n",
      "[349]\ttraining's binary_logloss: 0.487014\n",
      "[350]\ttraining's binary_logloss: 0.486784\n",
      "[351]\ttraining's binary_logloss: 0.486531\n",
      "[352]\ttraining's binary_logloss: 0.486303\n",
      "[353]\ttraining's binary_logloss: 0.486065\n",
      "[354]\ttraining's binary_logloss: 0.485843\n",
      "[355]\ttraining's binary_logloss: 0.485626\n",
      "[356]\ttraining's binary_logloss: 0.485334\n",
      "[357]\ttraining's binary_logloss: 0.485034\n",
      "[358]\ttraining's binary_logloss: 0.484758\n",
      "[359]\ttraining's binary_logloss: 0.48451\n",
      "[360]\ttraining's binary_logloss: 0.484246\n",
      "[361]\ttraining's binary_logloss: 0.483985\n",
      "[362]\ttraining's binary_logloss: 0.483704\n",
      "[363]\ttraining's binary_logloss: 0.48347\n",
      "[364]\ttraining's binary_logloss: 0.483235\n",
      "[365]\ttraining's binary_logloss: 0.482986\n",
      "[366]\ttraining's binary_logloss: 0.48273\n",
      "[367]\ttraining's binary_logloss: 0.482478\n",
      "[368]\ttraining's binary_logloss: 0.482239\n",
      "[369]\ttraining's binary_logloss: 0.48199\n",
      "[370]\ttraining's binary_logloss: 0.48175\n",
      "[371]\ttraining's binary_logloss: 0.481558\n",
      "[372]\ttraining's binary_logloss: 0.48138\n",
      "[373]\ttraining's binary_logloss: 0.481184\n",
      "[374]\ttraining's binary_logloss: 0.481013\n",
      "[375]\ttraining's binary_logloss: 0.480818\n",
      "[376]\ttraining's binary_logloss: 0.480578\n",
      "[377]\ttraining's binary_logloss: 0.480337\n",
      "[378]\ttraining's binary_logloss: 0.480101\n",
      "[379]\ttraining's binary_logloss: 0.479874\n",
      "[380]\ttraining's binary_logloss: 0.479662\n",
      "[381]\ttraining's binary_logloss: 0.479433\n",
      "[382]\ttraining's binary_logloss: 0.47921\n",
      "[383]\ttraining's binary_logloss: 0.47899\n",
      "[384]\ttraining's binary_logloss: 0.478818\n",
      "[385]\ttraining's binary_logloss: 0.478603\n",
      "[386]\ttraining's binary_logloss: 0.478356\n",
      "[387]\ttraining's binary_logloss: 0.478101\n",
      "[388]\ttraining's binary_logloss: 0.47783\n",
      "[389]\ttraining's binary_logloss: 0.477603\n",
      "[390]\ttraining's binary_logloss: 0.477372\n",
      "[391]\ttraining's binary_logloss: 0.477127\n",
      "[392]\ttraining's binary_logloss: 0.476894\n",
      "[393]\ttraining's binary_logloss: 0.476657\n",
      "[394]\ttraining's binary_logloss: 0.476439\n",
      "[395]\ttraining's binary_logloss: 0.476251\n",
      "[396]\ttraining's binary_logloss: 0.476008\n",
      "[397]\ttraining's binary_logloss: 0.475774\n",
      "[398]\ttraining's binary_logloss: 0.475518\n",
      "[399]\ttraining's binary_logloss: 0.475305\n",
      "[400]\ttraining's binary_logloss: 0.475068\n",
      "[401]\ttraining's binary_logloss: 0.474842\n",
      "[402]\ttraining's binary_logloss: 0.474647\n",
      "[403]\ttraining's binary_logloss: 0.474432\n",
      "[404]\ttraining's binary_logloss: 0.474226\n",
      "[405]\ttraining's binary_logloss: 0.474007\n",
      "[406]\ttraining's binary_logloss: 0.473786\n",
      "[407]\ttraining's binary_logloss: 0.473544\n",
      "[408]\ttraining's binary_logloss: 0.473349\n",
      "[409]\ttraining's binary_logloss: 0.473119\n",
      "[410]\ttraining's binary_logloss: 0.472889\n",
      "[411]\ttraining's binary_logloss: 0.472575\n",
      "[412]\ttraining's binary_logloss: 0.472322\n",
      "[413]\ttraining's binary_logloss: 0.472097\n",
      "[414]\ttraining's binary_logloss: 0.471847\n",
      "[415]\ttraining's binary_logloss: 0.471601\n",
      "[416]\ttraining's binary_logloss: 0.471358\n",
      "[417]\ttraining's binary_logloss: 0.471142\n",
      "[418]\ttraining's binary_logloss: 0.47091\n",
      "[419]\ttraining's binary_logloss: 0.470676\n",
      "[420]\ttraining's binary_logloss: 0.47045\n",
      "[421]\ttraining's binary_logloss: 0.47024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[422]\ttraining's binary_logloss: 0.469995\n",
      "[423]\ttraining's binary_logloss: 0.4698\n",
      "[424]\ttraining's binary_logloss: 0.469618\n",
      "[425]\ttraining's binary_logloss: 0.469449\n",
      "[426]\ttraining's binary_logloss: 0.469272\n",
      "[427]\ttraining's binary_logloss: 0.469029\n",
      "[428]\ttraining's binary_logloss: 0.468824\n",
      "[429]\ttraining's binary_logloss: 0.468592\n",
      "[430]\ttraining's binary_logloss: 0.468357\n",
      "[431]\ttraining's binary_logloss: 0.468064\n",
      "[432]\ttraining's binary_logloss: 0.467771\n",
      "[433]\ttraining's binary_logloss: 0.467508\n",
      "[434]\ttraining's binary_logloss: 0.467215\n",
      "[435]\ttraining's binary_logloss: 0.466943\n",
      "[436]\ttraining's binary_logloss: 0.466658\n",
      "[437]\ttraining's binary_logloss: 0.466367\n",
      "[438]\ttraining's binary_logloss: 0.466104\n",
      "[439]\ttraining's binary_logloss: 0.465856\n",
      "[440]\ttraining's binary_logloss: 0.465606\n",
      "[441]\ttraining's binary_logloss: 0.465351\n",
      "[442]\ttraining's binary_logloss: 0.465097\n",
      "[443]\ttraining's binary_logloss: 0.464843\n",
      "[444]\ttraining's binary_logloss: 0.464615\n",
      "[445]\ttraining's binary_logloss: 0.46442\n",
      "[446]\ttraining's binary_logloss: 0.464189\n",
      "[447]\ttraining's binary_logloss: 0.463928\n",
      "[448]\ttraining's binary_logloss: 0.463677\n",
      "[449]\ttraining's binary_logloss: 0.463415\n",
      "[450]\ttraining's binary_logloss: 0.463193\n",
      "[451]\ttraining's binary_logloss: 0.462957\n",
      "[452]\ttraining's binary_logloss: 0.462745\n",
      "[453]\ttraining's binary_logloss: 0.462582\n",
      "[454]\ttraining's binary_logloss: 0.46237\n",
      "[455]\ttraining's binary_logloss: 0.462149\n",
      "[456]\ttraining's binary_logloss: 0.461928\n",
      "[457]\ttraining's binary_logloss: 0.461738\n",
      "[458]\ttraining's binary_logloss: 0.461524\n",
      "[459]\ttraining's binary_logloss: 0.461311\n",
      "[460]\ttraining's binary_logloss: 0.461105\n",
      "[461]\ttraining's binary_logloss: 0.460874\n",
      "[462]\ttraining's binary_logloss: 0.460661\n",
      "[463]\ttraining's binary_logloss: 0.460414\n",
      "[464]\ttraining's binary_logloss: 0.460157\n",
      "[465]\ttraining's binary_logloss: 0.459908\n",
      "[466]\ttraining's binary_logloss: 0.459687\n",
      "[467]\ttraining's binary_logloss: 0.459468\n",
      "[468]\ttraining's binary_logloss: 0.459231\n",
      "[469]\ttraining's binary_logloss: 0.459003\n",
      "[470]\ttraining's binary_logloss: 0.458773\n",
      "[471]\ttraining's binary_logloss: 0.458598\n",
      "[472]\ttraining's binary_logloss: 0.458393\n",
      "[473]\ttraining's binary_logloss: 0.458184\n",
      "[474]\ttraining's binary_logloss: 0.457959\n",
      "[475]\ttraining's binary_logloss: 0.457764\n",
      "[476]\ttraining's binary_logloss: 0.457527\n",
      "[477]\ttraining's binary_logloss: 0.45729\n",
      "[478]\ttraining's binary_logloss: 0.457067\n",
      "[479]\ttraining's binary_logloss: 0.456842\n",
      "[480]\ttraining's binary_logloss: 0.456637\n",
      "[481]\ttraining's binary_logloss: 0.456427\n",
      "[482]\ttraining's binary_logloss: 0.456179\n",
      "[483]\ttraining's binary_logloss: 0.455957\n",
      "[484]\ttraining's binary_logloss: 0.455731\n",
      "[485]\ttraining's binary_logloss: 0.455506\n",
      "[486]\ttraining's binary_logloss: 0.455229\n",
      "[487]\ttraining's binary_logloss: 0.454994\n",
      "[488]\ttraining's binary_logloss: 0.454755\n",
      "[489]\ttraining's binary_logloss: 0.454531\n",
      "[490]\ttraining's binary_logloss: 0.454291\n",
      "[491]\ttraining's binary_logloss: 0.454106\n",
      "[492]\ttraining's binary_logloss: 0.453901\n",
      "[493]\ttraining's binary_logloss: 0.453709\n",
      "[494]\ttraining's binary_logloss: 0.453519\n",
      "[495]\ttraining's binary_logloss: 0.45334\n",
      "[496]\ttraining's binary_logloss: 0.453083\n",
      "[497]\ttraining's binary_logloss: 0.45285\n",
      "[498]\ttraining's binary_logloss: 0.45261\n",
      "[499]\ttraining's binary_logloss: 0.452381\n",
      "[500]\ttraining's binary_logloss: 0.452164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.612654\n",
      "[2]\ttraining's binary_logloss: 0.611024\n",
      "[3]\ttraining's binary_logloss: 0.609438\n",
      "[4]\ttraining's binary_logloss: 0.607916\n",
      "[5]\ttraining's binary_logloss: 0.606436\n",
      "[6]\ttraining's binary_logloss: 0.605082\n",
      "[7]\ttraining's binary_logloss: 0.603626\n",
      "[8]\ttraining's binary_logloss: 0.602268\n",
      "[9]\ttraining's binary_logloss: 0.600872\n",
      "[10]\ttraining's binary_logloss: 0.599547\n",
      "[11]\ttraining's binary_logloss: 0.598238\n",
      "[12]\ttraining's binary_logloss: 0.596973\n",
      "[13]\ttraining's binary_logloss: 0.595742\n",
      "[14]\ttraining's binary_logloss: 0.59465\n",
      "[15]\ttraining's binary_logloss: 0.593485\n",
      "[16]\ttraining's binary_logloss: 0.592376\n",
      "[17]\ttraining's binary_logloss: 0.591302\n",
      "[18]\ttraining's binary_logloss: 0.590167\n",
      "[19]\ttraining's binary_logloss: 0.589112\n",
      "[20]\ttraining's binary_logloss: 0.588084\n",
      "[21]\ttraining's binary_logloss: 0.58708\n",
      "[22]\ttraining's binary_logloss: 0.586148\n",
      "[23]\ttraining's binary_logloss: 0.585188\n",
      "[24]\ttraining's binary_logloss: 0.584281\n",
      "[25]\ttraining's binary_logloss: 0.583388\n",
      "[26]\ttraining's binary_logloss: 0.582538\n",
      "[27]\ttraining's binary_logloss: 0.581709\n",
      "[28]\ttraining's binary_logloss: 0.580888\n",
      "[29]\ttraining's binary_logloss: 0.58011\n",
      "[30]\ttraining's binary_logloss: 0.579281\n",
      "[31]\ttraining's binary_logloss: 0.578495\n",
      "[32]\ttraining's binary_logloss: 0.577745\n",
      "[33]\ttraining's binary_logloss: 0.577012\n",
      "[34]\ttraining's binary_logloss: 0.576401\n",
      "[35]\ttraining's binary_logloss: 0.575657\n",
      "[36]\ttraining's binary_logloss: 0.574938\n",
      "[37]\ttraining's binary_logloss: 0.574202\n",
      "[38]\ttraining's binary_logloss: 0.573492\n",
      "[39]\ttraining's binary_logloss: 0.572864\n",
      "[40]\ttraining's binary_logloss: 0.572198\n",
      "[41]\ttraining's binary_logloss: 0.571552\n",
      "[42]\ttraining's binary_logloss: 0.570919\n",
      "[43]\ttraining's binary_logloss: 0.570301\n",
      "[44]\ttraining's binary_logloss: 0.569653\n",
      "[45]\ttraining's binary_logloss: 0.569015\n",
      "[46]\ttraining's binary_logloss: 0.568388\n",
      "[47]\ttraining's binary_logloss: 0.567775\n",
      "[48]\ttraining's binary_logloss: 0.567165\n",
      "[49]\ttraining's binary_logloss: 0.566599\n",
      "[50]\ttraining's binary_logloss: 0.566042\n",
      "[51]\ttraining's binary_logloss: 0.5655\n",
      "[52]\ttraining's binary_logloss: 0.564991\n",
      "[53]\ttraining's binary_logloss: 0.564467\n",
      "[54]\ttraining's binary_logloss: 0.563955\n",
      "[55]\ttraining's binary_logloss: 0.563484\n",
      "[56]\ttraining's binary_logloss: 0.563021\n",
      "[57]\ttraining's binary_logloss: 0.562504\n",
      "[58]\ttraining's binary_logloss: 0.562051\n",
      "[59]\ttraining's binary_logloss: 0.561638\n",
      "[60]\ttraining's binary_logloss: 0.561204\n",
      "[61]\ttraining's binary_logloss: 0.560779\n",
      "[62]\ttraining's binary_logloss: 0.560363\n",
      "[63]\ttraining's binary_logloss: 0.559915\n",
      "[64]\ttraining's binary_logloss: 0.55952\n",
      "[65]\ttraining's binary_logloss: 0.559156\n",
      "[66]\ttraining's binary_logloss: 0.558676\n",
      "[67]\ttraining's binary_logloss: 0.558273\n",
      "[68]\ttraining's binary_logloss: 0.557809\n",
      "[69]\ttraining's binary_logloss: 0.55743\n",
      "[70]\ttraining's binary_logloss: 0.556993\n",
      "[71]\ttraining's binary_logloss: 0.556602\n",
      "[72]\ttraining's binary_logloss: 0.556223\n",
      "[73]\ttraining's binary_logloss: 0.555869\n",
      "[74]\ttraining's binary_logloss: 0.555449\n",
      "[75]\ttraining's binary_logloss: 0.55512\n",
      "[76]\ttraining's binary_logloss: 0.554747\n",
      "[77]\ttraining's binary_logloss: 0.554365\n",
      "[78]\ttraining's binary_logloss: 0.554087\n",
      "[79]\ttraining's binary_logloss: 0.553759\n",
      "[80]\ttraining's binary_logloss: 0.553464\n",
      "[81]\ttraining's binary_logloss: 0.553092\n",
      "[82]\ttraining's binary_logloss: 0.552783\n",
      "[83]\ttraining's binary_logloss: 0.552497\n",
      "[84]\ttraining's binary_logloss: 0.55217\n",
      "[85]\ttraining's binary_logloss: 0.551852\n",
      "[86]\ttraining's binary_logloss: 0.551533\n",
      "[87]\ttraining's binary_logloss: 0.551195\n",
      "[88]\ttraining's binary_logloss: 0.550886\n",
      "[89]\ttraining's binary_logloss: 0.550581\n",
      "[90]\ttraining's binary_logloss: 0.550265\n",
      "[91]\ttraining's binary_logloss: 0.549962\n",
      "[92]\ttraining's binary_logloss: 0.549676\n",
      "[93]\ttraining's binary_logloss: 0.549425\n",
      "[94]\ttraining's binary_logloss: 0.549151\n",
      "[95]\ttraining's binary_logloss: 0.548867\n",
      "[96]\ttraining's binary_logloss: 0.548627\n",
      "[97]\ttraining's binary_logloss: 0.54834\n",
      "[98]\ttraining's binary_logloss: 0.548029\n",
      "[99]\ttraining's binary_logloss: 0.547797\n",
      "[100]\ttraining's binary_logloss: 0.547529\n",
      "[101]\ttraining's binary_logloss: 0.547282\n",
      "[102]\ttraining's binary_logloss: 0.547051\n",
      "[103]\ttraining's binary_logloss: 0.546766\n",
      "[104]\ttraining's binary_logloss: 0.546522\n",
      "[105]\ttraining's binary_logloss: 0.546292\n",
      "[106]\ttraining's binary_logloss: 0.546028\n",
      "[107]\ttraining's binary_logloss: 0.545776\n",
      "[108]\ttraining's binary_logloss: 0.545507\n",
      "[109]\ttraining's binary_logloss: 0.545307\n",
      "[110]\ttraining's binary_logloss: 0.545071\n",
      "[111]\ttraining's binary_logloss: 0.54482\n",
      "[112]\ttraining's binary_logloss: 0.544545\n",
      "[113]\ttraining's binary_logloss: 0.544312\n",
      "[114]\ttraining's binary_logloss: 0.544045\n",
      "[115]\ttraining's binary_logloss: 0.543818\n",
      "[116]\ttraining's binary_logloss: 0.543534\n",
      "[117]\ttraining's binary_logloss: 0.543245\n",
      "[118]\ttraining's binary_logloss: 0.542984\n",
      "[119]\ttraining's binary_logloss: 0.542705\n",
      "[120]\ttraining's binary_logloss: 0.542432\n",
      "[121]\ttraining's binary_logloss: 0.542209\n",
      "[122]\ttraining's binary_logloss: 0.541944\n",
      "[123]\ttraining's binary_logloss: 0.541689\n",
      "[124]\ttraining's binary_logloss: 0.541446\n",
      "[125]\ttraining's binary_logloss: 0.541193\n",
      "[126]\ttraining's binary_logloss: 0.540934\n",
      "[127]\ttraining's binary_logloss: 0.54066\n",
      "[128]\ttraining's binary_logloss: 0.540429\n",
      "[129]\ttraining's binary_logloss: 0.540177\n",
      "[130]\ttraining's binary_logloss: 0.539942\n",
      "[131]\ttraining's binary_logloss: 0.539729\n",
      "[132]\ttraining's binary_logloss: 0.539499\n",
      "[133]\ttraining's binary_logloss: 0.539286\n",
      "[134]\ttraining's binary_logloss: 0.539091\n",
      "[135]\ttraining's binary_logloss: 0.538871\n",
      "[136]\ttraining's binary_logloss: 0.538646\n",
      "[137]\ttraining's binary_logloss: 0.538439\n",
      "[138]\ttraining's binary_logloss: 0.538229\n",
      "[139]\ttraining's binary_logloss: 0.538005\n",
      "[140]\ttraining's binary_logloss: 0.537795\n",
      "[141]\ttraining's binary_logloss: 0.537545\n",
      "[142]\ttraining's binary_logloss: 0.53731\n",
      "[143]\ttraining's binary_logloss: 0.537087\n",
      "[144]\ttraining's binary_logloss: 0.536818\n",
      "[145]\ttraining's binary_logloss: 0.536559\n",
      "[146]\ttraining's binary_logloss: 0.536294\n",
      "[147]\ttraining's binary_logloss: 0.536038\n",
      "[148]\ttraining's binary_logloss: 0.535798\n",
      "[149]\ttraining's binary_logloss: 0.535568\n",
      "[150]\ttraining's binary_logloss: 0.535335\n",
      "[151]\ttraining's binary_logloss: 0.535086\n",
      "[152]\ttraining's binary_logloss: 0.534886\n",
      "[153]\ttraining's binary_logloss: 0.534637\n",
      "[154]\ttraining's binary_logloss: 0.534418\n",
      "[155]\ttraining's binary_logloss: 0.534176\n",
      "[156]\ttraining's binary_logloss: 0.533981\n",
      "[157]\ttraining's binary_logloss: 0.53379\n",
      "[158]\ttraining's binary_logloss: 0.53361\n",
      "[159]\ttraining's binary_logloss: 0.533431\n",
      "[160]\ttraining's binary_logloss: 0.533225\n",
      "[161]\ttraining's binary_logloss: 0.53294\n",
      "[162]\ttraining's binary_logloss: 0.53266\n",
      "[163]\ttraining's binary_logloss: 0.53238\n",
      "[164]\ttraining's binary_logloss: 0.532133\n",
      "[165]\ttraining's binary_logloss: 0.531869\n",
      "[166]\ttraining's binary_logloss: 0.531604\n",
      "[167]\ttraining's binary_logloss: 0.531348\n",
      "[168]\ttraining's binary_logloss: 0.531111\n",
      "[169]\ttraining's binary_logloss: 0.53086\n",
      "[170]\ttraining's binary_logloss: 0.530609\n",
      "[171]\ttraining's binary_logloss: 0.530362\n",
      "[172]\ttraining's binary_logloss: 0.530155\n",
      "[173]\ttraining's binary_logloss: 0.529946\n",
      "[174]\ttraining's binary_logloss: 0.529776\n",
      "[175]\ttraining's binary_logloss: 0.529557\n",
      "[176]\ttraining's binary_logloss: 0.529363\n",
      "[177]\ttraining's binary_logloss: 0.529167\n",
      "[178]\ttraining's binary_logloss: 0.528989\n",
      "[179]\ttraining's binary_logloss: 0.528774\n",
      "[180]\ttraining's binary_logloss: 0.528573\n",
      "[181]\ttraining's binary_logloss: 0.528358\n",
      "[182]\ttraining's binary_logloss: 0.528148\n",
      "[183]\ttraining's binary_logloss: 0.527954\n",
      "[184]\ttraining's binary_logloss: 0.527755\n",
      "[185]\ttraining's binary_logloss: 0.527556\n",
      "[186]\ttraining's binary_logloss: 0.527352\n",
      "[187]\ttraining's binary_logloss: 0.527159\n",
      "[188]\ttraining's binary_logloss: 0.526964\n",
      "[189]\ttraining's binary_logloss: 0.526775\n",
      "[190]\ttraining's binary_logloss: 0.526606\n",
      "[191]\ttraining's binary_logloss: 0.526337\n",
      "[192]\ttraining's binary_logloss: 0.526123\n",
      "[193]\ttraining's binary_logloss: 0.525955\n",
      "[194]\ttraining's binary_logloss: 0.525778\n",
      "[195]\ttraining's binary_logloss: 0.525608\n",
      "[196]\ttraining's binary_logloss: 0.525435\n",
      "[197]\ttraining's binary_logloss: 0.525256\n",
      "[198]\ttraining's binary_logloss: 0.525078\n",
      "[199]\ttraining's binary_logloss: 0.524907\n",
      "[200]\ttraining's binary_logloss: 0.52474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[201]\ttraining's binary_logloss: 0.524539\n",
      "[202]\ttraining's binary_logloss: 0.524322\n",
      "[203]\ttraining's binary_logloss: 0.524101\n",
      "[204]\ttraining's binary_logloss: 0.523839\n",
      "[205]\ttraining's binary_logloss: 0.52367\n",
      "[206]\ttraining's binary_logloss: 0.52345\n",
      "[207]\ttraining's binary_logloss: 0.523256\n",
      "[208]\ttraining's binary_logloss: 0.523046\n",
      "[209]\ttraining's binary_logloss: 0.522841\n",
      "[210]\ttraining's binary_logloss: 0.522629\n",
      "[211]\ttraining's binary_logloss: 0.522397\n",
      "[212]\ttraining's binary_logloss: 0.522192\n",
      "[213]\ttraining's binary_logloss: 0.521967\n",
      "[214]\ttraining's binary_logloss: 0.521741\n",
      "[215]\ttraining's binary_logloss: 0.521523\n",
      "[216]\ttraining's binary_logloss: 0.521293\n",
      "[217]\ttraining's binary_logloss: 0.52102\n",
      "[218]\ttraining's binary_logloss: 0.520754\n",
      "[219]\ttraining's binary_logloss: 0.520533\n",
      "[220]\ttraining's binary_logloss: 0.520321\n",
      "[221]\ttraining's binary_logloss: 0.520088\n",
      "[222]\ttraining's binary_logloss: 0.519855\n",
      "[223]\ttraining's binary_logloss: 0.519623\n",
      "[224]\ttraining's binary_logloss: 0.519393\n",
      "[225]\ttraining's binary_logloss: 0.519173\n",
      "[226]\ttraining's binary_logloss: 0.518932\n",
      "[227]\ttraining's binary_logloss: 0.518721\n",
      "[228]\ttraining's binary_logloss: 0.518502\n",
      "[229]\ttraining's binary_logloss: 0.51827\n",
      "[230]\ttraining's binary_logloss: 0.518061\n",
      "[231]\ttraining's binary_logloss: 0.51785\n",
      "[232]\ttraining's binary_logloss: 0.517631\n",
      "[233]\ttraining's binary_logloss: 0.517419\n",
      "[234]\ttraining's binary_logloss: 0.517234\n",
      "[235]\ttraining's binary_logloss: 0.51702\n",
      "[236]\ttraining's binary_logloss: 0.516748\n",
      "[237]\ttraining's binary_logloss: 0.516516\n",
      "[238]\ttraining's binary_logloss: 0.516274\n",
      "[239]\ttraining's binary_logloss: 0.516058\n",
      "[240]\ttraining's binary_logloss: 0.51584\n",
      "[241]\ttraining's binary_logloss: 0.515612\n",
      "[242]\ttraining's binary_logloss: 0.51538\n",
      "[243]\ttraining's binary_logloss: 0.515167\n",
      "[244]\ttraining's binary_logloss: 0.514926\n",
      "[245]\ttraining's binary_logloss: 0.514672\n",
      "[246]\ttraining's binary_logloss: 0.514419\n",
      "[247]\ttraining's binary_logloss: 0.514167\n",
      "[248]\ttraining's binary_logloss: 0.51393\n",
      "[249]\ttraining's binary_logloss: 0.513643\n",
      "[250]\ttraining's binary_logloss: 0.513385\n",
      "[251]\ttraining's binary_logloss: 0.513167\n",
      "[252]\ttraining's binary_logloss: 0.512968\n",
      "[253]\ttraining's binary_logloss: 0.512757\n",
      "[254]\ttraining's binary_logloss: 0.51256\n",
      "[255]\ttraining's binary_logloss: 0.512401\n",
      "[256]\ttraining's binary_logloss: 0.512125\n",
      "[257]\ttraining's binary_logloss: 0.511897\n",
      "[258]\ttraining's binary_logloss: 0.511687\n",
      "[259]\ttraining's binary_logloss: 0.511473\n",
      "[260]\ttraining's binary_logloss: 0.511239\n",
      "[261]\ttraining's binary_logloss: 0.510982\n",
      "[262]\ttraining's binary_logloss: 0.510722\n",
      "[263]\ttraining's binary_logloss: 0.51047\n",
      "[264]\ttraining's binary_logloss: 0.510242\n",
      "[265]\ttraining's binary_logloss: 0.509983\n",
      "[266]\ttraining's binary_logloss: 0.509765\n",
      "[267]\ttraining's binary_logloss: 0.50959\n",
      "[268]\ttraining's binary_logloss: 0.509377\n",
      "[269]\ttraining's binary_logloss: 0.509183\n",
      "[270]\ttraining's binary_logloss: 0.508973\n",
      "[271]\ttraining's binary_logloss: 0.508697\n",
      "[272]\ttraining's binary_logloss: 0.508446\n",
      "[273]\ttraining's binary_logloss: 0.508138\n",
      "[274]\ttraining's binary_logloss: 0.507904\n",
      "[275]\ttraining's binary_logloss: 0.507674\n",
      "[276]\ttraining's binary_logloss: 0.507434\n",
      "[277]\ttraining's binary_logloss: 0.507239\n",
      "[278]\ttraining's binary_logloss: 0.507021\n",
      "[279]\ttraining's binary_logloss: 0.506796\n",
      "[280]\ttraining's binary_logloss: 0.506563\n",
      "[281]\ttraining's binary_logloss: 0.506305\n",
      "[282]\ttraining's binary_logloss: 0.50607\n",
      "[283]\ttraining's binary_logloss: 0.505808\n",
      "[284]\ttraining's binary_logloss: 0.505578\n",
      "[285]\ttraining's binary_logloss: 0.505337\n",
      "[286]\ttraining's binary_logloss: 0.505044\n",
      "[287]\ttraining's binary_logloss: 0.504809\n",
      "[288]\ttraining's binary_logloss: 0.504534\n",
      "[289]\ttraining's binary_logloss: 0.504257\n",
      "[290]\ttraining's binary_logloss: 0.503992\n",
      "[291]\ttraining's binary_logloss: 0.503716\n",
      "[292]\ttraining's binary_logloss: 0.503441\n",
      "[293]\ttraining's binary_logloss: 0.503165\n",
      "[294]\ttraining's binary_logloss: 0.502901\n",
      "[295]\ttraining's binary_logloss: 0.502645\n",
      "[296]\ttraining's binary_logloss: 0.502392\n",
      "[297]\ttraining's binary_logloss: 0.502127\n",
      "[298]\ttraining's binary_logloss: 0.501885\n",
      "[299]\ttraining's binary_logloss: 0.501668\n",
      "[300]\ttraining's binary_logloss: 0.501438\n",
      "[301]\ttraining's binary_logloss: 0.501175\n",
      "[302]\ttraining's binary_logloss: 0.500912\n",
      "[303]\ttraining's binary_logloss: 0.500693\n",
      "[304]\ttraining's binary_logloss: 0.500451\n",
      "[305]\ttraining's binary_logloss: 0.500186\n",
      "[306]\ttraining's binary_logloss: 0.499937\n",
      "[307]\ttraining's binary_logloss: 0.499733\n",
      "[308]\ttraining's binary_logloss: 0.499525\n",
      "[309]\ttraining's binary_logloss: 0.499277\n",
      "[310]\ttraining's binary_logloss: 0.499015\n",
      "[311]\ttraining's binary_logloss: 0.498817\n",
      "[312]\ttraining's binary_logloss: 0.498592\n",
      "[313]\ttraining's binary_logloss: 0.498364\n",
      "[314]\ttraining's binary_logloss: 0.498132\n",
      "[315]\ttraining's binary_logloss: 0.497905\n",
      "[316]\ttraining's binary_logloss: 0.497638\n",
      "[317]\ttraining's binary_logloss: 0.497411\n",
      "[318]\ttraining's binary_logloss: 0.497147\n",
      "[319]\ttraining's binary_logloss: 0.496916\n",
      "[320]\ttraining's binary_logloss: 0.496686\n",
      "[321]\ttraining's binary_logloss: 0.496427\n",
      "[322]\ttraining's binary_logloss: 0.496192\n",
      "[323]\ttraining's binary_logloss: 0.495955\n",
      "[324]\ttraining's binary_logloss: 0.495701\n",
      "[325]\ttraining's binary_logloss: 0.495482\n",
      "[326]\ttraining's binary_logloss: 0.49527\n",
      "[327]\ttraining's binary_logloss: 0.495009\n",
      "[328]\ttraining's binary_logloss: 0.494795\n",
      "[329]\ttraining's binary_logloss: 0.49457\n",
      "[330]\ttraining's binary_logloss: 0.494356\n",
      "[331]\ttraining's binary_logloss: 0.494106\n",
      "[332]\ttraining's binary_logloss: 0.493858\n",
      "[333]\ttraining's binary_logloss: 0.493609\n",
      "[334]\ttraining's binary_logloss: 0.493359\n",
      "[335]\ttraining's binary_logloss: 0.493107\n",
      "[336]\ttraining's binary_logloss: 0.492819\n",
      "[337]\ttraining's binary_logloss: 0.492573\n",
      "[338]\ttraining's binary_logloss: 0.49231\n",
      "[339]\ttraining's binary_logloss: 0.492072\n",
      "[340]\ttraining's binary_logloss: 0.49181\n",
      "[341]\ttraining's binary_logloss: 0.491615\n",
      "[342]\ttraining's binary_logloss: 0.491432\n",
      "[343]\ttraining's binary_logloss: 0.491239\n",
      "[344]\ttraining's binary_logloss: 0.49105\n",
      "[345]\ttraining's binary_logloss: 0.490847\n",
      "[346]\ttraining's binary_logloss: 0.490646\n",
      "[347]\ttraining's binary_logloss: 0.490481\n",
      "[348]\ttraining's binary_logloss: 0.490323\n",
      "[349]\ttraining's binary_logloss: 0.490134\n",
      "[350]\ttraining's binary_logloss: 0.489923\n",
      "[351]\ttraining's binary_logloss: 0.489645\n",
      "[352]\ttraining's binary_logloss: 0.489393\n",
      "[353]\ttraining's binary_logloss: 0.489154\n",
      "[354]\ttraining's binary_logloss: 0.488885\n",
      "[355]\ttraining's binary_logloss: 0.488635\n",
      "[356]\ttraining's binary_logloss: 0.488385\n",
      "[357]\ttraining's binary_logloss: 0.488133\n",
      "[358]\ttraining's binary_logloss: 0.487882\n",
      "[359]\ttraining's binary_logloss: 0.487646\n",
      "[360]\ttraining's binary_logloss: 0.487377\n",
      "[361]\ttraining's binary_logloss: 0.487112\n",
      "[362]\ttraining's binary_logloss: 0.486821\n",
      "[363]\ttraining's binary_logloss: 0.486559\n",
      "[364]\ttraining's binary_logloss: 0.486302\n",
      "[365]\ttraining's binary_logloss: 0.486055\n",
      "[366]\ttraining's binary_logloss: 0.48582\n",
      "[367]\ttraining's binary_logloss: 0.485552\n",
      "[368]\ttraining's binary_logloss: 0.48532\n",
      "[369]\ttraining's binary_logloss: 0.485101\n",
      "[370]\ttraining's binary_logloss: 0.48489\n",
      "[371]\ttraining's binary_logloss: 0.484686\n",
      "[372]\ttraining's binary_logloss: 0.484488\n",
      "[373]\ttraining's binary_logloss: 0.484301\n",
      "[374]\ttraining's binary_logloss: 0.484103\n",
      "[375]\ttraining's binary_logloss: 0.483924\n",
      "[376]\ttraining's binary_logloss: 0.483706\n",
      "[377]\ttraining's binary_logloss: 0.483499\n",
      "[378]\ttraining's binary_logloss: 0.483292\n",
      "[379]\ttraining's binary_logloss: 0.483091\n",
      "[380]\ttraining's binary_logloss: 0.482882\n",
      "[381]\ttraining's binary_logloss: 0.482665\n",
      "[382]\ttraining's binary_logloss: 0.482439\n",
      "[383]\ttraining's binary_logloss: 0.4822\n",
      "[384]\ttraining's binary_logloss: 0.482011\n",
      "[385]\ttraining's binary_logloss: 0.481777\n",
      "[386]\ttraining's binary_logloss: 0.481537\n",
      "[387]\ttraining's binary_logloss: 0.481316\n",
      "[388]\ttraining's binary_logloss: 0.481103\n",
      "[389]\ttraining's binary_logloss: 0.480834\n",
      "[390]\ttraining's binary_logloss: 0.480608\n",
      "[391]\ttraining's binary_logloss: 0.480402\n",
      "[392]\ttraining's binary_logloss: 0.480144\n",
      "[393]\ttraining's binary_logloss: 0.479897\n",
      "[394]\ttraining's binary_logloss: 0.479611\n",
      "[395]\ttraining's binary_logloss: 0.479363\n",
      "[396]\ttraining's binary_logloss: 0.479166\n",
      "[397]\ttraining's binary_logloss: 0.478996\n",
      "[398]\ttraining's binary_logloss: 0.478732\n",
      "[399]\ttraining's binary_logloss: 0.478472\n",
      "[400]\ttraining's binary_logloss: 0.478303\n",
      "[401]\ttraining's binary_logloss: 0.478053\n",
      "[402]\ttraining's binary_logloss: 0.477797\n",
      "[403]\ttraining's binary_logloss: 0.477558\n",
      "[404]\ttraining's binary_logloss: 0.47728\n",
      "[405]\ttraining's binary_logloss: 0.477039\n",
      "[406]\ttraining's binary_logloss: 0.476787\n",
      "[407]\ttraining's binary_logloss: 0.476548\n",
      "[408]\ttraining's binary_logloss: 0.476316\n",
      "[409]\ttraining's binary_logloss: 0.476067\n",
      "[410]\ttraining's binary_logloss: 0.475842\n",
      "[411]\ttraining's binary_logloss: 0.475603\n",
      "[412]\ttraining's binary_logloss: 0.475379\n",
      "[413]\ttraining's binary_logloss: 0.475157\n",
      "[414]\ttraining's binary_logloss: 0.474937\n",
      "[415]\ttraining's binary_logloss: 0.474724\n",
      "[416]\ttraining's binary_logloss: 0.47452\n",
      "[417]\ttraining's binary_logloss: 0.4743\n",
      "[418]\ttraining's binary_logloss: 0.474091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[419]\ttraining's binary_logloss: 0.473886\n",
      "[420]\ttraining's binary_logloss: 0.473674\n",
      "[421]\ttraining's binary_logloss: 0.473485\n",
      "[422]\ttraining's binary_logloss: 0.473303\n",
      "[423]\ttraining's binary_logloss: 0.473109\n",
      "[424]\ttraining's binary_logloss: 0.472935\n",
      "[425]\ttraining's binary_logloss: 0.472743\n",
      "[426]\ttraining's binary_logloss: 0.47254\n",
      "[427]\ttraining's binary_logloss: 0.472348\n",
      "[428]\ttraining's binary_logloss: 0.472095\n",
      "[429]\ttraining's binary_logloss: 0.471909\n",
      "[430]\ttraining's binary_logloss: 0.471685\n",
      "[431]\ttraining's binary_logloss: 0.471406\n",
      "[432]\ttraining's binary_logloss: 0.471184\n",
      "[433]\ttraining's binary_logloss: 0.470926\n",
      "[434]\ttraining's binary_logloss: 0.470644\n",
      "[435]\ttraining's binary_logloss: 0.470397\n",
      "[436]\ttraining's binary_logloss: 0.47019\n",
      "[437]\ttraining's binary_logloss: 0.469973\n",
      "[438]\ttraining's binary_logloss: 0.469729\n",
      "[439]\ttraining's binary_logloss: 0.469542\n",
      "[440]\ttraining's binary_logloss: 0.469354\n",
      "[441]\ttraining's binary_logloss: 0.469099\n",
      "[442]\ttraining's binary_logloss: 0.468845\n",
      "[443]\ttraining's binary_logloss: 0.46863\n",
      "[444]\ttraining's binary_logloss: 0.46841\n",
      "[445]\ttraining's binary_logloss: 0.468179\n",
      "[446]\ttraining's binary_logloss: 0.46795\n",
      "[447]\ttraining's binary_logloss: 0.46773\n",
      "[448]\ttraining's binary_logloss: 0.46748\n",
      "[449]\ttraining's binary_logloss: 0.467234\n",
      "[450]\ttraining's binary_logloss: 0.466956\n",
      "[451]\ttraining's binary_logloss: 0.46674\n",
      "[452]\ttraining's binary_logloss: 0.466537\n",
      "[453]\ttraining's binary_logloss: 0.466338\n",
      "[454]\ttraining's binary_logloss: 0.466101\n",
      "[455]\ttraining's binary_logloss: 0.465926\n",
      "[456]\ttraining's binary_logloss: 0.465722\n",
      "[457]\ttraining's binary_logloss: 0.465501\n",
      "[458]\ttraining's binary_logloss: 0.465295\n",
      "[459]\ttraining's binary_logloss: 0.465077\n",
      "[460]\ttraining's binary_logloss: 0.464862\n",
      "[461]\ttraining's binary_logloss: 0.464665\n",
      "[462]\ttraining's binary_logloss: 0.464434\n",
      "[463]\ttraining's binary_logloss: 0.464241\n",
      "[464]\ttraining's binary_logloss: 0.464077\n",
      "[465]\ttraining's binary_logloss: 0.463898\n",
      "[466]\ttraining's binary_logloss: 0.463661\n",
      "[467]\ttraining's binary_logloss: 0.463431\n",
      "[468]\ttraining's binary_logloss: 0.4632\n",
      "[469]\ttraining's binary_logloss: 0.46298\n",
      "[470]\ttraining's binary_logloss: 0.462752\n",
      "[471]\ttraining's binary_logloss: 0.462587\n",
      "[472]\ttraining's binary_logloss: 0.462407\n",
      "[473]\ttraining's binary_logloss: 0.46221\n",
      "[474]\ttraining's binary_logloss: 0.462041\n",
      "[475]\ttraining's binary_logloss: 0.461848\n",
      "[476]\ttraining's binary_logloss: 0.461618\n",
      "[477]\ttraining's binary_logloss: 0.461387\n",
      "[478]\ttraining's binary_logloss: 0.461163\n",
      "[479]\ttraining's binary_logloss: 0.460931\n",
      "[480]\ttraining's binary_logloss: 0.460697\n",
      "[481]\ttraining's binary_logloss: 0.460497\n",
      "[482]\ttraining's binary_logloss: 0.46029\n",
      "[483]\ttraining's binary_logloss: 0.460107\n",
      "[484]\ttraining's binary_logloss: 0.459912\n",
      "[485]\ttraining's binary_logloss: 0.459668\n",
      "[486]\ttraining's binary_logloss: 0.459405\n",
      "[487]\ttraining's binary_logloss: 0.459166\n",
      "[488]\ttraining's binary_logloss: 0.458923\n",
      "[489]\ttraining's binary_logloss: 0.458676\n",
      "[490]\ttraining's binary_logloss: 0.458435\n",
      "[491]\ttraining's binary_logloss: 0.458201\n",
      "[492]\ttraining's binary_logloss: 0.457975\n",
      "[493]\ttraining's binary_logloss: 0.457751\n",
      "[494]\ttraining's binary_logloss: 0.457528\n",
      "[495]\ttraining's binary_logloss: 0.457266\n",
      "[496]\ttraining's binary_logloss: 0.457034\n",
      "[497]\ttraining's binary_logloss: 0.456819\n",
      "[498]\ttraining's binary_logloss: 0.456594\n",
      "[499]\ttraining's binary_logloss: 0.45637\n",
      "[500]\ttraining's binary_logloss: 0.456172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.617114\n",
      "[2]\ttraining's binary_logloss: 0.615515\n",
      "[3]\ttraining's binary_logloss: 0.613972\n",
      "[4]\ttraining's binary_logloss: 0.612484\n",
      "[5]\ttraining's binary_logloss: 0.611021\n",
      "[6]\ttraining's binary_logloss: 0.609557\n",
      "[7]\ttraining's binary_logloss: 0.608145\n",
      "[8]\ttraining's binary_logloss: 0.606734\n",
      "[9]\ttraining's binary_logloss: 0.605391\n",
      "[10]\ttraining's binary_logloss: 0.604033\n",
      "[11]\ttraining's binary_logloss: 0.602731\n",
      "[12]\ttraining's binary_logloss: 0.6015\n",
      "[13]\ttraining's binary_logloss: 0.600213\n",
      "[14]\ttraining's binary_logloss: 0.599097\n",
      "[15]\ttraining's binary_logloss: 0.597871\n",
      "[16]\ttraining's binary_logloss: 0.596772\n",
      "[17]\ttraining's binary_logloss: 0.595694\n",
      "[18]\ttraining's binary_logloss: 0.594696\n",
      "[19]\ttraining's binary_logloss: 0.59369\n",
      "[20]\ttraining's binary_logloss: 0.592732\n",
      "[21]\ttraining's binary_logloss: 0.591749\n",
      "[22]\ttraining's binary_logloss: 0.590796\n",
      "[23]\ttraining's binary_logloss: 0.589844\n",
      "[24]\ttraining's binary_logloss: 0.588871\n",
      "[25]\ttraining's binary_logloss: 0.587968\n",
      "[26]\ttraining's binary_logloss: 0.587162\n",
      "[27]\ttraining's binary_logloss: 0.586292\n",
      "[28]\ttraining's binary_logloss: 0.585465\n",
      "[29]\ttraining's binary_logloss: 0.584735\n",
      "[30]\ttraining's binary_logloss: 0.583953\n",
      "[31]\ttraining's binary_logloss: 0.58312\n",
      "[32]\ttraining's binary_logloss: 0.582318\n",
      "[33]\ttraining's binary_logloss: 0.581546\n",
      "[34]\ttraining's binary_logloss: 0.580804\n",
      "[35]\ttraining's binary_logloss: 0.580057\n",
      "[36]\ttraining's binary_logloss: 0.579298\n",
      "[37]\ttraining's binary_logloss: 0.578611\n",
      "[38]\ttraining's binary_logloss: 0.577905\n",
      "[39]\ttraining's binary_logloss: 0.577202\n",
      "[40]\ttraining's binary_logloss: 0.576578\n",
      "[41]\ttraining's binary_logloss: 0.57601\n",
      "[42]\ttraining's binary_logloss: 0.575312\n",
      "[43]\ttraining's binary_logloss: 0.574759\n",
      "[44]\ttraining's binary_logloss: 0.57416\n",
      "[45]\ttraining's binary_logloss: 0.573631\n",
      "[46]\ttraining's binary_logloss: 0.57305\n",
      "[47]\ttraining's binary_logloss: 0.57247\n",
      "[48]\ttraining's binary_logloss: 0.571892\n",
      "[49]\ttraining's binary_logloss: 0.571347\n",
      "[50]\ttraining's binary_logloss: 0.570817\n",
      "[51]\ttraining's binary_logloss: 0.570254\n",
      "[52]\ttraining's binary_logloss: 0.569634\n",
      "[53]\ttraining's binary_logloss: 0.569105\n",
      "[54]\ttraining's binary_logloss: 0.568588\n",
      "[55]\ttraining's binary_logloss: 0.568104\n",
      "[56]\ttraining's binary_logloss: 0.567676\n",
      "[57]\ttraining's binary_logloss: 0.56721\n",
      "[58]\ttraining's binary_logloss: 0.566798\n",
      "[59]\ttraining's binary_logloss: 0.566399\n",
      "[60]\ttraining's binary_logloss: 0.565957\n",
      "[61]\ttraining's binary_logloss: 0.565515\n",
      "[62]\ttraining's binary_logloss: 0.565115\n",
      "[63]\ttraining's binary_logloss: 0.564688\n",
      "[64]\ttraining's binary_logloss: 0.564276\n",
      "[65]\ttraining's binary_logloss: 0.563829\n",
      "[66]\ttraining's binary_logloss: 0.563379\n",
      "[67]\ttraining's binary_logloss: 0.562991\n",
      "[68]\ttraining's binary_logloss: 0.562543\n",
      "[69]\ttraining's binary_logloss: 0.562112\n",
      "[70]\ttraining's binary_logloss: 0.561692\n",
      "[71]\ttraining's binary_logloss: 0.561347\n",
      "[72]\ttraining's binary_logloss: 0.560904\n",
      "[73]\ttraining's binary_logloss: 0.560509\n",
      "[74]\ttraining's binary_logloss: 0.560091\n",
      "[75]\ttraining's binary_logloss: 0.559676\n",
      "[76]\ttraining's binary_logloss: 0.559382\n",
      "[77]\ttraining's binary_logloss: 0.559068\n",
      "[78]\ttraining's binary_logloss: 0.558761\n",
      "[79]\ttraining's binary_logloss: 0.558389\n",
      "[80]\ttraining's binary_logloss: 0.557995\n",
      "[81]\ttraining's binary_logloss: 0.557626\n",
      "[82]\ttraining's binary_logloss: 0.557263\n",
      "[83]\ttraining's binary_logloss: 0.556898\n",
      "[84]\ttraining's binary_logloss: 0.556551\n",
      "[85]\ttraining's binary_logloss: 0.556216\n",
      "[86]\ttraining's binary_logloss: 0.55595\n",
      "[87]\ttraining's binary_logloss: 0.555653\n",
      "[88]\ttraining's binary_logloss: 0.555358\n",
      "[89]\ttraining's binary_logloss: 0.555063\n",
      "[90]\ttraining's binary_logloss: 0.554769\n",
      "[91]\ttraining's binary_logloss: 0.554437\n",
      "[92]\ttraining's binary_logloss: 0.55412\n",
      "[93]\ttraining's binary_logloss: 0.553776\n",
      "[94]\ttraining's binary_logloss: 0.553475\n",
      "[95]\ttraining's binary_logloss: 0.553186\n",
      "[96]\ttraining's binary_logloss: 0.552897\n",
      "[97]\ttraining's binary_logloss: 0.552674\n",
      "[98]\ttraining's binary_logloss: 0.552387\n",
      "[99]\ttraining's binary_logloss: 0.55211\n",
      "[100]\ttraining's binary_logloss: 0.551821\n",
      "[101]\ttraining's binary_logloss: 0.551533\n",
      "[102]\ttraining's binary_logloss: 0.551287\n",
      "[103]\ttraining's binary_logloss: 0.551047\n",
      "[104]\ttraining's binary_logloss: 0.550792\n",
      "[105]\ttraining's binary_logloss: 0.55053\n",
      "[106]\ttraining's binary_logloss: 0.550261\n",
      "[107]\ttraining's binary_logloss: 0.549966\n",
      "[108]\ttraining's binary_logloss: 0.549685\n",
      "[109]\ttraining's binary_logloss: 0.549443\n",
      "[110]\ttraining's binary_logloss: 0.549183\n",
      "[111]\ttraining's binary_logloss: 0.548992\n",
      "[112]\ttraining's binary_logloss: 0.548675\n",
      "[113]\ttraining's binary_logloss: 0.548375\n",
      "[114]\ttraining's binary_logloss: 0.548161\n",
      "[115]\ttraining's binary_logloss: 0.547881\n",
      "[116]\ttraining's binary_logloss: 0.547608\n",
      "[117]\ttraining's binary_logloss: 0.54733\n",
      "[118]\ttraining's binary_logloss: 0.547101\n",
      "[119]\ttraining's binary_logloss: 0.54684\n",
      "[120]\ttraining's binary_logloss: 0.546618\n",
      "[121]\ttraining's binary_logloss: 0.546404\n",
      "[122]\ttraining's binary_logloss: 0.546183\n",
      "[123]\ttraining's binary_logloss: 0.545977\n",
      "[124]\ttraining's binary_logloss: 0.545728\n",
      "[125]\ttraining's binary_logloss: 0.545533\n",
      "[126]\ttraining's binary_logloss: 0.545241\n",
      "[127]\ttraining's binary_logloss: 0.545\n",
      "[128]\ttraining's binary_logloss: 0.544742\n",
      "[129]\ttraining's binary_logloss: 0.544442\n",
      "[130]\ttraining's binary_logloss: 0.544202\n",
      "[131]\ttraining's binary_logloss: 0.543908\n",
      "[132]\ttraining's binary_logloss: 0.543628\n",
      "[133]\ttraining's binary_logloss: 0.543387\n",
      "[134]\ttraining's binary_logloss: 0.543171\n",
      "[135]\ttraining's binary_logloss: 0.542939\n",
      "[136]\ttraining's binary_logloss: 0.54268\n",
      "[137]\ttraining's binary_logloss: 0.54238\n",
      "[138]\ttraining's binary_logloss: 0.542103\n",
      "[139]\ttraining's binary_logloss: 0.541845\n",
      "[140]\ttraining's binary_logloss: 0.54161\n",
      "[141]\ttraining's binary_logloss: 0.541359\n",
      "[142]\ttraining's binary_logloss: 0.541108\n",
      "[143]\ttraining's binary_logloss: 0.540862\n",
      "[144]\ttraining's binary_logloss: 0.540598\n",
      "[145]\ttraining's binary_logloss: 0.540358\n",
      "[146]\ttraining's binary_logloss: 0.540193\n",
      "[147]\ttraining's binary_logloss: 0.539934\n",
      "[148]\ttraining's binary_logloss: 0.539662\n",
      "[149]\ttraining's binary_logloss: 0.539455\n",
      "[150]\ttraining's binary_logloss: 0.539209\n",
      "[151]\ttraining's binary_logloss: 0.539019\n",
      "[152]\ttraining's binary_logloss: 0.538822\n",
      "[153]\ttraining's binary_logloss: 0.53861\n",
      "[154]\ttraining's binary_logloss: 0.538432\n",
      "[155]\ttraining's binary_logloss: 0.538257\n",
      "[156]\ttraining's binary_logloss: 0.537976\n",
      "[157]\ttraining's binary_logloss: 0.537727\n",
      "[158]\ttraining's binary_logloss: 0.537434\n",
      "[159]\ttraining's binary_logloss: 0.537168\n",
      "[160]\ttraining's binary_logloss: 0.536909\n",
      "[161]\ttraining's binary_logloss: 0.536695\n",
      "[162]\ttraining's binary_logloss: 0.53646\n",
      "[163]\ttraining's binary_logloss: 0.536216\n",
      "[164]\ttraining's binary_logloss: 0.535987\n",
      "[165]\ttraining's binary_logloss: 0.535762\n",
      "[166]\ttraining's binary_logloss: 0.535529\n",
      "[167]\ttraining's binary_logloss: 0.535294\n",
      "[168]\ttraining's binary_logloss: 0.535014\n",
      "[169]\ttraining's binary_logloss: 0.534762\n",
      "[170]\ttraining's binary_logloss: 0.534486\n",
      "[171]\ttraining's binary_logloss: 0.534249\n",
      "[172]\ttraining's binary_logloss: 0.534016\n",
      "[173]\ttraining's binary_logloss: 0.533778\n",
      "[174]\ttraining's binary_logloss: 0.533565\n",
      "[175]\ttraining's binary_logloss: 0.53334\n",
      "[176]\ttraining's binary_logloss: 0.533115\n",
      "[177]\ttraining's binary_logloss: 0.532893\n",
      "[178]\ttraining's binary_logloss: 0.532647\n",
      "[179]\ttraining's binary_logloss: 0.532456\n",
      "[180]\ttraining's binary_logloss: 0.53222\n",
      "[181]\ttraining's binary_logloss: 0.531994\n",
      "[182]\ttraining's binary_logloss: 0.531802\n",
      "[183]\ttraining's binary_logloss: 0.531579\n",
      "[184]\ttraining's binary_logloss: 0.531353\n",
      "[185]\ttraining's binary_logloss: 0.531141\n",
      "[186]\ttraining's binary_logloss: 0.530924\n",
      "[187]\ttraining's binary_logloss: 0.530742\n",
      "[188]\ttraining's binary_logloss: 0.530524\n",
      "[189]\ttraining's binary_logloss: 0.530322\n",
      "[190]\ttraining's binary_logloss: 0.530129\n",
      "[191]\ttraining's binary_logloss: 0.529863\n",
      "[192]\ttraining's binary_logloss: 0.52963\n",
      "[193]\ttraining's binary_logloss: 0.529404\n",
      "[194]\ttraining's binary_logloss: 0.529183\n",
      "[195]\ttraining's binary_logloss: 0.528919\n",
      "[196]\ttraining's binary_logloss: 0.528679\n",
      "[197]\ttraining's binary_logloss: 0.528442\n",
      "[198]\ttraining's binary_logloss: 0.528243\n",
      "[199]\ttraining's binary_logloss: 0.52802\n",
      "[200]\ttraining's binary_logloss: 0.527787\n",
      "[201]\ttraining's binary_logloss: 0.527507\n",
      "[202]\ttraining's binary_logloss: 0.527257\n",
      "[203]\ttraining's binary_logloss: 0.526989\n",
      "[204]\ttraining's binary_logloss: 0.526718\n",
      "[205]\ttraining's binary_logloss: 0.526435\n",
      "[206]\ttraining's binary_logloss: 0.526211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[207]\ttraining's binary_logloss: 0.526028\n",
      "[208]\ttraining's binary_logloss: 0.525838\n",
      "[209]\ttraining's binary_logloss: 0.525631\n",
      "[210]\ttraining's binary_logloss: 0.525438\n",
      "[211]\ttraining's binary_logloss: 0.525225\n",
      "[212]\ttraining's binary_logloss: 0.524962\n",
      "[213]\ttraining's binary_logloss: 0.524737\n",
      "[214]\ttraining's binary_logloss: 0.524518\n",
      "[215]\ttraining's binary_logloss: 0.524327\n",
      "[216]\ttraining's binary_logloss: 0.524135\n",
      "[217]\ttraining's binary_logloss: 0.523895\n",
      "[218]\ttraining's binary_logloss: 0.523616\n",
      "[219]\ttraining's binary_logloss: 0.523372\n",
      "[220]\ttraining's binary_logloss: 0.523112\n",
      "[221]\ttraining's binary_logloss: 0.522875\n",
      "[222]\ttraining's binary_logloss: 0.522642\n",
      "[223]\ttraining's binary_logloss: 0.522412\n",
      "[224]\ttraining's binary_logloss: 0.52216\n",
      "[225]\ttraining's binary_logloss: 0.521917\n",
      "[226]\ttraining's binary_logloss: 0.52165\n",
      "[227]\ttraining's binary_logloss: 0.521398\n",
      "[228]\ttraining's binary_logloss: 0.521164\n",
      "[229]\ttraining's binary_logloss: 0.520924\n",
      "[230]\ttraining's binary_logloss: 0.52066\n",
      "[231]\ttraining's binary_logloss: 0.520463\n",
      "[232]\ttraining's binary_logloss: 0.52025\n",
      "[233]\ttraining's binary_logloss: 0.520045\n",
      "[234]\ttraining's binary_logloss: 0.51986\n",
      "[235]\ttraining's binary_logloss: 0.519647\n",
      "[236]\ttraining's binary_logloss: 0.519377\n",
      "[237]\ttraining's binary_logloss: 0.519126\n",
      "[238]\ttraining's binary_logloss: 0.518893\n",
      "[239]\ttraining's binary_logloss: 0.51868\n",
      "[240]\ttraining's binary_logloss: 0.518435\n",
      "[241]\ttraining's binary_logloss: 0.518175\n",
      "[242]\ttraining's binary_logloss: 0.517904\n",
      "[243]\ttraining's binary_logloss: 0.51764\n",
      "[244]\ttraining's binary_logloss: 0.517387\n",
      "[245]\ttraining's binary_logloss: 0.517147\n",
      "[246]\ttraining's binary_logloss: 0.5169\n",
      "[247]\ttraining's binary_logloss: 0.516656\n",
      "[248]\ttraining's binary_logloss: 0.516402\n",
      "[249]\ttraining's binary_logloss: 0.516163\n",
      "[250]\ttraining's binary_logloss: 0.515896\n",
      "[251]\ttraining's binary_logloss: 0.515695\n",
      "[252]\ttraining's binary_logloss: 0.515482\n",
      "[253]\ttraining's binary_logloss: 0.51525\n",
      "[254]\ttraining's binary_logloss: 0.515012\n",
      "[255]\ttraining's binary_logloss: 0.514772\n",
      "[256]\ttraining's binary_logloss: 0.514559\n",
      "[257]\ttraining's binary_logloss: 0.514328\n",
      "[258]\ttraining's binary_logloss: 0.514081\n",
      "[259]\ttraining's binary_logloss: 0.513848\n",
      "[260]\ttraining's binary_logloss: 0.513613\n",
      "[261]\ttraining's binary_logloss: 0.513375\n",
      "[262]\ttraining's binary_logloss: 0.513151\n",
      "[263]\ttraining's binary_logloss: 0.512927\n",
      "[264]\ttraining's binary_logloss: 0.512701\n",
      "[265]\ttraining's binary_logloss: 0.512489\n",
      "[266]\ttraining's binary_logloss: 0.512267\n",
      "[267]\ttraining's binary_logloss: 0.512059\n",
      "[268]\ttraining's binary_logloss: 0.511838\n",
      "[269]\ttraining's binary_logloss: 0.511606\n",
      "[270]\ttraining's binary_logloss: 0.511369\n",
      "[271]\ttraining's binary_logloss: 0.511117\n",
      "[272]\ttraining's binary_logloss: 0.510875\n",
      "[273]\ttraining's binary_logloss: 0.510609\n",
      "[274]\ttraining's binary_logloss: 0.51038\n",
      "[275]\ttraining's binary_logloss: 0.510139\n",
      "[276]\ttraining's binary_logloss: 0.509893\n",
      "[277]\ttraining's binary_logloss: 0.509634\n",
      "[278]\ttraining's binary_logloss: 0.509356\n",
      "[279]\ttraining's binary_logloss: 0.509097\n",
      "[280]\ttraining's binary_logloss: 0.508836\n",
      "[281]\ttraining's binary_logloss: 0.508606\n",
      "[282]\ttraining's binary_logloss: 0.508394\n",
      "[283]\ttraining's binary_logloss: 0.508145\n",
      "[284]\ttraining's binary_logloss: 0.507921\n",
      "[285]\ttraining's binary_logloss: 0.507658\n",
      "[286]\ttraining's binary_logloss: 0.507411\n",
      "[287]\ttraining's binary_logloss: 0.507173\n",
      "[288]\ttraining's binary_logloss: 0.506925\n",
      "[289]\ttraining's binary_logloss: 0.506671\n",
      "[290]\ttraining's binary_logloss: 0.506447\n",
      "[291]\ttraining's binary_logloss: 0.506211\n",
      "[292]\ttraining's binary_logloss: 0.505954\n",
      "[293]\ttraining's binary_logloss: 0.505704\n",
      "[294]\ttraining's binary_logloss: 0.505441\n",
      "[295]\ttraining's binary_logloss: 0.505181\n",
      "[296]\ttraining's binary_logloss: 0.504937\n",
      "[297]\ttraining's binary_logloss: 0.504693\n",
      "[298]\ttraining's binary_logloss: 0.504453\n",
      "[299]\ttraining's binary_logloss: 0.504198\n",
      "[300]\ttraining's binary_logloss: 0.503934\n",
      "[301]\ttraining's binary_logloss: 0.503681\n",
      "[302]\ttraining's binary_logloss: 0.503424\n",
      "[303]\ttraining's binary_logloss: 0.503176\n",
      "[304]\ttraining's binary_logloss: 0.502904\n",
      "[305]\ttraining's binary_logloss: 0.502654\n",
      "[306]\ttraining's binary_logloss: 0.502385\n",
      "[307]\ttraining's binary_logloss: 0.502141\n",
      "[308]\ttraining's binary_logloss: 0.501885\n",
      "[309]\ttraining's binary_logloss: 0.501607\n",
      "[310]\ttraining's binary_logloss: 0.501359\n",
      "[311]\ttraining's binary_logloss: 0.501159\n",
      "[312]\ttraining's binary_logloss: 0.500962\n",
      "[313]\ttraining's binary_logloss: 0.500769\n",
      "[314]\ttraining's binary_logloss: 0.50052\n",
      "[315]\ttraining's binary_logloss: 0.500302\n",
      "[316]\ttraining's binary_logloss: 0.500068\n",
      "[317]\ttraining's binary_logloss: 0.499808\n",
      "[318]\ttraining's binary_logloss: 0.499552\n",
      "[319]\ttraining's binary_logloss: 0.499312\n",
      "[320]\ttraining's binary_logloss: 0.499055\n",
      "[321]\ttraining's binary_logloss: 0.498814\n",
      "[322]\ttraining's binary_logloss: 0.498604\n",
      "[323]\ttraining's binary_logloss: 0.498383\n",
      "[324]\ttraining's binary_logloss: 0.498152\n",
      "[325]\ttraining's binary_logloss: 0.497934\n",
      "[326]\ttraining's binary_logloss: 0.497732\n",
      "[327]\ttraining's binary_logloss: 0.497514\n",
      "[328]\ttraining's binary_logloss: 0.497245\n",
      "[329]\ttraining's binary_logloss: 0.497037\n",
      "[330]\ttraining's binary_logloss: 0.49679\n",
      "[331]\ttraining's binary_logloss: 0.496534\n",
      "[332]\ttraining's binary_logloss: 0.496282\n",
      "[333]\ttraining's binary_logloss: 0.496051\n",
      "[334]\ttraining's binary_logloss: 0.495797\n",
      "[335]\ttraining's binary_logloss: 0.495562\n",
      "[336]\ttraining's binary_logloss: 0.495326\n",
      "[337]\ttraining's binary_logloss: 0.495096\n",
      "[338]\ttraining's binary_logloss: 0.494863\n",
      "[339]\ttraining's binary_logloss: 0.494643\n",
      "[340]\ttraining's binary_logloss: 0.494421\n",
      "[341]\ttraining's binary_logloss: 0.494234\n",
      "[342]\ttraining's binary_logloss: 0.494032\n",
      "[343]\ttraining's binary_logloss: 0.493802\n",
      "[344]\ttraining's binary_logloss: 0.493608\n",
      "[345]\ttraining's binary_logloss: 0.493394\n",
      "[346]\ttraining's binary_logloss: 0.493175\n",
      "[347]\ttraining's binary_logloss: 0.492945\n",
      "[348]\ttraining's binary_logloss: 0.492738\n",
      "[349]\ttraining's binary_logloss: 0.49258\n",
      "[350]\ttraining's binary_logloss: 0.492424\n",
      "[351]\ttraining's binary_logloss: 0.492148\n",
      "[352]\ttraining's binary_logloss: 0.491886\n",
      "[353]\ttraining's binary_logloss: 0.491631\n",
      "[354]\ttraining's binary_logloss: 0.491382\n",
      "[355]\ttraining's binary_logloss: 0.491127\n",
      "[356]\ttraining's binary_logloss: 0.490901\n",
      "[357]\ttraining's binary_logloss: 0.490648\n",
      "[358]\ttraining's binary_logloss: 0.490389\n",
      "[359]\ttraining's binary_logloss: 0.490128\n",
      "[360]\ttraining's binary_logloss: 0.489916\n",
      "[361]\ttraining's binary_logloss: 0.489658\n",
      "[362]\ttraining's binary_logloss: 0.489427\n",
      "[363]\ttraining's binary_logloss: 0.489202\n",
      "[364]\ttraining's binary_logloss: 0.488988\n",
      "[365]\ttraining's binary_logloss: 0.488686\n",
      "[366]\ttraining's binary_logloss: 0.488473\n",
      "[367]\ttraining's binary_logloss: 0.48828\n",
      "[368]\ttraining's binary_logloss: 0.488036\n",
      "[369]\ttraining's binary_logloss: 0.487821\n",
      "[370]\ttraining's binary_logloss: 0.487605\n",
      "[371]\ttraining's binary_logloss: 0.487315\n",
      "[372]\ttraining's binary_logloss: 0.48706\n",
      "[373]\ttraining's binary_logloss: 0.48681\n",
      "[374]\ttraining's binary_logloss: 0.486562\n",
      "[375]\ttraining's binary_logloss: 0.486309\n",
      "[376]\ttraining's binary_logloss: 0.486067\n",
      "[377]\ttraining's binary_logloss: 0.485834\n",
      "[378]\ttraining's binary_logloss: 0.485596\n",
      "[379]\ttraining's binary_logloss: 0.485359\n",
      "[380]\ttraining's binary_logloss: 0.485137\n",
      "[381]\ttraining's binary_logloss: 0.48485\n",
      "[382]\ttraining's binary_logloss: 0.484606\n",
      "[383]\ttraining's binary_logloss: 0.484375\n",
      "[384]\ttraining's binary_logloss: 0.484112\n",
      "[385]\ttraining's binary_logloss: 0.483838\n",
      "[386]\ttraining's binary_logloss: 0.483586\n",
      "[387]\ttraining's binary_logloss: 0.483368\n",
      "[388]\ttraining's binary_logloss: 0.483132\n",
      "[389]\ttraining's binary_logloss: 0.482894\n",
      "[390]\ttraining's binary_logloss: 0.482644\n",
      "[391]\ttraining's binary_logloss: 0.482393\n",
      "[392]\ttraining's binary_logloss: 0.482145\n",
      "[393]\ttraining's binary_logloss: 0.481895\n",
      "[394]\ttraining's binary_logloss: 0.481655\n",
      "[395]\ttraining's binary_logloss: 0.481414\n",
      "[396]\ttraining's binary_logloss: 0.48117\n",
      "[397]\ttraining's binary_logloss: 0.480919\n",
      "[398]\ttraining's binary_logloss: 0.480668\n",
      "[399]\ttraining's binary_logloss: 0.480429\n",
      "[400]\ttraining's binary_logloss: 0.48019\n",
      "[401]\ttraining's binary_logloss: 0.479926\n",
      "[402]\ttraining's binary_logloss: 0.479701\n",
      "[403]\ttraining's binary_logloss: 0.479446\n",
      "[404]\ttraining's binary_logloss: 0.479192\n",
      "[405]\ttraining's binary_logloss: 0.478936\n",
      "[406]\ttraining's binary_logloss: 0.478671\n",
      "[407]\ttraining's binary_logloss: 0.478446\n",
      "[408]\ttraining's binary_logloss: 0.478231\n",
      "[409]\ttraining's binary_logloss: 0.47798\n",
      "[410]\ttraining's binary_logloss: 0.477757\n",
      "[411]\ttraining's binary_logloss: 0.47752\n",
      "[412]\ttraining's binary_logloss: 0.477261\n",
      "[413]\ttraining's binary_logloss: 0.477042\n",
      "[414]\ttraining's binary_logloss: 0.476834\n",
      "[415]\ttraining's binary_logloss: 0.476603\n",
      "[416]\ttraining's binary_logloss: 0.47634\n",
      "[417]\ttraining's binary_logloss: 0.476115\n",
      "[418]\ttraining's binary_logloss: 0.475877\n",
      "[419]\ttraining's binary_logloss: 0.475652\n",
      "[420]\ttraining's binary_logloss: 0.47541\n",
      "[421]\ttraining's binary_logloss: 0.475219\n",
      "[422]\ttraining's binary_logloss: 0.475024\n",
      "[423]\ttraining's binary_logloss: 0.474821\n",
      "[424]\ttraining's binary_logloss: 0.47458\n",
      "[425]\ttraining's binary_logloss: 0.474412\n",
      "[426]\ttraining's binary_logloss: 0.474186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[427]\ttraining's binary_logloss: 0.473969\n",
      "[428]\ttraining's binary_logloss: 0.473761\n",
      "[429]\ttraining's binary_logloss: 0.473554\n",
      "[430]\ttraining's binary_logloss: 0.473347\n",
      "[431]\ttraining's binary_logloss: 0.473058\n",
      "[432]\ttraining's binary_logloss: 0.472842\n",
      "[433]\ttraining's binary_logloss: 0.472585\n",
      "[434]\ttraining's binary_logloss: 0.472329\n",
      "[435]\ttraining's binary_logloss: 0.472096\n",
      "[436]\ttraining's binary_logloss: 0.471869\n",
      "[437]\ttraining's binary_logloss: 0.471623\n",
      "[438]\ttraining's binary_logloss: 0.471383\n",
      "[439]\ttraining's binary_logloss: 0.471173\n",
      "[440]\ttraining's binary_logloss: 0.470977\n",
      "[441]\ttraining's binary_logloss: 0.470751\n",
      "[442]\ttraining's binary_logloss: 0.470541\n",
      "[443]\ttraining's binary_logloss: 0.470308\n",
      "[444]\ttraining's binary_logloss: 0.470086\n",
      "[445]\ttraining's binary_logloss: 0.469866\n",
      "[446]\ttraining's binary_logloss: 0.469653\n",
      "[447]\ttraining's binary_logloss: 0.46945\n",
      "[448]\ttraining's binary_logloss: 0.469249\n",
      "[449]\ttraining's binary_logloss: 0.469065\n",
      "[450]\ttraining's binary_logloss: 0.46888\n",
      "[451]\ttraining's binary_logloss: 0.468645\n",
      "[452]\ttraining's binary_logloss: 0.468413\n",
      "[453]\ttraining's binary_logloss: 0.468179\n",
      "[454]\ttraining's binary_logloss: 0.467955\n",
      "[455]\ttraining's binary_logloss: 0.467724\n",
      "[456]\ttraining's binary_logloss: 0.46748\n",
      "[457]\ttraining's binary_logloss: 0.467226\n",
      "[458]\ttraining's binary_logloss: 0.466953\n",
      "[459]\ttraining's binary_logloss: 0.466688\n",
      "[460]\ttraining's binary_logloss: 0.466439\n",
      "[461]\ttraining's binary_logloss: 0.466207\n",
      "[462]\ttraining's binary_logloss: 0.466006\n",
      "[463]\ttraining's binary_logloss: 0.465769\n",
      "[464]\ttraining's binary_logloss: 0.46556\n",
      "[465]\ttraining's binary_logloss: 0.465343\n",
      "[466]\ttraining's binary_logloss: 0.465067\n",
      "[467]\ttraining's binary_logloss: 0.464812\n",
      "[468]\ttraining's binary_logloss: 0.464554\n",
      "[469]\ttraining's binary_logloss: 0.464327\n",
      "[470]\ttraining's binary_logloss: 0.464073\n",
      "[471]\ttraining's binary_logloss: 0.463847\n",
      "[472]\ttraining's binary_logloss: 0.46364\n",
      "[473]\ttraining's binary_logloss: 0.463409\n",
      "[474]\ttraining's binary_logloss: 0.463195\n",
      "[475]\ttraining's binary_logloss: 0.462969\n",
      "[476]\ttraining's binary_logloss: 0.462737\n",
      "[477]\ttraining's binary_logloss: 0.462458\n",
      "[478]\ttraining's binary_logloss: 0.462188\n",
      "[479]\ttraining's binary_logloss: 0.461946\n",
      "[480]\ttraining's binary_logloss: 0.461708\n",
      "[481]\ttraining's binary_logloss: 0.46148\n",
      "[482]\ttraining's binary_logloss: 0.461262\n",
      "[483]\ttraining's binary_logloss: 0.461041\n",
      "[484]\ttraining's binary_logloss: 0.46082\n",
      "[485]\ttraining's binary_logloss: 0.460617\n",
      "[486]\ttraining's binary_logloss: 0.460416\n",
      "[487]\ttraining's binary_logloss: 0.460198\n",
      "[488]\ttraining's binary_logloss: 0.459977\n",
      "[489]\ttraining's binary_logloss: 0.459732\n",
      "[490]\ttraining's binary_logloss: 0.459485\n",
      "[491]\ttraining's binary_logloss: 0.459216\n",
      "[492]\ttraining's binary_logloss: 0.458947\n",
      "[493]\ttraining's binary_logloss: 0.458697\n",
      "[494]\ttraining's binary_logloss: 0.458444\n",
      "[495]\ttraining's binary_logloss: 0.458198\n",
      "[496]\ttraining's binary_logloss: 0.457974\n",
      "[497]\ttraining's binary_logloss: 0.457763\n",
      "[498]\ttraining's binary_logloss: 0.45755\n",
      "[499]\ttraining's binary_logloss: 0.457325\n",
      "[500]\ttraining's binary_logloss: 0.45704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613164\n",
      "[2]\ttraining's binary_logloss: 0.61153\n",
      "[3]\ttraining's binary_logloss: 0.609953\n",
      "[4]\ttraining's binary_logloss: 0.608423\n",
      "[5]\ttraining's binary_logloss: 0.606888\n",
      "[6]\ttraining's binary_logloss: 0.6054\n",
      "[7]\ttraining's binary_logloss: 0.603961\n",
      "[8]\ttraining's binary_logloss: 0.602525\n",
      "[9]\ttraining's binary_logloss: 0.601202\n",
      "[10]\ttraining's binary_logloss: 0.599863\n",
      "[11]\ttraining's binary_logloss: 0.598594\n",
      "[12]\ttraining's binary_logloss: 0.597385\n",
      "[13]\ttraining's binary_logloss: 0.596218\n",
      "[14]\ttraining's binary_logloss: 0.595075\n",
      "[15]\ttraining's binary_logloss: 0.593911\n",
      "[16]\ttraining's binary_logloss: 0.592883\n",
      "[17]\ttraining's binary_logloss: 0.591815\n",
      "[18]\ttraining's binary_logloss: 0.590772\n",
      "[19]\ttraining's binary_logloss: 0.589748\n",
      "[20]\ttraining's binary_logloss: 0.588776\n",
      "[21]\ttraining's binary_logloss: 0.587768\n",
      "[22]\ttraining's binary_logloss: 0.586793\n",
      "[23]\ttraining's binary_logloss: 0.585857\n",
      "[24]\ttraining's binary_logloss: 0.584932\n",
      "[25]\ttraining's binary_logloss: 0.584001\n",
      "[26]\ttraining's binary_logloss: 0.583108\n",
      "[27]\ttraining's binary_logloss: 0.582223\n",
      "[28]\ttraining's binary_logloss: 0.581402\n",
      "[29]\ttraining's binary_logloss: 0.580571\n",
      "[30]\ttraining's binary_logloss: 0.579781\n",
      "[31]\ttraining's binary_logloss: 0.579092\n",
      "[32]\ttraining's binary_logloss: 0.578396\n",
      "[33]\ttraining's binary_logloss: 0.577681\n",
      "[34]\ttraining's binary_logloss: 0.576924\n",
      "[35]\ttraining's binary_logloss: 0.57618\n",
      "[36]\ttraining's binary_logloss: 0.575449\n",
      "[37]\ttraining's binary_logloss: 0.574751\n",
      "[38]\ttraining's binary_logloss: 0.574125\n",
      "[39]\ttraining's binary_logloss: 0.573514\n",
      "[40]\ttraining's binary_logloss: 0.572851\n",
      "[41]\ttraining's binary_logloss: 0.57222\n",
      "[42]\ttraining's binary_logloss: 0.571585\n",
      "[43]\ttraining's binary_logloss: 0.570977\n",
      "[44]\ttraining's binary_logloss: 0.570372\n",
      "[45]\ttraining's binary_logloss: 0.569771\n",
      "[46]\ttraining's binary_logloss: 0.56911\n",
      "[47]\ttraining's binary_logloss: 0.568508\n",
      "[48]\ttraining's binary_logloss: 0.567966\n",
      "[49]\ttraining's binary_logloss: 0.567431\n",
      "[50]\ttraining's binary_logloss: 0.566962\n",
      "[51]\ttraining's binary_logloss: 0.566431\n",
      "[52]\ttraining's binary_logloss: 0.565889\n",
      "[53]\ttraining's binary_logloss: 0.565397\n",
      "[54]\ttraining's binary_logloss: 0.564815\n",
      "[55]\ttraining's binary_logloss: 0.564377\n",
      "[56]\ttraining's binary_logloss: 0.564004\n",
      "[57]\ttraining's binary_logloss: 0.563508\n",
      "[58]\ttraining's binary_logloss: 0.56301\n",
      "[59]\ttraining's binary_logloss: 0.562541\n",
      "[60]\ttraining's binary_logloss: 0.562087\n",
      "[61]\ttraining's binary_logloss: 0.561567\n",
      "[62]\ttraining's binary_logloss: 0.561187\n",
      "[63]\ttraining's binary_logloss: 0.560732\n",
      "[64]\ttraining's binary_logloss: 0.560278\n",
      "[65]\ttraining's binary_logloss: 0.559877\n",
      "[66]\ttraining's binary_logloss: 0.559423\n",
      "[67]\ttraining's binary_logloss: 0.558974\n",
      "[68]\ttraining's binary_logloss: 0.558488\n",
      "[69]\ttraining's binary_logloss: 0.558093\n",
      "[70]\ttraining's binary_logloss: 0.557713\n",
      "[71]\ttraining's binary_logloss: 0.557345\n",
      "[72]\ttraining's binary_logloss: 0.556931\n",
      "[73]\ttraining's binary_logloss: 0.55648\n",
      "[74]\ttraining's binary_logloss: 0.55604\n",
      "[75]\ttraining's binary_logloss: 0.555637\n",
      "[76]\ttraining's binary_logloss: 0.555333\n",
      "[77]\ttraining's binary_logloss: 0.554968\n",
      "[78]\ttraining's binary_logloss: 0.554676\n",
      "[79]\ttraining's binary_logloss: 0.554364\n",
      "[80]\ttraining's binary_logloss: 0.554074\n",
      "[81]\ttraining's binary_logloss: 0.55375\n",
      "[82]\ttraining's binary_logloss: 0.553401\n",
      "[83]\ttraining's binary_logloss: 0.553087\n",
      "[84]\ttraining's binary_logloss: 0.552828\n",
      "[85]\ttraining's binary_logloss: 0.552535\n",
      "[86]\ttraining's binary_logloss: 0.552228\n",
      "[87]\ttraining's binary_logloss: 0.551945\n",
      "[88]\ttraining's binary_logloss: 0.551668\n",
      "[89]\ttraining's binary_logloss: 0.551404\n",
      "[90]\ttraining's binary_logloss: 0.551162\n",
      "[91]\ttraining's binary_logloss: 0.550874\n",
      "[92]\ttraining's binary_logloss: 0.550598\n",
      "[93]\ttraining's binary_logloss: 0.550296\n",
      "[94]\ttraining's binary_logloss: 0.550061\n",
      "[95]\ttraining's binary_logloss: 0.549743\n",
      "[96]\ttraining's binary_logloss: 0.549474\n",
      "[97]\ttraining's binary_logloss: 0.549226\n",
      "[98]\ttraining's binary_logloss: 0.548969\n",
      "[99]\ttraining's binary_logloss: 0.548723\n",
      "[100]\ttraining's binary_logloss: 0.548472\n",
      "[101]\ttraining's binary_logloss: 0.548195\n",
      "[102]\ttraining's binary_logloss: 0.547913\n",
      "[103]\ttraining's binary_logloss: 0.547663\n",
      "[104]\ttraining's binary_logloss: 0.547373\n",
      "[105]\ttraining's binary_logloss: 0.547124\n",
      "[106]\ttraining's binary_logloss: 0.546831\n",
      "[107]\ttraining's binary_logloss: 0.546607\n",
      "[108]\ttraining's binary_logloss: 0.546368\n",
      "[109]\ttraining's binary_logloss: 0.546095\n",
      "[110]\ttraining's binary_logloss: 0.545807\n",
      "[111]\ttraining's binary_logloss: 0.545562\n",
      "[112]\ttraining's binary_logloss: 0.545284\n",
      "[113]\ttraining's binary_logloss: 0.54504\n",
      "[114]\ttraining's binary_logloss: 0.544805\n",
      "[115]\ttraining's binary_logloss: 0.544565\n",
      "[116]\ttraining's binary_logloss: 0.544344\n",
      "[117]\ttraining's binary_logloss: 0.544083\n",
      "[118]\ttraining's binary_logloss: 0.543881\n",
      "[119]\ttraining's binary_logloss: 0.543656\n",
      "[120]\ttraining's binary_logloss: 0.543449\n",
      "[121]\ttraining's binary_logloss: 0.543199\n",
      "[122]\ttraining's binary_logloss: 0.542971\n",
      "[123]\ttraining's binary_logloss: 0.542744\n",
      "[124]\ttraining's binary_logloss: 0.542493\n",
      "[125]\ttraining's binary_logloss: 0.542271\n",
      "[126]\ttraining's binary_logloss: 0.542016\n",
      "[127]\ttraining's binary_logloss: 0.541754\n",
      "[128]\ttraining's binary_logloss: 0.541536\n",
      "[129]\ttraining's binary_logloss: 0.541336\n",
      "[130]\ttraining's binary_logloss: 0.541119\n",
      "[131]\ttraining's binary_logloss: 0.540903\n",
      "[132]\ttraining's binary_logloss: 0.540717\n",
      "[133]\ttraining's binary_logloss: 0.540506\n",
      "[134]\ttraining's binary_logloss: 0.540287\n",
      "[135]\ttraining's binary_logloss: 0.540076\n",
      "[136]\ttraining's binary_logloss: 0.539872\n",
      "[137]\ttraining's binary_logloss: 0.539643\n",
      "[138]\ttraining's binary_logloss: 0.53943\n",
      "[139]\ttraining's binary_logloss: 0.539204\n",
      "[140]\ttraining's binary_logloss: 0.539012\n",
      "[141]\ttraining's binary_logloss: 0.538782\n",
      "[142]\ttraining's binary_logloss: 0.538551\n",
      "[143]\ttraining's binary_logloss: 0.53835\n",
      "[144]\ttraining's binary_logloss: 0.538157\n",
      "[145]\ttraining's binary_logloss: 0.537946\n",
      "[146]\ttraining's binary_logloss: 0.537676\n",
      "[147]\ttraining's binary_logloss: 0.537425\n",
      "[148]\ttraining's binary_logloss: 0.537196\n",
      "[149]\ttraining's binary_logloss: 0.536938\n",
      "[150]\ttraining's binary_logloss: 0.536696\n",
      "[151]\ttraining's binary_logloss: 0.536532\n",
      "[152]\ttraining's binary_logloss: 0.536361\n",
      "[153]\ttraining's binary_logloss: 0.536164\n",
      "[154]\ttraining's binary_logloss: 0.535976\n",
      "[155]\ttraining's binary_logloss: 0.535799\n",
      "[156]\ttraining's binary_logloss: 0.53559\n",
      "[157]\ttraining's binary_logloss: 0.53537\n",
      "[158]\ttraining's binary_logloss: 0.53513\n",
      "[159]\ttraining's binary_logloss: 0.534874\n",
      "[160]\ttraining's binary_logloss: 0.534641\n",
      "[161]\ttraining's binary_logloss: 0.534403\n",
      "[162]\ttraining's binary_logloss: 0.534188\n",
      "[163]\ttraining's binary_logloss: 0.533968\n",
      "[164]\ttraining's binary_logloss: 0.533753\n",
      "[165]\ttraining's binary_logloss: 0.533582\n",
      "[166]\ttraining's binary_logloss: 0.533363\n",
      "[167]\ttraining's binary_logloss: 0.533096\n",
      "[168]\ttraining's binary_logloss: 0.53285\n",
      "[169]\ttraining's binary_logloss: 0.532608\n",
      "[170]\ttraining's binary_logloss: 0.532369\n",
      "[171]\ttraining's binary_logloss: 0.532149\n",
      "[172]\ttraining's binary_logloss: 0.531902\n",
      "[173]\ttraining's binary_logloss: 0.531717\n",
      "[174]\ttraining's binary_logloss: 0.531505\n",
      "[175]\ttraining's binary_logloss: 0.531296\n",
      "[176]\ttraining's binary_logloss: 0.531058\n",
      "[177]\ttraining's binary_logloss: 0.530815\n",
      "[178]\ttraining's binary_logloss: 0.530597\n",
      "[179]\ttraining's binary_logloss: 0.530394\n",
      "[180]\ttraining's binary_logloss: 0.530202\n",
      "[181]\ttraining's binary_logloss: 0.529987\n",
      "[182]\ttraining's binary_logloss: 0.529801\n",
      "[183]\ttraining's binary_logloss: 0.529621\n",
      "[184]\ttraining's binary_logloss: 0.529434\n",
      "[185]\ttraining's binary_logloss: 0.529205\n",
      "[186]\ttraining's binary_logloss: 0.529006\n",
      "[187]\ttraining's binary_logloss: 0.52882\n",
      "[188]\ttraining's binary_logloss: 0.528657\n",
      "[189]\ttraining's binary_logloss: 0.528503\n",
      "[190]\ttraining's binary_logloss: 0.528328\n",
      "[191]\ttraining's binary_logloss: 0.528108\n",
      "[192]\ttraining's binary_logloss: 0.527863\n",
      "[193]\ttraining's binary_logloss: 0.527685\n",
      "[194]\ttraining's binary_logloss: 0.527465\n",
      "[195]\ttraining's binary_logloss: 0.527236\n",
      "[196]\ttraining's binary_logloss: 0.527012\n",
      "[197]\ttraining's binary_logloss: 0.526792\n",
      "[198]\ttraining's binary_logloss: 0.52657\n",
      "[199]\ttraining's binary_logloss: 0.526354\n",
      "[200]\ttraining's binary_logloss: 0.526146\n",
      "[201]\ttraining's binary_logloss: 0.525901\n",
      "[202]\ttraining's binary_logloss: 0.525687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[203]\ttraining's binary_logloss: 0.525458\n",
      "[204]\ttraining's binary_logloss: 0.525199\n",
      "[205]\ttraining's binary_logloss: 0.524986\n",
      "[206]\ttraining's binary_logloss: 0.524752\n",
      "[207]\ttraining's binary_logloss: 0.524549\n",
      "[208]\ttraining's binary_logloss: 0.524341\n",
      "[209]\ttraining's binary_logloss: 0.524132\n",
      "[210]\ttraining's binary_logloss: 0.523906\n",
      "[211]\ttraining's binary_logloss: 0.523663\n",
      "[212]\ttraining's binary_logloss: 0.523407\n",
      "[213]\ttraining's binary_logloss: 0.523168\n",
      "[214]\ttraining's binary_logloss: 0.522948\n",
      "[215]\ttraining's binary_logloss: 0.522738\n",
      "[216]\ttraining's binary_logloss: 0.522496\n",
      "[217]\ttraining's binary_logloss: 0.522239\n",
      "[218]\ttraining's binary_logloss: 0.522\n",
      "[219]\ttraining's binary_logloss: 0.521783\n",
      "[220]\ttraining's binary_logloss: 0.52153\n",
      "[221]\ttraining's binary_logloss: 0.521262\n",
      "[222]\ttraining's binary_logloss: 0.521032\n",
      "[223]\ttraining's binary_logloss: 0.520792\n",
      "[224]\ttraining's binary_logloss: 0.520575\n",
      "[225]\ttraining's binary_logloss: 0.520367\n",
      "[226]\ttraining's binary_logloss: 0.520138\n",
      "[227]\ttraining's binary_logloss: 0.519909\n",
      "[228]\ttraining's binary_logloss: 0.519685\n",
      "[229]\ttraining's binary_logloss: 0.519459\n",
      "[230]\ttraining's binary_logloss: 0.519252\n",
      "[231]\ttraining's binary_logloss: 0.518981\n",
      "[232]\ttraining's binary_logloss: 0.518719\n",
      "[233]\ttraining's binary_logloss: 0.518466\n",
      "[234]\ttraining's binary_logloss: 0.518206\n",
      "[235]\ttraining's binary_logloss: 0.517965\n",
      "[236]\ttraining's binary_logloss: 0.517734\n",
      "[237]\ttraining's binary_logloss: 0.517537\n",
      "[238]\ttraining's binary_logloss: 0.517342\n",
      "[239]\ttraining's binary_logloss: 0.517135\n",
      "[240]\ttraining's binary_logloss: 0.51692\n",
      "[241]\ttraining's binary_logloss: 0.516704\n",
      "[242]\ttraining's binary_logloss: 0.516504\n",
      "[243]\ttraining's binary_logloss: 0.516295\n",
      "[244]\ttraining's binary_logloss: 0.51606\n",
      "[245]\ttraining's binary_logloss: 0.515862\n",
      "[246]\ttraining's binary_logloss: 0.515615\n",
      "[247]\ttraining's binary_logloss: 0.515382\n",
      "[248]\ttraining's binary_logloss: 0.515128\n",
      "[249]\ttraining's binary_logloss: 0.514882\n",
      "[250]\ttraining's binary_logloss: 0.514656\n",
      "[251]\ttraining's binary_logloss: 0.514445\n",
      "[252]\ttraining's binary_logloss: 0.514217\n",
      "[253]\ttraining's binary_logloss: 0.514011\n",
      "[254]\ttraining's binary_logloss: 0.513791\n",
      "[255]\ttraining's binary_logloss: 0.513545\n",
      "[256]\ttraining's binary_logloss: 0.513284\n",
      "[257]\ttraining's binary_logloss: 0.513004\n",
      "[258]\ttraining's binary_logloss: 0.512761\n",
      "[259]\ttraining's binary_logloss: 0.512544\n",
      "[260]\ttraining's binary_logloss: 0.512324\n",
      "[261]\ttraining's binary_logloss: 0.512089\n",
      "[262]\ttraining's binary_logloss: 0.511835\n",
      "[263]\ttraining's binary_logloss: 0.511591\n",
      "[264]\ttraining's binary_logloss: 0.511339\n",
      "[265]\ttraining's binary_logloss: 0.511109\n",
      "[266]\ttraining's binary_logloss: 0.510927\n",
      "[267]\ttraining's binary_logloss: 0.510742\n",
      "[268]\ttraining's binary_logloss: 0.510555\n",
      "[269]\ttraining's binary_logloss: 0.510371\n",
      "[270]\ttraining's binary_logloss: 0.510153\n",
      "[271]\ttraining's binary_logloss: 0.509917\n",
      "[272]\ttraining's binary_logloss: 0.509695\n",
      "[273]\ttraining's binary_logloss: 0.50946\n",
      "[274]\ttraining's binary_logloss: 0.509224\n",
      "[275]\ttraining's binary_logloss: 0.509006\n",
      "[276]\ttraining's binary_logloss: 0.508768\n",
      "[277]\ttraining's binary_logloss: 0.50853\n",
      "[278]\ttraining's binary_logloss: 0.508298\n",
      "[279]\ttraining's binary_logloss: 0.508051\n",
      "[280]\ttraining's binary_logloss: 0.507834\n",
      "[281]\ttraining's binary_logloss: 0.507599\n",
      "[282]\ttraining's binary_logloss: 0.507367\n",
      "[283]\ttraining's binary_logloss: 0.507138\n",
      "[284]\ttraining's binary_logloss: 0.506935\n",
      "[285]\ttraining's binary_logloss: 0.506704\n",
      "[286]\ttraining's binary_logloss: 0.506423\n",
      "[287]\ttraining's binary_logloss: 0.506146\n",
      "[288]\ttraining's binary_logloss: 0.505875\n",
      "[289]\ttraining's binary_logloss: 0.505598\n",
      "[290]\ttraining's binary_logloss: 0.505336\n",
      "[291]\ttraining's binary_logloss: 0.505131\n",
      "[292]\ttraining's binary_logloss: 0.504897\n",
      "[293]\ttraining's binary_logloss: 0.504687\n",
      "[294]\ttraining's binary_logloss: 0.504491\n",
      "[295]\ttraining's binary_logloss: 0.504252\n",
      "[296]\ttraining's binary_logloss: 0.503953\n",
      "[297]\ttraining's binary_logloss: 0.503666\n",
      "[298]\ttraining's binary_logloss: 0.503395\n",
      "[299]\ttraining's binary_logloss: 0.503137\n",
      "[300]\ttraining's binary_logloss: 0.502882\n",
      "[301]\ttraining's binary_logloss: 0.502655\n",
      "[302]\ttraining's binary_logloss: 0.502379\n",
      "[303]\ttraining's binary_logloss: 0.502138\n",
      "[304]\ttraining's binary_logloss: 0.501878\n",
      "[305]\ttraining's binary_logloss: 0.501622\n",
      "[306]\ttraining's binary_logloss: 0.501352\n",
      "[307]\ttraining's binary_logloss: 0.5011\n",
      "[308]\ttraining's binary_logloss: 0.500825\n",
      "[309]\ttraining's binary_logloss: 0.500572\n",
      "[310]\ttraining's binary_logloss: 0.50034\n",
      "[311]\ttraining's binary_logloss: 0.500133\n",
      "[312]\ttraining's binary_logloss: 0.499897\n",
      "[313]\ttraining's binary_logloss: 0.499666\n",
      "[314]\ttraining's binary_logloss: 0.499466\n",
      "[315]\ttraining's binary_logloss: 0.499249\n",
      "[316]\ttraining's binary_logloss: 0.49905\n",
      "[317]\ttraining's binary_logloss: 0.49886\n",
      "[318]\ttraining's binary_logloss: 0.498668\n",
      "[319]\ttraining's binary_logloss: 0.498417\n",
      "[320]\ttraining's binary_logloss: 0.498173\n",
      "[321]\ttraining's binary_logloss: 0.497987\n",
      "[322]\ttraining's binary_logloss: 0.497753\n",
      "[323]\ttraining's binary_logloss: 0.497559\n",
      "[324]\ttraining's binary_logloss: 0.497356\n",
      "[325]\ttraining's binary_logloss: 0.49717\n",
      "[326]\ttraining's binary_logloss: 0.496977\n",
      "[327]\ttraining's binary_logloss: 0.496753\n",
      "[328]\ttraining's binary_logloss: 0.496548\n",
      "[329]\ttraining's binary_logloss: 0.49634\n",
      "[330]\ttraining's binary_logloss: 0.496111\n",
      "[331]\ttraining's binary_logloss: 0.495851\n",
      "[332]\ttraining's binary_logloss: 0.495621\n",
      "[333]\ttraining's binary_logloss: 0.495363\n",
      "[334]\ttraining's binary_logloss: 0.495109\n",
      "[335]\ttraining's binary_logloss: 0.494841\n",
      "[336]\ttraining's binary_logloss: 0.494568\n",
      "[337]\ttraining's binary_logloss: 0.494362\n",
      "[338]\ttraining's binary_logloss: 0.494163\n",
      "[339]\ttraining's binary_logloss: 0.493894\n",
      "[340]\ttraining's binary_logloss: 0.493626\n",
      "[341]\ttraining's binary_logloss: 0.493349\n",
      "[342]\ttraining's binary_logloss: 0.493085\n",
      "[343]\ttraining's binary_logloss: 0.492819\n",
      "[344]\ttraining's binary_logloss: 0.492532\n",
      "[345]\ttraining's binary_logloss: 0.492217\n",
      "[346]\ttraining's binary_logloss: 0.492\n",
      "[347]\ttraining's binary_logloss: 0.491779\n",
      "[348]\ttraining's binary_logloss: 0.491562\n",
      "[349]\ttraining's binary_logloss: 0.491351\n",
      "[350]\ttraining's binary_logloss: 0.491166\n",
      "[351]\ttraining's binary_logloss: 0.490937\n",
      "[352]\ttraining's binary_logloss: 0.490708\n",
      "[353]\ttraining's binary_logloss: 0.490463\n",
      "[354]\ttraining's binary_logloss: 0.490217\n",
      "[355]\ttraining's binary_logloss: 0.489963\n",
      "[356]\ttraining's binary_logloss: 0.489731\n",
      "[357]\ttraining's binary_logloss: 0.4895\n",
      "[358]\ttraining's binary_logloss: 0.489277\n",
      "[359]\ttraining's binary_logloss: 0.489077\n",
      "[360]\ttraining's binary_logloss: 0.488823\n",
      "[361]\ttraining's binary_logloss: 0.488592\n",
      "[362]\ttraining's binary_logloss: 0.488337\n",
      "[363]\ttraining's binary_logloss: 0.488067\n",
      "[364]\ttraining's binary_logloss: 0.487822\n",
      "[365]\ttraining's binary_logloss: 0.487612\n",
      "[366]\ttraining's binary_logloss: 0.487395\n",
      "[367]\ttraining's binary_logloss: 0.487217\n",
      "[368]\ttraining's binary_logloss: 0.487025\n",
      "[369]\ttraining's binary_logloss: 0.486794\n",
      "[370]\ttraining's binary_logloss: 0.486597\n",
      "[371]\ttraining's binary_logloss: 0.486346\n",
      "[372]\ttraining's binary_logloss: 0.486114\n",
      "[373]\ttraining's binary_logloss: 0.485888\n",
      "[374]\ttraining's binary_logloss: 0.48563\n",
      "[375]\ttraining's binary_logloss: 0.485372\n",
      "[376]\ttraining's binary_logloss: 0.485086\n",
      "[377]\ttraining's binary_logloss: 0.484821\n",
      "[378]\ttraining's binary_logloss: 0.484568\n",
      "[379]\ttraining's binary_logloss: 0.48428\n",
      "[380]\ttraining's binary_logloss: 0.484012\n",
      "[381]\ttraining's binary_logloss: 0.483768\n",
      "[382]\ttraining's binary_logloss: 0.483522\n",
      "[383]\ttraining's binary_logloss: 0.483295\n",
      "[384]\ttraining's binary_logloss: 0.483031\n",
      "[385]\ttraining's binary_logloss: 0.482817\n",
      "[386]\ttraining's binary_logloss: 0.482585\n",
      "[387]\ttraining's binary_logloss: 0.482347\n",
      "[388]\ttraining's binary_logloss: 0.482104\n",
      "[389]\ttraining's binary_logloss: 0.481878\n",
      "[390]\ttraining's binary_logloss: 0.481669\n",
      "[391]\ttraining's binary_logloss: 0.48142\n",
      "[392]\ttraining's binary_logloss: 0.481185\n",
      "[393]\ttraining's binary_logloss: 0.480919\n",
      "[394]\ttraining's binary_logloss: 0.480653\n",
      "[395]\ttraining's binary_logloss: 0.480406\n",
      "[396]\ttraining's binary_logloss: 0.480126\n",
      "[397]\ttraining's binary_logloss: 0.479844\n",
      "[398]\ttraining's binary_logloss: 0.47954\n",
      "[399]\ttraining's binary_logloss: 0.479274\n",
      "[400]\ttraining's binary_logloss: 0.478995\n",
      "[401]\ttraining's binary_logloss: 0.478729\n",
      "[402]\ttraining's binary_logloss: 0.478476\n",
      "[403]\ttraining's binary_logloss: 0.478219\n",
      "[404]\ttraining's binary_logloss: 0.477969\n",
      "[405]\ttraining's binary_logloss: 0.477734\n",
      "[406]\ttraining's binary_logloss: 0.477529\n",
      "[407]\ttraining's binary_logloss: 0.477312\n",
      "[408]\ttraining's binary_logloss: 0.477111\n",
      "[409]\ttraining's binary_logloss: 0.476922\n",
      "[410]\ttraining's binary_logloss: 0.476708\n",
      "[411]\ttraining's binary_logloss: 0.476423\n",
      "[412]\ttraining's binary_logloss: 0.476132\n",
      "[413]\ttraining's binary_logloss: 0.475924\n",
      "[414]\ttraining's binary_logloss: 0.475661\n",
      "[415]\ttraining's binary_logloss: 0.475444\n",
      "[416]\ttraining's binary_logloss: 0.475228\n",
      "[417]\ttraining's binary_logloss: 0.475005\n",
      "[418]\ttraining's binary_logloss: 0.474808\n",
      "[419]\ttraining's binary_logloss: 0.474586\n",
      "[420]\ttraining's binary_logloss: 0.47438\n",
      "[421]\ttraining's binary_logloss: 0.474184\n",
      "[422]\ttraining's binary_logloss: 0.473984\n",
      "[423]\ttraining's binary_logloss: 0.473741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[424]\ttraining's binary_logloss: 0.473556\n",
      "[425]\ttraining's binary_logloss: 0.473322\n",
      "[426]\ttraining's binary_logloss: 0.473069\n",
      "[427]\ttraining's binary_logloss: 0.472818\n",
      "[428]\ttraining's binary_logloss: 0.472561\n",
      "[429]\ttraining's binary_logloss: 0.47232\n",
      "[430]\ttraining's binary_logloss: 0.472053\n",
      "[431]\ttraining's binary_logloss: 0.471817\n",
      "[432]\ttraining's binary_logloss: 0.471585\n",
      "[433]\ttraining's binary_logloss: 0.471367\n",
      "[434]\ttraining's binary_logloss: 0.471143\n",
      "[435]\ttraining's binary_logloss: 0.470962\n",
      "[436]\ttraining's binary_logloss: 0.470715\n",
      "[437]\ttraining's binary_logloss: 0.470467\n",
      "[438]\ttraining's binary_logloss: 0.470189\n",
      "[439]\ttraining's binary_logloss: 0.469927\n",
      "[440]\ttraining's binary_logloss: 0.469701\n",
      "[441]\ttraining's binary_logloss: 0.469477\n",
      "[442]\ttraining's binary_logloss: 0.469227\n",
      "[443]\ttraining's binary_logloss: 0.46897\n",
      "[444]\ttraining's binary_logloss: 0.468737\n",
      "[445]\ttraining's binary_logloss: 0.4685\n",
      "[446]\ttraining's binary_logloss: 0.468273\n",
      "[447]\ttraining's binary_logloss: 0.468059\n",
      "[448]\ttraining's binary_logloss: 0.467793\n",
      "[449]\ttraining's binary_logloss: 0.467564\n",
      "[450]\ttraining's binary_logloss: 0.467355\n",
      "[451]\ttraining's binary_logloss: 0.467142\n",
      "[452]\ttraining's binary_logloss: 0.466967\n",
      "[453]\ttraining's binary_logloss: 0.466778\n",
      "[454]\ttraining's binary_logloss: 0.466606\n",
      "[455]\ttraining's binary_logloss: 0.466421\n",
      "[456]\ttraining's binary_logloss: 0.466187\n",
      "[457]\ttraining's binary_logloss: 0.46597\n",
      "[458]\ttraining's binary_logloss: 0.465762\n",
      "[459]\ttraining's binary_logloss: 0.465549\n",
      "[460]\ttraining's binary_logloss: 0.465328\n",
      "[461]\ttraining's binary_logloss: 0.465088\n",
      "[462]\ttraining's binary_logloss: 0.464848\n",
      "[463]\ttraining's binary_logloss: 0.464597\n",
      "[464]\ttraining's binary_logloss: 0.464365\n",
      "[465]\ttraining's binary_logloss: 0.464127\n",
      "[466]\ttraining's binary_logloss: 0.463871\n",
      "[467]\ttraining's binary_logloss: 0.463585\n",
      "[468]\ttraining's binary_logloss: 0.463337\n",
      "[469]\ttraining's binary_logloss: 0.46311\n",
      "[470]\ttraining's binary_logloss: 0.462864\n",
      "[471]\ttraining's binary_logloss: 0.46261\n",
      "[472]\ttraining's binary_logloss: 0.462372\n",
      "[473]\ttraining's binary_logloss: 0.462129\n",
      "[474]\ttraining's binary_logloss: 0.461914\n",
      "[475]\ttraining's binary_logloss: 0.461678\n",
      "[476]\ttraining's binary_logloss: 0.461467\n",
      "[477]\ttraining's binary_logloss: 0.461227\n",
      "[478]\ttraining's binary_logloss: 0.461025\n",
      "[479]\ttraining's binary_logloss: 0.460809\n",
      "[480]\ttraining's binary_logloss: 0.460551\n",
      "[481]\ttraining's binary_logloss: 0.46037\n",
      "[482]\ttraining's binary_logloss: 0.460174\n",
      "[483]\ttraining's binary_logloss: 0.459988\n",
      "[484]\ttraining's binary_logloss: 0.459827\n",
      "[485]\ttraining's binary_logloss: 0.459634\n",
      "[486]\ttraining's binary_logloss: 0.459461\n",
      "[487]\ttraining's binary_logloss: 0.459284\n",
      "[488]\ttraining's binary_logloss: 0.459097\n",
      "[489]\ttraining's binary_logloss: 0.458904\n",
      "[490]\ttraining's binary_logloss: 0.458707\n",
      "[491]\ttraining's binary_logloss: 0.458488\n",
      "[492]\ttraining's binary_logloss: 0.458304\n",
      "[493]\ttraining's binary_logloss: 0.458103\n",
      "[494]\ttraining's binary_logloss: 0.457849\n",
      "[495]\ttraining's binary_logloss: 0.457661\n",
      "[496]\ttraining's binary_logloss: 0.457396\n",
      "[497]\ttraining's binary_logloss: 0.457137\n",
      "[498]\ttraining's binary_logloss: 0.4569\n",
      "[499]\ttraining's binary_logloss: 0.456659\n",
      "[500]\ttraining's binary_logloss: 0.456394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614582\n",
      "[2]\ttraining's binary_logloss: 0.613632\n",
      "[3]\ttraining's binary_logloss: 0.612635\n",
      "[4]\ttraining's binary_logloss: 0.611754\n",
      "[5]\ttraining's binary_logloss: 0.610897\n",
      "[6]\ttraining's binary_logloss: 0.609946\n",
      "[7]\ttraining's binary_logloss: 0.609062\n",
      "[8]\ttraining's binary_logloss: 0.608205\n",
      "[9]\ttraining's binary_logloss: 0.607411\n",
      "[10]\ttraining's binary_logloss: 0.60663\n",
      "[11]\ttraining's binary_logloss: 0.606004\n",
      "[12]\ttraining's binary_logloss: 0.605256\n",
      "[13]\ttraining's binary_logloss: 0.604522\n",
      "[14]\ttraining's binary_logloss: 0.60384\n",
      "[15]\ttraining's binary_logloss: 0.603186\n",
      "[16]\ttraining's binary_logloss: 0.60262\n",
      "[17]\ttraining's binary_logloss: 0.602078\n",
      "[18]\ttraining's binary_logloss: 0.601568\n",
      "[19]\ttraining's binary_logloss: 0.600991\n",
      "[20]\ttraining's binary_logloss: 0.60051\n",
      "[21]\ttraining's binary_logloss: 0.599936\n",
      "[22]\ttraining's binary_logloss: 0.599386\n",
      "[23]\ttraining's binary_logloss: 0.598859\n",
      "[24]\ttraining's binary_logloss: 0.598375\n",
      "[25]\ttraining's binary_logloss: 0.59798\n",
      "[26]\ttraining's binary_logloss: 0.597628\n",
      "[27]\ttraining's binary_logloss: 0.597245\n",
      "[28]\ttraining's binary_logloss: 0.596887\n",
      "[29]\ttraining's binary_logloss: 0.596537\n",
      "[30]\ttraining's binary_logloss: 0.596206\n",
      "[31]\ttraining's binary_logloss: 0.595814\n",
      "[32]\ttraining's binary_logloss: 0.595533\n",
      "[33]\ttraining's binary_logloss: 0.595173\n",
      "[34]\ttraining's binary_logloss: 0.594928\n",
      "[35]\ttraining's binary_logloss: 0.594638\n",
      "[36]\ttraining's binary_logloss: 0.594373\n",
      "[37]\ttraining's binary_logloss: 0.594158\n",
      "[38]\ttraining's binary_logloss: 0.593939\n",
      "[39]\ttraining's binary_logloss: 0.593735\n",
      "[40]\ttraining's binary_logloss: 0.593515\n",
      "[41]\ttraining's binary_logloss: 0.593261\n",
      "[42]\ttraining's binary_logloss: 0.593015\n",
      "[43]\ttraining's binary_logloss: 0.592895\n",
      "[44]\ttraining's binary_logloss: 0.59267\n",
      "[45]\ttraining's binary_logloss: 0.592438\n",
      "[46]\ttraining's binary_logloss: 0.592195\n",
      "[47]\ttraining's binary_logloss: 0.59197\n",
      "[48]\ttraining's binary_logloss: 0.591758\n",
      "[49]\ttraining's binary_logloss: 0.591554\n",
      "[50]\ttraining's binary_logloss: 0.591393\n",
      "[51]\ttraining's binary_logloss: 0.591242\n",
      "[52]\ttraining's binary_logloss: 0.591088\n",
      "[53]\ttraining's binary_logloss: 0.590969\n",
      "[54]\ttraining's binary_logloss: 0.590831\n",
      "[55]\ttraining's binary_logloss: 0.590763\n",
      "[56]\ttraining's binary_logloss: 0.59069\n",
      "[57]\ttraining's binary_logloss: 0.590622\n",
      "[58]\ttraining's binary_logloss: 0.590564\n",
      "[59]\ttraining's binary_logloss: 0.590417\n",
      "[60]\ttraining's binary_logloss: 0.590285\n",
      "[61]\ttraining's binary_logloss: 0.590217\n",
      "[62]\ttraining's binary_logloss: 0.590145\n",
      "[63]\ttraining's binary_logloss: 0.590077\n",
      "[64]\ttraining's binary_logloss: 0.590021\n",
      "[65]\ttraining's binary_logloss: 0.590008\n",
      "[66]\ttraining's binary_logloss: 0.589952\n",
      "[67]\ttraining's binary_logloss: 0.58989\n",
      "[68]\ttraining's binary_logloss: 0.589868\n",
      "[69]\ttraining's binary_logloss: 0.589854\n",
      "[70]\ttraining's binary_logloss: 0.589811\n",
      "[71]\ttraining's binary_logloss: 0.589725\n",
      "[72]\ttraining's binary_logloss: 0.589678\n",
      "[73]\ttraining's binary_logloss: 0.589681\n",
      "[74]\ttraining's binary_logloss: 0.589643\n",
      "[75]\ttraining's binary_logloss: 0.58961\n",
      "[76]\ttraining's binary_logloss: 0.589578\n",
      "[77]\ttraining's binary_logloss: 0.589554\n",
      "[78]\ttraining's binary_logloss: 0.58959\n",
      "[79]\ttraining's binary_logloss: 0.589575\n",
      "[80]\ttraining's binary_logloss: 0.589566\n",
      "[81]\ttraining's binary_logloss: 0.589518\n",
      "[82]\ttraining's binary_logloss: 0.589469\n",
      "[83]\ttraining's binary_logloss: 0.589426\n",
      "[84]\ttraining's binary_logloss: 0.589389\n",
      "[85]\ttraining's binary_logloss: 0.589408\n",
      "[86]\ttraining's binary_logloss: 0.589431\n",
      "[87]\ttraining's binary_logloss: 0.589484\n",
      "[88]\ttraining's binary_logloss: 0.589517\n",
      "[89]\ttraining's binary_logloss: 0.58956\n",
      "[90]\ttraining's binary_logloss: 0.58959\n",
      "[91]\ttraining's binary_logloss: 0.589685\n",
      "[92]\ttraining's binary_logloss: 0.589691\n",
      "[93]\ttraining's binary_logloss: 0.589702\n",
      "[94]\ttraining's binary_logloss: 0.58972\n",
      "[95]\ttraining's binary_logloss: 0.589736\n",
      "[96]\ttraining's binary_logloss: 0.589747\n",
      "[97]\ttraining's binary_logloss: 0.589719\n",
      "[98]\ttraining's binary_logloss: 0.589765\n",
      "[99]\ttraining's binary_logloss: 0.589769\n",
      "[100]\ttraining's binary_logloss: 0.589755\n",
      "[101]\ttraining's binary_logloss: 0.589789\n",
      "[102]\ttraining's binary_logloss: 0.589826\n",
      "[103]\ttraining's binary_logloss: 0.589869\n",
      "[104]\ttraining's binary_logloss: 0.589916\n",
      "[105]\ttraining's binary_logloss: 0.589961\n",
      "[106]\ttraining's binary_logloss: 0.589955\n",
      "[107]\ttraining's binary_logloss: 0.589955\n",
      "[108]\ttraining's binary_logloss: 0.590039\n",
      "[109]\ttraining's binary_logloss: 0.590054\n",
      "[110]\ttraining's binary_logloss: 0.590106\n",
      "[111]\ttraining's binary_logloss: 0.59014\n",
      "[112]\ttraining's binary_logloss: 0.590159\n",
      "[113]\ttraining's binary_logloss: 0.590184\n",
      "[114]\ttraining's binary_logloss: 0.590224\n",
      "[115]\ttraining's binary_logloss: 0.590251\n",
      "[116]\ttraining's binary_logloss: 0.590303\n",
      "[117]\ttraining's binary_logloss: 0.590342\n",
      "[118]\ttraining's binary_logloss: 0.590421\n",
      "[119]\ttraining's binary_logloss: 0.590516\n",
      "[120]\ttraining's binary_logloss: 0.590569\n",
      "[121]\ttraining's binary_logloss: 0.590616\n",
      "[122]\ttraining's binary_logloss: 0.590664\n",
      "[123]\ttraining's binary_logloss: 0.59072\n",
      "[124]\ttraining's binary_logloss: 0.590776\n",
      "[125]\ttraining's binary_logloss: 0.590823\n",
      "[126]\ttraining's binary_logloss: 0.59088\n",
      "[127]\ttraining's binary_logloss: 0.590942\n",
      "[128]\ttraining's binary_logloss: 0.591006\n",
      "[129]\ttraining's binary_logloss: 0.591074\n",
      "[130]\ttraining's binary_logloss: 0.591147\n",
      "[131]\ttraining's binary_logloss: 0.591192\n",
      "[132]\ttraining's binary_logloss: 0.591203\n",
      "[133]\ttraining's binary_logloss: 0.591203\n",
      "[134]\ttraining's binary_logloss: 0.591229\n",
      "[135]\ttraining's binary_logloss: 0.591225\n",
      "[136]\ttraining's binary_logloss: 0.591282\n",
      "[137]\ttraining's binary_logloss: 0.59134\n",
      "[138]\ttraining's binary_logloss: 0.5914\n",
      "[139]\ttraining's binary_logloss: 0.591423\n",
      "[140]\ttraining's binary_logloss: 0.591426\n",
      "[141]\ttraining's binary_logloss: 0.591493\n",
      "[142]\ttraining's binary_logloss: 0.59155\n",
      "[143]\ttraining's binary_logloss: 0.59157\n",
      "[144]\ttraining's binary_logloss: 0.591633\n",
      "[145]\ttraining's binary_logloss: 0.591678\n",
      "[146]\ttraining's binary_logloss: 0.591693\n",
      "[147]\ttraining's binary_logloss: 0.591712\n",
      "[148]\ttraining's binary_logloss: 0.591698\n",
      "[149]\ttraining's binary_logloss: 0.591717\n",
      "[150]\ttraining's binary_logloss: 0.591769\n",
      "[151]\ttraining's binary_logloss: 0.591811\n",
      "[152]\ttraining's binary_logloss: 0.591835\n",
      "[153]\ttraining's binary_logloss: 0.591877\n",
      "[154]\ttraining's binary_logloss: 0.591921\n",
      "[155]\ttraining's binary_logloss: 0.59194\n",
      "[156]\ttraining's binary_logloss: 0.592005\n",
      "[157]\ttraining's binary_logloss: 0.592101\n",
      "[158]\ttraining's binary_logloss: 0.59219\n",
      "[159]\ttraining's binary_logloss: 0.592254\n",
      "[160]\ttraining's binary_logloss: 0.592301\n",
      "[161]\ttraining's binary_logloss: 0.592308\n",
      "[162]\ttraining's binary_logloss: 0.592293\n",
      "[163]\ttraining's binary_logloss: 0.592285\n",
      "[164]\ttraining's binary_logloss: 0.592291\n",
      "[165]\ttraining's binary_logloss: 0.592287\n",
      "[166]\ttraining's binary_logloss: 0.592316\n",
      "[167]\ttraining's binary_logloss: 0.592327\n",
      "[168]\ttraining's binary_logloss: 0.592344\n",
      "[169]\ttraining's binary_logloss: 0.592376\n",
      "[170]\ttraining's binary_logloss: 0.592402\n",
      "[171]\ttraining's binary_logloss: 0.5924\n",
      "[172]\ttraining's binary_logloss: 0.592397\n",
      "[173]\ttraining's binary_logloss: 0.592399\n",
      "[174]\ttraining's binary_logloss: 0.592436\n",
      "[175]\ttraining's binary_logloss: 0.592457\n",
      "[176]\ttraining's binary_logloss: 0.592516\n",
      "[177]\ttraining's binary_logloss: 0.592549\n",
      "[178]\ttraining's binary_logloss: 0.592584\n",
      "[179]\ttraining's binary_logloss: 0.592637\n",
      "[180]\ttraining's binary_logloss: 0.592646\n",
      "[181]\ttraining's binary_logloss: 0.592646\n",
      "[182]\ttraining's binary_logloss: 0.592645\n",
      "[183]\ttraining's binary_logloss: 0.592643\n",
      "[184]\ttraining's binary_logloss: 0.592653\n",
      "[185]\ttraining's binary_logloss: 0.592655\n",
      "[186]\ttraining's binary_logloss: 0.592673\n",
      "[187]\ttraining's binary_logloss: 0.592669\n",
      "[188]\ttraining's binary_logloss: 0.592663\n",
      "[189]\ttraining's binary_logloss: 0.592664\n",
      "[190]\ttraining's binary_logloss: 0.592671\n",
      "[191]\ttraining's binary_logloss: 0.592689\n",
      "[192]\ttraining's binary_logloss: 0.59271\n",
      "[193]\ttraining's binary_logloss: 0.592704\n",
      "[194]\ttraining's binary_logloss: 0.592729\n",
      "[195]\ttraining's binary_logloss: 0.59275\n",
      "[196]\ttraining's binary_logloss: 0.592762\n",
      "[197]\ttraining's binary_logloss: 0.592779\n",
      "[198]\ttraining's binary_logloss: 0.592803\n",
      "[199]\ttraining's binary_logloss: 0.592804\n",
      "[200]\ttraining's binary_logloss: 0.592826\n",
      "[201]\ttraining's binary_logloss: 0.592845\n",
      "[202]\ttraining's binary_logloss: 0.592863\n",
      "[203]\ttraining's binary_logloss: 0.592878\n",
      "[204]\ttraining's binary_logloss: 0.592899\n",
      "[205]\ttraining's binary_logloss: 0.592916\n",
      "[206]\ttraining's binary_logloss: 0.592945\n",
      "[207]\ttraining's binary_logloss: 0.592953\n",
      "[208]\ttraining's binary_logloss: 0.592975\n",
      "[209]\ttraining's binary_logloss: 0.593006\n",
      "[210]\ttraining's binary_logloss: 0.593029\n",
      "[211]\ttraining's binary_logloss: 0.593035\n",
      "[212]\ttraining's binary_logloss: 0.593044\n",
      "[213]\ttraining's binary_logloss: 0.593053\n",
      "[214]\ttraining's binary_logloss: 0.593069\n",
      "[215]\ttraining's binary_logloss: 0.593064\n",
      "[216]\ttraining's binary_logloss: 0.593047\n",
      "[217]\ttraining's binary_logloss: 0.593042\n",
      "[218]\ttraining's binary_logloss: 0.593027\n",
      "[219]\ttraining's binary_logloss: 0.59303\n",
      "[220]\ttraining's binary_logloss: 0.593016\n",
      "[221]\ttraining's binary_logloss: 0.593026\n",
      "[222]\ttraining's binary_logloss: 0.593004\n",
      "[223]\ttraining's binary_logloss: 0.593009\n",
      "[224]\ttraining's binary_logloss: 0.59299\n",
      "[225]\ttraining's binary_logloss: 0.592997\n",
      "[226]\ttraining's binary_logloss: 0.592995\n",
      "[227]\ttraining's binary_logloss: 0.592994\n",
      "[228]\ttraining's binary_logloss: 0.593004\n",
      "[229]\ttraining's binary_logloss: 0.593012\n",
      "[230]\ttraining's binary_logloss: 0.593017\n",
      "[231]\ttraining's binary_logloss: 0.59298\n",
      "[232]\ttraining's binary_logloss: 0.592946\n",
      "[233]\ttraining's binary_logloss: 0.592919\n",
      "[234]\ttraining's binary_logloss: 0.592877\n",
      "[235]\ttraining's binary_logloss: 0.59284\n",
      "[236]\ttraining's binary_logloss: 0.592795\n",
      "[237]\ttraining's binary_logloss: 0.592743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[238]\ttraining's binary_logloss: 0.592703\n",
      "[239]\ttraining's binary_logloss: 0.592668\n",
      "[240]\ttraining's binary_logloss: 0.59263\n",
      "[241]\ttraining's binary_logloss: 0.592611\n",
      "[242]\ttraining's binary_logloss: 0.592593\n",
      "[243]\ttraining's binary_logloss: 0.592596\n",
      "[244]\ttraining's binary_logloss: 0.592593\n",
      "[245]\ttraining's binary_logloss: 0.592587\n",
      "[246]\ttraining's binary_logloss: 0.592638\n",
      "[247]\ttraining's binary_logloss: 0.592672\n",
      "[248]\ttraining's binary_logloss: 0.592711\n",
      "[249]\ttraining's binary_logloss: 0.592746\n",
      "[250]\ttraining's binary_logloss: 0.592791\n",
      "[251]\ttraining's binary_logloss: 0.592754\n",
      "[252]\ttraining's binary_logloss: 0.592719\n",
      "[253]\ttraining's binary_logloss: 0.592691\n",
      "[254]\ttraining's binary_logloss: 0.592661\n",
      "[255]\ttraining's binary_logloss: 0.592629\n",
      "[256]\ttraining's binary_logloss: 0.592585\n",
      "[257]\ttraining's binary_logloss: 0.592544\n",
      "[258]\ttraining's binary_logloss: 0.592515\n",
      "[259]\ttraining's binary_logloss: 0.592478\n",
      "[260]\ttraining's binary_logloss: 0.592444\n",
      "[261]\ttraining's binary_logloss: 0.592416\n",
      "[262]\ttraining's binary_logloss: 0.592371\n",
      "[263]\ttraining's binary_logloss: 0.592344\n",
      "[264]\ttraining's binary_logloss: 0.592335\n",
      "[265]\ttraining's binary_logloss: 0.592299\n",
      "[266]\ttraining's binary_logloss: 0.59231\n",
      "[267]\ttraining's binary_logloss: 0.592323\n",
      "[268]\ttraining's binary_logloss: 0.592315\n",
      "[269]\ttraining's binary_logloss: 0.59231\n",
      "[270]\ttraining's binary_logloss: 0.592333\n",
      "[271]\ttraining's binary_logloss: 0.592281\n",
      "[272]\ttraining's binary_logloss: 0.59223\n",
      "[273]\ttraining's binary_logloss: 0.592183\n",
      "[274]\ttraining's binary_logloss: 0.59214\n",
      "[275]\ttraining's binary_logloss: 0.592101\n",
      "[276]\ttraining's binary_logloss: 0.592048\n",
      "[277]\ttraining's binary_logloss: 0.592\n",
      "[278]\ttraining's binary_logloss: 0.591958\n",
      "[279]\ttraining's binary_logloss: 0.591911\n",
      "[280]\ttraining's binary_logloss: 0.591872\n",
      "[281]\ttraining's binary_logloss: 0.591847\n",
      "[282]\ttraining's binary_logloss: 0.591828\n",
      "[283]\ttraining's binary_logloss: 0.5918\n",
      "[284]\ttraining's binary_logloss: 0.591779\n",
      "[285]\ttraining's binary_logloss: 0.591764\n",
      "[286]\ttraining's binary_logloss: 0.591739\n",
      "[287]\ttraining's binary_logloss: 0.591713\n",
      "[288]\ttraining's binary_logloss: 0.591655\n",
      "[289]\ttraining's binary_logloss: 0.591638\n",
      "[290]\ttraining's binary_logloss: 0.591594\n",
      "[291]\ttraining's binary_logloss: 0.59156\n",
      "[292]\ttraining's binary_logloss: 0.591497\n",
      "[293]\ttraining's binary_logloss: 0.591446\n",
      "[294]\ttraining's binary_logloss: 0.591392\n",
      "[295]\ttraining's binary_logloss: 0.591334\n",
      "[296]\ttraining's binary_logloss: 0.5913\n",
      "[297]\ttraining's binary_logloss: 0.591285\n",
      "[298]\ttraining's binary_logloss: 0.591253\n",
      "[299]\ttraining's binary_logloss: 0.591223\n",
      "[300]\ttraining's binary_logloss: 0.591198\n",
      "[301]\ttraining's binary_logloss: 0.591141\n",
      "[302]\ttraining's binary_logloss: 0.591095\n",
      "[303]\ttraining's binary_logloss: 0.59105\n",
      "[304]\ttraining's binary_logloss: 0.590997\n",
      "[305]\ttraining's binary_logloss: 0.590953\n",
      "[306]\ttraining's binary_logloss: 0.590917\n",
      "[307]\ttraining's binary_logloss: 0.590887\n",
      "[308]\ttraining's binary_logloss: 0.590861\n",
      "[309]\ttraining's binary_logloss: 0.590818\n",
      "[310]\ttraining's binary_logloss: 0.590782\n",
      "[311]\ttraining's binary_logloss: 0.590746\n",
      "[312]\ttraining's binary_logloss: 0.590734\n",
      "[313]\ttraining's binary_logloss: 0.590706\n",
      "[314]\ttraining's binary_logloss: 0.590672\n",
      "[315]\ttraining's binary_logloss: 0.59064\n",
      "[316]\ttraining's binary_logloss: 0.590578\n",
      "[317]\ttraining's binary_logloss: 0.590506\n",
      "[318]\ttraining's binary_logloss: 0.590428\n",
      "[319]\ttraining's binary_logloss: 0.590345\n",
      "[320]\ttraining's binary_logloss: 0.590281\n",
      "[321]\ttraining's binary_logloss: 0.590222\n",
      "[322]\ttraining's binary_logloss: 0.590165\n",
      "[323]\ttraining's binary_logloss: 0.590111\n",
      "[324]\ttraining's binary_logloss: 0.590049\n",
      "[325]\ttraining's binary_logloss: 0.589994\n",
      "[326]\ttraining's binary_logloss: 0.589934\n",
      "[327]\ttraining's binary_logloss: 0.589877\n",
      "[328]\ttraining's binary_logloss: 0.589831\n",
      "[329]\ttraining's binary_logloss: 0.589792\n",
      "[330]\ttraining's binary_logloss: 0.589737\n",
      "[331]\ttraining's binary_logloss: 0.589667\n",
      "[332]\ttraining's binary_logloss: 0.589598\n",
      "[333]\ttraining's binary_logloss: 0.589533\n",
      "[334]\ttraining's binary_logloss: 0.589429\n",
      "[335]\ttraining's binary_logloss: 0.589366\n",
      "[336]\ttraining's binary_logloss: 0.58933\n",
      "[337]\ttraining's binary_logloss: 0.589287\n",
      "[338]\ttraining's binary_logloss: 0.589246\n",
      "[339]\ttraining's binary_logloss: 0.58921\n",
      "[340]\ttraining's binary_logloss: 0.589192\n",
      "[341]\ttraining's binary_logloss: 0.58917\n",
      "[342]\ttraining's binary_logloss: 0.589154\n",
      "[343]\ttraining's binary_logloss: 0.589129\n",
      "[344]\ttraining's binary_logloss: 0.589102\n",
      "[345]\ttraining's binary_logloss: 0.589086\n",
      "[346]\ttraining's binary_logloss: 0.589012\n",
      "[347]\ttraining's binary_logloss: 0.588932\n",
      "[348]\ttraining's binary_logloss: 0.588862\n",
      "[349]\ttraining's binary_logloss: 0.588822\n",
      "[350]\ttraining's binary_logloss: 0.588763\n",
      "[351]\ttraining's binary_logloss: 0.588718\n",
      "[352]\ttraining's binary_logloss: 0.588655\n",
      "[353]\ttraining's binary_logloss: 0.588592\n",
      "[354]\ttraining's binary_logloss: 0.588543\n",
      "[355]\ttraining's binary_logloss: 0.588471\n",
      "[356]\ttraining's binary_logloss: 0.588404\n",
      "[357]\ttraining's binary_logloss: 0.588335\n",
      "[358]\ttraining's binary_logloss: 0.588235\n",
      "[359]\ttraining's binary_logloss: 0.588138\n",
      "[360]\ttraining's binary_logloss: 0.588069\n",
      "[361]\ttraining's binary_logloss: 0.587962\n",
      "[362]\ttraining's binary_logloss: 0.587881\n",
      "[363]\ttraining's binary_logloss: 0.587776\n",
      "[364]\ttraining's binary_logloss: 0.587675\n",
      "[365]\ttraining's binary_logloss: 0.587574\n",
      "[366]\ttraining's binary_logloss: 0.587525\n",
      "[367]\ttraining's binary_logloss: 0.587472\n",
      "[368]\ttraining's binary_logloss: 0.587428\n",
      "[369]\ttraining's binary_logloss: 0.587372\n",
      "[370]\ttraining's binary_logloss: 0.587312\n",
      "[371]\ttraining's binary_logloss: 0.587268\n",
      "[372]\ttraining's binary_logloss: 0.587225\n",
      "[373]\ttraining's binary_logloss: 0.587181\n",
      "[374]\ttraining's binary_logloss: 0.58714\n",
      "[375]\ttraining's binary_logloss: 0.587109\n",
      "[376]\ttraining's binary_logloss: 0.587033\n",
      "[377]\ttraining's binary_logloss: 0.586959\n",
      "[378]\ttraining's binary_logloss: 0.586889\n",
      "[379]\ttraining's binary_logloss: 0.58682\n",
      "[380]\ttraining's binary_logloss: 0.586758\n",
      "[381]\ttraining's binary_logloss: 0.586737\n",
      "[382]\ttraining's binary_logloss: 0.586704\n",
      "[383]\ttraining's binary_logloss: 0.586674\n",
      "[384]\ttraining's binary_logloss: 0.586658\n",
      "[385]\ttraining's binary_logloss: 0.586632\n",
      "[386]\ttraining's binary_logloss: 0.586505\n",
      "[387]\ttraining's binary_logloss: 0.586367\n",
      "[388]\ttraining's binary_logloss: 0.586232\n",
      "[389]\ttraining's binary_logloss: 0.586108\n",
      "[390]\ttraining's binary_logloss: 0.586007\n",
      "[391]\ttraining's binary_logloss: 0.585922\n",
      "[392]\ttraining's binary_logloss: 0.58587\n",
      "[393]\ttraining's binary_logloss: 0.585793\n",
      "[394]\ttraining's binary_logloss: 0.585717\n",
      "[395]\ttraining's binary_logloss: 0.585659\n",
      "[396]\ttraining's binary_logloss: 0.585585\n",
      "[397]\ttraining's binary_logloss: 0.585496\n",
      "[398]\ttraining's binary_logloss: 0.585413\n",
      "[399]\ttraining's binary_logloss: 0.58534\n",
      "[400]\ttraining's binary_logloss: 0.585277\n",
      "[401]\ttraining's binary_logloss: 0.585156\n",
      "[402]\ttraining's binary_logloss: 0.585037\n",
      "[403]\ttraining's binary_logloss: 0.584922\n",
      "[404]\ttraining's binary_logloss: 0.584823\n",
      "[405]\ttraining's binary_logloss: 0.584737\n",
      "[406]\ttraining's binary_logloss: 0.584689\n",
      "[407]\ttraining's binary_logloss: 0.584633\n",
      "[408]\ttraining's binary_logloss: 0.584569\n",
      "[409]\ttraining's binary_logloss: 0.584513\n",
      "[410]\ttraining's binary_logloss: 0.584456\n",
      "[411]\ttraining's binary_logloss: 0.58437\n",
      "[412]\ttraining's binary_logloss: 0.584261\n",
      "[413]\ttraining's binary_logloss: 0.584168\n",
      "[414]\ttraining's binary_logloss: 0.58407\n",
      "[415]\ttraining's binary_logloss: 0.583978\n",
      "[416]\ttraining's binary_logloss: 0.583904\n",
      "[417]\ttraining's binary_logloss: 0.583827\n",
      "[418]\ttraining's binary_logloss: 0.583742\n",
      "[419]\ttraining's binary_logloss: 0.583686\n",
      "[420]\ttraining's binary_logloss: 0.583602\n",
      "[421]\ttraining's binary_logloss: 0.583583\n",
      "[422]\ttraining's binary_logloss: 0.583565\n",
      "[423]\ttraining's binary_logloss: 0.583536\n",
      "[424]\ttraining's binary_logloss: 0.583519\n",
      "[425]\ttraining's binary_logloss: 0.583455\n",
      "[426]\ttraining's binary_logloss: 0.583404\n",
      "[427]\ttraining's binary_logloss: 0.583355\n",
      "[428]\ttraining's binary_logloss: 0.583291\n",
      "[429]\ttraining's binary_logloss: 0.583233\n",
      "[430]\ttraining's binary_logloss: 0.583186\n",
      "[431]\ttraining's binary_logloss: 0.58308\n",
      "[432]\ttraining's binary_logloss: 0.582997\n",
      "[433]\ttraining's binary_logloss: 0.582922\n",
      "[434]\ttraining's binary_logloss: 0.582846\n",
      "[435]\ttraining's binary_logloss: 0.58277\n",
      "[436]\ttraining's binary_logloss: 0.58271\n",
      "[437]\ttraining's binary_logloss: 0.582648\n",
      "[438]\ttraining's binary_logloss: 0.582586\n",
      "[439]\ttraining's binary_logloss: 0.582538\n",
      "[440]\ttraining's binary_logloss: 0.582497\n",
      "[441]\ttraining's binary_logloss: 0.582422\n",
      "[442]\ttraining's binary_logloss: 0.582349\n",
      "[443]\ttraining's binary_logloss: 0.582276\n",
      "[444]\ttraining's binary_logloss: 0.582197\n",
      "[445]\ttraining's binary_logloss: 0.582127\n",
      "[446]\ttraining's binary_logloss: 0.582067\n",
      "[447]\ttraining's binary_logloss: 0.582005\n",
      "[448]\ttraining's binary_logloss: 0.581945\n",
      "[449]\ttraining's binary_logloss: 0.581882\n",
      "[450]\ttraining's binary_logloss: 0.581804\n",
      "[451]\ttraining's binary_logloss: 0.581757\n",
      "[452]\ttraining's binary_logloss: 0.581703\n",
      "[453]\ttraining's binary_logloss: 0.58166\n",
      "[454]\ttraining's binary_logloss: 0.581609\n",
      "[455]\ttraining's binary_logloss: 0.581565\n",
      "[456]\ttraining's binary_logloss: 0.581507\n",
      "[457]\ttraining's binary_logloss: 0.581452\n",
      "[458]\ttraining's binary_logloss: 0.581398\n",
      "[459]\ttraining's binary_logloss: 0.581345\n",
      "[460]\ttraining's binary_logloss: 0.581296\n",
      "[461]\ttraining's binary_logloss: 0.581199\n",
      "[462]\ttraining's binary_logloss: 0.581115\n",
      "[463]\ttraining's binary_logloss: 0.58102\n",
      "[464]\ttraining's binary_logloss: 0.58093\n",
      "[465]\ttraining's binary_logloss: 0.580838\n",
      "[466]\ttraining's binary_logloss: 0.580763\n",
      "[467]\ttraining's binary_logloss: 0.580698\n",
      "[468]\ttraining's binary_logloss: 0.580634\n",
      "[469]\ttraining's binary_logloss: 0.580541\n",
      "[470]\ttraining's binary_logloss: 0.580479\n",
      "[471]\ttraining's binary_logloss: 0.580431\n",
      "[472]\ttraining's binary_logloss: 0.580387\n",
      "[473]\ttraining's binary_logloss: 0.58034\n",
      "[474]\ttraining's binary_logloss: 0.580291\n",
      "[475]\ttraining's binary_logloss: 0.580244\n",
      "[476]\ttraining's binary_logloss: 0.580188\n",
      "[477]\ttraining's binary_logloss: 0.580118\n",
      "[478]\ttraining's binary_logloss: 0.580067\n",
      "[479]\ttraining's binary_logloss: 0.579989\n",
      "[480]\ttraining's binary_logloss: 0.57994\n",
      "[481]\ttraining's binary_logloss: 0.579889\n",
      "[482]\ttraining's binary_logloss: 0.579814\n",
      "[483]\ttraining's binary_logloss: 0.579755\n",
      "[484]\ttraining's binary_logloss: 0.579681\n",
      "[485]\ttraining's binary_logloss: 0.579631\n",
      "[486]\ttraining's binary_logloss: 0.57953\n",
      "[487]\ttraining's binary_logloss: 0.579453\n",
      "[488]\ttraining's binary_logloss: 0.579354\n",
      "[489]\ttraining's binary_logloss: 0.579268\n",
      "[490]\ttraining's binary_logloss: 0.57918\n",
      "[491]\ttraining's binary_logloss: 0.57917\n",
      "[492]\ttraining's binary_logloss: 0.579155\n",
      "[493]\ttraining's binary_logloss: 0.579147\n",
      "[494]\ttraining's binary_logloss: 0.579138\n",
      "[495]\ttraining's binary_logloss: 0.579121\n",
      "[496]\ttraining's binary_logloss: 0.579047\n",
      "[497]\ttraining's binary_logloss: 0.578949\n",
      "[498]\ttraining's binary_logloss: 0.578855\n",
      "[499]\ttraining's binary_logloss: 0.57876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's binary_logloss: 0.57868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614196\n",
      "[2]\ttraining's binary_logloss: 0.613175\n",
      "[3]\ttraining's binary_logloss: 0.612097\n",
      "[4]\ttraining's binary_logloss: 0.611212\n",
      "[5]\ttraining's binary_logloss: 0.610306\n",
      "[6]\ttraining's binary_logloss: 0.609375\n",
      "[7]\ttraining's binary_logloss: 0.60848\n",
      "[8]\ttraining's binary_logloss: 0.607621\n",
      "[9]\ttraining's binary_logloss: 0.606765\n",
      "[10]\ttraining's binary_logloss: 0.605968\n",
      "[11]\ttraining's binary_logloss: 0.605251\n",
      "[12]\ttraining's binary_logloss: 0.604452\n",
      "[13]\ttraining's binary_logloss: 0.603671\n",
      "[14]\ttraining's binary_logloss: 0.602925\n",
      "[15]\ttraining's binary_logloss: 0.602233\n",
      "[16]\ttraining's binary_logloss: 0.60155\n",
      "[17]\ttraining's binary_logloss: 0.600995\n",
      "[18]\ttraining's binary_logloss: 0.600479\n",
      "[19]\ttraining's binary_logloss: 0.599866\n",
      "[20]\ttraining's binary_logloss: 0.59932\n",
      "[21]\ttraining's binary_logloss: 0.598722\n",
      "[22]\ttraining's binary_logloss: 0.598168\n",
      "[23]\ttraining's binary_logloss: 0.597619\n",
      "[24]\ttraining's binary_logloss: 0.597096\n",
      "[25]\ttraining's binary_logloss: 0.596662\n",
      "[26]\ttraining's binary_logloss: 0.596309\n",
      "[27]\ttraining's binary_logloss: 0.595915\n",
      "[28]\ttraining's binary_logloss: 0.595545\n",
      "[29]\ttraining's binary_logloss: 0.595168\n",
      "[30]\ttraining's binary_logloss: 0.594813\n",
      "[31]\ttraining's binary_logloss: 0.594431\n",
      "[32]\ttraining's binary_logloss: 0.594073\n",
      "[33]\ttraining's binary_logloss: 0.59372\n",
      "[34]\ttraining's binary_logloss: 0.593396\n",
      "[35]\ttraining's binary_logloss: 0.593077\n",
      "[36]\ttraining's binary_logloss: 0.592681\n",
      "[37]\ttraining's binary_logloss: 0.59231\n",
      "[38]\ttraining's binary_logloss: 0.591998\n",
      "[39]\ttraining's binary_logloss: 0.591698\n",
      "[40]\ttraining's binary_logloss: 0.591382\n",
      "[41]\ttraining's binary_logloss: 0.591111\n",
      "[42]\ttraining's binary_logloss: 0.590855\n",
      "[43]\ttraining's binary_logloss: 0.590743\n",
      "[44]\ttraining's binary_logloss: 0.590432\n",
      "[45]\ttraining's binary_logloss: 0.590172\n",
      "[46]\ttraining's binary_logloss: 0.589924\n",
      "[47]\ttraining's binary_logloss: 0.58969\n",
      "[48]\ttraining's binary_logloss: 0.589471\n",
      "[49]\ttraining's binary_logloss: 0.589257\n",
      "[50]\ttraining's binary_logloss: 0.589063\n",
      "[51]\ttraining's binary_logloss: 0.588798\n",
      "[52]\ttraining's binary_logloss: 0.588641\n",
      "[53]\ttraining's binary_logloss: 0.588394\n",
      "[54]\ttraining's binary_logloss: 0.588234\n",
      "[55]\ttraining's binary_logloss: 0.588147\n",
      "[56]\ttraining's binary_logloss: 0.588019\n",
      "[57]\ttraining's binary_logloss: 0.587802\n",
      "[58]\ttraining's binary_logloss: 0.587596\n",
      "[59]\ttraining's binary_logloss: 0.58741\n",
      "[60]\ttraining's binary_logloss: 0.587227\n",
      "[61]\ttraining's binary_logloss: 0.58705\n",
      "[62]\ttraining's binary_logloss: 0.586883\n",
      "[63]\ttraining's binary_logloss: 0.586726\n",
      "[64]\ttraining's binary_logloss: 0.586628\n",
      "[65]\ttraining's binary_logloss: 0.586555\n",
      "[66]\ttraining's binary_logloss: 0.586457\n",
      "[67]\ttraining's binary_logloss: 0.586344\n",
      "[68]\ttraining's binary_logloss: 0.586285\n",
      "[69]\ttraining's binary_logloss: 0.586203\n",
      "[70]\ttraining's binary_logloss: 0.586141\n",
      "[71]\ttraining's binary_logloss: 0.586055\n",
      "[72]\ttraining's binary_logloss: 0.585995\n",
      "[73]\ttraining's binary_logloss: 0.585927\n",
      "[74]\ttraining's binary_logloss: 0.585865\n",
      "[75]\ttraining's binary_logloss: 0.585839\n",
      "[76]\ttraining's binary_logloss: 0.585704\n",
      "[77]\ttraining's binary_logloss: 0.585681\n",
      "[78]\ttraining's binary_logloss: 0.585648\n",
      "[79]\ttraining's binary_logloss: 0.585549\n",
      "[80]\ttraining's binary_logloss: 0.585482\n",
      "[81]\ttraining's binary_logloss: 0.585402\n",
      "[82]\ttraining's binary_logloss: 0.585335\n",
      "[83]\ttraining's binary_logloss: 0.585274\n",
      "[84]\ttraining's binary_logloss: 0.585271\n",
      "[85]\ttraining's binary_logloss: 0.58526\n",
      "[86]\ttraining's binary_logloss: 0.585182\n",
      "[87]\ttraining's binary_logloss: 0.585108\n",
      "[88]\ttraining's binary_logloss: 0.585103\n",
      "[89]\ttraining's binary_logloss: 0.585087\n",
      "[90]\ttraining's binary_logloss: 0.585025\n",
      "[91]\ttraining's binary_logloss: 0.585085\n",
      "[92]\ttraining's binary_logloss: 0.585094\n",
      "[93]\ttraining's binary_logloss: 0.585102\n",
      "[94]\ttraining's binary_logloss: 0.585123\n",
      "[95]\ttraining's binary_logloss: 0.585147\n",
      "[96]\ttraining's binary_logloss: 0.585162\n",
      "[97]\ttraining's binary_logloss: 0.585184\n",
      "[98]\ttraining's binary_logloss: 0.585244\n",
      "[99]\ttraining's binary_logloss: 0.585274\n",
      "[100]\ttraining's binary_logloss: 0.585294\n",
      "[101]\ttraining's binary_logloss: 0.585339\n",
      "[102]\ttraining's binary_logloss: 0.585386\n",
      "[103]\ttraining's binary_logloss: 0.585428\n",
      "[104]\ttraining's binary_logloss: 0.585457\n",
      "[105]\ttraining's binary_logloss: 0.585468\n",
      "[106]\ttraining's binary_logloss: 0.585455\n",
      "[107]\ttraining's binary_logloss: 0.585447\n",
      "[108]\ttraining's binary_logloss: 0.585499\n",
      "[109]\ttraining's binary_logloss: 0.585506\n",
      "[110]\ttraining's binary_logloss: 0.58552\n",
      "[111]\ttraining's binary_logloss: 0.585564\n",
      "[112]\ttraining's binary_logloss: 0.585619\n",
      "[113]\ttraining's binary_logloss: 0.585673\n",
      "[114]\ttraining's binary_logloss: 0.585671\n",
      "[115]\ttraining's binary_logloss: 0.585737\n",
      "[116]\ttraining's binary_logloss: 0.585756\n",
      "[117]\ttraining's binary_logloss: 0.585825\n",
      "[118]\ttraining's binary_logloss: 0.585898\n",
      "[119]\ttraining's binary_logloss: 0.585977\n",
      "[120]\ttraining's binary_logloss: 0.586003\n",
      "[121]\ttraining's binary_logloss: 0.585973\n",
      "[122]\ttraining's binary_logloss: 0.585959\n",
      "[123]\ttraining's binary_logloss: 0.585998\n",
      "[124]\ttraining's binary_logloss: 0.585989\n",
      "[125]\ttraining's binary_logloss: 0.585981\n",
      "[126]\ttraining's binary_logloss: 0.585971\n",
      "[127]\ttraining's binary_logloss: 0.585964\n",
      "[128]\ttraining's binary_logloss: 0.585945\n",
      "[129]\ttraining's binary_logloss: 0.585926\n",
      "[130]\ttraining's binary_logloss: 0.58591\n",
      "[131]\ttraining's binary_logloss: 0.585907\n",
      "[132]\ttraining's binary_logloss: 0.585915\n",
      "[133]\ttraining's binary_logloss: 0.585919\n",
      "[134]\ttraining's binary_logloss: 0.585927\n",
      "[135]\ttraining's binary_logloss: 0.585942\n",
      "[136]\ttraining's binary_logloss: 0.585975\n",
      "[137]\ttraining's binary_logloss: 0.586007\n",
      "[138]\ttraining's binary_logloss: 0.586029\n",
      "[139]\ttraining's binary_logloss: 0.586043\n",
      "[140]\ttraining's binary_logloss: 0.586059\n",
      "[141]\ttraining's binary_logloss: 0.586095\n",
      "[142]\ttraining's binary_logloss: 0.586078\n",
      "[143]\ttraining's binary_logloss: 0.586064\n",
      "[144]\ttraining's binary_logloss: 0.586075\n",
      "[145]\ttraining's binary_logloss: 0.586067\n",
      "[146]\ttraining's binary_logloss: 0.586109\n",
      "[147]\ttraining's binary_logloss: 0.586152\n",
      "[148]\ttraining's binary_logloss: 0.586147\n",
      "[149]\ttraining's binary_logloss: 0.586196\n",
      "[150]\ttraining's binary_logloss: 0.586201\n",
      "[151]\ttraining's binary_logloss: 0.586211\n",
      "[152]\ttraining's binary_logloss: 0.586204\n",
      "[153]\ttraining's binary_logloss: 0.586189\n",
      "[154]\ttraining's binary_logloss: 0.586176\n",
      "[155]\ttraining's binary_logloss: 0.586187\n",
      "[156]\ttraining's binary_logloss: 0.586212\n",
      "[157]\ttraining's binary_logloss: 0.586253\n",
      "[158]\ttraining's binary_logloss: 0.586277\n",
      "[159]\ttraining's binary_logloss: 0.586307\n",
      "[160]\ttraining's binary_logloss: 0.586346\n",
      "[161]\ttraining's binary_logloss: 0.586306\n",
      "[162]\ttraining's binary_logloss: 0.586301\n",
      "[163]\ttraining's binary_logloss: 0.586288\n",
      "[164]\ttraining's binary_logloss: 0.586278\n",
      "[165]\ttraining's binary_logloss: 0.586273\n",
      "[166]\ttraining's binary_logloss: 0.586257\n",
      "[167]\ttraining's binary_logloss: 0.586277\n",
      "[168]\ttraining's binary_logloss: 0.586245\n",
      "[169]\ttraining's binary_logloss: 0.586226\n",
      "[170]\ttraining's binary_logloss: 0.586198\n",
      "[171]\ttraining's binary_logloss: 0.586193\n",
      "[172]\ttraining's binary_logloss: 0.586186\n",
      "[173]\ttraining's binary_logloss: 0.586211\n",
      "[174]\ttraining's binary_logloss: 0.58621\n",
      "[175]\ttraining's binary_logloss: 0.586237\n",
      "[176]\ttraining's binary_logloss: 0.586238\n",
      "[177]\ttraining's binary_logloss: 0.586243\n",
      "[178]\ttraining's binary_logloss: 0.586249\n",
      "[179]\ttraining's binary_logloss: 0.586273\n",
      "[180]\ttraining's binary_logloss: 0.586282\n",
      "[181]\ttraining's binary_logloss: 0.586297\n",
      "[182]\ttraining's binary_logloss: 0.586298\n",
      "[183]\ttraining's binary_logloss: 0.586305\n",
      "[184]\ttraining's binary_logloss: 0.58632\n",
      "[185]\ttraining's binary_logloss: 0.586335\n",
      "[186]\ttraining's binary_logloss: 0.586327\n",
      "[187]\ttraining's binary_logloss: 0.586328\n",
      "[188]\ttraining's binary_logloss: 0.586331\n",
      "[189]\ttraining's binary_logloss: 0.586335\n",
      "[190]\ttraining's binary_logloss: 0.586332\n",
      "[191]\ttraining's binary_logloss: 0.586334\n",
      "[192]\ttraining's binary_logloss: 0.586337\n",
      "[193]\ttraining's binary_logloss: 0.586365\n",
      "[194]\ttraining's binary_logloss: 0.586375\n",
      "[195]\ttraining's binary_logloss: 0.586382\n",
      "[196]\ttraining's binary_logloss: 0.586382\n",
      "[197]\ttraining's binary_logloss: 0.58635\n",
      "[198]\ttraining's binary_logloss: 0.58635\n",
      "[199]\ttraining's binary_logloss: 0.586364\n",
      "[200]\ttraining's binary_logloss: 0.586367\n",
      "[201]\ttraining's binary_logloss: 0.586365\n",
      "[202]\ttraining's binary_logloss: 0.586381\n",
      "[203]\ttraining's binary_logloss: 0.58638\n",
      "[204]\ttraining's binary_logloss: 0.586395\n",
      "[205]\ttraining's binary_logloss: 0.586414\n",
      "[206]\ttraining's binary_logloss: 0.586409\n",
      "[207]\ttraining's binary_logloss: 0.586406\n",
      "[208]\ttraining's binary_logloss: 0.586417\n",
      "[209]\ttraining's binary_logloss: 0.586412\n",
      "[210]\ttraining's binary_logloss: 0.586409\n",
      "[211]\ttraining's binary_logloss: 0.586431\n",
      "[212]\ttraining's binary_logloss: 0.586461\n",
      "[213]\ttraining's binary_logloss: 0.586482\n",
      "[214]\ttraining's binary_logloss: 0.586507\n",
      "[215]\ttraining's binary_logloss: 0.586521\n",
      "[216]\ttraining's binary_logloss: 0.58647\n",
      "[217]\ttraining's binary_logloss: 0.586428\n",
      "[218]\ttraining's binary_logloss: 0.586407\n",
      "[219]\ttraining's binary_logloss: 0.586373\n",
      "[220]\ttraining's binary_logloss: 0.586327\n",
      "[221]\ttraining's binary_logloss: 0.586255\n",
      "[222]\ttraining's binary_logloss: 0.586186\n",
      "[223]\ttraining's binary_logloss: 0.586172\n",
      "[224]\ttraining's binary_logloss: 0.586108\n",
      "[225]\ttraining's binary_logloss: 0.586085\n",
      "[226]\ttraining's binary_logloss: 0.58609\n",
      "[227]\ttraining's binary_logloss: 0.586101\n",
      "[228]\ttraining's binary_logloss: 0.586109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[229]\ttraining's binary_logloss: 0.58612\n",
      "[230]\ttraining's binary_logloss: 0.586115\n",
      "[231]\ttraining's binary_logloss: 0.58611\n",
      "[232]\ttraining's binary_logloss: 0.586102\n",
      "[233]\ttraining's binary_logloss: 0.586099\n",
      "[234]\ttraining's binary_logloss: 0.586102\n",
      "[235]\ttraining's binary_logloss: 0.586103\n",
      "[236]\ttraining's binary_logloss: 0.586061\n",
      "[237]\ttraining's binary_logloss: 0.586006\n",
      "[238]\ttraining's binary_logloss: 0.585962\n",
      "[239]\ttraining's binary_logloss: 0.585907\n",
      "[240]\ttraining's binary_logloss: 0.585854\n",
      "[241]\ttraining's binary_logloss: 0.585827\n",
      "[242]\ttraining's binary_logloss: 0.585802\n",
      "[243]\ttraining's binary_logloss: 0.585734\n",
      "[244]\ttraining's binary_logloss: 0.585689\n",
      "[245]\ttraining's binary_logloss: 0.585641\n",
      "[246]\ttraining's binary_logloss: 0.585592\n",
      "[247]\ttraining's binary_logloss: 0.585553\n",
      "[248]\ttraining's binary_logloss: 0.585507\n",
      "[249]\ttraining's binary_logloss: 0.585471\n",
      "[250]\ttraining's binary_logloss: 0.585436\n",
      "[251]\ttraining's binary_logloss: 0.585426\n",
      "[252]\ttraining's binary_logloss: 0.585435\n",
      "[253]\ttraining's binary_logloss: 0.58542\n",
      "[254]\ttraining's binary_logloss: 0.58541\n",
      "[255]\ttraining's binary_logloss: 0.585417\n",
      "[256]\ttraining's binary_logloss: 0.585358\n",
      "[257]\ttraining's binary_logloss: 0.585312\n",
      "[258]\ttraining's binary_logloss: 0.585256\n",
      "[259]\ttraining's binary_logloss: 0.585216\n",
      "[260]\ttraining's binary_logloss: 0.585174\n",
      "[261]\ttraining's binary_logloss: 0.585134\n",
      "[262]\ttraining's binary_logloss: 0.585119\n",
      "[263]\ttraining's binary_logloss: 0.585084\n",
      "[264]\ttraining's binary_logloss: 0.585064\n",
      "[265]\ttraining's binary_logloss: 0.585043\n",
      "[266]\ttraining's binary_logloss: 0.585066\n",
      "[267]\ttraining's binary_logloss: 0.585091\n",
      "[268]\ttraining's binary_logloss: 0.585117\n",
      "[269]\ttraining's binary_logloss: 0.585149\n",
      "[270]\ttraining's binary_logloss: 0.585177\n",
      "[271]\ttraining's binary_logloss: 0.585087\n",
      "[272]\ttraining's binary_logloss: 0.584999\n",
      "[273]\ttraining's binary_logloss: 0.584916\n",
      "[274]\ttraining's binary_logloss: 0.58483\n",
      "[275]\ttraining's binary_logloss: 0.584748\n",
      "[276]\ttraining's binary_logloss: 0.584677\n",
      "[277]\ttraining's binary_logloss: 0.584612\n",
      "[278]\ttraining's binary_logloss: 0.584542\n",
      "[279]\ttraining's binary_logloss: 0.584486\n",
      "[280]\ttraining's binary_logloss: 0.584416\n",
      "[281]\ttraining's binary_logloss: 0.584353\n",
      "[282]\ttraining's binary_logloss: 0.584291\n",
      "[283]\ttraining's binary_logloss: 0.58423\n",
      "[284]\ttraining's binary_logloss: 0.584171\n",
      "[285]\ttraining's binary_logloss: 0.584125\n",
      "[286]\ttraining's binary_logloss: 0.584073\n",
      "[287]\ttraining's binary_logloss: 0.584021\n",
      "[288]\ttraining's binary_logloss: 0.58397\n",
      "[289]\ttraining's binary_logloss: 0.583932\n",
      "[290]\ttraining's binary_logloss: 0.583872\n",
      "[291]\ttraining's binary_logloss: 0.583803\n",
      "[292]\ttraining's binary_logloss: 0.583736\n",
      "[293]\ttraining's binary_logloss: 0.583671\n",
      "[294]\ttraining's binary_logloss: 0.583602\n",
      "[295]\ttraining's binary_logloss: 0.583534\n",
      "[296]\ttraining's binary_logloss: 0.583501\n",
      "[297]\ttraining's binary_logloss: 0.583472\n",
      "[298]\ttraining's binary_logloss: 0.583462\n",
      "[299]\ttraining's binary_logloss: 0.583431\n",
      "[300]\ttraining's binary_logloss: 0.583401\n",
      "[301]\ttraining's binary_logloss: 0.583345\n",
      "[302]\ttraining's binary_logloss: 0.583257\n",
      "[303]\ttraining's binary_logloss: 0.583219\n",
      "[304]\ttraining's binary_logloss: 0.583162\n",
      "[305]\ttraining's binary_logloss: 0.583116\n",
      "[306]\ttraining's binary_logloss: 0.583056\n",
      "[307]\ttraining's binary_logloss: 0.582996\n",
      "[308]\ttraining's binary_logloss: 0.582942\n",
      "[309]\ttraining's binary_logloss: 0.582897\n",
      "[310]\ttraining's binary_logloss: 0.582839\n",
      "[311]\ttraining's binary_logloss: 0.582782\n",
      "[312]\ttraining's binary_logloss: 0.582725\n",
      "[313]\ttraining's binary_logloss: 0.582676\n",
      "[314]\ttraining's binary_logloss: 0.582653\n",
      "[315]\ttraining's binary_logloss: 0.582598\n",
      "[316]\ttraining's binary_logloss: 0.582556\n",
      "[317]\ttraining's binary_logloss: 0.5825\n",
      "[318]\ttraining's binary_logloss: 0.582442\n",
      "[319]\ttraining's binary_logloss: 0.582386\n",
      "[320]\ttraining's binary_logloss: 0.58231\n",
      "[321]\ttraining's binary_logloss: 0.582295\n",
      "[322]\ttraining's binary_logloss: 0.582245\n",
      "[323]\ttraining's binary_logloss: 0.582204\n",
      "[324]\ttraining's binary_logloss: 0.582185\n",
      "[325]\ttraining's binary_logloss: 0.582172\n",
      "[326]\ttraining's binary_logloss: 0.582117\n",
      "[327]\ttraining's binary_logloss: 0.582053\n",
      "[328]\ttraining's binary_logloss: 0.581995\n",
      "[329]\ttraining's binary_logloss: 0.581941\n",
      "[330]\ttraining's binary_logloss: 0.581886\n",
      "[331]\ttraining's binary_logloss: 0.581793\n",
      "[332]\ttraining's binary_logloss: 0.581717\n",
      "[333]\ttraining's binary_logloss: 0.581635\n",
      "[334]\ttraining's binary_logloss: 0.581565\n",
      "[335]\ttraining's binary_logloss: 0.581488\n",
      "[336]\ttraining's binary_logloss: 0.581449\n",
      "[337]\ttraining's binary_logloss: 0.581417\n",
      "[338]\ttraining's binary_logloss: 0.58138\n",
      "[339]\ttraining's binary_logloss: 0.581352\n",
      "[340]\ttraining's binary_logloss: 0.581312\n",
      "[341]\ttraining's binary_logloss: 0.581285\n",
      "[342]\ttraining's binary_logloss: 0.581262\n",
      "[343]\ttraining's binary_logloss: 0.581238\n",
      "[344]\ttraining's binary_logloss: 0.581204\n",
      "[345]\ttraining's binary_logloss: 0.581185\n",
      "[346]\ttraining's binary_logloss: 0.58113\n",
      "[347]\ttraining's binary_logloss: 0.581081\n",
      "[348]\ttraining's binary_logloss: 0.581044\n",
      "[349]\ttraining's binary_logloss: 0.581003\n",
      "[350]\ttraining's binary_logloss: 0.580941\n",
      "[351]\ttraining's binary_logloss: 0.580879\n",
      "[352]\ttraining's binary_logloss: 0.580813\n",
      "[353]\ttraining's binary_logloss: 0.580746\n",
      "[354]\ttraining's binary_logloss: 0.580681\n",
      "[355]\ttraining's binary_logloss: 0.580618\n",
      "[356]\ttraining's binary_logloss: 0.580515\n",
      "[357]\ttraining's binary_logloss: 0.580429\n",
      "[358]\ttraining's binary_logloss: 0.580337\n",
      "[359]\ttraining's binary_logloss: 0.58025\n",
      "[360]\ttraining's binary_logloss: 0.580162\n",
      "[361]\ttraining's binary_logloss: 0.580067\n",
      "[362]\ttraining's binary_logloss: 0.579973\n",
      "[363]\ttraining's binary_logloss: 0.579881\n",
      "[364]\ttraining's binary_logloss: 0.57979\n",
      "[365]\ttraining's binary_logloss: 0.579701\n",
      "[366]\ttraining's binary_logloss: 0.579647\n",
      "[367]\ttraining's binary_logloss: 0.579578\n",
      "[368]\ttraining's binary_logloss: 0.579512\n",
      "[369]\ttraining's binary_logloss: 0.579476\n",
      "[370]\ttraining's binary_logloss: 0.579412\n",
      "[371]\ttraining's binary_logloss: 0.579379\n",
      "[372]\ttraining's binary_logloss: 0.579345\n",
      "[373]\ttraining's binary_logloss: 0.579312\n",
      "[374]\ttraining's binary_logloss: 0.579282\n",
      "[375]\ttraining's binary_logloss: 0.579249\n",
      "[376]\ttraining's binary_logloss: 0.57918\n",
      "[377]\ttraining's binary_logloss: 0.579096\n",
      "[378]\ttraining's binary_logloss: 0.579025\n",
      "[379]\ttraining's binary_logloss: 0.578956\n",
      "[380]\ttraining's binary_logloss: 0.578889\n",
      "[381]\ttraining's binary_logloss: 0.578851\n",
      "[382]\ttraining's binary_logloss: 0.578778\n",
      "[383]\ttraining's binary_logloss: 0.57871\n",
      "[384]\ttraining's binary_logloss: 0.578673\n",
      "[385]\ttraining's binary_logloss: 0.578618\n",
      "[386]\ttraining's binary_logloss: 0.578519\n",
      "[387]\ttraining's binary_logloss: 0.57841\n",
      "[388]\ttraining's binary_logloss: 0.578311\n",
      "[389]\ttraining's binary_logloss: 0.578212\n",
      "[390]\ttraining's binary_logloss: 0.578118\n",
      "[391]\ttraining's binary_logloss: 0.578031\n",
      "[392]\ttraining's binary_logloss: 0.57796\n",
      "[393]\ttraining's binary_logloss: 0.577893\n",
      "[394]\ttraining's binary_logloss: 0.577813\n",
      "[395]\ttraining's binary_logloss: 0.577729\n",
      "[396]\ttraining's binary_logloss: 0.577652\n",
      "[397]\ttraining's binary_logloss: 0.577583\n",
      "[398]\ttraining's binary_logloss: 0.577499\n",
      "[399]\ttraining's binary_logloss: 0.577424\n",
      "[400]\ttraining's binary_logloss: 0.577348\n",
      "[401]\ttraining's binary_logloss: 0.577265\n",
      "[402]\ttraining's binary_logloss: 0.577183\n",
      "[403]\ttraining's binary_logloss: 0.577114\n",
      "[404]\ttraining's binary_logloss: 0.577034\n",
      "[405]\ttraining's binary_logloss: 0.576961\n",
      "[406]\ttraining's binary_logloss: 0.576887\n",
      "[407]\ttraining's binary_logloss: 0.576787\n",
      "[408]\ttraining's binary_logloss: 0.576711\n",
      "[409]\ttraining's binary_logloss: 0.57664\n",
      "[410]\ttraining's binary_logloss: 0.576561\n",
      "[411]\ttraining's binary_logloss: 0.576463\n",
      "[412]\ttraining's binary_logloss: 0.576339\n",
      "[413]\ttraining's binary_logloss: 0.576208\n",
      "[414]\ttraining's binary_logloss: 0.576093\n",
      "[415]\ttraining's binary_logloss: 0.57598\n",
      "[416]\ttraining's binary_logloss: 0.5759\n",
      "[417]\ttraining's binary_logloss: 0.57582\n",
      "[418]\ttraining's binary_logloss: 0.575743\n",
      "[419]\ttraining's binary_logloss: 0.575652\n",
      "[420]\ttraining's binary_logloss: 0.575579\n",
      "[421]\ttraining's binary_logloss: 0.575532\n",
      "[422]\ttraining's binary_logloss: 0.575487\n",
      "[423]\ttraining's binary_logloss: 0.575452\n",
      "[424]\ttraining's binary_logloss: 0.575409\n",
      "[425]\ttraining's binary_logloss: 0.575367\n",
      "[426]\ttraining's binary_logloss: 0.5753\n",
      "[427]\ttraining's binary_logloss: 0.575236\n",
      "[428]\ttraining's binary_logloss: 0.575175\n",
      "[429]\ttraining's binary_logloss: 0.575113\n",
      "[430]\ttraining's binary_logloss: 0.575044\n",
      "[431]\ttraining's binary_logloss: 0.574947\n",
      "[432]\ttraining's binary_logloss: 0.574853\n",
      "[433]\ttraining's binary_logloss: 0.574744\n",
      "[434]\ttraining's binary_logloss: 0.574663\n",
      "[435]\ttraining's binary_logloss: 0.574585\n",
      "[436]\ttraining's binary_logloss: 0.574507\n",
      "[437]\ttraining's binary_logloss: 0.574426\n",
      "[438]\ttraining's binary_logloss: 0.574341\n",
      "[439]\ttraining's binary_logloss: 0.574262\n",
      "[440]\ttraining's binary_logloss: 0.574185\n",
      "[441]\ttraining's binary_logloss: 0.574127\n",
      "[442]\ttraining's binary_logloss: 0.57407\n",
      "[443]\ttraining's binary_logloss: 0.574009\n",
      "[444]\ttraining's binary_logloss: 0.573939\n",
      "[445]\ttraining's binary_logloss: 0.57387\n",
      "[446]\ttraining's binary_logloss: 0.573769\n",
      "[447]\ttraining's binary_logloss: 0.573679\n",
      "[448]\ttraining's binary_logloss: 0.573599\n",
      "[449]\ttraining's binary_logloss: 0.573513\n",
      "[450]\ttraining's binary_logloss: 0.57344\n",
      "[451]\ttraining's binary_logloss: 0.573362\n",
      "[452]\ttraining's binary_logloss: 0.573299\n",
      "[453]\ttraining's binary_logloss: 0.57322\n",
      "[454]\ttraining's binary_logloss: 0.573143\n",
      "[455]\ttraining's binary_logloss: 0.573068\n",
      "[456]\ttraining's binary_logloss: 0.573017\n",
      "[457]\ttraining's binary_logloss: 0.572965\n",
      "[458]\ttraining's binary_logloss: 0.572921\n",
      "[459]\ttraining's binary_logloss: 0.572868\n",
      "[460]\ttraining's binary_logloss: 0.57282\n",
      "[461]\ttraining's binary_logloss: 0.572715\n",
      "[462]\ttraining's binary_logloss: 0.572606\n",
      "[463]\ttraining's binary_logloss: 0.572506\n",
      "[464]\ttraining's binary_logloss: 0.572407\n",
      "[465]\ttraining's binary_logloss: 0.572322\n",
      "[466]\ttraining's binary_logloss: 0.572238\n",
      "[467]\ttraining's binary_logloss: 0.572155\n",
      "[468]\ttraining's binary_logloss: 0.572092\n",
      "[469]\ttraining's binary_logloss: 0.57203\n",
      "[470]\ttraining's binary_logloss: 0.57197\n",
      "[471]\ttraining's binary_logloss: 0.571899\n",
      "[472]\ttraining's binary_logloss: 0.571833\n",
      "[473]\ttraining's binary_logloss: 0.571772\n",
      "[474]\ttraining's binary_logloss: 0.571706\n",
      "[475]\ttraining's binary_logloss: 0.571642\n",
      "[476]\ttraining's binary_logloss: 0.571604\n",
      "[477]\ttraining's binary_logloss: 0.571538\n",
      "[478]\ttraining's binary_logloss: 0.571481\n",
      "[479]\ttraining's binary_logloss: 0.571425\n",
      "[480]\ttraining's binary_logloss: 0.571367\n",
      "[481]\ttraining's binary_logloss: 0.57128\n",
      "[482]\ttraining's binary_logloss: 0.571196\n",
      "[483]\ttraining's binary_logloss: 0.571119\n",
      "[484]\ttraining's binary_logloss: 0.571044\n",
      "[485]\ttraining's binary_logloss: 0.57097\n",
      "[486]\ttraining's binary_logloss: 0.57088\n",
      "[487]\ttraining's binary_logloss: 0.570793\n",
      "[488]\ttraining's binary_logloss: 0.570709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[489]\ttraining's binary_logloss: 0.570625\n",
      "[490]\ttraining's binary_logloss: 0.570534\n",
      "[491]\ttraining's binary_logloss: 0.570472\n",
      "[492]\ttraining's binary_logloss: 0.570397\n",
      "[493]\ttraining's binary_logloss: 0.570332\n",
      "[494]\ttraining's binary_logloss: 0.570267\n",
      "[495]\ttraining's binary_logloss: 0.570214\n",
      "[496]\ttraining's binary_logloss: 0.570133\n",
      "[497]\ttraining's binary_logloss: 0.57003\n",
      "[498]\ttraining's binary_logloss: 0.569956\n",
      "[499]\ttraining's binary_logloss: 0.569852\n",
      "[500]\ttraining's binary_logloss: 0.569759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613304\n",
      "[2]\ttraining's binary_logloss: 0.612203\n",
      "[3]\ttraining's binary_logloss: 0.611227\n",
      "[4]\ttraining's binary_logloss: 0.610253\n",
      "[5]\ttraining's binary_logloss: 0.609319\n",
      "[6]\ttraining's binary_logloss: 0.608459\n",
      "[7]\ttraining's binary_logloss: 0.607635\n",
      "[8]\ttraining's binary_logloss: 0.606848\n",
      "[9]\ttraining's binary_logloss: 0.606064\n",
      "[10]\ttraining's binary_logloss: 0.605334\n",
      "[11]\ttraining's binary_logloss: 0.604641\n",
      "[12]\ttraining's binary_logloss: 0.603802\n",
      "[13]\ttraining's binary_logloss: 0.603013\n",
      "[14]\ttraining's binary_logloss: 0.60243\n",
      "[15]\ttraining's binary_logloss: 0.601695\n",
      "[16]\ttraining's binary_logloss: 0.600972\n",
      "[17]\ttraining's binary_logloss: 0.60028\n",
      "[18]\ttraining's binary_logloss: 0.599616\n",
      "[19]\ttraining's binary_logloss: 0.59898\n",
      "[20]\ttraining's binary_logloss: 0.598371\n",
      "[21]\ttraining's binary_logloss: 0.597746\n",
      "[22]\ttraining's binary_logloss: 0.597161\n",
      "[23]\ttraining's binary_logloss: 0.596717\n",
      "[24]\ttraining's binary_logloss: 0.596161\n",
      "[25]\ttraining's binary_logloss: 0.595628\n",
      "[26]\ttraining's binary_logloss: 0.595201\n",
      "[27]\ttraining's binary_logloss: 0.594856\n",
      "[28]\ttraining's binary_logloss: 0.594438\n",
      "[29]\ttraining's binary_logloss: 0.594069\n",
      "[30]\ttraining's binary_logloss: 0.593696\n",
      "[31]\ttraining's binary_logloss: 0.593235\n",
      "[32]\ttraining's binary_logloss: 0.592852\n",
      "[33]\ttraining's binary_logloss: 0.592629\n",
      "[34]\ttraining's binary_logloss: 0.592251\n",
      "[35]\ttraining's binary_logloss: 0.591913\n",
      "[36]\ttraining's binary_logloss: 0.591666\n",
      "[37]\ttraining's binary_logloss: 0.591485\n",
      "[38]\ttraining's binary_logloss: 0.591172\n",
      "[39]\ttraining's binary_logloss: 0.590825\n",
      "[40]\ttraining's binary_logloss: 0.590495\n",
      "[41]\ttraining's binary_logloss: 0.590276\n",
      "[42]\ttraining's binary_logloss: 0.590163\n",
      "[43]\ttraining's binary_logloss: 0.590035\n",
      "[44]\ttraining's binary_logloss: 0.589859\n",
      "[45]\ttraining's binary_logloss: 0.589679\n",
      "[46]\ttraining's binary_logloss: 0.589439\n",
      "[47]\ttraining's binary_logloss: 0.589212\n",
      "[48]\ttraining's binary_logloss: 0.58908\n",
      "[49]\ttraining's binary_logloss: 0.588876\n",
      "[50]\ttraining's binary_logloss: 0.588714\n",
      "[51]\ttraining's binary_logloss: 0.588606\n",
      "[52]\ttraining's binary_logloss: 0.588507\n",
      "[53]\ttraining's binary_logloss: 0.588415\n",
      "[54]\ttraining's binary_logloss: 0.588257\n",
      "[55]\ttraining's binary_logloss: 0.588177\n",
      "[56]\ttraining's binary_logloss: 0.587965\n",
      "[57]\ttraining's binary_logloss: 0.587789\n",
      "[58]\ttraining's binary_logloss: 0.587591\n",
      "[59]\ttraining's binary_logloss: 0.587423\n",
      "[60]\ttraining's binary_logloss: 0.587256\n",
      "[61]\ttraining's binary_logloss: 0.587175\n",
      "[62]\ttraining's binary_logloss: 0.587096\n",
      "[63]\ttraining's binary_logloss: 0.587025\n",
      "[64]\ttraining's binary_logloss: 0.586962\n",
      "[65]\ttraining's binary_logloss: 0.586826\n",
      "[66]\ttraining's binary_logloss: 0.586735\n",
      "[67]\ttraining's binary_logloss: 0.586652\n",
      "[68]\ttraining's binary_logloss: 0.586579\n",
      "[69]\ttraining's binary_logloss: 0.58652\n",
      "[70]\ttraining's binary_logloss: 0.586464\n",
      "[71]\ttraining's binary_logloss: 0.586398\n",
      "[72]\ttraining's binary_logloss: 0.586338\n",
      "[73]\ttraining's binary_logloss: 0.586286\n",
      "[74]\ttraining's binary_logloss: 0.586252\n",
      "[75]\ttraining's binary_logloss: 0.586203\n",
      "[76]\ttraining's binary_logloss: 0.586137\n",
      "[77]\ttraining's binary_logloss: 0.586074\n",
      "[78]\ttraining's binary_logloss: 0.586021\n",
      "[79]\ttraining's binary_logloss: 0.585975\n",
      "[80]\ttraining's binary_logloss: 0.585987\n",
      "[81]\ttraining's binary_logloss: 0.58599\n",
      "[82]\ttraining's binary_logloss: 0.585934\n",
      "[83]\ttraining's binary_logloss: 0.58588\n",
      "[84]\ttraining's binary_logloss: 0.585837\n",
      "[85]\ttraining's binary_logloss: 0.585797\n",
      "[86]\ttraining's binary_logloss: 0.585777\n",
      "[87]\ttraining's binary_logloss: 0.585738\n",
      "[88]\ttraining's binary_logloss: 0.585694\n",
      "[89]\ttraining's binary_logloss: 0.585665\n",
      "[90]\ttraining's binary_logloss: 0.585679\n",
      "[91]\ttraining's binary_logloss: 0.585638\n",
      "[92]\ttraining's binary_logloss: 0.585601\n",
      "[93]\ttraining's binary_logloss: 0.585568\n",
      "[94]\ttraining's binary_logloss: 0.585548\n",
      "[95]\ttraining's binary_logloss: 0.585526\n",
      "[96]\ttraining's binary_logloss: 0.585554\n",
      "[97]\ttraining's binary_logloss: 0.585594\n",
      "[98]\ttraining's binary_logloss: 0.585683\n",
      "[99]\ttraining's binary_logloss: 0.585734\n",
      "[100]\ttraining's binary_logloss: 0.585759\n",
      "[101]\ttraining's binary_logloss: 0.585823\n",
      "[102]\ttraining's binary_logloss: 0.585883\n",
      "[103]\ttraining's binary_logloss: 0.585957\n",
      "[104]\ttraining's binary_logloss: 0.58601\n",
      "[105]\ttraining's binary_logloss: 0.586082\n",
      "[106]\ttraining's binary_logloss: 0.586123\n",
      "[107]\ttraining's binary_logloss: 0.58618\n",
      "[108]\ttraining's binary_logloss: 0.586226\n",
      "[109]\ttraining's binary_logloss: 0.586281\n",
      "[110]\ttraining's binary_logloss: 0.586331\n",
      "[111]\ttraining's binary_logloss: 0.586353\n",
      "[112]\ttraining's binary_logloss: 0.586403\n",
      "[113]\ttraining's binary_logloss: 0.586433\n",
      "[114]\ttraining's binary_logloss: 0.586449\n",
      "[115]\ttraining's binary_logloss: 0.58648\n",
      "[116]\ttraining's binary_logloss: 0.586501\n",
      "[117]\ttraining's binary_logloss: 0.586509\n",
      "[118]\ttraining's binary_logloss: 0.586523\n",
      "[119]\ttraining's binary_logloss: 0.58654\n",
      "[120]\ttraining's binary_logloss: 0.586562\n",
      "[121]\ttraining's binary_logloss: 0.586562\n",
      "[122]\ttraining's binary_logloss: 0.586554\n",
      "[123]\ttraining's binary_logloss: 0.586565\n",
      "[124]\ttraining's binary_logloss: 0.586566\n",
      "[125]\ttraining's binary_logloss: 0.586575\n",
      "[126]\ttraining's binary_logloss: 0.586546\n",
      "[127]\ttraining's binary_logloss: 0.586521\n",
      "[128]\ttraining's binary_logloss: 0.5865\n",
      "[129]\ttraining's binary_logloss: 0.586472\n",
      "[130]\ttraining's binary_logloss: 0.586457\n",
      "[131]\ttraining's binary_logloss: 0.586495\n",
      "[132]\ttraining's binary_logloss: 0.586536\n",
      "[133]\ttraining's binary_logloss: 0.58658\n",
      "[134]\ttraining's binary_logloss: 0.586628\n",
      "[135]\ttraining's binary_logloss: 0.586685\n",
      "[136]\ttraining's binary_logloss: 0.586713\n",
      "[137]\ttraining's binary_logloss: 0.586753\n",
      "[138]\ttraining's binary_logloss: 0.586792\n",
      "[139]\ttraining's binary_logloss: 0.586836\n",
      "[140]\ttraining's binary_logloss: 0.586845\n",
      "[141]\ttraining's binary_logloss: 0.586861\n",
      "[142]\ttraining's binary_logloss: 0.586911\n",
      "[143]\ttraining's binary_logloss: 0.586928\n",
      "[144]\ttraining's binary_logloss: 0.586967\n",
      "[145]\ttraining's binary_logloss: 0.586999\n",
      "[146]\ttraining's binary_logloss: 0.586976\n",
      "[147]\ttraining's binary_logloss: 0.586961\n",
      "[148]\ttraining's binary_logloss: 0.586993\n",
      "[149]\ttraining's binary_logloss: 0.587004\n",
      "[150]\ttraining's binary_logloss: 0.587021\n",
      "[151]\ttraining's binary_logloss: 0.587076\n",
      "[152]\ttraining's binary_logloss: 0.587096\n",
      "[153]\ttraining's binary_logloss: 0.587139\n",
      "[154]\ttraining's binary_logloss: 0.587137\n",
      "[155]\ttraining's binary_logloss: 0.587161\n",
      "[156]\ttraining's binary_logloss: 0.587197\n",
      "[157]\ttraining's binary_logloss: 0.587213\n",
      "[158]\ttraining's binary_logloss: 0.58723\n",
      "[159]\ttraining's binary_logloss: 0.587263\n",
      "[160]\ttraining's binary_logloss: 0.587306\n",
      "[161]\ttraining's binary_logloss: 0.587276\n",
      "[162]\ttraining's binary_logloss: 0.587248\n",
      "[163]\ttraining's binary_logloss: 0.587244\n",
      "[164]\ttraining's binary_logloss: 0.587233\n",
      "[165]\ttraining's binary_logloss: 0.587208\n",
      "[166]\ttraining's binary_logloss: 0.587218\n",
      "[167]\ttraining's binary_logloss: 0.587227\n",
      "[168]\ttraining's binary_logloss: 0.587237\n",
      "[169]\ttraining's binary_logloss: 0.587261\n",
      "[170]\ttraining's binary_logloss: 0.587284\n",
      "[171]\ttraining's binary_logloss: 0.587333\n",
      "[172]\ttraining's binary_logloss: 0.587363\n",
      "[173]\ttraining's binary_logloss: 0.587414\n",
      "[174]\ttraining's binary_logloss: 0.587443\n",
      "[175]\ttraining's binary_logloss: 0.587478\n",
      "[176]\ttraining's binary_logloss: 0.587502\n",
      "[177]\ttraining's binary_logloss: 0.587537\n",
      "[178]\ttraining's binary_logloss: 0.587598\n",
      "[179]\ttraining's binary_logloss: 0.587651\n",
      "[180]\ttraining's binary_logloss: 0.587704\n",
      "[181]\ttraining's binary_logloss: 0.587727\n",
      "[182]\ttraining's binary_logloss: 0.587741\n",
      "[183]\ttraining's binary_logloss: 0.587767\n",
      "[184]\ttraining's binary_logloss: 0.587811\n",
      "[185]\ttraining's binary_logloss: 0.587839\n",
      "[186]\ttraining's binary_logloss: 0.587835\n",
      "[187]\ttraining's binary_logloss: 0.587823\n",
      "[188]\ttraining's binary_logloss: 0.587823\n",
      "[189]\ttraining's binary_logloss: 0.587827\n",
      "[190]\ttraining's binary_logloss: 0.587831\n",
      "[191]\ttraining's binary_logloss: 0.587836\n",
      "[192]\ttraining's binary_logloss: 0.587841\n",
      "[193]\ttraining's binary_logloss: 0.587856\n",
      "[194]\ttraining's binary_logloss: 0.587873\n",
      "[195]\ttraining's binary_logloss: 0.587892\n",
      "[196]\ttraining's binary_logloss: 0.587938\n",
      "[197]\ttraining's binary_logloss: 0.587962\n",
      "[198]\ttraining's binary_logloss: 0.587983\n",
      "[199]\ttraining's binary_logloss: 0.587998\n",
      "[200]\ttraining's binary_logloss: 0.588023\n",
      "[201]\ttraining's binary_logloss: 0.588027\n",
      "[202]\ttraining's binary_logloss: 0.588015\n",
      "[203]\ttraining's binary_logloss: 0.588015\n",
      "[204]\ttraining's binary_logloss: 0.588018\n",
      "[205]\ttraining's binary_logloss: 0.588056\n",
      "[206]\ttraining's binary_logloss: 0.588069\n",
      "[207]\ttraining's binary_logloss: 0.588098\n",
      "[208]\ttraining's binary_logloss: 0.588128\n",
      "[209]\ttraining's binary_logloss: 0.588149\n",
      "[210]\ttraining's binary_logloss: 0.588174\n",
      "[211]\ttraining's binary_logloss: 0.588207\n",
      "[212]\ttraining's binary_logloss: 0.588232\n",
      "[213]\ttraining's binary_logloss: 0.588267\n",
      "[214]\ttraining's binary_logloss: 0.588303\n",
      "[215]\ttraining's binary_logloss: 0.588336\n",
      "[216]\ttraining's binary_logloss: 0.588301\n",
      "[217]\ttraining's binary_logloss: 0.588269\n",
      "[218]\ttraining's binary_logloss: 0.588233\n",
      "[219]\ttraining's binary_logloss: 0.588197\n",
      "[220]\ttraining's binary_logloss: 0.588167\n",
      "[221]\ttraining's binary_logloss: 0.588125\n",
      "[222]\ttraining's binary_logloss: 0.588086\n",
      "[223]\ttraining's binary_logloss: 0.588051\n",
      "[224]\ttraining's binary_logloss: 0.588008\n",
      "[225]\ttraining's binary_logloss: 0.587972\n",
      "[226]\ttraining's binary_logloss: 0.587955\n",
      "[227]\ttraining's binary_logloss: 0.587935\n",
      "[228]\ttraining's binary_logloss: 0.587918\n",
      "[229]\ttraining's binary_logloss: 0.587907\n",
      "[230]\ttraining's binary_logloss: 0.587898\n",
      "[231]\ttraining's binary_logloss: 0.587909\n",
      "[232]\ttraining's binary_logloss: 0.587888\n",
      "[233]\ttraining's binary_logloss: 0.587902\n",
      "[234]\ttraining's binary_logloss: 0.587918\n",
      "[235]\ttraining's binary_logloss: 0.587936\n",
      "[236]\ttraining's binary_logloss: 0.587915\n",
      "[237]\ttraining's binary_logloss: 0.587896\n",
      "[238]\ttraining's binary_logloss: 0.587882\n",
      "[239]\ttraining's binary_logloss: 0.587858\n",
      "[240]\ttraining's binary_logloss: 0.587847\n",
      "[241]\ttraining's binary_logloss: 0.587841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[242]\ttraining's binary_logloss: 0.587797\n",
      "[243]\ttraining's binary_logloss: 0.587756\n",
      "[244]\ttraining's binary_logloss: 0.587717\n",
      "[245]\ttraining's binary_logloss: 0.58768\n",
      "[246]\ttraining's binary_logloss: 0.587592\n",
      "[247]\ttraining's binary_logloss: 0.587552\n",
      "[248]\ttraining's binary_logloss: 0.587478\n",
      "[249]\ttraining's binary_logloss: 0.587394\n",
      "[250]\ttraining's binary_logloss: 0.587326\n",
      "[251]\ttraining's binary_logloss: 0.587346\n",
      "[252]\ttraining's binary_logloss: 0.587338\n",
      "[253]\ttraining's binary_logloss: 0.587342\n",
      "[254]\ttraining's binary_logloss: 0.587344\n",
      "[255]\ttraining's binary_logloss: 0.587338\n",
      "[256]\ttraining's binary_logloss: 0.587289\n",
      "[257]\ttraining's binary_logloss: 0.587234\n",
      "[258]\ttraining's binary_logloss: 0.587191\n",
      "[259]\ttraining's binary_logloss: 0.587145\n",
      "[260]\ttraining's binary_logloss: 0.587104\n",
      "[261]\ttraining's binary_logloss: 0.587084\n",
      "[262]\ttraining's binary_logloss: 0.587063\n",
      "[263]\ttraining's binary_logloss: 0.587049\n",
      "[264]\ttraining's binary_logloss: 0.587022\n",
      "[265]\ttraining's binary_logloss: 0.586996\n",
      "[266]\ttraining's binary_logloss: 0.586985\n",
      "[267]\ttraining's binary_logloss: 0.586976\n",
      "[268]\ttraining's binary_logloss: 0.586976\n",
      "[269]\ttraining's binary_logloss: 0.586972\n",
      "[270]\ttraining's binary_logloss: 0.586966\n",
      "[271]\ttraining's binary_logloss: 0.586876\n",
      "[272]\ttraining's binary_logloss: 0.586787\n",
      "[273]\ttraining's binary_logloss: 0.586718\n",
      "[274]\ttraining's binary_logloss: 0.58665\n",
      "[275]\ttraining's binary_logloss: 0.586565\n",
      "[276]\ttraining's binary_logloss: 0.586555\n",
      "[277]\ttraining's binary_logloss: 0.586532\n",
      "[278]\ttraining's binary_logloss: 0.586489\n",
      "[279]\ttraining's binary_logloss: 0.586464\n",
      "[280]\ttraining's binary_logloss: 0.586437\n",
      "[281]\ttraining's binary_logloss: 0.586389\n",
      "[282]\ttraining's binary_logloss: 0.586342\n",
      "[283]\ttraining's binary_logloss: 0.586298\n",
      "[284]\ttraining's binary_logloss: 0.586256\n",
      "[285]\ttraining's binary_logloss: 0.586221\n",
      "[286]\ttraining's binary_logloss: 0.586134\n",
      "[287]\ttraining's binary_logloss: 0.586042\n",
      "[288]\ttraining's binary_logloss: 0.585953\n",
      "[289]\ttraining's binary_logloss: 0.585889\n",
      "[290]\ttraining's binary_logloss: 0.585814\n",
      "[291]\ttraining's binary_logloss: 0.58574\n",
      "[292]\ttraining's binary_logloss: 0.585665\n",
      "[293]\ttraining's binary_logloss: 0.585587\n",
      "[294]\ttraining's binary_logloss: 0.585508\n",
      "[295]\ttraining's binary_logloss: 0.585441\n",
      "[296]\ttraining's binary_logloss: 0.585379\n",
      "[297]\ttraining's binary_logloss: 0.585333\n",
      "[298]\ttraining's binary_logloss: 0.58529\n",
      "[299]\ttraining's binary_logloss: 0.585253\n",
      "[300]\ttraining's binary_logloss: 0.585204\n",
      "[301]\ttraining's binary_logloss: 0.585166\n",
      "[302]\ttraining's binary_logloss: 0.585115\n",
      "[303]\ttraining's binary_logloss: 0.585075\n",
      "[304]\ttraining's binary_logloss: 0.585047\n",
      "[305]\ttraining's binary_logloss: 0.585012\n",
      "[306]\ttraining's binary_logloss: 0.584951\n",
      "[307]\ttraining's binary_logloss: 0.584901\n",
      "[308]\ttraining's binary_logloss: 0.584863\n",
      "[309]\ttraining's binary_logloss: 0.58481\n",
      "[310]\ttraining's binary_logloss: 0.584751\n",
      "[311]\ttraining's binary_logloss: 0.584699\n",
      "[312]\ttraining's binary_logloss: 0.584649\n",
      "[313]\ttraining's binary_logloss: 0.584604\n",
      "[314]\ttraining's binary_logloss: 0.584537\n",
      "[315]\ttraining's binary_logloss: 0.584475\n",
      "[316]\ttraining's binary_logloss: 0.584409\n",
      "[317]\ttraining's binary_logloss: 0.584341\n",
      "[318]\ttraining's binary_logloss: 0.584275\n",
      "[319]\ttraining's binary_logloss: 0.58421\n",
      "[320]\ttraining's binary_logloss: 0.584146\n",
      "[321]\ttraining's binary_logloss: 0.584118\n",
      "[322]\ttraining's binary_logloss: 0.584092\n",
      "[323]\ttraining's binary_logloss: 0.584069\n",
      "[324]\ttraining's binary_logloss: 0.584056\n",
      "[325]\ttraining's binary_logloss: 0.584024\n",
      "[326]\ttraining's binary_logloss: 0.58397\n",
      "[327]\ttraining's binary_logloss: 0.583921\n",
      "[328]\ttraining's binary_logloss: 0.583871\n",
      "[329]\ttraining's binary_logloss: 0.583813\n",
      "[330]\ttraining's binary_logloss: 0.583764\n",
      "[331]\ttraining's binary_logloss: 0.583695\n",
      "[332]\ttraining's binary_logloss: 0.583642\n",
      "[333]\ttraining's binary_logloss: 0.583597\n",
      "[334]\ttraining's binary_logloss: 0.583546\n",
      "[335]\ttraining's binary_logloss: 0.583495\n",
      "[336]\ttraining's binary_logloss: 0.58343\n",
      "[337]\ttraining's binary_logloss: 0.583345\n",
      "[338]\ttraining's binary_logloss: 0.583248\n",
      "[339]\ttraining's binary_logloss: 0.583185\n",
      "[340]\ttraining's binary_logloss: 0.583108\n",
      "[341]\ttraining's binary_logloss: 0.583087\n",
      "[342]\ttraining's binary_logloss: 0.583074\n",
      "[343]\ttraining's binary_logloss: 0.583039\n",
      "[344]\ttraining's binary_logloss: 0.583028\n",
      "[345]\ttraining's binary_logloss: 0.58301\n",
      "[346]\ttraining's binary_logloss: 0.582988\n",
      "[347]\ttraining's binary_logloss: 0.582965\n",
      "[348]\ttraining's binary_logloss: 0.582916\n",
      "[349]\ttraining's binary_logloss: 0.582896\n",
      "[350]\ttraining's binary_logloss: 0.582857\n",
      "[351]\ttraining's binary_logloss: 0.582767\n",
      "[352]\ttraining's binary_logloss: 0.582687\n",
      "[353]\ttraining's binary_logloss: 0.582594\n",
      "[354]\ttraining's binary_logloss: 0.582518\n",
      "[355]\ttraining's binary_logloss: 0.582441\n",
      "[356]\ttraining's binary_logloss: 0.582366\n",
      "[357]\ttraining's binary_logloss: 0.582296\n",
      "[358]\ttraining's binary_logloss: 0.582224\n",
      "[359]\ttraining's binary_logloss: 0.582149\n",
      "[360]\ttraining's binary_logloss: 0.582082\n",
      "[361]\ttraining's binary_logloss: 0.581975\n",
      "[362]\ttraining's binary_logloss: 0.581869\n",
      "[363]\ttraining's binary_logloss: 0.581779\n",
      "[364]\ttraining's binary_logloss: 0.581689\n",
      "[365]\ttraining's binary_logloss: 0.581589\n",
      "[366]\ttraining's binary_logloss: 0.58153\n",
      "[367]\ttraining's binary_logloss: 0.58148\n",
      "[368]\ttraining's binary_logloss: 0.581425\n",
      "[369]\ttraining's binary_logloss: 0.581371\n",
      "[370]\ttraining's binary_logloss: 0.581319\n",
      "[371]\ttraining's binary_logloss: 0.581291\n",
      "[372]\ttraining's binary_logloss: 0.58126\n",
      "[373]\ttraining's binary_logloss: 0.58123\n",
      "[374]\ttraining's binary_logloss: 0.581199\n",
      "[375]\ttraining's binary_logloss: 0.581132\n",
      "[376]\ttraining's binary_logloss: 0.581074\n",
      "[377]\ttraining's binary_logloss: 0.581028\n",
      "[378]\ttraining's binary_logloss: 0.580957\n",
      "[379]\ttraining's binary_logloss: 0.580895\n",
      "[380]\ttraining's binary_logloss: 0.580846\n",
      "[381]\ttraining's binary_logloss: 0.580825\n",
      "[382]\ttraining's binary_logloss: 0.580807\n",
      "[383]\ttraining's binary_logloss: 0.580788\n",
      "[384]\ttraining's binary_logloss: 0.580767\n",
      "[385]\ttraining's binary_logloss: 0.580737\n",
      "[386]\ttraining's binary_logloss: 0.580672\n",
      "[387]\ttraining's binary_logloss: 0.580592\n",
      "[388]\ttraining's binary_logloss: 0.580515\n",
      "[389]\ttraining's binary_logloss: 0.580456\n",
      "[390]\ttraining's binary_logloss: 0.580388\n",
      "[391]\ttraining's binary_logloss: 0.5803\n",
      "[392]\ttraining's binary_logloss: 0.580213\n",
      "[393]\ttraining's binary_logloss: 0.580125\n",
      "[394]\ttraining's binary_logloss: 0.58003\n",
      "[395]\ttraining's binary_logloss: 0.579956\n",
      "[396]\ttraining's binary_logloss: 0.579907\n",
      "[397]\ttraining's binary_logloss: 0.579857\n",
      "[398]\ttraining's binary_logloss: 0.579798\n",
      "[399]\ttraining's binary_logloss: 0.579739\n",
      "[400]\ttraining's binary_logloss: 0.57969\n",
      "[401]\ttraining's binary_logloss: 0.579592\n",
      "[402]\ttraining's binary_logloss: 0.579502\n",
      "[403]\ttraining's binary_logloss: 0.579414\n",
      "[404]\ttraining's binary_logloss: 0.579324\n",
      "[405]\ttraining's binary_logloss: 0.579228\n",
      "[406]\ttraining's binary_logloss: 0.579164\n",
      "[407]\ttraining's binary_logloss: 0.579094\n",
      "[408]\ttraining's binary_logloss: 0.579024\n",
      "[409]\ttraining's binary_logloss: 0.578958\n",
      "[410]\ttraining's binary_logloss: 0.578896\n",
      "[411]\ttraining's binary_logloss: 0.578801\n",
      "[412]\ttraining's binary_logloss: 0.57871\n",
      "[413]\ttraining's binary_logloss: 0.578619\n",
      "[414]\ttraining's binary_logloss: 0.57854\n",
      "[415]\ttraining's binary_logloss: 0.578464\n",
      "[416]\ttraining's binary_logloss: 0.578407\n",
      "[417]\ttraining's binary_logloss: 0.578349\n",
      "[418]\ttraining's binary_logloss: 0.578292\n",
      "[419]\ttraining's binary_logloss: 0.578247\n",
      "[420]\ttraining's binary_logloss: 0.578194\n",
      "[421]\ttraining's binary_logloss: 0.578168\n",
      "[422]\ttraining's binary_logloss: 0.578139\n",
      "[423]\ttraining's binary_logloss: 0.578107\n",
      "[424]\ttraining's binary_logloss: 0.578083\n",
      "[425]\ttraining's binary_logloss: 0.578057\n",
      "[426]\ttraining's binary_logloss: 0.577986\n",
      "[427]\ttraining's binary_logloss: 0.577918\n",
      "[428]\ttraining's binary_logloss: 0.577848\n",
      "[429]\ttraining's binary_logloss: 0.577789\n",
      "[430]\ttraining's binary_logloss: 0.577724\n",
      "[431]\ttraining's binary_logloss: 0.577641\n",
      "[432]\ttraining's binary_logloss: 0.577538\n",
      "[433]\ttraining's binary_logloss: 0.577458\n",
      "[434]\ttraining's binary_logloss: 0.57736\n",
      "[435]\ttraining's binary_logloss: 0.577261\n",
      "[436]\ttraining's binary_logloss: 0.577216\n",
      "[437]\ttraining's binary_logloss: 0.577152\n",
      "[438]\ttraining's binary_logloss: 0.577103\n",
      "[439]\ttraining's binary_logloss: 0.577062\n",
      "[440]\ttraining's binary_logloss: 0.577031\n",
      "[441]\ttraining's binary_logloss: 0.576952\n",
      "[442]\ttraining's binary_logloss: 0.576887\n",
      "[443]\ttraining's binary_logloss: 0.576815\n",
      "[444]\ttraining's binary_logloss: 0.576757\n",
      "[445]\ttraining's binary_logloss: 0.576687\n",
      "[446]\ttraining's binary_logloss: 0.576611\n",
      "[447]\ttraining's binary_logloss: 0.576523\n",
      "[448]\ttraining's binary_logloss: 0.576442\n",
      "[449]\ttraining's binary_logloss: 0.57636\n",
      "[450]\ttraining's binary_logloss: 0.576296\n",
      "[451]\ttraining's binary_logloss: 0.57626\n",
      "[452]\ttraining's binary_logloss: 0.576213\n",
      "[453]\ttraining's binary_logloss: 0.576176\n",
      "[454]\ttraining's binary_logloss: 0.57613\n",
      "[455]\ttraining's binary_logloss: 0.576098\n",
      "[456]\ttraining's binary_logloss: 0.576037\n",
      "[457]\ttraining's binary_logloss: 0.575985\n",
      "[458]\ttraining's binary_logloss: 0.575913\n",
      "[459]\ttraining's binary_logloss: 0.575852\n",
      "[460]\ttraining's binary_logloss: 0.575784\n",
      "[461]\ttraining's binary_logloss: 0.575741\n",
      "[462]\ttraining's binary_logloss: 0.575697\n",
      "[463]\ttraining's binary_logloss: 0.575649\n",
      "[464]\ttraining's binary_logloss: 0.575599\n",
      "[465]\ttraining's binary_logloss: 0.575551\n",
      "[466]\ttraining's binary_logloss: 0.575465\n",
      "[467]\ttraining's binary_logloss: 0.575387\n",
      "[468]\ttraining's binary_logloss: 0.575316\n",
      "[469]\ttraining's binary_logloss: 0.575256\n",
      "[470]\ttraining's binary_logloss: 0.575182\n",
      "[471]\ttraining's binary_logloss: 0.575134\n",
      "[472]\ttraining's binary_logloss: 0.575088\n",
      "[473]\ttraining's binary_logloss: 0.57504\n",
      "[474]\ttraining's binary_logloss: 0.575007\n",
      "[475]\ttraining's binary_logloss: 0.57496\n",
      "[476]\ttraining's binary_logloss: 0.57487\n",
      "[477]\ttraining's binary_logloss: 0.574791\n",
      "[478]\ttraining's binary_logloss: 0.574712\n",
      "[479]\ttraining's binary_logloss: 0.574637\n",
      "[480]\ttraining's binary_logloss: 0.57457\n",
      "[481]\ttraining's binary_logloss: 0.574493\n",
      "[482]\ttraining's binary_logloss: 0.574422\n",
      "[483]\ttraining's binary_logloss: 0.574347\n",
      "[484]\ttraining's binary_logloss: 0.574266\n",
      "[485]\ttraining's binary_logloss: 0.574201\n",
      "[486]\ttraining's binary_logloss: 0.574091\n",
      "[487]\ttraining's binary_logloss: 0.573986\n",
      "[488]\ttraining's binary_logloss: 0.573881\n",
      "[489]\ttraining's binary_logloss: 0.573785\n",
      "[490]\ttraining's binary_logloss: 0.573683\n",
      "[491]\ttraining's binary_logloss: 0.573603\n",
      "[492]\ttraining's binary_logloss: 0.573524\n",
      "[493]\ttraining's binary_logloss: 0.573451\n",
      "[494]\ttraining's binary_logloss: 0.573378\n",
      "[495]\ttraining's binary_logloss: 0.573284\n",
      "[496]\ttraining's binary_logloss: 0.573209\n",
      "[497]\ttraining's binary_logloss: 0.573132\n",
      "[498]\ttraining's binary_logloss: 0.573061\n",
      "[499]\ttraining's binary_logloss: 0.572984\n",
      "[500]\ttraining's binary_logloss: 0.572918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.617701\n",
      "[2]\ttraining's binary_logloss: 0.616657\n",
      "[3]\ttraining's binary_logloss: 0.615655\n",
      "[4]\ttraining's binary_logloss: 0.614694\n",
      "[5]\ttraining's binary_logloss: 0.613788\n",
      "[6]\ttraining's binary_logloss: 0.612896\n",
      "[7]\ttraining's binary_logloss: 0.612051\n",
      "[8]\ttraining's binary_logloss: 0.611238\n",
      "[9]\ttraining's binary_logloss: 0.610457\n",
      "[10]\ttraining's binary_logloss: 0.609763\n",
      "[11]\ttraining's binary_logloss: 0.608978\n",
      "[12]\ttraining's binary_logloss: 0.608163\n",
      "[13]\ttraining's binary_logloss: 0.60745\n",
      "[14]\ttraining's binary_logloss: 0.606782\n",
      "[15]\ttraining's binary_logloss: 0.606111\n",
      "[16]\ttraining's binary_logloss: 0.605514\n",
      "[17]\ttraining's binary_logloss: 0.604926\n",
      "[18]\ttraining's binary_logloss: 0.604355\n",
      "[19]\ttraining's binary_logloss: 0.603746\n",
      "[20]\ttraining's binary_logloss: 0.603189\n",
      "[21]\ttraining's binary_logloss: 0.602623\n",
      "[22]\ttraining's binary_logloss: 0.602012\n",
      "[23]\ttraining's binary_logloss: 0.601431\n",
      "[24]\ttraining's binary_logloss: 0.600869\n",
      "[25]\ttraining's binary_logloss: 0.60033\n",
      "[26]\ttraining's binary_logloss: 0.599932\n",
      "[27]\ttraining's binary_logloss: 0.599481\n",
      "[28]\ttraining's binary_logloss: 0.599064\n",
      "[29]\ttraining's binary_logloss: 0.598643\n",
      "[30]\ttraining's binary_logloss: 0.598246\n",
      "[31]\ttraining's binary_logloss: 0.597915\n",
      "[32]\ttraining's binary_logloss: 0.597596\n",
      "[33]\ttraining's binary_logloss: 0.597335\n",
      "[34]\ttraining's binary_logloss: 0.597049\n",
      "[35]\ttraining's binary_logloss: 0.596717\n",
      "[36]\ttraining's binary_logloss: 0.596419\n",
      "[37]\ttraining's binary_logloss: 0.596159\n",
      "[38]\ttraining's binary_logloss: 0.595894\n",
      "[39]\ttraining's binary_logloss: 0.595677\n",
      "[40]\ttraining's binary_logloss: 0.595448\n",
      "[41]\ttraining's binary_logloss: 0.595163\n",
      "[42]\ttraining's binary_logloss: 0.594899\n",
      "[43]\ttraining's binary_logloss: 0.594634\n",
      "[44]\ttraining's binary_logloss: 0.594474\n",
      "[45]\ttraining's binary_logloss: 0.594328\n",
      "[46]\ttraining's binary_logloss: 0.594032\n",
      "[47]\ttraining's binary_logloss: 0.593752\n",
      "[48]\ttraining's binary_logloss: 0.593484\n",
      "[49]\ttraining's binary_logloss: 0.59328\n",
      "[50]\ttraining's binary_logloss: 0.593032\n",
      "[51]\ttraining's binary_logloss: 0.592819\n",
      "[52]\ttraining's binary_logloss: 0.592642\n",
      "[53]\ttraining's binary_logloss: 0.59245\n",
      "[54]\ttraining's binary_logloss: 0.592276\n",
      "[55]\ttraining's binary_logloss: 0.592119\n",
      "[56]\ttraining's binary_logloss: 0.591976\n",
      "[57]\ttraining's binary_logloss: 0.591833\n",
      "[58]\ttraining's binary_logloss: 0.591714\n",
      "[59]\ttraining's binary_logloss: 0.591605\n",
      "[60]\ttraining's binary_logloss: 0.591497\n",
      "[61]\ttraining's binary_logloss: 0.59137\n",
      "[62]\ttraining's binary_logloss: 0.59127\n",
      "[63]\ttraining's binary_logloss: 0.59116\n",
      "[64]\ttraining's binary_logloss: 0.591062\n",
      "[65]\ttraining's binary_logloss: 0.590984\n",
      "[66]\ttraining's binary_logloss: 0.590886\n",
      "[67]\ttraining's binary_logloss: 0.590811\n",
      "[68]\ttraining's binary_logloss: 0.59072\n",
      "[69]\ttraining's binary_logloss: 0.590636\n",
      "[70]\ttraining's binary_logloss: 0.590561\n",
      "[71]\ttraining's binary_logloss: 0.590482\n",
      "[72]\ttraining's binary_logloss: 0.590501\n",
      "[73]\ttraining's binary_logloss: 0.590441\n",
      "[74]\ttraining's binary_logloss: 0.590428\n",
      "[75]\ttraining's binary_logloss: 0.590367\n",
      "[76]\ttraining's binary_logloss: 0.590288\n",
      "[77]\ttraining's binary_logloss: 0.590216\n",
      "[78]\ttraining's binary_logloss: 0.590219\n",
      "[79]\ttraining's binary_logloss: 0.590163\n",
      "[80]\ttraining's binary_logloss: 0.590107\n",
      "[81]\ttraining's binary_logloss: 0.590055\n",
      "[82]\ttraining's binary_logloss: 0.589995\n",
      "[83]\ttraining's binary_logloss: 0.589939\n",
      "[84]\ttraining's binary_logloss: 0.589927\n",
      "[85]\ttraining's binary_logloss: 0.589881\n",
      "[86]\ttraining's binary_logloss: 0.589868\n",
      "[87]\ttraining's binary_logloss: 0.589873\n",
      "[88]\ttraining's binary_logloss: 0.589871\n",
      "[89]\ttraining's binary_logloss: 0.589872\n",
      "[90]\ttraining's binary_logloss: 0.589873\n",
      "[91]\ttraining's binary_logloss: 0.589811\n",
      "[92]\ttraining's binary_logloss: 0.589743\n",
      "[93]\ttraining's binary_logloss: 0.589681\n",
      "[94]\ttraining's binary_logloss: 0.589608\n",
      "[95]\ttraining's binary_logloss: 0.589655\n",
      "[96]\ttraining's binary_logloss: 0.589679\n",
      "[97]\ttraining's binary_logloss: 0.589675\n",
      "[98]\ttraining's binary_logloss: 0.589701\n",
      "[99]\ttraining's binary_logloss: 0.589734\n",
      "[100]\ttraining's binary_logloss: 0.589743\n",
      "[101]\ttraining's binary_logloss: 0.589749\n",
      "[102]\ttraining's binary_logloss: 0.589761\n",
      "[103]\ttraining's binary_logloss: 0.589781\n",
      "[104]\ttraining's binary_logloss: 0.589836\n",
      "[105]\ttraining's binary_logloss: 0.589829\n",
      "[106]\ttraining's binary_logloss: 0.589794\n",
      "[107]\ttraining's binary_logloss: 0.589767\n",
      "[108]\ttraining's binary_logloss: 0.589771\n",
      "[109]\ttraining's binary_logloss: 0.589788\n",
      "[110]\ttraining's binary_logloss: 0.589763\n",
      "[111]\ttraining's binary_logloss: 0.589757\n",
      "[112]\ttraining's binary_logloss: 0.589801\n",
      "[113]\ttraining's binary_logloss: 0.589831\n",
      "[114]\ttraining's binary_logloss: 0.589879\n",
      "[115]\ttraining's binary_logloss: 0.589927\n",
      "[116]\ttraining's binary_logloss: 0.589954\n",
      "[117]\ttraining's binary_logloss: 0.589935\n",
      "[118]\ttraining's binary_logloss: 0.589967\n",
      "[119]\ttraining's binary_logloss: 0.589969\n",
      "[120]\ttraining's binary_logloss: 0.590008\n",
      "[121]\ttraining's binary_logloss: 0.590045\n",
      "[122]\ttraining's binary_logloss: 0.590076\n",
      "[123]\ttraining's binary_logloss: 0.590123\n",
      "[124]\ttraining's binary_logloss: 0.590169\n",
      "[125]\ttraining's binary_logloss: 0.590211\n",
      "[126]\ttraining's binary_logloss: 0.590227\n",
      "[127]\ttraining's binary_logloss: 0.590254\n",
      "[128]\ttraining's binary_logloss: 0.590306\n",
      "[129]\ttraining's binary_logloss: 0.590329\n",
      "[130]\ttraining's binary_logloss: 0.590384\n",
      "[131]\ttraining's binary_logloss: 0.590355\n",
      "[132]\ttraining's binary_logloss: 0.590334\n",
      "[133]\ttraining's binary_logloss: 0.590372\n",
      "[134]\ttraining's binary_logloss: 0.590351\n",
      "[135]\ttraining's binary_logloss: 0.590333\n",
      "[136]\ttraining's binary_logloss: 0.590362\n",
      "[137]\ttraining's binary_logloss: 0.590396\n",
      "[138]\ttraining's binary_logloss: 0.590419\n",
      "[139]\ttraining's binary_logloss: 0.590461\n",
      "[140]\ttraining's binary_logloss: 0.590507\n",
      "[141]\ttraining's binary_logloss: 0.590488\n",
      "[142]\ttraining's binary_logloss: 0.590472\n",
      "[143]\ttraining's binary_logloss: 0.590469\n",
      "[144]\ttraining's binary_logloss: 0.59048\n",
      "[145]\ttraining's binary_logloss: 0.590526\n",
      "[146]\ttraining's binary_logloss: 0.590572\n",
      "[147]\ttraining's binary_logloss: 0.590594\n",
      "[148]\ttraining's binary_logloss: 0.590627\n",
      "[149]\ttraining's binary_logloss: 0.590641\n",
      "[150]\ttraining's binary_logloss: 0.590632\n",
      "[151]\ttraining's binary_logloss: 0.590666\n",
      "[152]\ttraining's binary_logloss: 0.590698\n",
      "[153]\ttraining's binary_logloss: 0.590738\n",
      "[154]\ttraining's binary_logloss: 0.590773\n",
      "[155]\ttraining's binary_logloss: 0.590816\n",
      "[156]\ttraining's binary_logloss: 0.590835\n",
      "[157]\ttraining's binary_logloss: 0.59085\n",
      "[158]\ttraining's binary_logloss: 0.590861\n",
      "[159]\ttraining's binary_logloss: 0.590874\n",
      "[160]\ttraining's binary_logloss: 0.590894\n",
      "[161]\ttraining's binary_logloss: 0.590862\n",
      "[162]\ttraining's binary_logloss: 0.590832\n",
      "[163]\ttraining's binary_logloss: 0.590803\n",
      "[164]\ttraining's binary_logloss: 0.590779\n",
      "[165]\ttraining's binary_logloss: 0.590753\n",
      "[166]\ttraining's binary_logloss: 0.590746\n",
      "[167]\ttraining's binary_logloss: 0.590749\n",
      "[168]\ttraining's binary_logloss: 0.590736\n",
      "[169]\ttraining's binary_logloss: 0.590725\n",
      "[170]\ttraining's binary_logloss: 0.590726\n",
      "[171]\ttraining's binary_logloss: 0.590757\n",
      "[172]\ttraining's binary_logloss: 0.590791\n",
      "[173]\ttraining's binary_logloss: 0.590806\n",
      "[174]\ttraining's binary_logloss: 0.59083\n",
      "[175]\ttraining's binary_logloss: 0.590856\n",
      "[176]\ttraining's binary_logloss: 0.59086\n",
      "[177]\ttraining's binary_logloss: 0.590861\n",
      "[178]\ttraining's binary_logloss: 0.590895\n",
      "[179]\ttraining's binary_logloss: 0.590902\n",
      "[180]\ttraining's binary_logloss: 0.590941\n",
      "[181]\ttraining's binary_logloss: 0.590985\n",
      "[182]\ttraining's binary_logloss: 0.590983\n",
      "[183]\ttraining's binary_logloss: 0.590973\n",
      "[184]\ttraining's binary_logloss: 0.590974\n",
      "[185]\ttraining's binary_logloss: 0.590967\n",
      "[186]\ttraining's binary_logloss: 0.590987\n",
      "[187]\ttraining's binary_logloss: 0.591006\n",
      "[188]\ttraining's binary_logloss: 0.591032\n",
      "[189]\ttraining's binary_logloss: 0.59106\n",
      "[190]\ttraining's binary_logloss: 0.59105\n",
      "[191]\ttraining's binary_logloss: 0.591053\n",
      "[192]\ttraining's binary_logloss: 0.591059\n",
      "[193]\ttraining's binary_logloss: 0.591041\n",
      "[194]\ttraining's binary_logloss: 0.591043\n",
      "[195]\ttraining's binary_logloss: 0.591044\n",
      "[196]\ttraining's binary_logloss: 0.591036\n",
      "[197]\ttraining's binary_logloss: 0.591032\n",
      "[198]\ttraining's binary_logloss: 0.591032\n",
      "[199]\ttraining's binary_logloss: 0.591031\n",
      "[200]\ttraining's binary_logloss: 0.591025\n",
      "[201]\ttraining's binary_logloss: 0.591027\n",
      "[202]\ttraining's binary_logloss: 0.591028\n",
      "[203]\ttraining's binary_logloss: 0.590988\n",
      "[204]\ttraining's binary_logloss: 0.590951\n",
      "[205]\ttraining's binary_logloss: 0.590922\n",
      "[206]\ttraining's binary_logloss: 0.590927\n",
      "[207]\ttraining's binary_logloss: 0.590955\n",
      "[208]\ttraining's binary_logloss: 0.590953\n",
      "[209]\ttraining's binary_logloss: 0.590965\n",
      "[210]\ttraining's binary_logloss: 0.590987\n",
      "[211]\ttraining's binary_logloss: 0.590988\n",
      "[212]\ttraining's binary_logloss: 0.590993\n",
      "[213]\ttraining's binary_logloss: 0.590983\n",
      "[214]\ttraining's binary_logloss: 0.590981\n",
      "[215]\ttraining's binary_logloss: 0.590986\n",
      "[216]\ttraining's binary_logloss: 0.590966\n",
      "[217]\ttraining's binary_logloss: 0.590933\n",
      "[218]\ttraining's binary_logloss: 0.590924\n",
      "[219]\ttraining's binary_logloss: 0.590905\n",
      "[220]\ttraining's binary_logloss: 0.590895\n",
      "[221]\ttraining's binary_logloss: 0.590877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[222]\ttraining's binary_logloss: 0.590839\n",
      "[223]\ttraining's binary_logloss: 0.590822\n",
      "[224]\ttraining's binary_logloss: 0.590791\n",
      "[225]\ttraining's binary_logloss: 0.590767\n",
      "[226]\ttraining's binary_logloss: 0.590738\n",
      "[227]\ttraining's binary_logloss: 0.590694\n",
      "[228]\ttraining's binary_logloss: 0.590667\n",
      "[229]\ttraining's binary_logloss: 0.590642\n",
      "[230]\ttraining's binary_logloss: 0.590622\n",
      "[231]\ttraining's binary_logloss: 0.590615\n",
      "[232]\ttraining's binary_logloss: 0.590625\n",
      "[233]\ttraining's binary_logloss: 0.590628\n",
      "[234]\ttraining's binary_logloss: 0.590615\n",
      "[235]\ttraining's binary_logloss: 0.590626\n",
      "[236]\ttraining's binary_logloss: 0.590592\n",
      "[237]\ttraining's binary_logloss: 0.590551\n",
      "[238]\ttraining's binary_logloss: 0.590522\n",
      "[239]\ttraining's binary_logloss: 0.590491\n",
      "[240]\ttraining's binary_logloss: 0.590457\n",
      "[241]\ttraining's binary_logloss: 0.590424\n",
      "[242]\ttraining's binary_logloss: 0.590385\n",
      "[243]\ttraining's binary_logloss: 0.590326\n",
      "[244]\ttraining's binary_logloss: 0.590279\n",
      "[245]\ttraining's binary_logloss: 0.590241\n",
      "[246]\ttraining's binary_logloss: 0.590191\n",
      "[247]\ttraining's binary_logloss: 0.590134\n",
      "[248]\ttraining's binary_logloss: 0.590069\n",
      "[249]\ttraining's binary_logloss: 0.590012\n",
      "[250]\ttraining's binary_logloss: 0.589953\n",
      "[251]\ttraining's binary_logloss: 0.589943\n",
      "[252]\ttraining's binary_logloss: 0.589916\n",
      "[253]\ttraining's binary_logloss: 0.589906\n",
      "[254]\ttraining's binary_logloss: 0.58989\n",
      "[255]\ttraining's binary_logloss: 0.589866\n",
      "[256]\ttraining's binary_logloss: 0.58983\n",
      "[257]\ttraining's binary_logloss: 0.589805\n",
      "[258]\ttraining's binary_logloss: 0.589776\n",
      "[259]\ttraining's binary_logloss: 0.589747\n",
      "[260]\ttraining's binary_logloss: 0.589722\n",
      "[261]\ttraining's binary_logloss: 0.589666\n",
      "[262]\ttraining's binary_logloss: 0.589599\n",
      "[263]\ttraining's binary_logloss: 0.589543\n",
      "[264]\ttraining's binary_logloss: 0.589488\n",
      "[265]\ttraining's binary_logloss: 0.589435\n",
      "[266]\ttraining's binary_logloss: 0.589408\n",
      "[267]\ttraining's binary_logloss: 0.589381\n",
      "[268]\ttraining's binary_logloss: 0.589369\n",
      "[269]\ttraining's binary_logloss: 0.589335\n",
      "[270]\ttraining's binary_logloss: 0.589316\n",
      "[271]\ttraining's binary_logloss: 0.589269\n",
      "[272]\ttraining's binary_logloss: 0.589229\n",
      "[273]\ttraining's binary_logloss: 0.589184\n",
      "[274]\ttraining's binary_logloss: 0.589141\n",
      "[275]\ttraining's binary_logloss: 0.589097\n",
      "[276]\ttraining's binary_logloss: 0.589032\n",
      "[277]\ttraining's binary_logloss: 0.589002\n",
      "[278]\ttraining's binary_logloss: 0.588942\n",
      "[279]\ttraining's binary_logloss: 0.588885\n",
      "[280]\ttraining's binary_logloss: 0.588849\n",
      "[281]\ttraining's binary_logloss: 0.588802\n",
      "[282]\ttraining's binary_logloss: 0.588758\n",
      "[283]\ttraining's binary_logloss: 0.588714\n",
      "[284]\ttraining's binary_logloss: 0.588673\n",
      "[285]\ttraining's binary_logloss: 0.588626\n",
      "[286]\ttraining's binary_logloss: 0.588572\n",
      "[287]\ttraining's binary_logloss: 0.588522\n",
      "[288]\ttraining's binary_logloss: 0.588471\n",
      "[289]\ttraining's binary_logloss: 0.588411\n",
      "[290]\ttraining's binary_logloss: 0.588357\n",
      "[291]\ttraining's binary_logloss: 0.588284\n",
      "[292]\ttraining's binary_logloss: 0.588213\n",
      "[293]\ttraining's binary_logloss: 0.588144\n",
      "[294]\ttraining's binary_logloss: 0.588083\n",
      "[295]\ttraining's binary_logloss: 0.58801\n",
      "[296]\ttraining's binary_logloss: 0.587972\n",
      "[297]\ttraining's binary_logloss: 0.587926\n",
      "[298]\ttraining's binary_logloss: 0.587862\n",
      "[299]\ttraining's binary_logloss: 0.587823\n",
      "[300]\ttraining's binary_logloss: 0.587753\n",
      "[301]\ttraining's binary_logloss: 0.587678\n",
      "[302]\ttraining's binary_logloss: 0.587604\n",
      "[303]\ttraining's binary_logloss: 0.58753\n",
      "[304]\ttraining's binary_logloss: 0.587458\n",
      "[305]\ttraining's binary_logloss: 0.587394\n",
      "[306]\ttraining's binary_logloss: 0.587334\n",
      "[307]\ttraining's binary_logloss: 0.58728\n",
      "[308]\ttraining's binary_logloss: 0.587228\n",
      "[309]\ttraining's binary_logloss: 0.587179\n",
      "[310]\ttraining's binary_logloss: 0.587101\n",
      "[311]\ttraining's binary_logloss: 0.58704\n",
      "[312]\ttraining's binary_logloss: 0.586986\n",
      "[313]\ttraining's binary_logloss: 0.586935\n",
      "[314]\ttraining's binary_logloss: 0.586879\n",
      "[315]\ttraining's binary_logloss: 0.586824\n",
      "[316]\ttraining's binary_logloss: 0.586746\n",
      "[317]\ttraining's binary_logloss: 0.586667\n",
      "[318]\ttraining's binary_logloss: 0.586589\n",
      "[319]\ttraining's binary_logloss: 0.586514\n",
      "[320]\ttraining's binary_logloss: 0.586439\n",
      "[321]\ttraining's binary_logloss: 0.586379\n",
      "[322]\ttraining's binary_logloss: 0.586321\n",
      "[323]\ttraining's binary_logloss: 0.58626\n",
      "[324]\ttraining's binary_logloss: 0.5862\n",
      "[325]\ttraining's binary_logloss: 0.58615\n",
      "[326]\ttraining's binary_logloss: 0.586103\n",
      "[327]\ttraining's binary_logloss: 0.586053\n",
      "[328]\ttraining's binary_logloss: 0.586004\n",
      "[329]\ttraining's binary_logloss: 0.585958\n",
      "[330]\ttraining's binary_logloss: 0.585911\n",
      "[331]\ttraining's binary_logloss: 0.585865\n",
      "[332]\ttraining's binary_logloss: 0.585808\n",
      "[333]\ttraining's binary_logloss: 0.585745\n",
      "[334]\ttraining's binary_logloss: 0.585691\n",
      "[335]\ttraining's binary_logloss: 0.585617\n",
      "[336]\ttraining's binary_logloss: 0.585534\n",
      "[337]\ttraining's binary_logloss: 0.585453\n",
      "[338]\ttraining's binary_logloss: 0.585373\n",
      "[339]\ttraining's binary_logloss: 0.585296\n",
      "[340]\ttraining's binary_logloss: 0.585223\n",
      "[341]\ttraining's binary_logloss: 0.585171\n",
      "[342]\ttraining's binary_logloss: 0.585124\n",
      "[343]\ttraining's binary_logloss: 0.585081\n",
      "[344]\ttraining's binary_logloss: 0.585036\n",
      "[345]\ttraining's binary_logloss: 0.584993\n",
      "[346]\ttraining's binary_logloss: 0.584963\n",
      "[347]\ttraining's binary_logloss: 0.584936\n",
      "[348]\ttraining's binary_logloss: 0.584906\n",
      "[349]\ttraining's binary_logloss: 0.584882\n",
      "[350]\ttraining's binary_logloss: 0.584859\n",
      "[351]\ttraining's binary_logloss: 0.584778\n",
      "[352]\ttraining's binary_logloss: 0.5847\n",
      "[353]\ttraining's binary_logloss: 0.584624\n",
      "[354]\ttraining's binary_logloss: 0.584555\n",
      "[355]\ttraining's binary_logloss: 0.584482\n",
      "[356]\ttraining's binary_logloss: 0.584423\n",
      "[357]\ttraining's binary_logloss: 0.584367\n",
      "[358]\ttraining's binary_logloss: 0.584295\n",
      "[359]\ttraining's binary_logloss: 0.584229\n",
      "[360]\ttraining's binary_logloss: 0.58417\n",
      "[361]\ttraining's binary_logloss: 0.584081\n",
      "[362]\ttraining's binary_logloss: 0.583997\n",
      "[363]\ttraining's binary_logloss: 0.583914\n",
      "[364]\ttraining's binary_logloss: 0.583845\n",
      "[365]\ttraining's binary_logloss: 0.583775\n",
      "[366]\ttraining's binary_logloss: 0.583743\n",
      "[367]\ttraining's binary_logloss: 0.583714\n",
      "[368]\ttraining's binary_logloss: 0.583679\n",
      "[369]\ttraining's binary_logloss: 0.58364\n",
      "[370]\ttraining's binary_logloss: 0.5836\n",
      "[371]\ttraining's binary_logloss: 0.583535\n",
      "[372]\ttraining's binary_logloss: 0.583471\n",
      "[373]\ttraining's binary_logloss: 0.583406\n",
      "[374]\ttraining's binary_logloss: 0.583334\n",
      "[375]\ttraining's binary_logloss: 0.583271\n",
      "[376]\ttraining's binary_logloss: 0.583195\n",
      "[377]\ttraining's binary_logloss: 0.583125\n",
      "[378]\ttraining's binary_logloss: 0.58306\n",
      "[379]\ttraining's binary_logloss: 0.582987\n",
      "[380]\ttraining's binary_logloss: 0.582904\n",
      "[381]\ttraining's binary_logloss: 0.582834\n",
      "[382]\ttraining's binary_logloss: 0.582765\n",
      "[383]\ttraining's binary_logloss: 0.582706\n",
      "[384]\ttraining's binary_logloss: 0.582659\n",
      "[385]\ttraining's binary_logloss: 0.582595\n",
      "[386]\ttraining's binary_logloss: 0.582515\n",
      "[387]\ttraining's binary_logloss: 0.582446\n",
      "[388]\ttraining's binary_logloss: 0.582369\n",
      "[389]\ttraining's binary_logloss: 0.582296\n",
      "[390]\ttraining's binary_logloss: 0.582223\n",
      "[391]\ttraining's binary_logloss: 0.582139\n",
      "[392]\ttraining's binary_logloss: 0.582056\n",
      "[393]\ttraining's binary_logloss: 0.581976\n",
      "[394]\ttraining's binary_logloss: 0.5819\n",
      "[395]\ttraining's binary_logloss: 0.581801\n",
      "[396]\ttraining's binary_logloss: 0.581742\n",
      "[397]\ttraining's binary_logloss: 0.581683\n",
      "[398]\ttraining's binary_logloss: 0.581628\n",
      "[399]\ttraining's binary_logloss: 0.581565\n",
      "[400]\ttraining's binary_logloss: 0.581508\n",
      "[401]\ttraining's binary_logloss: 0.581428\n",
      "[402]\ttraining's binary_logloss: 0.581349\n",
      "[403]\ttraining's binary_logloss: 0.581276\n",
      "[404]\ttraining's binary_logloss: 0.5812\n",
      "[405]\ttraining's binary_logloss: 0.581133\n",
      "[406]\ttraining's binary_logloss: 0.581067\n",
      "[407]\ttraining's binary_logloss: 0.580991\n",
      "[408]\ttraining's binary_logloss: 0.58094\n",
      "[409]\ttraining's binary_logloss: 0.58086\n",
      "[410]\ttraining's binary_logloss: 0.58079\n",
      "[411]\ttraining's binary_logloss: 0.580709\n",
      "[412]\ttraining's binary_logloss: 0.580629\n",
      "[413]\ttraining's binary_logloss: 0.580552\n",
      "[414]\ttraining's binary_logloss: 0.580476\n",
      "[415]\ttraining's binary_logloss: 0.580398\n",
      "[416]\ttraining's binary_logloss: 0.580356\n",
      "[417]\ttraining's binary_logloss: 0.580288\n",
      "[418]\ttraining's binary_logloss: 0.580222\n",
      "[419]\ttraining's binary_logloss: 0.580168\n",
      "[420]\ttraining's binary_logloss: 0.580104\n",
      "[421]\ttraining's binary_logloss: 0.580071\n",
      "[422]\ttraining's binary_logloss: 0.580042\n",
      "[423]\ttraining's binary_logloss: 0.580006\n",
      "[424]\ttraining's binary_logloss: 0.579981\n",
      "[425]\ttraining's binary_logloss: 0.579963\n",
      "[426]\ttraining's binary_logloss: 0.579888\n",
      "[427]\ttraining's binary_logloss: 0.579821\n",
      "[428]\ttraining's binary_logloss: 0.579752\n",
      "[429]\ttraining's binary_logloss: 0.579685\n",
      "[430]\ttraining's binary_logloss: 0.57962\n",
      "[431]\ttraining's binary_logloss: 0.579547\n",
      "[432]\ttraining's binary_logloss: 0.579475\n",
      "[433]\ttraining's binary_logloss: 0.57941\n",
      "[434]\ttraining's binary_logloss: 0.579351\n",
      "[435]\ttraining's binary_logloss: 0.579278\n",
      "[436]\ttraining's binary_logloss: 0.57923\n",
      "[437]\ttraining's binary_logloss: 0.579172\n",
      "[438]\ttraining's binary_logloss: 0.579113\n",
      "[439]\ttraining's binary_logloss: 0.579049\n",
      "[440]\ttraining's binary_logloss: 0.578997\n",
      "[441]\ttraining's binary_logloss: 0.578924\n",
      "[442]\ttraining's binary_logloss: 0.578838\n",
      "[443]\ttraining's binary_logloss: 0.578755\n",
      "[444]\ttraining's binary_logloss: 0.578691\n",
      "[445]\ttraining's binary_logloss: 0.578611\n",
      "[446]\ttraining's binary_logloss: 0.578544\n",
      "[447]\ttraining's binary_logloss: 0.578503\n",
      "[448]\ttraining's binary_logloss: 0.578426\n",
      "[449]\ttraining's binary_logloss: 0.578377\n",
      "[450]\ttraining's binary_logloss: 0.578313\n",
      "[451]\ttraining's binary_logloss: 0.578284\n",
      "[452]\ttraining's binary_logloss: 0.578265\n",
      "[453]\ttraining's binary_logloss: 0.578241\n",
      "[454]\ttraining's binary_logloss: 0.578218\n",
      "[455]\ttraining's binary_logloss: 0.578198\n",
      "[456]\ttraining's binary_logloss: 0.578112\n",
      "[457]\ttraining's binary_logloss: 0.578027\n",
      "[458]\ttraining's binary_logloss: 0.577949\n",
      "[459]\ttraining's binary_logloss: 0.577868\n",
      "[460]\ttraining's binary_logloss: 0.577793\n",
      "[461]\ttraining's binary_logloss: 0.577744\n",
      "[462]\ttraining's binary_logloss: 0.577689\n",
      "[463]\ttraining's binary_logloss: 0.577632\n",
      "[464]\ttraining's binary_logloss: 0.577586\n",
      "[465]\ttraining's binary_logloss: 0.57753\n",
      "[466]\ttraining's binary_logloss: 0.577443\n",
      "[467]\ttraining's binary_logloss: 0.577355\n",
      "[468]\ttraining's binary_logloss: 0.577268\n",
      "[469]\ttraining's binary_logloss: 0.577188\n",
      "[470]\ttraining's binary_logloss: 0.577108\n",
      "[471]\ttraining's binary_logloss: 0.577047\n",
      "[472]\ttraining's binary_logloss: 0.576998\n",
      "[473]\ttraining's binary_logloss: 0.576943\n",
      "[474]\ttraining's binary_logloss: 0.576892\n",
      "[475]\ttraining's binary_logloss: 0.576842\n",
      "[476]\ttraining's binary_logloss: 0.57675\n",
      "[477]\ttraining's binary_logloss: 0.576661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[478]\ttraining's binary_logloss: 0.576571\n",
      "[479]\ttraining's binary_logloss: 0.576481\n",
      "[480]\ttraining's binary_logloss: 0.576396\n",
      "[481]\ttraining's binary_logloss: 0.576309\n",
      "[482]\ttraining's binary_logloss: 0.576227\n",
      "[483]\ttraining's binary_logloss: 0.576153\n",
      "[484]\ttraining's binary_logloss: 0.576073\n",
      "[485]\ttraining's binary_logloss: 0.576005\n",
      "[486]\ttraining's binary_logloss: 0.575924\n",
      "[487]\ttraining's binary_logloss: 0.57588\n",
      "[488]\ttraining's binary_logloss: 0.575834\n",
      "[489]\ttraining's binary_logloss: 0.575764\n",
      "[490]\ttraining's binary_logloss: 0.575685\n",
      "[491]\ttraining's binary_logloss: 0.575579\n",
      "[492]\ttraining's binary_logloss: 0.575476\n",
      "[493]\ttraining's binary_logloss: 0.575373\n",
      "[494]\ttraining's binary_logloss: 0.575292\n",
      "[495]\ttraining's binary_logloss: 0.575215\n",
      "[496]\ttraining's binary_logloss: 0.575082\n",
      "[497]\ttraining's binary_logloss: 0.574939\n",
      "[498]\ttraining's binary_logloss: 0.574824\n",
      "[499]\ttraining's binary_logloss: 0.574709\n",
      "[500]\ttraining's binary_logloss: 0.574583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613857\n",
      "[2]\ttraining's binary_logloss: 0.612957\n",
      "[3]\ttraining's binary_logloss: 0.611942\n",
      "[4]\ttraining's binary_logloss: 0.611007\n",
      "[5]\ttraining's binary_logloss: 0.610226\n",
      "[6]\ttraining's binary_logloss: 0.609359\n",
      "[7]\ttraining's binary_logloss: 0.608479\n",
      "[8]\ttraining's binary_logloss: 0.607679\n",
      "[9]\ttraining's binary_logloss: 0.606914\n",
      "[10]\ttraining's binary_logloss: 0.606182\n",
      "[11]\ttraining's binary_logloss: 0.605492\n",
      "[12]\ttraining's binary_logloss: 0.604789\n",
      "[13]\ttraining's binary_logloss: 0.604153\n",
      "[14]\ttraining's binary_logloss: 0.603487\n",
      "[15]\ttraining's binary_logloss: 0.602881\n",
      "[16]\ttraining's binary_logloss: 0.602229\n",
      "[17]\ttraining's binary_logloss: 0.601692\n",
      "[18]\ttraining's binary_logloss: 0.601184\n",
      "[19]\ttraining's binary_logloss: 0.600617\n",
      "[20]\ttraining's binary_logloss: 0.600072\n",
      "[21]\ttraining's binary_logloss: 0.599589\n",
      "[22]\ttraining's binary_logloss: 0.599124\n",
      "[23]\ttraining's binary_logloss: 0.598677\n",
      "[24]\ttraining's binary_logloss: 0.598242\n",
      "[25]\ttraining's binary_logloss: 0.597784\n",
      "[26]\ttraining's binary_logloss: 0.597306\n",
      "[27]\ttraining's binary_logloss: 0.596851\n",
      "[28]\ttraining's binary_logloss: 0.596419\n",
      "[29]\ttraining's binary_logloss: 0.596007\n",
      "[30]\ttraining's binary_logloss: 0.595615\n",
      "[31]\ttraining's binary_logloss: 0.595251\n",
      "[32]\ttraining's binary_logloss: 0.594999\n",
      "[33]\ttraining's binary_logloss: 0.594695\n",
      "[34]\ttraining's binary_logloss: 0.594453\n",
      "[35]\ttraining's binary_logloss: 0.594158\n",
      "[36]\ttraining's binary_logloss: 0.593821\n",
      "[37]\ttraining's binary_logloss: 0.593506\n",
      "[38]\ttraining's binary_logloss: 0.593325\n",
      "[39]\ttraining's binary_logloss: 0.593114\n",
      "[40]\ttraining's binary_logloss: 0.592836\n",
      "[41]\ttraining's binary_logloss: 0.592614\n",
      "[42]\ttraining's binary_logloss: 0.592413\n",
      "[43]\ttraining's binary_logloss: 0.592328\n",
      "[44]\ttraining's binary_logloss: 0.592141\n",
      "[45]\ttraining's binary_logloss: 0.591966\n",
      "[46]\ttraining's binary_logloss: 0.591706\n",
      "[47]\ttraining's binary_logloss: 0.59146\n",
      "[48]\ttraining's binary_logloss: 0.591227\n",
      "[49]\ttraining's binary_logloss: 0.591035\n",
      "[50]\ttraining's binary_logloss: 0.590835\n",
      "[51]\ttraining's binary_logloss: 0.590569\n",
      "[52]\ttraining's binary_logloss: 0.590331\n",
      "[53]\ttraining's binary_logloss: 0.590088\n",
      "[54]\ttraining's binary_logloss: 0.589933\n",
      "[55]\ttraining's binary_logloss: 0.589815\n",
      "[56]\ttraining's binary_logloss: 0.58967\n",
      "[57]\ttraining's binary_logloss: 0.589657\n",
      "[58]\ttraining's binary_logloss: 0.589514\n",
      "[59]\ttraining's binary_logloss: 0.589342\n",
      "[60]\ttraining's binary_logloss: 0.58922\n",
      "[61]\ttraining's binary_logloss: 0.589114\n",
      "[62]\ttraining's binary_logloss: 0.588985\n",
      "[63]\ttraining's binary_logloss: 0.588861\n",
      "[64]\ttraining's binary_logloss: 0.588747\n",
      "[65]\ttraining's binary_logloss: 0.588705\n",
      "[66]\ttraining's binary_logloss: 0.588583\n",
      "[67]\ttraining's binary_logloss: 0.58847\n",
      "[68]\ttraining's binary_logloss: 0.588427\n",
      "[69]\ttraining's binary_logloss: 0.588334\n",
      "[70]\ttraining's binary_logloss: 0.588267\n",
      "[71]\ttraining's binary_logloss: 0.588167\n",
      "[72]\ttraining's binary_logloss: 0.588077\n",
      "[73]\ttraining's binary_logloss: 0.587992\n",
      "[74]\ttraining's binary_logloss: 0.587917\n",
      "[75]\ttraining's binary_logloss: 0.587902\n",
      "[76]\ttraining's binary_logloss: 0.587838\n",
      "[77]\ttraining's binary_logloss: 0.587849\n",
      "[78]\ttraining's binary_logloss: 0.587879\n",
      "[79]\ttraining's binary_logloss: 0.587822\n",
      "[80]\ttraining's binary_logloss: 0.587842\n",
      "[81]\ttraining's binary_logloss: 0.587833\n",
      "[82]\ttraining's binary_logloss: 0.587847\n",
      "[83]\ttraining's binary_logloss: 0.587796\n",
      "[84]\ttraining's binary_logloss: 0.587801\n",
      "[85]\ttraining's binary_logloss: 0.587815\n",
      "[86]\ttraining's binary_logloss: 0.587822\n",
      "[87]\ttraining's binary_logloss: 0.587838\n",
      "[88]\ttraining's binary_logloss: 0.587827\n",
      "[89]\ttraining's binary_logloss: 0.587878\n",
      "[90]\ttraining's binary_logloss: 0.587901\n",
      "[91]\ttraining's binary_logloss: 0.587914\n",
      "[92]\ttraining's binary_logloss: 0.587866\n",
      "[93]\ttraining's binary_logloss: 0.587888\n",
      "[94]\ttraining's binary_logloss: 0.587912\n",
      "[95]\ttraining's binary_logloss: 0.587934\n",
      "[96]\ttraining's binary_logloss: 0.587977\n",
      "[97]\ttraining's binary_logloss: 0.587956\n",
      "[98]\ttraining's binary_logloss: 0.588005\n",
      "[99]\ttraining's binary_logloss: 0.588057\n",
      "[100]\ttraining's binary_logloss: 0.588112\n",
      "[101]\ttraining's binary_logloss: 0.588101\n",
      "[102]\ttraining's binary_logloss: 0.588093\n",
      "[103]\ttraining's binary_logloss: 0.58809\n",
      "[104]\ttraining's binary_logloss: 0.588092\n",
      "[105]\ttraining's binary_logloss: 0.588117\n",
      "[106]\ttraining's binary_logloss: 0.588121\n",
      "[107]\ttraining's binary_logloss: 0.58813\n",
      "[108]\ttraining's binary_logloss: 0.588181\n",
      "[109]\ttraining's binary_logloss: 0.588244\n",
      "[110]\ttraining's binary_logloss: 0.588327\n",
      "[111]\ttraining's binary_logloss: 0.588347\n",
      "[112]\ttraining's binary_logloss: 0.588384\n",
      "[113]\ttraining's binary_logloss: 0.588413\n",
      "[114]\ttraining's binary_logloss: 0.58846\n",
      "[115]\ttraining's binary_logloss: 0.588494\n",
      "[116]\ttraining's binary_logloss: 0.588515\n",
      "[117]\ttraining's binary_logloss: 0.588532\n",
      "[118]\ttraining's binary_logloss: 0.588564\n",
      "[119]\ttraining's binary_logloss: 0.588628\n",
      "[120]\ttraining's binary_logloss: 0.588652\n",
      "[121]\ttraining's binary_logloss: 0.588674\n",
      "[122]\ttraining's binary_logloss: 0.588748\n",
      "[123]\ttraining's binary_logloss: 0.5888\n",
      "[124]\ttraining's binary_logloss: 0.588828\n",
      "[125]\ttraining's binary_logloss: 0.588872\n",
      "[126]\ttraining's binary_logloss: 0.588882\n",
      "[127]\ttraining's binary_logloss: 0.588897\n",
      "[128]\ttraining's binary_logloss: 0.588905\n",
      "[129]\ttraining's binary_logloss: 0.588929\n",
      "[130]\ttraining's binary_logloss: 0.588934\n",
      "[131]\ttraining's binary_logloss: 0.589003\n",
      "[132]\ttraining's binary_logloss: 0.589044\n",
      "[133]\ttraining's binary_logloss: 0.589116\n",
      "[134]\ttraining's binary_logloss: 0.589157\n",
      "[135]\ttraining's binary_logloss: 0.589145\n",
      "[136]\ttraining's binary_logloss: 0.589188\n",
      "[137]\ttraining's binary_logloss: 0.589224\n",
      "[138]\ttraining's binary_logloss: 0.58927\n",
      "[139]\ttraining's binary_logloss: 0.589282\n",
      "[140]\ttraining's binary_logloss: 0.589288\n",
      "[141]\ttraining's binary_logloss: 0.589337\n",
      "[142]\ttraining's binary_logloss: 0.589359\n",
      "[143]\ttraining's binary_logloss: 0.589359\n",
      "[144]\ttraining's binary_logloss: 0.589386\n",
      "[145]\ttraining's binary_logloss: 0.589413\n",
      "[146]\ttraining's binary_logloss: 0.589409\n",
      "[147]\ttraining's binary_logloss: 0.589441\n",
      "[148]\ttraining's binary_logloss: 0.589475\n",
      "[149]\ttraining's binary_logloss: 0.589527\n",
      "[150]\ttraining's binary_logloss: 0.589576\n",
      "[151]\ttraining's binary_logloss: 0.589646\n",
      "[152]\ttraining's binary_logloss: 0.589709\n",
      "[153]\ttraining's binary_logloss: 0.589714\n",
      "[154]\ttraining's binary_logloss: 0.589753\n",
      "[155]\ttraining's binary_logloss: 0.589839\n",
      "[156]\ttraining's binary_logloss: 0.589866\n",
      "[157]\ttraining's binary_logloss: 0.589891\n",
      "[158]\ttraining's binary_logloss: 0.589939\n",
      "[159]\ttraining's binary_logloss: 0.589931\n",
      "[160]\ttraining's binary_logloss: 0.589957\n",
      "[161]\ttraining's binary_logloss: 0.589977\n",
      "[162]\ttraining's binary_logloss: 0.589979\n",
      "[163]\ttraining's binary_logloss: 0.589992\n",
      "[164]\ttraining's binary_logloss: 0.590047\n",
      "[165]\ttraining's binary_logloss: 0.590063\n",
      "[166]\ttraining's binary_logloss: 0.590054\n",
      "[167]\ttraining's binary_logloss: 0.590057\n",
      "[168]\ttraining's binary_logloss: 0.590063\n",
      "[169]\ttraining's binary_logloss: 0.59006\n",
      "[170]\ttraining's binary_logloss: 0.590089\n",
      "[171]\ttraining's binary_logloss: 0.590083\n",
      "[172]\ttraining's binary_logloss: 0.59008\n",
      "[173]\ttraining's binary_logloss: 0.590068\n",
      "[174]\ttraining's binary_logloss: 0.590059\n",
      "[175]\ttraining's binary_logloss: 0.590052\n",
      "[176]\ttraining's binary_logloss: 0.590089\n",
      "[177]\ttraining's binary_logloss: 0.590109\n",
      "[178]\ttraining's binary_logloss: 0.590142\n",
      "[179]\ttraining's binary_logloss: 0.590192\n",
      "[180]\ttraining's binary_logloss: 0.590214\n",
      "[181]\ttraining's binary_logloss: 0.590252\n",
      "[182]\ttraining's binary_logloss: 0.5903\n",
      "[183]\ttraining's binary_logloss: 0.590334\n",
      "[184]\ttraining's binary_logloss: 0.590373\n",
      "[185]\ttraining's binary_logloss: 0.590416\n",
      "[186]\ttraining's binary_logloss: 0.590493\n",
      "[187]\ttraining's binary_logloss: 0.590558\n",
      "[188]\ttraining's binary_logloss: 0.590615\n",
      "[189]\ttraining's binary_logloss: 0.59068\n",
      "[190]\ttraining's binary_logloss: 0.590741\n",
      "[191]\ttraining's binary_logloss: 0.590782\n",
      "[192]\ttraining's binary_logloss: 0.590811\n",
      "[193]\ttraining's binary_logloss: 0.590853\n",
      "[194]\ttraining's binary_logloss: 0.590884\n",
      "[195]\ttraining's binary_logloss: 0.590889\n",
      "[196]\ttraining's binary_logloss: 0.590854\n",
      "[197]\ttraining's binary_logloss: 0.590823\n",
      "[198]\ttraining's binary_logloss: 0.590803\n",
      "[199]\ttraining's binary_logloss: 0.590792\n",
      "[200]\ttraining's binary_logloss: 0.590761\n",
      "[201]\ttraining's binary_logloss: 0.59074\n",
      "[202]\ttraining's binary_logloss: 0.590731\n",
      "[203]\ttraining's binary_logloss: 0.590716\n",
      "[204]\ttraining's binary_logloss: 0.590689\n",
      "[205]\ttraining's binary_logloss: 0.590675\n",
      "[206]\ttraining's binary_logloss: 0.590691\n",
      "[207]\ttraining's binary_logloss: 0.590733\n",
      "[208]\ttraining's binary_logloss: 0.590757\n",
      "[209]\ttraining's binary_logloss: 0.590768\n",
      "[210]\ttraining's binary_logloss: 0.590792\n",
      "[211]\ttraining's binary_logloss: 0.59079\n",
      "[212]\ttraining's binary_logloss: 0.59078\n",
      "[213]\ttraining's binary_logloss: 0.590775\n",
      "[214]\ttraining's binary_logloss: 0.590764\n",
      "[215]\ttraining's binary_logloss: 0.590756\n",
      "[216]\ttraining's binary_logloss: 0.59073\n",
      "[217]\ttraining's binary_logloss: 0.590706\n",
      "[218]\ttraining's binary_logloss: 0.590692\n",
      "[219]\ttraining's binary_logloss: 0.59066\n",
      "[220]\ttraining's binary_logloss: 0.590625\n",
      "[221]\ttraining's binary_logloss: 0.590644\n",
      "[222]\ttraining's binary_logloss: 0.590666\n",
      "[223]\ttraining's binary_logloss: 0.590683\n",
      "[224]\ttraining's binary_logloss: 0.590705\n",
      "[225]\ttraining's binary_logloss: 0.590727\n",
      "[226]\ttraining's binary_logloss: 0.590709\n",
      "[227]\ttraining's binary_logloss: 0.590704\n",
      "[228]\ttraining's binary_logloss: 0.590699\n",
      "[229]\ttraining's binary_logloss: 0.590696\n",
      "[230]\ttraining's binary_logloss: 0.590695\n",
      "[231]\ttraining's binary_logloss: 0.590694\n",
      "[232]\ttraining's binary_logloss: 0.590652\n",
      "[233]\ttraining's binary_logloss: 0.590622\n",
      "[234]\ttraining's binary_logloss: 0.590585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[235]\ttraining's binary_logloss: 0.590544\n",
      "[236]\ttraining's binary_logloss: 0.590551\n",
      "[237]\ttraining's binary_logloss: 0.590545\n",
      "[238]\ttraining's binary_logloss: 0.59054\n",
      "[239]\ttraining's binary_logloss: 0.590536\n",
      "[240]\ttraining's binary_logloss: 0.590535\n",
      "[241]\ttraining's binary_logloss: 0.590531\n",
      "[242]\ttraining's binary_logloss: 0.590538\n",
      "[243]\ttraining's binary_logloss: 0.590543\n",
      "[244]\ttraining's binary_logloss: 0.590539\n",
      "[245]\ttraining's binary_logloss: 0.590537\n",
      "[246]\ttraining's binary_logloss: 0.590498\n",
      "[247]\ttraining's binary_logloss: 0.590461\n",
      "[248]\ttraining's binary_logloss: 0.59042\n",
      "[249]\ttraining's binary_logloss: 0.590379\n",
      "[250]\ttraining's binary_logloss: 0.590311\n",
      "[251]\ttraining's binary_logloss: 0.59031\n",
      "[252]\ttraining's binary_logloss: 0.59031\n",
      "[253]\ttraining's binary_logloss: 0.59031\n",
      "[254]\ttraining's binary_logloss: 0.590311\n",
      "[255]\ttraining's binary_logloss: 0.590311\n",
      "[256]\ttraining's binary_logloss: 0.590274\n",
      "[257]\ttraining's binary_logloss: 0.590244\n",
      "[258]\ttraining's binary_logloss: 0.590209\n",
      "[259]\ttraining's binary_logloss: 0.590183\n",
      "[260]\ttraining's binary_logloss: 0.590146\n",
      "[261]\ttraining's binary_logloss: 0.590093\n",
      "[262]\ttraining's binary_logloss: 0.590036\n",
      "[263]\ttraining's binary_logloss: 0.589973\n",
      "[264]\ttraining's binary_logloss: 0.589907\n",
      "[265]\ttraining's binary_logloss: 0.589855\n",
      "[266]\ttraining's binary_logloss: 0.589837\n",
      "[267]\ttraining's binary_logloss: 0.589815\n",
      "[268]\ttraining's binary_logloss: 0.5898\n",
      "[269]\ttraining's binary_logloss: 0.589794\n",
      "[270]\ttraining's binary_logloss: 0.589775\n",
      "[271]\ttraining's binary_logloss: 0.589756\n",
      "[272]\ttraining's binary_logloss: 0.589739\n",
      "[273]\ttraining's binary_logloss: 0.589731\n",
      "[274]\ttraining's binary_logloss: 0.589716\n",
      "[275]\ttraining's binary_logloss: 0.589693\n",
      "[276]\ttraining's binary_logloss: 0.589646\n",
      "[277]\ttraining's binary_logloss: 0.589605\n",
      "[278]\ttraining's binary_logloss: 0.58956\n",
      "[279]\ttraining's binary_logloss: 0.589518\n",
      "[280]\ttraining's binary_logloss: 0.589478\n",
      "[281]\ttraining's binary_logloss: 0.589461\n",
      "[282]\ttraining's binary_logloss: 0.589429\n",
      "[283]\ttraining's binary_logloss: 0.589414\n",
      "[284]\ttraining's binary_logloss: 0.589397\n",
      "[285]\ttraining's binary_logloss: 0.589382\n",
      "[286]\ttraining's binary_logloss: 0.589283\n",
      "[287]\ttraining's binary_logloss: 0.589183\n",
      "[288]\ttraining's binary_logloss: 0.589086\n",
      "[289]\ttraining's binary_logloss: 0.588979\n",
      "[290]\ttraining's binary_logloss: 0.58888\n",
      "[291]\ttraining's binary_logloss: 0.588849\n",
      "[292]\ttraining's binary_logloss: 0.588816\n",
      "[293]\ttraining's binary_logloss: 0.58878\n",
      "[294]\ttraining's binary_logloss: 0.588747\n",
      "[295]\ttraining's binary_logloss: 0.588724\n",
      "[296]\ttraining's binary_logloss: 0.588644\n",
      "[297]\ttraining's binary_logloss: 0.588574\n",
      "[298]\ttraining's binary_logloss: 0.588499\n",
      "[299]\ttraining's binary_logloss: 0.588445\n",
      "[300]\ttraining's binary_logloss: 0.588385\n",
      "[301]\ttraining's binary_logloss: 0.588302\n",
      "[302]\ttraining's binary_logloss: 0.588233\n",
      "[303]\ttraining's binary_logloss: 0.588154\n",
      "[304]\ttraining's binary_logloss: 0.588084\n",
      "[305]\ttraining's binary_logloss: 0.588013\n",
      "[306]\ttraining's binary_logloss: 0.587904\n",
      "[307]\ttraining's binary_logloss: 0.587796\n",
      "[308]\ttraining's binary_logloss: 0.587722\n",
      "[309]\ttraining's binary_logloss: 0.587615\n",
      "[310]\ttraining's binary_logloss: 0.587516\n",
      "[311]\ttraining's binary_logloss: 0.587451\n",
      "[312]\ttraining's binary_logloss: 0.587401\n",
      "[313]\ttraining's binary_logloss: 0.587346\n",
      "[314]\ttraining's binary_logloss: 0.587279\n",
      "[315]\ttraining's binary_logloss: 0.587233\n",
      "[316]\ttraining's binary_logloss: 0.587178\n",
      "[317]\ttraining's binary_logloss: 0.587132\n",
      "[318]\ttraining's binary_logloss: 0.587088\n",
      "[319]\ttraining's binary_logloss: 0.587017\n",
      "[320]\ttraining's binary_logloss: 0.586958\n",
      "[321]\ttraining's binary_logloss: 0.58693\n",
      "[322]\ttraining's binary_logloss: 0.586901\n",
      "[323]\ttraining's binary_logloss: 0.586871\n",
      "[324]\ttraining's binary_logloss: 0.586843\n",
      "[325]\ttraining's binary_logloss: 0.586826\n",
      "[326]\ttraining's binary_logloss: 0.586789\n",
      "[327]\ttraining's binary_logloss: 0.586744\n",
      "[328]\ttraining's binary_logloss: 0.586703\n",
      "[329]\ttraining's binary_logloss: 0.586671\n",
      "[330]\ttraining's binary_logloss: 0.586633\n",
      "[331]\ttraining's binary_logloss: 0.586545\n",
      "[332]\ttraining's binary_logloss: 0.586462\n",
      "[333]\ttraining's binary_logloss: 0.586399\n",
      "[334]\ttraining's binary_logloss: 0.586337\n",
      "[335]\ttraining's binary_logloss: 0.586274\n",
      "[336]\ttraining's binary_logloss: 0.586213\n",
      "[337]\ttraining's binary_logloss: 0.586154\n",
      "[338]\ttraining's binary_logloss: 0.586095\n",
      "[339]\ttraining's binary_logloss: 0.586038\n",
      "[340]\ttraining's binary_logloss: 0.585955\n",
      "[341]\ttraining's binary_logloss: 0.585891\n",
      "[342]\ttraining's binary_logloss: 0.585806\n",
      "[343]\ttraining's binary_logloss: 0.585745\n",
      "[344]\ttraining's binary_logloss: 0.585674\n",
      "[345]\ttraining's binary_logloss: 0.585586\n",
      "[346]\ttraining's binary_logloss: 0.585542\n",
      "[347]\ttraining's binary_logloss: 0.585499\n",
      "[348]\ttraining's binary_logloss: 0.58547\n",
      "[349]\ttraining's binary_logloss: 0.585438\n",
      "[350]\ttraining's binary_logloss: 0.58538\n",
      "[351]\ttraining's binary_logloss: 0.585308\n",
      "[352]\ttraining's binary_logloss: 0.58524\n",
      "[353]\ttraining's binary_logloss: 0.585172\n",
      "[354]\ttraining's binary_logloss: 0.58509\n",
      "[355]\ttraining's binary_logloss: 0.585003\n",
      "[356]\ttraining's binary_logloss: 0.584952\n",
      "[357]\ttraining's binary_logloss: 0.584901\n",
      "[358]\ttraining's binary_logloss: 0.584853\n",
      "[359]\ttraining's binary_logloss: 0.584784\n",
      "[360]\ttraining's binary_logloss: 0.584724\n",
      "[361]\ttraining's binary_logloss: 0.584673\n",
      "[362]\ttraining's binary_logloss: 0.584608\n",
      "[363]\ttraining's binary_logloss: 0.584557\n",
      "[364]\ttraining's binary_logloss: 0.584515\n",
      "[365]\ttraining's binary_logloss: 0.584464\n",
      "[366]\ttraining's binary_logloss: 0.584436\n",
      "[367]\ttraining's binary_logloss: 0.58441\n",
      "[368]\ttraining's binary_logloss: 0.584385\n",
      "[369]\ttraining's binary_logloss: 0.584365\n",
      "[370]\ttraining's binary_logloss: 0.584339\n",
      "[371]\ttraining's binary_logloss: 0.584269\n",
      "[372]\ttraining's binary_logloss: 0.584192\n",
      "[373]\ttraining's binary_logloss: 0.584132\n",
      "[374]\ttraining's binary_logloss: 0.58406\n",
      "[375]\ttraining's binary_logloss: 0.583991\n",
      "[376]\ttraining's binary_logloss: 0.58388\n",
      "[377]\ttraining's binary_logloss: 0.583789\n",
      "[378]\ttraining's binary_logloss: 0.583689\n",
      "[379]\ttraining's binary_logloss: 0.583581\n",
      "[380]\ttraining's binary_logloss: 0.583485\n",
      "[381]\ttraining's binary_logloss: 0.58343\n",
      "[382]\ttraining's binary_logloss: 0.583378\n",
      "[383]\ttraining's binary_logloss: 0.583319\n",
      "[384]\ttraining's binary_logloss: 0.583267\n",
      "[385]\ttraining's binary_logloss: 0.58322\n",
      "[386]\ttraining's binary_logloss: 0.583159\n",
      "[387]\ttraining's binary_logloss: 0.583091\n",
      "[388]\ttraining's binary_logloss: 0.583031\n",
      "[389]\ttraining's binary_logloss: 0.582973\n",
      "[390]\ttraining's binary_logloss: 0.582916\n",
      "[391]\ttraining's binary_logloss: 0.582806\n",
      "[392]\ttraining's binary_logloss: 0.582683\n",
      "[393]\ttraining's binary_logloss: 0.582574\n",
      "[394]\ttraining's binary_logloss: 0.582439\n",
      "[395]\ttraining's binary_logloss: 0.582306\n",
      "[396]\ttraining's binary_logloss: 0.582232\n",
      "[397]\ttraining's binary_logloss: 0.582159\n",
      "[398]\ttraining's binary_logloss: 0.582092\n",
      "[399]\ttraining's binary_logloss: 0.582031\n",
      "[400]\ttraining's binary_logloss: 0.581973\n",
      "[401]\ttraining's binary_logloss: 0.581894\n",
      "[402]\ttraining's binary_logloss: 0.58182\n",
      "[403]\ttraining's binary_logloss: 0.581751\n",
      "[404]\ttraining's binary_logloss: 0.581672\n",
      "[405]\ttraining's binary_logloss: 0.581597\n",
      "[406]\ttraining's binary_logloss: 0.581538\n",
      "[407]\ttraining's binary_logloss: 0.581486\n",
      "[408]\ttraining's binary_logloss: 0.581418\n",
      "[409]\ttraining's binary_logloss: 0.581369\n",
      "[410]\ttraining's binary_logloss: 0.581325\n",
      "[411]\ttraining's binary_logloss: 0.581252\n",
      "[412]\ttraining's binary_logloss: 0.581187\n",
      "[413]\ttraining's binary_logloss: 0.581126\n",
      "[414]\ttraining's binary_logloss: 0.581055\n",
      "[415]\ttraining's binary_logloss: 0.580989\n",
      "[416]\ttraining's binary_logloss: 0.580929\n",
      "[417]\ttraining's binary_logloss: 0.580865\n",
      "[418]\ttraining's binary_logloss: 0.580804\n",
      "[419]\ttraining's binary_logloss: 0.580745\n",
      "[420]\ttraining's binary_logloss: 0.580692\n",
      "[421]\ttraining's binary_logloss: 0.58068\n",
      "[422]\ttraining's binary_logloss: 0.580668\n",
      "[423]\ttraining's binary_logloss: 0.580663\n",
      "[424]\ttraining's binary_logloss: 0.580653\n",
      "[425]\ttraining's binary_logloss: 0.580651\n",
      "[426]\ttraining's binary_logloss: 0.580528\n",
      "[427]\ttraining's binary_logloss: 0.580417\n",
      "[428]\ttraining's binary_logloss: 0.580308\n",
      "[429]\ttraining's binary_logloss: 0.580218\n",
      "[430]\ttraining's binary_logloss: 0.580107\n",
      "[431]\ttraining's binary_logloss: 0.58005\n",
      "[432]\ttraining's binary_logloss: 0.57999\n",
      "[433]\ttraining's binary_logloss: 0.579932\n",
      "[434]\ttraining's binary_logloss: 0.579866\n",
      "[435]\ttraining's binary_logloss: 0.579805\n",
      "[436]\ttraining's binary_logloss: 0.579721\n",
      "[437]\ttraining's binary_logloss: 0.57964\n",
      "[438]\ttraining's binary_logloss: 0.579551\n",
      "[439]\ttraining's binary_logloss: 0.579454\n",
      "[440]\ttraining's binary_logloss: 0.579375\n",
      "[441]\ttraining's binary_logloss: 0.579285\n",
      "[442]\ttraining's binary_logloss: 0.579199\n",
      "[443]\ttraining's binary_logloss: 0.579086\n",
      "[444]\ttraining's binary_logloss: 0.57899\n",
      "[445]\ttraining's binary_logloss: 0.57888\n",
      "[446]\ttraining's binary_logloss: 0.578819\n",
      "[447]\ttraining's binary_logloss: 0.578766\n",
      "[448]\ttraining's binary_logloss: 0.578708\n",
      "[449]\ttraining's binary_logloss: 0.57865\n",
      "[450]\ttraining's binary_logloss: 0.578598\n",
      "[451]\ttraining's binary_logloss: 0.578554\n",
      "[452]\ttraining's binary_logloss: 0.578507\n",
      "[453]\ttraining's binary_logloss: 0.578462\n",
      "[454]\ttraining's binary_logloss: 0.578411\n",
      "[455]\ttraining's binary_logloss: 0.578355\n",
      "[456]\ttraining's binary_logloss: 0.578306\n",
      "[457]\ttraining's binary_logloss: 0.578253\n",
      "[458]\ttraining's binary_logloss: 0.578202\n",
      "[459]\ttraining's binary_logloss: 0.578153\n",
      "[460]\ttraining's binary_logloss: 0.578091\n",
      "[461]\ttraining's binary_logloss: 0.578014\n",
      "[462]\ttraining's binary_logloss: 0.577936\n",
      "[463]\ttraining's binary_logloss: 0.577842\n",
      "[464]\ttraining's binary_logloss: 0.577751\n",
      "[465]\ttraining's binary_logloss: 0.577677\n",
      "[466]\ttraining's binary_logloss: 0.57757\n",
      "[467]\ttraining's binary_logloss: 0.577473\n",
      "[468]\ttraining's binary_logloss: 0.577378\n",
      "[469]\ttraining's binary_logloss: 0.577282\n",
      "[470]\ttraining's binary_logloss: 0.577174\n",
      "[471]\ttraining's binary_logloss: 0.577111\n",
      "[472]\ttraining's binary_logloss: 0.57705\n",
      "[473]\ttraining's binary_logloss: 0.576991\n",
      "[474]\ttraining's binary_logloss: 0.576932\n",
      "[475]\ttraining's binary_logloss: 0.576873\n",
      "[476]\ttraining's binary_logloss: 0.576803\n",
      "[477]\ttraining's binary_logloss: 0.576732\n",
      "[478]\ttraining's binary_logloss: 0.576676\n",
      "[479]\ttraining's binary_logloss: 0.576619\n",
      "[480]\ttraining's binary_logloss: 0.576561\n",
      "[481]\ttraining's binary_logloss: 0.57649\n",
      "[482]\ttraining's binary_logloss: 0.57641\n",
      "[483]\ttraining's binary_logloss: 0.576333\n",
      "[484]\ttraining's binary_logloss: 0.576261\n",
      "[485]\ttraining's binary_logloss: 0.576188\n",
      "[486]\ttraining's binary_logloss: 0.576113\n",
      "[487]\ttraining's binary_logloss: 0.576041\n",
      "[488]\ttraining's binary_logloss: 0.575972\n",
      "[489]\ttraining's binary_logloss: 0.575902\n",
      "[490]\ttraining's binary_logloss: 0.575836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[491]\ttraining's binary_logloss: 0.575763\n",
      "[492]\ttraining's binary_logloss: 0.575693\n",
      "[493]\ttraining's binary_logloss: 0.575626\n",
      "[494]\ttraining's binary_logloss: 0.575552\n",
      "[495]\ttraining's binary_logloss: 0.5755\n",
      "[496]\ttraining's binary_logloss: 0.57538\n",
      "[497]\ttraining's binary_logloss: 0.57527\n",
      "[498]\ttraining's binary_logloss: 0.575157\n",
      "[499]\ttraining's binary_logloss: 0.575055\n",
      "[500]\ttraining's binary_logloss: 0.57493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614285\n",
      "[2]\ttraining's binary_logloss: 0.613056\n",
      "[3]\ttraining's binary_logloss: 0.61184\n",
      "[4]\ttraining's binary_logloss: 0.610705\n",
      "[5]\ttraining's binary_logloss: 0.60961\n",
      "[6]\ttraining's binary_logloss: 0.608449\n",
      "[7]\ttraining's binary_logloss: 0.607343\n",
      "[8]\ttraining's binary_logloss: 0.606227\n",
      "[9]\ttraining's binary_logloss: 0.605218\n",
      "[10]\ttraining's binary_logloss: 0.604174\n",
      "[11]\ttraining's binary_logloss: 0.603316\n",
      "[12]\ttraining's binary_logloss: 0.60236\n",
      "[13]\ttraining's binary_logloss: 0.601424\n",
      "[14]\ttraining's binary_logloss: 0.600533\n",
      "[15]\ttraining's binary_logloss: 0.599642\n",
      "[16]\ttraining's binary_logloss: 0.598747\n",
      "[17]\ttraining's binary_logloss: 0.598009\n",
      "[18]\ttraining's binary_logloss: 0.597264\n",
      "[19]\ttraining's binary_logloss: 0.596537\n",
      "[20]\ttraining's binary_logloss: 0.595807\n",
      "[21]\ttraining's binary_logloss: 0.595055\n",
      "[22]\ttraining's binary_logloss: 0.594331\n",
      "[23]\ttraining's binary_logloss: 0.593633\n",
      "[24]\ttraining's binary_logloss: 0.592996\n",
      "[25]\ttraining's binary_logloss: 0.592445\n",
      "[26]\ttraining's binary_logloss: 0.591831\n",
      "[27]\ttraining's binary_logloss: 0.591239\n",
      "[28]\ttraining's binary_logloss: 0.590654\n",
      "[29]\ttraining's binary_logloss: 0.590095\n",
      "[30]\ttraining's binary_logloss: 0.589568\n",
      "[31]\ttraining's binary_logloss: 0.588998\n",
      "[32]\ttraining's binary_logloss: 0.588562\n",
      "[33]\ttraining's binary_logloss: 0.588041\n",
      "[34]\ttraining's binary_logloss: 0.587631\n",
      "[35]\ttraining's binary_logloss: 0.587155\n",
      "[36]\ttraining's binary_logloss: 0.586761\n",
      "[37]\ttraining's binary_logloss: 0.586389\n",
      "[38]\ttraining's binary_logloss: 0.586038\n",
      "[39]\ttraining's binary_logloss: 0.585712\n",
      "[40]\ttraining's binary_logloss: 0.585359\n",
      "[41]\ttraining's binary_logloss: 0.584934\n",
      "[42]\ttraining's binary_logloss: 0.58452\n",
      "[43]\ttraining's binary_logloss: 0.584253\n",
      "[44]\ttraining's binary_logloss: 0.583851\n",
      "[45]\ttraining's binary_logloss: 0.583452\n",
      "[46]\ttraining's binary_logloss: 0.583084\n",
      "[47]\ttraining's binary_logloss: 0.582741\n",
      "[48]\ttraining's binary_logloss: 0.582386\n",
      "[49]\ttraining's binary_logloss: 0.582059\n",
      "[50]\ttraining's binary_logloss: 0.581732\n",
      "[51]\ttraining's binary_logloss: 0.581504\n",
      "[52]\ttraining's binary_logloss: 0.581216\n",
      "[53]\ttraining's binary_logloss: 0.581002\n",
      "[54]\ttraining's binary_logloss: 0.58077\n",
      "[55]\ttraining's binary_logloss: 0.580572\n",
      "[56]\ttraining's binary_logloss: 0.580342\n",
      "[57]\ttraining's binary_logloss: 0.580173\n",
      "[58]\ttraining's binary_logloss: 0.579987\n",
      "[59]\ttraining's binary_logloss: 0.579801\n",
      "[60]\ttraining's binary_logloss: 0.579613\n",
      "[61]\ttraining's binary_logloss: 0.579378\n",
      "[62]\ttraining's binary_logloss: 0.579171\n",
      "[63]\ttraining's binary_logloss: 0.57897\n",
      "[64]\ttraining's binary_logloss: 0.5788\n",
      "[65]\ttraining's binary_logloss: 0.57863\n",
      "[66]\ttraining's binary_logloss: 0.578451\n",
      "[67]\ttraining's binary_logloss: 0.578295\n",
      "[68]\ttraining's binary_logloss: 0.578147\n",
      "[69]\ttraining's binary_logloss: 0.577997\n",
      "[70]\ttraining's binary_logloss: 0.577896\n",
      "[71]\ttraining's binary_logloss: 0.577781\n",
      "[72]\ttraining's binary_logloss: 0.577628\n",
      "[73]\ttraining's binary_logloss: 0.57753\n",
      "[74]\ttraining's binary_logloss: 0.577433\n",
      "[75]\ttraining's binary_logloss: 0.57734\n",
      "[76]\ttraining's binary_logloss: 0.577228\n",
      "[77]\ttraining's binary_logloss: 0.577149\n",
      "[78]\ttraining's binary_logloss: 0.577055\n",
      "[79]\ttraining's binary_logloss: 0.57694\n",
      "[80]\ttraining's binary_logloss: 0.576805\n",
      "[81]\ttraining's binary_logloss: 0.576655\n",
      "[82]\ttraining's binary_logloss: 0.57651\n",
      "[83]\ttraining's binary_logloss: 0.576374\n",
      "[84]\ttraining's binary_logloss: 0.57624\n",
      "[85]\ttraining's binary_logloss: 0.57616\n",
      "[86]\ttraining's binary_logloss: 0.57608\n",
      "[87]\ttraining's binary_logloss: 0.576017\n",
      "[88]\ttraining's binary_logloss: 0.575936\n",
      "[89]\ttraining's binary_logloss: 0.575859\n",
      "[90]\ttraining's binary_logloss: 0.575753\n",
      "[91]\ttraining's binary_logloss: 0.57567\n",
      "[92]\ttraining's binary_logloss: 0.575585\n",
      "[93]\ttraining's binary_logloss: 0.575493\n",
      "[94]\ttraining's binary_logloss: 0.57542\n",
      "[95]\ttraining's binary_logloss: 0.575343\n",
      "[96]\ttraining's binary_logloss: 0.575259\n",
      "[97]\ttraining's binary_logloss: 0.575169\n",
      "[98]\ttraining's binary_logloss: 0.575063\n",
      "[99]\ttraining's binary_logloss: 0.574971\n",
      "[100]\ttraining's binary_logloss: 0.574895\n",
      "[101]\ttraining's binary_logloss: 0.574831\n",
      "[102]\ttraining's binary_logloss: 0.574765\n",
      "[103]\ttraining's binary_logloss: 0.57469\n",
      "[104]\ttraining's binary_logloss: 0.574634\n",
      "[105]\ttraining's binary_logloss: 0.574546\n",
      "[106]\ttraining's binary_logloss: 0.574448\n",
      "[107]\ttraining's binary_logloss: 0.574362\n",
      "[108]\ttraining's binary_logloss: 0.574363\n",
      "[109]\ttraining's binary_logloss: 0.574333\n",
      "[110]\ttraining's binary_logloss: 0.574298\n",
      "[111]\ttraining's binary_logloss: 0.574213\n",
      "[112]\ttraining's binary_logloss: 0.574162\n",
      "[113]\ttraining's binary_logloss: 0.574077\n",
      "[114]\ttraining's binary_logloss: 0.573997\n",
      "[115]\ttraining's binary_logloss: 0.573913\n",
      "[116]\ttraining's binary_logloss: 0.573858\n",
      "[117]\ttraining's binary_logloss: 0.573808\n",
      "[118]\ttraining's binary_logloss: 0.573773\n",
      "[119]\ttraining's binary_logloss: 0.573737\n",
      "[120]\ttraining's binary_logloss: 0.573694\n",
      "[121]\ttraining's binary_logloss: 0.573638\n",
      "[122]\ttraining's binary_logloss: 0.573596\n",
      "[123]\ttraining's binary_logloss: 0.573541\n",
      "[124]\ttraining's binary_logloss: 0.573509\n",
      "[125]\ttraining's binary_logloss: 0.57348\n",
      "[126]\ttraining's binary_logloss: 0.573426\n",
      "[127]\ttraining's binary_logloss: 0.573376\n",
      "[128]\ttraining's binary_logloss: 0.573334\n",
      "[129]\ttraining's binary_logloss: 0.573296\n",
      "[130]\ttraining's binary_logloss: 0.573246\n",
      "[131]\ttraining's binary_logloss: 0.573176\n",
      "[132]\ttraining's binary_logloss: 0.573085\n",
      "[133]\ttraining's binary_logloss: 0.572984\n",
      "[134]\ttraining's binary_logloss: 0.572889\n",
      "[135]\ttraining's binary_logloss: 0.572806\n",
      "[136]\ttraining's binary_logloss: 0.572754\n",
      "[137]\ttraining's binary_logloss: 0.572717\n",
      "[138]\ttraining's binary_logloss: 0.572673\n",
      "[139]\ttraining's binary_logloss: 0.572619\n",
      "[140]\ttraining's binary_logloss: 0.572549\n",
      "[141]\ttraining's binary_logloss: 0.572507\n",
      "[142]\ttraining's binary_logloss: 0.572443\n",
      "[143]\ttraining's binary_logloss: 0.572384\n",
      "[144]\ttraining's binary_logloss: 0.572341\n",
      "[145]\ttraining's binary_logloss: 0.572291\n",
      "[146]\ttraining's binary_logloss: 0.57221\n",
      "[147]\ttraining's binary_logloss: 0.57213\n",
      "[148]\ttraining's binary_logloss: 0.572016\n",
      "[149]\ttraining's binary_logloss: 0.57194\n",
      "[150]\ttraining's binary_logloss: 0.571893\n",
      "[151]\ttraining's binary_logloss: 0.571804\n",
      "[152]\ttraining's binary_logloss: 0.571725\n",
      "[153]\ttraining's binary_logloss: 0.57166\n",
      "[154]\ttraining's binary_logloss: 0.571591\n",
      "[155]\ttraining's binary_logloss: 0.57153\n",
      "[156]\ttraining's binary_logloss: 0.571504\n",
      "[157]\ttraining's binary_logloss: 0.571486\n",
      "[158]\ttraining's binary_logloss: 0.571472\n",
      "[159]\ttraining's binary_logloss: 0.571433\n",
      "[160]\ttraining's binary_logloss: 0.571409\n",
      "[161]\ttraining's binary_logloss: 0.571332\n",
      "[162]\ttraining's binary_logloss: 0.571217\n",
      "[163]\ttraining's binary_logloss: 0.571108\n",
      "[164]\ttraining's binary_logloss: 0.571028\n",
      "[165]\ttraining's binary_logloss: 0.570925\n",
      "[166]\ttraining's binary_logloss: 0.570842\n",
      "[167]\ttraining's binary_logloss: 0.570756\n",
      "[168]\ttraining's binary_logloss: 0.570674\n",
      "[169]\ttraining's binary_logloss: 0.570597\n",
      "[170]\ttraining's binary_logloss: 0.570529\n",
      "[171]\ttraining's binary_logloss: 0.57044\n",
      "[172]\ttraining's binary_logloss: 0.570365\n",
      "[173]\ttraining's binary_logloss: 0.570274\n",
      "[174]\ttraining's binary_logloss: 0.570194\n",
      "[175]\ttraining's binary_logloss: 0.570108\n",
      "[176]\ttraining's binary_logloss: 0.570072\n",
      "[177]\ttraining's binary_logloss: 0.570013\n",
      "[178]\ttraining's binary_logloss: 0.569977\n",
      "[179]\ttraining's binary_logloss: 0.569906\n",
      "[180]\ttraining's binary_logloss: 0.56985\n",
      "[181]\ttraining's binary_logloss: 0.569786\n",
      "[182]\ttraining's binary_logloss: 0.569722\n",
      "[183]\ttraining's binary_logloss: 0.569656\n",
      "[184]\ttraining's binary_logloss: 0.569592\n",
      "[185]\ttraining's binary_logloss: 0.569521\n",
      "[186]\ttraining's binary_logloss: 0.569467\n",
      "[187]\ttraining's binary_logloss: 0.569434\n",
      "[188]\ttraining's binary_logloss: 0.569373\n",
      "[189]\ttraining's binary_logloss: 0.569321\n",
      "[190]\ttraining's binary_logloss: 0.569272\n",
      "[191]\ttraining's binary_logloss: 0.569204\n",
      "[192]\ttraining's binary_logloss: 0.569137\n",
      "[193]\ttraining's binary_logloss: 0.569071\n",
      "[194]\ttraining's binary_logloss: 0.568998\n",
      "[195]\ttraining's binary_logloss: 0.568915\n",
      "[196]\ttraining's binary_logloss: 0.568847\n",
      "[197]\ttraining's binary_logloss: 0.568765\n",
      "[198]\ttraining's binary_logloss: 0.568703\n",
      "[199]\ttraining's binary_logloss: 0.568606\n",
      "[200]\ttraining's binary_logloss: 0.568545\n",
      "[201]\ttraining's binary_logloss: 0.568507\n",
      "[202]\ttraining's binary_logloss: 0.568444\n",
      "[203]\ttraining's binary_logloss: 0.568373\n",
      "[204]\ttraining's binary_logloss: 0.568314\n",
      "[205]\ttraining's binary_logloss: 0.568266\n",
      "[206]\ttraining's binary_logloss: 0.568186\n",
      "[207]\ttraining's binary_logloss: 0.568094\n",
      "[208]\ttraining's binary_logloss: 0.568006\n",
      "[209]\ttraining's binary_logloss: 0.567911\n",
      "[210]\ttraining's binary_logloss: 0.567829\n",
      "[211]\ttraining's binary_logloss: 0.567746\n",
      "[212]\ttraining's binary_logloss: 0.567651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[213]\ttraining's binary_logloss: 0.567579\n",
      "[214]\ttraining's binary_logloss: 0.56752\n",
      "[215]\ttraining's binary_logloss: 0.567464\n",
      "[216]\ttraining's binary_logloss: 0.567392\n",
      "[217]\ttraining's binary_logloss: 0.567326\n",
      "[218]\ttraining's binary_logloss: 0.567219\n",
      "[219]\ttraining's binary_logloss: 0.567126\n",
      "[220]\ttraining's binary_logloss: 0.567066\n",
      "[221]\ttraining's binary_logloss: 0.566948\n",
      "[222]\ttraining's binary_logloss: 0.566833\n",
      "[223]\ttraining's binary_logloss: 0.566742\n",
      "[224]\ttraining's binary_logloss: 0.566634\n",
      "[225]\ttraining's binary_logloss: 0.566561\n",
      "[226]\ttraining's binary_logloss: 0.566506\n",
      "[227]\ttraining's binary_logloss: 0.566452\n",
      "[228]\ttraining's binary_logloss: 0.566379\n",
      "[229]\ttraining's binary_logloss: 0.566329\n",
      "[230]\ttraining's binary_logloss: 0.566275\n",
      "[231]\ttraining's binary_logloss: 0.566153\n",
      "[232]\ttraining's binary_logloss: 0.566048\n",
      "[233]\ttraining's binary_logloss: 0.565941\n",
      "[234]\ttraining's binary_logloss: 0.565846\n",
      "[235]\ttraining's binary_logloss: 0.565743\n",
      "[236]\ttraining's binary_logloss: 0.565612\n",
      "[237]\ttraining's binary_logloss: 0.565475\n",
      "[238]\ttraining's binary_logloss: 0.565346\n",
      "[239]\ttraining's binary_logloss: 0.565225\n",
      "[240]\ttraining's binary_logloss: 0.565093\n",
      "[241]\ttraining's binary_logloss: 0.564979\n",
      "[242]\ttraining's binary_logloss: 0.564871\n",
      "[243]\ttraining's binary_logloss: 0.564775\n",
      "[244]\ttraining's binary_logloss: 0.564676\n",
      "[245]\ttraining's binary_logloss: 0.564582\n",
      "[246]\ttraining's binary_logloss: 0.564551\n",
      "[247]\ttraining's binary_logloss: 0.56451\n",
      "[248]\ttraining's binary_logloss: 0.564477\n",
      "[249]\ttraining's binary_logloss: 0.564453\n",
      "[250]\ttraining's binary_logloss: 0.564425\n",
      "[251]\ttraining's binary_logloss: 0.564315\n",
      "[252]\ttraining's binary_logloss: 0.564224\n",
      "[253]\ttraining's binary_logloss: 0.564123\n",
      "[254]\ttraining's binary_logloss: 0.564017\n",
      "[255]\ttraining's binary_logloss: 0.563919\n",
      "[256]\ttraining's binary_logloss: 0.563799\n",
      "[257]\ttraining's binary_logloss: 0.563688\n",
      "[258]\ttraining's binary_logloss: 0.563578\n",
      "[259]\ttraining's binary_logloss: 0.563473\n",
      "[260]\ttraining's binary_logloss: 0.563366\n",
      "[261]\ttraining's binary_logloss: 0.563235\n",
      "[262]\ttraining's binary_logloss: 0.563153\n",
      "[263]\ttraining's binary_logloss: 0.563054\n",
      "[264]\ttraining's binary_logloss: 0.562964\n",
      "[265]\ttraining's binary_logloss: 0.562864\n",
      "[266]\ttraining's binary_logloss: 0.562807\n",
      "[267]\ttraining's binary_logloss: 0.562725\n",
      "[268]\ttraining's binary_logloss: 0.562667\n",
      "[269]\ttraining's binary_logloss: 0.562588\n",
      "[270]\ttraining's binary_logloss: 0.562513\n",
      "[271]\ttraining's binary_logloss: 0.562382\n",
      "[272]\ttraining's binary_logloss: 0.562236\n",
      "[273]\ttraining's binary_logloss: 0.562094\n",
      "[274]\ttraining's binary_logloss: 0.561964\n",
      "[275]\ttraining's binary_logloss: 0.561839\n",
      "[276]\ttraining's binary_logloss: 0.561695\n",
      "[277]\ttraining's binary_logloss: 0.561593\n",
      "[278]\ttraining's binary_logloss: 0.56149\n",
      "[279]\ttraining's binary_logloss: 0.561356\n",
      "[280]\ttraining's binary_logloss: 0.56125\n",
      "[281]\ttraining's binary_logloss: 0.561159\n",
      "[282]\ttraining's binary_logloss: 0.561056\n",
      "[283]\ttraining's binary_logloss: 0.56096\n",
      "[284]\ttraining's binary_logloss: 0.560877\n",
      "[285]\ttraining's binary_logloss: 0.560777\n",
      "[286]\ttraining's binary_logloss: 0.560653\n",
      "[287]\ttraining's binary_logloss: 0.560517\n",
      "[288]\ttraining's binary_logloss: 0.560386\n",
      "[289]\ttraining's binary_logloss: 0.560273\n",
      "[290]\ttraining's binary_logloss: 0.560158\n",
      "[291]\ttraining's binary_logloss: 0.560013\n",
      "[292]\ttraining's binary_logloss: 0.559877\n",
      "[293]\ttraining's binary_logloss: 0.55975\n",
      "[294]\ttraining's binary_logloss: 0.55962\n",
      "[295]\ttraining's binary_logloss: 0.559502\n",
      "[296]\ttraining's binary_logloss: 0.559369\n",
      "[297]\ttraining's binary_logloss: 0.559244\n",
      "[298]\ttraining's binary_logloss: 0.55914\n",
      "[299]\ttraining's binary_logloss: 0.55904\n",
      "[300]\ttraining's binary_logloss: 0.558939\n",
      "[301]\ttraining's binary_logloss: 0.558809\n",
      "[302]\ttraining's binary_logloss: 0.558675\n",
      "[303]\ttraining's binary_logloss: 0.558549\n",
      "[304]\ttraining's binary_logloss: 0.558431\n",
      "[305]\ttraining's binary_logloss: 0.558298\n",
      "[306]\ttraining's binary_logloss: 0.558181\n",
      "[307]\ttraining's binary_logloss: 0.55808\n",
      "[308]\ttraining's binary_logloss: 0.557969\n",
      "[309]\ttraining's binary_logloss: 0.557858\n",
      "[310]\ttraining's binary_logloss: 0.55775\n",
      "[311]\ttraining's binary_logloss: 0.557666\n",
      "[312]\ttraining's binary_logloss: 0.557591\n",
      "[313]\ttraining's binary_logloss: 0.557518\n",
      "[314]\ttraining's binary_logloss: 0.557443\n",
      "[315]\ttraining's binary_logloss: 0.557383\n",
      "[316]\ttraining's binary_logloss: 0.55725\n",
      "[317]\ttraining's binary_logloss: 0.557124\n",
      "[318]\ttraining's binary_logloss: 0.556974\n",
      "[319]\ttraining's binary_logloss: 0.556828\n",
      "[320]\ttraining's binary_logloss: 0.556665\n",
      "[321]\ttraining's binary_logloss: 0.556514\n",
      "[322]\ttraining's binary_logloss: 0.556363\n",
      "[323]\ttraining's binary_logloss: 0.556229\n",
      "[324]\ttraining's binary_logloss: 0.556103\n",
      "[325]\ttraining's binary_logloss: 0.555972\n",
      "[326]\ttraining's binary_logloss: 0.555836\n",
      "[327]\ttraining's binary_logloss: 0.555684\n",
      "[328]\ttraining's binary_logloss: 0.555545\n",
      "[329]\ttraining's binary_logloss: 0.55541\n",
      "[330]\ttraining's binary_logloss: 0.555264\n",
      "[331]\ttraining's binary_logloss: 0.555093\n",
      "[332]\ttraining's binary_logloss: 0.554951\n",
      "[333]\ttraining's binary_logloss: 0.554819\n",
      "[334]\ttraining's binary_logloss: 0.554646\n",
      "[335]\ttraining's binary_logloss: 0.55452\n",
      "[336]\ttraining's binary_logloss: 0.554416\n",
      "[337]\ttraining's binary_logloss: 0.554344\n",
      "[338]\ttraining's binary_logloss: 0.554239\n",
      "[339]\ttraining's binary_logloss: 0.554127\n",
      "[340]\ttraining's binary_logloss: 0.554025\n",
      "[341]\ttraining's binary_logloss: 0.553924\n",
      "[342]\ttraining's binary_logloss: 0.553836\n",
      "[343]\ttraining's binary_logloss: 0.553743\n",
      "[344]\ttraining's binary_logloss: 0.553602\n",
      "[345]\ttraining's binary_logloss: 0.553516\n",
      "[346]\ttraining's binary_logloss: 0.553378\n",
      "[347]\ttraining's binary_logloss: 0.553249\n",
      "[348]\ttraining's binary_logloss: 0.553111\n",
      "[349]\ttraining's binary_logloss: 0.552987\n",
      "[350]\ttraining's binary_logloss: 0.55286\n",
      "[351]\ttraining's binary_logloss: 0.552751\n",
      "[352]\ttraining's binary_logloss: 0.552639\n",
      "[353]\ttraining's binary_logloss: 0.552522\n",
      "[354]\ttraining's binary_logloss: 0.5524\n",
      "[355]\ttraining's binary_logloss: 0.552296\n",
      "[356]\ttraining's binary_logloss: 0.552147\n",
      "[357]\ttraining's binary_logloss: 0.551988\n",
      "[358]\ttraining's binary_logloss: 0.551861\n",
      "[359]\ttraining's binary_logloss: 0.551723\n",
      "[360]\ttraining's binary_logloss: 0.551582\n",
      "[361]\ttraining's binary_logloss: 0.551421\n",
      "[362]\ttraining's binary_logloss: 0.551268\n",
      "[363]\ttraining's binary_logloss: 0.551109\n",
      "[364]\ttraining's binary_logloss: 0.550954\n",
      "[365]\ttraining's binary_logloss: 0.550798\n",
      "[366]\ttraining's binary_logloss: 0.550692\n",
      "[367]\ttraining's binary_logloss: 0.550584\n",
      "[368]\ttraining's binary_logloss: 0.550466\n",
      "[369]\ttraining's binary_logloss: 0.550367\n",
      "[370]\ttraining's binary_logloss: 0.550239\n",
      "[371]\ttraining's binary_logloss: 0.550144\n",
      "[372]\ttraining's binary_logloss: 0.550039\n",
      "[373]\ttraining's binary_logloss: 0.54993\n",
      "[374]\ttraining's binary_logloss: 0.549802\n",
      "[375]\ttraining's binary_logloss: 0.549698\n",
      "[376]\ttraining's binary_logloss: 0.549554\n",
      "[377]\ttraining's binary_logloss: 0.549418\n",
      "[378]\ttraining's binary_logloss: 0.549284\n",
      "[379]\ttraining's binary_logloss: 0.549158\n",
      "[380]\ttraining's binary_logloss: 0.549028\n",
      "[381]\ttraining's binary_logloss: 0.548918\n",
      "[382]\ttraining's binary_logloss: 0.548818\n",
      "[383]\ttraining's binary_logloss: 0.548729\n",
      "[384]\ttraining's binary_logloss: 0.548645\n",
      "[385]\ttraining's binary_logloss: 0.548545\n",
      "[386]\ttraining's binary_logloss: 0.548338\n",
      "[387]\ttraining's binary_logloss: 0.548136\n",
      "[388]\ttraining's binary_logloss: 0.547951\n",
      "[389]\ttraining's binary_logloss: 0.547769\n",
      "[390]\ttraining's binary_logloss: 0.547564\n",
      "[391]\ttraining's binary_logloss: 0.547429\n",
      "[392]\ttraining's binary_logloss: 0.547286\n",
      "[393]\ttraining's binary_logloss: 0.547153\n",
      "[394]\ttraining's binary_logloss: 0.547029\n",
      "[395]\ttraining's binary_logloss: 0.546899\n",
      "[396]\ttraining's binary_logloss: 0.546752\n",
      "[397]\ttraining's binary_logloss: 0.546608\n",
      "[398]\ttraining's binary_logloss: 0.546481\n",
      "[399]\ttraining's binary_logloss: 0.546362\n",
      "[400]\ttraining's binary_logloss: 0.546235\n",
      "[401]\ttraining's binary_logloss: 0.546051\n",
      "[402]\ttraining's binary_logloss: 0.545872\n",
      "[403]\ttraining's binary_logloss: 0.545684\n",
      "[404]\ttraining's binary_logloss: 0.545533\n",
      "[405]\ttraining's binary_logloss: 0.54537\n",
      "[406]\ttraining's binary_logloss: 0.54526\n",
      "[407]\ttraining's binary_logloss: 0.545147\n",
      "[408]\ttraining's binary_logloss: 0.545037\n",
      "[409]\ttraining's binary_logloss: 0.544924\n",
      "[410]\ttraining's binary_logloss: 0.544814\n",
      "[411]\ttraining's binary_logloss: 0.544624\n",
      "[412]\ttraining's binary_logloss: 0.544441\n",
      "[413]\ttraining's binary_logloss: 0.544291\n",
      "[414]\ttraining's binary_logloss: 0.544115\n",
      "[415]\ttraining's binary_logloss: 0.543943\n",
      "[416]\ttraining's binary_logloss: 0.543811\n",
      "[417]\ttraining's binary_logloss: 0.543691\n",
      "[418]\ttraining's binary_logloss: 0.543558\n",
      "[419]\ttraining's binary_logloss: 0.543405\n",
      "[420]\ttraining's binary_logloss: 0.543277\n",
      "[421]\ttraining's binary_logloss: 0.543162\n",
      "[422]\ttraining's binary_logloss: 0.543026\n",
      "[423]\ttraining's binary_logloss: 0.542928\n",
      "[424]\ttraining's binary_logloss: 0.542841\n",
      "[425]\ttraining's binary_logloss: 0.542723\n",
      "[426]\ttraining's binary_logloss: 0.542628\n",
      "[427]\ttraining's binary_logloss: 0.54251\n",
      "[428]\ttraining's binary_logloss: 0.542396\n",
      "[429]\ttraining's binary_logloss: 0.542293\n",
      "[430]\ttraining's binary_logloss: 0.542192\n",
      "[431]\ttraining's binary_logloss: 0.542035\n",
      "[432]\ttraining's binary_logloss: 0.541892\n",
      "[433]\ttraining's binary_logloss: 0.541758\n",
      "[434]\ttraining's binary_logloss: 0.54164\n",
      "[435]\ttraining's binary_logloss: 0.541523\n",
      "[436]\ttraining's binary_logloss: 0.541406\n",
      "[437]\ttraining's binary_logloss: 0.541276\n",
      "[438]\ttraining's binary_logloss: 0.541178\n",
      "[439]\ttraining's binary_logloss: 0.541065\n",
      "[440]\ttraining's binary_logloss: 0.540934\n",
      "[441]\ttraining's binary_logloss: 0.540786\n",
      "[442]\ttraining's binary_logloss: 0.540638\n",
      "[443]\ttraining's binary_logloss: 0.54048\n",
      "[444]\ttraining's binary_logloss: 0.540338\n",
      "[445]\ttraining's binary_logloss: 0.540196\n",
      "[446]\ttraining's binary_logloss: 0.540067\n",
      "[447]\ttraining's binary_logloss: 0.539953\n",
      "[448]\ttraining's binary_logloss: 0.539838\n",
      "[449]\ttraining's binary_logloss: 0.539714\n",
      "[450]\ttraining's binary_logloss: 0.539603\n",
      "[451]\ttraining's binary_logloss: 0.539501\n",
      "[452]\ttraining's binary_logloss: 0.539382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[453]\ttraining's binary_logloss: 0.539275\n",
      "[454]\ttraining's binary_logloss: 0.539159\n",
      "[455]\ttraining's binary_logloss: 0.539044\n",
      "[456]\ttraining's binary_logloss: 0.538915\n",
      "[457]\ttraining's binary_logloss: 0.538787\n",
      "[458]\ttraining's binary_logloss: 0.538685\n",
      "[459]\ttraining's binary_logloss: 0.538578\n",
      "[460]\ttraining's binary_logloss: 0.538477\n",
      "[461]\ttraining's binary_logloss: 0.538327\n",
      "[462]\ttraining's binary_logloss: 0.538183\n",
      "[463]\ttraining's binary_logloss: 0.538019\n",
      "[464]\ttraining's binary_logloss: 0.537879\n",
      "[465]\ttraining's binary_logloss: 0.537756\n",
      "[466]\ttraining's binary_logloss: 0.537629\n",
      "[467]\ttraining's binary_logloss: 0.537493\n",
      "[468]\ttraining's binary_logloss: 0.53734\n",
      "[469]\ttraining's binary_logloss: 0.537193\n",
      "[470]\ttraining's binary_logloss: 0.537043\n",
      "[471]\ttraining's binary_logloss: 0.536942\n",
      "[472]\ttraining's binary_logloss: 0.536843\n",
      "[473]\ttraining's binary_logloss: 0.536728\n",
      "[474]\ttraining's binary_logloss: 0.536626\n",
      "[475]\ttraining's binary_logloss: 0.53652\n",
      "[476]\ttraining's binary_logloss: 0.536395\n",
      "[477]\ttraining's binary_logloss: 0.536273\n",
      "[478]\ttraining's binary_logloss: 0.536159\n",
      "[479]\ttraining's binary_logloss: 0.536008\n",
      "[480]\ttraining's binary_logloss: 0.535897\n",
      "[481]\ttraining's binary_logloss: 0.535772\n",
      "[482]\ttraining's binary_logloss: 0.535652\n",
      "[483]\ttraining's binary_logloss: 0.535542\n",
      "[484]\ttraining's binary_logloss: 0.535432\n",
      "[485]\ttraining's binary_logloss: 0.535322\n",
      "[486]\ttraining's binary_logloss: 0.535173\n",
      "[487]\ttraining's binary_logloss: 0.535048\n",
      "[488]\ttraining's binary_logloss: 0.534905\n",
      "[489]\ttraining's binary_logloss: 0.534758\n",
      "[490]\ttraining's binary_logloss: 0.534619\n",
      "[491]\ttraining's binary_logloss: 0.534534\n",
      "[492]\ttraining's binary_logloss: 0.53446\n",
      "[493]\ttraining's binary_logloss: 0.534373\n",
      "[494]\ttraining's binary_logloss: 0.534304\n",
      "[495]\ttraining's binary_logloss: 0.534227\n",
      "[496]\ttraining's binary_logloss: 0.534121\n",
      "[497]\ttraining's binary_logloss: 0.533983\n",
      "[498]\ttraining's binary_logloss: 0.533851\n",
      "[499]\ttraining's binary_logloss: 0.533691\n",
      "[500]\ttraining's binary_logloss: 0.53358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613853\n",
      "[2]\ttraining's binary_logloss: 0.612513\n",
      "[3]\ttraining's binary_logloss: 0.611091\n",
      "[4]\ttraining's binary_logloss: 0.609881\n",
      "[5]\ttraining's binary_logloss: 0.608718\n",
      "[6]\ttraining's binary_logloss: 0.607484\n",
      "[7]\ttraining's binary_logloss: 0.606337\n",
      "[8]\ttraining's binary_logloss: 0.605247\n",
      "[9]\ttraining's binary_logloss: 0.604204\n",
      "[10]\ttraining's binary_logloss: 0.603083\n",
      "[11]\ttraining's binary_logloss: 0.602156\n",
      "[12]\ttraining's binary_logloss: 0.601109\n",
      "[13]\ttraining's binary_logloss: 0.600102\n",
      "[14]\ttraining's binary_logloss: 0.599143\n",
      "[15]\ttraining's binary_logloss: 0.598245\n",
      "[16]\ttraining's binary_logloss: 0.597356\n",
      "[17]\ttraining's binary_logloss: 0.596685\n",
      "[18]\ttraining's binary_logloss: 0.595936\n",
      "[19]\ttraining's binary_logloss: 0.595101\n",
      "[20]\ttraining's binary_logloss: 0.594361\n",
      "[21]\ttraining's binary_logloss: 0.593588\n",
      "[22]\ttraining's binary_logloss: 0.592851\n",
      "[23]\ttraining's binary_logloss: 0.592129\n",
      "[24]\ttraining's binary_logloss: 0.591432\n",
      "[25]\ttraining's binary_logloss: 0.590813\n",
      "[26]\ttraining's binary_logloss: 0.590225\n",
      "[27]\ttraining's binary_logloss: 0.589644\n",
      "[28]\ttraining's binary_logloss: 0.589097\n",
      "[29]\ttraining's binary_logloss: 0.588517\n",
      "[30]\ttraining's binary_logloss: 0.587931\n",
      "[31]\ttraining's binary_logloss: 0.587302\n",
      "[32]\ttraining's binary_logloss: 0.586791\n",
      "[33]\ttraining's binary_logloss: 0.586204\n",
      "[34]\ttraining's binary_logloss: 0.58573\n",
      "[35]\ttraining's binary_logloss: 0.585214\n",
      "[36]\ttraining's binary_logloss: 0.584624\n",
      "[37]\ttraining's binary_logloss: 0.584075\n",
      "[38]\ttraining's binary_logloss: 0.583601\n",
      "[39]\ttraining's binary_logloss: 0.583128\n",
      "[40]\ttraining's binary_logloss: 0.58264\n",
      "[41]\ttraining's binary_logloss: 0.582151\n",
      "[42]\ttraining's binary_logloss: 0.581788\n",
      "[43]\ttraining's binary_logloss: 0.581443\n",
      "[44]\ttraining's binary_logloss: 0.581113\n",
      "[45]\ttraining's binary_logloss: 0.580717\n",
      "[46]\ttraining's binary_logloss: 0.580309\n",
      "[47]\ttraining's binary_logloss: 0.579966\n",
      "[48]\ttraining's binary_logloss: 0.579636\n",
      "[49]\ttraining's binary_logloss: 0.579275\n",
      "[50]\ttraining's binary_logloss: 0.578948\n",
      "[51]\ttraining's binary_logloss: 0.578543\n",
      "[52]\ttraining's binary_logloss: 0.57816\n",
      "[53]\ttraining's binary_logloss: 0.577798\n",
      "[54]\ttraining's binary_logloss: 0.577444\n",
      "[55]\ttraining's binary_logloss: 0.5772\n",
      "[56]\ttraining's binary_logloss: 0.576962\n",
      "[57]\ttraining's binary_logloss: 0.576638\n",
      "[58]\ttraining's binary_logloss: 0.57632\n",
      "[59]\ttraining's binary_logloss: 0.576009\n",
      "[60]\ttraining's binary_logloss: 0.575727\n",
      "[61]\ttraining's binary_logloss: 0.575447\n",
      "[62]\ttraining's binary_logloss: 0.575181\n",
      "[63]\ttraining's binary_logloss: 0.574927\n",
      "[64]\ttraining's binary_logloss: 0.574689\n",
      "[65]\ttraining's binary_logloss: 0.574477\n",
      "[66]\ttraining's binary_logloss: 0.574252\n",
      "[67]\ttraining's binary_logloss: 0.574041\n",
      "[68]\ttraining's binary_logloss: 0.57392\n",
      "[69]\ttraining's binary_logloss: 0.573747\n",
      "[70]\ttraining's binary_logloss: 0.573557\n",
      "[71]\ttraining's binary_logloss: 0.573393\n",
      "[72]\ttraining's binary_logloss: 0.573207\n",
      "[73]\ttraining's binary_logloss: 0.573054\n",
      "[74]\ttraining's binary_logloss: 0.572869\n",
      "[75]\ttraining's binary_logloss: 0.572707\n",
      "[76]\ttraining's binary_logloss: 0.572469\n",
      "[77]\ttraining's binary_logloss: 0.572334\n",
      "[78]\ttraining's binary_logloss: 0.572216\n",
      "[79]\ttraining's binary_logloss: 0.572002\n",
      "[80]\ttraining's binary_logloss: 0.571828\n",
      "[81]\ttraining's binary_logloss: 0.571678\n",
      "[82]\ttraining's binary_logloss: 0.571525\n",
      "[83]\ttraining's binary_logloss: 0.571382\n",
      "[84]\ttraining's binary_logloss: 0.571209\n",
      "[85]\ttraining's binary_logloss: 0.571087\n",
      "[86]\ttraining's binary_logloss: 0.5709\n",
      "[87]\ttraining's binary_logloss: 0.570713\n",
      "[88]\ttraining's binary_logloss: 0.570593\n",
      "[89]\ttraining's binary_logloss: 0.570466\n",
      "[90]\ttraining's binary_logloss: 0.570309\n",
      "[91]\ttraining's binary_logloss: 0.570216\n",
      "[92]\ttraining's binary_logloss: 0.5701\n",
      "[93]\ttraining's binary_logloss: 0.569999\n",
      "[94]\ttraining's binary_logloss: 0.569893\n",
      "[95]\ttraining's binary_logloss: 0.569813\n",
      "[96]\ttraining's binary_logloss: 0.569683\n",
      "[97]\ttraining's binary_logloss: 0.569581\n",
      "[98]\ttraining's binary_logloss: 0.569516\n",
      "[99]\ttraining's binary_logloss: 0.569442\n",
      "[100]\ttraining's binary_logloss: 0.569355\n",
      "[101]\ttraining's binary_logloss: 0.569274\n",
      "[102]\ttraining's binary_logloss: 0.569199\n",
      "[103]\ttraining's binary_logloss: 0.569135\n",
      "[104]\ttraining's binary_logloss: 0.56907\n",
      "[105]\ttraining's binary_logloss: 0.568968\n",
      "[106]\ttraining's binary_logloss: 0.568821\n",
      "[107]\ttraining's binary_logloss: 0.568687\n",
      "[108]\ttraining's binary_logloss: 0.568609\n",
      "[109]\ttraining's binary_logloss: 0.568513\n",
      "[110]\ttraining's binary_logloss: 0.568465\n",
      "[111]\ttraining's binary_logloss: 0.568384\n",
      "[112]\ttraining's binary_logloss: 0.568293\n",
      "[113]\ttraining's binary_logloss: 0.568207\n",
      "[114]\ttraining's binary_logloss: 0.568118\n",
      "[115]\ttraining's binary_logloss: 0.568071\n",
      "[116]\ttraining's binary_logloss: 0.567989\n",
      "[117]\ttraining's binary_logloss: 0.567883\n",
      "[118]\ttraining's binary_logloss: 0.567819\n",
      "[119]\ttraining's binary_logloss: 0.567791\n",
      "[120]\ttraining's binary_logloss: 0.567724\n",
      "[121]\ttraining's binary_logloss: 0.567612\n",
      "[122]\ttraining's binary_logloss: 0.567523\n",
      "[123]\ttraining's binary_logloss: 0.567451\n",
      "[124]\ttraining's binary_logloss: 0.567367\n",
      "[125]\ttraining's binary_logloss: 0.567294\n",
      "[126]\ttraining's binary_logloss: 0.567196\n",
      "[127]\ttraining's binary_logloss: 0.567105\n",
      "[128]\ttraining's binary_logloss: 0.567018\n",
      "[129]\ttraining's binary_logloss: 0.566924\n",
      "[130]\ttraining's binary_logloss: 0.566836\n",
      "[131]\ttraining's binary_logloss: 0.566744\n",
      "[132]\ttraining's binary_logloss: 0.56666\n",
      "[133]\ttraining's binary_logloss: 0.56658\n",
      "[134]\ttraining's binary_logloss: 0.566501\n",
      "[135]\ttraining's binary_logloss: 0.566432\n",
      "[136]\ttraining's binary_logloss: 0.566362\n",
      "[137]\ttraining's binary_logloss: 0.566286\n",
      "[138]\ttraining's binary_logloss: 0.566229\n",
      "[139]\ttraining's binary_logloss: 0.566167\n",
      "[140]\ttraining's binary_logloss: 0.566087\n",
      "[141]\ttraining's binary_logloss: 0.566045\n",
      "[142]\ttraining's binary_logloss: 0.565957\n",
      "[143]\ttraining's binary_logloss: 0.565875\n",
      "[144]\ttraining's binary_logloss: 0.565805\n",
      "[145]\ttraining's binary_logloss: 0.565745\n",
      "[146]\ttraining's binary_logloss: 0.565683\n",
      "[147]\ttraining's binary_logloss: 0.565632\n",
      "[148]\ttraining's binary_logloss: 0.565536\n",
      "[149]\ttraining's binary_logloss: 0.565486\n",
      "[150]\ttraining's binary_logloss: 0.565394\n",
      "[151]\ttraining's binary_logloss: 0.565313\n",
      "[152]\ttraining's binary_logloss: 0.565214\n",
      "[153]\ttraining's binary_logloss: 0.565098\n",
      "[154]\ttraining's binary_logloss: 0.564995\n",
      "[155]\ttraining's binary_logloss: 0.564928\n",
      "[156]\ttraining's binary_logloss: 0.56486\n",
      "[157]\ttraining's binary_logloss: 0.564804\n",
      "[158]\ttraining's binary_logloss: 0.564758\n",
      "[159]\ttraining's binary_logloss: 0.564705\n",
      "[160]\ttraining's binary_logloss: 0.564636\n",
      "[161]\ttraining's binary_logloss: 0.564509\n",
      "[162]\ttraining's binary_logloss: 0.564434\n",
      "[163]\ttraining's binary_logloss: 0.564363\n",
      "[164]\ttraining's binary_logloss: 0.564266\n",
      "[165]\ttraining's binary_logloss: 0.564211\n",
      "[166]\ttraining's binary_logloss: 0.564113\n",
      "[167]\ttraining's binary_logloss: 0.564048\n",
      "[168]\ttraining's binary_logloss: 0.563947\n",
      "[169]\ttraining's binary_logloss: 0.563853\n",
      "[170]\ttraining's binary_logloss: 0.56376\n",
      "[171]\ttraining's binary_logloss: 0.563644\n",
      "[172]\ttraining's binary_logloss: 0.563537\n",
      "[173]\ttraining's binary_logloss: 0.563426\n",
      "[174]\ttraining's binary_logloss: 0.563323\n",
      "[175]\ttraining's binary_logloss: 0.563264\n",
      "[176]\ttraining's binary_logloss: 0.563184\n",
      "[177]\ttraining's binary_logloss: 0.563114\n",
      "[178]\ttraining's binary_logloss: 0.563044\n",
      "[179]\ttraining's binary_logloss: 0.562972\n",
      "[180]\ttraining's binary_logloss: 0.562907\n",
      "[181]\ttraining's binary_logloss: 0.562826\n",
      "[182]\ttraining's binary_logloss: 0.562775\n",
      "[183]\ttraining's binary_logloss: 0.562727\n",
      "[184]\ttraining's binary_logloss: 0.562669\n",
      "[185]\ttraining's binary_logloss: 0.562623\n",
      "[186]\ttraining's binary_logloss: 0.562522\n",
      "[187]\ttraining's binary_logloss: 0.562447\n",
      "[188]\ttraining's binary_logloss: 0.562377\n",
      "[189]\ttraining's binary_logloss: 0.562321\n",
      "[190]\ttraining's binary_logloss: 0.562239\n",
      "[191]\ttraining's binary_logloss: 0.562155\n",
      "[192]\ttraining's binary_logloss: 0.562063\n",
      "[193]\ttraining's binary_logloss: 0.561989\n",
      "[194]\ttraining's binary_logloss: 0.561899\n",
      "[195]\ttraining's binary_logloss: 0.561828\n",
      "[196]\ttraining's binary_logloss: 0.561762\n",
      "[197]\ttraining's binary_logloss: 0.561654\n",
      "[198]\ttraining's binary_logloss: 0.561585\n",
      "[199]\ttraining's binary_logloss: 0.561487\n",
      "[200]\ttraining's binary_logloss: 0.561425\n",
      "[201]\ttraining's binary_logloss: 0.561309\n",
      "[202]\ttraining's binary_logloss: 0.561217\n",
      "[203]\ttraining's binary_logloss: 0.561132\n",
      "[204]\ttraining's binary_logloss: 0.561039\n",
      "[205]\ttraining's binary_logloss: 0.560933\n",
      "[206]\ttraining's binary_logloss: 0.56085\n",
      "[207]\ttraining's binary_logloss: 0.560771\n",
      "[208]\ttraining's binary_logloss: 0.560677\n",
      "[209]\ttraining's binary_logloss: 0.560599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[210]\ttraining's binary_logloss: 0.560529\n",
      "[211]\ttraining's binary_logloss: 0.560468\n",
      "[212]\ttraining's binary_logloss: 0.560412\n",
      "[213]\ttraining's binary_logloss: 0.560356\n",
      "[214]\ttraining's binary_logloss: 0.560304\n",
      "[215]\ttraining's binary_logloss: 0.560251\n",
      "[216]\ttraining's binary_logloss: 0.560123\n",
      "[217]\ttraining's binary_logloss: 0.56002\n",
      "[218]\ttraining's binary_logloss: 0.559924\n",
      "[219]\ttraining's binary_logloss: 0.559805\n",
      "[220]\ttraining's binary_logloss: 0.559698\n",
      "[221]\ttraining's binary_logloss: 0.559542\n",
      "[222]\ttraining's binary_logloss: 0.559391\n",
      "[223]\ttraining's binary_logloss: 0.559279\n",
      "[224]\ttraining's binary_logloss: 0.55913\n",
      "[225]\ttraining's binary_logloss: 0.559045\n",
      "[226]\ttraining's binary_logloss: 0.558984\n",
      "[227]\ttraining's binary_logloss: 0.558929\n",
      "[228]\ttraining's binary_logloss: 0.558835\n",
      "[229]\ttraining's binary_logloss: 0.558785\n",
      "[230]\ttraining's binary_logloss: 0.558687\n",
      "[231]\ttraining's binary_logloss: 0.558609\n",
      "[232]\ttraining's binary_logloss: 0.558533\n",
      "[233]\ttraining's binary_logloss: 0.558443\n",
      "[234]\ttraining's binary_logloss: 0.558351\n",
      "[235]\ttraining's binary_logloss: 0.558274\n",
      "[236]\ttraining's binary_logloss: 0.558159\n",
      "[237]\ttraining's binary_logloss: 0.55803\n",
      "[238]\ttraining's binary_logloss: 0.557894\n",
      "[239]\ttraining's binary_logloss: 0.557767\n",
      "[240]\ttraining's binary_logloss: 0.557646\n",
      "[241]\ttraining's binary_logloss: 0.557561\n",
      "[242]\ttraining's binary_logloss: 0.557482\n",
      "[243]\ttraining's binary_logloss: 0.557374\n",
      "[244]\ttraining's binary_logloss: 0.557281\n",
      "[245]\ttraining's binary_logloss: 0.55718\n",
      "[246]\ttraining's binary_logloss: 0.557069\n",
      "[247]\ttraining's binary_logloss: 0.556958\n",
      "[248]\ttraining's binary_logloss: 0.556852\n",
      "[249]\ttraining's binary_logloss: 0.55675\n",
      "[250]\ttraining's binary_logloss: 0.55667\n",
      "[251]\ttraining's binary_logloss: 0.556591\n",
      "[252]\ttraining's binary_logloss: 0.556525\n",
      "[253]\ttraining's binary_logloss: 0.556438\n",
      "[254]\ttraining's binary_logloss: 0.556345\n",
      "[255]\ttraining's binary_logloss: 0.556251\n",
      "[256]\ttraining's binary_logloss: 0.556116\n",
      "[257]\ttraining's binary_logloss: 0.555985\n",
      "[258]\ttraining's binary_logloss: 0.555869\n",
      "[259]\ttraining's binary_logloss: 0.555738\n",
      "[260]\ttraining's binary_logloss: 0.555623\n",
      "[261]\ttraining's binary_logloss: 0.555511\n",
      "[262]\ttraining's binary_logloss: 0.555436\n",
      "[263]\ttraining's binary_logloss: 0.555354\n",
      "[264]\ttraining's binary_logloss: 0.555249\n",
      "[265]\ttraining's binary_logloss: 0.555129\n",
      "[266]\ttraining's binary_logloss: 0.555089\n",
      "[267]\ttraining's binary_logloss: 0.555051\n",
      "[268]\ttraining's binary_logloss: 0.55502\n",
      "[269]\ttraining's binary_logloss: 0.55498\n",
      "[270]\ttraining's binary_logloss: 0.554922\n",
      "[271]\ttraining's binary_logloss: 0.554771\n",
      "[272]\ttraining's binary_logloss: 0.554622\n",
      "[273]\ttraining's binary_logloss: 0.554477\n",
      "[274]\ttraining's binary_logloss: 0.55434\n",
      "[275]\ttraining's binary_logloss: 0.554203\n",
      "[276]\ttraining's binary_logloss: 0.55404\n",
      "[277]\ttraining's binary_logloss: 0.553902\n",
      "[278]\ttraining's binary_logloss: 0.55375\n",
      "[279]\ttraining's binary_logloss: 0.553601\n",
      "[280]\ttraining's binary_logloss: 0.553448\n",
      "[281]\ttraining's binary_logloss: 0.553352\n",
      "[282]\ttraining's binary_logloss: 0.553224\n",
      "[283]\ttraining's binary_logloss: 0.553104\n",
      "[284]\ttraining's binary_logloss: 0.552983\n",
      "[285]\ttraining's binary_logloss: 0.55287\n",
      "[286]\ttraining's binary_logloss: 0.552751\n",
      "[287]\ttraining's binary_logloss: 0.552652\n",
      "[288]\ttraining's binary_logloss: 0.552552\n",
      "[289]\ttraining's binary_logloss: 0.552458\n",
      "[290]\ttraining's binary_logloss: 0.552361\n",
      "[291]\ttraining's binary_logloss: 0.552221\n",
      "[292]\ttraining's binary_logloss: 0.552085\n",
      "[293]\ttraining's binary_logloss: 0.551968\n",
      "[294]\ttraining's binary_logloss: 0.551819\n",
      "[295]\ttraining's binary_logloss: 0.551679\n",
      "[296]\ttraining's binary_logloss: 0.551567\n",
      "[297]\ttraining's binary_logloss: 0.55146\n",
      "[298]\ttraining's binary_logloss: 0.551363\n",
      "[299]\ttraining's binary_logloss: 0.551261\n",
      "[300]\ttraining's binary_logloss: 0.551155\n",
      "[301]\ttraining's binary_logloss: 0.550998\n",
      "[302]\ttraining's binary_logloss: 0.550839\n",
      "[303]\ttraining's binary_logloss: 0.550729\n",
      "[304]\ttraining's binary_logloss: 0.55059\n",
      "[305]\ttraining's binary_logloss: 0.550456\n",
      "[306]\ttraining's binary_logloss: 0.550343\n",
      "[307]\ttraining's binary_logloss: 0.550222\n",
      "[308]\ttraining's binary_logloss: 0.550096\n",
      "[309]\ttraining's binary_logloss: 0.549965\n",
      "[310]\ttraining's binary_logloss: 0.549857\n",
      "[311]\ttraining's binary_logloss: 0.54975\n",
      "[312]\ttraining's binary_logloss: 0.549643\n",
      "[313]\ttraining's binary_logloss: 0.549538\n",
      "[314]\ttraining's binary_logloss: 0.549446\n",
      "[315]\ttraining's binary_logloss: 0.5493\n",
      "[316]\ttraining's binary_logloss: 0.549201\n",
      "[317]\ttraining's binary_logloss: 0.549073\n",
      "[318]\ttraining's binary_logloss: 0.548964\n",
      "[319]\ttraining's binary_logloss: 0.548853\n",
      "[320]\ttraining's binary_logloss: 0.548745\n",
      "[321]\ttraining's binary_logloss: 0.548658\n",
      "[322]\ttraining's binary_logloss: 0.548553\n",
      "[323]\ttraining's binary_logloss: 0.548425\n",
      "[324]\ttraining's binary_logloss: 0.548335\n",
      "[325]\ttraining's binary_logloss: 0.548268\n",
      "[326]\ttraining's binary_logloss: 0.548142\n",
      "[327]\ttraining's binary_logloss: 0.548038\n",
      "[328]\ttraining's binary_logloss: 0.54791\n",
      "[329]\ttraining's binary_logloss: 0.547784\n",
      "[330]\ttraining's binary_logloss: 0.547665\n",
      "[331]\ttraining's binary_logloss: 0.547526\n",
      "[332]\ttraining's binary_logloss: 0.547382\n",
      "[333]\ttraining's binary_logloss: 0.547257\n",
      "[334]\ttraining's binary_logloss: 0.547076\n",
      "[335]\ttraining's binary_logloss: 0.546961\n",
      "[336]\ttraining's binary_logloss: 0.546832\n",
      "[337]\ttraining's binary_logloss: 0.546715\n",
      "[338]\ttraining's binary_logloss: 0.546593\n",
      "[339]\ttraining's binary_logloss: 0.546482\n",
      "[340]\ttraining's binary_logloss: 0.546367\n",
      "[341]\ttraining's binary_logloss: 0.546253\n",
      "[342]\ttraining's binary_logloss: 0.546139\n",
      "[343]\ttraining's binary_logloss: 0.546025\n",
      "[344]\ttraining's binary_logloss: 0.545912\n",
      "[345]\ttraining's binary_logloss: 0.545809\n",
      "[346]\ttraining's binary_logloss: 0.545691\n",
      "[347]\ttraining's binary_logloss: 0.545577\n",
      "[348]\ttraining's binary_logloss: 0.545461\n",
      "[349]\ttraining's binary_logloss: 0.545336\n",
      "[350]\ttraining's binary_logloss: 0.545205\n",
      "[351]\ttraining's binary_logloss: 0.545088\n",
      "[352]\ttraining's binary_logloss: 0.544957\n",
      "[353]\ttraining's binary_logloss: 0.544847\n",
      "[354]\ttraining's binary_logloss: 0.544694\n",
      "[355]\ttraining's binary_logloss: 0.544537\n",
      "[356]\ttraining's binary_logloss: 0.54436\n",
      "[357]\ttraining's binary_logloss: 0.544206\n",
      "[358]\ttraining's binary_logloss: 0.544039\n",
      "[359]\ttraining's binary_logloss: 0.543879\n",
      "[360]\ttraining's binary_logloss: 0.543726\n",
      "[361]\ttraining's binary_logloss: 0.543559\n",
      "[362]\ttraining's binary_logloss: 0.54342\n",
      "[363]\ttraining's binary_logloss: 0.54326\n",
      "[364]\ttraining's binary_logloss: 0.543103\n",
      "[365]\ttraining's binary_logloss: 0.542953\n",
      "[366]\ttraining's binary_logloss: 0.542876\n",
      "[367]\ttraining's binary_logloss: 0.542721\n",
      "[368]\ttraining's binary_logloss: 0.542571\n",
      "[369]\ttraining's binary_logloss: 0.54245\n",
      "[370]\ttraining's binary_logloss: 0.542308\n",
      "[371]\ttraining's binary_logloss: 0.542212\n",
      "[372]\ttraining's binary_logloss: 0.542121\n",
      "[373]\ttraining's binary_logloss: 0.542019\n",
      "[374]\ttraining's binary_logloss: 0.541927\n",
      "[375]\ttraining's binary_logloss: 0.541843\n",
      "[376]\ttraining's binary_logloss: 0.541719\n",
      "[377]\ttraining's binary_logloss: 0.541593\n",
      "[378]\ttraining's binary_logloss: 0.541445\n",
      "[379]\ttraining's binary_logloss: 0.541325\n",
      "[380]\ttraining's binary_logloss: 0.541192\n",
      "[381]\ttraining's binary_logloss: 0.541113\n",
      "[382]\ttraining's binary_logloss: 0.541023\n",
      "[383]\ttraining's binary_logloss: 0.540935\n",
      "[384]\ttraining's binary_logloss: 0.540849\n",
      "[385]\ttraining's binary_logloss: 0.540736\n",
      "[386]\ttraining's binary_logloss: 0.540583\n",
      "[387]\ttraining's binary_logloss: 0.540431\n",
      "[388]\ttraining's binary_logloss: 0.540277\n",
      "[389]\ttraining's binary_logloss: 0.540103\n",
      "[390]\ttraining's binary_logloss: 0.539944\n",
      "[391]\ttraining's binary_logloss: 0.539798\n",
      "[392]\ttraining's binary_logloss: 0.539662\n",
      "[393]\ttraining's binary_logloss: 0.539553\n",
      "[394]\ttraining's binary_logloss: 0.5394\n",
      "[395]\ttraining's binary_logloss: 0.53926\n",
      "[396]\ttraining's binary_logloss: 0.53913\n",
      "[397]\ttraining's binary_logloss: 0.538989\n",
      "[398]\ttraining's binary_logloss: 0.538831\n",
      "[399]\ttraining's binary_logloss: 0.538702\n",
      "[400]\ttraining's binary_logloss: 0.53858\n",
      "[401]\ttraining's binary_logloss: 0.538438\n",
      "[402]\ttraining's binary_logloss: 0.538292\n",
      "[403]\ttraining's binary_logloss: 0.538172\n",
      "[404]\ttraining's binary_logloss: 0.538048\n",
      "[405]\ttraining's binary_logloss: 0.537933\n",
      "[406]\ttraining's binary_logloss: 0.537796\n",
      "[407]\ttraining's binary_logloss: 0.537678\n",
      "[408]\ttraining's binary_logloss: 0.537549\n",
      "[409]\ttraining's binary_logloss: 0.53742\n",
      "[410]\ttraining's binary_logloss: 0.537282\n",
      "[411]\ttraining's binary_logloss: 0.537157\n",
      "[412]\ttraining's binary_logloss: 0.53702\n",
      "[413]\ttraining's binary_logloss: 0.536877\n",
      "[414]\ttraining's binary_logloss: 0.536694\n",
      "[415]\ttraining's binary_logloss: 0.536515\n",
      "[416]\ttraining's binary_logloss: 0.536374\n",
      "[417]\ttraining's binary_logloss: 0.536239\n",
      "[418]\ttraining's binary_logloss: 0.536102\n",
      "[419]\ttraining's binary_logloss: 0.535958\n",
      "[420]\ttraining's binary_logloss: 0.535825\n",
      "[421]\ttraining's binary_logloss: 0.535691\n",
      "[422]\ttraining's binary_logloss: 0.535571\n",
      "[423]\ttraining's binary_logloss: 0.53548\n",
      "[424]\ttraining's binary_logloss: 0.535351\n",
      "[425]\ttraining's binary_logloss: 0.535249\n",
      "[426]\ttraining's binary_logloss: 0.53511\n",
      "[427]\ttraining's binary_logloss: 0.534968\n",
      "[428]\ttraining's binary_logloss: 0.53484\n",
      "[429]\ttraining's binary_logloss: 0.534711\n",
      "[430]\ttraining's binary_logloss: 0.534581\n",
      "[431]\ttraining's binary_logloss: 0.534425\n",
      "[432]\ttraining's binary_logloss: 0.534245\n",
      "[433]\ttraining's binary_logloss: 0.534066\n",
      "[434]\ttraining's binary_logloss: 0.533913\n",
      "[435]\ttraining's binary_logloss: 0.533796\n",
      "[436]\ttraining's binary_logloss: 0.533639\n",
      "[437]\ttraining's binary_logloss: 0.533464\n",
      "[438]\ttraining's binary_logloss: 0.533301\n",
      "[439]\ttraining's binary_logloss: 0.533143\n",
      "[440]\ttraining's binary_logloss: 0.532992\n",
      "[441]\ttraining's binary_logloss: 0.532865\n",
      "[442]\ttraining's binary_logloss: 0.532736\n",
      "[443]\ttraining's binary_logloss: 0.532615\n",
      "[444]\ttraining's binary_logloss: 0.532475\n",
      "[445]\ttraining's binary_logloss: 0.532347\n",
      "[446]\ttraining's binary_logloss: 0.53222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[447]\ttraining's binary_logloss: 0.532079\n",
      "[448]\ttraining's binary_logloss: 0.531942\n",
      "[449]\ttraining's binary_logloss: 0.531805\n",
      "[450]\ttraining's binary_logloss: 0.531673\n",
      "[451]\ttraining's binary_logloss: 0.531547\n",
      "[452]\ttraining's binary_logloss: 0.531412\n",
      "[453]\ttraining's binary_logloss: 0.531303\n",
      "[454]\ttraining's binary_logloss: 0.531188\n",
      "[455]\ttraining's binary_logloss: 0.531044\n",
      "[456]\ttraining's binary_logloss: 0.530932\n",
      "[457]\ttraining's binary_logloss: 0.530833\n",
      "[458]\ttraining's binary_logloss: 0.530735\n",
      "[459]\ttraining's binary_logloss: 0.530633\n",
      "[460]\ttraining's binary_logloss: 0.530531\n",
      "[461]\ttraining's binary_logloss: 0.530403\n",
      "[462]\ttraining's binary_logloss: 0.53025\n",
      "[463]\ttraining's binary_logloss: 0.530103\n",
      "[464]\ttraining's binary_logloss: 0.529974\n",
      "[465]\ttraining's binary_logloss: 0.529848\n",
      "[466]\ttraining's binary_logloss: 0.529727\n",
      "[467]\ttraining's binary_logloss: 0.529575\n",
      "[468]\ttraining's binary_logloss: 0.529448\n",
      "[469]\ttraining's binary_logloss: 0.529316\n",
      "[470]\ttraining's binary_logloss: 0.529199\n",
      "[471]\ttraining's binary_logloss: 0.529088\n",
      "[472]\ttraining's binary_logloss: 0.528978\n",
      "[473]\ttraining's binary_logloss: 0.528869\n",
      "[474]\ttraining's binary_logloss: 0.528748\n",
      "[475]\ttraining's binary_logloss: 0.528632\n",
      "[476]\ttraining's binary_logloss: 0.528498\n",
      "[477]\ttraining's binary_logloss: 0.528365\n",
      "[478]\ttraining's binary_logloss: 0.528252\n",
      "[479]\ttraining's binary_logloss: 0.528143\n",
      "[480]\ttraining's binary_logloss: 0.528014\n",
      "[481]\ttraining's binary_logloss: 0.527885\n",
      "[482]\ttraining's binary_logloss: 0.52777\n",
      "[483]\ttraining's binary_logloss: 0.527668\n",
      "[484]\ttraining's binary_logloss: 0.52754\n",
      "[485]\ttraining's binary_logloss: 0.527419\n",
      "[486]\ttraining's binary_logloss: 0.527253\n",
      "[487]\ttraining's binary_logloss: 0.527091\n",
      "[488]\ttraining's binary_logloss: 0.526943\n",
      "[489]\ttraining's binary_logloss: 0.526794\n",
      "[490]\ttraining's binary_logloss: 0.526651\n",
      "[491]\ttraining's binary_logloss: 0.526539\n",
      "[492]\ttraining's binary_logloss: 0.526427\n",
      "[493]\ttraining's binary_logloss: 0.526317\n",
      "[494]\ttraining's binary_logloss: 0.526214\n",
      "[495]\ttraining's binary_logloss: 0.526116\n",
      "[496]\ttraining's binary_logloss: 0.525977\n",
      "[497]\ttraining's binary_logloss: 0.525816\n",
      "[498]\ttraining's binary_logloss: 0.525685\n",
      "[499]\ttraining's binary_logloss: 0.525521\n",
      "[500]\ttraining's binary_logloss: 0.52536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613033\n",
      "[2]\ttraining's binary_logloss: 0.611708\n",
      "[3]\ttraining's binary_logloss: 0.610491\n",
      "[4]\ttraining's binary_logloss: 0.60927\n",
      "[5]\ttraining's binary_logloss: 0.608083\n",
      "[6]\ttraining's binary_logloss: 0.606908\n",
      "[7]\ttraining's binary_logloss: 0.605795\n",
      "[8]\ttraining's binary_logloss: 0.604721\n",
      "[9]\ttraining's binary_logloss: 0.603756\n",
      "[10]\ttraining's binary_logloss: 0.602695\n",
      "[11]\ttraining's binary_logloss: 0.601776\n",
      "[12]\ttraining's binary_logloss: 0.600759\n",
      "[13]\ttraining's binary_logloss: 0.599774\n",
      "[14]\ttraining's binary_logloss: 0.598934\n",
      "[15]\ttraining's binary_logloss: 0.598015\n",
      "[16]\ttraining's binary_logloss: 0.597073\n",
      "[17]\ttraining's binary_logloss: 0.596166\n",
      "[18]\ttraining's binary_logloss: 0.595292\n",
      "[19]\ttraining's binary_logloss: 0.594444\n",
      "[20]\ttraining's binary_logloss: 0.593637\n",
      "[21]\ttraining's binary_logloss: 0.592907\n",
      "[22]\ttraining's binary_logloss: 0.592217\n",
      "[23]\ttraining's binary_logloss: 0.591576\n",
      "[24]\ttraining's binary_logloss: 0.59093\n",
      "[25]\ttraining's binary_logloss: 0.590241\n",
      "[26]\ttraining's binary_logloss: 0.589567\n",
      "[27]\ttraining's binary_logloss: 0.589019\n",
      "[28]\ttraining's binary_logloss: 0.588419\n",
      "[29]\ttraining's binary_logloss: 0.587844\n",
      "[30]\ttraining's binary_logloss: 0.587269\n",
      "[31]\ttraining's binary_logloss: 0.586695\n",
      "[32]\ttraining's binary_logloss: 0.586155\n",
      "[33]\ttraining's binary_logloss: 0.585768\n",
      "[34]\ttraining's binary_logloss: 0.585296\n",
      "[35]\ttraining's binary_logloss: 0.584766\n",
      "[36]\ttraining's binary_logloss: 0.584315\n",
      "[37]\ttraining's binary_logloss: 0.583959\n",
      "[38]\ttraining's binary_logloss: 0.583473\n",
      "[39]\ttraining's binary_logloss: 0.583024\n",
      "[40]\ttraining's binary_logloss: 0.582594\n",
      "[41]\ttraining's binary_logloss: 0.582144\n",
      "[42]\ttraining's binary_logloss: 0.58185\n",
      "[43]\ttraining's binary_logloss: 0.581572\n",
      "[44]\ttraining's binary_logloss: 0.581169\n",
      "[45]\ttraining's binary_logloss: 0.580791\n",
      "[46]\ttraining's binary_logloss: 0.580396\n",
      "[47]\ttraining's binary_logloss: 0.579989\n",
      "[48]\ttraining's binary_logloss: 0.579653\n",
      "[49]\ttraining's binary_logloss: 0.579314\n",
      "[50]\ttraining's binary_logloss: 0.578968\n",
      "[51]\ttraining's binary_logloss: 0.57863\n",
      "[52]\ttraining's binary_logloss: 0.578362\n",
      "[53]\ttraining's binary_logloss: 0.578118\n",
      "[54]\ttraining's binary_logloss: 0.577858\n",
      "[55]\ttraining's binary_logloss: 0.577564\n",
      "[56]\ttraining's binary_logloss: 0.577322\n",
      "[57]\ttraining's binary_logloss: 0.577078\n",
      "[58]\ttraining's binary_logloss: 0.576846\n",
      "[59]\ttraining's binary_logloss: 0.576619\n",
      "[60]\ttraining's binary_logloss: 0.576346\n",
      "[61]\ttraining's binary_logloss: 0.576144\n",
      "[62]\ttraining's binary_logloss: 0.575961\n",
      "[63]\ttraining's binary_logloss: 0.575769\n",
      "[64]\ttraining's binary_logloss: 0.575477\n",
      "[65]\ttraining's binary_logloss: 0.575303\n",
      "[66]\ttraining's binary_logloss: 0.575055\n",
      "[67]\ttraining's binary_logloss: 0.574828\n",
      "[68]\ttraining's binary_logloss: 0.574638\n",
      "[69]\ttraining's binary_logloss: 0.574459\n",
      "[70]\ttraining's binary_logloss: 0.574252\n",
      "[71]\ttraining's binary_logloss: 0.574018\n",
      "[72]\ttraining's binary_logloss: 0.573794\n",
      "[73]\ttraining's binary_logloss: 0.573583\n",
      "[74]\ttraining's binary_logloss: 0.573379\n",
      "[75]\ttraining's binary_logloss: 0.573189\n",
      "[76]\ttraining's binary_logloss: 0.573011\n",
      "[77]\ttraining's binary_logloss: 0.572848\n",
      "[78]\ttraining's binary_logloss: 0.572696\n",
      "[79]\ttraining's binary_logloss: 0.572566\n",
      "[80]\ttraining's binary_logloss: 0.572474\n",
      "[81]\ttraining's binary_logloss: 0.572333\n",
      "[82]\ttraining's binary_logloss: 0.572143\n",
      "[83]\ttraining's binary_logloss: 0.571973\n",
      "[84]\ttraining's binary_logloss: 0.571799\n",
      "[85]\ttraining's binary_logloss: 0.571642\n",
      "[86]\ttraining's binary_logloss: 0.571496\n",
      "[87]\ttraining's binary_logloss: 0.571321\n",
      "[88]\ttraining's binary_logloss: 0.571187\n",
      "[89]\ttraining's binary_logloss: 0.571019\n",
      "[90]\ttraining's binary_logloss: 0.570898\n",
      "[91]\ttraining's binary_logloss: 0.570819\n",
      "[92]\ttraining's binary_logloss: 0.570745\n",
      "[93]\ttraining's binary_logloss: 0.570691\n",
      "[94]\ttraining's binary_logloss: 0.570568\n",
      "[95]\ttraining's binary_logloss: 0.570515\n",
      "[96]\ttraining's binary_logloss: 0.570422\n",
      "[97]\ttraining's binary_logloss: 0.570321\n",
      "[98]\ttraining's binary_logloss: 0.570289\n",
      "[99]\ttraining's binary_logloss: 0.570212\n",
      "[100]\ttraining's binary_logloss: 0.57012\n",
      "[101]\ttraining's binary_logloss: 0.57004\n",
      "[102]\ttraining's binary_logloss: 0.570001\n",
      "[103]\ttraining's binary_logloss: 0.569932\n",
      "[104]\ttraining's binary_logloss: 0.569897\n",
      "[105]\ttraining's binary_logloss: 0.569822\n",
      "[106]\ttraining's binary_logloss: 0.569747\n",
      "[107]\ttraining's binary_logloss: 0.569689\n",
      "[108]\ttraining's binary_logloss: 0.569617\n",
      "[109]\ttraining's binary_logloss: 0.569554\n",
      "[110]\ttraining's binary_logloss: 0.569497\n",
      "[111]\ttraining's binary_logloss: 0.569433\n",
      "[112]\ttraining's binary_logloss: 0.569381\n",
      "[113]\ttraining's binary_logloss: 0.569305\n",
      "[114]\ttraining's binary_logloss: 0.569217\n",
      "[115]\ttraining's binary_logloss: 0.569175\n",
      "[116]\ttraining's binary_logloss: 0.569075\n",
      "[117]\ttraining's binary_logloss: 0.568952\n",
      "[118]\ttraining's binary_logloss: 0.568895\n",
      "[119]\ttraining's binary_logloss: 0.568851\n",
      "[120]\ttraining's binary_logloss: 0.568744\n",
      "[121]\ttraining's binary_logloss: 0.568679\n",
      "[122]\ttraining's binary_logloss: 0.568593\n",
      "[123]\ttraining's binary_logloss: 0.568524\n",
      "[124]\ttraining's binary_logloss: 0.568436\n",
      "[125]\ttraining's binary_logloss: 0.568355\n",
      "[126]\ttraining's binary_logloss: 0.568262\n",
      "[127]\ttraining's binary_logloss: 0.568158\n",
      "[128]\ttraining's binary_logloss: 0.568059\n",
      "[129]\ttraining's binary_logloss: 0.567983\n",
      "[130]\ttraining's binary_logloss: 0.567905\n",
      "[131]\ttraining's binary_logloss: 0.567811\n",
      "[132]\ttraining's binary_logloss: 0.567725\n",
      "[133]\ttraining's binary_logloss: 0.567645\n",
      "[134]\ttraining's binary_logloss: 0.56757\n",
      "[135]\ttraining's binary_logloss: 0.567543\n",
      "[136]\ttraining's binary_logloss: 0.567489\n",
      "[137]\ttraining's binary_logloss: 0.567441\n",
      "[138]\ttraining's binary_logloss: 0.5674\n",
      "[139]\ttraining's binary_logloss: 0.567364\n",
      "[140]\ttraining's binary_logloss: 0.567323\n",
      "[141]\ttraining's binary_logloss: 0.56723\n",
      "[142]\ttraining's binary_logloss: 0.567149\n",
      "[143]\ttraining's binary_logloss: 0.56708\n",
      "[144]\ttraining's binary_logloss: 0.567004\n",
      "[145]\ttraining's binary_logloss: 0.566927\n",
      "[146]\ttraining's binary_logloss: 0.566827\n",
      "[147]\ttraining's binary_logloss: 0.56672\n",
      "[148]\ttraining's binary_logloss: 0.566616\n",
      "[149]\ttraining's binary_logloss: 0.566528\n",
      "[150]\ttraining's binary_logloss: 0.566429\n",
      "[151]\ttraining's binary_logloss: 0.566384\n",
      "[152]\ttraining's binary_logloss: 0.566326\n",
      "[153]\ttraining's binary_logloss: 0.566264\n",
      "[154]\ttraining's binary_logloss: 0.56621\n",
      "[155]\ttraining's binary_logloss: 0.566161\n",
      "[156]\ttraining's binary_logloss: 0.566119\n",
      "[157]\ttraining's binary_logloss: 0.566066\n",
      "[158]\ttraining's binary_logloss: 0.566025\n",
      "[159]\ttraining's binary_logloss: 0.565981\n",
      "[160]\ttraining's binary_logloss: 0.565948\n",
      "[161]\ttraining's binary_logloss: 0.565832\n",
      "[162]\ttraining's binary_logloss: 0.565729\n",
      "[163]\ttraining's binary_logloss: 0.565653\n",
      "[164]\ttraining's binary_logloss: 0.565538\n",
      "[165]\ttraining's binary_logloss: 0.565434\n",
      "[166]\ttraining's binary_logloss: 0.565333\n",
      "[167]\ttraining's binary_logloss: 0.565248\n",
      "[168]\ttraining's binary_logloss: 0.565166\n",
      "[169]\ttraining's binary_logloss: 0.565087\n",
      "[170]\ttraining's binary_logloss: 0.565024\n",
      "[171]\ttraining's binary_logloss: 0.564984\n",
      "[172]\ttraining's binary_logloss: 0.564967\n",
      "[173]\ttraining's binary_logloss: 0.564937\n",
      "[174]\ttraining's binary_logloss: 0.564915\n",
      "[175]\ttraining's binary_logloss: 0.564895\n",
      "[176]\ttraining's binary_logloss: 0.564835\n",
      "[177]\ttraining's binary_logloss: 0.564783\n",
      "[178]\ttraining's binary_logloss: 0.564729\n",
      "[179]\ttraining's binary_logloss: 0.56469\n",
      "[180]\ttraining's binary_logloss: 0.564639\n",
      "[181]\ttraining's binary_logloss: 0.56458\n",
      "[182]\ttraining's binary_logloss: 0.564514\n",
      "[183]\ttraining's binary_logloss: 0.564456\n",
      "[184]\ttraining's binary_logloss: 0.564426\n",
      "[185]\ttraining's binary_logloss: 0.564368\n",
      "[186]\ttraining's binary_logloss: 0.564316\n",
      "[187]\ttraining's binary_logloss: 0.564239\n",
      "[188]\ttraining's binary_logloss: 0.564196\n",
      "[189]\ttraining's binary_logloss: 0.564145\n",
      "[190]\ttraining's binary_logloss: 0.564096\n",
      "[191]\ttraining's binary_logloss: 0.564019\n",
      "[192]\ttraining's binary_logloss: 0.563931\n",
      "[193]\ttraining's binary_logloss: 0.563851\n",
      "[194]\ttraining's binary_logloss: 0.563779\n",
      "[195]\ttraining's binary_logloss: 0.563702\n",
      "[196]\ttraining's binary_logloss: 0.563664\n",
      "[197]\ttraining's binary_logloss: 0.563627\n",
      "[198]\ttraining's binary_logloss: 0.563585\n",
      "[199]\ttraining's binary_logloss: 0.563525\n",
      "[200]\ttraining's binary_logloss: 0.563491\n",
      "[201]\ttraining's binary_logloss: 0.563402\n",
      "[202]\ttraining's binary_logloss: 0.563338\n",
      "[203]\ttraining's binary_logloss: 0.563271\n",
      "[204]\ttraining's binary_logloss: 0.56318\n",
      "[205]\ttraining's binary_logloss: 0.563123\n",
      "[206]\ttraining's binary_logloss: 0.563062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[207]\ttraining's binary_logloss: 0.563033\n",
      "[208]\ttraining's binary_logloss: 0.562994\n",
      "[209]\ttraining's binary_logloss: 0.562966\n",
      "[210]\ttraining's binary_logloss: 0.562891\n",
      "[211]\ttraining's binary_logloss: 0.562824\n",
      "[212]\ttraining's binary_logloss: 0.56277\n",
      "[213]\ttraining's binary_logloss: 0.56271\n",
      "[214]\ttraining's binary_logloss: 0.562601\n",
      "[215]\ttraining's binary_logloss: 0.562548\n",
      "[216]\ttraining's binary_logloss: 0.562438\n",
      "[217]\ttraining's binary_logloss: 0.562331\n",
      "[218]\ttraining's binary_logloss: 0.562228\n",
      "[219]\ttraining's binary_logloss: 0.562134\n",
      "[220]\ttraining's binary_logloss: 0.562045\n",
      "[221]\ttraining's binary_logloss: 0.56193\n",
      "[222]\ttraining's binary_logloss: 0.561813\n",
      "[223]\ttraining's binary_logloss: 0.561701\n",
      "[224]\ttraining's binary_logloss: 0.56159\n",
      "[225]\ttraining's binary_logloss: 0.561492\n",
      "[226]\ttraining's binary_logloss: 0.561378\n",
      "[227]\ttraining's binary_logloss: 0.561283\n",
      "[228]\ttraining's binary_logloss: 0.561182\n",
      "[229]\ttraining's binary_logloss: 0.561074\n",
      "[230]\ttraining's binary_logloss: 0.560987\n",
      "[231]\ttraining's binary_logloss: 0.56087\n",
      "[232]\ttraining's binary_logloss: 0.560753\n",
      "[233]\ttraining's binary_logloss: 0.560674\n",
      "[234]\ttraining's binary_logloss: 0.560588\n",
      "[235]\ttraining's binary_logloss: 0.560483\n",
      "[236]\ttraining's binary_logloss: 0.560407\n",
      "[237]\ttraining's binary_logloss: 0.560325\n",
      "[238]\ttraining's binary_logloss: 0.560253\n",
      "[239]\ttraining's binary_logloss: 0.560146\n",
      "[240]\ttraining's binary_logloss: 0.560072\n",
      "[241]\ttraining's binary_logloss: 0.559952\n",
      "[242]\ttraining's binary_logloss: 0.55984\n",
      "[243]\ttraining's binary_logloss: 0.55972\n",
      "[244]\ttraining's binary_logloss: 0.559613\n",
      "[245]\ttraining's binary_logloss: 0.559512\n",
      "[246]\ttraining's binary_logloss: 0.559397\n",
      "[247]\ttraining's binary_logloss: 0.559258\n",
      "[248]\ttraining's binary_logloss: 0.559144\n",
      "[249]\ttraining's binary_logloss: 0.559033\n",
      "[250]\ttraining's binary_logloss: 0.558922\n",
      "[251]\ttraining's binary_logloss: 0.558862\n",
      "[252]\ttraining's binary_logloss: 0.558788\n",
      "[253]\ttraining's binary_logloss: 0.558733\n",
      "[254]\ttraining's binary_logloss: 0.558665\n",
      "[255]\ttraining's binary_logloss: 0.558612\n",
      "[256]\ttraining's binary_logloss: 0.55852\n",
      "[257]\ttraining's binary_logloss: 0.55839\n",
      "[258]\ttraining's binary_logloss: 0.558267\n",
      "[259]\ttraining's binary_logloss: 0.558136\n",
      "[260]\ttraining's binary_logloss: 0.557992\n",
      "[261]\ttraining's binary_logloss: 0.557895\n",
      "[262]\ttraining's binary_logloss: 0.557809\n",
      "[263]\ttraining's binary_logloss: 0.557733\n",
      "[264]\ttraining's binary_logloss: 0.557664\n",
      "[265]\ttraining's binary_logloss: 0.557566\n",
      "[266]\ttraining's binary_logloss: 0.557495\n",
      "[267]\ttraining's binary_logloss: 0.557435\n",
      "[268]\ttraining's binary_logloss: 0.557357\n",
      "[269]\ttraining's binary_logloss: 0.557277\n",
      "[270]\ttraining's binary_logloss: 0.5572\n",
      "[271]\ttraining's binary_logloss: 0.557039\n",
      "[272]\ttraining's binary_logloss: 0.556881\n",
      "[273]\ttraining's binary_logloss: 0.556731\n",
      "[274]\ttraining's binary_logloss: 0.556623\n",
      "[275]\ttraining's binary_logloss: 0.556475\n",
      "[276]\ttraining's binary_logloss: 0.556354\n",
      "[277]\ttraining's binary_logloss: 0.55626\n",
      "[278]\ttraining's binary_logloss: 0.556162\n",
      "[279]\ttraining's binary_logloss: 0.556051\n",
      "[280]\ttraining's binary_logloss: 0.555939\n",
      "[281]\ttraining's binary_logloss: 0.555803\n",
      "[282]\ttraining's binary_logloss: 0.555668\n",
      "[283]\ttraining's binary_logloss: 0.555548\n",
      "[284]\ttraining's binary_logloss: 0.555446\n",
      "[285]\ttraining's binary_logloss: 0.555308\n",
      "[286]\ttraining's binary_logloss: 0.555177\n",
      "[287]\ttraining's binary_logloss: 0.555046\n",
      "[288]\ttraining's binary_logloss: 0.554917\n",
      "[289]\ttraining's binary_logloss: 0.55478\n",
      "[290]\ttraining's binary_logloss: 0.554643\n",
      "[291]\ttraining's binary_logloss: 0.554487\n",
      "[292]\ttraining's binary_logloss: 0.554349\n",
      "[293]\ttraining's binary_logloss: 0.554203\n",
      "[294]\ttraining's binary_logloss: 0.55405\n",
      "[295]\ttraining's binary_logloss: 0.553908\n",
      "[296]\ttraining's binary_logloss: 0.553791\n",
      "[297]\ttraining's binary_logloss: 0.553676\n",
      "[298]\ttraining's binary_logloss: 0.553563\n",
      "[299]\ttraining's binary_logloss: 0.553456\n",
      "[300]\ttraining's binary_logloss: 0.553319\n",
      "[301]\ttraining's binary_logloss: 0.55319\n",
      "[302]\ttraining's binary_logloss: 0.5531\n",
      "[303]\ttraining's binary_logloss: 0.552958\n",
      "[304]\ttraining's binary_logloss: 0.552849\n",
      "[305]\ttraining's binary_logloss: 0.55274\n",
      "[306]\ttraining's binary_logloss: 0.552631\n",
      "[307]\ttraining's binary_logloss: 0.552497\n",
      "[308]\ttraining's binary_logloss: 0.552406\n",
      "[309]\ttraining's binary_logloss: 0.552276\n",
      "[310]\ttraining's binary_logloss: 0.552178\n",
      "[311]\ttraining's binary_logloss: 0.552056\n",
      "[312]\ttraining's binary_logloss: 0.5519\n",
      "[313]\ttraining's binary_logloss: 0.551792\n",
      "[314]\ttraining's binary_logloss: 0.551622\n",
      "[315]\ttraining's binary_logloss: 0.551479\n",
      "[316]\ttraining's binary_logloss: 0.551333\n",
      "[317]\ttraining's binary_logloss: 0.551199\n",
      "[318]\ttraining's binary_logloss: 0.551055\n",
      "[319]\ttraining's binary_logloss: 0.550936\n",
      "[320]\ttraining's binary_logloss: 0.550815\n",
      "[321]\ttraining's binary_logloss: 0.550707\n",
      "[322]\ttraining's binary_logloss: 0.550595\n",
      "[323]\ttraining's binary_logloss: 0.550484\n",
      "[324]\ttraining's binary_logloss: 0.550409\n",
      "[325]\ttraining's binary_logloss: 0.550293\n",
      "[326]\ttraining's binary_logloss: 0.550158\n",
      "[327]\ttraining's binary_logloss: 0.550042\n",
      "[328]\ttraining's binary_logloss: 0.549925\n",
      "[329]\ttraining's binary_logloss: 0.549791\n",
      "[330]\ttraining's binary_logloss: 0.549662\n",
      "[331]\ttraining's binary_logloss: 0.54954\n",
      "[332]\ttraining's binary_logloss: 0.549423\n",
      "[333]\ttraining's binary_logloss: 0.549301\n",
      "[334]\ttraining's binary_logloss: 0.549177\n",
      "[335]\ttraining's binary_logloss: 0.549086\n",
      "[336]\ttraining's binary_logloss: 0.548932\n",
      "[337]\ttraining's binary_logloss: 0.548792\n",
      "[338]\ttraining's binary_logloss: 0.54863\n",
      "[339]\ttraining's binary_logloss: 0.548493\n",
      "[340]\ttraining's binary_logloss: 0.548334\n",
      "[341]\ttraining's binary_logloss: 0.548254\n",
      "[342]\ttraining's binary_logloss: 0.548171\n",
      "[343]\ttraining's binary_logloss: 0.548063\n",
      "[344]\ttraining's binary_logloss: 0.547984\n",
      "[345]\ttraining's binary_logloss: 0.54791\n",
      "[346]\ttraining's binary_logloss: 0.547821\n",
      "[347]\ttraining's binary_logloss: 0.547726\n",
      "[348]\ttraining's binary_logloss: 0.547643\n",
      "[349]\ttraining's binary_logloss: 0.547552\n",
      "[350]\ttraining's binary_logloss: 0.547472\n",
      "[351]\ttraining's binary_logloss: 0.547316\n",
      "[352]\ttraining's binary_logloss: 0.547172\n",
      "[353]\ttraining's binary_logloss: 0.547009\n",
      "[354]\ttraining's binary_logloss: 0.546859\n",
      "[355]\ttraining's binary_logloss: 0.546691\n",
      "[356]\ttraining's binary_logloss: 0.546542\n",
      "[357]\ttraining's binary_logloss: 0.546402\n",
      "[358]\ttraining's binary_logloss: 0.546266\n",
      "[359]\ttraining's binary_logloss: 0.546116\n",
      "[360]\ttraining's binary_logloss: 0.545983\n",
      "[361]\ttraining's binary_logloss: 0.545823\n",
      "[362]\ttraining's binary_logloss: 0.545665\n",
      "[363]\ttraining's binary_logloss: 0.545511\n",
      "[364]\ttraining's binary_logloss: 0.545363\n",
      "[365]\ttraining's binary_logloss: 0.545214\n",
      "[366]\ttraining's binary_logloss: 0.545101\n",
      "[367]\ttraining's binary_logloss: 0.544974\n",
      "[368]\ttraining's binary_logloss: 0.544855\n",
      "[369]\ttraining's binary_logloss: 0.544725\n",
      "[370]\ttraining's binary_logloss: 0.544624\n",
      "[371]\ttraining's binary_logloss: 0.544538\n",
      "[372]\ttraining's binary_logloss: 0.544457\n",
      "[373]\ttraining's binary_logloss: 0.544375\n",
      "[374]\ttraining's binary_logloss: 0.544274\n",
      "[375]\ttraining's binary_logloss: 0.544204\n",
      "[376]\ttraining's binary_logloss: 0.54408\n",
      "[377]\ttraining's binary_logloss: 0.543948\n",
      "[378]\ttraining's binary_logloss: 0.54383\n",
      "[379]\ttraining's binary_logloss: 0.543699\n",
      "[380]\ttraining's binary_logloss: 0.543578\n",
      "[381]\ttraining's binary_logloss: 0.543481\n",
      "[382]\ttraining's binary_logloss: 0.543402\n",
      "[383]\ttraining's binary_logloss: 0.543311\n",
      "[384]\ttraining's binary_logloss: 0.543229\n",
      "[385]\ttraining's binary_logloss: 0.543137\n",
      "[386]\ttraining's binary_logloss: 0.542989\n",
      "[387]\ttraining's binary_logloss: 0.542875\n",
      "[388]\ttraining's binary_logloss: 0.542726\n",
      "[389]\ttraining's binary_logloss: 0.542587\n",
      "[390]\ttraining's binary_logloss: 0.542434\n",
      "[391]\ttraining's binary_logloss: 0.542303\n",
      "[392]\ttraining's binary_logloss: 0.542178\n",
      "[393]\ttraining's binary_logloss: 0.542031\n",
      "[394]\ttraining's binary_logloss: 0.541876\n",
      "[395]\ttraining's binary_logloss: 0.541721\n",
      "[396]\ttraining's binary_logloss: 0.541593\n",
      "[397]\ttraining's binary_logloss: 0.541474\n",
      "[398]\ttraining's binary_logloss: 0.541349\n",
      "[399]\ttraining's binary_logloss: 0.541248\n",
      "[400]\ttraining's binary_logloss: 0.541149\n",
      "[401]\ttraining's binary_logloss: 0.540998\n",
      "[402]\ttraining's binary_logloss: 0.54081\n",
      "[403]\ttraining's binary_logloss: 0.540629\n",
      "[404]\ttraining's binary_logloss: 0.54048\n",
      "[405]\ttraining's binary_logloss: 0.540353\n",
      "[406]\ttraining's binary_logloss: 0.540196\n",
      "[407]\ttraining's binary_logloss: 0.540052\n",
      "[408]\ttraining's binary_logloss: 0.539935\n",
      "[409]\ttraining's binary_logloss: 0.539793\n",
      "[410]\ttraining's binary_logloss: 0.539651\n",
      "[411]\ttraining's binary_logloss: 0.539486\n",
      "[412]\ttraining's binary_logloss: 0.539344\n",
      "[413]\ttraining's binary_logloss: 0.539211\n",
      "[414]\ttraining's binary_logloss: 0.539074\n",
      "[415]\ttraining's binary_logloss: 0.538956\n",
      "[416]\ttraining's binary_logloss: 0.538841\n",
      "[417]\ttraining's binary_logloss: 0.538728\n",
      "[418]\ttraining's binary_logloss: 0.538617\n",
      "[419]\ttraining's binary_logloss: 0.538523\n",
      "[420]\ttraining's binary_logloss: 0.538403\n",
      "[421]\ttraining's binary_logloss: 0.538313\n",
      "[422]\ttraining's binary_logloss: 0.538238\n",
      "[423]\ttraining's binary_logloss: 0.53816\n",
      "[424]\ttraining's binary_logloss: 0.538089\n",
      "[425]\ttraining's binary_logloss: 0.537989\n",
      "[426]\ttraining's binary_logloss: 0.537868\n",
      "[427]\ttraining's binary_logloss: 0.537758\n",
      "[428]\ttraining's binary_logloss: 0.537652\n",
      "[429]\ttraining's binary_logloss: 0.537525\n",
      "[430]\ttraining's binary_logloss: 0.537418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[431]\ttraining's binary_logloss: 0.537246\n",
      "[432]\ttraining's binary_logloss: 0.537078\n",
      "[433]\ttraining's binary_logloss: 0.536908\n",
      "[434]\ttraining's binary_logloss: 0.536719\n",
      "[435]\ttraining's binary_logloss: 0.536542\n",
      "[436]\ttraining's binary_logloss: 0.536424\n",
      "[437]\ttraining's binary_logloss: 0.536315\n",
      "[438]\ttraining's binary_logloss: 0.5362\n",
      "[439]\ttraining's binary_logloss: 0.536088\n",
      "[440]\ttraining's binary_logloss: 0.535989\n",
      "[441]\ttraining's binary_logloss: 0.535828\n",
      "[442]\ttraining's binary_logloss: 0.535659\n",
      "[443]\ttraining's binary_logloss: 0.535492\n",
      "[444]\ttraining's binary_logloss: 0.535328\n",
      "[445]\ttraining's binary_logloss: 0.535206\n",
      "[446]\ttraining's binary_logloss: 0.535069\n",
      "[447]\ttraining's binary_logloss: 0.534908\n",
      "[448]\ttraining's binary_logloss: 0.534756\n",
      "[449]\ttraining's binary_logloss: 0.534603\n",
      "[450]\ttraining's binary_logloss: 0.534456\n",
      "[451]\ttraining's binary_logloss: 0.534342\n",
      "[452]\ttraining's binary_logloss: 0.534239\n",
      "[453]\ttraining's binary_logloss: 0.534146\n",
      "[454]\ttraining's binary_logloss: 0.534045\n",
      "[455]\ttraining's binary_logloss: 0.53396\n",
      "[456]\ttraining's binary_logloss: 0.533847\n",
      "[457]\ttraining's binary_logloss: 0.533727\n",
      "[458]\ttraining's binary_logloss: 0.533609\n",
      "[459]\ttraining's binary_logloss: 0.533495\n",
      "[460]\ttraining's binary_logloss: 0.53336\n",
      "[461]\ttraining's binary_logloss: 0.533257\n",
      "[462]\ttraining's binary_logloss: 0.533142\n",
      "[463]\ttraining's binary_logloss: 0.533031\n",
      "[464]\ttraining's binary_logloss: 0.532925\n",
      "[465]\ttraining's binary_logloss: 0.532816\n",
      "[466]\ttraining's binary_logloss: 0.532676\n",
      "[467]\ttraining's binary_logloss: 0.532537\n",
      "[468]\ttraining's binary_logloss: 0.532384\n",
      "[469]\ttraining's binary_logloss: 0.532246\n",
      "[470]\ttraining's binary_logloss: 0.532128\n",
      "[471]\ttraining's binary_logloss: 0.532039\n",
      "[472]\ttraining's binary_logloss: 0.531943\n",
      "[473]\ttraining's binary_logloss: 0.53186\n",
      "[474]\ttraining's binary_logloss: 0.531768\n",
      "[475]\ttraining's binary_logloss: 0.531646\n",
      "[476]\ttraining's binary_logloss: 0.531464\n",
      "[477]\ttraining's binary_logloss: 0.531289\n",
      "[478]\ttraining's binary_logloss: 0.531112\n",
      "[479]\ttraining's binary_logloss: 0.53094\n",
      "[480]\ttraining's binary_logloss: 0.530818\n",
      "[481]\ttraining's binary_logloss: 0.530666\n",
      "[482]\ttraining's binary_logloss: 0.530525\n",
      "[483]\ttraining's binary_logloss: 0.530385\n",
      "[484]\ttraining's binary_logloss: 0.530249\n",
      "[485]\ttraining's binary_logloss: 0.530143\n",
      "[486]\ttraining's binary_logloss: 0.529976\n",
      "[487]\ttraining's binary_logloss: 0.529821\n",
      "[488]\ttraining's binary_logloss: 0.529659\n",
      "[489]\ttraining's binary_logloss: 0.5295\n",
      "[490]\ttraining's binary_logloss: 0.529353\n",
      "[491]\ttraining's binary_logloss: 0.529208\n",
      "[492]\ttraining's binary_logloss: 0.529059\n",
      "[493]\ttraining's binary_logloss: 0.528936\n",
      "[494]\ttraining's binary_logloss: 0.528812\n",
      "[495]\ttraining's binary_logloss: 0.528677\n",
      "[496]\ttraining's binary_logloss: 0.528546\n",
      "[497]\ttraining's binary_logloss: 0.528409\n",
      "[498]\ttraining's binary_logloss: 0.528282\n",
      "[499]\ttraining's binary_logloss: 0.528158\n",
      "[500]\ttraining's binary_logloss: 0.528039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.617435\n",
      "[2]\ttraining's binary_logloss: 0.616142\n",
      "[3]\ttraining's binary_logloss: 0.61489\n",
      "[4]\ttraining's binary_logloss: 0.613667\n",
      "[5]\ttraining's binary_logloss: 0.612505\n",
      "[6]\ttraining's binary_logloss: 0.611372\n",
      "[7]\ttraining's binary_logloss: 0.610305\n",
      "[8]\ttraining's binary_logloss: 0.609295\n",
      "[9]\ttraining's binary_logloss: 0.608229\n",
      "[10]\ttraining's binary_logloss: 0.607311\n",
      "[11]\ttraining's binary_logloss: 0.606247\n",
      "[12]\ttraining's binary_logloss: 0.605208\n",
      "[13]\ttraining's binary_logloss: 0.604256\n",
      "[14]\ttraining's binary_logloss: 0.603375\n",
      "[15]\ttraining's binary_logloss: 0.602503\n",
      "[16]\ttraining's binary_logloss: 0.601679\n",
      "[17]\ttraining's binary_logloss: 0.600882\n",
      "[18]\ttraining's binary_logloss: 0.600117\n",
      "[19]\ttraining's binary_logloss: 0.599394\n",
      "[20]\ttraining's binary_logloss: 0.598564\n",
      "[21]\ttraining's binary_logloss: 0.59777\n",
      "[22]\ttraining's binary_logloss: 0.597003\n",
      "[23]\ttraining's binary_logloss: 0.596288\n",
      "[24]\ttraining's binary_logloss: 0.59551\n",
      "[25]\ttraining's binary_logloss: 0.594801\n",
      "[26]\ttraining's binary_logloss: 0.594194\n",
      "[27]\ttraining's binary_logloss: 0.593552\n",
      "[28]\ttraining's binary_logloss: 0.592964\n",
      "[29]\ttraining's binary_logloss: 0.592405\n",
      "[30]\ttraining's binary_logloss: 0.59186\n",
      "[31]\ttraining's binary_logloss: 0.591349\n",
      "[32]\ttraining's binary_logloss: 0.590851\n",
      "[33]\ttraining's binary_logloss: 0.590377\n",
      "[34]\ttraining's binary_logloss: 0.589911\n",
      "[35]\ttraining's binary_logloss: 0.589383\n",
      "[36]\ttraining's binary_logloss: 0.588918\n",
      "[37]\ttraining's binary_logloss: 0.588558\n",
      "[38]\ttraining's binary_logloss: 0.588136\n",
      "[39]\ttraining's binary_logloss: 0.587744\n",
      "[40]\ttraining's binary_logloss: 0.587303\n",
      "[41]\ttraining's binary_logloss: 0.586925\n",
      "[42]\ttraining's binary_logloss: 0.586564\n",
      "[43]\ttraining's binary_logloss: 0.586218\n",
      "[44]\ttraining's binary_logloss: 0.585895\n",
      "[45]\ttraining's binary_logloss: 0.585604\n",
      "[46]\ttraining's binary_logloss: 0.585255\n",
      "[47]\ttraining's binary_logloss: 0.584923\n",
      "[48]\ttraining's binary_logloss: 0.584541\n",
      "[49]\ttraining's binary_logloss: 0.584177\n",
      "[50]\ttraining's binary_logloss: 0.583878\n",
      "[51]\ttraining's binary_logloss: 0.583526\n",
      "[52]\ttraining's binary_logloss: 0.583193\n",
      "[53]\ttraining's binary_logloss: 0.582873\n",
      "[54]\ttraining's binary_logloss: 0.582604\n",
      "[55]\ttraining's binary_logloss: 0.582351\n",
      "[56]\ttraining's binary_logloss: 0.582116\n",
      "[57]\ttraining's binary_logloss: 0.581835\n",
      "[58]\ttraining's binary_logloss: 0.581604\n",
      "[59]\ttraining's binary_logloss: 0.581397\n",
      "[60]\ttraining's binary_logloss: 0.581194\n",
      "[61]\ttraining's binary_logloss: 0.580924\n",
      "[62]\ttraining's binary_logloss: 0.580685\n",
      "[63]\ttraining's binary_logloss: 0.580456\n",
      "[64]\ttraining's binary_logloss: 0.580211\n",
      "[65]\ttraining's binary_logloss: 0.580005\n",
      "[66]\ttraining's binary_logloss: 0.579793\n",
      "[67]\ttraining's binary_logloss: 0.579541\n",
      "[68]\ttraining's binary_logloss: 0.579299\n",
      "[69]\ttraining's binary_logloss: 0.579057\n",
      "[70]\ttraining's binary_logloss: 0.578835\n",
      "[71]\ttraining's binary_logloss: 0.578616\n",
      "[72]\ttraining's binary_logloss: 0.578491\n",
      "[73]\ttraining's binary_logloss: 0.5783\n",
      "[74]\ttraining's binary_logloss: 0.57818\n",
      "[75]\ttraining's binary_logloss: 0.577996\n",
      "[76]\ttraining's binary_logloss: 0.5778\n",
      "[77]\ttraining's binary_logloss: 0.577598\n",
      "[78]\ttraining's binary_logloss: 0.577446\n",
      "[79]\ttraining's binary_logloss: 0.577261\n",
      "[80]\ttraining's binary_logloss: 0.577061\n",
      "[81]\ttraining's binary_logloss: 0.576879\n",
      "[82]\ttraining's binary_logloss: 0.576693\n",
      "[83]\ttraining's binary_logloss: 0.576524\n",
      "[84]\ttraining's binary_logloss: 0.576396\n",
      "[85]\ttraining's binary_logloss: 0.576232\n",
      "[86]\ttraining's binary_logloss: 0.576116\n",
      "[87]\ttraining's binary_logloss: 0.575994\n",
      "[88]\ttraining's binary_logloss: 0.575886\n",
      "[89]\ttraining's binary_logloss: 0.575783\n",
      "[90]\ttraining's binary_logloss: 0.575679\n",
      "[91]\ttraining's binary_logloss: 0.575524\n",
      "[92]\ttraining's binary_logloss: 0.575409\n",
      "[93]\ttraining's binary_logloss: 0.575247\n",
      "[94]\ttraining's binary_logloss: 0.575134\n",
      "[95]\ttraining's binary_logloss: 0.57508\n",
      "[96]\ttraining's binary_logloss: 0.575009\n",
      "[97]\ttraining's binary_logloss: 0.574917\n",
      "[98]\ttraining's binary_logloss: 0.574838\n",
      "[99]\ttraining's binary_logloss: 0.574776\n",
      "[100]\ttraining's binary_logloss: 0.574694\n",
      "[101]\ttraining's binary_logloss: 0.574621\n",
      "[102]\ttraining's binary_logloss: 0.574561\n",
      "[103]\ttraining's binary_logloss: 0.574503\n",
      "[104]\ttraining's binary_logloss: 0.574425\n",
      "[105]\ttraining's binary_logloss: 0.574349\n",
      "[106]\ttraining's binary_logloss: 0.574266\n",
      "[107]\ttraining's binary_logloss: 0.574143\n",
      "[108]\ttraining's binary_logloss: 0.574047\n",
      "[109]\ttraining's binary_logloss: 0.573938\n",
      "[110]\ttraining's binary_logloss: 0.573854\n",
      "[111]\ttraining's binary_logloss: 0.573793\n",
      "[112]\ttraining's binary_logloss: 0.573716\n",
      "[113]\ttraining's binary_logloss: 0.573669\n",
      "[114]\ttraining's binary_logloss: 0.573568\n",
      "[115]\ttraining's binary_logloss: 0.573496\n",
      "[116]\ttraining's binary_logloss: 0.573406\n",
      "[117]\ttraining's binary_logloss: 0.573316\n",
      "[118]\ttraining's binary_logloss: 0.5732\n",
      "[119]\ttraining's binary_logloss: 0.573131\n",
      "[120]\ttraining's binary_logloss: 0.573022\n",
      "[121]\ttraining's binary_logloss: 0.572964\n",
      "[122]\ttraining's binary_logloss: 0.572908\n",
      "[123]\ttraining's binary_logloss: 0.572862\n",
      "[124]\ttraining's binary_logloss: 0.572801\n",
      "[125]\ttraining's binary_logloss: 0.572761\n",
      "[126]\ttraining's binary_logloss: 0.572678\n",
      "[127]\ttraining's binary_logloss: 0.572577\n",
      "[128]\ttraining's binary_logloss: 0.5725\n",
      "[129]\ttraining's binary_logloss: 0.572399\n",
      "[130]\ttraining's binary_logloss: 0.572291\n",
      "[131]\ttraining's binary_logloss: 0.572173\n",
      "[132]\ttraining's binary_logloss: 0.572066\n",
      "[133]\ttraining's binary_logloss: 0.572028\n",
      "[134]\ttraining's binary_logloss: 0.571934\n",
      "[135]\ttraining's binary_logloss: 0.571835\n",
      "[136]\ttraining's binary_logloss: 0.571738\n",
      "[137]\ttraining's binary_logloss: 0.571665\n",
      "[138]\ttraining's binary_logloss: 0.571577\n",
      "[139]\ttraining's binary_logloss: 0.571499\n",
      "[140]\ttraining's binary_logloss: 0.571452\n",
      "[141]\ttraining's binary_logloss: 0.571364\n",
      "[142]\ttraining's binary_logloss: 0.571275\n",
      "[143]\ttraining's binary_logloss: 0.571164\n",
      "[144]\ttraining's binary_logloss: 0.571073\n",
      "[145]\ttraining's binary_logloss: 0.571041\n",
      "[146]\ttraining's binary_logloss: 0.571003\n",
      "[147]\ttraining's binary_logloss: 0.570921\n",
      "[148]\ttraining's binary_logloss: 0.570867\n",
      "[149]\ttraining's binary_logloss: 0.570808\n",
      "[150]\ttraining's binary_logloss: 0.57069\n",
      "[151]\ttraining's binary_logloss: 0.57064\n",
      "[152]\ttraining's binary_logloss: 0.570593\n",
      "[153]\ttraining's binary_logloss: 0.570565\n",
      "[154]\ttraining's binary_logloss: 0.570503\n",
      "[155]\ttraining's binary_logloss: 0.570466\n",
      "[156]\ttraining's binary_logloss: 0.570394\n",
      "[157]\ttraining's binary_logloss: 0.570312\n",
      "[158]\ttraining's binary_logloss: 0.570237\n",
      "[159]\ttraining's binary_logloss: 0.570169\n",
      "[160]\ttraining's binary_logloss: 0.570078\n",
      "[161]\ttraining's binary_logloss: 0.569983\n",
      "[162]\ttraining's binary_logloss: 0.569892\n",
      "[163]\ttraining's binary_logloss: 0.569791\n",
      "[164]\ttraining's binary_logloss: 0.569698\n",
      "[165]\ttraining's binary_logloss: 0.569611\n",
      "[166]\ttraining's binary_logloss: 0.569505\n",
      "[167]\ttraining's binary_logloss: 0.56941\n",
      "[168]\ttraining's binary_logloss: 0.569286\n",
      "[169]\ttraining's binary_logloss: 0.569184\n",
      "[170]\ttraining's binary_logloss: 0.569104\n",
      "[171]\ttraining's binary_logloss: 0.569052\n",
      "[172]\ttraining's binary_logloss: 0.569003\n",
      "[173]\ttraining's binary_logloss: 0.568946\n",
      "[174]\ttraining's binary_logloss: 0.568881\n",
      "[175]\ttraining's binary_logloss: 0.568825\n",
      "[176]\ttraining's binary_logloss: 0.568736\n",
      "[177]\ttraining's binary_logloss: 0.568645\n",
      "[178]\ttraining's binary_logloss: 0.5686\n",
      "[179]\ttraining's binary_logloss: 0.568514\n",
      "[180]\ttraining's binary_logloss: 0.56846\n",
      "[181]\ttraining's binary_logloss: 0.568394\n",
      "[182]\ttraining's binary_logloss: 0.568327\n",
      "[183]\ttraining's binary_logloss: 0.568246\n",
      "[184]\ttraining's binary_logloss: 0.56817\n",
      "[185]\ttraining's binary_logloss: 0.568101\n",
      "[186]\ttraining's binary_logloss: 0.568025\n",
      "[187]\ttraining's binary_logloss: 0.567957\n",
      "[188]\ttraining's binary_logloss: 0.567924\n",
      "[189]\ttraining's binary_logloss: 0.567874\n",
      "[190]\ttraining's binary_logloss: 0.567781\n",
      "[191]\ttraining's binary_logloss: 0.567691\n",
      "[192]\ttraining's binary_logloss: 0.567615\n",
      "[193]\ttraining's binary_logloss: 0.567534\n",
      "[194]\ttraining's binary_logloss: 0.567443\n",
      "[195]\ttraining's binary_logloss: 0.567372\n",
      "[196]\ttraining's binary_logloss: 0.567282\n",
      "[197]\ttraining's binary_logloss: 0.567179\n",
      "[198]\ttraining's binary_logloss: 0.567091\n",
      "[199]\ttraining's binary_logloss: 0.566994\n",
      "[200]\ttraining's binary_logloss: 0.566898\n",
      "[201]\ttraining's binary_logloss: 0.566768\n",
      "[202]\ttraining's binary_logloss: 0.566655\n",
      "[203]\ttraining's binary_logloss: 0.566545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[204]\ttraining's binary_logloss: 0.566467\n",
      "[205]\ttraining's binary_logloss: 0.566381\n",
      "[206]\ttraining's binary_logloss: 0.566311\n",
      "[207]\ttraining's binary_logloss: 0.566245\n",
      "[208]\ttraining's binary_logloss: 0.566195\n",
      "[209]\ttraining's binary_logloss: 0.566149\n",
      "[210]\ttraining's binary_logloss: 0.566098\n",
      "[211]\ttraining's binary_logloss: 0.566028\n",
      "[212]\ttraining's binary_logloss: 0.565973\n",
      "[213]\ttraining's binary_logloss: 0.565911\n",
      "[214]\ttraining's binary_logloss: 0.565826\n",
      "[215]\ttraining's binary_logloss: 0.565728\n",
      "[216]\ttraining's binary_logloss: 0.565646\n",
      "[217]\ttraining's binary_logloss: 0.565527\n",
      "[218]\ttraining's binary_logloss: 0.565424\n",
      "[219]\ttraining's binary_logloss: 0.565301\n",
      "[220]\ttraining's binary_logloss: 0.565219\n",
      "[221]\ttraining's binary_logloss: 0.565116\n",
      "[222]\ttraining's binary_logloss: 0.565016\n",
      "[223]\ttraining's binary_logloss: 0.564931\n",
      "[224]\ttraining's binary_logloss: 0.564842\n",
      "[225]\ttraining's binary_logloss: 0.564739\n",
      "[226]\ttraining's binary_logloss: 0.564648\n",
      "[227]\ttraining's binary_logloss: 0.564538\n",
      "[228]\ttraining's binary_logloss: 0.56445\n",
      "[229]\ttraining's binary_logloss: 0.564349\n",
      "[230]\ttraining's binary_logloss: 0.564271\n",
      "[231]\ttraining's binary_logloss: 0.564182\n",
      "[232]\ttraining's binary_logloss: 0.564113\n",
      "[233]\ttraining's binary_logloss: 0.564048\n",
      "[234]\ttraining's binary_logloss: 0.563983\n",
      "[235]\ttraining's binary_logloss: 0.563909\n",
      "[236]\ttraining's binary_logloss: 0.563803\n",
      "[237]\ttraining's binary_logloss: 0.563692\n",
      "[238]\ttraining's binary_logloss: 0.563585\n",
      "[239]\ttraining's binary_logloss: 0.563501\n",
      "[240]\ttraining's binary_logloss: 0.563405\n",
      "[241]\ttraining's binary_logloss: 0.56329\n",
      "[242]\ttraining's binary_logloss: 0.563183\n",
      "[243]\ttraining's binary_logloss: 0.563066\n",
      "[244]\ttraining's binary_logloss: 0.56295\n",
      "[245]\ttraining's binary_logloss: 0.562842\n",
      "[246]\ttraining's binary_logloss: 0.562701\n",
      "[247]\ttraining's binary_logloss: 0.562565\n",
      "[248]\ttraining's binary_logloss: 0.56245\n",
      "[249]\ttraining's binary_logloss: 0.562318\n",
      "[250]\ttraining's binary_logloss: 0.562166\n",
      "[251]\ttraining's binary_logloss: 0.56208\n",
      "[252]\ttraining's binary_logloss: 0.561983\n",
      "[253]\ttraining's binary_logloss: 0.56188\n",
      "[254]\ttraining's binary_logloss: 0.561801\n",
      "[255]\ttraining's binary_logloss: 0.561712\n",
      "[256]\ttraining's binary_logloss: 0.5616\n",
      "[257]\ttraining's binary_logloss: 0.56151\n",
      "[258]\ttraining's binary_logloss: 0.56139\n",
      "[259]\ttraining's binary_logloss: 0.561282\n",
      "[260]\ttraining's binary_logloss: 0.561194\n",
      "[261]\ttraining's binary_logloss: 0.561073\n",
      "[262]\ttraining's binary_logloss: 0.560957\n",
      "[263]\ttraining's binary_logloss: 0.56084\n",
      "[264]\ttraining's binary_logloss: 0.560735\n",
      "[265]\ttraining's binary_logloss: 0.56061\n",
      "[266]\ttraining's binary_logloss: 0.560525\n",
      "[267]\ttraining's binary_logloss: 0.560445\n",
      "[268]\ttraining's binary_logloss: 0.560366\n",
      "[269]\ttraining's binary_logloss: 0.560261\n",
      "[270]\ttraining's binary_logloss: 0.560167\n",
      "[271]\ttraining's binary_logloss: 0.560042\n",
      "[272]\ttraining's binary_logloss: 0.559938\n",
      "[273]\ttraining's binary_logloss: 0.559808\n",
      "[274]\ttraining's binary_logloss: 0.559694\n",
      "[275]\ttraining's binary_logloss: 0.559573\n",
      "[276]\ttraining's binary_logloss: 0.55945\n",
      "[277]\ttraining's binary_logloss: 0.559322\n",
      "[278]\ttraining's binary_logloss: 0.559202\n",
      "[279]\ttraining's binary_logloss: 0.559078\n",
      "[280]\ttraining's binary_logloss: 0.558955\n",
      "[281]\ttraining's binary_logloss: 0.558836\n",
      "[282]\ttraining's binary_logloss: 0.558724\n",
      "[283]\ttraining's binary_logloss: 0.558624\n",
      "[284]\ttraining's binary_logloss: 0.558511\n",
      "[285]\ttraining's binary_logloss: 0.558395\n",
      "[286]\ttraining's binary_logloss: 0.558267\n",
      "[287]\ttraining's binary_logloss: 0.558133\n",
      "[288]\ttraining's binary_logloss: 0.558017\n",
      "[289]\ttraining's binary_logloss: 0.557856\n",
      "[290]\ttraining's binary_logloss: 0.557738\n",
      "[291]\ttraining's binary_logloss: 0.557614\n",
      "[292]\ttraining's binary_logloss: 0.557491\n",
      "[293]\ttraining's binary_logloss: 0.557386\n",
      "[294]\ttraining's binary_logloss: 0.557255\n",
      "[295]\ttraining's binary_logloss: 0.557121\n",
      "[296]\ttraining's binary_logloss: 0.556989\n",
      "[297]\ttraining's binary_logloss: 0.556859\n",
      "[298]\ttraining's binary_logloss: 0.55672\n",
      "[299]\ttraining's binary_logloss: 0.556598\n",
      "[300]\ttraining's binary_logloss: 0.556476\n",
      "[301]\ttraining's binary_logloss: 0.556324\n",
      "[302]\ttraining's binary_logloss: 0.556177\n",
      "[303]\ttraining's binary_logloss: 0.55603\n",
      "[304]\ttraining's binary_logloss: 0.55589\n",
      "[305]\ttraining's binary_logloss: 0.555748\n",
      "[306]\ttraining's binary_logloss: 0.55562\n",
      "[307]\ttraining's binary_logloss: 0.555499\n",
      "[308]\ttraining's binary_logloss: 0.555375\n",
      "[309]\ttraining's binary_logloss: 0.55526\n",
      "[310]\ttraining's binary_logloss: 0.555114\n",
      "[311]\ttraining's binary_logloss: 0.554969\n",
      "[312]\ttraining's binary_logloss: 0.554846\n",
      "[313]\ttraining's binary_logloss: 0.554727\n",
      "[314]\ttraining's binary_logloss: 0.554591\n",
      "[315]\ttraining's binary_logloss: 0.554446\n",
      "[316]\ttraining's binary_logloss: 0.554311\n",
      "[317]\ttraining's binary_logloss: 0.554189\n",
      "[318]\ttraining's binary_logloss: 0.554042\n",
      "[319]\ttraining's binary_logloss: 0.553877\n",
      "[320]\ttraining's binary_logloss: 0.553729\n",
      "[321]\ttraining's binary_logloss: 0.5536\n",
      "[322]\ttraining's binary_logloss: 0.553473\n",
      "[323]\ttraining's binary_logloss: 0.553347\n",
      "[324]\ttraining's binary_logloss: 0.553221\n",
      "[325]\ttraining's binary_logloss: 0.553099\n",
      "[326]\ttraining's binary_logloss: 0.552987\n",
      "[327]\ttraining's binary_logloss: 0.552875\n",
      "[328]\ttraining's binary_logloss: 0.552771\n",
      "[329]\ttraining's binary_logloss: 0.55267\n",
      "[330]\ttraining's binary_logloss: 0.552544\n",
      "[331]\ttraining's binary_logloss: 0.55242\n",
      "[332]\ttraining's binary_logloss: 0.552294\n",
      "[333]\ttraining's binary_logloss: 0.552155\n",
      "[334]\ttraining's binary_logloss: 0.552023\n",
      "[335]\ttraining's binary_logloss: 0.5519\n",
      "[336]\ttraining's binary_logloss: 0.551761\n",
      "[337]\ttraining's binary_logloss: 0.55163\n",
      "[338]\ttraining's binary_logloss: 0.5515\n",
      "[339]\ttraining's binary_logloss: 0.551375\n",
      "[340]\ttraining's binary_logloss: 0.551245\n",
      "[341]\ttraining's binary_logloss: 0.551139\n",
      "[342]\ttraining's binary_logloss: 0.551029\n",
      "[343]\ttraining's binary_logloss: 0.550901\n",
      "[344]\ttraining's binary_logloss: 0.550821\n",
      "[345]\ttraining's binary_logloss: 0.550699\n",
      "[346]\ttraining's binary_logloss: 0.550575\n",
      "[347]\ttraining's binary_logloss: 0.550467\n",
      "[348]\ttraining's binary_logloss: 0.550343\n",
      "[349]\ttraining's binary_logloss: 0.550227\n",
      "[350]\ttraining's binary_logloss: 0.55015\n",
      "[351]\ttraining's binary_logloss: 0.550008\n",
      "[352]\ttraining's binary_logloss: 0.549865\n",
      "[353]\ttraining's binary_logloss: 0.549717\n",
      "[354]\ttraining's binary_logloss: 0.549596\n",
      "[355]\ttraining's binary_logloss: 0.549461\n",
      "[356]\ttraining's binary_logloss: 0.549331\n",
      "[357]\ttraining's binary_logloss: 0.5492\n",
      "[358]\ttraining's binary_logloss: 0.549081\n",
      "[359]\ttraining's binary_logloss: 0.548942\n",
      "[360]\ttraining's binary_logloss: 0.548818\n",
      "[361]\ttraining's binary_logloss: 0.548658\n",
      "[362]\ttraining's binary_logloss: 0.548516\n",
      "[363]\ttraining's binary_logloss: 0.548374\n",
      "[364]\ttraining's binary_logloss: 0.548221\n",
      "[365]\ttraining's binary_logloss: 0.548088\n",
      "[366]\ttraining's binary_logloss: 0.547995\n",
      "[367]\ttraining's binary_logloss: 0.547907\n",
      "[368]\ttraining's binary_logloss: 0.547814\n",
      "[369]\ttraining's binary_logloss: 0.547723\n",
      "[370]\ttraining's binary_logloss: 0.547592\n",
      "[371]\ttraining's binary_logloss: 0.547451\n",
      "[372]\ttraining's binary_logloss: 0.54732\n",
      "[373]\ttraining's binary_logloss: 0.547196\n",
      "[374]\ttraining's binary_logloss: 0.547055\n",
      "[375]\ttraining's binary_logloss: 0.546918\n",
      "[376]\ttraining's binary_logloss: 0.546798\n",
      "[377]\ttraining's binary_logloss: 0.546648\n",
      "[378]\ttraining's binary_logloss: 0.546502\n",
      "[379]\ttraining's binary_logloss: 0.546363\n",
      "[380]\ttraining's binary_logloss: 0.546248\n",
      "[381]\ttraining's binary_logloss: 0.546099\n",
      "[382]\ttraining's binary_logloss: 0.545971\n",
      "[383]\ttraining's binary_logloss: 0.545847\n",
      "[384]\ttraining's binary_logloss: 0.54571\n",
      "[385]\ttraining's binary_logloss: 0.545577\n",
      "[386]\ttraining's binary_logloss: 0.545452\n",
      "[387]\ttraining's binary_logloss: 0.54533\n",
      "[388]\ttraining's binary_logloss: 0.545174\n",
      "[389]\ttraining's binary_logloss: 0.545046\n",
      "[390]\ttraining's binary_logloss: 0.544923\n",
      "[391]\ttraining's binary_logloss: 0.544778\n",
      "[392]\ttraining's binary_logloss: 0.54465\n",
      "[393]\ttraining's binary_logloss: 0.544519\n",
      "[394]\ttraining's binary_logloss: 0.544385\n",
      "[395]\ttraining's binary_logloss: 0.544262\n",
      "[396]\ttraining's binary_logloss: 0.544128\n",
      "[397]\ttraining's binary_logloss: 0.543988\n",
      "[398]\ttraining's binary_logloss: 0.54386\n",
      "[399]\ttraining's binary_logloss: 0.543737\n",
      "[400]\ttraining's binary_logloss: 0.543615\n",
      "[401]\ttraining's binary_logloss: 0.543474\n",
      "[402]\ttraining's binary_logloss: 0.54334\n",
      "[403]\ttraining's binary_logloss: 0.54322\n",
      "[404]\ttraining's binary_logloss: 0.543079\n",
      "[405]\ttraining's binary_logloss: 0.54294\n",
      "[406]\ttraining's binary_logloss: 0.542808\n",
      "[407]\ttraining's binary_logloss: 0.542686\n",
      "[408]\ttraining's binary_logloss: 0.542562\n",
      "[409]\ttraining's binary_logloss: 0.542415\n",
      "[410]\ttraining's binary_logloss: 0.542272\n",
      "[411]\ttraining's binary_logloss: 0.542135\n",
      "[412]\ttraining's binary_logloss: 0.542002\n",
      "[413]\ttraining's binary_logloss: 0.541857\n",
      "[414]\ttraining's binary_logloss: 0.541733\n",
      "[415]\ttraining's binary_logloss: 0.54161\n",
      "[416]\ttraining's binary_logloss: 0.541507\n",
      "[417]\ttraining's binary_logloss: 0.541379\n",
      "[418]\ttraining's binary_logloss: 0.54125\n",
      "[419]\ttraining's binary_logloss: 0.541113\n",
      "[420]\ttraining's binary_logloss: 0.540992\n",
      "[421]\ttraining's binary_logloss: 0.540903\n",
      "[422]\ttraining's binary_logloss: 0.540803\n",
      "[423]\ttraining's binary_logloss: 0.540719\n",
      "[424]\ttraining's binary_logloss: 0.540633\n",
      "[425]\ttraining's binary_logloss: 0.540562\n",
      "[426]\ttraining's binary_logloss: 0.540433\n",
      "[427]\ttraining's binary_logloss: 0.540311\n",
      "[428]\ttraining's binary_logloss: 0.540183\n",
      "[429]\ttraining's binary_logloss: 0.540068\n",
      "[430]\ttraining's binary_logloss: 0.539944\n",
      "[431]\ttraining's binary_logloss: 0.539821\n",
      "[432]\ttraining's binary_logloss: 0.539703\n",
      "[433]\ttraining's binary_logloss: 0.539569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[434]\ttraining's binary_logloss: 0.539467\n",
      "[435]\ttraining's binary_logloss: 0.539354\n",
      "[436]\ttraining's binary_logloss: 0.539244\n",
      "[437]\ttraining's binary_logloss: 0.539146\n",
      "[438]\ttraining's binary_logloss: 0.539043\n",
      "[439]\ttraining's binary_logloss: 0.538928\n",
      "[440]\ttraining's binary_logloss: 0.538825\n",
      "[441]\ttraining's binary_logloss: 0.538658\n",
      "[442]\ttraining's binary_logloss: 0.538521\n",
      "[443]\ttraining's binary_logloss: 0.538388\n",
      "[444]\ttraining's binary_logloss: 0.538258\n",
      "[445]\ttraining's binary_logloss: 0.538131\n",
      "[446]\ttraining's binary_logloss: 0.537984\n",
      "[447]\ttraining's binary_logloss: 0.537891\n",
      "[448]\ttraining's binary_logloss: 0.537755\n",
      "[449]\ttraining's binary_logloss: 0.537671\n",
      "[450]\ttraining's binary_logloss: 0.537543\n",
      "[451]\ttraining's binary_logloss: 0.537415\n",
      "[452]\ttraining's binary_logloss: 0.537297\n",
      "[453]\ttraining's binary_logloss: 0.537183\n",
      "[454]\ttraining's binary_logloss: 0.537069\n",
      "[455]\ttraining's binary_logloss: 0.536969\n",
      "[456]\ttraining's binary_logloss: 0.536814\n",
      "[457]\ttraining's binary_logloss: 0.53667\n",
      "[458]\ttraining's binary_logloss: 0.536508\n",
      "[459]\ttraining's binary_logloss: 0.536365\n",
      "[460]\ttraining's binary_logloss: 0.536222\n",
      "[461]\ttraining's binary_logloss: 0.536119\n",
      "[462]\ttraining's binary_logloss: 0.535992\n",
      "[463]\ttraining's binary_logloss: 0.535862\n",
      "[464]\ttraining's binary_logloss: 0.535753\n",
      "[465]\ttraining's binary_logloss: 0.53565\n",
      "[466]\ttraining's binary_logloss: 0.535472\n",
      "[467]\ttraining's binary_logloss: 0.535277\n",
      "[468]\ttraining's binary_logloss: 0.535118\n",
      "[469]\ttraining's binary_logloss: 0.534959\n",
      "[470]\ttraining's binary_logloss: 0.534795\n",
      "[471]\ttraining's binary_logloss: 0.534663\n",
      "[472]\ttraining's binary_logloss: 0.534545\n",
      "[473]\ttraining's binary_logloss: 0.534412\n",
      "[474]\ttraining's binary_logloss: 0.534287\n",
      "[475]\ttraining's binary_logloss: 0.534173\n",
      "[476]\ttraining's binary_logloss: 0.534042\n",
      "[477]\ttraining's binary_logloss: 0.53391\n",
      "[478]\ttraining's binary_logloss: 0.533776\n",
      "[479]\ttraining's binary_logloss: 0.533632\n",
      "[480]\ttraining's binary_logloss: 0.533507\n",
      "[481]\ttraining's binary_logloss: 0.533349\n",
      "[482]\ttraining's binary_logloss: 0.533207\n",
      "[483]\ttraining's binary_logloss: 0.533085\n",
      "[484]\ttraining's binary_logloss: 0.532953\n",
      "[485]\ttraining's binary_logloss: 0.532825\n",
      "[486]\ttraining's binary_logloss: 0.532691\n",
      "[487]\ttraining's binary_logloss: 0.532568\n",
      "[488]\ttraining's binary_logloss: 0.532463\n",
      "[489]\ttraining's binary_logloss: 0.532339\n",
      "[490]\ttraining's binary_logloss: 0.532213\n",
      "[491]\ttraining's binary_logloss: 0.53205\n",
      "[492]\ttraining's binary_logloss: 0.531886\n",
      "[493]\ttraining's binary_logloss: 0.531748\n",
      "[494]\ttraining's binary_logloss: 0.531569\n",
      "[495]\ttraining's binary_logloss: 0.531431\n",
      "[496]\ttraining's binary_logloss: 0.531266\n",
      "[497]\ttraining's binary_logloss: 0.531071\n",
      "[498]\ttraining's binary_logloss: 0.530908\n",
      "[499]\ttraining's binary_logloss: 0.530748\n",
      "[500]\ttraining's binary_logloss: 0.530587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613658\n",
      "[2]\ttraining's binary_logloss: 0.612444\n",
      "[3]\ttraining's binary_logloss: 0.611158\n",
      "[4]\ttraining's binary_logloss: 0.609899\n",
      "[5]\ttraining's binary_logloss: 0.608759\n",
      "[6]\ttraining's binary_logloss: 0.607545\n",
      "[7]\ttraining's binary_logloss: 0.606395\n",
      "[8]\ttraining's binary_logloss: 0.605266\n",
      "[9]\ttraining's binary_logloss: 0.60418\n",
      "[10]\ttraining's binary_logloss: 0.603135\n",
      "[11]\ttraining's binary_logloss: 0.602248\n",
      "[12]\ttraining's binary_logloss: 0.60134\n",
      "[13]\ttraining's binary_logloss: 0.600438\n",
      "[14]\ttraining's binary_logloss: 0.599548\n",
      "[15]\ttraining's binary_logloss: 0.598714\n",
      "[16]\ttraining's binary_logloss: 0.597877\n",
      "[17]\ttraining's binary_logloss: 0.597114\n",
      "[18]\ttraining's binary_logloss: 0.596357\n",
      "[19]\ttraining's binary_logloss: 0.595594\n",
      "[20]\ttraining's binary_logloss: 0.594861\n",
      "[21]\ttraining's binary_logloss: 0.594115\n",
      "[22]\ttraining's binary_logloss: 0.593379\n",
      "[23]\ttraining's binary_logloss: 0.592681\n",
      "[24]\ttraining's binary_logloss: 0.59201\n",
      "[25]\ttraining's binary_logloss: 0.591433\n",
      "[26]\ttraining's binary_logloss: 0.590784\n",
      "[27]\ttraining's binary_logloss: 0.590172\n",
      "[28]\ttraining's binary_logloss: 0.589572\n",
      "[29]\ttraining's binary_logloss: 0.589008\n",
      "[30]\ttraining's binary_logloss: 0.588433\n",
      "[31]\ttraining's binary_logloss: 0.587931\n",
      "[32]\ttraining's binary_logloss: 0.587527\n",
      "[33]\ttraining's binary_logloss: 0.587003\n",
      "[34]\ttraining's binary_logloss: 0.586602\n",
      "[35]\ttraining's binary_logloss: 0.586112\n",
      "[36]\ttraining's binary_logloss: 0.585587\n",
      "[37]\ttraining's binary_logloss: 0.585092\n",
      "[38]\ttraining's binary_logloss: 0.584727\n",
      "[39]\ttraining's binary_logloss: 0.58432\n",
      "[40]\ttraining's binary_logloss: 0.583866\n",
      "[41]\ttraining's binary_logloss: 0.583475\n",
      "[42]\ttraining's binary_logloss: 0.583096\n",
      "[43]\ttraining's binary_logloss: 0.58283\n",
      "[44]\ttraining's binary_logloss: 0.582475\n",
      "[45]\ttraining's binary_logloss: 0.582127\n",
      "[46]\ttraining's binary_logloss: 0.581759\n",
      "[47]\ttraining's binary_logloss: 0.581426\n",
      "[48]\ttraining's binary_logloss: 0.581094\n",
      "[49]\ttraining's binary_logloss: 0.580713\n",
      "[50]\ttraining's binary_logloss: 0.580407\n",
      "[51]\ttraining's binary_logloss: 0.580106\n",
      "[52]\ttraining's binary_logloss: 0.579841\n",
      "[53]\ttraining's binary_logloss: 0.579563\n",
      "[54]\ttraining's binary_logloss: 0.579324\n",
      "[55]\ttraining's binary_logloss: 0.579082\n",
      "[56]\ttraining's binary_logloss: 0.578844\n",
      "[57]\ttraining's binary_logloss: 0.578647\n",
      "[58]\ttraining's binary_logloss: 0.578376\n",
      "[59]\ttraining's binary_logloss: 0.578128\n",
      "[60]\ttraining's binary_logloss: 0.577871\n",
      "[61]\ttraining's binary_logloss: 0.577572\n",
      "[62]\ttraining's binary_logloss: 0.577305\n",
      "[63]\ttraining's binary_logloss: 0.577047\n",
      "[64]\ttraining's binary_logloss: 0.576803\n",
      "[65]\ttraining's binary_logloss: 0.576638\n",
      "[66]\ttraining's binary_logloss: 0.576392\n",
      "[67]\ttraining's binary_logloss: 0.576151\n",
      "[68]\ttraining's binary_logloss: 0.575969\n",
      "[69]\ttraining's binary_logloss: 0.575739\n",
      "[70]\ttraining's binary_logloss: 0.575544\n",
      "[71]\ttraining's binary_logloss: 0.575314\n",
      "[72]\ttraining's binary_logloss: 0.575086\n",
      "[73]\ttraining's binary_logloss: 0.574886\n",
      "[74]\ttraining's binary_logloss: 0.574678\n",
      "[75]\ttraining's binary_logloss: 0.574523\n",
      "[76]\ttraining's binary_logloss: 0.574398\n",
      "[77]\ttraining's binary_logloss: 0.574313\n",
      "[78]\ttraining's binary_logloss: 0.574254\n",
      "[79]\ttraining's binary_logloss: 0.574149\n",
      "[80]\ttraining's binary_logloss: 0.574064\n",
      "[81]\ttraining's binary_logloss: 0.573928\n",
      "[82]\ttraining's binary_logloss: 0.573802\n",
      "[83]\ttraining's binary_logloss: 0.573642\n",
      "[84]\ttraining's binary_logloss: 0.573517\n",
      "[85]\ttraining's binary_logloss: 0.573419\n",
      "[86]\ttraining's binary_logloss: 0.573292\n",
      "[87]\ttraining's binary_logloss: 0.57318\n",
      "[88]\ttraining's binary_logloss: 0.573108\n",
      "[89]\ttraining's binary_logloss: 0.572997\n",
      "[90]\ttraining's binary_logloss: 0.572868\n",
      "[91]\ttraining's binary_logloss: 0.572756\n",
      "[92]\ttraining's binary_logloss: 0.572622\n",
      "[93]\ttraining's binary_logloss: 0.572547\n",
      "[94]\ttraining's binary_logloss: 0.572448\n",
      "[95]\ttraining's binary_logloss: 0.572371\n",
      "[96]\ttraining's binary_logloss: 0.572301\n",
      "[97]\ttraining's binary_logloss: 0.572236\n",
      "[98]\ttraining's binary_logloss: 0.572185\n",
      "[99]\ttraining's binary_logloss: 0.572117\n",
      "[100]\ttraining's binary_logloss: 0.572053\n",
      "[101]\ttraining's binary_logloss: 0.571974\n",
      "[102]\ttraining's binary_logloss: 0.571894\n",
      "[103]\ttraining's binary_logloss: 0.571813\n",
      "[104]\ttraining's binary_logloss: 0.571749\n",
      "[105]\ttraining's binary_logloss: 0.571673\n",
      "[106]\ttraining's binary_logloss: 0.57158\n",
      "[107]\ttraining's binary_logloss: 0.571486\n",
      "[108]\ttraining's binary_logloss: 0.571408\n",
      "[109]\ttraining's binary_logloss: 0.57139\n",
      "[110]\ttraining's binary_logloss: 0.57136\n",
      "[111]\ttraining's binary_logloss: 0.571286\n",
      "[112]\ttraining's binary_logloss: 0.571188\n",
      "[113]\ttraining's binary_logloss: 0.571118\n",
      "[114]\ttraining's binary_logloss: 0.571036\n",
      "[115]\ttraining's binary_logloss: 0.570972\n",
      "[116]\ttraining's binary_logloss: 0.570882\n",
      "[117]\ttraining's binary_logloss: 0.570803\n",
      "[118]\ttraining's binary_logloss: 0.570752\n",
      "[119]\ttraining's binary_logloss: 0.570706\n",
      "[120]\ttraining's binary_logloss: 0.570643\n",
      "[121]\ttraining's binary_logloss: 0.570574\n",
      "[122]\ttraining's binary_logloss: 0.570529\n",
      "[123]\ttraining's binary_logloss: 0.570507\n",
      "[124]\ttraining's binary_logloss: 0.570453\n",
      "[125]\ttraining's binary_logloss: 0.57041\n",
      "[126]\ttraining's binary_logloss: 0.570324\n",
      "[127]\ttraining's binary_logloss: 0.570226\n",
      "[128]\ttraining's binary_logloss: 0.570142\n",
      "[129]\ttraining's binary_logloss: 0.570064\n",
      "[130]\ttraining's binary_logloss: 0.57\n",
      "[131]\ttraining's binary_logloss: 0.569991\n",
      "[132]\ttraining's binary_logloss: 0.569936\n",
      "[133]\ttraining's binary_logloss: 0.569915\n",
      "[134]\ttraining's binary_logloss: 0.569836\n",
      "[135]\ttraining's binary_logloss: 0.56982\n",
      "[136]\ttraining's binary_logloss: 0.569739\n",
      "[137]\ttraining's binary_logloss: 0.569677\n",
      "[138]\ttraining's binary_logloss: 0.56959\n",
      "[139]\ttraining's binary_logloss: 0.569557\n",
      "[140]\ttraining's binary_logloss: 0.569522\n",
      "[141]\ttraining's binary_logloss: 0.569462\n",
      "[142]\ttraining's binary_logloss: 0.569384\n",
      "[143]\ttraining's binary_logloss: 0.569332\n",
      "[144]\ttraining's binary_logloss: 0.569263\n",
      "[145]\ttraining's binary_logloss: 0.569197\n",
      "[146]\ttraining's binary_logloss: 0.5691\n",
      "[147]\ttraining's binary_logloss: 0.569022\n",
      "[148]\ttraining's binary_logloss: 0.568979\n",
      "[149]\ttraining's binary_logloss: 0.568936\n",
      "[150]\ttraining's binary_logloss: 0.568856\n",
      "[151]\ttraining's binary_logloss: 0.568805\n",
      "[152]\ttraining's binary_logloss: 0.568757\n",
      "[153]\ttraining's binary_logloss: 0.568686\n",
      "[154]\ttraining's binary_logloss: 0.568651\n",
      "[155]\ttraining's binary_logloss: 0.568623\n",
      "[156]\ttraining's binary_logloss: 0.56856\n",
      "[157]\ttraining's binary_logloss: 0.568477\n",
      "[158]\ttraining's binary_logloss: 0.568386\n",
      "[159]\ttraining's binary_logloss: 0.568314\n",
      "[160]\ttraining's binary_logloss: 0.568279\n",
      "[161]\ttraining's binary_logloss: 0.568214\n",
      "[162]\ttraining's binary_logloss: 0.568143\n",
      "[163]\ttraining's binary_logloss: 0.568069\n",
      "[164]\ttraining's binary_logloss: 0.568002\n",
      "[165]\ttraining's binary_logloss: 0.56793\n",
      "[166]\ttraining's binary_logloss: 0.567828\n",
      "[167]\ttraining's binary_logloss: 0.567725\n",
      "[168]\ttraining's binary_logloss: 0.567626\n",
      "[169]\ttraining's binary_logloss: 0.567576\n",
      "[170]\ttraining's binary_logloss: 0.567524\n",
      "[171]\ttraining's binary_logloss: 0.567456\n",
      "[172]\ttraining's binary_logloss: 0.567369\n",
      "[173]\ttraining's binary_logloss: 0.567293\n",
      "[174]\ttraining's binary_logloss: 0.567227\n",
      "[175]\ttraining's binary_logloss: 0.56716\n",
      "[176]\ttraining's binary_logloss: 0.567088\n",
      "[177]\ttraining's binary_logloss: 0.567022\n",
      "[178]\ttraining's binary_logloss: 0.566969\n",
      "[179]\ttraining's binary_logloss: 0.566914\n",
      "[180]\ttraining's binary_logloss: 0.56685\n",
      "[181]\ttraining's binary_logloss: 0.566796\n",
      "[182]\ttraining's binary_logloss: 0.566737\n",
      "[183]\ttraining's binary_logloss: 0.566694\n",
      "[184]\ttraining's binary_logloss: 0.566648\n",
      "[185]\ttraining's binary_logloss: 0.5666\n",
      "[186]\ttraining's binary_logloss: 0.566578\n",
      "[187]\ttraining's binary_logloss: 0.566561\n",
      "[188]\ttraining's binary_logloss: 0.566555\n",
      "[189]\ttraining's binary_logloss: 0.566528\n",
      "[190]\ttraining's binary_logloss: 0.5665\n",
      "[191]\ttraining's binary_logloss: 0.566444\n",
      "[192]\ttraining's binary_logloss: 0.566413\n",
      "[193]\ttraining's binary_logloss: 0.566382\n",
      "[194]\ttraining's binary_logloss: 0.566324\n",
      "[195]\ttraining's binary_logloss: 0.56624\n",
      "[196]\ttraining's binary_logloss: 0.566142\n",
      "[197]\ttraining's binary_logloss: 0.56604\n",
      "[198]\ttraining's binary_logloss: 0.565991\n",
      "[199]\ttraining's binary_logloss: 0.565946\n",
      "[200]\ttraining's binary_logloss: 0.56585\n",
      "[201]\ttraining's binary_logloss: 0.565754\n",
      "[202]\ttraining's binary_logloss: 0.565665\n",
      "[203]\ttraining's binary_logloss: 0.565583\n",
      "[204]\ttraining's binary_logloss: 0.565503\n",
      "[205]\ttraining's binary_logloss: 0.565426\n",
      "[206]\ttraining's binary_logloss: 0.565342\n",
      "[207]\ttraining's binary_logloss: 0.565268\n",
      "[208]\ttraining's binary_logloss: 0.565214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[209]\ttraining's binary_logloss: 0.56513\n",
      "[210]\ttraining's binary_logloss: 0.565065\n",
      "[211]\ttraining's binary_logloss: 0.564982\n",
      "[212]\ttraining's binary_logloss: 0.564881\n",
      "[213]\ttraining's binary_logloss: 0.564786\n",
      "[214]\ttraining's binary_logloss: 0.564691\n",
      "[215]\ttraining's binary_logloss: 0.564609\n",
      "[216]\ttraining's binary_logloss: 0.564494\n",
      "[217]\ttraining's binary_logloss: 0.564396\n",
      "[218]\ttraining's binary_logloss: 0.564261\n",
      "[219]\ttraining's binary_logloss: 0.564145\n",
      "[220]\ttraining's binary_logloss: 0.564045\n",
      "[221]\ttraining's binary_logloss: 0.563976\n",
      "[222]\ttraining's binary_logloss: 0.563904\n",
      "[223]\ttraining's binary_logloss: 0.56385\n",
      "[224]\ttraining's binary_logloss: 0.563773\n",
      "[225]\ttraining's binary_logloss: 0.563713\n",
      "[226]\ttraining's binary_logloss: 0.563627\n",
      "[227]\ttraining's binary_logloss: 0.563521\n",
      "[228]\ttraining's binary_logloss: 0.563434\n",
      "[229]\ttraining's binary_logloss: 0.56336\n",
      "[230]\ttraining's binary_logloss: 0.563256\n",
      "[231]\ttraining's binary_logloss: 0.563158\n",
      "[232]\ttraining's binary_logloss: 0.563031\n",
      "[233]\ttraining's binary_logloss: 0.562928\n",
      "[234]\ttraining's binary_logloss: 0.562811\n",
      "[235]\ttraining's binary_logloss: 0.562694\n",
      "[236]\ttraining's binary_logloss: 0.562613\n",
      "[237]\ttraining's binary_logloss: 0.562526\n",
      "[238]\ttraining's binary_logloss: 0.562445\n",
      "[239]\ttraining's binary_logloss: 0.562371\n",
      "[240]\ttraining's binary_logloss: 0.562292\n",
      "[241]\ttraining's binary_logloss: 0.562213\n",
      "[242]\ttraining's binary_logloss: 0.562131\n",
      "[243]\ttraining's binary_logloss: 0.562054\n",
      "[244]\ttraining's binary_logloss: 0.561978\n",
      "[245]\ttraining's binary_logloss: 0.561908\n",
      "[246]\ttraining's binary_logloss: 0.561797\n",
      "[247]\ttraining's binary_logloss: 0.561683\n",
      "[248]\ttraining's binary_logloss: 0.56158\n",
      "[249]\ttraining's binary_logloss: 0.561462\n",
      "[250]\ttraining's binary_logloss: 0.561313\n",
      "[251]\ttraining's binary_logloss: 0.561231\n",
      "[252]\ttraining's binary_logloss: 0.561144\n",
      "[253]\ttraining's binary_logloss: 0.561043\n",
      "[254]\ttraining's binary_logloss: 0.560963\n",
      "[255]\ttraining's binary_logloss: 0.56088\n",
      "[256]\ttraining's binary_logloss: 0.560764\n",
      "[257]\ttraining's binary_logloss: 0.560651\n",
      "[258]\ttraining's binary_logloss: 0.560549\n",
      "[259]\ttraining's binary_logloss: 0.560456\n",
      "[260]\ttraining's binary_logloss: 0.560359\n",
      "[261]\ttraining's binary_logloss: 0.560227\n",
      "[262]\ttraining's binary_logloss: 0.560091\n",
      "[263]\ttraining's binary_logloss: 0.559971\n",
      "[264]\ttraining's binary_logloss: 0.559847\n",
      "[265]\ttraining's binary_logloss: 0.559726\n",
      "[266]\ttraining's binary_logloss: 0.559627\n",
      "[267]\ttraining's binary_logloss: 0.559539\n",
      "[268]\ttraining's binary_logloss: 0.559461\n",
      "[269]\ttraining's binary_logloss: 0.559391\n",
      "[270]\ttraining's binary_logloss: 0.55931\n",
      "[271]\ttraining's binary_logloss: 0.559222\n",
      "[272]\ttraining's binary_logloss: 0.559132\n",
      "[273]\ttraining's binary_logloss: 0.559057\n",
      "[274]\ttraining's binary_logloss: 0.558939\n",
      "[275]\ttraining's binary_logloss: 0.55882\n",
      "[276]\ttraining's binary_logloss: 0.558691\n",
      "[277]\ttraining's binary_logloss: 0.558571\n",
      "[278]\ttraining's binary_logloss: 0.558447\n",
      "[279]\ttraining's binary_logloss: 0.558324\n",
      "[280]\ttraining's binary_logloss: 0.558207\n",
      "[281]\ttraining's binary_logloss: 0.558115\n",
      "[282]\ttraining's binary_logloss: 0.557998\n",
      "[283]\ttraining's binary_logloss: 0.557885\n",
      "[284]\ttraining's binary_logloss: 0.557781\n",
      "[285]\ttraining's binary_logloss: 0.557677\n",
      "[286]\ttraining's binary_logloss: 0.557508\n",
      "[287]\ttraining's binary_logloss: 0.557332\n",
      "[288]\ttraining's binary_logloss: 0.55717\n",
      "[289]\ttraining's binary_logloss: 0.556996\n",
      "[290]\ttraining's binary_logloss: 0.55683\n",
      "[291]\ttraining's binary_logloss: 0.55673\n",
      "[292]\ttraining's binary_logloss: 0.556622\n",
      "[293]\ttraining's binary_logloss: 0.556507\n",
      "[294]\ttraining's binary_logloss: 0.556397\n",
      "[295]\ttraining's binary_logloss: 0.556306\n",
      "[296]\ttraining's binary_logloss: 0.556171\n",
      "[297]\ttraining's binary_logloss: 0.556038\n",
      "[298]\ttraining's binary_logloss: 0.555883\n",
      "[299]\ttraining's binary_logloss: 0.555746\n",
      "[300]\ttraining's binary_logloss: 0.555593\n",
      "[301]\ttraining's binary_logloss: 0.555456\n",
      "[302]\ttraining's binary_logloss: 0.555332\n",
      "[303]\ttraining's binary_logloss: 0.555203\n",
      "[304]\ttraining's binary_logloss: 0.555087\n",
      "[305]\ttraining's binary_logloss: 0.554954\n",
      "[306]\ttraining's binary_logloss: 0.554794\n",
      "[307]\ttraining's binary_logloss: 0.554642\n",
      "[308]\ttraining's binary_logloss: 0.554469\n",
      "[309]\ttraining's binary_logloss: 0.554317\n",
      "[310]\ttraining's binary_logloss: 0.554153\n",
      "[311]\ttraining's binary_logloss: 0.55402\n",
      "[312]\ttraining's binary_logloss: 0.553888\n",
      "[313]\ttraining's binary_logloss: 0.553771\n",
      "[314]\ttraining's binary_logloss: 0.553629\n",
      "[315]\ttraining's binary_logloss: 0.553497\n",
      "[316]\ttraining's binary_logloss: 0.553362\n",
      "[317]\ttraining's binary_logloss: 0.553238\n",
      "[318]\ttraining's binary_logloss: 0.553114\n",
      "[319]\ttraining's binary_logloss: 0.553005\n",
      "[320]\ttraining's binary_logloss: 0.552855\n",
      "[321]\ttraining's binary_logloss: 0.552782\n",
      "[322]\ttraining's binary_logloss: 0.552697\n",
      "[323]\ttraining's binary_logloss: 0.552613\n",
      "[324]\ttraining's binary_logloss: 0.552531\n",
      "[325]\ttraining's binary_logloss: 0.552454\n",
      "[326]\ttraining's binary_logloss: 0.552364\n",
      "[327]\ttraining's binary_logloss: 0.552255\n",
      "[328]\ttraining's binary_logloss: 0.552139\n",
      "[329]\ttraining's binary_logloss: 0.552075\n",
      "[330]\ttraining's binary_logloss: 0.551957\n",
      "[331]\ttraining's binary_logloss: 0.55181\n",
      "[332]\ttraining's binary_logloss: 0.551653\n",
      "[333]\ttraining's binary_logloss: 0.551528\n",
      "[334]\ttraining's binary_logloss: 0.551398\n",
      "[335]\ttraining's binary_logloss: 0.551268\n",
      "[336]\ttraining's binary_logloss: 0.551116\n",
      "[337]\ttraining's binary_logloss: 0.550966\n",
      "[338]\ttraining's binary_logloss: 0.550814\n",
      "[339]\ttraining's binary_logloss: 0.55065\n",
      "[340]\ttraining's binary_logloss: 0.550518\n",
      "[341]\ttraining's binary_logloss: 0.550365\n",
      "[342]\ttraining's binary_logloss: 0.550208\n",
      "[343]\ttraining's binary_logloss: 0.550058\n",
      "[344]\ttraining's binary_logloss: 0.549903\n",
      "[345]\ttraining's binary_logloss: 0.549754\n",
      "[346]\ttraining's binary_logloss: 0.549662\n",
      "[347]\ttraining's binary_logloss: 0.54956\n",
      "[348]\ttraining's binary_logloss: 0.549473\n",
      "[349]\ttraining's binary_logloss: 0.549377\n",
      "[350]\ttraining's binary_logloss: 0.54928\n",
      "[351]\ttraining's binary_logloss: 0.549135\n",
      "[352]\ttraining's binary_logloss: 0.548982\n",
      "[353]\ttraining's binary_logloss: 0.548843\n",
      "[354]\ttraining's binary_logloss: 0.548699\n",
      "[355]\ttraining's binary_logloss: 0.548536\n",
      "[356]\ttraining's binary_logloss: 0.548436\n",
      "[357]\ttraining's binary_logloss: 0.54832\n",
      "[358]\ttraining's binary_logloss: 0.548215\n",
      "[359]\ttraining's binary_logloss: 0.548087\n",
      "[360]\ttraining's binary_logloss: 0.547967\n",
      "[361]\ttraining's binary_logloss: 0.547868\n",
      "[362]\ttraining's binary_logloss: 0.547764\n",
      "[363]\ttraining's binary_logloss: 0.547656\n",
      "[364]\ttraining's binary_logloss: 0.547547\n",
      "[365]\ttraining's binary_logloss: 0.547452\n",
      "[366]\ttraining's binary_logloss: 0.547357\n",
      "[367]\ttraining's binary_logloss: 0.547275\n",
      "[368]\ttraining's binary_logloss: 0.547181\n",
      "[369]\ttraining's binary_logloss: 0.547083\n",
      "[370]\ttraining's binary_logloss: 0.54699\n",
      "[371]\ttraining's binary_logloss: 0.54685\n",
      "[372]\ttraining's binary_logloss: 0.546716\n",
      "[373]\ttraining's binary_logloss: 0.546593\n",
      "[374]\ttraining's binary_logloss: 0.546466\n",
      "[375]\ttraining's binary_logloss: 0.546317\n",
      "[376]\ttraining's binary_logloss: 0.54614\n",
      "[377]\ttraining's binary_logloss: 0.54599\n",
      "[378]\ttraining's binary_logloss: 0.545807\n",
      "[379]\ttraining's binary_logloss: 0.545645\n",
      "[380]\ttraining's binary_logloss: 0.545525\n",
      "[381]\ttraining's binary_logloss: 0.545385\n",
      "[382]\ttraining's binary_logloss: 0.545266\n",
      "[383]\ttraining's binary_logloss: 0.54514\n",
      "[384]\ttraining's binary_logloss: 0.545009\n",
      "[385]\ttraining's binary_logloss: 0.544896\n",
      "[386]\ttraining's binary_logloss: 0.544783\n",
      "[387]\ttraining's binary_logloss: 0.544648\n",
      "[388]\ttraining's binary_logloss: 0.544537\n",
      "[389]\ttraining's binary_logloss: 0.54442\n",
      "[390]\ttraining's binary_logloss: 0.544322\n",
      "[391]\ttraining's binary_logloss: 0.544147\n",
      "[392]\ttraining's binary_logloss: 0.543966\n",
      "[393]\ttraining's binary_logloss: 0.543796\n",
      "[394]\ttraining's binary_logloss: 0.543611\n",
      "[395]\ttraining's binary_logloss: 0.54343\n",
      "[396]\ttraining's binary_logloss: 0.543251\n",
      "[397]\ttraining's binary_logloss: 0.543076\n",
      "[398]\ttraining's binary_logloss: 0.542903\n",
      "[399]\ttraining's binary_logloss: 0.54274\n",
      "[400]\ttraining's binary_logloss: 0.542595\n",
      "[401]\ttraining's binary_logloss: 0.542468\n",
      "[402]\ttraining's binary_logloss: 0.542326\n",
      "[403]\ttraining's binary_logloss: 0.542178\n",
      "[404]\ttraining's binary_logloss: 0.542036\n",
      "[405]\ttraining's binary_logloss: 0.541901\n",
      "[406]\ttraining's binary_logloss: 0.54179\n",
      "[407]\ttraining's binary_logloss: 0.541682\n",
      "[408]\ttraining's binary_logloss: 0.54157\n",
      "[409]\ttraining's binary_logloss: 0.541439\n",
      "[410]\ttraining's binary_logloss: 0.541311\n",
      "[411]\ttraining's binary_logloss: 0.5412\n",
      "[412]\ttraining's binary_logloss: 0.541065\n",
      "[413]\ttraining's binary_logloss: 0.540953\n",
      "[414]\ttraining's binary_logloss: 0.540785\n",
      "[415]\ttraining's binary_logloss: 0.54066\n",
      "[416]\ttraining's binary_logloss: 0.540532\n",
      "[417]\ttraining's binary_logloss: 0.540389\n",
      "[418]\ttraining's binary_logloss: 0.540257\n",
      "[419]\ttraining's binary_logloss: 0.540136\n",
      "[420]\ttraining's binary_logloss: 0.540017\n",
      "[421]\ttraining's binary_logloss: 0.539955\n",
      "[422]\ttraining's binary_logloss: 0.53987\n",
      "[423]\ttraining's binary_logloss: 0.539804\n",
      "[424]\ttraining's binary_logloss: 0.539731\n",
      "[425]\ttraining's binary_logloss: 0.539667\n",
      "[426]\ttraining's binary_logloss: 0.539499\n",
      "[427]\ttraining's binary_logloss: 0.539327\n",
      "[428]\ttraining's binary_logloss: 0.539167\n",
      "[429]\ttraining's binary_logloss: 0.539027\n",
      "[430]\ttraining's binary_logloss: 0.538858\n",
      "[431]\ttraining's binary_logloss: 0.538755\n",
      "[432]\ttraining's binary_logloss: 0.538651\n",
      "[433]\ttraining's binary_logloss: 0.538544\n",
      "[434]\ttraining's binary_logloss: 0.538441\n",
      "[435]\ttraining's binary_logloss: 0.538321\n",
      "[436]\ttraining's binary_logloss: 0.538147\n",
      "[437]\ttraining's binary_logloss: 0.538004\n",
      "[438]\ttraining's binary_logloss: 0.537843\n",
      "[439]\ttraining's binary_logloss: 0.537675\n",
      "[440]\ttraining's binary_logloss: 0.537525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[441]\ttraining's binary_logloss: 0.537401\n",
      "[442]\ttraining's binary_logloss: 0.53725\n",
      "[443]\ttraining's binary_logloss: 0.53712\n",
      "[444]\ttraining's binary_logloss: 0.536962\n",
      "[445]\ttraining's binary_logloss: 0.536813\n",
      "[446]\ttraining's binary_logloss: 0.536683\n",
      "[447]\ttraining's binary_logloss: 0.536555\n",
      "[448]\ttraining's binary_logloss: 0.536438\n",
      "[449]\ttraining's binary_logloss: 0.536318\n",
      "[450]\ttraining's binary_logloss: 0.536201\n",
      "[451]\ttraining's binary_logloss: 0.536115\n",
      "[452]\ttraining's binary_logloss: 0.536033\n",
      "[453]\ttraining's binary_logloss: 0.535954\n",
      "[454]\ttraining's binary_logloss: 0.535887\n",
      "[455]\ttraining's binary_logloss: 0.53578\n",
      "[456]\ttraining's binary_logloss: 0.535672\n",
      "[457]\ttraining's binary_logloss: 0.535521\n",
      "[458]\ttraining's binary_logloss: 0.535366\n",
      "[459]\ttraining's binary_logloss: 0.535223\n",
      "[460]\ttraining's binary_logloss: 0.535076\n",
      "[461]\ttraining's binary_logloss: 0.534945\n",
      "[462]\ttraining's binary_logloss: 0.534789\n",
      "[463]\ttraining's binary_logloss: 0.534635\n",
      "[464]\ttraining's binary_logloss: 0.534501\n",
      "[465]\ttraining's binary_logloss: 0.534375\n",
      "[466]\ttraining's binary_logloss: 0.534206\n",
      "[467]\ttraining's binary_logloss: 0.534034\n",
      "[468]\ttraining's binary_logloss: 0.533838\n",
      "[469]\ttraining's binary_logloss: 0.533673\n",
      "[470]\ttraining's binary_logloss: 0.533502\n",
      "[471]\ttraining's binary_logloss: 0.533337\n",
      "[472]\ttraining's binary_logloss: 0.53318\n",
      "[473]\ttraining's binary_logloss: 0.533022\n",
      "[474]\ttraining's binary_logloss: 0.532882\n",
      "[475]\ttraining's binary_logloss: 0.532734\n",
      "[476]\ttraining's binary_logloss: 0.532606\n",
      "[477]\ttraining's binary_logloss: 0.532498\n",
      "[478]\ttraining's binary_logloss: 0.532375\n",
      "[479]\ttraining's binary_logloss: 0.532256\n",
      "[480]\ttraining's binary_logloss: 0.532142\n",
      "[481]\ttraining's binary_logloss: 0.532019\n",
      "[482]\ttraining's binary_logloss: 0.531886\n",
      "[483]\ttraining's binary_logloss: 0.531756\n",
      "[484]\ttraining's binary_logloss: 0.531626\n",
      "[485]\ttraining's binary_logloss: 0.531512\n",
      "[486]\ttraining's binary_logloss: 0.53139\n",
      "[487]\ttraining's binary_logloss: 0.531274\n",
      "[488]\ttraining's binary_logloss: 0.531154\n",
      "[489]\ttraining's binary_logloss: 0.531041\n",
      "[490]\ttraining's binary_logloss: 0.530926\n",
      "[491]\ttraining's binary_logloss: 0.530801\n",
      "[492]\ttraining's binary_logloss: 0.530676\n",
      "[493]\ttraining's binary_logloss: 0.530562\n",
      "[494]\ttraining's binary_logloss: 0.530443\n",
      "[495]\ttraining's binary_logloss: 0.530334\n",
      "[496]\ttraining's binary_logloss: 0.530171\n",
      "[497]\ttraining's binary_logloss: 0.530006\n",
      "[498]\ttraining's binary_logloss: 0.529825\n",
      "[499]\ttraining's binary_logloss: 0.529643\n",
      "[500]\ttraining's binary_logloss: 0.529469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614106\n",
      "[2]\ttraining's binary_logloss: 0.61271\n",
      "[3]\ttraining's binary_logloss: 0.611345\n",
      "[4]\ttraining's binary_logloss: 0.610064\n",
      "[5]\ttraining's binary_logloss: 0.60883\n",
      "[6]\ttraining's binary_logloss: 0.607511\n",
      "[7]\ttraining's binary_logloss: 0.606235\n",
      "[8]\ttraining's binary_logloss: 0.605001\n",
      "[9]\ttraining's binary_logloss: 0.603843\n",
      "[10]\ttraining's binary_logloss: 0.602684\n",
      "[11]\ttraining's binary_logloss: 0.601676\n",
      "[12]\ttraining's binary_logloss: 0.600575\n",
      "[13]\ttraining's binary_logloss: 0.599515\n",
      "[14]\ttraining's binary_logloss: 0.598465\n",
      "[15]\ttraining's binary_logloss: 0.597459\n",
      "[16]\ttraining's binary_logloss: 0.596514\n",
      "[17]\ttraining's binary_logloss: 0.595619\n",
      "[18]\ttraining's binary_logloss: 0.594713\n",
      "[19]\ttraining's binary_logloss: 0.593785\n",
      "[20]\ttraining's binary_logloss: 0.592932\n",
      "[21]\ttraining's binary_logloss: 0.592066\n",
      "[22]\ttraining's binary_logloss: 0.591239\n",
      "[23]\ttraining's binary_logloss: 0.590435\n",
      "[24]\ttraining's binary_logloss: 0.589677\n",
      "[25]\ttraining's binary_logloss: 0.588991\n",
      "[26]\ttraining's binary_logloss: 0.588299\n",
      "[27]\ttraining's binary_logloss: 0.587584\n",
      "[28]\ttraining's binary_logloss: 0.586873\n",
      "[29]\ttraining's binary_logloss: 0.586197\n",
      "[30]\ttraining's binary_logloss: 0.585534\n",
      "[31]\ttraining's binary_logloss: 0.584835\n",
      "[32]\ttraining's binary_logloss: 0.584284\n",
      "[33]\ttraining's binary_logloss: 0.58364\n",
      "[34]\ttraining's binary_logloss: 0.583126\n",
      "[35]\ttraining's binary_logloss: 0.582518\n",
      "[36]\ttraining's binary_logloss: 0.582008\n",
      "[37]\ttraining's binary_logloss: 0.581464\n",
      "[38]\ttraining's binary_logloss: 0.581025\n",
      "[39]\ttraining's binary_logloss: 0.580585\n",
      "[40]\ttraining's binary_logloss: 0.580115\n",
      "[41]\ttraining's binary_logloss: 0.579548\n",
      "[42]\ttraining's binary_logloss: 0.579005\n",
      "[43]\ttraining's binary_logloss: 0.578614\n",
      "[44]\ttraining's binary_logloss: 0.578097\n",
      "[45]\ttraining's binary_logloss: 0.577626\n",
      "[46]\ttraining's binary_logloss: 0.57715\n",
      "[47]\ttraining's binary_logloss: 0.576705\n",
      "[48]\ttraining's binary_logloss: 0.576264\n",
      "[49]\ttraining's binary_logloss: 0.5758\n",
      "[50]\ttraining's binary_logloss: 0.575378\n",
      "[51]\ttraining's binary_logloss: 0.57494\n",
      "[52]\ttraining's binary_logloss: 0.574559\n",
      "[53]\ttraining's binary_logloss: 0.574143\n",
      "[54]\ttraining's binary_logloss: 0.573784\n",
      "[55]\ttraining's binary_logloss: 0.57351\n",
      "[56]\ttraining's binary_logloss: 0.573166\n",
      "[57]\ttraining's binary_logloss: 0.57285\n",
      "[58]\ttraining's binary_logloss: 0.5725\n",
      "[59]\ttraining's binary_logloss: 0.572201\n",
      "[60]\ttraining's binary_logloss: 0.571882\n",
      "[61]\ttraining's binary_logloss: 0.571545\n",
      "[62]\ttraining's binary_logloss: 0.571219\n",
      "[63]\ttraining's binary_logloss: 0.570899\n",
      "[64]\ttraining's binary_logloss: 0.57061\n",
      "[65]\ttraining's binary_logloss: 0.57032\n",
      "[66]\ttraining's binary_logloss: 0.570027\n",
      "[67]\ttraining's binary_logloss: 0.569757\n",
      "[68]\ttraining's binary_logloss: 0.569512\n",
      "[69]\ttraining's binary_logloss: 0.569262\n",
      "[70]\ttraining's binary_logloss: 0.569059\n",
      "[71]\ttraining's binary_logloss: 0.568839\n",
      "[72]\ttraining's binary_logloss: 0.568628\n",
      "[73]\ttraining's binary_logloss: 0.568437\n",
      "[74]\ttraining's binary_logloss: 0.568239\n",
      "[75]\ttraining's binary_logloss: 0.568063\n",
      "[76]\ttraining's binary_logloss: 0.56784\n",
      "[77]\ttraining's binary_logloss: 0.567653\n",
      "[78]\ttraining's binary_logloss: 0.567449\n",
      "[79]\ttraining's binary_logloss: 0.567228\n",
      "[80]\ttraining's binary_logloss: 0.566985\n",
      "[81]\ttraining's binary_logloss: 0.56674\n",
      "[82]\ttraining's binary_logloss: 0.566508\n",
      "[83]\ttraining's binary_logloss: 0.566273\n",
      "[84]\ttraining's binary_logloss: 0.56606\n",
      "[85]\ttraining's binary_logloss: 0.565908\n",
      "[86]\ttraining's binary_logloss: 0.56568\n",
      "[87]\ttraining's binary_logloss: 0.56548\n",
      "[88]\ttraining's binary_logloss: 0.565309\n",
      "[89]\ttraining's binary_logloss: 0.565172\n",
      "[90]\ttraining's binary_logloss: 0.564971\n",
      "[91]\ttraining's binary_logloss: 0.564872\n",
      "[92]\ttraining's binary_logloss: 0.564692\n",
      "[93]\ttraining's binary_logloss: 0.564513\n",
      "[94]\ttraining's binary_logloss: 0.564352\n",
      "[95]\ttraining's binary_logloss: 0.564183\n",
      "[96]\ttraining's binary_logloss: 0.563998\n",
      "[97]\ttraining's binary_logloss: 0.563813\n",
      "[98]\ttraining's binary_logloss: 0.563655\n",
      "[99]\ttraining's binary_logloss: 0.563457\n",
      "[100]\ttraining's binary_logloss: 0.563287\n",
      "[101]\ttraining's binary_logloss: 0.563109\n",
      "[102]\ttraining's binary_logloss: 0.562929\n",
      "[103]\ttraining's binary_logloss: 0.562771\n",
      "[104]\ttraining's binary_logloss: 0.562613\n",
      "[105]\ttraining's binary_logloss: 0.562455\n",
      "[106]\ttraining's binary_logloss: 0.56228\n",
      "[107]\ttraining's binary_logloss: 0.562121\n",
      "[108]\ttraining's binary_logloss: 0.562022\n",
      "[109]\ttraining's binary_logloss: 0.561881\n",
      "[110]\ttraining's binary_logloss: 0.561753\n",
      "[111]\ttraining's binary_logloss: 0.561565\n",
      "[112]\ttraining's binary_logloss: 0.561433\n",
      "[113]\ttraining's binary_logloss: 0.561253\n",
      "[114]\ttraining's binary_logloss: 0.561076\n",
      "[115]\ttraining's binary_logloss: 0.560905\n",
      "[116]\ttraining's binary_logloss: 0.56075\n",
      "[117]\ttraining's binary_logloss: 0.560605\n",
      "[118]\ttraining's binary_logloss: 0.560495\n",
      "[119]\ttraining's binary_logloss: 0.56037\n",
      "[120]\ttraining's binary_logloss: 0.560255\n",
      "[121]\ttraining's binary_logloss: 0.560125\n",
      "[122]\ttraining's binary_logloss: 0.560028\n",
      "[123]\ttraining's binary_logloss: 0.559887\n",
      "[124]\ttraining's binary_logloss: 0.559784\n",
      "[125]\ttraining's binary_logloss: 0.559665\n",
      "[126]\ttraining's binary_logloss: 0.559504\n",
      "[127]\ttraining's binary_logloss: 0.55934\n",
      "[128]\ttraining's binary_logloss: 0.559191\n",
      "[129]\ttraining's binary_logloss: 0.559045\n",
      "[130]\ttraining's binary_logloss: 0.558926\n",
      "[131]\ttraining's binary_logloss: 0.558766\n",
      "[132]\ttraining's binary_logloss: 0.558572\n",
      "[133]\ttraining's binary_logloss: 0.558392\n",
      "[134]\ttraining's binary_logloss: 0.558215\n",
      "[135]\ttraining's binary_logloss: 0.558043\n",
      "[136]\ttraining's binary_logloss: 0.557917\n",
      "[137]\ttraining's binary_logloss: 0.557796\n",
      "[138]\ttraining's binary_logloss: 0.557681\n",
      "[139]\ttraining's binary_logloss: 0.557527\n",
      "[140]\ttraining's binary_logloss: 0.557378\n",
      "[141]\ttraining's binary_logloss: 0.557242\n",
      "[142]\ttraining's binary_logloss: 0.557088\n",
      "[143]\ttraining's binary_logloss: 0.556929\n",
      "[144]\ttraining's binary_logloss: 0.556781\n",
      "[145]\ttraining's binary_logloss: 0.556643\n",
      "[146]\ttraining's binary_logloss: 0.556482\n",
      "[147]\ttraining's binary_logloss: 0.556343\n",
      "[148]\ttraining's binary_logloss: 0.556164\n",
      "[149]\ttraining's binary_logloss: 0.556001\n",
      "[150]\ttraining's binary_logloss: 0.555846\n",
      "[151]\ttraining's binary_logloss: 0.555663\n",
      "[152]\ttraining's binary_logloss: 0.555469\n",
      "[153]\ttraining's binary_logloss: 0.555306\n",
      "[154]\ttraining's binary_logloss: 0.555168\n",
      "[155]\ttraining's binary_logloss: 0.555017\n",
      "[156]\ttraining's binary_logloss: 0.554902\n",
      "[157]\ttraining's binary_logloss: 0.554776\n",
      "[158]\ttraining's binary_logloss: 0.554678\n",
      "[159]\ttraining's binary_logloss: 0.554574\n",
      "[160]\ttraining's binary_logloss: 0.554467\n",
      "[161]\ttraining's binary_logloss: 0.554292\n",
      "[162]\ttraining's binary_logloss: 0.554107\n",
      "[163]\ttraining's binary_logloss: 0.553921\n",
      "[164]\ttraining's binary_logloss: 0.553761\n",
      "[165]\ttraining's binary_logloss: 0.553599\n",
      "[166]\ttraining's binary_logloss: 0.553422\n",
      "[167]\ttraining's binary_logloss: 0.55328\n",
      "[168]\ttraining's binary_logloss: 0.553138\n",
      "[169]\ttraining's binary_logloss: 0.552978\n",
      "[170]\ttraining's binary_logloss: 0.55283\n",
      "[171]\ttraining's binary_logloss: 0.552653\n",
      "[172]\ttraining's binary_logloss: 0.552527\n",
      "[173]\ttraining's binary_logloss: 0.552369\n",
      "[174]\ttraining's binary_logloss: 0.552191\n",
      "[175]\ttraining's binary_logloss: 0.552028\n",
      "[176]\ttraining's binary_logloss: 0.551875\n",
      "[177]\ttraining's binary_logloss: 0.551726\n",
      "[178]\ttraining's binary_logloss: 0.551584\n",
      "[179]\ttraining's binary_logloss: 0.551489\n",
      "[180]\ttraining's binary_logloss: 0.551368\n",
      "[181]\ttraining's binary_logloss: 0.551236\n",
      "[182]\ttraining's binary_logloss: 0.551096\n",
      "[183]\ttraining's binary_logloss: 0.550949\n",
      "[184]\ttraining's binary_logloss: 0.55084\n",
      "[185]\ttraining's binary_logloss: 0.550703\n",
      "[186]\ttraining's binary_logloss: 0.550555\n",
      "[187]\ttraining's binary_logloss: 0.550425\n",
      "[188]\ttraining's binary_logloss: 0.550284\n",
      "[189]\ttraining's binary_logloss: 0.550171\n",
      "[190]\ttraining's binary_logloss: 0.550071\n",
      "[191]\ttraining's binary_logloss: 0.549934\n",
      "[192]\ttraining's binary_logloss: 0.549796\n",
      "[193]\ttraining's binary_logloss: 0.549665\n",
      "[194]\ttraining's binary_logloss: 0.54955\n",
      "[195]\ttraining's binary_logloss: 0.549393\n",
      "[196]\ttraining's binary_logloss: 0.549248\n",
      "[197]\ttraining's binary_logloss: 0.549089\n",
      "[198]\ttraining's binary_logloss: 0.548953\n",
      "[199]\ttraining's binary_logloss: 0.548805\n",
      "[200]\ttraining's binary_logloss: 0.548671\n",
      "[201]\ttraining's binary_logloss: 0.548565\n",
      "[202]\ttraining's binary_logloss: 0.548439\n",
      "[203]\ttraining's binary_logloss: 0.548297\n",
      "[204]\ttraining's binary_logloss: 0.548185\n",
      "[205]\ttraining's binary_logloss: 0.548076\n",
      "[206]\ttraining's binary_logloss: 0.547973\n",
      "[207]\ttraining's binary_logloss: 0.547799\n",
      "[208]\ttraining's binary_logloss: 0.547661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[209]\ttraining's binary_logloss: 0.547488\n",
      "[210]\ttraining's binary_logloss: 0.547402\n",
      "[211]\ttraining's binary_logloss: 0.547241\n",
      "[212]\ttraining's binary_logloss: 0.547077\n",
      "[213]\ttraining's binary_logloss: 0.546903\n",
      "[214]\ttraining's binary_logloss: 0.546774\n",
      "[215]\ttraining's binary_logloss: 0.546649\n",
      "[216]\ttraining's binary_logloss: 0.546521\n",
      "[217]\ttraining's binary_logloss: 0.546393\n",
      "[218]\ttraining's binary_logloss: 0.546211\n",
      "[219]\ttraining's binary_logloss: 0.546039\n",
      "[220]\ttraining's binary_logloss: 0.545927\n",
      "[221]\ttraining's binary_logloss: 0.54574\n",
      "[222]\ttraining's binary_logloss: 0.545552\n",
      "[223]\ttraining's binary_logloss: 0.545399\n",
      "[224]\ttraining's binary_logloss: 0.545215\n",
      "[225]\ttraining's binary_logloss: 0.545043\n",
      "[226]\ttraining's binary_logloss: 0.544904\n",
      "[227]\ttraining's binary_logloss: 0.544756\n",
      "[228]\ttraining's binary_logloss: 0.544631\n",
      "[229]\ttraining's binary_logloss: 0.544502\n",
      "[230]\ttraining's binary_logloss: 0.544352\n",
      "[231]\ttraining's binary_logloss: 0.544142\n",
      "[232]\ttraining's binary_logloss: 0.543946\n",
      "[233]\ttraining's binary_logloss: 0.543741\n",
      "[234]\ttraining's binary_logloss: 0.543581\n",
      "[235]\ttraining's binary_logloss: 0.543382\n",
      "[236]\ttraining's binary_logloss: 0.543186\n",
      "[237]\ttraining's binary_logloss: 0.54297\n",
      "[238]\ttraining's binary_logloss: 0.542776\n",
      "[239]\ttraining's binary_logloss: 0.542594\n",
      "[240]\ttraining's binary_logloss: 0.542406\n",
      "[241]\ttraining's binary_logloss: 0.542234\n",
      "[242]\ttraining's binary_logloss: 0.542061\n",
      "[243]\ttraining's binary_logloss: 0.541899\n",
      "[244]\ttraining's binary_logloss: 0.541714\n",
      "[245]\ttraining's binary_logloss: 0.541545\n",
      "[246]\ttraining's binary_logloss: 0.541458\n",
      "[247]\ttraining's binary_logloss: 0.541355\n",
      "[248]\ttraining's binary_logloss: 0.541259\n",
      "[249]\ttraining's binary_logloss: 0.541169\n",
      "[250]\ttraining's binary_logloss: 0.541063\n",
      "[251]\ttraining's binary_logloss: 0.54087\n",
      "[252]\ttraining's binary_logloss: 0.540708\n",
      "[253]\ttraining's binary_logloss: 0.540525\n",
      "[254]\ttraining's binary_logloss: 0.540353\n",
      "[255]\ttraining's binary_logloss: 0.540203\n",
      "[256]\ttraining's binary_logloss: 0.54002\n",
      "[257]\ttraining's binary_logloss: 0.539858\n",
      "[258]\ttraining's binary_logloss: 0.539694\n",
      "[259]\ttraining's binary_logloss: 0.539525\n",
      "[260]\ttraining's binary_logloss: 0.539372\n",
      "[261]\ttraining's binary_logloss: 0.53918\n",
      "[262]\ttraining's binary_logloss: 0.539028\n",
      "[263]\ttraining's binary_logloss: 0.538854\n",
      "[264]\ttraining's binary_logloss: 0.538715\n",
      "[265]\ttraining's binary_logloss: 0.538568\n",
      "[266]\ttraining's binary_logloss: 0.538375\n",
      "[267]\ttraining's binary_logloss: 0.538235\n",
      "[268]\ttraining's binary_logloss: 0.538114\n",
      "[269]\ttraining's binary_logloss: 0.53798\n",
      "[270]\ttraining's binary_logloss: 0.537871\n",
      "[271]\ttraining's binary_logloss: 0.53766\n",
      "[272]\ttraining's binary_logloss: 0.537442\n",
      "[273]\ttraining's binary_logloss: 0.537229\n",
      "[274]\ttraining's binary_logloss: 0.537022\n",
      "[275]\ttraining's binary_logloss: 0.536812\n",
      "[276]\ttraining's binary_logloss: 0.536634\n",
      "[277]\ttraining's binary_logloss: 0.536464\n",
      "[278]\ttraining's binary_logloss: 0.536293\n",
      "[279]\ttraining's binary_logloss: 0.536098\n",
      "[280]\ttraining's binary_logloss: 0.535932\n",
      "[281]\ttraining's binary_logloss: 0.535782\n",
      "[282]\ttraining's binary_logloss: 0.535638\n",
      "[283]\ttraining's binary_logloss: 0.535486\n",
      "[284]\ttraining's binary_logloss: 0.535354\n",
      "[285]\ttraining's binary_logloss: 0.535217\n",
      "[286]\ttraining's binary_logloss: 0.535033\n",
      "[287]\ttraining's binary_logloss: 0.534833\n",
      "[288]\ttraining's binary_logloss: 0.534641\n",
      "[289]\ttraining's binary_logloss: 0.534453\n",
      "[290]\ttraining's binary_logloss: 0.534266\n",
      "[291]\ttraining's binary_logloss: 0.534078\n",
      "[292]\ttraining's binary_logloss: 0.53389\n",
      "[293]\ttraining's binary_logloss: 0.533676\n",
      "[294]\ttraining's binary_logloss: 0.533486\n",
      "[295]\ttraining's binary_logloss: 0.533275\n",
      "[296]\ttraining's binary_logloss: 0.533105\n",
      "[297]\ttraining's binary_logloss: 0.532929\n",
      "[298]\ttraining's binary_logloss: 0.532777\n",
      "[299]\ttraining's binary_logloss: 0.532618\n",
      "[300]\ttraining's binary_logloss: 0.532496\n",
      "[301]\ttraining's binary_logloss: 0.532268\n",
      "[302]\ttraining's binary_logloss: 0.532089\n",
      "[303]\ttraining's binary_logloss: 0.5319\n",
      "[304]\ttraining's binary_logloss: 0.531713\n",
      "[305]\ttraining's binary_logloss: 0.531511\n",
      "[306]\ttraining's binary_logloss: 0.531328\n",
      "[307]\ttraining's binary_logloss: 0.531152\n",
      "[308]\ttraining's binary_logloss: 0.530955\n",
      "[309]\ttraining's binary_logloss: 0.530764\n",
      "[310]\ttraining's binary_logloss: 0.5306\n",
      "[311]\ttraining's binary_logloss: 0.530446\n",
      "[312]\ttraining's binary_logloss: 0.530312\n",
      "[313]\ttraining's binary_logloss: 0.530152\n",
      "[314]\ttraining's binary_logloss: 0.530014\n",
      "[315]\ttraining's binary_logloss: 0.529868\n",
      "[316]\ttraining's binary_logloss: 0.529682\n",
      "[317]\ttraining's binary_logloss: 0.529483\n",
      "[318]\ttraining's binary_logloss: 0.529284\n",
      "[319]\ttraining's binary_logloss: 0.529056\n",
      "[320]\ttraining's binary_logloss: 0.528869\n",
      "[321]\ttraining's binary_logloss: 0.528663\n",
      "[322]\ttraining's binary_logloss: 0.528456\n",
      "[323]\ttraining's binary_logloss: 0.528263\n",
      "[324]\ttraining's binary_logloss: 0.528104\n",
      "[325]\ttraining's binary_logloss: 0.527921\n",
      "[326]\ttraining's binary_logloss: 0.527689\n",
      "[327]\ttraining's binary_logloss: 0.527474\n",
      "[328]\ttraining's binary_logloss: 0.527255\n",
      "[329]\ttraining's binary_logloss: 0.527057\n",
      "[330]\ttraining's binary_logloss: 0.526862\n",
      "[331]\ttraining's binary_logloss: 0.526679\n",
      "[332]\ttraining's binary_logloss: 0.526483\n",
      "[333]\ttraining's binary_logloss: 0.526293\n",
      "[334]\ttraining's binary_logloss: 0.526091\n",
      "[335]\ttraining's binary_logloss: 0.525901\n",
      "[336]\ttraining's binary_logloss: 0.525753\n",
      "[337]\ttraining's binary_logloss: 0.525608\n",
      "[338]\ttraining's binary_logloss: 0.525478\n",
      "[339]\ttraining's binary_logloss: 0.525341\n",
      "[340]\ttraining's binary_logloss: 0.52521\n",
      "[341]\ttraining's binary_logloss: 0.525031\n",
      "[342]\ttraining's binary_logloss: 0.524878\n",
      "[343]\ttraining's binary_logloss: 0.524715\n",
      "[344]\ttraining's binary_logloss: 0.524549\n",
      "[345]\ttraining's binary_logloss: 0.524381\n",
      "[346]\ttraining's binary_logloss: 0.524195\n",
      "[347]\ttraining's binary_logloss: 0.523974\n",
      "[348]\ttraining's binary_logloss: 0.523781\n",
      "[349]\ttraining's binary_logloss: 0.523611\n",
      "[350]\ttraining's binary_logloss: 0.523409\n",
      "[351]\ttraining's binary_logloss: 0.523231\n",
      "[352]\ttraining's binary_logloss: 0.523062\n",
      "[353]\ttraining's binary_logloss: 0.522896\n",
      "[354]\ttraining's binary_logloss: 0.52272\n",
      "[355]\ttraining's binary_logloss: 0.52257\n",
      "[356]\ttraining's binary_logloss: 0.522357\n",
      "[357]\ttraining's binary_logloss: 0.522142\n",
      "[358]\ttraining's binary_logloss: 0.521971\n",
      "[359]\ttraining's binary_logloss: 0.521766\n",
      "[360]\ttraining's binary_logloss: 0.521566\n",
      "[361]\ttraining's binary_logloss: 0.521332\n",
      "[362]\ttraining's binary_logloss: 0.521133\n",
      "[363]\ttraining's binary_logloss: 0.520937\n",
      "[364]\ttraining's binary_logloss: 0.520711\n",
      "[365]\ttraining's binary_logloss: 0.520487\n",
      "[366]\ttraining's binary_logloss: 0.520317\n",
      "[367]\ttraining's binary_logloss: 0.520126\n",
      "[368]\ttraining's binary_logloss: 0.51995\n",
      "[369]\ttraining's binary_logloss: 0.519785\n",
      "[370]\ttraining's binary_logloss: 0.519626\n",
      "[371]\ttraining's binary_logloss: 0.519471\n",
      "[372]\ttraining's binary_logloss: 0.519302\n",
      "[373]\ttraining's binary_logloss: 0.519124\n",
      "[374]\ttraining's binary_logloss: 0.51895\n",
      "[375]\ttraining's binary_logloss: 0.518804\n",
      "[376]\ttraining's binary_logloss: 0.51861\n",
      "[377]\ttraining's binary_logloss: 0.518423\n",
      "[378]\ttraining's binary_logloss: 0.518251\n",
      "[379]\ttraining's binary_logloss: 0.518069\n",
      "[380]\ttraining's binary_logloss: 0.517897\n",
      "[381]\ttraining's binary_logloss: 0.517747\n",
      "[382]\ttraining's binary_logloss: 0.517602\n",
      "[383]\ttraining's binary_logloss: 0.517452\n",
      "[384]\ttraining's binary_logloss: 0.517304\n",
      "[385]\ttraining's binary_logloss: 0.517139\n",
      "[386]\ttraining's binary_logloss: 0.516914\n",
      "[387]\ttraining's binary_logloss: 0.516692\n",
      "[388]\ttraining's binary_logloss: 0.516446\n",
      "[389]\ttraining's binary_logloss: 0.516214\n",
      "[390]\ttraining's binary_logloss: 0.516005\n",
      "[391]\ttraining's binary_logloss: 0.515807\n",
      "[392]\ttraining's binary_logloss: 0.515653\n",
      "[393]\ttraining's binary_logloss: 0.515494\n",
      "[394]\ttraining's binary_logloss: 0.515294\n",
      "[395]\ttraining's binary_logloss: 0.515127\n",
      "[396]\ttraining's binary_logloss: 0.514929\n",
      "[397]\ttraining's binary_logloss: 0.51474\n",
      "[398]\ttraining's binary_logloss: 0.514561\n",
      "[399]\ttraining's binary_logloss: 0.51436\n",
      "[400]\ttraining's binary_logloss: 0.514198\n",
      "[401]\ttraining's binary_logloss: 0.51397\n",
      "[402]\ttraining's binary_logloss: 0.513737\n",
      "[403]\ttraining's binary_logloss: 0.513541\n",
      "[404]\ttraining's binary_logloss: 0.513312\n",
      "[405]\ttraining's binary_logloss: 0.513128\n",
      "[406]\ttraining's binary_logloss: 0.512969\n",
      "[407]\ttraining's binary_logloss: 0.512835\n",
      "[408]\ttraining's binary_logloss: 0.512678\n",
      "[409]\ttraining's binary_logloss: 0.512525\n",
      "[410]\ttraining's binary_logloss: 0.512361\n",
      "[411]\ttraining's binary_logloss: 0.512114\n",
      "[412]\ttraining's binary_logloss: 0.511865\n",
      "[413]\ttraining's binary_logloss: 0.511677\n",
      "[414]\ttraining's binary_logloss: 0.511431\n",
      "[415]\ttraining's binary_logloss: 0.5112\n",
      "[416]\ttraining's binary_logloss: 0.511045\n",
      "[417]\ttraining's binary_logloss: 0.510867\n",
      "[418]\ttraining's binary_logloss: 0.51063\n",
      "[419]\ttraining's binary_logloss: 0.510452\n",
      "[420]\ttraining's binary_logloss: 0.510263\n",
      "[421]\ttraining's binary_logloss: 0.510102\n",
      "[422]\ttraining's binary_logloss: 0.509935\n",
      "[423]\ttraining's binary_logloss: 0.509779\n",
      "[424]\ttraining's binary_logloss: 0.509638\n",
      "[425]\ttraining's binary_logloss: 0.509505\n",
      "[426]\ttraining's binary_logloss: 0.509359\n",
      "[427]\ttraining's binary_logloss: 0.509172\n",
      "[428]\ttraining's binary_logloss: 0.50899\n",
      "[429]\ttraining's binary_logloss: 0.508834\n",
      "[430]\ttraining's binary_logloss: 0.508684\n",
      "[431]\ttraining's binary_logloss: 0.508471\n",
      "[432]\ttraining's binary_logloss: 0.508279\n",
      "[433]\ttraining's binary_logloss: 0.508088\n",
      "[434]\ttraining's binary_logloss: 0.507868\n",
      "[435]\ttraining's binary_logloss: 0.507673\n",
      "[436]\ttraining's binary_logloss: 0.507521\n",
      "[437]\ttraining's binary_logloss: 0.507306\n",
      "[438]\ttraining's binary_logloss: 0.50712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[439]\ttraining's binary_logloss: 0.506955\n",
      "[440]\ttraining's binary_logloss: 0.506776\n",
      "[441]\ttraining's binary_logloss: 0.506583\n",
      "[442]\ttraining's binary_logloss: 0.506375\n",
      "[443]\ttraining's binary_logloss: 0.50619\n",
      "[444]\ttraining's binary_logloss: 0.50598\n",
      "[445]\ttraining's binary_logloss: 0.505773\n",
      "[446]\ttraining's binary_logloss: 0.505612\n",
      "[447]\ttraining's binary_logloss: 0.505447\n",
      "[448]\ttraining's binary_logloss: 0.505285\n",
      "[449]\ttraining's binary_logloss: 0.505115\n",
      "[450]\ttraining's binary_logloss: 0.504946\n",
      "[451]\ttraining's binary_logloss: 0.504771\n",
      "[452]\ttraining's binary_logloss: 0.504585\n",
      "[453]\ttraining's binary_logloss: 0.50442\n",
      "[454]\ttraining's binary_logloss: 0.504232\n",
      "[455]\ttraining's binary_logloss: 0.504068\n",
      "[456]\ttraining's binary_logloss: 0.503888\n",
      "[457]\ttraining's binary_logloss: 0.503706\n",
      "[458]\ttraining's binary_logloss: 0.503528\n",
      "[459]\ttraining's binary_logloss: 0.503362\n",
      "[460]\ttraining's binary_logloss: 0.503201\n",
      "[461]\ttraining's binary_logloss: 0.503022\n",
      "[462]\ttraining's binary_logloss: 0.502851\n",
      "[463]\ttraining's binary_logloss: 0.502683\n",
      "[464]\ttraining's binary_logloss: 0.502515\n",
      "[465]\ttraining's binary_logloss: 0.502341\n",
      "[466]\ttraining's binary_logloss: 0.502186\n",
      "[467]\ttraining's binary_logloss: 0.501994\n",
      "[468]\ttraining's binary_logloss: 0.501795\n",
      "[469]\ttraining's binary_logloss: 0.5016\n",
      "[470]\ttraining's binary_logloss: 0.501403\n",
      "[471]\ttraining's binary_logloss: 0.501236\n",
      "[472]\ttraining's binary_logloss: 0.501064\n",
      "[473]\ttraining's binary_logloss: 0.500904\n",
      "[474]\ttraining's binary_logloss: 0.500763\n",
      "[475]\ttraining's binary_logloss: 0.50061\n",
      "[476]\ttraining's binary_logloss: 0.500412\n",
      "[477]\ttraining's binary_logloss: 0.500199\n",
      "[478]\ttraining's binary_logloss: 0.500038\n",
      "[479]\ttraining's binary_logloss: 0.499857\n",
      "[480]\ttraining's binary_logloss: 0.499697\n",
      "[481]\ttraining's binary_logloss: 0.499542\n",
      "[482]\ttraining's binary_logloss: 0.499381\n",
      "[483]\ttraining's binary_logloss: 0.499208\n",
      "[484]\ttraining's binary_logloss: 0.499049\n",
      "[485]\ttraining's binary_logloss: 0.498882\n",
      "[486]\ttraining's binary_logloss: 0.498667\n",
      "[487]\ttraining's binary_logloss: 0.498477\n",
      "[488]\ttraining's binary_logloss: 0.498268\n",
      "[489]\ttraining's binary_logloss: 0.498066\n",
      "[490]\ttraining's binary_logloss: 0.497868\n",
      "[491]\ttraining's binary_logloss: 0.497705\n",
      "[492]\ttraining's binary_logloss: 0.497555\n",
      "[493]\ttraining's binary_logloss: 0.49743\n",
      "[494]\ttraining's binary_logloss: 0.497282\n",
      "[495]\ttraining's binary_logloss: 0.497152\n",
      "[496]\ttraining's binary_logloss: 0.496992\n",
      "[497]\ttraining's binary_logloss: 0.496812\n",
      "[498]\ttraining's binary_logloss: 0.496654\n",
      "[499]\ttraining's binary_logloss: 0.496466\n",
      "[500]\ttraining's binary_logloss: 0.496309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613679\n",
      "[2]\ttraining's binary_logloss: 0.61218\n",
      "[3]\ttraining's binary_logloss: 0.610579\n",
      "[4]\ttraining's binary_logloss: 0.609209\n",
      "[5]\ttraining's binary_logloss: 0.607875\n",
      "[6]\ttraining's binary_logloss: 0.606484\n",
      "[7]\ttraining's binary_logloss: 0.605209\n",
      "[8]\ttraining's binary_logloss: 0.603965\n",
      "[9]\ttraining's binary_logloss: 0.602768\n",
      "[10]\ttraining's binary_logloss: 0.601591\n",
      "[11]\ttraining's binary_logloss: 0.600516\n",
      "[12]\ttraining's binary_logloss: 0.599326\n",
      "[13]\ttraining's binary_logloss: 0.598188\n",
      "[14]\ttraining's binary_logloss: 0.597066\n",
      "[15]\ttraining's binary_logloss: 0.595978\n",
      "[16]\ttraining's binary_logloss: 0.594937\n",
      "[17]\ttraining's binary_logloss: 0.594027\n",
      "[18]\ttraining's binary_logloss: 0.593098\n",
      "[19]\ttraining's binary_logloss: 0.592109\n",
      "[20]\ttraining's binary_logloss: 0.591237\n",
      "[21]\ttraining's binary_logloss: 0.590328\n",
      "[22]\ttraining's binary_logloss: 0.589466\n",
      "[23]\ttraining's binary_logloss: 0.588627\n",
      "[24]\ttraining's binary_logloss: 0.5878\n",
      "[25]\ttraining's binary_logloss: 0.586999\n",
      "[26]\ttraining's binary_logloss: 0.586283\n",
      "[27]\ttraining's binary_logloss: 0.585557\n",
      "[28]\ttraining's binary_logloss: 0.584854\n",
      "[29]\ttraining's binary_logloss: 0.584194\n",
      "[30]\ttraining's binary_logloss: 0.583502\n",
      "[31]\ttraining's binary_logloss: 0.58274\n",
      "[32]\ttraining's binary_logloss: 0.582094\n",
      "[33]\ttraining's binary_logloss: 0.581409\n",
      "[34]\ttraining's binary_logloss: 0.580808\n",
      "[35]\ttraining's binary_logloss: 0.580163\n",
      "[36]\ttraining's binary_logloss: 0.579436\n",
      "[37]\ttraining's binary_logloss: 0.578745\n",
      "[38]\ttraining's binary_logloss: 0.5782\n",
      "[39]\ttraining's binary_logloss: 0.577603\n",
      "[40]\ttraining's binary_logloss: 0.576962\n",
      "[41]\ttraining's binary_logloss: 0.576455\n",
      "[42]\ttraining's binary_logloss: 0.575862\n",
      "[43]\ttraining's binary_logloss: 0.575467\n",
      "[44]\ttraining's binary_logloss: 0.575006\n",
      "[45]\ttraining's binary_logloss: 0.574489\n",
      "[46]\ttraining's binary_logloss: 0.573995\n",
      "[47]\ttraining's binary_logloss: 0.57353\n",
      "[48]\ttraining's binary_logloss: 0.573079\n",
      "[49]\ttraining's binary_logloss: 0.57259\n",
      "[50]\ttraining's binary_logloss: 0.572152\n",
      "[51]\ttraining's binary_logloss: 0.571653\n",
      "[52]\ttraining's binary_logloss: 0.571195\n",
      "[53]\ttraining's binary_logloss: 0.570715\n",
      "[54]\ttraining's binary_logloss: 0.570229\n",
      "[55]\ttraining's binary_logloss: 0.569855\n",
      "[56]\ttraining's binary_logloss: 0.56949\n",
      "[57]\ttraining's binary_logloss: 0.569053\n",
      "[58]\ttraining's binary_logloss: 0.568633\n",
      "[59]\ttraining's binary_logloss: 0.568229\n",
      "[60]\ttraining's binary_logloss: 0.567815\n",
      "[61]\ttraining's binary_logloss: 0.567451\n",
      "[62]\ttraining's binary_logloss: 0.567094\n",
      "[63]\ttraining's binary_logloss: 0.566748\n",
      "[64]\ttraining's binary_logloss: 0.566412\n",
      "[65]\ttraining's binary_logloss: 0.566105\n",
      "[66]\ttraining's binary_logloss: 0.565783\n",
      "[67]\ttraining's binary_logloss: 0.565474\n",
      "[68]\ttraining's binary_logloss: 0.565241\n",
      "[69]\ttraining's binary_logloss: 0.564951\n",
      "[70]\ttraining's binary_logloss: 0.564661\n",
      "[71]\ttraining's binary_logloss: 0.564394\n",
      "[72]\ttraining's binary_logloss: 0.564107\n",
      "[73]\ttraining's binary_logloss: 0.56386\n",
      "[74]\ttraining's binary_logloss: 0.563579\n",
      "[75]\ttraining's binary_logloss: 0.563325\n",
      "[76]\ttraining's binary_logloss: 0.563018\n",
      "[77]\ttraining's binary_logloss: 0.562788\n",
      "[78]\ttraining's binary_logloss: 0.562578\n",
      "[79]\ttraining's binary_logloss: 0.562276\n",
      "[80]\ttraining's binary_logloss: 0.562015\n",
      "[81]\ttraining's binary_logloss: 0.561716\n",
      "[82]\ttraining's binary_logloss: 0.561435\n",
      "[83]\ttraining's binary_logloss: 0.561215\n",
      "[84]\ttraining's binary_logloss: 0.560942\n",
      "[85]\ttraining's binary_logloss: 0.560732\n",
      "[86]\ttraining's binary_logloss: 0.560429\n",
      "[87]\ttraining's binary_logloss: 0.560138\n",
      "[88]\ttraining's binary_logloss: 0.559885\n",
      "[89]\ttraining's binary_logloss: 0.559648\n",
      "[90]\ttraining's binary_logloss: 0.559375\n",
      "[91]\ttraining's binary_logloss: 0.55919\n",
      "[92]\ttraining's binary_logloss: 0.558966\n",
      "[93]\ttraining's binary_logloss: 0.558776\n",
      "[94]\ttraining's binary_logloss: 0.558556\n",
      "[95]\ttraining's binary_logloss: 0.558358\n",
      "[96]\ttraining's binary_logloss: 0.558139\n",
      "[97]\ttraining's binary_logloss: 0.557937\n",
      "[98]\ttraining's binary_logloss: 0.557792\n",
      "[99]\ttraining's binary_logloss: 0.557571\n",
      "[100]\ttraining's binary_logloss: 0.557396\n",
      "[101]\ttraining's binary_logloss: 0.557227\n",
      "[102]\ttraining's binary_logloss: 0.557057\n",
      "[103]\ttraining's binary_logloss: 0.556908\n",
      "[104]\ttraining's binary_logloss: 0.556743\n",
      "[105]\ttraining's binary_logloss: 0.556532\n",
      "[106]\ttraining's binary_logloss: 0.556302\n",
      "[107]\ttraining's binary_logloss: 0.556076\n",
      "[108]\ttraining's binary_logloss: 0.555915\n",
      "[109]\ttraining's binary_logloss: 0.555736\n",
      "[110]\ttraining's binary_logloss: 0.555581\n",
      "[111]\ttraining's binary_logloss: 0.555402\n",
      "[112]\ttraining's binary_logloss: 0.555223\n",
      "[113]\ttraining's binary_logloss: 0.555023\n",
      "[114]\ttraining's binary_logloss: 0.554841\n",
      "[115]\ttraining's binary_logloss: 0.554681\n",
      "[116]\ttraining's binary_logloss: 0.554493\n",
      "[117]\ttraining's binary_logloss: 0.554301\n",
      "[118]\ttraining's binary_logloss: 0.554145\n",
      "[119]\ttraining's binary_logloss: 0.55405\n",
      "[120]\ttraining's binary_logloss: 0.553891\n",
      "[121]\ttraining's binary_logloss: 0.553696\n",
      "[122]\ttraining's binary_logloss: 0.553535\n",
      "[123]\ttraining's binary_logloss: 0.553348\n",
      "[124]\ttraining's binary_logloss: 0.553191\n",
      "[125]\ttraining's binary_logloss: 0.553048\n",
      "[126]\ttraining's binary_logloss: 0.552858\n",
      "[127]\ttraining's binary_logloss: 0.552671\n",
      "[128]\ttraining's binary_logloss: 0.552503\n",
      "[129]\ttraining's binary_logloss: 0.552311\n",
      "[130]\ttraining's binary_logloss: 0.552124\n",
      "[131]\ttraining's binary_logloss: 0.551986\n",
      "[132]\ttraining's binary_logloss: 0.551844\n",
      "[133]\ttraining's binary_logloss: 0.551718\n",
      "[134]\ttraining's binary_logloss: 0.551578\n",
      "[135]\ttraining's binary_logloss: 0.551468\n",
      "[136]\ttraining's binary_logloss: 0.551313\n",
      "[137]\ttraining's binary_logloss: 0.551148\n",
      "[138]\ttraining's binary_logloss: 0.551006\n",
      "[139]\ttraining's binary_logloss: 0.550857\n",
      "[140]\ttraining's binary_logloss: 0.550704\n",
      "[141]\ttraining's binary_logloss: 0.550609\n",
      "[142]\ttraining's binary_logloss: 0.550461\n",
      "[143]\ttraining's binary_logloss: 0.55029\n",
      "[144]\ttraining's binary_logloss: 0.550136\n",
      "[145]\ttraining's binary_logloss: 0.549997\n",
      "[146]\ttraining's binary_logloss: 0.549838\n",
      "[147]\ttraining's binary_logloss: 0.549689\n",
      "[148]\ttraining's binary_logloss: 0.549522\n",
      "[149]\ttraining's binary_logloss: 0.54939\n",
      "[150]\ttraining's binary_logloss: 0.549218\n",
      "[151]\ttraining's binary_logloss: 0.549061\n",
      "[152]\ttraining's binary_logloss: 0.548881\n",
      "[153]\ttraining's binary_logloss: 0.548686\n",
      "[154]\ttraining's binary_logloss: 0.548509\n",
      "[155]\ttraining's binary_logloss: 0.548348\n",
      "[156]\ttraining's binary_logloss: 0.548202\n",
      "[157]\ttraining's binary_logloss: 0.548072\n",
      "[158]\ttraining's binary_logloss: 0.547937\n",
      "[159]\ttraining's binary_logloss: 0.547816\n",
      "[160]\ttraining's binary_logloss: 0.547669\n",
      "[161]\ttraining's binary_logloss: 0.547464\n",
      "[162]\ttraining's binary_logloss: 0.547287\n",
      "[163]\ttraining's binary_logloss: 0.547117\n",
      "[164]\ttraining's binary_logloss: 0.546941\n",
      "[165]\ttraining's binary_logloss: 0.546814\n",
      "[166]\ttraining's binary_logloss: 0.546635\n",
      "[167]\ttraining's binary_logloss: 0.546466\n",
      "[168]\ttraining's binary_logloss: 0.546307\n",
      "[169]\ttraining's binary_logloss: 0.546134\n",
      "[170]\ttraining's binary_logloss: 0.545968\n",
      "[171]\ttraining's binary_logloss: 0.545792\n",
      "[172]\ttraining's binary_logloss: 0.545631\n",
      "[173]\ttraining's binary_logloss: 0.545466\n",
      "[174]\ttraining's binary_logloss: 0.545289\n",
      "[175]\ttraining's binary_logloss: 0.545132\n",
      "[176]\ttraining's binary_logloss: 0.544988\n",
      "[177]\ttraining's binary_logloss: 0.544852\n",
      "[178]\ttraining's binary_logloss: 0.544706\n",
      "[179]\ttraining's binary_logloss: 0.544574\n",
      "[180]\ttraining's binary_logloss: 0.544416\n",
      "[181]\ttraining's binary_logloss: 0.544255\n",
      "[182]\ttraining's binary_logloss: 0.544129\n",
      "[183]\ttraining's binary_logloss: 0.544011\n",
      "[184]\ttraining's binary_logloss: 0.543871\n",
      "[185]\ttraining's binary_logloss: 0.543754\n",
      "[186]\ttraining's binary_logloss: 0.543581\n",
      "[187]\ttraining's binary_logloss: 0.543421\n",
      "[188]\ttraining's binary_logloss: 0.543252\n",
      "[189]\ttraining's binary_logloss: 0.543082\n",
      "[190]\ttraining's binary_logloss: 0.542909\n",
      "[191]\ttraining's binary_logloss: 0.542748\n",
      "[192]\ttraining's binary_logloss: 0.542591\n",
      "[193]\ttraining's binary_logloss: 0.542406\n",
      "[194]\ttraining's binary_logloss: 0.542284\n",
      "[195]\ttraining's binary_logloss: 0.54211\n",
      "[196]\ttraining's binary_logloss: 0.541979\n",
      "[197]\ttraining's binary_logloss: 0.541816\n",
      "[198]\ttraining's binary_logloss: 0.541667\n",
      "[199]\ttraining's binary_logloss: 0.541508\n",
      "[200]\ttraining's binary_logloss: 0.54136\n",
      "[201]\ttraining's binary_logloss: 0.54118\n",
      "[202]\ttraining's binary_logloss: 0.541023\n",
      "[203]\ttraining's binary_logloss: 0.540863\n",
      "[204]\ttraining's binary_logloss: 0.540709\n",
      "[205]\ttraining's binary_logloss: 0.540541\n",
      "[206]\ttraining's binary_logloss: 0.540397\n",
      "[207]\ttraining's binary_logloss: 0.540212\n",
      "[208]\ttraining's binary_logloss: 0.540074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[209]\ttraining's binary_logloss: 0.53994\n",
      "[210]\ttraining's binary_logloss: 0.539791\n",
      "[211]\ttraining's binary_logloss: 0.539646\n",
      "[212]\ttraining's binary_logloss: 0.539505\n",
      "[213]\ttraining's binary_logloss: 0.539366\n",
      "[214]\ttraining's binary_logloss: 0.53924\n",
      "[215]\ttraining's binary_logloss: 0.539115\n",
      "[216]\ttraining's binary_logloss: 0.538915\n",
      "[217]\ttraining's binary_logloss: 0.53874\n",
      "[218]\ttraining's binary_logloss: 0.538575\n",
      "[219]\ttraining's binary_logloss: 0.538383\n",
      "[220]\ttraining's binary_logloss: 0.538213\n",
      "[221]\ttraining's binary_logloss: 0.538002\n",
      "[222]\ttraining's binary_logloss: 0.537774\n",
      "[223]\ttraining's binary_logloss: 0.537615\n",
      "[224]\ttraining's binary_logloss: 0.537408\n",
      "[225]\ttraining's binary_logloss: 0.53727\n",
      "[226]\ttraining's binary_logloss: 0.537124\n",
      "[227]\ttraining's binary_logloss: 0.536988\n",
      "[228]\ttraining's binary_logloss: 0.536871\n",
      "[229]\ttraining's binary_logloss: 0.536756\n",
      "[230]\ttraining's binary_logloss: 0.536645\n",
      "[231]\ttraining's binary_logloss: 0.536514\n",
      "[232]\ttraining's binary_logloss: 0.536353\n",
      "[233]\ttraining's binary_logloss: 0.536212\n",
      "[234]\ttraining's binary_logloss: 0.536078\n",
      "[235]\ttraining's binary_logloss: 0.535938\n",
      "[236]\ttraining's binary_logloss: 0.535726\n",
      "[237]\ttraining's binary_logloss: 0.53552\n",
      "[238]\ttraining's binary_logloss: 0.535315\n",
      "[239]\ttraining's binary_logloss: 0.535123\n",
      "[240]\ttraining's binary_logloss: 0.534929\n",
      "[241]\ttraining's binary_logloss: 0.534775\n",
      "[242]\ttraining's binary_logloss: 0.534595\n",
      "[243]\ttraining's binary_logloss: 0.534419\n",
      "[244]\ttraining's binary_logloss: 0.534242\n",
      "[245]\ttraining's binary_logloss: 0.534077\n",
      "[246]\ttraining's binary_logloss: 0.533919\n",
      "[247]\ttraining's binary_logloss: 0.533748\n",
      "[248]\ttraining's binary_logloss: 0.533591\n",
      "[249]\ttraining's binary_logloss: 0.533439\n",
      "[250]\ttraining's binary_logloss: 0.533283\n",
      "[251]\ttraining's binary_logloss: 0.533119\n",
      "[252]\ttraining's binary_logloss: 0.532979\n",
      "[253]\ttraining's binary_logloss: 0.532823\n",
      "[254]\ttraining's binary_logloss: 0.532649\n",
      "[255]\ttraining's binary_logloss: 0.532489\n",
      "[256]\ttraining's binary_logloss: 0.532287\n",
      "[257]\ttraining's binary_logloss: 0.532102\n",
      "[258]\ttraining's binary_logloss: 0.53195\n",
      "[259]\ttraining's binary_logloss: 0.531758\n",
      "[260]\ttraining's binary_logloss: 0.531574\n",
      "[261]\ttraining's binary_logloss: 0.531387\n",
      "[262]\ttraining's binary_logloss: 0.531204\n",
      "[263]\ttraining's binary_logloss: 0.530999\n",
      "[264]\ttraining's binary_logloss: 0.53085\n",
      "[265]\ttraining's binary_logloss: 0.53069\n",
      "[266]\ttraining's binary_logloss: 0.5306\n",
      "[267]\ttraining's binary_logloss: 0.530512\n",
      "[268]\ttraining's binary_logloss: 0.530422\n",
      "[269]\ttraining's binary_logloss: 0.530319\n",
      "[270]\ttraining's binary_logloss: 0.530219\n",
      "[271]\ttraining's binary_logloss: 0.530004\n",
      "[272]\ttraining's binary_logloss: 0.529791\n",
      "[273]\ttraining's binary_logloss: 0.52958\n",
      "[274]\ttraining's binary_logloss: 0.529371\n",
      "[275]\ttraining's binary_logloss: 0.529181\n",
      "[276]\ttraining's binary_logloss: 0.528957\n",
      "[277]\ttraining's binary_logloss: 0.528739\n",
      "[278]\ttraining's binary_logloss: 0.528528\n",
      "[279]\ttraining's binary_logloss: 0.528317\n",
      "[280]\ttraining's binary_logloss: 0.528128\n",
      "[281]\ttraining's binary_logloss: 0.527932\n",
      "[282]\ttraining's binary_logloss: 0.52775\n",
      "[283]\ttraining's binary_logloss: 0.527567\n",
      "[284]\ttraining's binary_logloss: 0.527372\n",
      "[285]\ttraining's binary_logloss: 0.527205\n",
      "[286]\ttraining's binary_logloss: 0.527019\n",
      "[287]\ttraining's binary_logloss: 0.526866\n",
      "[288]\ttraining's binary_logloss: 0.526694\n",
      "[289]\ttraining's binary_logloss: 0.526535\n",
      "[290]\ttraining's binary_logloss: 0.526326\n",
      "[291]\ttraining's binary_logloss: 0.526142\n",
      "[292]\ttraining's binary_logloss: 0.525958\n",
      "[293]\ttraining's binary_logloss: 0.525745\n",
      "[294]\ttraining's binary_logloss: 0.525572\n",
      "[295]\ttraining's binary_logloss: 0.525357\n",
      "[296]\ttraining's binary_logloss: 0.525218\n",
      "[297]\ttraining's binary_logloss: 0.525035\n",
      "[298]\ttraining's binary_logloss: 0.524883\n",
      "[299]\ttraining's binary_logloss: 0.524748\n",
      "[300]\ttraining's binary_logloss: 0.52462\n",
      "[301]\ttraining's binary_logloss: 0.524408\n",
      "[302]\ttraining's binary_logloss: 0.524213\n",
      "[303]\ttraining's binary_logloss: 0.524067\n",
      "[304]\ttraining's binary_logloss: 0.523872\n",
      "[305]\ttraining's binary_logloss: 0.523668\n",
      "[306]\ttraining's binary_logloss: 0.523496\n",
      "[307]\ttraining's binary_logloss: 0.523327\n",
      "[308]\ttraining's binary_logloss: 0.523149\n",
      "[309]\ttraining's binary_logloss: 0.522977\n",
      "[310]\ttraining's binary_logloss: 0.522806\n",
      "[311]\ttraining's binary_logloss: 0.522602\n",
      "[312]\ttraining's binary_logloss: 0.522406\n",
      "[313]\ttraining's binary_logloss: 0.522235\n",
      "[314]\ttraining's binary_logloss: 0.522049\n",
      "[315]\ttraining's binary_logloss: 0.521847\n",
      "[316]\ttraining's binary_logloss: 0.521691\n",
      "[317]\ttraining's binary_logloss: 0.521501\n",
      "[318]\ttraining's binary_logloss: 0.521298\n",
      "[319]\ttraining's binary_logloss: 0.52115\n",
      "[320]\ttraining's binary_logloss: 0.520997\n",
      "[321]\ttraining's binary_logloss: 0.520816\n",
      "[322]\ttraining's binary_logloss: 0.520639\n",
      "[323]\ttraining's binary_logloss: 0.520468\n",
      "[324]\ttraining's binary_logloss: 0.520317\n",
      "[325]\ttraining's binary_logloss: 0.520146\n",
      "[326]\ttraining's binary_logloss: 0.51994\n",
      "[327]\ttraining's binary_logloss: 0.519763\n",
      "[328]\ttraining's binary_logloss: 0.519572\n",
      "[329]\ttraining's binary_logloss: 0.519392\n",
      "[330]\ttraining's binary_logloss: 0.519208\n",
      "[331]\ttraining's binary_logloss: 0.519013\n",
      "[332]\ttraining's binary_logloss: 0.518821\n",
      "[333]\ttraining's binary_logloss: 0.518639\n",
      "[334]\ttraining's binary_logloss: 0.518445\n",
      "[335]\ttraining's binary_logloss: 0.518263\n",
      "[336]\ttraining's binary_logloss: 0.518092\n",
      "[337]\ttraining's binary_logloss: 0.51791\n",
      "[338]\ttraining's binary_logloss: 0.517731\n",
      "[339]\ttraining's binary_logloss: 0.517564\n",
      "[340]\ttraining's binary_logloss: 0.517385\n",
      "[341]\ttraining's binary_logloss: 0.517185\n",
      "[342]\ttraining's binary_logloss: 0.517025\n",
      "[343]\ttraining's binary_logloss: 0.516841\n",
      "[344]\ttraining's binary_logloss: 0.516659\n",
      "[345]\ttraining's binary_logloss: 0.516502\n",
      "[346]\ttraining's binary_logloss: 0.516309\n",
      "[347]\ttraining's binary_logloss: 0.51613\n",
      "[348]\ttraining's binary_logloss: 0.515958\n",
      "[349]\ttraining's binary_logloss: 0.515777\n",
      "[350]\ttraining's binary_logloss: 0.515619\n",
      "[351]\ttraining's binary_logloss: 0.51544\n",
      "[352]\ttraining's binary_logloss: 0.515219\n",
      "[353]\ttraining's binary_logloss: 0.514997\n",
      "[354]\ttraining's binary_logloss: 0.514756\n",
      "[355]\ttraining's binary_logloss: 0.514521\n",
      "[356]\ttraining's binary_logloss: 0.514328\n",
      "[357]\ttraining's binary_logloss: 0.5141\n",
      "[358]\ttraining's binary_logloss: 0.5139\n",
      "[359]\ttraining's binary_logloss: 0.513694\n",
      "[360]\ttraining's binary_logloss: 0.513488\n",
      "[361]\ttraining's binary_logloss: 0.513288\n",
      "[362]\ttraining's binary_logloss: 0.513085\n",
      "[363]\ttraining's binary_logloss: 0.512881\n",
      "[364]\ttraining's binary_logloss: 0.512665\n",
      "[365]\ttraining's binary_logloss: 0.512469\n",
      "[366]\ttraining's binary_logloss: 0.512295\n",
      "[367]\ttraining's binary_logloss: 0.51208\n",
      "[368]\ttraining's binary_logloss: 0.511867\n",
      "[369]\ttraining's binary_logloss: 0.511704\n",
      "[370]\ttraining's binary_logloss: 0.511496\n",
      "[371]\ttraining's binary_logloss: 0.511337\n",
      "[372]\ttraining's binary_logloss: 0.511198\n",
      "[373]\ttraining's binary_logloss: 0.511053\n",
      "[374]\ttraining's binary_logloss: 0.510903\n",
      "[375]\ttraining's binary_logloss: 0.510776\n",
      "[376]\ttraining's binary_logloss: 0.510616\n",
      "[377]\ttraining's binary_logloss: 0.510463\n",
      "[378]\ttraining's binary_logloss: 0.510313\n",
      "[379]\ttraining's binary_logloss: 0.510159\n",
      "[380]\ttraining's binary_logloss: 0.509988\n",
      "[381]\ttraining's binary_logloss: 0.50984\n",
      "[382]\ttraining's binary_logloss: 0.509661\n",
      "[383]\ttraining's binary_logloss: 0.509484\n",
      "[384]\ttraining's binary_logloss: 0.509305\n",
      "[385]\ttraining's binary_logloss: 0.509138\n",
      "[386]\ttraining's binary_logloss: 0.508922\n",
      "[387]\ttraining's binary_logloss: 0.508721\n",
      "[388]\ttraining's binary_logloss: 0.508493\n",
      "[389]\ttraining's binary_logloss: 0.50829\n",
      "[390]\ttraining's binary_logloss: 0.50808\n",
      "[391]\ttraining's binary_logloss: 0.507893\n",
      "[392]\ttraining's binary_logloss: 0.50769\n",
      "[393]\ttraining's binary_logloss: 0.507514\n",
      "[394]\ttraining's binary_logloss: 0.507325\n",
      "[395]\ttraining's binary_logloss: 0.507148\n",
      "[396]\ttraining's binary_logloss: 0.506971\n",
      "[397]\ttraining's binary_logloss: 0.506792\n",
      "[398]\ttraining's binary_logloss: 0.506629\n",
      "[399]\ttraining's binary_logloss: 0.506445\n",
      "[400]\ttraining's binary_logloss: 0.506277\n",
      "[401]\ttraining's binary_logloss: 0.506081\n",
      "[402]\ttraining's binary_logloss: 0.505909\n",
      "[403]\ttraining's binary_logloss: 0.505734\n",
      "[404]\ttraining's binary_logloss: 0.505572\n",
      "[405]\ttraining's binary_logloss: 0.505412\n",
      "[406]\ttraining's binary_logloss: 0.505227\n",
      "[407]\ttraining's binary_logloss: 0.505071\n",
      "[408]\ttraining's binary_logloss: 0.504908\n",
      "[409]\ttraining's binary_logloss: 0.504713\n",
      "[410]\ttraining's binary_logloss: 0.504526\n",
      "[411]\ttraining's binary_logloss: 0.504349\n",
      "[412]\ttraining's binary_logloss: 0.504175\n",
      "[413]\ttraining's binary_logloss: 0.503994\n",
      "[414]\ttraining's binary_logloss: 0.503753\n",
      "[415]\ttraining's binary_logloss: 0.503518\n",
      "[416]\ttraining's binary_logloss: 0.503324\n",
      "[417]\ttraining's binary_logloss: 0.503133\n",
      "[418]\ttraining's binary_logloss: 0.502945\n",
      "[419]\ttraining's binary_logloss: 0.50272\n",
      "[420]\ttraining's binary_logloss: 0.502532\n",
      "[421]\ttraining's binary_logloss: 0.502325\n",
      "[422]\ttraining's binary_logloss: 0.502158\n",
      "[423]\ttraining's binary_logloss: 0.502024\n",
      "[424]\ttraining's binary_logloss: 0.501828\n",
      "[425]\ttraining's binary_logloss: 0.501669\n",
      "[426]\ttraining's binary_logloss: 0.50149\n",
      "[427]\ttraining's binary_logloss: 0.501296\n",
      "[428]\ttraining's binary_logloss: 0.501126\n",
      "[429]\ttraining's binary_logloss: 0.500937\n",
      "[430]\ttraining's binary_logloss: 0.500761\n",
      "[431]\ttraining's binary_logloss: 0.50056\n",
      "[432]\ttraining's binary_logloss: 0.50034\n",
      "[433]\ttraining's binary_logloss: 0.500121\n",
      "[434]\ttraining's binary_logloss: 0.49993\n",
      "[435]\ttraining's binary_logloss: 0.499703\n",
      "[436]\ttraining's binary_logloss: 0.499482\n",
      "[437]\ttraining's binary_logloss: 0.499255\n",
      "[438]\ttraining's binary_logloss: 0.499006\n",
      "[439]\ttraining's binary_logloss: 0.49882\n",
      "[440]\ttraining's binary_logloss: 0.498603\n",
      "[441]\ttraining's binary_logloss: 0.498402\n",
      "[442]\ttraining's binary_logloss: 0.498212\n",
      "[443]\ttraining's binary_logloss: 0.498024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[444]\ttraining's binary_logloss: 0.497836\n",
      "[445]\ttraining's binary_logloss: 0.497663\n",
      "[446]\ttraining's binary_logloss: 0.497438\n",
      "[447]\ttraining's binary_logloss: 0.497228\n",
      "[448]\ttraining's binary_logloss: 0.497014\n",
      "[449]\ttraining's binary_logloss: 0.496813\n",
      "[450]\ttraining's binary_logloss: 0.496622\n",
      "[451]\ttraining's binary_logloss: 0.496484\n",
      "[452]\ttraining's binary_logloss: 0.496344\n",
      "[453]\ttraining's binary_logloss: 0.496188\n",
      "[454]\ttraining's binary_logloss: 0.496034\n",
      "[455]\ttraining's binary_logloss: 0.49589\n",
      "[456]\ttraining's binary_logloss: 0.495715\n",
      "[457]\ttraining's binary_logloss: 0.495561\n",
      "[458]\ttraining's binary_logloss: 0.495391\n",
      "[459]\ttraining's binary_logloss: 0.495225\n",
      "[460]\ttraining's binary_logloss: 0.495056\n",
      "[461]\ttraining's binary_logloss: 0.494823\n",
      "[462]\ttraining's binary_logloss: 0.494595\n",
      "[463]\ttraining's binary_logloss: 0.494373\n",
      "[464]\ttraining's binary_logloss: 0.494204\n",
      "[465]\ttraining's binary_logloss: 0.494002\n",
      "[466]\ttraining's binary_logloss: 0.493809\n",
      "[467]\ttraining's binary_logloss: 0.493595\n",
      "[468]\ttraining's binary_logloss: 0.493391\n",
      "[469]\ttraining's binary_logloss: 0.493183\n",
      "[470]\ttraining's binary_logloss: 0.492989\n",
      "[471]\ttraining's binary_logloss: 0.492838\n",
      "[472]\ttraining's binary_logloss: 0.492677\n",
      "[473]\ttraining's binary_logloss: 0.49252\n",
      "[474]\ttraining's binary_logloss: 0.492371\n",
      "[475]\ttraining's binary_logloss: 0.492218\n",
      "[476]\ttraining's binary_logloss: 0.492021\n",
      "[477]\ttraining's binary_logloss: 0.491819\n",
      "[478]\ttraining's binary_logloss: 0.491665\n",
      "[479]\ttraining's binary_logloss: 0.491499\n",
      "[480]\ttraining's binary_logloss: 0.4913\n",
      "[481]\ttraining's binary_logloss: 0.491139\n",
      "[482]\ttraining's binary_logloss: 0.49096\n",
      "[483]\ttraining's binary_logloss: 0.490809\n",
      "[484]\ttraining's binary_logloss: 0.490634\n",
      "[485]\ttraining's binary_logloss: 0.490485\n",
      "[486]\ttraining's binary_logloss: 0.490289\n",
      "[487]\ttraining's binary_logloss: 0.490066\n",
      "[488]\ttraining's binary_logloss: 0.489859\n",
      "[489]\ttraining's binary_logloss: 0.48966\n",
      "[490]\ttraining's binary_logloss: 0.489466\n",
      "[491]\ttraining's binary_logloss: 0.4893\n",
      "[492]\ttraining's binary_logloss: 0.489117\n",
      "[493]\ttraining's binary_logloss: 0.488954\n",
      "[494]\ttraining's binary_logloss: 0.488773\n",
      "[495]\ttraining's binary_logloss: 0.488613\n",
      "[496]\ttraining's binary_logloss: 0.488435\n",
      "[497]\ttraining's binary_logloss: 0.488208\n",
      "[498]\ttraining's binary_logloss: 0.488032\n",
      "[499]\ttraining's binary_logloss: 0.487823\n",
      "[500]\ttraining's binary_logloss: 0.487623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.612812\n",
      "[2]\ttraining's binary_logloss: 0.611344\n",
      "[3]\ttraining's binary_logloss: 0.609976\n",
      "[4]\ttraining's binary_logloss: 0.608584\n",
      "[5]\ttraining's binary_logloss: 0.607229\n",
      "[6]\ttraining's binary_logloss: 0.605886\n",
      "[7]\ttraining's binary_logloss: 0.604625\n",
      "[8]\ttraining's binary_logloss: 0.603381\n",
      "[9]\ttraining's binary_logloss: 0.602285\n",
      "[10]\ttraining's binary_logloss: 0.601074\n",
      "[11]\ttraining's binary_logloss: 0.60001\n",
      "[12]\ttraining's binary_logloss: 0.598888\n",
      "[13]\ttraining's binary_logloss: 0.597769\n",
      "[14]\ttraining's binary_logloss: 0.596762\n",
      "[15]\ttraining's binary_logloss: 0.595697\n",
      "[16]\ttraining's binary_logloss: 0.594623\n",
      "[17]\ttraining's binary_logloss: 0.593578\n",
      "[18]\ttraining's binary_logloss: 0.592571\n",
      "[19]\ttraining's binary_logloss: 0.591595\n",
      "[20]\ttraining's binary_logloss: 0.59066\n",
      "[21]\ttraining's binary_logloss: 0.589785\n",
      "[22]\ttraining's binary_logloss: 0.588965\n",
      "[23]\ttraining's binary_logloss: 0.588187\n",
      "[24]\ttraining's binary_logloss: 0.587408\n",
      "[25]\ttraining's binary_logloss: 0.586598\n",
      "[26]\ttraining's binary_logloss: 0.585799\n",
      "[27]\ttraining's binary_logloss: 0.585109\n",
      "[28]\ttraining's binary_logloss: 0.58439\n",
      "[29]\ttraining's binary_logloss: 0.58374\n",
      "[30]\ttraining's binary_logloss: 0.583027\n",
      "[31]\ttraining's binary_logloss: 0.582338\n",
      "[32]\ttraining's binary_logloss: 0.581682\n",
      "[33]\ttraining's binary_logloss: 0.58114\n",
      "[34]\ttraining's binary_logloss: 0.580554\n",
      "[35]\ttraining's binary_logloss: 0.579948\n",
      "[36]\ttraining's binary_logloss: 0.579375\n",
      "[37]\ttraining's binary_logloss: 0.578931\n",
      "[38]\ttraining's binary_logloss: 0.578322\n",
      "[39]\ttraining's binary_logloss: 0.577796\n",
      "[40]\ttraining's binary_logloss: 0.577242\n",
      "[41]\ttraining's binary_logloss: 0.576725\n",
      "[42]\ttraining's binary_logloss: 0.576263\n",
      "[43]\ttraining's binary_logloss: 0.575866\n",
      "[44]\ttraining's binary_logloss: 0.575379\n",
      "[45]\ttraining's binary_logloss: 0.574853\n",
      "[46]\ttraining's binary_logloss: 0.574342\n",
      "[47]\ttraining's binary_logloss: 0.573817\n",
      "[48]\ttraining's binary_logloss: 0.573408\n",
      "[49]\ttraining's binary_logloss: 0.57295\n",
      "[50]\ttraining's binary_logloss: 0.572485\n",
      "[51]\ttraining's binary_logloss: 0.572031\n",
      "[52]\ttraining's binary_logloss: 0.571652\n",
      "[53]\ttraining's binary_logloss: 0.571278\n",
      "[54]\ttraining's binary_logloss: 0.570887\n",
      "[55]\ttraining's binary_logloss: 0.570486\n",
      "[56]\ttraining's binary_logloss: 0.570158\n",
      "[57]\ttraining's binary_logloss: 0.569829\n",
      "[58]\ttraining's binary_logloss: 0.569507\n",
      "[59]\ttraining's binary_logloss: 0.569168\n",
      "[60]\ttraining's binary_logloss: 0.568795\n",
      "[61]\ttraining's binary_logloss: 0.568476\n",
      "[62]\ttraining's binary_logloss: 0.568178\n",
      "[63]\ttraining's binary_logloss: 0.567883\n",
      "[64]\ttraining's binary_logloss: 0.567568\n",
      "[65]\ttraining's binary_logloss: 0.567226\n",
      "[66]\ttraining's binary_logloss: 0.566857\n",
      "[67]\ttraining's binary_logloss: 0.566491\n",
      "[68]\ttraining's binary_logloss: 0.566231\n",
      "[69]\ttraining's binary_logloss: 0.565921\n",
      "[70]\ttraining's binary_logloss: 0.565617\n",
      "[71]\ttraining's binary_logloss: 0.565285\n",
      "[72]\ttraining's binary_logloss: 0.564964\n",
      "[73]\ttraining's binary_logloss: 0.564647\n",
      "[74]\ttraining's binary_logloss: 0.564353\n",
      "[75]\ttraining's binary_logloss: 0.564061\n",
      "[76]\ttraining's binary_logloss: 0.563775\n",
      "[77]\ttraining's binary_logloss: 0.563527\n",
      "[78]\ttraining's binary_logloss: 0.563268\n",
      "[79]\ttraining's binary_logloss: 0.563042\n",
      "[80]\ttraining's binary_logloss: 0.562849\n",
      "[81]\ttraining's binary_logloss: 0.562628\n",
      "[82]\ttraining's binary_logloss: 0.562374\n",
      "[83]\ttraining's binary_logloss: 0.562126\n",
      "[84]\ttraining's binary_logloss: 0.561837\n",
      "[85]\ttraining's binary_logloss: 0.561558\n",
      "[86]\ttraining's binary_logloss: 0.561345\n",
      "[87]\ttraining's binary_logloss: 0.561089\n",
      "[88]\ttraining's binary_logloss: 0.560848\n",
      "[89]\ttraining's binary_logloss: 0.56059\n",
      "[90]\ttraining's binary_logloss: 0.560432\n",
      "[91]\ttraining's binary_logloss: 0.560197\n",
      "[92]\ttraining's binary_logloss: 0.560015\n",
      "[93]\ttraining's binary_logloss: 0.559799\n",
      "[94]\ttraining's binary_logloss: 0.559613\n",
      "[95]\ttraining's binary_logloss: 0.559403\n",
      "[96]\ttraining's binary_logloss: 0.559212\n",
      "[97]\ttraining's binary_logloss: 0.55902\n",
      "[98]\ttraining's binary_logloss: 0.558874\n",
      "[99]\ttraining's binary_logloss: 0.558668\n",
      "[100]\ttraining's binary_logloss: 0.558492\n",
      "[101]\ttraining's binary_logloss: 0.558338\n",
      "[102]\ttraining's binary_logloss: 0.558182\n",
      "[103]\ttraining's binary_logloss: 0.558037\n",
      "[104]\ttraining's binary_logloss: 0.557873\n",
      "[105]\ttraining's binary_logloss: 0.557757\n",
      "[106]\ttraining's binary_logloss: 0.557577\n",
      "[107]\ttraining's binary_logloss: 0.557439\n",
      "[108]\ttraining's binary_logloss: 0.557245\n",
      "[109]\ttraining's binary_logloss: 0.557073\n",
      "[110]\ttraining's binary_logloss: 0.55692\n",
      "[111]\ttraining's binary_logloss: 0.556776\n",
      "[112]\ttraining's binary_logloss: 0.556618\n",
      "[113]\ttraining's binary_logloss: 0.556453\n",
      "[114]\ttraining's binary_logloss: 0.556333\n",
      "[115]\ttraining's binary_logloss: 0.556194\n",
      "[116]\ttraining's binary_logloss: 0.556021\n",
      "[117]\ttraining's binary_logloss: 0.555844\n",
      "[118]\ttraining's binary_logloss: 0.55572\n",
      "[119]\ttraining's binary_logloss: 0.555561\n",
      "[120]\ttraining's binary_logloss: 0.555399\n",
      "[121]\ttraining's binary_logloss: 0.555257\n",
      "[122]\ttraining's binary_logloss: 0.555093\n",
      "[123]\ttraining's binary_logloss: 0.55495\n",
      "[124]\ttraining's binary_logloss: 0.554777\n",
      "[125]\ttraining's binary_logloss: 0.554607\n",
      "[126]\ttraining's binary_logloss: 0.554403\n",
      "[127]\ttraining's binary_logloss: 0.554201\n",
      "[128]\ttraining's binary_logloss: 0.554011\n",
      "[129]\ttraining's binary_logloss: 0.553854\n",
      "[130]\ttraining's binary_logloss: 0.553675\n",
      "[131]\ttraining's binary_logloss: 0.553547\n",
      "[132]\ttraining's binary_logloss: 0.553431\n",
      "[133]\ttraining's binary_logloss: 0.553279\n",
      "[134]\ttraining's binary_logloss: 0.553142\n",
      "[135]\ttraining's binary_logloss: 0.553035\n",
      "[136]\ttraining's binary_logloss: 0.552924\n",
      "[137]\ttraining's binary_logloss: 0.552811\n",
      "[138]\ttraining's binary_logloss: 0.552643\n",
      "[139]\ttraining's binary_logloss: 0.552523\n",
      "[140]\ttraining's binary_logloss: 0.552384\n",
      "[141]\ttraining's binary_logloss: 0.552184\n",
      "[142]\ttraining's binary_logloss: 0.552033\n",
      "[143]\ttraining's binary_logloss: 0.551844\n",
      "[144]\ttraining's binary_logloss: 0.551663\n",
      "[145]\ttraining's binary_logloss: 0.551533\n",
      "[146]\ttraining's binary_logloss: 0.551354\n",
      "[147]\ttraining's binary_logloss: 0.551142\n",
      "[148]\ttraining's binary_logloss: 0.55094\n",
      "[149]\ttraining's binary_logloss: 0.550778\n",
      "[150]\ttraining's binary_logloss: 0.550599\n",
      "[151]\ttraining's binary_logloss: 0.550466\n",
      "[152]\ttraining's binary_logloss: 0.550327\n",
      "[153]\ttraining's binary_logloss: 0.550177\n",
      "[154]\ttraining's binary_logloss: 0.550045\n",
      "[155]\ttraining's binary_logloss: 0.549916\n",
      "[156]\ttraining's binary_logloss: 0.549804\n",
      "[157]\ttraining's binary_logloss: 0.54968\n",
      "[158]\ttraining's binary_logloss: 0.549525\n",
      "[159]\ttraining's binary_logloss: 0.549415\n",
      "[160]\ttraining's binary_logloss: 0.549318\n",
      "[161]\ttraining's binary_logloss: 0.549108\n",
      "[162]\ttraining's binary_logloss: 0.548935\n",
      "[163]\ttraining's binary_logloss: 0.548796\n",
      "[164]\ttraining's binary_logloss: 0.548639\n",
      "[165]\ttraining's binary_logloss: 0.548439\n",
      "[166]\ttraining's binary_logloss: 0.548271\n",
      "[167]\ttraining's binary_logloss: 0.548123\n",
      "[168]\ttraining's binary_logloss: 0.54794\n",
      "[169]\ttraining's binary_logloss: 0.547769\n",
      "[170]\ttraining's binary_logloss: 0.547635\n",
      "[171]\ttraining's binary_logloss: 0.547504\n",
      "[172]\ttraining's binary_logloss: 0.547393\n",
      "[173]\ttraining's binary_logloss: 0.547327\n",
      "[174]\ttraining's binary_logloss: 0.547262\n",
      "[175]\ttraining's binary_logloss: 0.547114\n",
      "[176]\ttraining's binary_logloss: 0.546989\n",
      "[177]\ttraining's binary_logloss: 0.546863\n",
      "[178]\ttraining's binary_logloss: 0.546767\n",
      "[179]\ttraining's binary_logloss: 0.54666\n",
      "[180]\ttraining's binary_logloss: 0.546572\n",
      "[181]\ttraining's binary_logloss: 0.546453\n",
      "[182]\ttraining's binary_logloss: 0.546333\n",
      "[183]\ttraining's binary_logloss: 0.546222\n",
      "[184]\ttraining's binary_logloss: 0.546078\n",
      "[185]\ttraining's binary_logloss: 0.545969\n",
      "[186]\ttraining's binary_logloss: 0.545847\n",
      "[187]\ttraining's binary_logloss: 0.545729\n",
      "[188]\ttraining's binary_logloss: 0.545625\n",
      "[189]\ttraining's binary_logloss: 0.545529\n",
      "[190]\ttraining's binary_logloss: 0.545414\n",
      "[191]\ttraining's binary_logloss: 0.545292\n",
      "[192]\ttraining's binary_logloss: 0.545128\n",
      "[193]\ttraining's binary_logloss: 0.545013\n",
      "[194]\ttraining's binary_logloss: 0.544856\n",
      "[195]\ttraining's binary_logloss: 0.544692\n",
      "[196]\ttraining's binary_logloss: 0.544593\n",
      "[197]\ttraining's binary_logloss: 0.544471\n",
      "[198]\ttraining's binary_logloss: 0.544354\n",
      "[199]\ttraining's binary_logloss: 0.544225\n",
      "[200]\ttraining's binary_logloss: 0.54412\n",
      "[201]\ttraining's binary_logloss: 0.543989\n",
      "[202]\ttraining's binary_logloss: 0.54383\n",
      "[203]\ttraining's binary_logloss: 0.54369\n",
      "[204]\ttraining's binary_logloss: 0.543559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[205]\ttraining's binary_logloss: 0.543408\n",
      "[206]\ttraining's binary_logloss: 0.543244\n",
      "[207]\ttraining's binary_logloss: 0.543119\n",
      "[208]\ttraining's binary_logloss: 0.54302\n",
      "[209]\ttraining's binary_logloss: 0.542885\n",
      "[210]\ttraining's binary_logloss: 0.542722\n",
      "[211]\ttraining's binary_logloss: 0.542568\n",
      "[212]\ttraining's binary_logloss: 0.542433\n",
      "[213]\ttraining's binary_logloss: 0.542289\n",
      "[214]\ttraining's binary_logloss: 0.542149\n",
      "[215]\ttraining's binary_logloss: 0.542015\n",
      "[216]\ttraining's binary_logloss: 0.541858\n",
      "[217]\ttraining's binary_logloss: 0.541702\n",
      "[218]\ttraining's binary_logloss: 0.541543\n",
      "[219]\ttraining's binary_logloss: 0.541326\n",
      "[220]\ttraining's binary_logloss: 0.541194\n",
      "[221]\ttraining's binary_logloss: 0.541017\n",
      "[222]\ttraining's binary_logloss: 0.540844\n",
      "[223]\ttraining's binary_logloss: 0.54067\n",
      "[224]\ttraining's binary_logloss: 0.540485\n",
      "[225]\ttraining's binary_logloss: 0.540338\n",
      "[226]\ttraining's binary_logloss: 0.540172\n",
      "[227]\ttraining's binary_logloss: 0.540021\n",
      "[228]\ttraining's binary_logloss: 0.539845\n",
      "[229]\ttraining's binary_logloss: 0.539686\n",
      "[230]\ttraining's binary_logloss: 0.539529\n",
      "[231]\ttraining's binary_logloss: 0.53938\n",
      "[232]\ttraining's binary_logloss: 0.539186\n",
      "[233]\ttraining's binary_logloss: 0.539045\n",
      "[234]\ttraining's binary_logloss: 0.538922\n",
      "[235]\ttraining's binary_logloss: 0.53873\n",
      "[236]\ttraining's binary_logloss: 0.53858\n",
      "[237]\ttraining's binary_logloss: 0.538437\n",
      "[238]\ttraining's binary_logloss: 0.538306\n",
      "[239]\ttraining's binary_logloss: 0.538194\n",
      "[240]\ttraining's binary_logloss: 0.538051\n",
      "[241]\ttraining's binary_logloss: 0.537903\n",
      "[242]\ttraining's binary_logloss: 0.537714\n",
      "[243]\ttraining's binary_logloss: 0.537523\n",
      "[244]\ttraining's binary_logloss: 0.537385\n",
      "[245]\ttraining's binary_logloss: 0.537209\n",
      "[246]\ttraining's binary_logloss: 0.537015\n",
      "[247]\ttraining's binary_logloss: 0.536786\n",
      "[248]\ttraining's binary_logloss: 0.536584\n",
      "[249]\ttraining's binary_logloss: 0.536376\n",
      "[250]\ttraining's binary_logloss: 0.536202\n",
      "[251]\ttraining's binary_logloss: 0.536074\n",
      "[252]\ttraining's binary_logloss: 0.53591\n",
      "[253]\ttraining's binary_logloss: 0.535791\n",
      "[254]\ttraining's binary_logloss: 0.535634\n",
      "[255]\ttraining's binary_logloss: 0.535496\n",
      "[256]\ttraining's binary_logloss: 0.535324\n",
      "[257]\ttraining's binary_logloss: 0.535135\n",
      "[258]\ttraining's binary_logloss: 0.534933\n",
      "[259]\ttraining's binary_logloss: 0.534739\n",
      "[260]\ttraining's binary_logloss: 0.534494\n",
      "[261]\ttraining's binary_logloss: 0.534353\n",
      "[262]\ttraining's binary_logloss: 0.534203\n",
      "[263]\ttraining's binary_logloss: 0.534061\n",
      "[264]\ttraining's binary_logloss: 0.533944\n",
      "[265]\ttraining's binary_logloss: 0.533785\n",
      "[266]\ttraining's binary_logloss: 0.533659\n",
      "[267]\ttraining's binary_logloss: 0.533536\n",
      "[268]\ttraining's binary_logloss: 0.533404\n",
      "[269]\ttraining's binary_logloss: 0.533268\n",
      "[270]\ttraining's binary_logloss: 0.533113\n",
      "[271]\ttraining's binary_logloss: 0.532901\n",
      "[272]\ttraining's binary_logloss: 0.532695\n",
      "[273]\ttraining's binary_logloss: 0.532528\n",
      "[274]\ttraining's binary_logloss: 0.532371\n",
      "[275]\ttraining's binary_logloss: 0.532197\n",
      "[276]\ttraining's binary_logloss: 0.532033\n",
      "[277]\ttraining's binary_logloss: 0.531856\n",
      "[278]\ttraining's binary_logloss: 0.531681\n",
      "[279]\ttraining's binary_logloss: 0.5315\n",
      "[280]\ttraining's binary_logloss: 0.531329\n",
      "[281]\ttraining's binary_logloss: 0.53111\n",
      "[282]\ttraining's binary_logloss: 0.530891\n",
      "[283]\ttraining's binary_logloss: 0.530681\n",
      "[284]\ttraining's binary_logloss: 0.530513\n",
      "[285]\ttraining's binary_logloss: 0.530297\n",
      "[286]\ttraining's binary_logloss: 0.53009\n",
      "[287]\ttraining's binary_logloss: 0.529903\n",
      "[288]\ttraining's binary_logloss: 0.529722\n",
      "[289]\ttraining's binary_logloss: 0.529516\n",
      "[290]\ttraining's binary_logloss: 0.529332\n",
      "[291]\ttraining's binary_logloss: 0.529114\n",
      "[292]\ttraining's binary_logloss: 0.528912\n",
      "[293]\ttraining's binary_logloss: 0.528703\n",
      "[294]\ttraining's binary_logloss: 0.528492\n",
      "[295]\ttraining's binary_logloss: 0.528292\n",
      "[296]\ttraining's binary_logloss: 0.528094\n",
      "[297]\ttraining's binary_logloss: 0.527921\n",
      "[298]\ttraining's binary_logloss: 0.527747\n",
      "[299]\ttraining's binary_logloss: 0.527582\n",
      "[300]\ttraining's binary_logloss: 0.527385\n",
      "[301]\ttraining's binary_logloss: 0.527198\n",
      "[302]\ttraining's binary_logloss: 0.527023\n",
      "[303]\ttraining's binary_logloss: 0.526828\n",
      "[304]\ttraining's binary_logloss: 0.526663\n",
      "[305]\ttraining's binary_logloss: 0.526483\n",
      "[306]\ttraining's binary_logloss: 0.526294\n",
      "[307]\ttraining's binary_logloss: 0.526114\n",
      "[308]\ttraining's binary_logloss: 0.525929\n",
      "[309]\ttraining's binary_logloss: 0.52575\n",
      "[310]\ttraining's binary_logloss: 0.525573\n",
      "[311]\ttraining's binary_logloss: 0.525366\n",
      "[312]\ttraining's binary_logloss: 0.525165\n",
      "[313]\ttraining's binary_logloss: 0.524989\n",
      "[314]\ttraining's binary_logloss: 0.524734\n",
      "[315]\ttraining's binary_logloss: 0.524541\n",
      "[316]\ttraining's binary_logloss: 0.524368\n",
      "[317]\ttraining's binary_logloss: 0.524169\n",
      "[318]\ttraining's binary_logloss: 0.523993\n",
      "[319]\ttraining's binary_logloss: 0.523821\n",
      "[320]\ttraining's binary_logloss: 0.52363\n",
      "[321]\ttraining's binary_logloss: 0.52344\n",
      "[322]\ttraining's binary_logloss: 0.523256\n",
      "[323]\ttraining's binary_logloss: 0.523074\n",
      "[324]\ttraining's binary_logloss: 0.522884\n",
      "[325]\ttraining's binary_logloss: 0.522709\n",
      "[326]\ttraining's binary_logloss: 0.522522\n",
      "[327]\ttraining's binary_logloss: 0.522336\n",
      "[328]\ttraining's binary_logloss: 0.522133\n",
      "[329]\ttraining's binary_logloss: 0.521953\n",
      "[330]\ttraining's binary_logloss: 0.521762\n",
      "[331]\ttraining's binary_logloss: 0.521537\n",
      "[332]\ttraining's binary_logloss: 0.521363\n",
      "[333]\ttraining's binary_logloss: 0.521161\n",
      "[334]\ttraining's binary_logloss: 0.520962\n",
      "[335]\ttraining's binary_logloss: 0.520793\n",
      "[336]\ttraining's binary_logloss: 0.520581\n",
      "[337]\ttraining's binary_logloss: 0.520405\n",
      "[338]\ttraining's binary_logloss: 0.520199\n",
      "[339]\ttraining's binary_logloss: 0.520015\n",
      "[340]\ttraining's binary_logloss: 0.519811\n",
      "[341]\ttraining's binary_logloss: 0.519671\n",
      "[342]\ttraining's binary_logloss: 0.519525\n",
      "[343]\ttraining's binary_logloss: 0.519363\n",
      "[344]\ttraining's binary_logloss: 0.519214\n",
      "[345]\ttraining's binary_logloss: 0.519076\n",
      "[346]\ttraining's binary_logloss: 0.518923\n",
      "[347]\ttraining's binary_logloss: 0.518743\n",
      "[348]\ttraining's binary_logloss: 0.518584\n",
      "[349]\ttraining's binary_logloss: 0.518423\n",
      "[350]\ttraining's binary_logloss: 0.518296\n",
      "[351]\ttraining's binary_logloss: 0.518092\n",
      "[352]\ttraining's binary_logloss: 0.517867\n",
      "[353]\ttraining's binary_logloss: 0.517638\n",
      "[354]\ttraining's binary_logloss: 0.517433\n",
      "[355]\ttraining's binary_logloss: 0.517219\n",
      "[356]\ttraining's binary_logloss: 0.51702\n",
      "[357]\ttraining's binary_logloss: 0.516811\n",
      "[358]\ttraining's binary_logloss: 0.516619\n",
      "[359]\ttraining's binary_logloss: 0.516427\n",
      "[360]\ttraining's binary_logloss: 0.516229\n",
      "[361]\ttraining's binary_logloss: 0.516028\n",
      "[362]\ttraining's binary_logloss: 0.515787\n",
      "[363]\ttraining's binary_logloss: 0.515576\n",
      "[364]\ttraining's binary_logloss: 0.515346\n",
      "[365]\ttraining's binary_logloss: 0.515157\n",
      "[366]\ttraining's binary_logloss: 0.51495\n",
      "[367]\ttraining's binary_logloss: 0.514774\n",
      "[368]\ttraining's binary_logloss: 0.514587\n",
      "[369]\ttraining's binary_logloss: 0.51443\n",
      "[370]\ttraining's binary_logloss: 0.514274\n",
      "[371]\ttraining's binary_logloss: 0.51412\n",
      "[372]\ttraining's binary_logloss: 0.513961\n",
      "[373]\ttraining's binary_logloss: 0.513812\n",
      "[374]\ttraining's binary_logloss: 0.513659\n",
      "[375]\ttraining's binary_logloss: 0.513524\n",
      "[376]\ttraining's binary_logloss: 0.513341\n",
      "[377]\ttraining's binary_logloss: 0.513176\n",
      "[378]\ttraining's binary_logloss: 0.512998\n",
      "[379]\ttraining's binary_logloss: 0.51284\n",
      "[380]\ttraining's binary_logloss: 0.512648\n",
      "[381]\ttraining's binary_logloss: 0.512467\n",
      "[382]\ttraining's binary_logloss: 0.512313\n",
      "[383]\ttraining's binary_logloss: 0.512139\n",
      "[384]\ttraining's binary_logloss: 0.512006\n",
      "[385]\ttraining's binary_logloss: 0.511847\n",
      "[386]\ttraining's binary_logloss: 0.511632\n",
      "[387]\ttraining's binary_logloss: 0.511435\n",
      "[388]\ttraining's binary_logloss: 0.511198\n",
      "[389]\ttraining's binary_logloss: 0.511007\n",
      "[390]\ttraining's binary_logloss: 0.51083\n",
      "[391]\ttraining's binary_logloss: 0.510598\n",
      "[392]\ttraining's binary_logloss: 0.510368\n",
      "[393]\ttraining's binary_logloss: 0.510145\n",
      "[394]\ttraining's binary_logloss: 0.509942\n",
      "[395]\ttraining's binary_logloss: 0.509734\n",
      "[396]\ttraining's binary_logloss: 0.509525\n",
      "[397]\ttraining's binary_logloss: 0.509332\n",
      "[398]\ttraining's binary_logloss: 0.509151\n",
      "[399]\ttraining's binary_logloss: 0.508971\n",
      "[400]\ttraining's binary_logloss: 0.50881\n",
      "[401]\ttraining's binary_logloss: 0.508604\n",
      "[402]\ttraining's binary_logloss: 0.508389\n",
      "[403]\ttraining's binary_logloss: 0.508142\n",
      "[404]\ttraining's binary_logloss: 0.507923\n",
      "[405]\ttraining's binary_logloss: 0.507725\n",
      "[406]\ttraining's binary_logloss: 0.507513\n",
      "[407]\ttraining's binary_logloss: 0.5073\n",
      "[408]\ttraining's binary_logloss: 0.507121\n",
      "[409]\ttraining's binary_logloss: 0.506915\n",
      "[410]\ttraining's binary_logloss: 0.506727\n",
      "[411]\ttraining's binary_logloss: 0.506508\n",
      "[412]\ttraining's binary_logloss: 0.506286\n",
      "[413]\ttraining's binary_logloss: 0.506125\n",
      "[414]\ttraining's binary_logloss: 0.505932\n",
      "[415]\ttraining's binary_logloss: 0.505766\n",
      "[416]\ttraining's binary_logloss: 0.505583\n",
      "[417]\ttraining's binary_logloss: 0.505426\n",
      "[418]\ttraining's binary_logloss: 0.505257\n",
      "[419]\ttraining's binary_logloss: 0.505105\n",
      "[420]\ttraining's binary_logloss: 0.504915\n",
      "[421]\ttraining's binary_logloss: 0.504773\n",
      "[422]\ttraining's binary_logloss: 0.504659\n",
      "[423]\ttraining's binary_logloss: 0.504514\n",
      "[424]\ttraining's binary_logloss: 0.504393\n",
      "[425]\ttraining's binary_logloss: 0.504256\n",
      "[426]\ttraining's binary_logloss: 0.504099\n",
      "[427]\ttraining's binary_logloss: 0.503932\n",
      "[428]\ttraining's binary_logloss: 0.503743\n",
      "[429]\ttraining's binary_logloss: 0.503584\n",
      "[430]\ttraining's binary_logloss: 0.503434\n",
      "[431]\ttraining's binary_logloss: 0.503223\n",
      "[432]\ttraining's binary_logloss: 0.503\n",
      "[433]\ttraining's binary_logloss: 0.50279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[434]\ttraining's binary_logloss: 0.502555\n",
      "[435]\ttraining's binary_logloss: 0.502333\n",
      "[436]\ttraining's binary_logloss: 0.502137\n",
      "[437]\ttraining's binary_logloss: 0.501972\n",
      "[438]\ttraining's binary_logloss: 0.501797\n",
      "[439]\ttraining's binary_logloss: 0.501605\n",
      "[440]\ttraining's binary_logloss: 0.501457\n",
      "[441]\ttraining's binary_logloss: 0.501245\n",
      "[442]\ttraining's binary_logloss: 0.501021\n",
      "[443]\ttraining's binary_logloss: 0.500801\n",
      "[444]\ttraining's binary_logloss: 0.500586\n",
      "[445]\ttraining's binary_logloss: 0.500377\n",
      "[446]\ttraining's binary_logloss: 0.500192\n",
      "[447]\ttraining's binary_logloss: 0.499973\n",
      "[448]\ttraining's binary_logloss: 0.499769\n",
      "[449]\ttraining's binary_logloss: 0.499569\n",
      "[450]\ttraining's binary_logloss: 0.499367\n",
      "[451]\ttraining's binary_logloss: 0.49919\n",
      "[452]\ttraining's binary_logloss: 0.499032\n",
      "[453]\ttraining's binary_logloss: 0.498894\n",
      "[454]\ttraining's binary_logloss: 0.498735\n",
      "[455]\ttraining's binary_logloss: 0.498563\n",
      "[456]\ttraining's binary_logloss: 0.498399\n",
      "[457]\ttraining's binary_logloss: 0.498233\n",
      "[458]\ttraining's binary_logloss: 0.498083\n",
      "[459]\ttraining's binary_logloss: 0.497935\n",
      "[460]\ttraining's binary_logloss: 0.497769\n",
      "[461]\ttraining's binary_logloss: 0.497595\n",
      "[462]\ttraining's binary_logloss: 0.497444\n",
      "[463]\ttraining's binary_logloss: 0.497282\n",
      "[464]\ttraining's binary_logloss: 0.497111\n",
      "[465]\ttraining's binary_logloss: 0.496966\n",
      "[466]\ttraining's binary_logloss: 0.496794\n",
      "[467]\ttraining's binary_logloss: 0.496618\n",
      "[468]\ttraining's binary_logloss: 0.496442\n",
      "[469]\ttraining's binary_logloss: 0.496267\n",
      "[470]\ttraining's binary_logloss: 0.496105\n",
      "[471]\ttraining's binary_logloss: 0.495953\n",
      "[472]\ttraining's binary_logloss: 0.495807\n",
      "[473]\ttraining's binary_logloss: 0.495663\n",
      "[474]\ttraining's binary_logloss: 0.495529\n",
      "[475]\ttraining's binary_logloss: 0.495372\n",
      "[476]\ttraining's binary_logloss: 0.495156\n",
      "[477]\ttraining's binary_logloss: 0.494953\n",
      "[478]\ttraining's binary_logloss: 0.49475\n",
      "[479]\ttraining's binary_logloss: 0.49456\n",
      "[480]\ttraining's binary_logloss: 0.494391\n",
      "[481]\ttraining's binary_logloss: 0.494196\n",
      "[482]\ttraining's binary_logloss: 0.494012\n",
      "[483]\ttraining's binary_logloss: 0.493827\n",
      "[484]\ttraining's binary_logloss: 0.493636\n",
      "[485]\ttraining's binary_logloss: 0.493482\n",
      "[486]\ttraining's binary_logloss: 0.493257\n",
      "[487]\ttraining's binary_logloss: 0.493061\n",
      "[488]\ttraining's binary_logloss: 0.492855\n",
      "[489]\ttraining's binary_logloss: 0.492637\n",
      "[490]\ttraining's binary_logloss: 0.492436\n",
      "[491]\ttraining's binary_logloss: 0.492249\n",
      "[492]\ttraining's binary_logloss: 0.492061\n",
      "[493]\ttraining's binary_logloss: 0.491873\n",
      "[494]\ttraining's binary_logloss: 0.491698\n",
      "[495]\ttraining's binary_logloss: 0.491514\n",
      "[496]\ttraining's binary_logloss: 0.491324\n",
      "[497]\ttraining's binary_logloss: 0.49116\n",
      "[498]\ttraining's binary_logloss: 0.490998\n",
      "[499]\ttraining's binary_logloss: 0.490817\n",
      "[500]\ttraining's binary_logloss: 0.490643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.61727\n",
      "[2]\ttraining's binary_logloss: 0.61584\n",
      "[3]\ttraining's binary_logloss: 0.614423\n",
      "[4]\ttraining's binary_logloss: 0.61306\n",
      "[5]\ttraining's binary_logloss: 0.611747\n",
      "[6]\ttraining's binary_logloss: 0.61047\n",
      "[7]\ttraining's binary_logloss: 0.609253\n",
      "[8]\ttraining's binary_logloss: 0.608106\n",
      "[9]\ttraining's binary_logloss: 0.60689\n",
      "[10]\ttraining's binary_logloss: 0.605804\n",
      "[11]\ttraining's binary_logloss: 0.604649\n",
      "[12]\ttraining's binary_logloss: 0.603459\n",
      "[13]\ttraining's binary_logloss: 0.602307\n",
      "[14]\ttraining's binary_logloss: 0.601263\n",
      "[15]\ttraining's binary_logloss: 0.600251\n",
      "[16]\ttraining's binary_logloss: 0.599264\n",
      "[17]\ttraining's binary_logloss: 0.598322\n",
      "[18]\ttraining's binary_logloss: 0.597426\n",
      "[19]\ttraining's binary_logloss: 0.596545\n",
      "[20]\ttraining's binary_logloss: 0.595583\n",
      "[21]\ttraining's binary_logloss: 0.594655\n",
      "[22]\ttraining's binary_logloss: 0.593796\n",
      "[23]\ttraining's binary_logloss: 0.592952\n",
      "[24]\ttraining's binary_logloss: 0.592139\n",
      "[25]\ttraining's binary_logloss: 0.591253\n",
      "[26]\ttraining's binary_logloss: 0.590481\n",
      "[27]\ttraining's binary_logloss: 0.589708\n",
      "[28]\ttraining's binary_logloss: 0.588946\n",
      "[29]\ttraining's binary_logloss: 0.588248\n",
      "[30]\ttraining's binary_logloss: 0.587588\n",
      "[31]\ttraining's binary_logloss: 0.586938\n",
      "[32]\ttraining's binary_logloss: 0.586299\n",
      "[33]\ttraining's binary_logloss: 0.585714\n",
      "[34]\ttraining's binary_logloss: 0.585108\n",
      "[35]\ttraining's binary_logloss: 0.584432\n",
      "[36]\ttraining's binary_logloss: 0.583822\n",
      "[37]\ttraining's binary_logloss: 0.583331\n",
      "[38]\ttraining's binary_logloss: 0.582771\n",
      "[39]\ttraining's binary_logloss: 0.582263\n",
      "[40]\ttraining's binary_logloss: 0.581702\n",
      "[41]\ttraining's binary_logloss: 0.581208\n",
      "[42]\ttraining's binary_logloss: 0.580733\n",
      "[43]\ttraining's binary_logloss: 0.580294\n",
      "[44]\ttraining's binary_logloss: 0.579845\n",
      "[45]\ttraining's binary_logloss: 0.579401\n",
      "[46]\ttraining's binary_logloss: 0.578938\n",
      "[47]\ttraining's binary_logloss: 0.578465\n",
      "[48]\ttraining's binary_logloss: 0.578017\n",
      "[49]\ttraining's binary_logloss: 0.57754\n",
      "[50]\ttraining's binary_logloss: 0.577137\n",
      "[51]\ttraining's binary_logloss: 0.576704\n",
      "[52]\ttraining's binary_logloss: 0.576269\n",
      "[53]\ttraining's binary_logloss: 0.575838\n",
      "[54]\ttraining's binary_logloss: 0.575415\n",
      "[55]\ttraining's binary_logloss: 0.575054\n",
      "[56]\ttraining's binary_logloss: 0.574729\n",
      "[57]\ttraining's binary_logloss: 0.57437\n",
      "[58]\ttraining's binary_logloss: 0.574036\n",
      "[59]\ttraining's binary_logloss: 0.57372\n",
      "[60]\ttraining's binary_logloss: 0.573402\n",
      "[61]\ttraining's binary_logloss: 0.573006\n",
      "[62]\ttraining's binary_logloss: 0.572662\n",
      "[63]\ttraining's binary_logloss: 0.57229\n",
      "[64]\ttraining's binary_logloss: 0.571931\n",
      "[65]\ttraining's binary_logloss: 0.57162\n",
      "[66]\ttraining's binary_logloss: 0.571313\n",
      "[67]\ttraining's binary_logloss: 0.570951\n",
      "[68]\ttraining's binary_logloss: 0.570599\n",
      "[69]\ttraining's binary_logloss: 0.570265\n",
      "[70]\ttraining's binary_logloss: 0.569918\n",
      "[71]\ttraining's binary_logloss: 0.569581\n",
      "[72]\ttraining's binary_logloss: 0.569363\n",
      "[73]\ttraining's binary_logloss: 0.569061\n",
      "[74]\ttraining's binary_logloss: 0.568848\n",
      "[75]\ttraining's binary_logloss: 0.568528\n",
      "[76]\ttraining's binary_logloss: 0.568224\n",
      "[77]\ttraining's binary_logloss: 0.567898\n",
      "[78]\ttraining's binary_logloss: 0.56765\n",
      "[79]\ttraining's binary_logloss: 0.567371\n",
      "[80]\ttraining's binary_logloss: 0.567099\n",
      "[81]\ttraining's binary_logloss: 0.566815\n",
      "[82]\ttraining's binary_logloss: 0.566524\n",
      "[83]\ttraining's binary_logloss: 0.566257\n",
      "[84]\ttraining's binary_logloss: 0.566034\n",
      "[85]\ttraining's binary_logloss: 0.565792\n",
      "[86]\ttraining's binary_logloss: 0.565582\n",
      "[87]\ttraining's binary_logloss: 0.565369\n",
      "[88]\ttraining's binary_logloss: 0.565175\n",
      "[89]\ttraining's binary_logloss: 0.564946\n",
      "[90]\ttraining's binary_logloss: 0.564735\n",
      "[91]\ttraining's binary_logloss: 0.564487\n",
      "[92]\ttraining's binary_logloss: 0.564262\n",
      "[93]\ttraining's binary_logloss: 0.564039\n",
      "[94]\ttraining's binary_logloss: 0.563863\n",
      "[95]\ttraining's binary_logloss: 0.563703\n",
      "[96]\ttraining's binary_logloss: 0.563544\n",
      "[97]\ttraining's binary_logloss: 0.563373\n",
      "[98]\ttraining's binary_logloss: 0.56322\n",
      "[99]\ttraining's binary_logloss: 0.563061\n",
      "[100]\ttraining's binary_logloss: 0.562872\n",
      "[101]\ttraining's binary_logloss: 0.562693\n",
      "[102]\ttraining's binary_logloss: 0.562516\n",
      "[103]\ttraining's binary_logloss: 0.562346\n",
      "[104]\ttraining's binary_logloss: 0.562173\n",
      "[105]\ttraining's binary_logloss: 0.561995\n",
      "[106]\ttraining's binary_logloss: 0.561824\n",
      "[107]\ttraining's binary_logloss: 0.561611\n",
      "[108]\ttraining's binary_logloss: 0.561415\n",
      "[109]\ttraining's binary_logloss: 0.561244\n",
      "[110]\ttraining's binary_logloss: 0.561064\n",
      "[111]\ttraining's binary_logloss: 0.560865\n",
      "[112]\ttraining's binary_logloss: 0.560688\n",
      "[113]\ttraining's binary_logloss: 0.560513\n",
      "[114]\ttraining's binary_logloss: 0.560401\n",
      "[115]\ttraining's binary_logloss: 0.560234\n",
      "[116]\ttraining's binary_logloss: 0.560074\n",
      "[117]\ttraining's binary_logloss: 0.559886\n",
      "[118]\ttraining's binary_logloss: 0.559706\n",
      "[119]\ttraining's binary_logloss: 0.559529\n",
      "[120]\ttraining's binary_logloss: 0.559378\n",
      "[121]\ttraining's binary_logloss: 0.559247\n",
      "[122]\ttraining's binary_logloss: 0.559113\n",
      "[123]\ttraining's binary_logloss: 0.558986\n",
      "[124]\ttraining's binary_logloss: 0.558859\n",
      "[125]\ttraining's binary_logloss: 0.55875\n",
      "[126]\ttraining's binary_logloss: 0.558579\n",
      "[127]\ttraining's binary_logloss: 0.558434\n",
      "[128]\ttraining's binary_logloss: 0.558289\n",
      "[129]\ttraining's binary_logloss: 0.558148\n",
      "[130]\ttraining's binary_logloss: 0.557986\n",
      "[131]\ttraining's binary_logloss: 0.557819\n",
      "[132]\ttraining's binary_logloss: 0.557645\n",
      "[133]\ttraining's binary_logloss: 0.557512\n",
      "[134]\ttraining's binary_logloss: 0.557347\n",
      "[135]\ttraining's binary_logloss: 0.557193\n",
      "[136]\ttraining's binary_logloss: 0.556998\n",
      "[137]\ttraining's binary_logloss: 0.55684\n",
      "[138]\ttraining's binary_logloss: 0.556684\n",
      "[139]\ttraining's binary_logloss: 0.556523\n",
      "[140]\ttraining's binary_logloss: 0.55639\n",
      "[141]\ttraining's binary_logloss: 0.556227\n",
      "[142]\ttraining's binary_logloss: 0.556034\n",
      "[143]\ttraining's binary_logloss: 0.555827\n",
      "[144]\ttraining's binary_logloss: 0.555661\n",
      "[145]\ttraining's binary_logloss: 0.555548\n",
      "[146]\ttraining's binary_logloss: 0.555424\n",
      "[147]\ttraining's binary_logloss: 0.555254\n",
      "[148]\ttraining's binary_logloss: 0.555074\n",
      "[149]\ttraining's binary_logloss: 0.554907\n",
      "[150]\ttraining's binary_logloss: 0.554729\n",
      "[151]\ttraining's binary_logloss: 0.554604\n",
      "[152]\ttraining's binary_logloss: 0.554475\n",
      "[153]\ttraining's binary_logloss: 0.55437\n",
      "[154]\ttraining's binary_logloss: 0.554252\n",
      "[155]\ttraining's binary_logloss: 0.55414\n",
      "[156]\ttraining's binary_logloss: 0.554016\n",
      "[157]\ttraining's binary_logloss: 0.553851\n",
      "[158]\ttraining's binary_logloss: 0.553693\n",
      "[159]\ttraining's binary_logloss: 0.553536\n",
      "[160]\ttraining's binary_logloss: 0.553342\n",
      "[161]\ttraining's binary_logloss: 0.553175\n",
      "[162]\ttraining's binary_logloss: 0.553025\n",
      "[163]\ttraining's binary_logloss: 0.552865\n",
      "[164]\ttraining's binary_logloss: 0.55271\n",
      "[165]\ttraining's binary_logloss: 0.552555\n",
      "[166]\ttraining's binary_logloss: 0.552394\n",
      "[167]\ttraining's binary_logloss: 0.552237\n",
      "[168]\ttraining's binary_logloss: 0.552026\n",
      "[169]\ttraining's binary_logloss: 0.551867\n",
      "[170]\ttraining's binary_logloss: 0.551721\n",
      "[171]\ttraining's binary_logloss: 0.551566\n",
      "[172]\ttraining's binary_logloss: 0.551408\n",
      "[173]\ttraining's binary_logloss: 0.551264\n",
      "[174]\ttraining's binary_logloss: 0.551111\n",
      "[175]\ttraining's binary_logloss: 0.550991\n",
      "[176]\ttraining's binary_logloss: 0.550836\n",
      "[177]\ttraining's binary_logloss: 0.550694\n",
      "[178]\ttraining's binary_logloss: 0.550574\n",
      "[179]\ttraining's binary_logloss: 0.550446\n",
      "[180]\ttraining's binary_logloss: 0.550284\n",
      "[181]\ttraining's binary_logloss: 0.550148\n",
      "[182]\ttraining's binary_logloss: 0.550014\n",
      "[183]\ttraining's binary_logloss: 0.549874\n",
      "[184]\ttraining's binary_logloss: 0.549704\n",
      "[185]\ttraining's binary_logloss: 0.549596\n",
      "[186]\ttraining's binary_logloss: 0.549458\n",
      "[187]\ttraining's binary_logloss: 0.54931\n",
      "[188]\ttraining's binary_logloss: 0.549155\n",
      "[189]\ttraining's binary_logloss: 0.549053\n",
      "[190]\ttraining's binary_logloss: 0.548887\n",
      "[191]\ttraining's binary_logloss: 0.548702\n",
      "[192]\ttraining's binary_logloss: 0.548509\n",
      "[193]\ttraining's binary_logloss: 0.548321\n",
      "[194]\ttraining's binary_logloss: 0.548119\n",
      "[195]\ttraining's binary_logloss: 0.547988\n",
      "[196]\ttraining's binary_logloss: 0.54782\n",
      "[197]\ttraining's binary_logloss: 0.547645\n",
      "[198]\ttraining's binary_logloss: 0.547494\n",
      "[199]\ttraining's binary_logloss: 0.54735\n",
      "[200]\ttraining's binary_logloss: 0.547205\n",
      "[201]\ttraining's binary_logloss: 0.547029\n",
      "[202]\ttraining's binary_logloss: 0.546897\n",
      "[203]\ttraining's binary_logloss: 0.546735\n",
      "[204]\ttraining's binary_logloss: 0.546579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[205]\ttraining's binary_logloss: 0.546413\n",
      "[206]\ttraining's binary_logloss: 0.546273\n",
      "[207]\ttraining's binary_logloss: 0.546118\n",
      "[208]\ttraining's binary_logloss: 0.545993\n",
      "[209]\ttraining's binary_logloss: 0.545873\n",
      "[210]\ttraining's binary_logloss: 0.545765\n",
      "[211]\ttraining's binary_logloss: 0.545636\n",
      "[212]\ttraining's binary_logloss: 0.545512\n",
      "[213]\ttraining's binary_logloss: 0.545402\n",
      "[214]\ttraining's binary_logloss: 0.545262\n",
      "[215]\ttraining's binary_logloss: 0.545102\n",
      "[216]\ttraining's binary_logloss: 0.544945\n",
      "[217]\ttraining's binary_logloss: 0.54476\n",
      "[218]\ttraining's binary_logloss: 0.544593\n",
      "[219]\ttraining's binary_logloss: 0.544391\n",
      "[220]\ttraining's binary_logloss: 0.544195\n",
      "[221]\ttraining's binary_logloss: 0.544024\n",
      "[222]\ttraining's binary_logloss: 0.543842\n",
      "[223]\ttraining's binary_logloss: 0.543696\n",
      "[224]\ttraining's binary_logloss: 0.543506\n",
      "[225]\ttraining's binary_logloss: 0.543331\n",
      "[226]\ttraining's binary_logloss: 0.543129\n",
      "[227]\ttraining's binary_logloss: 0.542949\n",
      "[228]\ttraining's binary_logloss: 0.54276\n",
      "[229]\ttraining's binary_logloss: 0.542592\n",
      "[230]\ttraining's binary_logloss: 0.542405\n",
      "[231]\ttraining's binary_logloss: 0.542223\n",
      "[232]\ttraining's binary_logloss: 0.542073\n",
      "[233]\ttraining's binary_logloss: 0.541932\n",
      "[234]\ttraining's binary_logloss: 0.541812\n",
      "[235]\ttraining's binary_logloss: 0.541649\n",
      "[236]\ttraining's binary_logloss: 0.541479\n",
      "[237]\ttraining's binary_logloss: 0.541258\n",
      "[238]\ttraining's binary_logloss: 0.54108\n",
      "[239]\ttraining's binary_logloss: 0.540904\n",
      "[240]\ttraining's binary_logloss: 0.540735\n",
      "[241]\ttraining's binary_logloss: 0.540548\n",
      "[242]\ttraining's binary_logloss: 0.540352\n",
      "[243]\ttraining's binary_logloss: 0.540161\n",
      "[244]\ttraining's binary_logloss: 0.539984\n",
      "[245]\ttraining's binary_logloss: 0.539807\n",
      "[246]\ttraining's binary_logloss: 0.539633\n",
      "[247]\ttraining's binary_logloss: 0.539436\n",
      "[248]\ttraining's binary_logloss: 0.53925\n",
      "[249]\ttraining's binary_logloss: 0.539065\n",
      "[250]\ttraining's binary_logloss: 0.538907\n",
      "[251]\ttraining's binary_logloss: 0.538749\n",
      "[252]\ttraining's binary_logloss: 0.538578\n",
      "[253]\ttraining's binary_logloss: 0.5384\n",
      "[254]\ttraining's binary_logloss: 0.53824\n",
      "[255]\ttraining's binary_logloss: 0.538076\n",
      "[256]\ttraining's binary_logloss: 0.537902\n",
      "[257]\ttraining's binary_logloss: 0.537752\n",
      "[258]\ttraining's binary_logloss: 0.537567\n",
      "[259]\ttraining's binary_logloss: 0.537388\n",
      "[260]\ttraining's binary_logloss: 0.537246\n",
      "[261]\ttraining's binary_logloss: 0.537059\n",
      "[262]\ttraining's binary_logloss: 0.536907\n",
      "[263]\ttraining's binary_logloss: 0.536735\n",
      "[264]\ttraining's binary_logloss: 0.53657\n",
      "[265]\ttraining's binary_logloss: 0.536396\n",
      "[266]\ttraining's binary_logloss: 0.53624\n",
      "[267]\ttraining's binary_logloss: 0.536114\n",
      "[268]\ttraining's binary_logloss: 0.535967\n",
      "[269]\ttraining's binary_logloss: 0.535825\n",
      "[270]\ttraining's binary_logloss: 0.53568\n",
      "[271]\ttraining's binary_logloss: 0.535465\n",
      "[272]\ttraining's binary_logloss: 0.535303\n",
      "[273]\ttraining's binary_logloss: 0.53509\n",
      "[274]\ttraining's binary_logloss: 0.534894\n",
      "[275]\ttraining's binary_logloss: 0.53471\n",
      "[276]\ttraining's binary_logloss: 0.534496\n",
      "[277]\ttraining's binary_logloss: 0.534291\n",
      "[278]\ttraining's binary_logloss: 0.534113\n",
      "[279]\ttraining's binary_logloss: 0.533915\n",
      "[280]\ttraining's binary_logloss: 0.533732\n",
      "[281]\ttraining's binary_logloss: 0.533567\n",
      "[282]\ttraining's binary_logloss: 0.533418\n",
      "[283]\ttraining's binary_logloss: 0.53326\n",
      "[284]\ttraining's binary_logloss: 0.533095\n",
      "[285]\ttraining's binary_logloss: 0.53294\n",
      "[286]\ttraining's binary_logloss: 0.532757\n",
      "[287]\ttraining's binary_logloss: 0.532561\n",
      "[288]\ttraining's binary_logloss: 0.532382\n",
      "[289]\ttraining's binary_logloss: 0.532177\n",
      "[290]\ttraining's binary_logloss: 0.531992\n",
      "[291]\ttraining's binary_logloss: 0.531793\n",
      "[292]\ttraining's binary_logloss: 0.5316\n",
      "[293]\ttraining's binary_logloss: 0.531445\n",
      "[294]\ttraining's binary_logloss: 0.531243\n",
      "[295]\ttraining's binary_logloss: 0.531044\n",
      "[296]\ttraining's binary_logloss: 0.530861\n",
      "[297]\ttraining's binary_logloss: 0.530687\n",
      "[298]\ttraining's binary_logloss: 0.530493\n",
      "[299]\ttraining's binary_logloss: 0.530321\n",
      "[300]\ttraining's binary_logloss: 0.530128\n",
      "[301]\ttraining's binary_logloss: 0.529932\n",
      "[302]\ttraining's binary_logloss: 0.529746\n",
      "[303]\ttraining's binary_logloss: 0.529552\n",
      "[304]\ttraining's binary_logloss: 0.529361\n",
      "[305]\ttraining's binary_logloss: 0.529165\n",
      "[306]\ttraining's binary_logloss: 0.528952\n",
      "[307]\ttraining's binary_logloss: 0.528761\n",
      "[308]\ttraining's binary_logloss: 0.528575\n",
      "[309]\ttraining's binary_logloss: 0.528382\n",
      "[310]\ttraining's binary_logloss: 0.528182\n",
      "[311]\ttraining's binary_logloss: 0.527973\n",
      "[312]\ttraining's binary_logloss: 0.527793\n",
      "[313]\ttraining's binary_logloss: 0.527613\n",
      "[314]\ttraining's binary_logloss: 0.527416\n",
      "[315]\ttraining's binary_logloss: 0.527215\n",
      "[316]\ttraining's binary_logloss: 0.527006\n",
      "[317]\ttraining's binary_logloss: 0.52681\n",
      "[318]\ttraining's binary_logloss: 0.526618\n",
      "[319]\ttraining's binary_logloss: 0.5264\n",
      "[320]\ttraining's binary_logloss: 0.52621\n",
      "[321]\ttraining's binary_logloss: 0.52603\n",
      "[322]\ttraining's binary_logloss: 0.525847\n",
      "[323]\ttraining's binary_logloss: 0.525665\n",
      "[324]\ttraining's binary_logloss: 0.525487\n",
      "[325]\ttraining's binary_logloss: 0.525315\n",
      "[326]\ttraining's binary_logloss: 0.525119\n",
      "[327]\ttraining's binary_logloss: 0.524953\n",
      "[328]\ttraining's binary_logloss: 0.524803\n",
      "[329]\ttraining's binary_logloss: 0.524657\n",
      "[330]\ttraining's binary_logloss: 0.524455\n",
      "[331]\ttraining's binary_logloss: 0.524236\n",
      "[332]\ttraining's binary_logloss: 0.52404\n",
      "[333]\ttraining's binary_logloss: 0.523835\n",
      "[334]\ttraining's binary_logloss: 0.523641\n",
      "[335]\ttraining's binary_logloss: 0.523465\n",
      "[336]\ttraining's binary_logloss: 0.523288\n",
      "[337]\ttraining's binary_logloss: 0.52312\n",
      "[338]\ttraining's binary_logloss: 0.522947\n",
      "[339]\ttraining's binary_logloss: 0.522753\n",
      "[340]\ttraining's binary_logloss: 0.522583\n",
      "[341]\ttraining's binary_logloss: 0.522386\n",
      "[342]\ttraining's binary_logloss: 0.5222\n",
      "[343]\ttraining's binary_logloss: 0.522026\n",
      "[344]\ttraining's binary_logloss: 0.521832\n",
      "[345]\ttraining's binary_logloss: 0.521649\n",
      "[346]\ttraining's binary_logloss: 0.521443\n",
      "[347]\ttraining's binary_logloss: 0.521265\n",
      "[348]\ttraining's binary_logloss: 0.521071\n",
      "[349]\ttraining's binary_logloss: 0.520892\n",
      "[350]\ttraining's binary_logloss: 0.520747\n",
      "[351]\ttraining's binary_logloss: 0.520575\n",
      "[352]\ttraining's binary_logloss: 0.520367\n",
      "[353]\ttraining's binary_logloss: 0.520183\n",
      "[354]\ttraining's binary_logloss: 0.520009\n",
      "[355]\ttraining's binary_logloss: 0.519792\n",
      "[356]\ttraining's binary_logloss: 0.519608\n",
      "[357]\ttraining's binary_logloss: 0.51943\n",
      "[358]\ttraining's binary_logloss: 0.519262\n",
      "[359]\ttraining's binary_logloss: 0.519066\n",
      "[360]\ttraining's binary_logloss: 0.518897\n",
      "[361]\ttraining's binary_logloss: 0.518666\n",
      "[362]\ttraining's binary_logloss: 0.518497\n",
      "[363]\ttraining's binary_logloss: 0.51829\n",
      "[364]\ttraining's binary_logloss: 0.518088\n",
      "[365]\ttraining's binary_logloss: 0.517868\n",
      "[366]\ttraining's binary_logloss: 0.517718\n",
      "[367]\ttraining's binary_logloss: 0.517575\n",
      "[368]\ttraining's binary_logloss: 0.517425\n",
      "[369]\ttraining's binary_logloss: 0.517285\n",
      "[370]\ttraining's binary_logloss: 0.517142\n",
      "[371]\ttraining's binary_logloss: 0.516952\n",
      "[372]\ttraining's binary_logloss: 0.51674\n",
      "[373]\ttraining's binary_logloss: 0.51658\n",
      "[374]\ttraining's binary_logloss: 0.516385\n",
      "[375]\ttraining's binary_logloss: 0.516227\n",
      "[376]\ttraining's binary_logloss: 0.516022\n",
      "[377]\ttraining's binary_logloss: 0.515832\n",
      "[378]\ttraining's binary_logloss: 0.515657\n",
      "[379]\ttraining's binary_logloss: 0.51548\n",
      "[380]\ttraining's binary_logloss: 0.515315\n",
      "[381]\ttraining's binary_logloss: 0.515108\n",
      "[382]\ttraining's binary_logloss: 0.514899\n",
      "[383]\ttraining's binary_logloss: 0.514721\n",
      "[384]\ttraining's binary_logloss: 0.514536\n",
      "[385]\ttraining's binary_logloss: 0.514357\n",
      "[386]\ttraining's binary_logloss: 0.514172\n",
      "[387]\ttraining's binary_logloss: 0.513999\n",
      "[388]\ttraining's binary_logloss: 0.513836\n",
      "[389]\ttraining's binary_logloss: 0.513654\n",
      "[390]\ttraining's binary_logloss: 0.513481\n",
      "[391]\ttraining's binary_logloss: 0.513297\n",
      "[392]\ttraining's binary_logloss: 0.513105\n",
      "[393]\ttraining's binary_logloss: 0.512933\n",
      "[394]\ttraining's binary_logloss: 0.512738\n",
      "[395]\ttraining's binary_logloss: 0.512555\n",
      "[396]\ttraining's binary_logloss: 0.51235\n",
      "[397]\ttraining's binary_logloss: 0.512153\n",
      "[398]\ttraining's binary_logloss: 0.511954\n",
      "[399]\ttraining's binary_logloss: 0.511751\n",
      "[400]\ttraining's binary_logloss: 0.511561\n",
      "[401]\ttraining's binary_logloss: 0.511356\n",
      "[402]\ttraining's binary_logloss: 0.511163\n",
      "[403]\ttraining's binary_logloss: 0.510981\n",
      "[404]\ttraining's binary_logloss: 0.510769\n",
      "[405]\ttraining's binary_logloss: 0.510549\n",
      "[406]\ttraining's binary_logloss: 0.510367\n",
      "[407]\ttraining's binary_logloss: 0.510186\n",
      "[408]\ttraining's binary_logloss: 0.510023\n",
      "[409]\ttraining's binary_logloss: 0.509844\n",
      "[410]\ttraining's binary_logloss: 0.509664\n",
      "[411]\ttraining's binary_logloss: 0.509479\n",
      "[412]\ttraining's binary_logloss: 0.509297\n",
      "[413]\ttraining's binary_logloss: 0.509133\n",
      "[414]\ttraining's binary_logloss: 0.508964\n",
      "[415]\ttraining's binary_logloss: 0.5088\n",
      "[416]\ttraining's binary_logloss: 0.508663\n",
      "[417]\ttraining's binary_logloss: 0.508497\n",
      "[418]\ttraining's binary_logloss: 0.508326\n",
      "[419]\ttraining's binary_logloss: 0.508159\n",
      "[420]\ttraining's binary_logloss: 0.50797\n",
      "[421]\ttraining's binary_logloss: 0.50781\n",
      "[422]\ttraining's binary_logloss: 0.507644\n",
      "[423]\ttraining's binary_logloss: 0.5075\n",
      "[424]\ttraining's binary_logloss: 0.507345\n",
      "[425]\ttraining's binary_logloss: 0.507194\n",
      "[426]\ttraining's binary_logloss: 0.507022\n",
      "[427]\ttraining's binary_logloss: 0.50683\n",
      "[428]\ttraining's binary_logloss: 0.506645\n",
      "[429]\ttraining's binary_logloss: 0.506489\n",
      "[430]\ttraining's binary_logloss: 0.506302\n",
      "[431]\ttraining's binary_logloss: 0.506078\n",
      "[432]\ttraining's binary_logloss: 0.505868\n",
      "[433]\ttraining's binary_logloss: 0.50567\n",
      "[434]\ttraining's binary_logloss: 0.505503\n",
      "[435]\ttraining's binary_logloss: 0.50532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[436]\ttraining's binary_logloss: 0.505159\n",
      "[437]\ttraining's binary_logloss: 0.504978\n",
      "[438]\ttraining's binary_logloss: 0.50483\n",
      "[439]\ttraining's binary_logloss: 0.50467\n",
      "[440]\ttraining's binary_logloss: 0.504521\n",
      "[441]\ttraining's binary_logloss: 0.504323\n",
      "[442]\ttraining's binary_logloss: 0.504134\n",
      "[443]\ttraining's binary_logloss: 0.50395\n",
      "[444]\ttraining's binary_logloss: 0.503762\n",
      "[445]\ttraining's binary_logloss: 0.503587\n",
      "[446]\ttraining's binary_logloss: 0.50339\n",
      "[447]\ttraining's binary_logloss: 0.503246\n",
      "[448]\ttraining's binary_logloss: 0.503062\n",
      "[449]\ttraining's binary_logloss: 0.502921\n",
      "[450]\ttraining's binary_logloss: 0.502749\n",
      "[451]\ttraining's binary_logloss: 0.502581\n",
      "[452]\ttraining's binary_logloss: 0.502437\n",
      "[453]\ttraining's binary_logloss: 0.502273\n",
      "[454]\ttraining's binary_logloss: 0.502098\n",
      "[455]\ttraining's binary_logloss: 0.501916\n",
      "[456]\ttraining's binary_logloss: 0.501695\n",
      "[457]\ttraining's binary_logloss: 0.501487\n",
      "[458]\ttraining's binary_logloss: 0.501268\n",
      "[459]\ttraining's binary_logloss: 0.501045\n",
      "[460]\ttraining's binary_logloss: 0.500835\n",
      "[461]\ttraining's binary_logloss: 0.500652\n",
      "[462]\ttraining's binary_logloss: 0.500485\n",
      "[463]\ttraining's binary_logloss: 0.500307\n",
      "[464]\ttraining's binary_logloss: 0.500159\n",
      "[465]\ttraining's binary_logloss: 0.499966\n",
      "[466]\ttraining's binary_logloss: 0.499735\n",
      "[467]\ttraining's binary_logloss: 0.499504\n",
      "[468]\ttraining's binary_logloss: 0.499303\n",
      "[469]\ttraining's binary_logloss: 0.499102\n",
      "[470]\ttraining's binary_logloss: 0.498892\n",
      "[471]\ttraining's binary_logloss: 0.498726\n",
      "[472]\ttraining's binary_logloss: 0.498554\n",
      "[473]\ttraining's binary_logloss: 0.498357\n",
      "[474]\ttraining's binary_logloss: 0.498207\n",
      "[475]\ttraining's binary_logloss: 0.498042\n",
      "[476]\ttraining's binary_logloss: 0.497815\n",
      "[477]\ttraining's binary_logloss: 0.497596\n",
      "[478]\ttraining's binary_logloss: 0.497388\n",
      "[479]\ttraining's binary_logloss: 0.49718\n",
      "[480]\ttraining's binary_logloss: 0.496965\n",
      "[481]\ttraining's binary_logloss: 0.496759\n",
      "[482]\ttraining's binary_logloss: 0.496585\n",
      "[483]\ttraining's binary_logloss: 0.496395\n",
      "[484]\ttraining's binary_logloss: 0.496219\n",
      "[485]\ttraining's binary_logloss: 0.496042\n",
      "[486]\ttraining's binary_logloss: 0.495869\n",
      "[487]\ttraining's binary_logloss: 0.49566\n",
      "[488]\ttraining's binary_logloss: 0.495501\n",
      "[489]\ttraining's binary_logloss: 0.495338\n",
      "[490]\ttraining's binary_logloss: 0.495182\n",
      "[491]\ttraining's binary_logloss: 0.494951\n",
      "[492]\ttraining's binary_logloss: 0.494692\n",
      "[493]\ttraining's binary_logloss: 0.494466\n",
      "[494]\ttraining's binary_logloss: 0.494257\n",
      "[495]\ttraining's binary_logloss: 0.494066\n",
      "[496]\ttraining's binary_logloss: 0.493862\n",
      "[497]\ttraining's binary_logloss: 0.493634\n",
      "[498]\ttraining's binary_logloss: 0.493422\n",
      "[499]\ttraining's binary_logloss: 0.493201\n",
      "[500]\ttraining's binary_logloss: 0.492985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613478\n",
      "[2]\ttraining's binary_logloss: 0.612053\n",
      "[3]\ttraining's binary_logloss: 0.610574\n",
      "[4]\ttraining's binary_logloss: 0.609158\n",
      "[5]\ttraining's binary_logloss: 0.607843\n",
      "[6]\ttraining's binary_logloss: 0.606495\n",
      "[7]\ttraining's binary_logloss: 0.60518\n",
      "[8]\ttraining's binary_logloss: 0.603918\n",
      "[9]\ttraining's binary_logloss: 0.602691\n",
      "[10]\ttraining's binary_logloss: 0.601493\n",
      "[11]\ttraining's binary_logloss: 0.600454\n",
      "[12]\ttraining's binary_logloss: 0.599408\n",
      "[13]\ttraining's binary_logloss: 0.598371\n",
      "[14]\ttraining's binary_logloss: 0.59735\n",
      "[15]\ttraining's binary_logloss: 0.596371\n",
      "[16]\ttraining's binary_logloss: 0.595404\n",
      "[17]\ttraining's binary_logloss: 0.594496\n",
      "[18]\ttraining's binary_logloss: 0.593594\n",
      "[19]\ttraining's binary_logloss: 0.5927\n",
      "[20]\ttraining's binary_logloss: 0.591828\n",
      "[21]\ttraining's binary_logloss: 0.590946\n",
      "[22]\ttraining's binary_logloss: 0.590073\n",
      "[23]\ttraining's binary_logloss: 0.589235\n",
      "[24]\ttraining's binary_logloss: 0.588409\n",
      "[25]\ttraining's binary_logloss: 0.587702\n",
      "[26]\ttraining's binary_logloss: 0.586917\n",
      "[27]\ttraining's binary_logloss: 0.586167\n",
      "[28]\ttraining's binary_logloss: 0.585409\n",
      "[29]\ttraining's binary_logloss: 0.584724\n",
      "[30]\ttraining's binary_logloss: 0.584054\n",
      "[31]\ttraining's binary_logloss: 0.583404\n",
      "[32]\ttraining's binary_logloss: 0.582871\n",
      "[33]\ttraining's binary_logloss: 0.582255\n",
      "[34]\ttraining's binary_logloss: 0.581706\n",
      "[35]\ttraining's binary_logloss: 0.581085\n",
      "[36]\ttraining's binary_logloss: 0.580435\n",
      "[37]\ttraining's binary_logloss: 0.579809\n",
      "[38]\ttraining's binary_logloss: 0.5793\n",
      "[39]\ttraining's binary_logloss: 0.578756\n",
      "[40]\ttraining's binary_logloss: 0.578209\n",
      "[41]\ttraining's binary_logloss: 0.577658\n",
      "[42]\ttraining's binary_logloss: 0.577117\n",
      "[43]\ttraining's binary_logloss: 0.576734\n",
      "[44]\ttraining's binary_logloss: 0.576238\n",
      "[45]\ttraining's binary_logloss: 0.575788\n",
      "[46]\ttraining's binary_logloss: 0.575281\n",
      "[47]\ttraining's binary_logloss: 0.574826\n",
      "[48]\ttraining's binary_logloss: 0.574368\n",
      "[49]\ttraining's binary_logloss: 0.573935\n",
      "[50]\ttraining's binary_logloss: 0.573518\n",
      "[51]\ttraining's binary_logloss: 0.573063\n",
      "[52]\ttraining's binary_logloss: 0.572678\n",
      "[53]\ttraining's binary_logloss: 0.572308\n",
      "[54]\ttraining's binary_logloss: 0.57193\n",
      "[55]\ttraining's binary_logloss: 0.571579\n",
      "[56]\ttraining's binary_logloss: 0.571235\n",
      "[57]\ttraining's binary_logloss: 0.570924\n",
      "[58]\ttraining's binary_logloss: 0.570555\n",
      "[59]\ttraining's binary_logloss: 0.570194\n",
      "[60]\ttraining's binary_logloss: 0.569837\n",
      "[61]\ttraining's binary_logloss: 0.569424\n",
      "[62]\ttraining's binary_logloss: 0.569046\n",
      "[63]\ttraining's binary_logloss: 0.568674\n",
      "[64]\ttraining's binary_logloss: 0.568324\n",
      "[65]\ttraining's binary_logloss: 0.568045\n",
      "[66]\ttraining's binary_logloss: 0.567716\n",
      "[67]\ttraining's binary_logloss: 0.567416\n",
      "[68]\ttraining's binary_logloss: 0.567071\n",
      "[69]\ttraining's binary_logloss: 0.566753\n",
      "[70]\ttraining's binary_logloss: 0.566441\n",
      "[71]\ttraining's binary_logloss: 0.566117\n",
      "[72]\ttraining's binary_logloss: 0.565772\n",
      "[73]\ttraining's binary_logloss: 0.565473\n",
      "[74]\ttraining's binary_logloss: 0.565173\n",
      "[75]\ttraining's binary_logloss: 0.564884\n",
      "[76]\ttraining's binary_logloss: 0.564652\n",
      "[77]\ttraining's binary_logloss: 0.564456\n",
      "[78]\ttraining's binary_logloss: 0.564302\n",
      "[79]\ttraining's binary_logloss: 0.564115\n",
      "[80]\ttraining's binary_logloss: 0.563932\n",
      "[81]\ttraining's binary_logloss: 0.563735\n",
      "[82]\ttraining's binary_logloss: 0.563487\n",
      "[83]\ttraining's binary_logloss: 0.563243\n",
      "[84]\ttraining's binary_logloss: 0.563017\n",
      "[85]\ttraining's binary_logloss: 0.562802\n",
      "[86]\ttraining's binary_logloss: 0.5626\n",
      "[87]\ttraining's binary_logloss: 0.562413\n",
      "[88]\ttraining's binary_logloss: 0.562266\n",
      "[89]\ttraining's binary_logloss: 0.562094\n",
      "[90]\ttraining's binary_logloss: 0.561902\n",
      "[91]\ttraining's binary_logloss: 0.561683\n",
      "[92]\ttraining's binary_logloss: 0.561459\n",
      "[93]\ttraining's binary_logloss: 0.561299\n",
      "[94]\ttraining's binary_logloss: 0.561097\n",
      "[95]\ttraining's binary_logloss: 0.560942\n",
      "[96]\ttraining's binary_logloss: 0.56078\n",
      "[97]\ttraining's binary_logloss: 0.560612\n",
      "[98]\ttraining's binary_logloss: 0.560461\n",
      "[99]\ttraining's binary_logloss: 0.560287\n",
      "[100]\ttraining's binary_logloss: 0.560132\n",
      "[101]\ttraining's binary_logloss: 0.559943\n",
      "[102]\ttraining's binary_logloss: 0.559762\n",
      "[103]\ttraining's binary_logloss: 0.559568\n",
      "[104]\ttraining's binary_logloss: 0.55939\n",
      "[105]\ttraining's binary_logloss: 0.559201\n",
      "[106]\ttraining's binary_logloss: 0.55902\n",
      "[107]\ttraining's binary_logloss: 0.558828\n",
      "[108]\ttraining's binary_logloss: 0.558672\n",
      "[109]\ttraining's binary_logloss: 0.558535\n",
      "[110]\ttraining's binary_logloss: 0.558386\n",
      "[111]\ttraining's binary_logloss: 0.558242\n",
      "[112]\ttraining's binary_logloss: 0.558086\n",
      "[113]\ttraining's binary_logloss: 0.557947\n",
      "[114]\ttraining's binary_logloss: 0.557769\n",
      "[115]\ttraining's binary_logloss: 0.557601\n",
      "[116]\ttraining's binary_logloss: 0.557432\n",
      "[117]\ttraining's binary_logloss: 0.55728\n",
      "[118]\ttraining's binary_logloss: 0.557123\n",
      "[119]\ttraining's binary_logloss: 0.557008\n",
      "[120]\ttraining's binary_logloss: 0.556841\n",
      "[121]\ttraining's binary_logloss: 0.55667\n",
      "[122]\ttraining's binary_logloss: 0.556545\n",
      "[123]\ttraining's binary_logloss: 0.556413\n",
      "[124]\ttraining's binary_logloss: 0.556249\n",
      "[125]\ttraining's binary_logloss: 0.556114\n",
      "[126]\ttraining's binary_logloss: 0.555955\n",
      "[127]\ttraining's binary_logloss: 0.555757\n",
      "[128]\ttraining's binary_logloss: 0.555588\n",
      "[129]\ttraining's binary_logloss: 0.555436\n",
      "[130]\ttraining's binary_logloss: 0.555286\n",
      "[131]\ttraining's binary_logloss: 0.555204\n",
      "[132]\ttraining's binary_logloss: 0.555027\n",
      "[133]\ttraining's binary_logloss: 0.554915\n",
      "[134]\ttraining's binary_logloss: 0.554783\n",
      "[135]\ttraining's binary_logloss: 0.55469\n",
      "[136]\ttraining's binary_logloss: 0.55454\n",
      "[137]\ttraining's binary_logloss: 0.554395\n",
      "[138]\ttraining's binary_logloss: 0.554236\n",
      "[139]\ttraining's binary_logloss: 0.554105\n",
      "[140]\ttraining's binary_logloss: 0.553996\n",
      "[141]\ttraining's binary_logloss: 0.553858\n",
      "[142]\ttraining's binary_logloss: 0.55372\n",
      "[143]\ttraining's binary_logloss: 0.553579\n",
      "[144]\ttraining's binary_logloss: 0.553449\n",
      "[145]\ttraining's binary_logloss: 0.553299\n",
      "[146]\ttraining's binary_logloss: 0.55312\n",
      "[147]\ttraining's binary_logloss: 0.552966\n",
      "[148]\ttraining's binary_logloss: 0.552799\n",
      "[149]\ttraining's binary_logloss: 0.552679\n",
      "[150]\ttraining's binary_logloss: 0.552527\n",
      "[151]\ttraining's binary_logloss: 0.552384\n",
      "[152]\ttraining's binary_logloss: 0.552254\n",
      "[153]\ttraining's binary_logloss: 0.552153\n",
      "[154]\ttraining's binary_logloss: 0.552032\n",
      "[155]\ttraining's binary_logloss: 0.551923\n",
      "[156]\ttraining's binary_logloss: 0.551784\n",
      "[157]\ttraining's binary_logloss: 0.551638\n",
      "[158]\ttraining's binary_logloss: 0.551486\n",
      "[159]\ttraining's binary_logloss: 0.551326\n",
      "[160]\ttraining's binary_logloss: 0.551219\n",
      "[161]\ttraining's binary_logloss: 0.551071\n",
      "[162]\ttraining's binary_logloss: 0.550931\n",
      "[163]\ttraining's binary_logloss: 0.55078\n",
      "[164]\ttraining's binary_logloss: 0.550663\n",
      "[165]\ttraining's binary_logloss: 0.550516\n",
      "[166]\ttraining's binary_logloss: 0.550315\n",
      "[167]\ttraining's binary_logloss: 0.55012\n",
      "[168]\ttraining's binary_logloss: 0.549931\n",
      "[169]\ttraining's binary_logloss: 0.549748\n",
      "[170]\ttraining's binary_logloss: 0.549621\n",
      "[171]\ttraining's binary_logloss: 0.549478\n",
      "[172]\ttraining's binary_logloss: 0.54931\n",
      "[173]\ttraining's binary_logloss: 0.549169\n",
      "[174]\ttraining's binary_logloss: 0.549025\n",
      "[175]\ttraining's binary_logloss: 0.548884\n",
      "[176]\ttraining's binary_logloss: 0.548722\n",
      "[177]\ttraining's binary_logloss: 0.548572\n",
      "[178]\ttraining's binary_logloss: 0.54843\n",
      "[179]\ttraining's binary_logloss: 0.548285\n",
      "[180]\ttraining's binary_logloss: 0.54815\n",
      "[181]\ttraining's binary_logloss: 0.54801\n",
      "[182]\ttraining's binary_logloss: 0.54788\n",
      "[183]\ttraining's binary_logloss: 0.547788\n",
      "[184]\ttraining's binary_logloss: 0.547686\n",
      "[185]\ttraining's binary_logloss: 0.547593\n",
      "[186]\ttraining's binary_logloss: 0.547485\n",
      "[187]\ttraining's binary_logloss: 0.547382\n",
      "[188]\ttraining's binary_logloss: 0.547274\n",
      "[189]\ttraining's binary_logloss: 0.547175\n",
      "[190]\ttraining's binary_logloss: 0.5471\n",
      "[191]\ttraining's binary_logloss: 0.546963\n",
      "[192]\ttraining's binary_logloss: 0.546809\n",
      "[193]\ttraining's binary_logloss: 0.546656\n",
      "[194]\ttraining's binary_logloss: 0.546536\n",
      "[195]\ttraining's binary_logloss: 0.546375\n",
      "[196]\ttraining's binary_logloss: 0.546212\n",
      "[197]\ttraining's binary_logloss: 0.546068\n",
      "[198]\ttraining's binary_logloss: 0.545921\n",
      "[199]\ttraining's binary_logloss: 0.545745\n",
      "[200]\ttraining's binary_logloss: 0.54559\n",
      "[201]\ttraining's binary_logloss: 0.545434\n",
      "[202]\ttraining's binary_logloss: 0.545287\n",
      "[203]\ttraining's binary_logloss: 0.545145\n",
      "[204]\ttraining's binary_logloss: 0.545005\n",
      "[205]\ttraining's binary_logloss: 0.544861\n",
      "[206]\ttraining's binary_logloss: 0.544727\n",
      "[207]\ttraining's binary_logloss: 0.544624\n",
      "[208]\ttraining's binary_logloss: 0.54448\n",
      "[209]\ttraining's binary_logloss: 0.544314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[210]\ttraining's binary_logloss: 0.544172\n",
      "[211]\ttraining's binary_logloss: 0.544025\n",
      "[212]\ttraining's binary_logloss: 0.543857\n",
      "[213]\ttraining's binary_logloss: 0.543697\n",
      "[214]\ttraining's binary_logloss: 0.543537\n",
      "[215]\ttraining's binary_logloss: 0.543383\n",
      "[216]\ttraining's binary_logloss: 0.543203\n",
      "[217]\ttraining's binary_logloss: 0.543056\n",
      "[218]\ttraining's binary_logloss: 0.542804\n",
      "[219]\ttraining's binary_logloss: 0.542628\n",
      "[220]\ttraining's binary_logloss: 0.542466\n",
      "[221]\ttraining's binary_logloss: 0.542317\n",
      "[222]\ttraining's binary_logloss: 0.542135\n",
      "[223]\ttraining's binary_logloss: 0.542\n",
      "[224]\ttraining's binary_logloss: 0.541819\n",
      "[225]\ttraining's binary_logloss: 0.541643\n",
      "[226]\ttraining's binary_logloss: 0.541488\n",
      "[227]\ttraining's binary_logloss: 0.541327\n",
      "[228]\ttraining's binary_logloss: 0.54114\n",
      "[229]\ttraining's binary_logloss: 0.540974\n",
      "[230]\ttraining's binary_logloss: 0.540807\n",
      "[231]\ttraining's binary_logloss: 0.540618\n",
      "[232]\ttraining's binary_logloss: 0.540419\n",
      "[233]\ttraining's binary_logloss: 0.540274\n",
      "[234]\ttraining's binary_logloss: 0.540097\n",
      "[235]\ttraining's binary_logloss: 0.539935\n",
      "[236]\ttraining's binary_logloss: 0.539787\n",
      "[237]\ttraining's binary_logloss: 0.539628\n",
      "[238]\ttraining's binary_logloss: 0.53948\n",
      "[239]\ttraining's binary_logloss: 0.539334\n",
      "[240]\ttraining's binary_logloss: 0.539196\n",
      "[241]\ttraining's binary_logloss: 0.539042\n",
      "[242]\ttraining's binary_logloss: 0.538883\n",
      "[243]\ttraining's binary_logloss: 0.538708\n",
      "[244]\ttraining's binary_logloss: 0.538557\n",
      "[245]\ttraining's binary_logloss: 0.53842\n",
      "[246]\ttraining's binary_logloss: 0.538242\n",
      "[247]\ttraining's binary_logloss: 0.53806\n",
      "[248]\ttraining's binary_logloss: 0.537892\n",
      "[249]\ttraining's binary_logloss: 0.537719\n",
      "[250]\ttraining's binary_logloss: 0.537495\n",
      "[251]\ttraining's binary_logloss: 0.537331\n",
      "[252]\ttraining's binary_logloss: 0.537178\n",
      "[253]\ttraining's binary_logloss: 0.537017\n",
      "[254]\ttraining's binary_logloss: 0.536848\n",
      "[255]\ttraining's binary_logloss: 0.53669\n",
      "[256]\ttraining's binary_logloss: 0.536505\n",
      "[257]\ttraining's binary_logloss: 0.53633\n",
      "[258]\ttraining's binary_logloss: 0.536141\n",
      "[259]\ttraining's binary_logloss: 0.535967\n",
      "[260]\ttraining's binary_logloss: 0.535822\n",
      "[261]\ttraining's binary_logloss: 0.535619\n",
      "[262]\ttraining's binary_logloss: 0.535427\n",
      "[263]\ttraining's binary_logloss: 0.535261\n",
      "[264]\ttraining's binary_logloss: 0.535085\n",
      "[265]\ttraining's binary_logloss: 0.534905\n",
      "[266]\ttraining's binary_logloss: 0.534763\n",
      "[267]\ttraining's binary_logloss: 0.534631\n",
      "[268]\ttraining's binary_logloss: 0.534517\n",
      "[269]\ttraining's binary_logloss: 0.534398\n",
      "[270]\ttraining's binary_logloss: 0.534216\n",
      "[271]\ttraining's binary_logloss: 0.534035\n",
      "[272]\ttraining's binary_logloss: 0.533869\n",
      "[273]\ttraining's binary_logloss: 0.533702\n",
      "[274]\ttraining's binary_logloss: 0.533531\n",
      "[275]\ttraining's binary_logloss: 0.533349\n",
      "[276]\ttraining's binary_logloss: 0.53315\n",
      "[277]\ttraining's binary_logloss: 0.532989\n",
      "[278]\ttraining's binary_logloss: 0.532803\n",
      "[279]\ttraining's binary_logloss: 0.532596\n",
      "[280]\ttraining's binary_logloss: 0.532411\n",
      "[281]\ttraining's binary_logloss: 0.532257\n",
      "[282]\ttraining's binary_logloss: 0.53208\n",
      "[283]\ttraining's binary_logloss: 0.531904\n",
      "[284]\ttraining's binary_logloss: 0.531745\n",
      "[285]\ttraining's binary_logloss: 0.531568\n",
      "[286]\ttraining's binary_logloss: 0.531343\n",
      "[287]\ttraining's binary_logloss: 0.531128\n",
      "[288]\ttraining's binary_logloss: 0.530926\n",
      "[289]\ttraining's binary_logloss: 0.530718\n",
      "[290]\ttraining's binary_logloss: 0.530519\n",
      "[291]\ttraining's binary_logloss: 0.530344\n",
      "[292]\ttraining's binary_logloss: 0.530173\n",
      "[293]\ttraining's binary_logloss: 0.530014\n",
      "[294]\ttraining's binary_logloss: 0.529872\n",
      "[295]\ttraining's binary_logloss: 0.529713\n",
      "[296]\ttraining's binary_logloss: 0.529514\n",
      "[297]\ttraining's binary_logloss: 0.52933\n",
      "[298]\ttraining's binary_logloss: 0.529147\n",
      "[299]\ttraining's binary_logloss: 0.528941\n",
      "[300]\ttraining's binary_logloss: 0.528742\n",
      "[301]\ttraining's binary_logloss: 0.528554\n",
      "[302]\ttraining's binary_logloss: 0.528351\n",
      "[303]\ttraining's binary_logloss: 0.528159\n",
      "[304]\ttraining's binary_logloss: 0.527947\n",
      "[305]\ttraining's binary_logloss: 0.52773\n",
      "[306]\ttraining's binary_logloss: 0.527548\n",
      "[307]\ttraining's binary_logloss: 0.527372\n",
      "[308]\ttraining's binary_logloss: 0.527171\n",
      "[309]\ttraining's binary_logloss: 0.527026\n",
      "[310]\ttraining's binary_logloss: 0.526853\n",
      "[311]\ttraining's binary_logloss: 0.526679\n",
      "[312]\ttraining's binary_logloss: 0.526492\n",
      "[313]\ttraining's binary_logloss: 0.526328\n",
      "[314]\ttraining's binary_logloss: 0.526148\n",
      "[315]\ttraining's binary_logloss: 0.52597\n",
      "[316]\ttraining's binary_logloss: 0.525782\n",
      "[317]\ttraining's binary_logloss: 0.525615\n",
      "[318]\ttraining's binary_logloss: 0.525418\n",
      "[319]\ttraining's binary_logloss: 0.525224\n",
      "[320]\ttraining's binary_logloss: 0.525021\n",
      "[321]\ttraining's binary_logloss: 0.524899\n",
      "[322]\ttraining's binary_logloss: 0.52476\n",
      "[323]\ttraining's binary_logloss: 0.524611\n",
      "[324]\ttraining's binary_logloss: 0.524483\n",
      "[325]\ttraining's binary_logloss: 0.524377\n",
      "[326]\ttraining's binary_logloss: 0.524222\n",
      "[327]\ttraining's binary_logloss: 0.524031\n",
      "[328]\ttraining's binary_logloss: 0.523868\n",
      "[329]\ttraining's binary_logloss: 0.523761\n",
      "[330]\ttraining's binary_logloss: 0.523603\n",
      "[331]\ttraining's binary_logloss: 0.52339\n",
      "[332]\ttraining's binary_logloss: 0.523174\n",
      "[333]\ttraining's binary_logloss: 0.522989\n",
      "[334]\ttraining's binary_logloss: 0.522807\n",
      "[335]\ttraining's binary_logloss: 0.522618\n",
      "[336]\ttraining's binary_logloss: 0.522417\n",
      "[337]\ttraining's binary_logloss: 0.522199\n",
      "[338]\ttraining's binary_logloss: 0.522026\n",
      "[339]\ttraining's binary_logloss: 0.521809\n",
      "[340]\ttraining's binary_logloss: 0.521608\n",
      "[341]\ttraining's binary_logloss: 0.521398\n",
      "[342]\ttraining's binary_logloss: 0.521186\n",
      "[343]\ttraining's binary_logloss: 0.520987\n",
      "[344]\ttraining's binary_logloss: 0.520775\n",
      "[345]\ttraining's binary_logloss: 0.520571\n",
      "[346]\ttraining's binary_logloss: 0.520424\n",
      "[347]\ttraining's binary_logloss: 0.520269\n",
      "[348]\ttraining's binary_logloss: 0.520113\n",
      "[349]\ttraining's binary_logloss: 0.519937\n",
      "[350]\ttraining's binary_logloss: 0.519797\n",
      "[351]\ttraining's binary_logloss: 0.5196\n",
      "[352]\ttraining's binary_logloss: 0.519414\n",
      "[353]\ttraining's binary_logloss: 0.519224\n",
      "[354]\ttraining's binary_logloss: 0.519033\n",
      "[355]\ttraining's binary_logloss: 0.518851\n",
      "[356]\ttraining's binary_logloss: 0.518686\n",
      "[357]\ttraining's binary_logloss: 0.518508\n",
      "[358]\ttraining's binary_logloss: 0.518339\n",
      "[359]\ttraining's binary_logloss: 0.518154\n",
      "[360]\ttraining's binary_logloss: 0.517973\n",
      "[361]\ttraining's binary_logloss: 0.51784\n",
      "[362]\ttraining's binary_logloss: 0.517688\n",
      "[363]\ttraining's binary_logloss: 0.517507\n",
      "[364]\ttraining's binary_logloss: 0.517356\n",
      "[365]\ttraining's binary_logloss: 0.517218\n",
      "[366]\ttraining's binary_logloss: 0.517075\n",
      "[367]\ttraining's binary_logloss: 0.516946\n",
      "[368]\ttraining's binary_logloss: 0.516768\n",
      "[369]\ttraining's binary_logloss: 0.51662\n",
      "[370]\ttraining's binary_logloss: 0.516469\n",
      "[371]\ttraining's binary_logloss: 0.516279\n",
      "[372]\ttraining's binary_logloss: 0.516089\n",
      "[373]\ttraining's binary_logloss: 0.515907\n",
      "[374]\ttraining's binary_logloss: 0.515718\n",
      "[375]\ttraining's binary_logloss: 0.515522\n",
      "[376]\ttraining's binary_logloss: 0.515333\n",
      "[377]\ttraining's binary_logloss: 0.515097\n",
      "[378]\ttraining's binary_logloss: 0.514933\n",
      "[379]\ttraining's binary_logloss: 0.514719\n",
      "[380]\ttraining's binary_logloss: 0.51454\n",
      "[381]\ttraining's binary_logloss: 0.514352\n",
      "[382]\ttraining's binary_logloss: 0.514176\n",
      "[383]\ttraining's binary_logloss: 0.513982\n",
      "[384]\ttraining's binary_logloss: 0.513793\n",
      "[385]\ttraining's binary_logloss: 0.513628\n",
      "[386]\ttraining's binary_logloss: 0.51344\n",
      "[387]\ttraining's binary_logloss: 0.513264\n",
      "[388]\ttraining's binary_logloss: 0.513092\n",
      "[389]\ttraining's binary_logloss: 0.512923\n",
      "[390]\ttraining's binary_logloss: 0.512751\n",
      "[391]\ttraining's binary_logloss: 0.512528\n",
      "[392]\ttraining's binary_logloss: 0.512322\n",
      "[393]\ttraining's binary_logloss: 0.512106\n",
      "[394]\ttraining's binary_logloss: 0.511905\n",
      "[395]\ttraining's binary_logloss: 0.51168\n",
      "[396]\ttraining's binary_logloss: 0.511456\n",
      "[397]\ttraining's binary_logloss: 0.511238\n",
      "[398]\ttraining's binary_logloss: 0.511027\n",
      "[399]\ttraining's binary_logloss: 0.510787\n",
      "[400]\ttraining's binary_logloss: 0.510606\n",
      "[401]\ttraining's binary_logloss: 0.510417\n",
      "[402]\ttraining's binary_logloss: 0.510217\n",
      "[403]\ttraining's binary_logloss: 0.510063\n",
      "[404]\ttraining's binary_logloss: 0.509852\n",
      "[405]\ttraining's binary_logloss: 0.509665\n",
      "[406]\ttraining's binary_logloss: 0.5095\n",
      "[407]\ttraining's binary_logloss: 0.509344\n",
      "[408]\ttraining's binary_logloss: 0.509183\n",
      "[409]\ttraining's binary_logloss: 0.509013\n",
      "[410]\ttraining's binary_logloss: 0.508848\n",
      "[411]\ttraining's binary_logloss: 0.508661\n",
      "[412]\ttraining's binary_logloss: 0.50848\n",
      "[413]\ttraining's binary_logloss: 0.508312\n",
      "[414]\ttraining's binary_logloss: 0.508081\n",
      "[415]\ttraining's binary_logloss: 0.507911\n",
      "[416]\ttraining's binary_logloss: 0.507726\n",
      "[417]\ttraining's binary_logloss: 0.507528\n",
      "[418]\ttraining's binary_logloss: 0.507334\n",
      "[419]\ttraining's binary_logloss: 0.507143\n",
      "[420]\ttraining's binary_logloss: 0.506969\n",
      "[421]\ttraining's binary_logloss: 0.506794\n",
      "[422]\ttraining's binary_logloss: 0.506634\n",
      "[423]\ttraining's binary_logloss: 0.506475\n",
      "[424]\ttraining's binary_logloss: 0.506307\n",
      "[425]\ttraining's binary_logloss: 0.50615\n",
      "[426]\ttraining's binary_logloss: 0.505886\n",
      "[427]\ttraining's binary_logloss: 0.505666\n",
      "[428]\ttraining's binary_logloss: 0.505449\n",
      "[429]\ttraining's binary_logloss: 0.505257\n",
      "[430]\ttraining's binary_logloss: 0.505041\n",
      "[431]\ttraining's binary_logloss: 0.504874\n",
      "[432]\ttraining's binary_logloss: 0.504705\n",
      "[433]\ttraining's binary_logloss: 0.504539\n",
      "[434]\ttraining's binary_logloss: 0.50438\n",
      "[435]\ttraining's binary_logloss: 0.504219\n",
      "[436]\ttraining's binary_logloss: 0.503984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[437]\ttraining's binary_logloss: 0.503735\n",
      "[438]\ttraining's binary_logloss: 0.50351\n",
      "[439]\ttraining's binary_logloss: 0.503278\n",
      "[440]\ttraining's binary_logloss: 0.503072\n",
      "[441]\ttraining's binary_logloss: 0.502855\n",
      "[442]\ttraining's binary_logloss: 0.502638\n",
      "[443]\ttraining's binary_logloss: 0.502437\n",
      "[444]\ttraining's binary_logloss: 0.502206\n",
      "[445]\ttraining's binary_logloss: 0.502004\n",
      "[446]\ttraining's binary_logloss: 0.501837\n",
      "[447]\ttraining's binary_logloss: 0.501673\n",
      "[448]\ttraining's binary_logloss: 0.501516\n",
      "[449]\ttraining's binary_logloss: 0.501336\n",
      "[450]\ttraining's binary_logloss: 0.501154\n",
      "[451]\ttraining's binary_logloss: 0.501011\n",
      "[452]\ttraining's binary_logloss: 0.500864\n",
      "[453]\ttraining's binary_logloss: 0.500709\n",
      "[454]\ttraining's binary_logloss: 0.50057\n",
      "[455]\ttraining's binary_logloss: 0.500442\n",
      "[456]\ttraining's binary_logloss: 0.500277\n",
      "[457]\ttraining's binary_logloss: 0.500086\n",
      "[458]\ttraining's binary_logloss: 0.499894\n",
      "[459]\ttraining's binary_logloss: 0.499714\n",
      "[460]\ttraining's binary_logloss: 0.499546\n",
      "[461]\ttraining's binary_logloss: 0.499342\n",
      "[462]\ttraining's binary_logloss: 0.499144\n",
      "[463]\ttraining's binary_logloss: 0.498944\n",
      "[464]\ttraining's binary_logloss: 0.498745\n",
      "[465]\ttraining's binary_logloss: 0.498574\n",
      "[466]\ttraining's binary_logloss: 0.498355\n",
      "[467]\ttraining's binary_logloss: 0.498128\n",
      "[468]\ttraining's binary_logloss: 0.497891\n",
      "[469]\ttraining's binary_logloss: 0.497666\n",
      "[470]\ttraining's binary_logloss: 0.497461\n",
      "[471]\ttraining's binary_logloss: 0.497237\n",
      "[472]\ttraining's binary_logloss: 0.497036\n",
      "[473]\ttraining's binary_logloss: 0.496812\n",
      "[474]\ttraining's binary_logloss: 0.496575\n",
      "[475]\ttraining's binary_logloss: 0.496367\n",
      "[476]\ttraining's binary_logloss: 0.496197\n",
      "[477]\ttraining's binary_logloss: 0.496033\n",
      "[478]\ttraining's binary_logloss: 0.495866\n",
      "[479]\ttraining's binary_logloss: 0.495695\n",
      "[480]\ttraining's binary_logloss: 0.495536\n",
      "[481]\ttraining's binary_logloss: 0.495365\n",
      "[482]\ttraining's binary_logloss: 0.495179\n",
      "[483]\ttraining's binary_logloss: 0.495005\n",
      "[484]\ttraining's binary_logloss: 0.494825\n",
      "[485]\ttraining's binary_logloss: 0.494662\n",
      "[486]\ttraining's binary_logloss: 0.494512\n",
      "[487]\ttraining's binary_logloss: 0.49436\n",
      "[488]\ttraining's binary_logloss: 0.494186\n",
      "[489]\ttraining's binary_logloss: 0.494025\n",
      "[490]\ttraining's binary_logloss: 0.49387\n",
      "[491]\ttraining's binary_logloss: 0.493702\n",
      "[492]\ttraining's binary_logloss: 0.493531\n",
      "[493]\ttraining's binary_logloss: 0.493345\n",
      "[494]\ttraining's binary_logloss: 0.493173\n",
      "[495]\ttraining's binary_logloss: 0.493027\n",
      "[496]\ttraining's binary_logloss: 0.492841\n",
      "[497]\ttraining's binary_logloss: 0.492616\n",
      "[498]\ttraining's binary_logloss: 0.492394\n",
      "[499]\ttraining's binary_logloss: 0.492184\n",
      "[500]\ttraining's binary_logloss: 0.491957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613973\n",
      "[2]\ttraining's binary_logloss: 0.612451\n",
      "[3]\ttraining's binary_logloss: 0.610965\n",
      "[4]\ttraining's binary_logloss: 0.609548\n",
      "[5]\ttraining's binary_logloss: 0.608172\n",
      "[6]\ttraining's binary_logloss: 0.606728\n",
      "[7]\ttraining's binary_logloss: 0.605312\n",
      "[8]\ttraining's binary_logloss: 0.603958\n",
      "[9]\ttraining's binary_logloss: 0.602674\n",
      "[10]\ttraining's binary_logloss: 0.601379\n",
      "[11]\ttraining's binary_logloss: 0.600258\n",
      "[12]\ttraining's binary_logloss: 0.599053\n",
      "[13]\ttraining's binary_logloss: 0.59788\n",
      "[14]\ttraining's binary_logloss: 0.596746\n",
      "[15]\ttraining's binary_logloss: 0.595627\n",
      "[16]\ttraining's binary_logloss: 0.59451\n",
      "[17]\ttraining's binary_logloss: 0.593462\n",
      "[18]\ttraining's binary_logloss: 0.592452\n",
      "[19]\ttraining's binary_logloss: 0.591412\n",
      "[20]\ttraining's binary_logloss: 0.590397\n",
      "[21]\ttraining's binary_logloss: 0.589433\n",
      "[22]\ttraining's binary_logloss: 0.588512\n",
      "[23]\ttraining's binary_logloss: 0.587604\n",
      "[24]\ttraining's binary_logloss: 0.586751\n",
      "[25]\ttraining's binary_logloss: 0.585947\n",
      "[26]\ttraining's binary_logloss: 0.58516\n",
      "[27]\ttraining's binary_logloss: 0.584318\n",
      "[28]\ttraining's binary_logloss: 0.583509\n",
      "[29]\ttraining's binary_logloss: 0.582724\n",
      "[30]\ttraining's binary_logloss: 0.58195\n",
      "[31]\ttraining's binary_logloss: 0.581146\n",
      "[32]\ttraining's binary_logloss: 0.580492\n",
      "[33]\ttraining's binary_logloss: 0.57974\n",
      "[34]\ttraining's binary_logloss: 0.579118\n",
      "[35]\ttraining's binary_logloss: 0.578413\n",
      "[36]\ttraining's binary_logloss: 0.577777\n",
      "[37]\ttraining's binary_logloss: 0.577145\n",
      "[38]\ttraining's binary_logloss: 0.576618\n",
      "[39]\ttraining's binary_logloss: 0.576075\n",
      "[40]\ttraining's binary_logloss: 0.575476\n",
      "[41]\ttraining's binary_logloss: 0.574793\n",
      "[42]\ttraining's binary_logloss: 0.574161\n",
      "[43]\ttraining's binary_logloss: 0.573672\n",
      "[44]\ttraining's binary_logloss: 0.573046\n",
      "[45]\ttraining's binary_logloss: 0.57249\n",
      "[46]\ttraining's binary_logloss: 0.571909\n",
      "[47]\ttraining's binary_logloss: 0.571362\n",
      "[48]\ttraining's binary_logloss: 0.570815\n",
      "[49]\ttraining's binary_logloss: 0.570287\n",
      "[50]\ttraining's binary_logloss: 0.569754\n",
      "[51]\ttraining's binary_logloss: 0.569213\n",
      "[52]\ttraining's binary_logloss: 0.568745\n",
      "[53]\ttraining's binary_logloss: 0.568215\n",
      "[54]\ttraining's binary_logloss: 0.56776\n",
      "[55]\ttraining's binary_logloss: 0.567387\n",
      "[56]\ttraining's binary_logloss: 0.566952\n",
      "[57]\ttraining's binary_logloss: 0.566509\n",
      "[58]\ttraining's binary_logloss: 0.566056\n",
      "[59]\ttraining's binary_logloss: 0.565661\n",
      "[60]\ttraining's binary_logloss: 0.565228\n",
      "[61]\ttraining's binary_logloss: 0.564793\n",
      "[62]\ttraining's binary_logloss: 0.564379\n",
      "[63]\ttraining's binary_logloss: 0.56396\n",
      "[64]\ttraining's binary_logloss: 0.563564\n",
      "[65]\ttraining's binary_logloss: 0.563193\n",
      "[66]\ttraining's binary_logloss: 0.562813\n",
      "[67]\ttraining's binary_logloss: 0.562443\n",
      "[68]\ttraining's binary_logloss: 0.562091\n",
      "[69]\ttraining's binary_logloss: 0.561758\n",
      "[70]\ttraining's binary_logloss: 0.56146\n",
      "[71]\ttraining's binary_logloss: 0.56113\n",
      "[72]\ttraining's binary_logloss: 0.560842\n",
      "[73]\ttraining's binary_logloss: 0.560567\n",
      "[74]\ttraining's binary_logloss: 0.56029\n",
      "[75]\ttraining's binary_logloss: 0.559996\n",
      "[76]\ttraining's binary_logloss: 0.559693\n",
      "[77]\ttraining's binary_logloss: 0.559419\n",
      "[78]\ttraining's binary_logloss: 0.559118\n",
      "[79]\ttraining's binary_logloss: 0.55882\n",
      "[80]\ttraining's binary_logloss: 0.55848\n",
      "[81]\ttraining's binary_logloss: 0.558154\n",
      "[82]\ttraining's binary_logloss: 0.557835\n",
      "[83]\ttraining's binary_logloss: 0.557521\n",
      "[84]\ttraining's binary_logloss: 0.557212\n",
      "[85]\ttraining's binary_logloss: 0.556972\n",
      "[86]\ttraining's binary_logloss: 0.556665\n",
      "[87]\ttraining's binary_logloss: 0.55641\n",
      "[88]\ttraining's binary_logloss: 0.556189\n",
      "[89]\ttraining's binary_logloss: 0.555952\n",
      "[90]\ttraining's binary_logloss: 0.555678\n",
      "[91]\ttraining's binary_logloss: 0.555508\n",
      "[92]\ttraining's binary_logloss: 0.555245\n",
      "[93]\ttraining's binary_logloss: 0.555007\n",
      "[94]\ttraining's binary_logloss: 0.554754\n",
      "[95]\ttraining's binary_logloss: 0.554492\n",
      "[96]\ttraining's binary_logloss: 0.55423\n",
      "[97]\ttraining's binary_logloss: 0.553954\n",
      "[98]\ttraining's binary_logloss: 0.553712\n",
      "[99]\ttraining's binary_logloss: 0.553445\n",
      "[100]\ttraining's binary_logloss: 0.553196\n",
      "[101]\ttraining's binary_logloss: 0.552935\n",
      "[102]\ttraining's binary_logloss: 0.552665\n",
      "[103]\ttraining's binary_logloss: 0.552404\n",
      "[104]\ttraining's binary_logloss: 0.552151\n",
      "[105]\ttraining's binary_logloss: 0.551926\n",
      "[106]\ttraining's binary_logloss: 0.551666\n",
      "[107]\ttraining's binary_logloss: 0.551431\n",
      "[108]\ttraining's binary_logloss: 0.55124\n",
      "[109]\ttraining's binary_logloss: 0.551025\n",
      "[110]\ttraining's binary_logloss: 0.550805\n",
      "[111]\ttraining's binary_logloss: 0.550542\n",
      "[112]\ttraining's binary_logloss: 0.550314\n",
      "[113]\ttraining's binary_logloss: 0.550062\n",
      "[114]\ttraining's binary_logloss: 0.549838\n",
      "[115]\ttraining's binary_logloss: 0.549584\n",
      "[116]\ttraining's binary_logloss: 0.549324\n",
      "[117]\ttraining's binary_logloss: 0.549083\n",
      "[118]\ttraining's binary_logloss: 0.54887\n",
      "[119]\ttraining's binary_logloss: 0.548649\n",
      "[120]\ttraining's binary_logloss: 0.54843\n",
      "[121]\ttraining's binary_logloss: 0.548225\n",
      "[122]\ttraining's binary_logloss: 0.54805\n",
      "[123]\ttraining's binary_logloss: 0.547853\n",
      "[124]\ttraining's binary_logloss: 0.547686\n",
      "[125]\ttraining's binary_logloss: 0.547526\n",
      "[126]\ttraining's binary_logloss: 0.547273\n",
      "[127]\ttraining's binary_logloss: 0.547027\n",
      "[128]\ttraining's binary_logloss: 0.546796\n",
      "[129]\ttraining's binary_logloss: 0.546574\n",
      "[130]\ttraining's binary_logloss: 0.546345\n",
      "[131]\ttraining's binary_logloss: 0.546081\n",
      "[132]\ttraining's binary_logloss: 0.545833\n",
      "[133]\ttraining's binary_logloss: 0.545601\n",
      "[134]\ttraining's binary_logloss: 0.545352\n",
      "[135]\ttraining's binary_logloss: 0.54509\n",
      "[136]\ttraining's binary_logloss: 0.544903\n",
      "[137]\ttraining's binary_logloss: 0.544714\n",
      "[138]\ttraining's binary_logloss: 0.544521\n",
      "[139]\ttraining's binary_logloss: 0.5443\n",
      "[140]\ttraining's binary_logloss: 0.544077\n",
      "[141]\ttraining's binary_logloss: 0.543844\n",
      "[142]\ttraining's binary_logloss: 0.543567\n",
      "[143]\ttraining's binary_logloss: 0.54332\n",
      "[144]\ttraining's binary_logloss: 0.543078\n",
      "[145]\ttraining's binary_logloss: 0.542807\n",
      "[146]\ttraining's binary_logloss: 0.542569\n",
      "[147]\ttraining's binary_logloss: 0.542343\n",
      "[148]\ttraining's binary_logloss: 0.542097\n",
      "[149]\ttraining's binary_logloss: 0.541869\n",
      "[150]\ttraining's binary_logloss: 0.541639\n",
      "[151]\ttraining's binary_logloss: 0.541446\n",
      "[152]\ttraining's binary_logloss: 0.541222\n",
      "[153]\ttraining's binary_logloss: 0.541035\n",
      "[154]\ttraining's binary_logloss: 0.540824\n",
      "[155]\ttraining's binary_logloss: 0.540552\n",
      "[156]\ttraining's binary_logloss: 0.540382\n",
      "[157]\ttraining's binary_logloss: 0.54027\n",
      "[158]\ttraining's binary_logloss: 0.540082\n",
      "[159]\ttraining's binary_logloss: 0.539917\n",
      "[160]\ttraining's binary_logloss: 0.539742\n",
      "[161]\ttraining's binary_logloss: 0.539485\n",
      "[162]\ttraining's binary_logloss: 0.539234\n",
      "[163]\ttraining's binary_logloss: 0.538998\n",
      "[164]\ttraining's binary_logloss: 0.538768\n",
      "[165]\ttraining's binary_logloss: 0.538537\n",
      "[166]\ttraining's binary_logloss: 0.53831\n",
      "[167]\ttraining's binary_logloss: 0.538092\n",
      "[168]\ttraining's binary_logloss: 0.537852\n",
      "[169]\ttraining's binary_logloss: 0.537611\n",
      "[170]\ttraining's binary_logloss: 0.537392\n",
      "[171]\ttraining's binary_logloss: 0.537129\n",
      "[172]\ttraining's binary_logloss: 0.536937\n",
      "[173]\ttraining's binary_logloss: 0.536684\n",
      "[174]\ttraining's binary_logloss: 0.536438\n",
      "[175]\ttraining's binary_logloss: 0.5362\n",
      "[176]\ttraining's binary_logloss: 0.535984\n",
      "[177]\ttraining's binary_logloss: 0.53578\n",
      "[178]\ttraining's binary_logloss: 0.535578\n",
      "[179]\ttraining's binary_logloss: 0.535377\n",
      "[180]\ttraining's binary_logloss: 0.5352\n",
      "[181]\ttraining's binary_logloss: 0.535011\n",
      "[182]\ttraining's binary_logloss: 0.534778\n",
      "[183]\ttraining's binary_logloss: 0.534551\n",
      "[184]\ttraining's binary_logloss: 0.534364\n",
      "[185]\ttraining's binary_logloss: 0.534122\n",
      "[186]\ttraining's binary_logloss: 0.533923\n",
      "[187]\ttraining's binary_logloss: 0.533728\n",
      "[188]\ttraining's binary_logloss: 0.533552\n",
      "[189]\ttraining's binary_logloss: 0.533354\n",
      "[190]\ttraining's binary_logloss: 0.53319\n",
      "[191]\ttraining's binary_logloss: 0.532962\n",
      "[192]\ttraining's binary_logloss: 0.532743\n",
      "[193]\ttraining's binary_logloss: 0.532533\n",
      "[194]\ttraining's binary_logloss: 0.532337\n",
      "[195]\ttraining's binary_logloss: 0.532131\n",
      "[196]\ttraining's binary_logloss: 0.531902\n",
      "[197]\ttraining's binary_logloss: 0.53167\n",
      "[198]\ttraining's binary_logloss: 0.531477\n",
      "[199]\ttraining's binary_logloss: 0.531289\n",
      "[200]\ttraining's binary_logloss: 0.53108\n",
      "[201]\ttraining's binary_logloss: 0.53087\n",
      "[202]\ttraining's binary_logloss: 0.530657\n",
      "[203]\ttraining's binary_logloss: 0.530408\n",
      "[204]\ttraining's binary_logloss: 0.530207\n",
      "[205]\ttraining's binary_logloss: 0.529997\n",
      "[206]\ttraining's binary_logloss: 0.529786\n",
      "[207]\ttraining's binary_logloss: 0.529575\n",
      "[208]\ttraining's binary_logloss: 0.529352\n",
      "[209]\ttraining's binary_logloss: 0.529144\n",
      "[210]\ttraining's binary_logloss: 0.528977\n",
      "[211]\ttraining's binary_logloss: 0.52878\n",
      "[212]\ttraining's binary_logloss: 0.528558\n",
      "[213]\ttraining's binary_logloss: 0.528345\n",
      "[214]\ttraining's binary_logloss: 0.528157\n",
      "[215]\ttraining's binary_logloss: 0.527954\n",
      "[216]\ttraining's binary_logloss: 0.527762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[217]\ttraining's binary_logloss: 0.5276\n",
      "[218]\ttraining's binary_logloss: 0.527345\n",
      "[219]\ttraining's binary_logloss: 0.527113\n",
      "[220]\ttraining's binary_logloss: 0.526938\n",
      "[221]\ttraining's binary_logloss: 0.526705\n",
      "[222]\ttraining's binary_logloss: 0.526449\n",
      "[223]\ttraining's binary_logloss: 0.526244\n",
      "[224]\ttraining's binary_logloss: 0.52598\n",
      "[225]\ttraining's binary_logloss: 0.525744\n",
      "[226]\ttraining's binary_logloss: 0.525543\n",
      "[227]\ttraining's binary_logloss: 0.525343\n",
      "[228]\ttraining's binary_logloss: 0.52516\n",
      "[229]\ttraining's binary_logloss: 0.524975\n",
      "[230]\ttraining's binary_logloss: 0.524788\n",
      "[231]\ttraining's binary_logloss: 0.524527\n",
      "[232]\ttraining's binary_logloss: 0.524258\n",
      "[233]\ttraining's binary_logloss: 0.524032\n",
      "[234]\ttraining's binary_logloss: 0.52381\n",
      "[235]\ttraining's binary_logloss: 0.523588\n",
      "[236]\ttraining's binary_logloss: 0.523338\n",
      "[237]\ttraining's binary_logloss: 0.523063\n",
      "[238]\ttraining's binary_logloss: 0.52282\n",
      "[239]\ttraining's binary_logloss: 0.522592\n",
      "[240]\ttraining's binary_logloss: 0.522367\n",
      "[241]\ttraining's binary_logloss: 0.522137\n",
      "[242]\ttraining's binary_logloss: 0.521915\n",
      "[243]\ttraining's binary_logloss: 0.521701\n",
      "[244]\ttraining's binary_logloss: 0.521472\n",
      "[245]\ttraining's binary_logloss: 0.52126\n",
      "[246]\ttraining's binary_logloss: 0.521091\n",
      "[247]\ttraining's binary_logloss: 0.520912\n",
      "[248]\ttraining's binary_logloss: 0.520726\n",
      "[249]\ttraining's binary_logloss: 0.520573\n",
      "[250]\ttraining's binary_logloss: 0.520395\n",
      "[251]\ttraining's binary_logloss: 0.520174\n",
      "[252]\ttraining's binary_logloss: 0.519951\n",
      "[253]\ttraining's binary_logloss: 0.519747\n",
      "[254]\ttraining's binary_logloss: 0.519519\n",
      "[255]\ttraining's binary_logloss: 0.519275\n",
      "[256]\ttraining's binary_logloss: 0.519057\n",
      "[257]\ttraining's binary_logloss: 0.518812\n",
      "[258]\ttraining's binary_logloss: 0.518622\n",
      "[259]\ttraining's binary_logloss: 0.518408\n",
      "[260]\ttraining's binary_logloss: 0.518209\n",
      "[261]\ttraining's binary_logloss: 0.517956\n",
      "[262]\ttraining's binary_logloss: 0.517745\n",
      "[263]\ttraining's binary_logloss: 0.517523\n",
      "[264]\ttraining's binary_logloss: 0.517318\n",
      "[265]\ttraining's binary_logloss: 0.517106\n",
      "[266]\ttraining's binary_logloss: 0.516838\n",
      "[267]\ttraining's binary_logloss: 0.516644\n",
      "[268]\ttraining's binary_logloss: 0.516467\n",
      "[269]\ttraining's binary_logloss: 0.516273\n",
      "[270]\ttraining's binary_logloss: 0.516091\n",
      "[271]\ttraining's binary_logloss: 0.515839\n",
      "[272]\ttraining's binary_logloss: 0.515561\n",
      "[273]\ttraining's binary_logloss: 0.515309\n",
      "[274]\ttraining's binary_logloss: 0.515056\n",
      "[275]\ttraining's binary_logloss: 0.514795\n",
      "[276]\ttraining's binary_logloss: 0.514545\n",
      "[277]\ttraining's binary_logloss: 0.514309\n",
      "[278]\ttraining's binary_logloss: 0.514082\n",
      "[279]\ttraining's binary_logloss: 0.513867\n",
      "[280]\ttraining's binary_logloss: 0.51365\n",
      "[281]\ttraining's binary_logloss: 0.513443\n",
      "[282]\ttraining's binary_logloss: 0.513265\n",
      "[283]\ttraining's binary_logloss: 0.513064\n",
      "[284]\ttraining's binary_logloss: 0.512898\n",
      "[285]\ttraining's binary_logloss: 0.512707\n",
      "[286]\ttraining's binary_logloss: 0.512504\n",
      "[287]\ttraining's binary_logloss: 0.512238\n",
      "[288]\ttraining's binary_logloss: 0.511997\n",
      "[289]\ttraining's binary_logloss: 0.511749\n",
      "[290]\ttraining's binary_logloss: 0.511525\n",
      "[291]\ttraining's binary_logloss: 0.511271\n",
      "[292]\ttraining's binary_logloss: 0.511004\n",
      "[293]\ttraining's binary_logloss: 0.510753\n",
      "[294]\ttraining's binary_logloss: 0.510524\n",
      "[295]\ttraining's binary_logloss: 0.510266\n",
      "[296]\ttraining's binary_logloss: 0.510045\n",
      "[297]\ttraining's binary_logloss: 0.509794\n",
      "[298]\ttraining's binary_logloss: 0.509586\n",
      "[299]\ttraining's binary_logloss: 0.509317\n",
      "[300]\ttraining's binary_logloss: 0.509102\n",
      "[301]\ttraining's binary_logloss: 0.508867\n",
      "[302]\ttraining's binary_logloss: 0.508642\n",
      "[303]\ttraining's binary_logloss: 0.508409\n",
      "[304]\ttraining's binary_logloss: 0.508151\n",
      "[305]\ttraining's binary_logloss: 0.50793\n",
      "[306]\ttraining's binary_logloss: 0.50767\n",
      "[307]\ttraining's binary_logloss: 0.507497\n",
      "[308]\ttraining's binary_logloss: 0.507285\n",
      "[309]\ttraining's binary_logloss: 0.507022\n",
      "[310]\ttraining's binary_logloss: 0.50682\n",
      "[311]\ttraining's binary_logloss: 0.506618\n",
      "[312]\ttraining's binary_logloss: 0.506419\n",
      "[313]\ttraining's binary_logloss: 0.506203\n",
      "[314]\ttraining's binary_logloss: 0.506013\n",
      "[315]\ttraining's binary_logloss: 0.505828\n",
      "[316]\ttraining's binary_logloss: 0.505547\n",
      "[317]\ttraining's binary_logloss: 0.505292\n",
      "[318]\ttraining's binary_logloss: 0.50503\n",
      "[319]\ttraining's binary_logloss: 0.504756\n",
      "[320]\ttraining's binary_logloss: 0.5045\n",
      "[321]\ttraining's binary_logloss: 0.504274\n",
      "[322]\ttraining's binary_logloss: 0.504039\n",
      "[323]\ttraining's binary_logloss: 0.503774\n",
      "[324]\ttraining's binary_logloss: 0.503544\n",
      "[325]\ttraining's binary_logloss: 0.503316\n",
      "[326]\ttraining's binary_logloss: 0.503032\n",
      "[327]\ttraining's binary_logloss: 0.502743\n",
      "[328]\ttraining's binary_logloss: 0.502459\n",
      "[329]\ttraining's binary_logloss: 0.502196\n",
      "[330]\ttraining's binary_logloss: 0.501932\n",
      "[331]\ttraining's binary_logloss: 0.501678\n",
      "[332]\ttraining's binary_logloss: 0.501451\n",
      "[333]\ttraining's binary_logloss: 0.501222\n",
      "[334]\ttraining's binary_logloss: 0.500989\n",
      "[335]\ttraining's binary_logloss: 0.50076\n",
      "[336]\ttraining's binary_logloss: 0.500538\n",
      "[337]\ttraining's binary_logloss: 0.500334\n",
      "[338]\ttraining's binary_logloss: 0.500145\n",
      "[339]\ttraining's binary_logloss: 0.499949\n",
      "[340]\ttraining's binary_logloss: 0.49977\n",
      "[341]\ttraining's binary_logloss: 0.499557\n",
      "[342]\ttraining's binary_logloss: 0.499362\n",
      "[343]\ttraining's binary_logloss: 0.499167\n",
      "[344]\ttraining's binary_logloss: 0.49893\n",
      "[345]\ttraining's binary_logloss: 0.498737\n",
      "[346]\ttraining's binary_logloss: 0.498504\n",
      "[347]\ttraining's binary_logloss: 0.498261\n",
      "[348]\ttraining's binary_logloss: 0.498038\n",
      "[349]\ttraining's binary_logloss: 0.497788\n",
      "[350]\ttraining's binary_logloss: 0.497557\n",
      "[351]\ttraining's binary_logloss: 0.497352\n",
      "[352]\ttraining's binary_logloss: 0.497145\n",
      "[353]\ttraining's binary_logloss: 0.496924\n",
      "[354]\ttraining's binary_logloss: 0.496696\n",
      "[355]\ttraining's binary_logloss: 0.496514\n",
      "[356]\ttraining's binary_logloss: 0.496282\n",
      "[357]\ttraining's binary_logloss: 0.496021\n",
      "[358]\ttraining's binary_logloss: 0.495773\n",
      "[359]\ttraining's binary_logloss: 0.495537\n",
      "[360]\ttraining's binary_logloss: 0.495327\n",
      "[361]\ttraining's binary_logloss: 0.495049\n",
      "[362]\ttraining's binary_logloss: 0.494808\n",
      "[363]\ttraining's binary_logloss: 0.494541\n",
      "[364]\ttraining's binary_logloss: 0.494275\n",
      "[365]\ttraining's binary_logloss: 0.494025\n",
      "[366]\ttraining's binary_logloss: 0.4938\n",
      "[367]\ttraining's binary_logloss: 0.493553\n",
      "[368]\ttraining's binary_logloss: 0.493327\n",
      "[369]\ttraining's binary_logloss: 0.49311\n",
      "[370]\ttraining's binary_logloss: 0.492909\n",
      "[371]\ttraining's binary_logloss: 0.492695\n",
      "[372]\ttraining's binary_logloss: 0.492487\n",
      "[373]\ttraining's binary_logloss: 0.492273\n",
      "[374]\ttraining's binary_logloss: 0.492041\n",
      "[375]\ttraining's binary_logloss: 0.49183\n",
      "[376]\ttraining's binary_logloss: 0.491617\n",
      "[377]\ttraining's binary_logloss: 0.491396\n",
      "[378]\ttraining's binary_logloss: 0.491175\n",
      "[379]\ttraining's binary_logloss: 0.490955\n",
      "[380]\ttraining's binary_logloss: 0.490736\n",
      "[381]\ttraining's binary_logloss: 0.49053\n",
      "[382]\ttraining's binary_logloss: 0.49033\n",
      "[383]\ttraining's binary_logloss: 0.490118\n",
      "[384]\ttraining's binary_logloss: 0.489934\n",
      "[385]\ttraining's binary_logloss: 0.489712\n",
      "[386]\ttraining's binary_logloss: 0.489434\n",
      "[387]\ttraining's binary_logloss: 0.489168\n",
      "[388]\ttraining's binary_logloss: 0.488885\n",
      "[389]\ttraining's binary_logloss: 0.488602\n",
      "[390]\ttraining's binary_logloss: 0.488277\n",
      "[391]\ttraining's binary_logloss: 0.488007\n",
      "[392]\ttraining's binary_logloss: 0.48781\n",
      "[393]\ttraining's binary_logloss: 0.487594\n",
      "[394]\ttraining's binary_logloss: 0.48736\n",
      "[395]\ttraining's binary_logloss: 0.487119\n",
      "[396]\ttraining's binary_logloss: 0.486898\n",
      "[397]\ttraining's binary_logloss: 0.486682\n",
      "[398]\ttraining's binary_logloss: 0.486457\n",
      "[399]\ttraining's binary_logloss: 0.486215\n",
      "[400]\ttraining's binary_logloss: 0.485977\n",
      "[401]\ttraining's binary_logloss: 0.485716\n",
      "[402]\ttraining's binary_logloss: 0.485454\n",
      "[403]\ttraining's binary_logloss: 0.485195\n",
      "[404]\ttraining's binary_logloss: 0.48493\n",
      "[405]\ttraining's binary_logloss: 0.484667\n",
      "[406]\ttraining's binary_logloss: 0.484466\n",
      "[407]\ttraining's binary_logloss: 0.484287\n",
      "[408]\ttraining's binary_logloss: 0.484082\n",
      "[409]\ttraining's binary_logloss: 0.483856\n",
      "[410]\ttraining's binary_logloss: 0.483648\n",
      "[411]\ttraining's binary_logloss: 0.483347\n",
      "[412]\ttraining's binary_logloss: 0.483093\n",
      "[413]\ttraining's binary_logloss: 0.482849\n",
      "[414]\ttraining's binary_logloss: 0.48255\n",
      "[415]\ttraining's binary_logloss: 0.482281\n",
      "[416]\ttraining's binary_logloss: 0.482036\n",
      "[417]\ttraining's binary_logloss: 0.48172\n",
      "[418]\ttraining's binary_logloss: 0.48144\n",
      "[419]\ttraining's binary_logloss: 0.481205\n",
      "[420]\ttraining's binary_logloss: 0.480981\n",
      "[421]\ttraining's binary_logloss: 0.480784\n",
      "[422]\ttraining's binary_logloss: 0.480574\n",
      "[423]\ttraining's binary_logloss: 0.480395\n",
      "[424]\ttraining's binary_logloss: 0.48021\n",
      "[425]\ttraining's binary_logloss: 0.480002\n",
      "[426]\ttraining's binary_logloss: 0.479816\n",
      "[427]\ttraining's binary_logloss: 0.479598\n",
      "[428]\ttraining's binary_logloss: 0.479405\n",
      "[429]\ttraining's binary_logloss: 0.479199\n",
      "[430]\ttraining's binary_logloss: 0.478993\n",
      "[431]\ttraining's binary_logloss: 0.47873\n",
      "[432]\ttraining's binary_logloss: 0.478476\n",
      "[433]\ttraining's binary_logloss: 0.478236\n",
      "[434]\ttraining's binary_logloss: 0.477979\n",
      "[435]\ttraining's binary_logloss: 0.477741\n",
      "[436]\ttraining's binary_logloss: 0.477517\n",
      "[437]\ttraining's binary_logloss: 0.477297\n",
      "[438]\ttraining's binary_logloss: 0.477069\n",
      "[439]\ttraining's binary_logloss: 0.476846\n",
      "[440]\ttraining's binary_logloss: 0.47664\n",
      "[441]\ttraining's binary_logloss: 0.476423\n",
      "[442]\ttraining's binary_logloss: 0.476166\n",
      "[443]\ttraining's binary_logloss: 0.475942\n",
      "[444]\ttraining's binary_logloss: 0.475703\n",
      "[445]\ttraining's binary_logloss: 0.475457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[446]\ttraining's binary_logloss: 0.475231\n",
      "[447]\ttraining's binary_logloss: 0.475015\n",
      "[448]\ttraining's binary_logloss: 0.474785\n",
      "[449]\ttraining's binary_logloss: 0.474571\n",
      "[450]\ttraining's binary_logloss: 0.474376\n",
      "[451]\ttraining's binary_logloss: 0.474158\n",
      "[452]\ttraining's binary_logloss: 0.473942\n",
      "[453]\ttraining's binary_logloss: 0.473743\n",
      "[454]\ttraining's binary_logloss: 0.473523\n",
      "[455]\ttraining's binary_logloss: 0.473296\n",
      "[456]\ttraining's binary_logloss: 0.473057\n",
      "[457]\ttraining's binary_logloss: 0.472835\n",
      "[458]\ttraining's binary_logloss: 0.472619\n",
      "[459]\ttraining's binary_logloss: 0.472388\n",
      "[460]\ttraining's binary_logloss: 0.472163\n",
      "[461]\ttraining's binary_logloss: 0.471917\n",
      "[462]\ttraining's binary_logloss: 0.471664\n",
      "[463]\ttraining's binary_logloss: 0.47141\n",
      "[464]\ttraining's binary_logloss: 0.471152\n",
      "[465]\ttraining's binary_logloss: 0.470903\n",
      "[466]\ttraining's binary_logloss: 0.470666\n",
      "[467]\ttraining's binary_logloss: 0.470431\n",
      "[468]\ttraining's binary_logloss: 0.470202\n",
      "[469]\ttraining's binary_logloss: 0.469967\n",
      "[470]\ttraining's binary_logloss: 0.469719\n",
      "[471]\ttraining's binary_logloss: 0.469514\n",
      "[472]\ttraining's binary_logloss: 0.469304\n",
      "[473]\ttraining's binary_logloss: 0.469109\n",
      "[474]\ttraining's binary_logloss: 0.468891\n",
      "[475]\ttraining's binary_logloss: 0.468701\n",
      "[476]\ttraining's binary_logloss: 0.468447\n",
      "[477]\ttraining's binary_logloss: 0.468215\n",
      "[478]\ttraining's binary_logloss: 0.46798\n",
      "[479]\ttraining's binary_logloss: 0.467801\n",
      "[480]\ttraining's binary_logloss: 0.467588\n",
      "[481]\ttraining's binary_logloss: 0.467351\n",
      "[482]\ttraining's binary_logloss: 0.46713\n",
      "[483]\ttraining's binary_logloss: 0.466911\n",
      "[484]\ttraining's binary_logloss: 0.466686\n",
      "[485]\ttraining's binary_logloss: 0.466466\n",
      "[486]\ttraining's binary_logloss: 0.466199\n",
      "[487]\ttraining's binary_logloss: 0.465955\n",
      "[488]\ttraining's binary_logloss: 0.4657\n",
      "[489]\ttraining's binary_logloss: 0.46544\n",
      "[490]\ttraining's binary_logloss: 0.465196\n",
      "[491]\ttraining's binary_logloss: 0.465004\n",
      "[492]\ttraining's binary_logloss: 0.464829\n",
      "[493]\ttraining's binary_logloss: 0.464643\n",
      "[494]\ttraining's binary_logloss: 0.464467\n",
      "[495]\ttraining's binary_logloss: 0.464286\n",
      "[496]\ttraining's binary_logloss: 0.464054\n",
      "[497]\ttraining's binary_logloss: 0.463822\n",
      "[498]\ttraining's binary_logloss: 0.463609\n",
      "[499]\ttraining's binary_logloss: 0.463396\n",
      "[500]\ttraining's binary_logloss: 0.463178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613536\n",
      "[2]\ttraining's binary_logloss: 0.611899\n",
      "[3]\ttraining's binary_logloss: 0.610162\n",
      "[4]\ttraining's binary_logloss: 0.608636\n",
      "[5]\ttraining's binary_logloss: 0.607143\n",
      "[6]\ttraining's binary_logloss: 0.605635\n",
      "[7]\ttraining's binary_logloss: 0.604195\n",
      "[8]\ttraining's binary_logloss: 0.60284\n",
      "[9]\ttraining's binary_logloss: 0.601483\n",
      "[10]\ttraining's binary_logloss: 0.600174\n",
      "[11]\ttraining's binary_logloss: 0.598983\n",
      "[12]\ttraining's binary_logloss: 0.597683\n",
      "[13]\ttraining's binary_logloss: 0.596395\n",
      "[14]\ttraining's binary_logloss: 0.595155\n",
      "[15]\ttraining's binary_logloss: 0.593974\n",
      "[16]\ttraining's binary_logloss: 0.592812\n",
      "[17]\ttraining's binary_logloss: 0.59187\n",
      "[18]\ttraining's binary_logloss: 0.590803\n",
      "[19]\ttraining's binary_logloss: 0.589713\n",
      "[20]\ttraining's binary_logloss: 0.588633\n",
      "[21]\ttraining's binary_logloss: 0.587609\n",
      "[22]\ttraining's binary_logloss: 0.586627\n",
      "[23]\ttraining's binary_logloss: 0.585675\n",
      "[24]\ttraining's binary_logloss: 0.584728\n",
      "[25]\ttraining's binary_logloss: 0.583817\n",
      "[26]\ttraining's binary_logloss: 0.582989\n",
      "[27]\ttraining's binary_logloss: 0.58212\n",
      "[28]\ttraining's binary_logloss: 0.581256\n",
      "[29]\ttraining's binary_logloss: 0.580444\n",
      "[30]\ttraining's binary_logloss: 0.579657\n",
      "[31]\ttraining's binary_logloss: 0.578809\n",
      "[32]\ttraining's binary_logloss: 0.578071\n",
      "[33]\ttraining's binary_logloss: 0.577286\n",
      "[34]\ttraining's binary_logloss: 0.57658\n",
      "[35]\ttraining's binary_logloss: 0.57583\n",
      "[36]\ttraining's binary_logloss: 0.574995\n",
      "[37]\ttraining's binary_logloss: 0.574201\n",
      "[38]\ttraining's binary_logloss: 0.573563\n",
      "[39]\ttraining's binary_logloss: 0.572881\n",
      "[40]\ttraining's binary_logloss: 0.572183\n",
      "[41]\ttraining's binary_logloss: 0.571539\n",
      "[42]\ttraining's binary_logloss: 0.570938\n",
      "[43]\ttraining's binary_logloss: 0.570403\n",
      "[44]\ttraining's binary_logloss: 0.569823\n",
      "[45]\ttraining's binary_logloss: 0.569203\n",
      "[46]\ttraining's binary_logloss: 0.56861\n",
      "[47]\ttraining's binary_logloss: 0.568049\n",
      "[48]\ttraining's binary_logloss: 0.5675\n",
      "[49]\ttraining's binary_logloss: 0.566952\n",
      "[50]\ttraining's binary_logloss: 0.566386\n",
      "[51]\ttraining's binary_logloss: 0.56585\n",
      "[52]\ttraining's binary_logloss: 0.565269\n",
      "[53]\ttraining's binary_logloss: 0.564744\n",
      "[54]\ttraining's binary_logloss: 0.564172\n",
      "[55]\ttraining's binary_logloss: 0.563688\n",
      "[56]\ttraining's binary_logloss: 0.56323\n",
      "[57]\ttraining's binary_logloss: 0.562681\n",
      "[58]\ttraining's binary_logloss: 0.562174\n",
      "[59]\ttraining's binary_logloss: 0.561665\n",
      "[60]\ttraining's binary_logloss: 0.561165\n",
      "[61]\ttraining's binary_logloss: 0.560693\n",
      "[62]\ttraining's binary_logloss: 0.560245\n",
      "[63]\ttraining's binary_logloss: 0.559797\n",
      "[64]\ttraining's binary_logloss: 0.559364\n",
      "[65]\ttraining's binary_logloss: 0.55896\n",
      "[66]\ttraining's binary_logloss: 0.558543\n",
      "[67]\ttraining's binary_logloss: 0.558149\n",
      "[68]\ttraining's binary_logloss: 0.557806\n",
      "[69]\ttraining's binary_logloss: 0.557425\n",
      "[70]\ttraining's binary_logloss: 0.557053\n",
      "[71]\ttraining's binary_logloss: 0.556654\n",
      "[72]\ttraining's binary_logloss: 0.556273\n",
      "[73]\ttraining's binary_logloss: 0.55589\n",
      "[74]\ttraining's binary_logloss: 0.555525\n",
      "[75]\ttraining's binary_logloss: 0.555177\n",
      "[76]\ttraining's binary_logloss: 0.554786\n",
      "[77]\ttraining's binary_logloss: 0.554482\n",
      "[78]\ttraining's binary_logloss: 0.554178\n",
      "[79]\ttraining's binary_logloss: 0.553805\n",
      "[80]\ttraining's binary_logloss: 0.553449\n",
      "[81]\ttraining's binary_logloss: 0.553033\n",
      "[82]\ttraining's binary_logloss: 0.552653\n",
      "[83]\ttraining's binary_logloss: 0.552355\n",
      "[84]\ttraining's binary_logloss: 0.551996\n",
      "[85]\ttraining's binary_logloss: 0.551699\n",
      "[86]\ttraining's binary_logloss: 0.551303\n",
      "[87]\ttraining's binary_logloss: 0.550909\n",
      "[88]\ttraining's binary_logloss: 0.550571\n",
      "[89]\ttraining's binary_logloss: 0.550272\n",
      "[90]\ttraining's binary_logloss: 0.549911\n",
      "[91]\ttraining's binary_logloss: 0.549643\n",
      "[92]\ttraining's binary_logloss: 0.549319\n",
      "[93]\ttraining's binary_logloss: 0.549013\n",
      "[94]\ttraining's binary_logloss: 0.548717\n",
      "[95]\ttraining's binary_logloss: 0.548426\n",
      "[96]\ttraining's binary_logloss: 0.548126\n",
      "[97]\ttraining's binary_logloss: 0.547823\n",
      "[98]\ttraining's binary_logloss: 0.547596\n",
      "[99]\ttraining's binary_logloss: 0.547302\n",
      "[100]\ttraining's binary_logloss: 0.547023\n",
      "[101]\ttraining's binary_logloss: 0.54676\n",
      "[102]\ttraining's binary_logloss: 0.546506\n",
      "[103]\ttraining's binary_logloss: 0.546259\n",
      "[104]\ttraining's binary_logloss: 0.546018\n",
      "[105]\ttraining's binary_logloss: 0.545728\n",
      "[106]\ttraining's binary_logloss: 0.545428\n",
      "[107]\ttraining's binary_logloss: 0.545135\n",
      "[108]\ttraining's binary_logloss: 0.544862\n",
      "[109]\ttraining's binary_logloss: 0.544616\n",
      "[110]\ttraining's binary_logloss: 0.544378\n",
      "[111]\ttraining's binary_logloss: 0.54412\n",
      "[112]\ttraining's binary_logloss: 0.543866\n",
      "[113]\ttraining's binary_logloss: 0.543583\n",
      "[114]\ttraining's binary_logloss: 0.543322\n",
      "[115]\ttraining's binary_logloss: 0.543067\n",
      "[116]\ttraining's binary_logloss: 0.54282\n",
      "[117]\ttraining's binary_logloss: 0.542552\n",
      "[118]\ttraining's binary_logloss: 0.542328\n",
      "[119]\ttraining's binary_logloss: 0.542135\n",
      "[120]\ttraining's binary_logloss: 0.541884\n",
      "[121]\ttraining's binary_logloss: 0.54161\n",
      "[122]\ttraining's binary_logloss: 0.541355\n",
      "[123]\ttraining's binary_logloss: 0.541154\n",
      "[124]\ttraining's binary_logloss: 0.540918\n",
      "[125]\ttraining's binary_logloss: 0.540696\n",
      "[126]\ttraining's binary_logloss: 0.540427\n",
      "[127]\ttraining's binary_logloss: 0.540164\n",
      "[128]\ttraining's binary_logloss: 0.539919\n",
      "[129]\ttraining's binary_logloss: 0.539654\n",
      "[130]\ttraining's binary_logloss: 0.539389\n",
      "[131]\ttraining's binary_logloss: 0.539159\n",
      "[132]\ttraining's binary_logloss: 0.53893\n",
      "[133]\ttraining's binary_logloss: 0.538702\n",
      "[134]\ttraining's binary_logloss: 0.53849\n",
      "[135]\ttraining's binary_logloss: 0.538287\n",
      "[136]\ttraining's binary_logloss: 0.538059\n",
      "[137]\ttraining's binary_logloss: 0.537846\n",
      "[138]\ttraining's binary_logloss: 0.53763\n",
      "[139]\ttraining's binary_logloss: 0.537409\n",
      "[140]\ttraining's binary_logloss: 0.537161\n",
      "[141]\ttraining's binary_logloss: 0.536975\n",
      "[142]\ttraining's binary_logloss: 0.53674\n",
      "[143]\ttraining's binary_logloss: 0.536528\n",
      "[144]\ttraining's binary_logloss: 0.536292\n",
      "[145]\ttraining's binary_logloss: 0.536074\n",
      "[146]\ttraining's binary_logloss: 0.535852\n",
      "[147]\ttraining's binary_logloss: 0.535628\n",
      "[148]\ttraining's binary_logloss: 0.535397\n",
      "[149]\ttraining's binary_logloss: 0.53519\n",
      "[150]\ttraining's binary_logloss: 0.534955\n",
      "[151]\ttraining's binary_logloss: 0.534727\n",
      "[152]\ttraining's binary_logloss: 0.534461\n",
      "[153]\ttraining's binary_logloss: 0.534216\n",
      "[154]\ttraining's binary_logloss: 0.533969\n",
      "[155]\ttraining's binary_logloss: 0.533744\n",
      "[156]\ttraining's binary_logloss: 0.533524\n",
      "[157]\ttraining's binary_logloss: 0.533335\n",
      "[158]\ttraining's binary_logloss: 0.533146\n",
      "[159]\ttraining's binary_logloss: 0.532956\n",
      "[160]\ttraining's binary_logloss: 0.532749\n",
      "[161]\ttraining's binary_logloss: 0.532473\n",
      "[162]\ttraining's binary_logloss: 0.532219\n",
      "[163]\ttraining's binary_logloss: 0.531983\n",
      "[164]\ttraining's binary_logloss: 0.531744\n",
      "[165]\ttraining's binary_logloss: 0.531528\n",
      "[166]\ttraining's binary_logloss: 0.531319\n",
      "[167]\ttraining's binary_logloss: 0.531086\n",
      "[168]\ttraining's binary_logloss: 0.530876\n",
      "[169]\ttraining's binary_logloss: 0.530641\n",
      "[170]\ttraining's binary_logloss: 0.530413\n",
      "[171]\ttraining's binary_logloss: 0.530171\n",
      "[172]\ttraining's binary_logloss: 0.529933\n",
      "[173]\ttraining's binary_logloss: 0.529669\n",
      "[174]\ttraining's binary_logloss: 0.529451\n",
      "[175]\ttraining's binary_logloss: 0.52921\n",
      "[176]\ttraining's binary_logloss: 0.528978\n",
      "[177]\ttraining's binary_logloss: 0.52878\n",
      "[178]\ttraining's binary_logloss: 0.52856\n",
      "[179]\ttraining's binary_logloss: 0.528368\n",
      "[180]\ttraining's binary_logloss: 0.528172\n",
      "[181]\ttraining's binary_logloss: 0.527948\n",
      "[182]\ttraining's binary_logloss: 0.527778\n",
      "[183]\ttraining's binary_logloss: 0.527603\n",
      "[184]\ttraining's binary_logloss: 0.52739\n",
      "[185]\ttraining's binary_logloss: 0.527217\n",
      "[186]\ttraining's binary_logloss: 0.526977\n",
      "[187]\ttraining's binary_logloss: 0.526714\n",
      "[188]\ttraining's binary_logloss: 0.526451\n",
      "[189]\ttraining's binary_logloss: 0.526203\n",
      "[190]\ttraining's binary_logloss: 0.525961\n",
      "[191]\ttraining's binary_logloss: 0.52572\n",
      "[192]\ttraining's binary_logloss: 0.525497\n",
      "[193]\ttraining's binary_logloss: 0.525245\n",
      "[194]\ttraining's binary_logloss: 0.525043\n",
      "[195]\ttraining's binary_logloss: 0.52484\n",
      "[196]\ttraining's binary_logloss: 0.524611\n",
      "[197]\ttraining's binary_logloss: 0.524402\n",
      "[198]\ttraining's binary_logloss: 0.52418\n",
      "[199]\ttraining's binary_logloss: 0.523951\n",
      "[200]\ttraining's binary_logloss: 0.52369\n",
      "[201]\ttraining's binary_logloss: 0.523456\n",
      "[202]\ttraining's binary_logloss: 0.523253\n",
      "[203]\ttraining's binary_logloss: 0.523036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[204]\ttraining's binary_logloss: 0.522843\n",
      "[205]\ttraining's binary_logloss: 0.522635\n",
      "[206]\ttraining's binary_logloss: 0.522392\n",
      "[207]\ttraining's binary_logloss: 0.522136\n",
      "[208]\ttraining's binary_logloss: 0.521918\n",
      "[209]\ttraining's binary_logloss: 0.521687\n",
      "[210]\ttraining's binary_logloss: 0.521447\n",
      "[211]\ttraining's binary_logloss: 0.521267\n",
      "[212]\ttraining's binary_logloss: 0.52107\n",
      "[213]\ttraining's binary_logloss: 0.520866\n",
      "[214]\ttraining's binary_logloss: 0.520685\n",
      "[215]\ttraining's binary_logloss: 0.520497\n",
      "[216]\ttraining's binary_logloss: 0.520225\n",
      "[217]\ttraining's binary_logloss: 0.519993\n",
      "[218]\ttraining's binary_logloss: 0.519786\n",
      "[219]\ttraining's binary_logloss: 0.519517\n",
      "[220]\ttraining's binary_logloss: 0.519275\n",
      "[221]\ttraining's binary_logloss: 0.519005\n",
      "[222]\ttraining's binary_logloss: 0.518715\n",
      "[223]\ttraining's binary_logloss: 0.518494\n",
      "[224]\ttraining's binary_logloss: 0.518216\n",
      "[225]\ttraining's binary_logloss: 0.517976\n",
      "[226]\ttraining's binary_logloss: 0.51778\n",
      "[227]\ttraining's binary_logloss: 0.517593\n",
      "[228]\ttraining's binary_logloss: 0.517381\n",
      "[229]\ttraining's binary_logloss: 0.517186\n",
      "[230]\ttraining's binary_logloss: 0.516994\n",
      "[231]\ttraining's binary_logloss: 0.516788\n",
      "[232]\ttraining's binary_logloss: 0.516597\n",
      "[233]\ttraining's binary_logloss: 0.516407\n",
      "[234]\ttraining's binary_logloss: 0.516227\n",
      "[235]\ttraining's binary_logloss: 0.516055\n",
      "[236]\ttraining's binary_logloss: 0.51581\n",
      "[237]\ttraining's binary_logloss: 0.515567\n",
      "[238]\ttraining's binary_logloss: 0.515316\n",
      "[239]\ttraining's binary_logloss: 0.515079\n",
      "[240]\ttraining's binary_logloss: 0.514816\n",
      "[241]\ttraining's binary_logloss: 0.514594\n",
      "[242]\ttraining's binary_logloss: 0.514392\n",
      "[243]\ttraining's binary_logloss: 0.514179\n",
      "[244]\ttraining's binary_logloss: 0.513942\n",
      "[245]\ttraining's binary_logloss: 0.513716\n",
      "[246]\ttraining's binary_logloss: 0.51348\n",
      "[247]\ttraining's binary_logloss: 0.513209\n",
      "[248]\ttraining's binary_logloss: 0.512965\n",
      "[249]\ttraining's binary_logloss: 0.512751\n",
      "[250]\ttraining's binary_logloss: 0.51253\n",
      "[251]\ttraining's binary_logloss: 0.51232\n",
      "[252]\ttraining's binary_logloss: 0.512145\n",
      "[253]\ttraining's binary_logloss: 0.51196\n",
      "[254]\ttraining's binary_logloss: 0.511768\n",
      "[255]\ttraining's binary_logloss: 0.511555\n",
      "[256]\ttraining's binary_logloss: 0.51131\n",
      "[257]\ttraining's binary_logloss: 0.511076\n",
      "[258]\ttraining's binary_logloss: 0.510855\n",
      "[259]\ttraining's binary_logloss: 0.510601\n",
      "[260]\ttraining's binary_logloss: 0.510357\n",
      "[261]\ttraining's binary_logloss: 0.510102\n",
      "[262]\ttraining's binary_logloss: 0.50985\n",
      "[263]\ttraining's binary_logloss: 0.509594\n",
      "[264]\ttraining's binary_logloss: 0.509375\n",
      "[265]\ttraining's binary_logloss: 0.509143\n",
      "[266]\ttraining's binary_logloss: 0.508957\n",
      "[267]\ttraining's binary_logloss: 0.508796\n",
      "[268]\ttraining's binary_logloss: 0.508634\n",
      "[269]\ttraining's binary_logloss: 0.508464\n",
      "[270]\ttraining's binary_logloss: 0.508317\n",
      "[271]\ttraining's binary_logloss: 0.50803\n",
      "[272]\ttraining's binary_logloss: 0.50775\n",
      "[273]\ttraining's binary_logloss: 0.507472\n",
      "[274]\ttraining's binary_logloss: 0.507221\n",
      "[275]\ttraining's binary_logloss: 0.506964\n",
      "[276]\ttraining's binary_logloss: 0.50669\n",
      "[277]\ttraining's binary_logloss: 0.506402\n",
      "[278]\ttraining's binary_logloss: 0.506156\n",
      "[279]\ttraining's binary_logloss: 0.505887\n",
      "[280]\ttraining's binary_logloss: 0.505632\n",
      "[281]\ttraining's binary_logloss: 0.505418\n",
      "[282]\ttraining's binary_logloss: 0.505137\n",
      "[283]\ttraining's binary_logloss: 0.504873\n",
      "[284]\ttraining's binary_logloss: 0.504613\n",
      "[285]\ttraining's binary_logloss: 0.504362\n",
      "[286]\ttraining's binary_logloss: 0.504125\n",
      "[287]\ttraining's binary_logloss: 0.503838\n",
      "[288]\ttraining's binary_logloss: 0.503602\n",
      "[289]\ttraining's binary_logloss: 0.503354\n",
      "[290]\ttraining's binary_logloss: 0.503138\n",
      "[291]\ttraining's binary_logloss: 0.50285\n",
      "[292]\ttraining's binary_logloss: 0.502601\n",
      "[293]\ttraining's binary_logloss: 0.502332\n",
      "[294]\ttraining's binary_logloss: 0.502095\n",
      "[295]\ttraining's binary_logloss: 0.501888\n",
      "[296]\ttraining's binary_logloss: 0.501646\n",
      "[297]\ttraining's binary_logloss: 0.501398\n",
      "[298]\ttraining's binary_logloss: 0.501184\n",
      "[299]\ttraining's binary_logloss: 0.500898\n",
      "[300]\ttraining's binary_logloss: 0.500681\n",
      "[301]\ttraining's binary_logloss: 0.500384\n",
      "[302]\ttraining's binary_logloss: 0.500153\n",
      "[303]\ttraining's binary_logloss: 0.499937\n",
      "[304]\ttraining's binary_logloss: 0.499695\n",
      "[305]\ttraining's binary_logloss: 0.499428\n",
      "[306]\ttraining's binary_logloss: 0.499191\n",
      "[307]\ttraining's binary_logloss: 0.49898\n",
      "[308]\ttraining's binary_logloss: 0.498747\n",
      "[309]\ttraining's binary_logloss: 0.498498\n",
      "[310]\ttraining's binary_logloss: 0.498277\n",
      "[311]\ttraining's binary_logloss: 0.49805\n",
      "[312]\ttraining's binary_logloss: 0.49784\n",
      "[313]\ttraining's binary_logloss: 0.497629\n",
      "[314]\ttraining's binary_logloss: 0.49739\n",
      "[315]\ttraining's binary_logloss: 0.497166\n",
      "[316]\ttraining's binary_logloss: 0.496933\n",
      "[317]\ttraining's binary_logloss: 0.496683\n",
      "[318]\ttraining's binary_logloss: 0.496467\n",
      "[319]\ttraining's binary_logloss: 0.49623\n",
      "[320]\ttraining's binary_logloss: 0.496012\n",
      "[321]\ttraining's binary_logloss: 0.495806\n",
      "[322]\ttraining's binary_logloss: 0.495608\n",
      "[323]\ttraining's binary_logloss: 0.495389\n",
      "[324]\ttraining's binary_logloss: 0.495197\n",
      "[325]\ttraining's binary_logloss: 0.494954\n",
      "[326]\ttraining's binary_logloss: 0.494712\n",
      "[327]\ttraining's binary_logloss: 0.49451\n",
      "[328]\ttraining's binary_logloss: 0.494269\n",
      "[329]\ttraining's binary_logloss: 0.494031\n",
      "[330]\ttraining's binary_logloss: 0.493787\n",
      "[331]\ttraining's binary_logloss: 0.493547\n",
      "[332]\ttraining's binary_logloss: 0.493303\n",
      "[333]\ttraining's binary_logloss: 0.493028\n",
      "[334]\ttraining's binary_logloss: 0.492787\n",
      "[335]\ttraining's binary_logloss: 0.492558\n",
      "[336]\ttraining's binary_logloss: 0.492336\n",
      "[337]\ttraining's binary_logloss: 0.492101\n",
      "[338]\ttraining's binary_logloss: 0.491853\n",
      "[339]\ttraining's binary_logloss: 0.491634\n",
      "[340]\ttraining's binary_logloss: 0.4914\n",
      "[341]\ttraining's binary_logloss: 0.491127\n",
      "[342]\ttraining's binary_logloss: 0.49091\n",
      "[343]\ttraining's binary_logloss: 0.490654\n",
      "[344]\ttraining's binary_logloss: 0.490438\n",
      "[345]\ttraining's binary_logloss: 0.490197\n",
      "[346]\ttraining's binary_logloss: 0.489942\n",
      "[347]\ttraining's binary_logloss: 0.489725\n",
      "[348]\ttraining's binary_logloss: 0.48948\n",
      "[349]\ttraining's binary_logloss: 0.489264\n",
      "[350]\ttraining's binary_logloss: 0.489047\n",
      "[351]\ttraining's binary_logloss: 0.488788\n",
      "[352]\ttraining's binary_logloss: 0.488565\n",
      "[353]\ttraining's binary_logloss: 0.488317\n",
      "[354]\ttraining's binary_logloss: 0.488019\n",
      "[355]\ttraining's binary_logloss: 0.487789\n",
      "[356]\ttraining's binary_logloss: 0.487541\n",
      "[357]\ttraining's binary_logloss: 0.487251\n",
      "[358]\ttraining's binary_logloss: 0.486986\n",
      "[359]\ttraining's binary_logloss: 0.486724\n",
      "[360]\ttraining's binary_logloss: 0.486454\n",
      "[361]\ttraining's binary_logloss: 0.486158\n",
      "[362]\ttraining's binary_logloss: 0.48587\n",
      "[363]\ttraining's binary_logloss: 0.485609\n",
      "[364]\ttraining's binary_logloss: 0.48537\n",
      "[365]\ttraining's binary_logloss: 0.485102\n",
      "[366]\ttraining's binary_logloss: 0.48491\n",
      "[367]\ttraining's binary_logloss: 0.48468\n",
      "[368]\ttraining's binary_logloss: 0.484429\n",
      "[369]\ttraining's binary_logloss: 0.484201\n",
      "[370]\ttraining's binary_logloss: 0.483942\n",
      "[371]\ttraining's binary_logloss: 0.483752\n",
      "[372]\ttraining's binary_logloss: 0.48353\n",
      "[373]\ttraining's binary_logloss: 0.483332\n",
      "[374]\ttraining's binary_logloss: 0.483166\n",
      "[375]\ttraining's binary_logloss: 0.482991\n",
      "[376]\ttraining's binary_logloss: 0.482794\n",
      "[377]\ttraining's binary_logloss: 0.482548\n",
      "[378]\ttraining's binary_logloss: 0.482333\n",
      "[379]\ttraining's binary_logloss: 0.482144\n",
      "[380]\ttraining's binary_logloss: 0.481935\n",
      "[381]\ttraining's binary_logloss: 0.48172\n",
      "[382]\ttraining's binary_logloss: 0.481513\n",
      "[383]\ttraining's binary_logloss: 0.481288\n",
      "[384]\ttraining's binary_logloss: 0.481064\n",
      "[385]\ttraining's binary_logloss: 0.480844\n",
      "[386]\ttraining's binary_logloss: 0.480579\n",
      "[387]\ttraining's binary_logloss: 0.480335\n",
      "[388]\ttraining's binary_logloss: 0.480064\n",
      "[389]\ttraining's binary_logloss: 0.479837\n",
      "[390]\ttraining's binary_logloss: 0.479609\n",
      "[391]\ttraining's binary_logloss: 0.479384\n",
      "[392]\ttraining's binary_logloss: 0.47914\n",
      "[393]\ttraining's binary_logloss: 0.478932\n",
      "[394]\ttraining's binary_logloss: 0.478687\n",
      "[395]\ttraining's binary_logloss: 0.478466\n",
      "[396]\ttraining's binary_logloss: 0.478185\n",
      "[397]\ttraining's binary_logloss: 0.477921\n",
      "[398]\ttraining's binary_logloss: 0.477672\n",
      "[399]\ttraining's binary_logloss: 0.477388\n",
      "[400]\ttraining's binary_logloss: 0.477129\n",
      "[401]\ttraining's binary_logloss: 0.476897\n",
      "[402]\ttraining's binary_logloss: 0.476662\n",
      "[403]\ttraining's binary_logloss: 0.476467\n",
      "[404]\ttraining's binary_logloss: 0.476255\n",
      "[405]\ttraining's binary_logloss: 0.476023\n",
      "[406]\ttraining's binary_logloss: 0.475812\n",
      "[407]\ttraining's binary_logloss: 0.475585\n",
      "[408]\ttraining's binary_logloss: 0.475372\n",
      "[409]\ttraining's binary_logloss: 0.475139\n",
      "[410]\ttraining's binary_logloss: 0.474931\n",
      "[411]\ttraining's binary_logloss: 0.474732\n",
      "[412]\ttraining's binary_logloss: 0.47453\n",
      "[413]\ttraining's binary_logloss: 0.474311\n",
      "[414]\ttraining's binary_logloss: 0.474011\n",
      "[415]\ttraining's binary_logloss: 0.473739\n",
      "[416]\ttraining's binary_logloss: 0.473503\n",
      "[417]\ttraining's binary_logloss: 0.473263\n",
      "[418]\ttraining's binary_logloss: 0.473023\n",
      "[419]\ttraining's binary_logloss: 0.472738\n",
      "[420]\ttraining's binary_logloss: 0.47251\n",
      "[421]\ttraining's binary_logloss: 0.472249\n",
      "[422]\ttraining's binary_logloss: 0.472039\n",
      "[423]\ttraining's binary_logloss: 0.471828\n",
      "[424]\ttraining's binary_logloss: 0.4716\n",
      "[425]\ttraining's binary_logloss: 0.471375\n",
      "[426]\ttraining's binary_logloss: 0.471144\n",
      "[427]\ttraining's binary_logloss: 0.470917\n",
      "[428]\ttraining's binary_logloss: 0.470685\n",
      "[429]\ttraining's binary_logloss: 0.470452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[430]\ttraining's binary_logloss: 0.470222\n",
      "[431]\ttraining's binary_logloss: 0.469962\n",
      "[432]\ttraining's binary_logloss: 0.469698\n",
      "[433]\ttraining's binary_logloss: 0.469424\n",
      "[434]\ttraining's binary_logloss: 0.469171\n",
      "[435]\ttraining's binary_logloss: 0.46894\n",
      "[436]\ttraining's binary_logloss: 0.468657\n",
      "[437]\ttraining's binary_logloss: 0.468389\n",
      "[438]\ttraining's binary_logloss: 0.468156\n",
      "[439]\ttraining's binary_logloss: 0.467876\n",
      "[440]\ttraining's binary_logloss: 0.467629\n",
      "[441]\ttraining's binary_logloss: 0.467366\n",
      "[442]\ttraining's binary_logloss: 0.467127\n",
      "[443]\ttraining's binary_logloss: 0.466911\n",
      "[444]\ttraining's binary_logloss: 0.466687\n",
      "[445]\ttraining's binary_logloss: 0.466463\n",
      "[446]\ttraining's binary_logloss: 0.466225\n",
      "[447]\ttraining's binary_logloss: 0.46598\n",
      "[448]\ttraining's binary_logloss: 0.465724\n",
      "[449]\ttraining's binary_logloss: 0.465486\n",
      "[450]\ttraining's binary_logloss: 0.465256\n",
      "[451]\ttraining's binary_logloss: 0.465038\n",
      "[452]\ttraining's binary_logloss: 0.464832\n",
      "[453]\ttraining's binary_logloss: 0.464615\n",
      "[454]\ttraining's binary_logloss: 0.464414\n",
      "[455]\ttraining's binary_logloss: 0.464217\n",
      "[456]\ttraining's binary_logloss: 0.464023\n",
      "[457]\ttraining's binary_logloss: 0.463814\n",
      "[458]\ttraining's binary_logloss: 0.463613\n",
      "[459]\ttraining's binary_logloss: 0.463387\n",
      "[460]\ttraining's binary_logloss: 0.463209\n",
      "[461]\ttraining's binary_logloss: 0.462963\n",
      "[462]\ttraining's binary_logloss: 0.462726\n",
      "[463]\ttraining's binary_logloss: 0.462498\n",
      "[464]\ttraining's binary_logloss: 0.462305\n",
      "[465]\ttraining's binary_logloss: 0.462094\n",
      "[466]\ttraining's binary_logloss: 0.46187\n",
      "[467]\ttraining's binary_logloss: 0.461618\n",
      "[468]\ttraining's binary_logloss: 0.461372\n",
      "[469]\ttraining's binary_logloss: 0.461139\n",
      "[470]\ttraining's binary_logloss: 0.460895\n",
      "[471]\ttraining's binary_logloss: 0.460698\n",
      "[472]\ttraining's binary_logloss: 0.460505\n",
      "[473]\ttraining's binary_logloss: 0.460307\n",
      "[474]\ttraining's binary_logloss: 0.460127\n",
      "[475]\ttraining's binary_logloss: 0.45995\n",
      "[476]\ttraining's binary_logloss: 0.459735\n",
      "[477]\ttraining's binary_logloss: 0.459492\n",
      "[478]\ttraining's binary_logloss: 0.45925\n",
      "[479]\ttraining's binary_logloss: 0.459054\n",
      "[480]\ttraining's binary_logloss: 0.45883\n",
      "[481]\ttraining's binary_logloss: 0.458618\n",
      "[482]\ttraining's binary_logloss: 0.458372\n",
      "[483]\ttraining's binary_logloss: 0.458147\n",
      "[484]\ttraining's binary_logloss: 0.457918\n",
      "[485]\ttraining's binary_logloss: 0.45771\n",
      "[486]\ttraining's binary_logloss: 0.457473\n",
      "[487]\ttraining's binary_logloss: 0.457224\n",
      "[488]\ttraining's binary_logloss: 0.456964\n",
      "[489]\ttraining's binary_logloss: 0.456725\n",
      "[490]\ttraining's binary_logloss: 0.456486\n",
      "[491]\ttraining's binary_logloss: 0.456283\n",
      "[492]\ttraining's binary_logloss: 0.456075\n",
      "[493]\ttraining's binary_logloss: 0.455864\n",
      "[494]\ttraining's binary_logloss: 0.455651\n",
      "[495]\ttraining's binary_logloss: 0.45546\n",
      "[496]\ttraining's binary_logloss: 0.455239\n",
      "[497]\ttraining's binary_logloss: 0.454977\n",
      "[498]\ttraining's binary_logloss: 0.454782\n",
      "[499]\ttraining's binary_logloss: 0.454535\n",
      "[500]\ttraining's binary_logloss: 0.454286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.612683\n",
      "[2]\ttraining's binary_logloss: 0.611075\n",
      "[3]\ttraining's binary_logloss: 0.609557\n",
      "[4]\ttraining's binary_logloss: 0.608002\n",
      "[5]\ttraining's binary_logloss: 0.606484\n",
      "[6]\ttraining's binary_logloss: 0.605009\n",
      "[7]\ttraining's binary_logloss: 0.603619\n",
      "[8]\ttraining's binary_logloss: 0.60225\n",
      "[9]\ttraining's binary_logloss: 0.601024\n",
      "[10]\ttraining's binary_logloss: 0.599696\n",
      "[11]\ttraining's binary_logloss: 0.598507\n",
      "[12]\ttraining's binary_logloss: 0.597284\n",
      "[13]\ttraining's binary_logloss: 0.59612\n",
      "[14]\ttraining's binary_logloss: 0.594981\n",
      "[15]\ttraining's binary_logloss: 0.593902\n",
      "[16]\ttraining's binary_logloss: 0.592697\n",
      "[17]\ttraining's binary_logloss: 0.591593\n",
      "[18]\ttraining's binary_logloss: 0.590528\n",
      "[19]\ttraining's binary_logloss: 0.589486\n",
      "[20]\ttraining's binary_logloss: 0.588492\n",
      "[21]\ttraining's binary_logloss: 0.587499\n",
      "[22]\ttraining's binary_logloss: 0.586539\n",
      "[23]\ttraining's binary_logloss: 0.585598\n",
      "[24]\ttraining's binary_logloss: 0.584697\n",
      "[25]\ttraining's binary_logloss: 0.58378\n",
      "[26]\ttraining's binary_logloss: 0.582878\n",
      "[27]\ttraining's binary_logloss: 0.582088\n",
      "[28]\ttraining's binary_logloss: 0.581303\n",
      "[29]\ttraining's binary_logloss: 0.580559\n",
      "[30]\ttraining's binary_logloss: 0.579732\n",
      "[31]\ttraining's binary_logloss: 0.578975\n",
      "[32]\ttraining's binary_logloss: 0.578222\n",
      "[33]\ttraining's binary_logloss: 0.577567\n",
      "[34]\ttraining's binary_logloss: 0.576886\n",
      "[35]\ttraining's binary_logloss: 0.576161\n",
      "[36]\ttraining's binary_logloss: 0.575507\n",
      "[37]\ttraining's binary_logloss: 0.574962\n",
      "[38]\ttraining's binary_logloss: 0.574252\n",
      "[39]\ttraining's binary_logloss: 0.573628\n",
      "[40]\ttraining's binary_logloss: 0.572978\n",
      "[41]\ttraining's binary_logloss: 0.572337\n",
      "[42]\ttraining's binary_logloss: 0.571823\n",
      "[43]\ttraining's binary_logloss: 0.571319\n",
      "[44]\ttraining's binary_logloss: 0.570714\n",
      "[45]\ttraining's binary_logloss: 0.570077\n",
      "[46]\ttraining's binary_logloss: 0.569468\n",
      "[47]\ttraining's binary_logloss: 0.56884\n",
      "[48]\ttraining's binary_logloss: 0.568301\n",
      "[49]\ttraining's binary_logloss: 0.567769\n",
      "[50]\ttraining's binary_logloss: 0.567211\n",
      "[51]\ttraining's binary_logloss: 0.566665\n",
      "[52]\ttraining's binary_logloss: 0.566175\n",
      "[53]\ttraining's binary_logloss: 0.565709\n",
      "[54]\ttraining's binary_logloss: 0.565192\n",
      "[55]\ttraining's binary_logloss: 0.564672\n",
      "[56]\ttraining's binary_logloss: 0.564245\n",
      "[57]\ttraining's binary_logloss: 0.563825\n",
      "[58]\ttraining's binary_logloss: 0.56341\n",
      "[59]\ttraining's binary_logloss: 0.562994\n",
      "[60]\ttraining's binary_logloss: 0.562524\n",
      "[61]\ttraining's binary_logloss: 0.562089\n",
      "[62]\ttraining's binary_logloss: 0.561655\n",
      "[63]\ttraining's binary_logloss: 0.561241\n",
      "[64]\ttraining's binary_logloss: 0.560784\n",
      "[65]\ttraining's binary_logloss: 0.560388\n",
      "[66]\ttraining's binary_logloss: 0.559927\n",
      "[67]\ttraining's binary_logloss: 0.559479\n",
      "[68]\ttraining's binary_logloss: 0.559137\n",
      "[69]\ttraining's binary_logloss: 0.558753\n",
      "[70]\ttraining's binary_logloss: 0.558335\n",
      "[71]\ttraining's binary_logloss: 0.557891\n",
      "[72]\ttraining's binary_logloss: 0.557456\n",
      "[73]\ttraining's binary_logloss: 0.55704\n",
      "[74]\ttraining's binary_logloss: 0.556636\n",
      "[75]\ttraining's binary_logloss: 0.556272\n",
      "[76]\ttraining's binary_logloss: 0.555908\n",
      "[77]\ttraining's binary_logloss: 0.555578\n",
      "[78]\ttraining's binary_logloss: 0.555226\n",
      "[79]\ttraining's binary_logloss: 0.554932\n",
      "[80]\ttraining's binary_logloss: 0.554644\n",
      "[81]\ttraining's binary_logloss: 0.55433\n",
      "[82]\ttraining's binary_logloss: 0.553932\n",
      "[83]\ttraining's binary_logloss: 0.553546\n",
      "[84]\ttraining's binary_logloss: 0.553177\n",
      "[85]\ttraining's binary_logloss: 0.552815\n",
      "[86]\ttraining's binary_logloss: 0.55249\n",
      "[87]\ttraining's binary_logloss: 0.552146\n",
      "[88]\ttraining's binary_logloss: 0.551804\n",
      "[89]\ttraining's binary_logloss: 0.551463\n",
      "[90]\ttraining's binary_logloss: 0.55116\n",
      "[91]\ttraining's binary_logloss: 0.550851\n",
      "[92]\ttraining's binary_logloss: 0.550548\n",
      "[93]\ttraining's binary_logloss: 0.550265\n",
      "[94]\ttraining's binary_logloss: 0.550001\n",
      "[95]\ttraining's binary_logloss: 0.549727\n",
      "[96]\ttraining's binary_logloss: 0.54946\n",
      "[97]\ttraining's binary_logloss: 0.549184\n",
      "[98]\ttraining's binary_logloss: 0.548959\n",
      "[99]\ttraining's binary_logloss: 0.548697\n",
      "[100]\ttraining's binary_logloss: 0.548456\n",
      "[101]\ttraining's binary_logloss: 0.548219\n",
      "[102]\ttraining's binary_logloss: 0.547977\n",
      "[103]\ttraining's binary_logloss: 0.547738\n",
      "[104]\ttraining's binary_logloss: 0.547522\n",
      "[105]\ttraining's binary_logloss: 0.547285\n",
      "[106]\ttraining's binary_logloss: 0.547036\n",
      "[107]\ttraining's binary_logloss: 0.546812\n",
      "[108]\ttraining's binary_logloss: 0.546539\n",
      "[109]\ttraining's binary_logloss: 0.546289\n",
      "[110]\ttraining's binary_logloss: 0.546058\n",
      "[111]\ttraining's binary_logloss: 0.545804\n",
      "[112]\ttraining's binary_logloss: 0.545577\n",
      "[113]\ttraining's binary_logloss: 0.545367\n",
      "[114]\ttraining's binary_logloss: 0.545183\n",
      "[115]\ttraining's binary_logloss: 0.544942\n",
      "[116]\ttraining's binary_logloss: 0.544671\n",
      "[117]\ttraining's binary_logloss: 0.544408\n",
      "[118]\ttraining's binary_logloss: 0.544217\n",
      "[119]\ttraining's binary_logloss: 0.544042\n",
      "[120]\ttraining's binary_logloss: 0.543792\n",
      "[121]\ttraining's binary_logloss: 0.543576\n",
      "[122]\ttraining's binary_logloss: 0.543342\n",
      "[123]\ttraining's binary_logloss: 0.543104\n",
      "[124]\ttraining's binary_logloss: 0.542863\n",
      "[125]\ttraining's binary_logloss: 0.54263\n",
      "[126]\ttraining's binary_logloss: 0.542335\n",
      "[127]\ttraining's binary_logloss: 0.542047\n",
      "[128]\ttraining's binary_logloss: 0.541768\n",
      "[129]\ttraining's binary_logloss: 0.54151\n",
      "[130]\ttraining's binary_logloss: 0.541238\n",
      "[131]\ttraining's binary_logloss: 0.540984\n",
      "[132]\ttraining's binary_logloss: 0.540743\n",
      "[133]\ttraining's binary_logloss: 0.540491\n",
      "[134]\ttraining's binary_logloss: 0.540245\n",
      "[135]\ttraining's binary_logloss: 0.54006\n",
      "[136]\ttraining's binary_logloss: 0.539862\n",
      "[137]\ttraining's binary_logloss: 0.539655\n",
      "[138]\ttraining's binary_logloss: 0.539438\n",
      "[139]\ttraining's binary_logloss: 0.539234\n",
      "[140]\ttraining's binary_logloss: 0.538979\n",
      "[141]\ttraining's binary_logloss: 0.538698\n",
      "[142]\ttraining's binary_logloss: 0.538489\n",
      "[143]\ttraining's binary_logloss: 0.538236\n",
      "[144]\ttraining's binary_logloss: 0.537969\n",
      "[145]\ttraining's binary_logloss: 0.537742\n",
      "[146]\ttraining's binary_logloss: 0.537486\n",
      "[147]\ttraining's binary_logloss: 0.537206\n",
      "[148]\ttraining's binary_logloss: 0.536956\n",
      "[149]\ttraining's binary_logloss: 0.536724\n",
      "[150]\ttraining's binary_logloss: 0.5365\n",
      "[151]\ttraining's binary_logloss: 0.536287\n",
      "[152]\ttraining's binary_logloss: 0.536053\n",
      "[153]\ttraining's binary_logloss: 0.535835\n",
      "[154]\ttraining's binary_logloss: 0.535607\n",
      "[155]\ttraining's binary_logloss: 0.535406\n",
      "[156]\ttraining's binary_logloss: 0.535218\n",
      "[157]\ttraining's binary_logloss: 0.535026\n",
      "[158]\ttraining's binary_logloss: 0.534812\n",
      "[159]\ttraining's binary_logloss: 0.534638\n",
      "[160]\ttraining's binary_logloss: 0.534451\n",
      "[161]\ttraining's binary_logloss: 0.53418\n",
      "[162]\ttraining's binary_logloss: 0.533896\n",
      "[163]\ttraining's binary_logloss: 0.533674\n",
      "[164]\ttraining's binary_logloss: 0.533459\n",
      "[165]\ttraining's binary_logloss: 0.533213\n",
      "[166]\ttraining's binary_logloss: 0.532935\n",
      "[167]\ttraining's binary_logloss: 0.532684\n",
      "[168]\ttraining's binary_logloss: 0.532465\n",
      "[169]\ttraining's binary_logloss: 0.532235\n",
      "[170]\ttraining's binary_logloss: 0.532016\n",
      "[171]\ttraining's binary_logloss: 0.531797\n",
      "[172]\ttraining's binary_logloss: 0.531566\n",
      "[173]\ttraining's binary_logloss: 0.531353\n",
      "[174]\ttraining's binary_logloss: 0.531161\n",
      "[175]\ttraining's binary_logloss: 0.530969\n",
      "[176]\ttraining's binary_logloss: 0.530778\n",
      "[177]\ttraining's binary_logloss: 0.530602\n",
      "[178]\ttraining's binary_logloss: 0.530407\n",
      "[179]\ttraining's binary_logloss: 0.530219\n",
      "[180]\ttraining's binary_logloss: 0.530028\n",
      "[181]\ttraining's binary_logloss: 0.529843\n",
      "[182]\ttraining's binary_logloss: 0.529659\n",
      "[183]\ttraining's binary_logloss: 0.529488\n",
      "[184]\ttraining's binary_logloss: 0.529321\n",
      "[185]\ttraining's binary_logloss: 0.529082\n",
      "[186]\ttraining's binary_logloss: 0.528901\n",
      "[187]\ttraining's binary_logloss: 0.528676\n",
      "[188]\ttraining's binary_logloss: 0.528506\n",
      "[189]\ttraining's binary_logloss: 0.528331\n",
      "[190]\ttraining's binary_logloss: 0.528113\n",
      "[191]\ttraining's binary_logloss: 0.527937\n",
      "[192]\ttraining's binary_logloss: 0.527759\n",
      "[193]\ttraining's binary_logloss: 0.527567\n",
      "[194]\ttraining's binary_logloss: 0.527415\n",
      "[195]\ttraining's binary_logloss: 0.527193\n",
      "[196]\ttraining's binary_logloss: 0.52701\n",
      "[197]\ttraining's binary_logloss: 0.526833\n",
      "[198]\ttraining's binary_logloss: 0.526651\n",
      "[199]\ttraining's binary_logloss: 0.526442\n",
      "[200]\ttraining's binary_logloss: 0.526287\n",
      "[201]\ttraining's binary_logloss: 0.526069\n",
      "[202]\ttraining's binary_logloss: 0.525834\n",
      "[203]\ttraining's binary_logloss: 0.525638\n",
      "[204]\ttraining's binary_logloss: 0.525463\n",
      "[205]\ttraining's binary_logloss: 0.525243\n",
      "[206]\ttraining's binary_logloss: 0.525015\n",
      "[207]\ttraining's binary_logloss: 0.524821\n",
      "[208]\ttraining's binary_logloss: 0.524643\n",
      "[209]\ttraining's binary_logloss: 0.524449\n",
      "[210]\ttraining's binary_logloss: 0.524209\n",
      "[211]\ttraining's binary_logloss: 0.523992\n",
      "[212]\ttraining's binary_logloss: 0.523794\n",
      "[213]\ttraining's binary_logloss: 0.523583\n",
      "[214]\ttraining's binary_logloss: 0.523378\n",
      "[215]\ttraining's binary_logloss: 0.523176\n",
      "[216]\ttraining's binary_logloss: 0.52294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[217]\ttraining's binary_logloss: 0.522707\n",
      "[218]\ttraining's binary_logloss: 0.522497\n",
      "[219]\ttraining's binary_logloss: 0.522287\n",
      "[220]\ttraining's binary_logloss: 0.522091\n",
      "[221]\ttraining's binary_logloss: 0.521861\n",
      "[222]\ttraining's binary_logloss: 0.521621\n",
      "[223]\ttraining's binary_logloss: 0.521394\n",
      "[224]\ttraining's binary_logloss: 0.521143\n",
      "[225]\ttraining's binary_logloss: 0.52093\n",
      "[226]\ttraining's binary_logloss: 0.520701\n",
      "[227]\ttraining's binary_logloss: 0.520467\n",
      "[228]\ttraining's binary_logloss: 0.520218\n",
      "[229]\ttraining's binary_logloss: 0.519995\n",
      "[230]\ttraining's binary_logloss: 0.519788\n",
      "[231]\ttraining's binary_logloss: 0.519591\n",
      "[232]\ttraining's binary_logloss: 0.519355\n",
      "[233]\ttraining's binary_logloss: 0.519169\n",
      "[234]\ttraining's binary_logloss: 0.519\n",
      "[235]\ttraining's binary_logloss: 0.518744\n",
      "[236]\ttraining's binary_logloss: 0.518542\n",
      "[237]\ttraining's binary_logloss: 0.518358\n",
      "[238]\ttraining's binary_logloss: 0.518152\n",
      "[239]\ttraining's binary_logloss: 0.517958\n",
      "[240]\ttraining's binary_logloss: 0.517771\n",
      "[241]\ttraining's binary_logloss: 0.517546\n",
      "[242]\ttraining's binary_logloss: 0.517313\n",
      "[243]\ttraining's binary_logloss: 0.517073\n",
      "[244]\ttraining's binary_logloss: 0.516857\n",
      "[245]\ttraining's binary_logloss: 0.516655\n",
      "[246]\ttraining's binary_logloss: 0.516413\n",
      "[247]\ttraining's binary_logloss: 0.516128\n",
      "[248]\ttraining's binary_logloss: 0.515909\n",
      "[249]\ttraining's binary_logloss: 0.515674\n",
      "[250]\ttraining's binary_logloss: 0.515458\n",
      "[251]\ttraining's binary_logloss: 0.515254\n",
      "[252]\ttraining's binary_logloss: 0.515028\n",
      "[253]\ttraining's binary_logloss: 0.51484\n",
      "[254]\ttraining's binary_logloss: 0.514624\n",
      "[255]\ttraining's binary_logloss: 0.514439\n",
      "[256]\ttraining's binary_logloss: 0.514231\n",
      "[257]\ttraining's binary_logloss: 0.513983\n",
      "[258]\ttraining's binary_logloss: 0.513722\n",
      "[259]\ttraining's binary_logloss: 0.513499\n",
      "[260]\ttraining's binary_logloss: 0.513247\n",
      "[261]\ttraining's binary_logloss: 0.513024\n",
      "[262]\ttraining's binary_logloss: 0.512792\n",
      "[263]\ttraining's binary_logloss: 0.51257\n",
      "[264]\ttraining's binary_logloss: 0.51234\n",
      "[265]\ttraining's binary_logloss: 0.512136\n",
      "[266]\ttraining's binary_logloss: 0.511948\n",
      "[267]\ttraining's binary_logloss: 0.511759\n",
      "[268]\ttraining's binary_logloss: 0.511527\n",
      "[269]\ttraining's binary_logloss: 0.511336\n",
      "[270]\ttraining's binary_logloss: 0.511117\n",
      "[271]\ttraining's binary_logloss: 0.510849\n",
      "[272]\ttraining's binary_logloss: 0.510585\n",
      "[273]\ttraining's binary_logloss: 0.51037\n",
      "[274]\ttraining's binary_logloss: 0.51015\n",
      "[275]\ttraining's binary_logloss: 0.509919\n",
      "[276]\ttraining's binary_logloss: 0.509756\n",
      "[277]\ttraining's binary_logloss: 0.509507\n",
      "[278]\ttraining's binary_logloss: 0.509268\n",
      "[279]\ttraining's binary_logloss: 0.509026\n",
      "[280]\ttraining's binary_logloss: 0.50879\n",
      "[281]\ttraining's binary_logloss: 0.508555\n",
      "[282]\ttraining's binary_logloss: 0.508284\n",
      "[283]\ttraining's binary_logloss: 0.508029\n",
      "[284]\ttraining's binary_logloss: 0.507815\n",
      "[285]\ttraining's binary_logloss: 0.507557\n",
      "[286]\ttraining's binary_logloss: 0.507318\n",
      "[287]\ttraining's binary_logloss: 0.50704\n",
      "[288]\ttraining's binary_logloss: 0.506767\n",
      "[289]\ttraining's binary_logloss: 0.506511\n",
      "[290]\ttraining's binary_logloss: 0.506241\n",
      "[291]\ttraining's binary_logloss: 0.505958\n",
      "[292]\ttraining's binary_logloss: 0.505708\n",
      "[293]\ttraining's binary_logloss: 0.505446\n",
      "[294]\ttraining's binary_logloss: 0.505175\n",
      "[295]\ttraining's binary_logloss: 0.504928\n",
      "[296]\ttraining's binary_logloss: 0.504694\n",
      "[297]\ttraining's binary_logloss: 0.504461\n",
      "[298]\ttraining's binary_logloss: 0.504229\n",
      "[299]\ttraining's binary_logloss: 0.50401\n",
      "[300]\ttraining's binary_logloss: 0.503751\n",
      "[301]\ttraining's binary_logloss: 0.5035\n",
      "[302]\ttraining's binary_logloss: 0.503271\n",
      "[303]\ttraining's binary_logloss: 0.503046\n",
      "[304]\ttraining's binary_logloss: 0.502838\n",
      "[305]\ttraining's binary_logloss: 0.502615\n",
      "[306]\ttraining's binary_logloss: 0.502369\n",
      "[307]\ttraining's binary_logloss: 0.502132\n",
      "[308]\ttraining's binary_logloss: 0.5019\n",
      "[309]\ttraining's binary_logloss: 0.501669\n",
      "[310]\ttraining's binary_logloss: 0.501437\n",
      "[311]\ttraining's binary_logloss: 0.501165\n",
      "[312]\ttraining's binary_logloss: 0.500894\n",
      "[313]\ttraining's binary_logloss: 0.500638\n",
      "[314]\ttraining's binary_logloss: 0.500375\n",
      "[315]\ttraining's binary_logloss: 0.500139\n",
      "[316]\ttraining's binary_logloss: 0.499894\n",
      "[317]\ttraining's binary_logloss: 0.499636\n",
      "[318]\ttraining's binary_logloss: 0.499375\n",
      "[319]\ttraining's binary_logloss: 0.499139\n",
      "[320]\ttraining's binary_logloss: 0.498873\n",
      "[321]\ttraining's binary_logloss: 0.498625\n",
      "[322]\ttraining's binary_logloss: 0.498402\n",
      "[323]\ttraining's binary_logloss: 0.498159\n",
      "[324]\ttraining's binary_logloss: 0.497918\n",
      "[325]\ttraining's binary_logloss: 0.497719\n",
      "[326]\ttraining's binary_logloss: 0.497487\n",
      "[327]\ttraining's binary_logloss: 0.497261\n",
      "[328]\ttraining's binary_logloss: 0.497037\n",
      "[329]\ttraining's binary_logloss: 0.496802\n",
      "[330]\ttraining's binary_logloss: 0.496591\n",
      "[331]\ttraining's binary_logloss: 0.496313\n",
      "[332]\ttraining's binary_logloss: 0.496056\n",
      "[333]\ttraining's binary_logloss: 0.495796\n",
      "[334]\ttraining's binary_logloss: 0.495594\n",
      "[335]\ttraining's binary_logloss: 0.495358\n",
      "[336]\ttraining's binary_logloss: 0.495066\n",
      "[337]\ttraining's binary_logloss: 0.494834\n",
      "[338]\ttraining's binary_logloss: 0.49457\n",
      "[339]\ttraining's binary_logloss: 0.494308\n",
      "[340]\ttraining's binary_logloss: 0.494041\n",
      "[341]\ttraining's binary_logloss: 0.493844\n",
      "[342]\ttraining's binary_logloss: 0.493619\n",
      "[343]\ttraining's binary_logloss: 0.493385\n",
      "[344]\ttraining's binary_logloss: 0.493183\n",
      "[345]\ttraining's binary_logloss: 0.492986\n",
      "[346]\ttraining's binary_logloss: 0.492772\n",
      "[347]\ttraining's binary_logloss: 0.492548\n",
      "[348]\ttraining's binary_logloss: 0.492343\n",
      "[349]\ttraining's binary_logloss: 0.492134\n",
      "[350]\ttraining's binary_logloss: 0.491946\n",
      "[351]\ttraining's binary_logloss: 0.491652\n",
      "[352]\ttraining's binary_logloss: 0.491398\n",
      "[353]\ttraining's binary_logloss: 0.491139\n",
      "[354]\ttraining's binary_logloss: 0.490889\n",
      "[355]\ttraining's binary_logloss: 0.490621\n",
      "[356]\ttraining's binary_logloss: 0.490393\n",
      "[357]\ttraining's binary_logloss: 0.490135\n",
      "[358]\ttraining's binary_logloss: 0.489902\n",
      "[359]\ttraining's binary_logloss: 0.489683\n",
      "[360]\ttraining's binary_logloss: 0.489429\n",
      "[361]\ttraining's binary_logloss: 0.489163\n",
      "[362]\ttraining's binary_logloss: 0.48891\n",
      "[363]\ttraining's binary_logloss: 0.48865\n",
      "[364]\ttraining's binary_logloss: 0.488419\n",
      "[365]\ttraining's binary_logloss: 0.488145\n",
      "[366]\ttraining's binary_logloss: 0.487916\n",
      "[367]\ttraining's binary_logloss: 0.487697\n",
      "[368]\ttraining's binary_logloss: 0.487503\n",
      "[369]\ttraining's binary_logloss: 0.487304\n",
      "[370]\ttraining's binary_logloss: 0.487083\n",
      "[371]\ttraining's binary_logloss: 0.486866\n",
      "[372]\ttraining's binary_logloss: 0.486685\n",
      "[373]\ttraining's binary_logloss: 0.486496\n",
      "[374]\ttraining's binary_logloss: 0.486284\n",
      "[375]\ttraining's binary_logloss: 0.486078\n",
      "[376]\ttraining's binary_logloss: 0.485817\n",
      "[377]\ttraining's binary_logloss: 0.485598\n",
      "[378]\ttraining's binary_logloss: 0.485411\n",
      "[379]\ttraining's binary_logloss: 0.485195\n",
      "[380]\ttraining's binary_logloss: 0.484998\n",
      "[381]\ttraining's binary_logloss: 0.484776\n",
      "[382]\ttraining's binary_logloss: 0.484578\n",
      "[383]\ttraining's binary_logloss: 0.484387\n",
      "[384]\ttraining's binary_logloss: 0.484208\n",
      "[385]\ttraining's binary_logloss: 0.483991\n",
      "[386]\ttraining's binary_logloss: 0.483737\n",
      "[387]\ttraining's binary_logloss: 0.483514\n",
      "[388]\ttraining's binary_logloss: 0.483236\n",
      "[389]\ttraining's binary_logloss: 0.482984\n",
      "[390]\ttraining's binary_logloss: 0.482702\n",
      "[391]\ttraining's binary_logloss: 0.482431\n",
      "[392]\ttraining's binary_logloss: 0.48215\n",
      "[393]\ttraining's binary_logloss: 0.481898\n",
      "[394]\ttraining's binary_logloss: 0.481633\n",
      "[395]\ttraining's binary_logloss: 0.481399\n",
      "[396]\ttraining's binary_logloss: 0.481196\n",
      "[397]\ttraining's binary_logloss: 0.480993\n",
      "[398]\ttraining's binary_logloss: 0.480769\n",
      "[399]\ttraining's binary_logloss: 0.480564\n",
      "[400]\ttraining's binary_logloss: 0.480331\n",
      "[401]\ttraining's binary_logloss: 0.480058\n",
      "[402]\ttraining's binary_logloss: 0.479794\n",
      "[403]\ttraining's binary_logloss: 0.479533\n",
      "[404]\ttraining's binary_logloss: 0.479279\n",
      "[405]\ttraining's binary_logloss: 0.479026\n",
      "[406]\ttraining's binary_logloss: 0.478793\n",
      "[407]\ttraining's binary_logloss: 0.478548\n",
      "[408]\ttraining's binary_logloss: 0.47833\n",
      "[409]\ttraining's binary_logloss: 0.47808\n",
      "[410]\ttraining's binary_logloss: 0.477855\n",
      "[411]\ttraining's binary_logloss: 0.477625\n",
      "[412]\ttraining's binary_logloss: 0.477377\n",
      "[413]\ttraining's binary_logloss: 0.477157\n",
      "[414]\ttraining's binary_logloss: 0.476911\n",
      "[415]\ttraining's binary_logloss: 0.476709\n",
      "[416]\ttraining's binary_logloss: 0.476481\n",
      "[417]\ttraining's binary_logloss: 0.476248\n",
      "[418]\ttraining's binary_logloss: 0.476016\n",
      "[419]\ttraining's binary_logloss: 0.475794\n",
      "[420]\ttraining's binary_logloss: 0.47558\n",
      "[421]\ttraining's binary_logloss: 0.475397\n",
      "[422]\ttraining's binary_logloss: 0.475229\n",
      "[423]\ttraining's binary_logloss: 0.475054\n",
      "[424]\ttraining's binary_logloss: 0.47488\n",
      "[425]\ttraining's binary_logloss: 0.474668\n",
      "[426]\ttraining's binary_logloss: 0.474451\n",
      "[427]\ttraining's binary_logloss: 0.474238\n",
      "[428]\ttraining's binary_logloss: 0.474039\n",
      "[429]\ttraining's binary_logloss: 0.47381\n",
      "[430]\ttraining's binary_logloss: 0.473632\n",
      "[431]\ttraining's binary_logloss: 0.473369\n",
      "[432]\ttraining's binary_logloss: 0.473104\n",
      "[433]\ttraining's binary_logloss: 0.472838\n",
      "[434]\ttraining's binary_logloss: 0.472578\n",
      "[435]\ttraining's binary_logloss: 0.472277\n",
      "[436]\ttraining's binary_logloss: 0.472058\n",
      "[437]\ttraining's binary_logloss: 0.471858\n",
      "[438]\ttraining's binary_logloss: 0.471596\n",
      "[439]\ttraining's binary_logloss: 0.471388\n",
      "[440]\ttraining's binary_logloss: 0.471183\n",
      "[441]\ttraining's binary_logloss: 0.470908\n",
      "[442]\ttraining's binary_logloss: 0.470629\n",
      "[443]\ttraining's binary_logloss: 0.470363\n",
      "[444]\ttraining's binary_logloss: 0.47015\n",
      "[445]\ttraining's binary_logloss: 0.469886\n",
      "[446]\ttraining's binary_logloss: 0.46966\n",
      "[447]\ttraining's binary_logloss: 0.469401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[448]\ttraining's binary_logloss: 0.46918\n",
      "[449]\ttraining's binary_logloss: 0.468961\n",
      "[450]\ttraining's binary_logloss: 0.468692\n",
      "[451]\ttraining's binary_logloss: 0.468513\n",
      "[452]\ttraining's binary_logloss: 0.468268\n",
      "[453]\ttraining's binary_logloss: 0.468074\n",
      "[454]\ttraining's binary_logloss: 0.467839\n",
      "[455]\ttraining's binary_logloss: 0.467605\n",
      "[456]\ttraining's binary_logloss: 0.467389\n",
      "[457]\ttraining's binary_logloss: 0.46718\n",
      "[458]\ttraining's binary_logloss: 0.466988\n",
      "[459]\ttraining's binary_logloss: 0.466806\n",
      "[460]\ttraining's binary_logloss: 0.466613\n",
      "[461]\ttraining's binary_logloss: 0.466396\n",
      "[462]\ttraining's binary_logloss: 0.466177\n",
      "[463]\ttraining's binary_logloss: 0.465965\n",
      "[464]\ttraining's binary_logloss: 0.465747\n",
      "[465]\ttraining's binary_logloss: 0.465588\n",
      "[466]\ttraining's binary_logloss: 0.46534\n",
      "[467]\ttraining's binary_logloss: 0.465094\n",
      "[468]\ttraining's binary_logloss: 0.464873\n",
      "[469]\ttraining's binary_logloss: 0.464652\n",
      "[470]\ttraining's binary_logloss: 0.464421\n",
      "[471]\ttraining's binary_logloss: 0.464209\n",
      "[472]\ttraining's binary_logloss: 0.464\n",
      "[473]\ttraining's binary_logloss: 0.463815\n",
      "[474]\ttraining's binary_logloss: 0.463635\n",
      "[475]\ttraining's binary_logloss: 0.463434\n",
      "[476]\ttraining's binary_logloss: 0.463218\n",
      "[477]\ttraining's binary_logloss: 0.462977\n",
      "[478]\ttraining's binary_logloss: 0.462727\n",
      "[479]\ttraining's binary_logloss: 0.462498\n",
      "[480]\ttraining's binary_logloss: 0.462283\n",
      "[481]\ttraining's binary_logloss: 0.462057\n",
      "[482]\ttraining's binary_logloss: 0.461832\n",
      "[483]\ttraining's binary_logloss: 0.461611\n",
      "[484]\ttraining's binary_logloss: 0.461386\n",
      "[485]\ttraining's binary_logloss: 0.461174\n",
      "[486]\ttraining's binary_logloss: 0.460905\n",
      "[487]\ttraining's binary_logloss: 0.460648\n",
      "[488]\ttraining's binary_logloss: 0.460398\n",
      "[489]\ttraining's binary_logloss: 0.460125\n",
      "[490]\ttraining's binary_logloss: 0.45988\n",
      "[491]\ttraining's binary_logloss: 0.459617\n",
      "[492]\ttraining's binary_logloss: 0.459362\n",
      "[493]\ttraining's binary_logloss: 0.459114\n",
      "[494]\ttraining's binary_logloss: 0.458879\n",
      "[495]\ttraining's binary_logloss: 0.458664\n",
      "[496]\ttraining's binary_logloss: 0.458442\n",
      "[497]\ttraining's binary_logloss: 0.458246\n",
      "[498]\ttraining's binary_logloss: 0.458011\n",
      "[499]\ttraining's binary_logloss: 0.45778\n",
      "[500]\ttraining's binary_logloss: 0.457529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.617119\n",
      "[2]\ttraining's binary_logloss: 0.61557\n",
      "[3]\ttraining's binary_logloss: 0.614025\n",
      "[4]\ttraining's binary_logloss: 0.612549\n",
      "[5]\ttraining's binary_logloss: 0.611098\n",
      "[6]\ttraining's binary_logloss: 0.609723\n",
      "[7]\ttraining's binary_logloss: 0.608385\n",
      "[8]\ttraining's binary_logloss: 0.607103\n",
      "[9]\ttraining's binary_logloss: 0.605756\n",
      "[10]\ttraining's binary_logloss: 0.604542\n",
      "[11]\ttraining's binary_logloss: 0.603269\n",
      "[12]\ttraining's binary_logloss: 0.601948\n",
      "[13]\ttraining's binary_logloss: 0.600746\n",
      "[14]\ttraining's binary_logloss: 0.599576\n",
      "[15]\ttraining's binary_logloss: 0.598449\n",
      "[16]\ttraining's binary_logloss: 0.597377\n",
      "[17]\ttraining's binary_logloss: 0.596341\n",
      "[18]\ttraining's binary_logloss: 0.595333\n",
      "[19]\ttraining's binary_logloss: 0.594289\n",
      "[20]\ttraining's binary_logloss: 0.593222\n",
      "[21]\ttraining's binary_logloss: 0.592176\n",
      "[22]\ttraining's binary_logloss: 0.591197\n",
      "[23]\ttraining's binary_logloss: 0.590203\n",
      "[24]\ttraining's binary_logloss: 0.589268\n",
      "[25]\ttraining's binary_logloss: 0.588272\n",
      "[26]\ttraining's binary_logloss: 0.587401\n",
      "[27]\ttraining's binary_logloss: 0.586511\n",
      "[28]\ttraining's binary_logloss: 0.585645\n",
      "[29]\ttraining's binary_logloss: 0.584831\n",
      "[30]\ttraining's binary_logloss: 0.584056\n",
      "[31]\ttraining's binary_logloss: 0.583283\n",
      "[32]\ttraining's binary_logloss: 0.582528\n",
      "[33]\ttraining's binary_logloss: 0.581837\n",
      "[34]\ttraining's binary_logloss: 0.581106\n",
      "[35]\ttraining's binary_logloss: 0.580327\n",
      "[36]\ttraining's binary_logloss: 0.57963\n",
      "[37]\ttraining's binary_logloss: 0.579028\n",
      "[38]\ttraining's binary_logloss: 0.578373\n",
      "[39]\ttraining's binary_logloss: 0.577764\n",
      "[40]\ttraining's binary_logloss: 0.577143\n",
      "[41]\ttraining's binary_logloss: 0.576547\n",
      "[42]\ttraining's binary_logloss: 0.575976\n",
      "[43]\ttraining's binary_logloss: 0.575431\n",
      "[44]\ttraining's binary_logloss: 0.574875\n",
      "[45]\ttraining's binary_logloss: 0.574319\n",
      "[46]\ttraining's binary_logloss: 0.573753\n",
      "[47]\ttraining's binary_logloss: 0.573178\n",
      "[48]\ttraining's binary_logloss: 0.572646\n",
      "[49]\ttraining's binary_logloss: 0.572073\n",
      "[50]\ttraining's binary_logloss: 0.57155\n",
      "[51]\ttraining's binary_logloss: 0.571001\n",
      "[52]\ttraining's binary_logloss: 0.570477\n",
      "[53]\ttraining's binary_logloss: 0.569962\n",
      "[54]\ttraining's binary_logloss: 0.569469\n",
      "[55]\ttraining's binary_logloss: 0.569006\n",
      "[56]\ttraining's binary_logloss: 0.568613\n",
      "[57]\ttraining's binary_logloss: 0.56816\n",
      "[58]\ttraining's binary_logloss: 0.567727\n",
      "[59]\ttraining's binary_logloss: 0.567327\n",
      "[60]\ttraining's binary_logloss: 0.566936\n",
      "[61]\ttraining's binary_logloss: 0.566471\n",
      "[62]\ttraining's binary_logloss: 0.566033\n",
      "[63]\ttraining's binary_logloss: 0.565562\n",
      "[64]\ttraining's binary_logloss: 0.565118\n",
      "[65]\ttraining's binary_logloss: 0.564686\n",
      "[66]\ttraining's binary_logloss: 0.564288\n",
      "[67]\ttraining's binary_logloss: 0.563824\n",
      "[68]\ttraining's binary_logloss: 0.563377\n",
      "[69]\ttraining's binary_logloss: 0.562945\n",
      "[70]\ttraining's binary_logloss: 0.562507\n",
      "[71]\ttraining's binary_logloss: 0.562075\n",
      "[72]\ttraining's binary_logloss: 0.561778\n",
      "[73]\ttraining's binary_logloss: 0.56137\n",
      "[74]\ttraining's binary_logloss: 0.561067\n",
      "[75]\ttraining's binary_logloss: 0.560667\n",
      "[76]\ttraining's binary_logloss: 0.560268\n",
      "[77]\ttraining's binary_logloss: 0.559833\n",
      "[78]\ttraining's binary_logloss: 0.559517\n",
      "[79]\ttraining's binary_logloss: 0.559148\n",
      "[80]\ttraining's binary_logloss: 0.558771\n",
      "[81]\ttraining's binary_logloss: 0.5584\n",
      "[82]\ttraining's binary_logloss: 0.558043\n",
      "[83]\ttraining's binary_logloss: 0.557699\n",
      "[84]\ttraining's binary_logloss: 0.5574\n",
      "[85]\ttraining's binary_logloss: 0.557075\n",
      "[86]\ttraining's binary_logloss: 0.556777\n",
      "[87]\ttraining's binary_logloss: 0.556487\n",
      "[88]\ttraining's binary_logloss: 0.55619\n",
      "[89]\ttraining's binary_logloss: 0.555889\n",
      "[90]\ttraining's binary_logloss: 0.555606\n",
      "[91]\ttraining's binary_logloss: 0.555261\n",
      "[92]\ttraining's binary_logloss: 0.554951\n",
      "[93]\ttraining's binary_logloss: 0.554691\n",
      "[94]\ttraining's binary_logloss: 0.554422\n",
      "[95]\ttraining's binary_logloss: 0.55421\n",
      "[96]\ttraining's binary_logloss: 0.553973\n",
      "[97]\ttraining's binary_logloss: 0.553691\n",
      "[98]\ttraining's binary_logloss: 0.553419\n",
      "[99]\ttraining's binary_logloss: 0.553157\n",
      "[100]\ttraining's binary_logloss: 0.552897\n",
      "[101]\ttraining's binary_logloss: 0.55262\n",
      "[102]\ttraining's binary_logloss: 0.55236\n",
      "[103]\ttraining's binary_logloss: 0.552077\n",
      "[104]\ttraining's binary_logloss: 0.551844\n",
      "[105]\ttraining's binary_logloss: 0.551615\n",
      "[106]\ttraining's binary_logloss: 0.551363\n",
      "[107]\ttraining's binary_logloss: 0.551083\n",
      "[108]\ttraining's binary_logloss: 0.550791\n",
      "[109]\ttraining's binary_logloss: 0.550531\n",
      "[110]\ttraining's binary_logloss: 0.550294\n",
      "[111]\ttraining's binary_logloss: 0.550036\n",
      "[112]\ttraining's binary_logloss: 0.549755\n",
      "[113]\ttraining's binary_logloss: 0.549507\n",
      "[114]\ttraining's binary_logloss: 0.549308\n",
      "[115]\ttraining's binary_logloss: 0.549057\n",
      "[116]\ttraining's binary_logloss: 0.548815\n",
      "[117]\ttraining's binary_logloss: 0.548542\n",
      "[118]\ttraining's binary_logloss: 0.548286\n",
      "[119]\ttraining's binary_logloss: 0.548049\n",
      "[120]\ttraining's binary_logloss: 0.547794\n",
      "[121]\ttraining's binary_logloss: 0.547587\n",
      "[122]\ttraining's binary_logloss: 0.547384\n",
      "[123]\ttraining's binary_logloss: 0.54719\n",
      "[124]\ttraining's binary_logloss: 0.547002\n",
      "[125]\ttraining's binary_logloss: 0.546774\n",
      "[126]\ttraining's binary_logloss: 0.546521\n",
      "[127]\ttraining's binary_logloss: 0.546285\n",
      "[128]\ttraining's binary_logloss: 0.546062\n",
      "[129]\ttraining's binary_logloss: 0.545831\n",
      "[130]\ttraining's binary_logloss: 0.545609\n",
      "[131]\ttraining's binary_logloss: 0.545362\n",
      "[132]\ttraining's binary_logloss: 0.545111\n",
      "[133]\ttraining's binary_logloss: 0.544899\n",
      "[134]\ttraining's binary_logloss: 0.544656\n",
      "[135]\ttraining's binary_logloss: 0.544437\n",
      "[136]\ttraining's binary_logloss: 0.544169\n",
      "[137]\ttraining's binary_logloss: 0.543929\n",
      "[138]\ttraining's binary_logloss: 0.543699\n",
      "[139]\ttraining's binary_logloss: 0.543464\n",
      "[140]\ttraining's binary_logloss: 0.543272\n",
      "[141]\ttraining's binary_logloss: 0.543035\n",
      "[142]\ttraining's binary_logloss: 0.542754\n",
      "[143]\ttraining's binary_logloss: 0.54251\n",
      "[144]\ttraining's binary_logloss: 0.542267\n",
      "[145]\ttraining's binary_logloss: 0.542082\n",
      "[146]\ttraining's binary_logloss: 0.541874\n",
      "[147]\ttraining's binary_logloss: 0.541624\n",
      "[148]\ttraining's binary_logloss: 0.541388\n",
      "[149]\ttraining's binary_logloss: 0.54117\n",
      "[150]\ttraining's binary_logloss: 0.540904\n",
      "[151]\ttraining's binary_logloss: 0.540684\n",
      "[152]\ttraining's binary_logloss: 0.540492\n",
      "[153]\ttraining's binary_logloss: 0.540314\n",
      "[154]\ttraining's binary_logloss: 0.54013\n",
      "[155]\ttraining's binary_logloss: 0.53997\n",
      "[156]\ttraining's binary_logloss: 0.539752\n",
      "[157]\ttraining's binary_logloss: 0.539477\n",
      "[158]\ttraining's binary_logloss: 0.539222\n",
      "[159]\ttraining's binary_logloss: 0.538999\n",
      "[160]\ttraining's binary_logloss: 0.53877\n",
      "[161]\ttraining's binary_logloss: 0.538531\n",
      "[162]\ttraining's binary_logloss: 0.538325\n",
      "[163]\ttraining's binary_logloss: 0.538103\n",
      "[164]\ttraining's binary_logloss: 0.537899\n",
      "[165]\ttraining's binary_logloss: 0.537678\n",
      "[166]\ttraining's binary_logloss: 0.537421\n",
      "[167]\ttraining's binary_logloss: 0.537172\n",
      "[168]\ttraining's binary_logloss: 0.536895\n",
      "[169]\ttraining's binary_logloss: 0.536666\n",
      "[170]\ttraining's binary_logloss: 0.536446\n",
      "[171]\ttraining's binary_logloss: 0.536237\n",
      "[172]\ttraining's binary_logloss: 0.536015\n",
      "[173]\ttraining's binary_logloss: 0.53578\n",
      "[174]\ttraining's binary_logloss: 0.535558\n",
      "[175]\ttraining's binary_logloss: 0.535379\n",
      "[176]\ttraining's binary_logloss: 0.535126\n",
      "[177]\ttraining's binary_logloss: 0.534933\n",
      "[178]\ttraining's binary_logloss: 0.534743\n",
      "[179]\ttraining's binary_logloss: 0.534546\n",
      "[180]\ttraining's binary_logloss: 0.534313\n",
      "[181]\ttraining's binary_logloss: 0.534137\n",
      "[182]\ttraining's binary_logloss: 0.533932\n",
      "[183]\ttraining's binary_logloss: 0.533719\n",
      "[184]\ttraining's binary_logloss: 0.5335\n",
      "[185]\ttraining's binary_logloss: 0.533313\n",
      "[186]\ttraining's binary_logloss: 0.533093\n",
      "[187]\ttraining's binary_logloss: 0.532886\n",
      "[188]\ttraining's binary_logloss: 0.532684\n",
      "[189]\ttraining's binary_logloss: 0.532509\n",
      "[190]\ttraining's binary_logloss: 0.53228\n",
      "[191]\ttraining's binary_logloss: 0.532017\n",
      "[192]\ttraining's binary_logloss: 0.531751\n",
      "[193]\ttraining's binary_logloss: 0.53153\n",
      "[194]\ttraining's binary_logloss: 0.531282\n",
      "[195]\ttraining's binary_logloss: 0.531046\n",
      "[196]\ttraining's binary_logloss: 0.530818\n",
      "[197]\ttraining's binary_logloss: 0.530574\n",
      "[198]\ttraining's binary_logloss: 0.530365\n",
      "[199]\ttraining's binary_logloss: 0.530133\n",
      "[200]\ttraining's binary_logloss: 0.529934\n",
      "[201]\ttraining's binary_logloss: 0.529698\n",
      "[202]\ttraining's binary_logloss: 0.529453\n",
      "[203]\ttraining's binary_logloss: 0.529225\n",
      "[204]\ttraining's binary_logloss: 0.529017\n",
      "[205]\ttraining's binary_logloss: 0.528779\n",
      "[206]\ttraining's binary_logloss: 0.528559\n",
      "[207]\ttraining's binary_logloss: 0.528325\n",
      "[208]\ttraining's binary_logloss: 0.528104\n",
      "[209]\ttraining's binary_logloss: 0.527913\n",
      "[210]\ttraining's binary_logloss: 0.527727\n",
      "[211]\ttraining's binary_logloss: 0.527538\n",
      "[212]\ttraining's binary_logloss: 0.527343\n",
      "[213]\ttraining's binary_logloss: 0.527117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[214]\ttraining's binary_logloss: 0.526927\n",
      "[215]\ttraining's binary_logloss: 0.526693\n",
      "[216]\ttraining's binary_logloss: 0.526457\n",
      "[217]\ttraining's binary_logloss: 0.526227\n",
      "[218]\ttraining's binary_logloss: 0.526002\n",
      "[219]\ttraining's binary_logloss: 0.525748\n",
      "[220]\ttraining's binary_logloss: 0.525477\n",
      "[221]\ttraining's binary_logloss: 0.525254\n",
      "[222]\ttraining's binary_logloss: 0.525027\n",
      "[223]\ttraining's binary_logloss: 0.524769\n",
      "[224]\ttraining's binary_logloss: 0.524513\n",
      "[225]\ttraining's binary_logloss: 0.524267\n",
      "[226]\ttraining's binary_logloss: 0.524012\n",
      "[227]\ttraining's binary_logloss: 0.52378\n",
      "[228]\ttraining's binary_logloss: 0.523535\n",
      "[229]\ttraining's binary_logloss: 0.523295\n",
      "[230]\ttraining's binary_logloss: 0.523048\n",
      "[231]\ttraining's binary_logloss: 0.522786\n",
      "[232]\ttraining's binary_logloss: 0.522591\n",
      "[233]\ttraining's binary_logloss: 0.522374\n",
      "[234]\ttraining's binary_logloss: 0.522181\n",
      "[235]\ttraining's binary_logloss: 0.521996\n",
      "[236]\ttraining's binary_logloss: 0.52176\n",
      "[237]\ttraining's binary_logloss: 0.521519\n",
      "[238]\ttraining's binary_logloss: 0.521251\n",
      "[239]\ttraining's binary_logloss: 0.521032\n",
      "[240]\ttraining's binary_logloss: 0.520815\n",
      "[241]\ttraining's binary_logloss: 0.520571\n",
      "[242]\ttraining's binary_logloss: 0.520306\n",
      "[243]\ttraining's binary_logloss: 0.520074\n",
      "[244]\ttraining's binary_logloss: 0.519855\n",
      "[245]\ttraining's binary_logloss: 0.519607\n",
      "[246]\ttraining's binary_logloss: 0.519384\n",
      "[247]\ttraining's binary_logloss: 0.519134\n",
      "[248]\ttraining's binary_logloss: 0.518886\n",
      "[249]\ttraining's binary_logloss: 0.518629\n",
      "[250]\ttraining's binary_logloss: 0.51841\n",
      "[251]\ttraining's binary_logloss: 0.518192\n",
      "[252]\ttraining's binary_logloss: 0.517968\n",
      "[253]\ttraining's binary_logloss: 0.517744\n",
      "[254]\ttraining's binary_logloss: 0.517518\n",
      "[255]\ttraining's binary_logloss: 0.517296\n",
      "[256]\ttraining's binary_logloss: 0.517112\n",
      "[257]\ttraining's binary_logloss: 0.516928\n",
      "[258]\ttraining's binary_logloss: 0.516693\n",
      "[259]\ttraining's binary_logloss: 0.516459\n",
      "[260]\ttraining's binary_logloss: 0.516254\n",
      "[261]\ttraining's binary_logloss: 0.51605\n",
      "[262]\ttraining's binary_logloss: 0.515837\n",
      "[263]\ttraining's binary_logloss: 0.515617\n",
      "[264]\ttraining's binary_logloss: 0.515397\n",
      "[265]\ttraining's binary_logloss: 0.515166\n",
      "[266]\ttraining's binary_logloss: 0.514961\n",
      "[267]\ttraining's binary_logloss: 0.51477\n",
      "[268]\ttraining's binary_logloss: 0.514551\n",
      "[269]\ttraining's binary_logloss: 0.514358\n",
      "[270]\ttraining's binary_logloss: 0.514138\n",
      "[271]\ttraining's binary_logloss: 0.513864\n",
      "[272]\ttraining's binary_logloss: 0.513627\n",
      "[273]\ttraining's binary_logloss: 0.513375\n",
      "[274]\ttraining's binary_logloss: 0.513128\n",
      "[275]\ttraining's binary_logloss: 0.512895\n",
      "[276]\ttraining's binary_logloss: 0.512626\n",
      "[277]\ttraining's binary_logloss: 0.512364\n",
      "[278]\ttraining's binary_logloss: 0.512097\n",
      "[279]\ttraining's binary_logloss: 0.511851\n",
      "[280]\ttraining's binary_logloss: 0.511601\n",
      "[281]\ttraining's binary_logloss: 0.511389\n",
      "[282]\ttraining's binary_logloss: 0.511181\n",
      "[283]\ttraining's binary_logloss: 0.510941\n",
      "[284]\ttraining's binary_logloss: 0.510717\n",
      "[285]\ttraining's binary_logloss: 0.510517\n",
      "[286]\ttraining's binary_logloss: 0.510291\n",
      "[287]\ttraining's binary_logloss: 0.510067\n",
      "[288]\ttraining's binary_logloss: 0.509832\n",
      "[289]\ttraining's binary_logloss: 0.509597\n",
      "[290]\ttraining's binary_logloss: 0.509362\n",
      "[291]\ttraining's binary_logloss: 0.509117\n",
      "[292]\ttraining's binary_logloss: 0.508845\n",
      "[293]\ttraining's binary_logloss: 0.508638\n",
      "[294]\ttraining's binary_logloss: 0.508392\n",
      "[295]\ttraining's binary_logloss: 0.508146\n",
      "[296]\ttraining's binary_logloss: 0.507902\n",
      "[297]\ttraining's binary_logloss: 0.507652\n",
      "[298]\ttraining's binary_logloss: 0.507386\n",
      "[299]\ttraining's binary_logloss: 0.507132\n",
      "[300]\ttraining's binary_logloss: 0.506884\n",
      "[301]\ttraining's binary_logloss: 0.506648\n",
      "[302]\ttraining's binary_logloss: 0.506388\n",
      "[303]\ttraining's binary_logloss: 0.506092\n",
      "[304]\ttraining's binary_logloss: 0.505836\n",
      "[305]\ttraining's binary_logloss: 0.505581\n",
      "[306]\ttraining's binary_logloss: 0.50532\n",
      "[307]\ttraining's binary_logloss: 0.505096\n",
      "[308]\ttraining's binary_logloss: 0.504864\n",
      "[309]\ttraining's binary_logloss: 0.504646\n",
      "[310]\ttraining's binary_logloss: 0.504399\n",
      "[311]\ttraining's binary_logloss: 0.504184\n",
      "[312]\ttraining's binary_logloss: 0.503974\n",
      "[313]\ttraining's binary_logloss: 0.503744\n",
      "[314]\ttraining's binary_logloss: 0.503488\n",
      "[315]\ttraining's binary_logloss: 0.503244\n",
      "[316]\ttraining's binary_logloss: 0.502952\n",
      "[317]\ttraining's binary_logloss: 0.502664\n",
      "[318]\ttraining's binary_logloss: 0.502385\n",
      "[319]\ttraining's binary_logloss: 0.502112\n",
      "[320]\ttraining's binary_logloss: 0.501893\n",
      "[321]\ttraining's binary_logloss: 0.501645\n",
      "[322]\ttraining's binary_logloss: 0.501407\n",
      "[323]\ttraining's binary_logloss: 0.50117\n",
      "[324]\ttraining's binary_logloss: 0.500946\n",
      "[325]\ttraining's binary_logloss: 0.500719\n",
      "[326]\ttraining's binary_logloss: 0.500474\n",
      "[327]\ttraining's binary_logloss: 0.500263\n",
      "[328]\ttraining's binary_logloss: 0.500056\n",
      "[329]\ttraining's binary_logloss: 0.499831\n",
      "[330]\ttraining's binary_logloss: 0.49962\n",
      "[331]\ttraining's binary_logloss: 0.499369\n",
      "[332]\ttraining's binary_logloss: 0.499123\n",
      "[333]\ttraining's binary_logloss: 0.498886\n",
      "[334]\ttraining's binary_logloss: 0.498634\n",
      "[335]\ttraining's binary_logloss: 0.498419\n",
      "[336]\ttraining's binary_logloss: 0.498184\n",
      "[337]\ttraining's binary_logloss: 0.49794\n",
      "[338]\ttraining's binary_logloss: 0.497713\n",
      "[339]\ttraining's binary_logloss: 0.49747\n",
      "[340]\ttraining's binary_logloss: 0.497225\n",
      "[341]\ttraining's binary_logloss: 0.497025\n",
      "[342]\ttraining's binary_logloss: 0.496812\n",
      "[343]\ttraining's binary_logloss: 0.496557\n",
      "[344]\ttraining's binary_logloss: 0.496335\n",
      "[345]\ttraining's binary_logloss: 0.496072\n",
      "[346]\ttraining's binary_logloss: 0.495832\n",
      "[347]\ttraining's binary_logloss: 0.49558\n",
      "[348]\ttraining's binary_logloss: 0.495355\n",
      "[349]\ttraining's binary_logloss: 0.495108\n",
      "[350]\ttraining's binary_logloss: 0.494912\n",
      "[351]\ttraining's binary_logloss: 0.494659\n",
      "[352]\ttraining's binary_logloss: 0.494384\n",
      "[353]\ttraining's binary_logloss: 0.494113\n",
      "[354]\ttraining's binary_logloss: 0.49385\n",
      "[355]\ttraining's binary_logloss: 0.493584\n",
      "[356]\ttraining's binary_logloss: 0.493363\n",
      "[357]\ttraining's binary_logloss: 0.493129\n",
      "[358]\ttraining's binary_logloss: 0.492907\n",
      "[359]\ttraining's binary_logloss: 0.492648\n",
      "[360]\ttraining's binary_logloss: 0.4924\n",
      "[361]\ttraining's binary_logloss: 0.492152\n",
      "[362]\ttraining's binary_logloss: 0.491871\n",
      "[363]\ttraining's binary_logloss: 0.491625\n",
      "[364]\ttraining's binary_logloss: 0.49139\n",
      "[365]\ttraining's binary_logloss: 0.491141\n",
      "[366]\ttraining's binary_logloss: 0.490926\n",
      "[367]\ttraining's binary_logloss: 0.49071\n",
      "[368]\ttraining's binary_logloss: 0.490507\n",
      "[369]\ttraining's binary_logloss: 0.490319\n",
      "[370]\ttraining's binary_logloss: 0.490147\n",
      "[371]\ttraining's binary_logloss: 0.489917\n",
      "[372]\ttraining's binary_logloss: 0.489662\n",
      "[373]\ttraining's binary_logloss: 0.489408\n",
      "[374]\ttraining's binary_logloss: 0.489143\n",
      "[375]\ttraining's binary_logloss: 0.488923\n",
      "[376]\ttraining's binary_logloss: 0.488704\n",
      "[377]\ttraining's binary_logloss: 0.488488\n",
      "[378]\ttraining's binary_logloss: 0.488272\n",
      "[379]\ttraining's binary_logloss: 0.488011\n",
      "[380]\ttraining's binary_logloss: 0.487806\n",
      "[381]\ttraining's binary_logloss: 0.487548\n",
      "[382]\ttraining's binary_logloss: 0.487311\n",
      "[383]\ttraining's binary_logloss: 0.487066\n",
      "[384]\ttraining's binary_logloss: 0.486839\n",
      "[385]\ttraining's binary_logloss: 0.486593\n",
      "[386]\ttraining's binary_logloss: 0.486367\n",
      "[387]\ttraining's binary_logloss: 0.486142\n",
      "[388]\ttraining's binary_logloss: 0.485905\n",
      "[389]\ttraining's binary_logloss: 0.485705\n",
      "[390]\ttraining's binary_logloss: 0.485474\n",
      "[391]\ttraining's binary_logloss: 0.485244\n",
      "[392]\ttraining's binary_logloss: 0.485011\n",
      "[393]\ttraining's binary_logloss: 0.484783\n",
      "[394]\ttraining's binary_logloss: 0.484519\n",
      "[395]\ttraining's binary_logloss: 0.484286\n",
      "[396]\ttraining's binary_logloss: 0.484029\n",
      "[397]\ttraining's binary_logloss: 0.483794\n",
      "[398]\ttraining's binary_logloss: 0.483548\n",
      "[399]\ttraining's binary_logloss: 0.483317\n",
      "[400]\ttraining's binary_logloss: 0.483083\n",
      "[401]\ttraining's binary_logloss: 0.482838\n",
      "[402]\ttraining's binary_logloss: 0.482625\n",
      "[403]\ttraining's binary_logloss: 0.482385\n",
      "[404]\ttraining's binary_logloss: 0.482139\n",
      "[405]\ttraining's binary_logloss: 0.481903\n",
      "[406]\ttraining's binary_logloss: 0.481693\n",
      "[407]\ttraining's binary_logloss: 0.481459\n",
      "[408]\ttraining's binary_logloss: 0.481244\n",
      "[409]\ttraining's binary_logloss: 0.481043\n",
      "[410]\ttraining's binary_logloss: 0.480804\n",
      "[411]\ttraining's binary_logloss: 0.480563\n",
      "[412]\ttraining's binary_logloss: 0.480337\n",
      "[413]\ttraining's binary_logloss: 0.480111\n",
      "[414]\ttraining's binary_logloss: 0.479908\n",
      "[415]\ttraining's binary_logloss: 0.479682\n",
      "[416]\ttraining's binary_logloss: 0.479499\n",
      "[417]\ttraining's binary_logloss: 0.479249\n",
      "[418]\ttraining's binary_logloss: 0.479016\n",
      "[419]\ttraining's binary_logloss: 0.4788\n",
      "[420]\ttraining's binary_logloss: 0.478576\n",
      "[421]\ttraining's binary_logloss: 0.478358\n",
      "[422]\ttraining's binary_logloss: 0.478134\n",
      "[423]\ttraining's binary_logloss: 0.477945\n",
      "[424]\ttraining's binary_logloss: 0.477733\n",
      "[425]\ttraining's binary_logloss: 0.477523\n",
      "[426]\ttraining's binary_logloss: 0.477326\n",
      "[427]\ttraining's binary_logloss: 0.477118\n",
      "[428]\ttraining's binary_logloss: 0.476914\n",
      "[429]\ttraining's binary_logloss: 0.476695\n",
      "[430]\ttraining's binary_logloss: 0.476488\n",
      "[431]\ttraining's binary_logloss: 0.47625\n",
      "[432]\ttraining's binary_logloss: 0.476001\n",
      "[433]\ttraining's binary_logloss: 0.47576\n",
      "[434]\ttraining's binary_logloss: 0.475559\n",
      "[435]\ttraining's binary_logloss: 0.475368\n",
      "[436]\ttraining's binary_logloss: 0.475141\n",
      "[437]\ttraining's binary_logloss: 0.474941\n",
      "[438]\ttraining's binary_logloss: 0.474734\n",
      "[439]\ttraining's binary_logloss: 0.474528\n",
      "[440]\ttraining's binary_logloss: 0.474322\n",
      "[441]\ttraining's binary_logloss: 0.474075\n",
      "[442]\ttraining's binary_logloss: 0.473846\n",
      "[443]\ttraining's binary_logloss: 0.47361\n",
      "[444]\ttraining's binary_logloss: 0.473378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[445]\ttraining's binary_logloss: 0.473153\n",
      "[446]\ttraining's binary_logloss: 0.472964\n",
      "[447]\ttraining's binary_logloss: 0.472759\n",
      "[448]\ttraining's binary_logloss: 0.472569\n",
      "[449]\ttraining's binary_logloss: 0.472375\n",
      "[450]\ttraining's binary_logloss: 0.472183\n",
      "[451]\ttraining's binary_logloss: 0.471955\n",
      "[452]\ttraining's binary_logloss: 0.47173\n",
      "[453]\ttraining's binary_logloss: 0.471504\n",
      "[454]\ttraining's binary_logloss: 0.471282\n",
      "[455]\ttraining's binary_logloss: 0.47109\n",
      "[456]\ttraining's binary_logloss: 0.47083\n",
      "[457]\ttraining's binary_logloss: 0.470582\n",
      "[458]\ttraining's binary_logloss: 0.470313\n",
      "[459]\ttraining's binary_logloss: 0.470057\n",
      "[460]\ttraining's binary_logloss: 0.469805\n",
      "[461]\ttraining's binary_logloss: 0.469574\n",
      "[462]\ttraining's binary_logloss: 0.469356\n",
      "[463]\ttraining's binary_logloss: 0.469141\n",
      "[464]\ttraining's binary_logloss: 0.468879\n",
      "[465]\ttraining's binary_logloss: 0.468647\n",
      "[466]\ttraining's binary_logloss: 0.468422\n",
      "[467]\ttraining's binary_logloss: 0.468154\n",
      "[468]\ttraining's binary_logloss: 0.46789\n",
      "[469]\ttraining's binary_logloss: 0.467621\n",
      "[470]\ttraining's binary_logloss: 0.467342\n",
      "[471]\ttraining's binary_logloss: 0.46713\n",
      "[472]\ttraining's binary_logloss: 0.466909\n",
      "[473]\ttraining's binary_logloss: 0.466688\n",
      "[474]\ttraining's binary_logloss: 0.466499\n",
      "[475]\ttraining's binary_logloss: 0.466315\n",
      "[476]\ttraining's binary_logloss: 0.466092\n",
      "[477]\ttraining's binary_logloss: 0.465859\n",
      "[478]\ttraining's binary_logloss: 0.465644\n",
      "[479]\ttraining's binary_logloss: 0.465373\n",
      "[480]\ttraining's binary_logloss: 0.465154\n",
      "[481]\ttraining's binary_logloss: 0.464938\n",
      "[482]\ttraining's binary_logloss: 0.464732\n",
      "[483]\ttraining's binary_logloss: 0.464518\n",
      "[484]\ttraining's binary_logloss: 0.464264\n",
      "[485]\ttraining's binary_logloss: 0.464044\n",
      "[486]\ttraining's binary_logloss: 0.463838\n",
      "[487]\ttraining's binary_logloss: 0.463648\n",
      "[488]\ttraining's binary_logloss: 0.463465\n",
      "[489]\ttraining's binary_logloss: 0.46326\n",
      "[490]\ttraining's binary_logloss: 0.463038\n",
      "[491]\ttraining's binary_logloss: 0.462783\n",
      "[492]\ttraining's binary_logloss: 0.462475\n",
      "[493]\ttraining's binary_logloss: 0.462207\n",
      "[494]\ttraining's binary_logloss: 0.461932\n",
      "[495]\ttraining's binary_logloss: 0.461681\n",
      "[496]\ttraining's binary_logloss: 0.461416\n",
      "[497]\ttraining's binary_logloss: 0.461158\n",
      "[498]\ttraining's binary_logloss: 0.460901\n",
      "[499]\ttraining's binary_logloss: 0.460624\n",
      "[500]\ttraining's binary_logloss: 0.460383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613325\n",
      "[2]\ttraining's binary_logloss: 0.611776\n",
      "[3]\ttraining's binary_logloss: 0.610153\n",
      "[4]\ttraining's binary_logloss: 0.608613\n",
      "[5]\ttraining's binary_logloss: 0.607159\n",
      "[6]\ttraining's binary_logloss: 0.605685\n",
      "[7]\ttraining's binary_logloss: 0.604243\n",
      "[8]\ttraining's binary_logloss: 0.602854\n",
      "[9]\ttraining's binary_logloss: 0.601508\n",
      "[10]\ttraining's binary_logloss: 0.600217\n",
      "[11]\ttraining's binary_logloss: 0.599058\n",
      "[12]\ttraining's binary_logloss: 0.597898\n",
      "[13]\ttraining's binary_logloss: 0.596744\n",
      "[14]\ttraining's binary_logloss: 0.595598\n",
      "[15]\ttraining's binary_logloss: 0.594471\n",
      "[16]\ttraining's binary_logloss: 0.593358\n",
      "[17]\ttraining's binary_logloss: 0.592353\n",
      "[18]\ttraining's binary_logloss: 0.591329\n",
      "[19]\ttraining's binary_logloss: 0.590317\n",
      "[20]\ttraining's binary_logloss: 0.589346\n",
      "[21]\ttraining's binary_logloss: 0.588348\n",
      "[22]\ttraining's binary_logloss: 0.587354\n",
      "[23]\ttraining's binary_logloss: 0.586369\n",
      "[24]\ttraining's binary_logloss: 0.585432\n",
      "[25]\ttraining's binary_logloss: 0.584606\n",
      "[26]\ttraining's binary_logloss: 0.583716\n",
      "[27]\ttraining's binary_logloss: 0.582855\n",
      "[28]\ttraining's binary_logloss: 0.581992\n",
      "[29]\ttraining's binary_logloss: 0.581167\n",
      "[30]\ttraining's binary_logloss: 0.580378\n",
      "[31]\ttraining's binary_logloss: 0.579632\n",
      "[32]\ttraining's binary_logloss: 0.578997\n",
      "[33]\ttraining's binary_logloss: 0.578269\n",
      "[34]\ttraining's binary_logloss: 0.577614\n",
      "[35]\ttraining's binary_logloss: 0.576929\n",
      "[36]\ttraining's binary_logloss: 0.57616\n",
      "[37]\ttraining's binary_logloss: 0.575423\n",
      "[38]\ttraining's binary_logloss: 0.574802\n",
      "[39]\ttraining's binary_logloss: 0.574147\n",
      "[40]\ttraining's binary_logloss: 0.573444\n",
      "[41]\ttraining's binary_logloss: 0.572781\n",
      "[42]\ttraining's binary_logloss: 0.572117\n",
      "[43]\ttraining's binary_logloss: 0.571642\n",
      "[44]\ttraining's binary_logloss: 0.571026\n",
      "[45]\ttraining's binary_logloss: 0.570438\n",
      "[46]\ttraining's binary_logloss: 0.569823\n",
      "[47]\ttraining's binary_logloss: 0.569269\n",
      "[48]\ttraining's binary_logloss: 0.568713\n",
      "[49]\ttraining's binary_logloss: 0.568185\n",
      "[50]\ttraining's binary_logloss: 0.567684\n",
      "[51]\ttraining's binary_logloss: 0.567135\n",
      "[52]\ttraining's binary_logloss: 0.566657\n",
      "[53]\ttraining's binary_logloss: 0.566152\n",
      "[54]\ttraining's binary_logloss: 0.565698\n",
      "[55]\ttraining's binary_logloss: 0.565195\n",
      "[56]\ttraining's binary_logloss: 0.564755\n",
      "[57]\ttraining's binary_logloss: 0.564333\n",
      "[58]\ttraining's binary_logloss: 0.563865\n",
      "[59]\ttraining's binary_logloss: 0.563408\n",
      "[60]\ttraining's binary_logloss: 0.562954\n",
      "[61]\ttraining's binary_logloss: 0.562506\n",
      "[62]\ttraining's binary_logloss: 0.562023\n",
      "[63]\ttraining's binary_logloss: 0.561523\n",
      "[64]\ttraining's binary_logloss: 0.561049\n",
      "[65]\ttraining's binary_logloss: 0.560664\n",
      "[66]\ttraining's binary_logloss: 0.560253\n",
      "[67]\ttraining's binary_logloss: 0.559794\n",
      "[68]\ttraining's binary_logloss: 0.559351\n",
      "[69]\ttraining's binary_logloss: 0.558944\n",
      "[70]\ttraining's binary_logloss: 0.558517\n",
      "[71]\ttraining's binary_logloss: 0.558127\n",
      "[72]\ttraining's binary_logloss: 0.557723\n",
      "[73]\ttraining's binary_logloss: 0.557376\n",
      "[74]\ttraining's binary_logloss: 0.556995\n",
      "[75]\ttraining's binary_logloss: 0.556592\n",
      "[76]\ttraining's binary_logloss: 0.556279\n",
      "[77]\ttraining's binary_logloss: 0.555989\n",
      "[78]\ttraining's binary_logloss: 0.555711\n",
      "[79]\ttraining's binary_logloss: 0.555421\n",
      "[80]\ttraining's binary_logloss: 0.555159\n",
      "[81]\ttraining's binary_logloss: 0.55487\n",
      "[82]\ttraining's binary_logloss: 0.554567\n",
      "[83]\ttraining's binary_logloss: 0.554237\n",
      "[84]\ttraining's binary_logloss: 0.553959\n",
      "[85]\ttraining's binary_logloss: 0.553658\n",
      "[86]\ttraining's binary_logloss: 0.553375\n",
      "[87]\ttraining's binary_logloss: 0.553112\n",
      "[88]\ttraining's binary_logloss: 0.552882\n",
      "[89]\ttraining's binary_logloss: 0.552634\n",
      "[90]\ttraining's binary_logloss: 0.552357\n",
      "[91]\ttraining's binary_logloss: 0.552055\n",
      "[92]\ttraining's binary_logloss: 0.551766\n",
      "[93]\ttraining's binary_logloss: 0.551469\n",
      "[94]\ttraining's binary_logloss: 0.551151\n",
      "[95]\ttraining's binary_logloss: 0.550906\n",
      "[96]\ttraining's binary_logloss: 0.550678\n",
      "[97]\ttraining's binary_logloss: 0.550424\n",
      "[98]\ttraining's binary_logloss: 0.55019\n",
      "[99]\ttraining's binary_logloss: 0.549917\n",
      "[100]\ttraining's binary_logloss: 0.549682\n",
      "[101]\ttraining's binary_logloss: 0.549393\n",
      "[102]\ttraining's binary_logloss: 0.549111\n",
      "[103]\ttraining's binary_logloss: 0.548863\n",
      "[104]\ttraining's binary_logloss: 0.548598\n",
      "[105]\ttraining's binary_logloss: 0.548327\n",
      "[106]\ttraining's binary_logloss: 0.548041\n",
      "[107]\ttraining's binary_logloss: 0.547746\n",
      "[108]\ttraining's binary_logloss: 0.547504\n",
      "[109]\ttraining's binary_logloss: 0.547279\n",
      "[110]\ttraining's binary_logloss: 0.547028\n",
      "[111]\ttraining's binary_logloss: 0.546767\n",
      "[112]\ttraining's binary_logloss: 0.546547\n",
      "[113]\ttraining's binary_logloss: 0.54631\n",
      "[114]\ttraining's binary_logloss: 0.546064\n",
      "[115]\ttraining's binary_logloss: 0.545815\n",
      "[116]\ttraining's binary_logloss: 0.545579\n",
      "[117]\ttraining's binary_logloss: 0.545369\n",
      "[118]\ttraining's binary_logloss: 0.545112\n",
      "[119]\ttraining's binary_logloss: 0.544934\n",
      "[120]\ttraining's binary_logloss: 0.544708\n",
      "[121]\ttraining's binary_logloss: 0.544452\n",
      "[122]\ttraining's binary_logloss: 0.544212\n",
      "[123]\ttraining's binary_logloss: 0.543999\n",
      "[124]\ttraining's binary_logloss: 0.543743\n",
      "[125]\ttraining's binary_logloss: 0.543518\n",
      "[126]\ttraining's binary_logloss: 0.54324\n",
      "[127]\ttraining's binary_logloss: 0.542971\n",
      "[128]\ttraining's binary_logloss: 0.542748\n",
      "[129]\ttraining's binary_logloss: 0.542529\n",
      "[130]\ttraining's binary_logloss: 0.542304\n",
      "[131]\ttraining's binary_logloss: 0.542138\n",
      "[132]\ttraining's binary_logloss: 0.541897\n",
      "[133]\ttraining's binary_logloss: 0.541705\n",
      "[134]\ttraining's binary_logloss: 0.54147\n",
      "[135]\ttraining's binary_logloss: 0.541304\n",
      "[136]\ttraining's binary_logloss: 0.541072\n",
      "[137]\ttraining's binary_logloss: 0.540866\n",
      "[138]\ttraining's binary_logloss: 0.540643\n",
      "[139]\ttraining's binary_logloss: 0.540453\n",
      "[140]\ttraining's binary_logloss: 0.540264\n",
      "[141]\ttraining's binary_logloss: 0.540057\n",
      "[142]\ttraining's binary_logloss: 0.539833\n",
      "[143]\ttraining's binary_logloss: 0.539567\n",
      "[144]\ttraining's binary_logloss: 0.539352\n",
      "[145]\ttraining's binary_logloss: 0.539141\n",
      "[146]\ttraining's binary_logloss: 0.538871\n",
      "[147]\ttraining's binary_logloss: 0.538649\n",
      "[148]\ttraining's binary_logloss: 0.538419\n",
      "[149]\ttraining's binary_logloss: 0.538238\n",
      "[150]\ttraining's binary_logloss: 0.537972\n",
      "[151]\ttraining's binary_logloss: 0.5378\n",
      "[152]\ttraining's binary_logloss: 0.537602\n",
      "[153]\ttraining's binary_logloss: 0.537434\n",
      "[154]\ttraining's binary_logloss: 0.537223\n",
      "[155]\ttraining's binary_logloss: 0.537034\n",
      "[156]\ttraining's binary_logloss: 0.536829\n",
      "[157]\ttraining's binary_logloss: 0.536614\n",
      "[158]\ttraining's binary_logloss: 0.536413\n",
      "[159]\ttraining's binary_logloss: 0.536184\n",
      "[160]\ttraining's binary_logloss: 0.535996\n",
      "[161]\ttraining's binary_logloss: 0.535803\n",
      "[162]\ttraining's binary_logloss: 0.535548\n",
      "[163]\ttraining's binary_logloss: 0.535349\n",
      "[164]\ttraining's binary_logloss: 0.535173\n",
      "[165]\ttraining's binary_logloss: 0.534965\n",
      "[166]\ttraining's binary_logloss: 0.534713\n",
      "[167]\ttraining's binary_logloss: 0.534468\n",
      "[168]\ttraining's binary_logloss: 0.534204\n",
      "[169]\ttraining's binary_logloss: 0.533955\n",
      "[170]\ttraining's binary_logloss: 0.533706\n",
      "[171]\ttraining's binary_logloss: 0.53352\n",
      "[172]\ttraining's binary_logloss: 0.533277\n",
      "[173]\ttraining's binary_logloss: 0.533074\n",
      "[174]\ttraining's binary_logloss: 0.532874\n",
      "[175]\ttraining's binary_logloss: 0.532671\n",
      "[176]\ttraining's binary_logloss: 0.532465\n",
      "[177]\ttraining's binary_logloss: 0.53226\n",
      "[178]\ttraining's binary_logloss: 0.532042\n",
      "[179]\ttraining's binary_logloss: 0.531841\n",
      "[180]\ttraining's binary_logloss: 0.531627\n",
      "[181]\ttraining's binary_logloss: 0.531418\n",
      "[182]\ttraining's binary_logloss: 0.531239\n",
      "[183]\ttraining's binary_logloss: 0.531063\n",
      "[184]\ttraining's binary_logloss: 0.530863\n",
      "[185]\ttraining's binary_logloss: 0.530671\n",
      "[186]\ttraining's binary_logloss: 0.53048\n",
      "[187]\ttraining's binary_logloss: 0.530296\n",
      "[188]\ttraining's binary_logloss: 0.530106\n",
      "[189]\ttraining's binary_logloss: 0.529929\n",
      "[190]\ttraining's binary_logloss: 0.529737\n",
      "[191]\ttraining's binary_logloss: 0.52952\n",
      "[192]\ttraining's binary_logloss: 0.529316\n",
      "[193]\ttraining's binary_logloss: 0.529112\n",
      "[194]\ttraining's binary_logloss: 0.528896\n",
      "[195]\ttraining's binary_logloss: 0.528695\n",
      "[196]\ttraining's binary_logloss: 0.528479\n",
      "[197]\ttraining's binary_logloss: 0.528285\n",
      "[198]\ttraining's binary_logloss: 0.528079\n",
      "[199]\ttraining's binary_logloss: 0.527874\n",
      "[200]\ttraining's binary_logloss: 0.527663\n",
      "[201]\ttraining's binary_logloss: 0.527456\n",
      "[202]\ttraining's binary_logloss: 0.527262\n",
      "[203]\ttraining's binary_logloss: 0.527082\n",
      "[204]\ttraining's binary_logloss: 0.526894\n",
      "[205]\ttraining's binary_logloss: 0.526696\n",
      "[206]\ttraining's binary_logloss: 0.526491\n",
      "[207]\ttraining's binary_logloss: 0.526324\n",
      "[208]\ttraining's binary_logloss: 0.526122\n",
      "[209]\ttraining's binary_logloss: 0.525891\n",
      "[210]\ttraining's binary_logloss: 0.525715\n",
      "[211]\ttraining's binary_logloss: 0.525499\n",
      "[212]\ttraining's binary_logloss: 0.525258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[213]\ttraining's binary_logloss: 0.525057\n",
      "[214]\ttraining's binary_logloss: 0.524834\n",
      "[215]\ttraining's binary_logloss: 0.524622\n",
      "[216]\ttraining's binary_logloss: 0.52439\n",
      "[217]\ttraining's binary_logloss: 0.524176\n",
      "[218]\ttraining's binary_logloss: 0.523922\n",
      "[219]\ttraining's binary_logloss: 0.523686\n",
      "[220]\ttraining's binary_logloss: 0.523446\n",
      "[221]\ttraining's binary_logloss: 0.523236\n",
      "[222]\ttraining's binary_logloss: 0.523015\n",
      "[223]\ttraining's binary_logloss: 0.522783\n",
      "[224]\ttraining's binary_logloss: 0.52253\n",
      "[225]\ttraining's binary_logloss: 0.522325\n",
      "[226]\ttraining's binary_logloss: 0.522097\n",
      "[227]\ttraining's binary_logloss: 0.52187\n",
      "[228]\ttraining's binary_logloss: 0.521644\n",
      "[229]\ttraining's binary_logloss: 0.521401\n",
      "[230]\ttraining's binary_logloss: 0.52117\n",
      "[231]\ttraining's binary_logloss: 0.520929\n",
      "[232]\ttraining's binary_logloss: 0.520655\n",
      "[233]\ttraining's binary_logloss: 0.520425\n",
      "[234]\ttraining's binary_logloss: 0.520182\n",
      "[235]\ttraining's binary_logloss: 0.519924\n",
      "[236]\ttraining's binary_logloss: 0.519709\n",
      "[237]\ttraining's binary_logloss: 0.519489\n",
      "[238]\ttraining's binary_logloss: 0.519247\n",
      "[239]\ttraining's binary_logloss: 0.519035\n",
      "[240]\ttraining's binary_logloss: 0.51883\n",
      "[241]\ttraining's binary_logloss: 0.518605\n",
      "[242]\ttraining's binary_logloss: 0.51838\n",
      "[243]\ttraining's binary_logloss: 0.518179\n",
      "[244]\ttraining's binary_logloss: 0.517981\n",
      "[245]\ttraining's binary_logloss: 0.517795\n",
      "[246]\ttraining's binary_logloss: 0.517554\n",
      "[247]\ttraining's binary_logloss: 0.517298\n",
      "[248]\ttraining's binary_logloss: 0.517059\n",
      "[249]\ttraining's binary_logloss: 0.516823\n",
      "[250]\ttraining's binary_logloss: 0.516542\n",
      "[251]\ttraining's binary_logloss: 0.516295\n",
      "[252]\ttraining's binary_logloss: 0.51606\n",
      "[253]\ttraining's binary_logloss: 0.515808\n",
      "[254]\ttraining's binary_logloss: 0.515562\n",
      "[255]\ttraining's binary_logloss: 0.515337\n",
      "[256]\ttraining's binary_logloss: 0.515092\n",
      "[257]\ttraining's binary_logloss: 0.51487\n",
      "[258]\ttraining's binary_logloss: 0.514622\n",
      "[259]\ttraining's binary_logloss: 0.514342\n",
      "[260]\ttraining's binary_logloss: 0.514098\n",
      "[261]\ttraining's binary_logloss: 0.513864\n",
      "[262]\ttraining's binary_logloss: 0.513602\n",
      "[263]\ttraining's binary_logloss: 0.513374\n",
      "[264]\ttraining's binary_logloss: 0.513137\n",
      "[265]\ttraining's binary_logloss: 0.512908\n",
      "[266]\ttraining's binary_logloss: 0.512675\n",
      "[267]\ttraining's binary_logloss: 0.51248\n",
      "[268]\ttraining's binary_logloss: 0.512294\n",
      "[269]\ttraining's binary_logloss: 0.5121\n",
      "[270]\ttraining's binary_logloss: 0.511886\n",
      "[271]\ttraining's binary_logloss: 0.511643\n",
      "[272]\ttraining's binary_logloss: 0.511416\n",
      "[273]\ttraining's binary_logloss: 0.511196\n",
      "[274]\ttraining's binary_logloss: 0.510955\n",
      "[275]\ttraining's binary_logloss: 0.510706\n",
      "[276]\ttraining's binary_logloss: 0.510436\n",
      "[277]\ttraining's binary_logloss: 0.510208\n",
      "[278]\ttraining's binary_logloss: 0.50995\n",
      "[279]\ttraining's binary_logloss: 0.509691\n",
      "[280]\ttraining's binary_logloss: 0.509434\n",
      "[281]\ttraining's binary_logloss: 0.509221\n",
      "[282]\ttraining's binary_logloss: 0.508983\n",
      "[283]\ttraining's binary_logloss: 0.508766\n",
      "[284]\ttraining's binary_logloss: 0.508532\n",
      "[285]\ttraining's binary_logloss: 0.508309\n",
      "[286]\ttraining's binary_logloss: 0.508037\n",
      "[287]\ttraining's binary_logloss: 0.50775\n",
      "[288]\ttraining's binary_logloss: 0.507495\n",
      "[289]\ttraining's binary_logloss: 0.507224\n",
      "[290]\ttraining's binary_logloss: 0.50697\n",
      "[291]\ttraining's binary_logloss: 0.506733\n",
      "[292]\ttraining's binary_logloss: 0.506498\n",
      "[293]\ttraining's binary_logloss: 0.506289\n",
      "[294]\ttraining's binary_logloss: 0.50612\n",
      "[295]\ttraining's binary_logloss: 0.505909\n",
      "[296]\ttraining's binary_logloss: 0.505657\n",
      "[297]\ttraining's binary_logloss: 0.505448\n",
      "[298]\ttraining's binary_logloss: 0.505227\n",
      "[299]\ttraining's binary_logloss: 0.504974\n",
      "[300]\ttraining's binary_logloss: 0.504779\n",
      "[301]\ttraining's binary_logloss: 0.504521\n",
      "[302]\ttraining's binary_logloss: 0.504272\n",
      "[303]\ttraining's binary_logloss: 0.50403\n",
      "[304]\ttraining's binary_logloss: 0.503786\n",
      "[305]\ttraining's binary_logloss: 0.503569\n",
      "[306]\ttraining's binary_logloss: 0.503338\n",
      "[307]\ttraining's binary_logloss: 0.503116\n",
      "[308]\ttraining's binary_logloss: 0.50287\n",
      "[309]\ttraining's binary_logloss: 0.502668\n",
      "[310]\ttraining's binary_logloss: 0.502409\n",
      "[311]\ttraining's binary_logloss: 0.502169\n",
      "[312]\ttraining's binary_logloss: 0.501917\n",
      "[313]\ttraining's binary_logloss: 0.501684\n",
      "[314]\ttraining's binary_logloss: 0.501455\n",
      "[315]\ttraining's binary_logloss: 0.501217\n",
      "[316]\ttraining's binary_logloss: 0.501004\n",
      "[317]\ttraining's binary_logloss: 0.500783\n",
      "[318]\ttraining's binary_logloss: 0.500522\n",
      "[319]\ttraining's binary_logloss: 0.500312\n",
      "[320]\ttraining's binary_logloss: 0.500113\n",
      "[321]\ttraining's binary_logloss: 0.499929\n",
      "[322]\ttraining's binary_logloss: 0.499737\n",
      "[323]\ttraining's binary_logloss: 0.499541\n",
      "[324]\ttraining's binary_logloss: 0.49936\n",
      "[325]\ttraining's binary_logloss: 0.499185\n",
      "[326]\ttraining's binary_logloss: 0.498968\n",
      "[327]\ttraining's binary_logloss: 0.498751\n",
      "[328]\ttraining's binary_logloss: 0.498528\n",
      "[329]\ttraining's binary_logloss: 0.498323\n",
      "[330]\ttraining's binary_logloss: 0.498131\n",
      "[331]\ttraining's binary_logloss: 0.49787\n",
      "[332]\ttraining's binary_logloss: 0.49761\n",
      "[333]\ttraining's binary_logloss: 0.497375\n",
      "[334]\ttraining's binary_logloss: 0.497135\n",
      "[335]\ttraining's binary_logloss: 0.49687\n",
      "[336]\ttraining's binary_logloss: 0.496624\n",
      "[337]\ttraining's binary_logloss: 0.496365\n",
      "[338]\ttraining's binary_logloss: 0.496136\n",
      "[339]\ttraining's binary_logloss: 0.495878\n",
      "[340]\ttraining's binary_logloss: 0.495646\n",
      "[341]\ttraining's binary_logloss: 0.495394\n",
      "[342]\ttraining's binary_logloss: 0.495145\n",
      "[343]\ttraining's binary_logloss: 0.494924\n",
      "[344]\ttraining's binary_logloss: 0.494658\n",
      "[345]\ttraining's binary_logloss: 0.494418\n",
      "[346]\ttraining's binary_logloss: 0.494241\n",
      "[347]\ttraining's binary_logloss: 0.494009\n",
      "[348]\ttraining's binary_logloss: 0.493786\n",
      "[349]\ttraining's binary_logloss: 0.493596\n",
      "[350]\ttraining's binary_logloss: 0.493402\n",
      "[351]\ttraining's binary_logloss: 0.493142\n",
      "[352]\ttraining's binary_logloss: 0.49291\n",
      "[353]\ttraining's binary_logloss: 0.492655\n",
      "[354]\ttraining's binary_logloss: 0.492393\n",
      "[355]\ttraining's binary_logloss: 0.49214\n",
      "[356]\ttraining's binary_logloss: 0.491915\n",
      "[357]\ttraining's binary_logloss: 0.491691\n",
      "[358]\ttraining's binary_logloss: 0.491495\n",
      "[359]\ttraining's binary_logloss: 0.491258\n",
      "[360]\ttraining's binary_logloss: 0.491014\n",
      "[361]\ttraining's binary_logloss: 0.490819\n",
      "[362]\ttraining's binary_logloss: 0.490573\n",
      "[363]\ttraining's binary_logloss: 0.490341\n",
      "[364]\ttraining's binary_logloss: 0.490102\n",
      "[365]\ttraining's binary_logloss: 0.489878\n",
      "[366]\ttraining's binary_logloss: 0.489674\n",
      "[367]\ttraining's binary_logloss: 0.48948\n",
      "[368]\ttraining's binary_logloss: 0.489299\n",
      "[369]\ttraining's binary_logloss: 0.489108\n",
      "[370]\ttraining's binary_logloss: 0.488916\n",
      "[371]\ttraining's binary_logloss: 0.488684\n",
      "[372]\ttraining's binary_logloss: 0.488435\n",
      "[373]\ttraining's binary_logloss: 0.488194\n",
      "[374]\ttraining's binary_logloss: 0.487953\n",
      "[375]\ttraining's binary_logloss: 0.487704\n",
      "[376]\ttraining's binary_logloss: 0.487448\n",
      "[377]\ttraining's binary_logloss: 0.48721\n",
      "[378]\ttraining's binary_logloss: 0.486962\n",
      "[379]\ttraining's binary_logloss: 0.48674\n",
      "[380]\ttraining's binary_logloss: 0.486516\n",
      "[381]\ttraining's binary_logloss: 0.486265\n",
      "[382]\ttraining's binary_logloss: 0.48605\n",
      "[383]\ttraining's binary_logloss: 0.4858\n",
      "[384]\ttraining's binary_logloss: 0.485558\n",
      "[385]\ttraining's binary_logloss: 0.485314\n",
      "[386]\ttraining's binary_logloss: 0.485103\n",
      "[387]\ttraining's binary_logloss: 0.484862\n",
      "[388]\ttraining's binary_logloss: 0.484659\n",
      "[389]\ttraining's binary_logloss: 0.484454\n",
      "[390]\ttraining's binary_logloss: 0.484204\n",
      "[391]\ttraining's binary_logloss: 0.483962\n",
      "[392]\ttraining's binary_logloss: 0.483714\n",
      "[393]\ttraining's binary_logloss: 0.483459\n",
      "[394]\ttraining's binary_logloss: 0.483201\n",
      "[395]\ttraining's binary_logloss: 0.482956\n",
      "[396]\ttraining's binary_logloss: 0.482727\n",
      "[397]\ttraining's binary_logloss: 0.482469\n",
      "[398]\ttraining's binary_logloss: 0.482237\n",
      "[399]\ttraining's binary_logloss: 0.482001\n",
      "[400]\ttraining's binary_logloss: 0.481786\n",
      "[401]\ttraining's binary_logloss: 0.481542\n",
      "[402]\ttraining's binary_logloss: 0.481294\n",
      "[403]\ttraining's binary_logloss: 0.481088\n",
      "[404]\ttraining's binary_logloss: 0.480842\n",
      "[405]\ttraining's binary_logloss: 0.480611\n",
      "[406]\ttraining's binary_logloss: 0.480376\n",
      "[407]\ttraining's binary_logloss: 0.480171\n",
      "[408]\ttraining's binary_logloss: 0.479964\n",
      "[409]\ttraining's binary_logloss: 0.479748\n",
      "[410]\ttraining's binary_logloss: 0.479529\n",
      "[411]\ttraining's binary_logloss: 0.479297\n",
      "[412]\ttraining's binary_logloss: 0.479077\n",
      "[413]\ttraining's binary_logloss: 0.478877\n",
      "[414]\ttraining's binary_logloss: 0.478598\n",
      "[415]\ttraining's binary_logloss: 0.478368\n",
      "[416]\ttraining's binary_logloss: 0.478166\n",
      "[417]\ttraining's binary_logloss: 0.477909\n",
      "[418]\ttraining's binary_logloss: 0.477744\n",
      "[419]\ttraining's binary_logloss: 0.477537\n",
      "[420]\ttraining's binary_logloss: 0.477286\n",
      "[421]\ttraining's binary_logloss: 0.477107\n",
      "[422]\ttraining's binary_logloss: 0.476896\n",
      "[423]\ttraining's binary_logloss: 0.476692\n",
      "[424]\ttraining's binary_logloss: 0.476504\n",
      "[425]\ttraining's binary_logloss: 0.476317\n",
      "[426]\ttraining's binary_logloss: 0.476052\n",
      "[427]\ttraining's binary_logloss: 0.475748\n",
      "[428]\ttraining's binary_logloss: 0.475481\n",
      "[429]\ttraining's binary_logloss: 0.475217\n",
      "[430]\ttraining's binary_logloss: 0.474944\n",
      "[431]\ttraining's binary_logloss: 0.474733\n",
      "[432]\ttraining's binary_logloss: 0.474505\n",
      "[433]\ttraining's binary_logloss: 0.474295\n",
      "[434]\ttraining's binary_logloss: 0.474067\n",
      "[435]\ttraining's binary_logloss: 0.473851\n",
      "[436]\ttraining's binary_logloss: 0.473575\n",
      "[437]\ttraining's binary_logloss: 0.473279\n",
      "[438]\ttraining's binary_logloss: 0.473052\n",
      "[439]\ttraining's binary_logloss: 0.472748\n",
      "[440]\ttraining's binary_logloss: 0.472506\n",
      "[441]\ttraining's binary_logloss: 0.472254\n",
      "[442]\ttraining's binary_logloss: 0.472003\n",
      "[443]\ttraining's binary_logloss: 0.471745\n",
      "[444]\ttraining's binary_logloss: 0.471472\n",
      "[445]\ttraining's binary_logloss: 0.471267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[446]\ttraining's binary_logloss: 0.471032\n",
      "[447]\ttraining's binary_logloss: 0.470795\n",
      "[448]\ttraining's binary_logloss: 0.47058\n",
      "[449]\ttraining's binary_logloss: 0.470376\n",
      "[450]\ttraining's binary_logloss: 0.470168\n",
      "[451]\ttraining's binary_logloss: 0.469989\n",
      "[452]\ttraining's binary_logloss: 0.469817\n",
      "[453]\ttraining's binary_logloss: 0.469638\n",
      "[454]\ttraining's binary_logloss: 0.469475\n",
      "[455]\ttraining's binary_logloss: 0.469302\n",
      "[456]\ttraining's binary_logloss: 0.469059\n",
      "[457]\ttraining's binary_logloss: 0.468828\n",
      "[458]\ttraining's binary_logloss: 0.468627\n",
      "[459]\ttraining's binary_logloss: 0.468423\n",
      "[460]\ttraining's binary_logloss: 0.468212\n",
      "[461]\ttraining's binary_logloss: 0.467966\n",
      "[462]\ttraining's binary_logloss: 0.467718\n",
      "[463]\ttraining's binary_logloss: 0.467483\n",
      "[464]\ttraining's binary_logloss: 0.467238\n",
      "[465]\ttraining's binary_logloss: 0.467005\n",
      "[466]\ttraining's binary_logloss: 0.466727\n",
      "[467]\ttraining's binary_logloss: 0.466444\n",
      "[468]\ttraining's binary_logloss: 0.466181\n",
      "[469]\ttraining's binary_logloss: 0.465919\n",
      "[470]\ttraining's binary_logloss: 0.465664\n",
      "[471]\ttraining's binary_logloss: 0.46543\n",
      "[472]\ttraining's binary_logloss: 0.465204\n",
      "[473]\ttraining's binary_logloss: 0.464977\n",
      "[474]\ttraining's binary_logloss: 0.46476\n",
      "[475]\ttraining's binary_logloss: 0.464503\n",
      "[476]\ttraining's binary_logloss: 0.464264\n",
      "[477]\ttraining's binary_logloss: 0.464058\n",
      "[478]\ttraining's binary_logloss: 0.463835\n",
      "[479]\ttraining's binary_logloss: 0.463625\n",
      "[480]\ttraining's binary_logloss: 0.463408\n",
      "[481]\ttraining's binary_logloss: 0.463184\n",
      "[482]\ttraining's binary_logloss: 0.462958\n",
      "[483]\ttraining's binary_logloss: 0.462748\n",
      "[484]\ttraining's binary_logloss: 0.462528\n",
      "[485]\ttraining's binary_logloss: 0.462321\n",
      "[486]\ttraining's binary_logloss: 0.462108\n",
      "[487]\ttraining's binary_logloss: 0.461944\n",
      "[488]\ttraining's binary_logloss: 0.461753\n",
      "[489]\ttraining's binary_logloss: 0.461545\n",
      "[490]\ttraining's binary_logloss: 0.461364\n",
      "[491]\ttraining's binary_logloss: 0.461152\n",
      "[492]\ttraining's binary_logloss: 0.460938\n",
      "[493]\ttraining's binary_logloss: 0.46071\n",
      "[494]\ttraining's binary_logloss: 0.460512\n",
      "[495]\ttraining's binary_logloss: 0.460338\n",
      "[496]\ttraining's binary_logloss: 0.460102\n",
      "[497]\ttraining's binary_logloss: 0.459847\n",
      "[498]\ttraining's binary_logloss: 0.459581\n",
      "[499]\ttraining's binary_logloss: 0.459308\n",
      "[500]\ttraining's binary_logloss: 0.459029\n"
     ]
    }
   ],
   "source": [
    "leavenumber_values = [10,20,30,40]\n",
    "min_data_in_leave_values = [10,20,30,40]\n",
    "k = 5\n",
    "\n",
    "res4mean = dict()\n",
    "for s in min_data_in_leave_values:\n",
    "    res4mean[s] = list()\n",
    "    \n",
    "res4std = dict()\n",
    "for s in min_data_in_leave_values:\n",
    "    res4std[s] = list()\n",
    "\n",
    "#Now train and get results for each option\n",
    "for s in min_data_in_leave_values:\n",
    "    for l in leavenumber_values:\n",
    "        (a,b) = xValLGM(dataset, 'Target', k, l, s)\n",
    "        res4mean[s].append(a)\n",
    "        res4std[s].append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testRF(X_Train,Y_Train,X_Test,Y_Test, nestimator, maxfeat):\n",
    "    '''\n",
    "    Build a function that takes in tree hyperparams, data and returns accuracy on test data\n",
    "    '''\n",
    "    clf = RandomForestClassifier(criterion='entropy', bootstrap=True, max_depth=30, n_estimators=nestimator, max_features= maxfeat, min_samples_split=20, min_samples_leaf=10, n_jobs = -1, oob_score=True)\n",
    "    \n",
    "    clf.fit(X_Train, Y_Train)\n",
    "    test_p = clf.predict_proba(X_Test)[:,1]\n",
    "    \n",
    "    return metrics.roc_auc_score(Y_Test, test_p)\n",
    "\n",
    "def testLGM(trainx,trainy,testx,testy, nleaves, mininleave):\n",
    "    scalar = MinMaxScaler()\n",
    "    scalar.fit(trainx)\n",
    "    trainx = scalar.transform(trainx)\n",
    "    testx = scalar.transform(testx)\n",
    "        \n",
    "        #created dataset for lightgbm\n",
    "    lgb_train = lgb.Dataset(trainx, trainy)\n",
    "    \n",
    "    params = {\n",
    "            'colsample_bytree':0.4,\n",
    "            \n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'is_unbalance': 'true',         # base rate: 0.30\n",
    "            'num_leaves': nleaves,\n",
    "            \"num_threads\": 4,\n",
    "            'learning_rate': 0.01,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'n_estimators': 500,\n",
    "            'verbose': 0,\n",
    "            'min_data_in_leaf': mininleave\n",
    "        }\n",
    "    \n",
    "    gbm = lgb.train(params,\n",
    "                        lgb_train,\n",
    "                        num_boost_round=10,\n",
    "                        valid_sets=lgb_train,  # eval training data\n",
    "                        categorical_feature = 'auto')\n",
    "# predict\n",
    "    test_p = gbm.predict(testx, num_iteration=gbm.best_iteration)\n",
    "    \n",
    "    return metrics.roc_auc_score(testy, test_p)\n",
    "       \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72103148, 0.72131646, 0.72172404, 0.72171337, 0.72155245,\n",
       "       0.72208913, 0.72241735, 0.7220669 ])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(res3mean[0.2])+np.asarray(res3std[0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Cross Validation AUC by Hyperparameters')"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py:2267: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def r():\n",
    "    return np.random.rand()\n",
    "\n",
    "#Now plot            \n",
    "fig = plt.figure(figsize = (6, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for s in min_data_in_leave_values:\n",
    "    c = (r(),r(),r())\n",
    "    plt.plot(leavenumber_values, res4mean[s], \n",
    "             color= c, label='min_data_in_leaves={}'.format(s))\n",
    "   # plt.plot(leavenumber_values, np.asarray(res4mean[s])+np.asarray(res4std[s]), \n",
    "    #         '-.',color= c, label='min_data_in_leaves={}_mean+std'.format(s))\n",
    "    #plt.plot(leavenumber_values, np.asarray(res4mean[s])-np.asarray(res4std[s]), \n",
    "     #      '--',  color= c, label='min_data_in_leaves={}_mean-std'.format(s))\n",
    "    \n",
    "\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(loc='center left', bbox_to_anchor=(0, -0.5))\n",
    "#plt.legend(loc=4, ncol=3, mode=\"expand\")\n",
    "ax.set_xlabel('num_of_leave')\n",
    "ax.set_ylabel('AUC')\n",
    "plt.title('Cross Validation AUC by Hyperparameters')\n",
    "\n",
    "#n_estimator made to 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Cross Validation AUC by Hyperparameters')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py:2267: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def r():\n",
    "    return np.random.rand()\n",
    "\n",
    "#Now plot            \n",
    "fig = plt.figure(figsize = (6, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for s in max_features_values:\n",
    "    c = (r(),r(),r())\n",
    "    plt.plot(n_estimators_values, res3mean[s], \n",
    "             color= c, label='Max_feature={}'.format(s))\n",
    "    #plt.plot(n_estimators_values, np.asarray(res3mean[s])+np.asarray(res3std[s]), \n",
    "           # '-.', color= c, label='Max_feature={}_mean+std'.format(s))\n",
    "    #plt.plot(n_estimators_values, np.asarray(res3mean[s])-np.asarray(res3std[s]), \n",
    "            # '--',color= c, label='Max_feature={}_mean-std'.format(s))\n",
    "    \n",
    "\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(loc='center left', bbox_to_anchor=(0, -0.4))\n",
    "#plt.legend(loc=4, ncol=3, mode=\"expand\")\n",
    "ax.set_xlabel('n_estimators')\n",
    "ax.set_ylabel('AUC')\n",
    "plt.title('Cross Validation AUC by Hyperparameters')\n",
    "\n",
    "#n_estimator made to 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "basetrain = pd.read_csv('trainset4.csv')\n",
    "basetest = pd.read_csv('testset4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HistCrit', 'Zipcode', 'Price', 'Rating', 'ReviewCount',\n",
       "       'WeeklyOpenHr', 'WeeklyOvernightTimes', 'PriceMV',\n",
       "       'DaysSinceLastInsp', 'InitialInsp', 'RatSighting', 'MouseSighting',\n",
       "       'CondAttractRodents', 'RodentSigns', 'DaysSinceLastCrit',\n",
       "       'WeeklyOpenDays', 'NoHistCrit', 'CritRate', 'AveTemp3dayMax',\n",
       "       'MaxTemp3dayMax', 'AveHum3dayMax', 'AveTemp3dayAve',\n",
       "       'MaxTemp3dayAve', 'AveHum3dayAve', 'AveTemp3dayRange',\n",
       "       'MaxTemp3dayRange', 'AveHum3dayRange', 'SubBoroPct',\n",
       "       'ChildUnder18', 'IncomeDiv', 'MedianIncome', 'Population',\n",
       "       'PopDensity', 'PovertyRate', 'RacialDiv', 'UnemployRate',\n",
       "       'MedianRentB', '25NoHighSchool', 'CrimeRate', 'CrimeRateViolent',\n",
       "       'CrimeRateProperty', 'PriceOverRating', 'RatingOverPrice',\n",
       "       'RatingCountProd', 'FoodType', 'Month', 'LastAction', 'LastScore',\n",
       "       'LastScoreMV', 'LastGrade', 'TotalOpenDays', 'LastInspProgram',\n",
       "       'LastInspCat', 'SubBoro', 'Reviews', 'RodentScore',\n",
       "       'LastCritOverLastInsp', 'LastCritOverLastInspMV', 'Target'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basetrain.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "basetrax = basetrain[['LastScore','LastGrade','Zipcode','LastAction','Target','Reviews']]\n",
    "basetray = basetrain['Target']\n",
    "basetesx = basetest[['LastScore','LastGrade','Zipcode','LastAction','Reviews']]\n",
    "basetesy = basetest['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LastScore</th>\n",
       "      <th>LastGrade</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>LastAction</th>\n",
       "      <th>Target</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>LastGradeM</td>\n",
       "      <td>11231.0</td>\n",
       "      <td>LastActionCited</td>\n",
       "      <td>0.0</td>\n",
       "      <td>and This place is a gem for anybody that love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>LastGradeA</td>\n",
       "      <td>11206.0</td>\n",
       "      <td>LastActionCited</td>\n",
       "      <td>0.0</td>\n",
       "      <td>and Hiiiii, soooo the pizza at this Domino's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>LastGradeA</td>\n",
       "      <td>11236.0</td>\n",
       "      <td>LastActionCited</td>\n",
       "      <td>0.0</td>\n",
       "      <td>and The best pizza I've ever tasted and the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>LastGradeM</td>\n",
       "      <td>10031.0</td>\n",
       "      <td>LastActionCited</td>\n",
       "      <td>0.0</td>\n",
       "      <td>and Good customer service \\nClean place, is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.0</td>\n",
       "      <td>LastGradeM</td>\n",
       "      <td>11206.0</td>\n",
       "      <td>LastActionCited</td>\n",
       "      <td>0.0</td>\n",
       "      <td>and My oh my, what a discovery!  Newtown is s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LastScore   LastGrade  Zipcode       LastAction  Target  \\\n",
       "0       11.0  LastGradeM  11231.0  LastActionCited     0.0   \n",
       "1       10.0  LastGradeA  11206.0  LastActionCited     0.0   \n",
       "2        7.0  LastGradeA  11236.0  LastActionCited     0.0   \n",
       "3       21.0  LastGradeM  10031.0  LastActionCited     0.0   \n",
       "4       23.0  LastGradeM  11206.0  LastActionCited     0.0   \n",
       "\n",
       "                                             Reviews  \n",
       "0   and This place is a gem for anybody that love...  \n",
       "1   and Hiiiii, soooo the pizza at this Domino's ...  \n",
       "2   and The best pizza I've ever tasted and the p...  \n",
       "3   and Good customer service \\nClean place, is t...  \n",
       "4   and My oh my, what a discovery!  Newtown is s...  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basetrax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(basetrax,basetesx) = batchencoder(basetrax,basetesx,col = ['LastGrade','LastAction'], method = ['onehot','onehot'],targ = 'Target')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "basetrax.drop('Target',1,inplace = True)\n",
    "basetesx.drop('Target',1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LastScore</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>LastGradeA</th>\n",
       "      <th>LastGradeB</th>\n",
       "      <th>LastGradeC</th>\n",
       "      <th>LastGradeM</th>\n",
       "      <th>LastGradeNot Yet Graded</th>\n",
       "      <th>LastGradeP</th>\n",
       "      <th>LastGradeZ</th>\n",
       "      <th>LastActionCited</th>\n",
       "      <th>LastActionNoVio</th>\n",
       "      <th>LastActionReClosed</th>\n",
       "      <th>LastActionReOpened</th>\n",
       "      <th>LastActionclosed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>11231.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11206.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>11236.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>10031.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.0</td>\n",
       "      <td>11206.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LastScore  Zipcode  LastGradeA  LastGradeB  LastGradeC  LastGradeM  \\\n",
       "0       11.0  11231.0         0.0         0.0         0.0         1.0   \n",
       "1       10.0  11206.0         1.0         0.0         0.0         0.0   \n",
       "2        7.0  11236.0         1.0         0.0         0.0         0.0   \n",
       "3       21.0  10031.0         0.0         0.0         0.0         1.0   \n",
       "4       23.0  11206.0         0.0         0.0         0.0         1.0   \n",
       "\n",
       "   LastGradeNot Yet Graded  LastGradeP  LastGradeZ  LastActionCited  \\\n",
       "0                      0.0         0.0         0.0              1.0   \n",
       "1                      0.0         0.0         0.0              1.0   \n",
       "2                      0.0         0.0         0.0              1.0   \n",
       "3                      0.0         0.0         0.0              1.0   \n",
       "4                      0.0         0.0         0.0              1.0   \n",
       "\n",
       "   LastActionNoVio  LastActionReClosed  LastActionReOpened  LastActionclosed  \n",
       "0              0.0                 0.0                 0.0               0.0  \n",
       "1              0.0                 0.0                 0.0               0.0  \n",
       "2              0.0                 0.0                 0.0               0.0  \n",
       "3              0.0                 0.0                 0.0               0.0  \n",
       "4              0.0                 0.0                 0.0               0.0  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basetrax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py:2267: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = LogisticRegression( ).fit(basetrax,basetray)\n",
    "y_pred = lr.predict_proba(basetesx)[:,1]\n",
    "plotAUC(basetesy,y_pred,'logistic regression baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall = pd.read_csv('dataall.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Negative:  9128\n",
      "Number of Positive :  3985\n",
      "Positive ratio:  0.3038968962098681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py:2267: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAEMCAYAAADwJwB6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl4VdXd/v/3h6kWZRKl8sgQUMBoJkhAqMggg8DjT6qAQxUJKpbaAg9TixUtDj/qhFJRikCVwQGqUAGFqlQoUgcQDENVBARRUQMoEESGhM/3j3NymhyGnANhB5P7dV3nOjlr7WHtEHJn7b322ubuiIiInGzlSroBIiJSNihwREQkEAocEREJhAJHREQCocAREZFAKHBERCQQChwREQmEAkdERAKhwBERkUBUKOkGnMrOOussT0hIKOlmiIic0lasWLHd3c8uajkFzjEkJCTw/vvvl3QzREROaWb2WSzL6ZSaiIgEQoEjIiKBUOCIiEggFDgiZVBCQgJJSUkcOnSoUNnatWuLbR+bN2/mrLPOKrbtxapv375cdNFFXHvttYfVtWvXjlq1arFnz55CZa+88spJa8+oUaM4cOBA5PPdd9/NzJkzT9r+Xn31VZo1a0ZycjJt27Zl06ZNkbphw4bRoEEDzKzQv/WOHTvo1q0bTZo0ISUlhauvvppt27ZF6p9++mmSk5NJS0sjIyODt9566/ga5+56HeWVnp7uIqVR/fr1vX79+j5lypRCZWvWrCm2fWzatMlr1qx5wtvJzc2Nedmvv/7aq1Sp4nl5eUesb9u2rdevX99HjRpVqGzevHkn3M6jATwnJ+ekbb+gb7/91mvWrOnr1q1zd/fp06f75ZdfHql/6623fMuWLYf9W+/YscMXLVoU+Txs2DC/+eab3d19+/btXqVKFf/666/d3X3OnDmemJhYaL/A+x7D71T1cETKqFGjRh3213e+6N5Owc8JCQmMHDmSVq1aUa9ePZ5//nnGjh1LixYtOP/88w/763fYsGG0aNGC5OTkQnXz58/nkksuIT09nVatWvHuu+8CsHjxYtLS0hgwYAAtW7ZkwYIFh7Vv2rRpJCcnk5KSwlVXXUV2djY5OTm0b9+evXv30qxZMx577LEjHvcdd9zB+PHj2b59+2F1u3fv5tZbb6VFixakpKQwaNAg8vLyAPjwww+5+OKLSUpK4sYbb6Rly5aRntGYMWNo3rw5TZs2pVWrVmRlZQHwm9/8BoCf//znpKWlsXPnTjIzM3niiSfYu3cvZ511VqF2DB06lHvuuQeA9957j/bt25Oenk56ejqvvvrqEY+noA0bNvCzn/2Mxo0bA9CtWzdee+21yD5at25N3bp1D1vvzDPPpF27dpHPLVu25LPPQgPPPPyQzpycHAB27txJnTp1imzLEcWSSmX1pR6OlFb5f+H27NnTx44dW6gs+usj1Q0bNszd3ZctW+aVK1f2J554wt3dZ86c6Zdccom7h3o4gE+dOtXd3RcvXuznnnuu79u3zzds2OAtW7b0Xbt2ubv72rVrvW7duu7uvmjRIi9Xrpy//fbbR2z7mjVrvHbt2r5161Z3dx85cqRfc801kX0eq1eV35sZNmyY/9///V+hMnf3W265xadNm+bu7nl5eX7dddf5xIkT3d29WbNmPn36dHd3X758uZcrVy6yXnZ2dmQfb7zxhl988cWRz0T1cPr06ePjxo1zd/ebb77Z//znP7u7+8GDB7127dq+adMm/+677zwtLS1yjFu3bvVzzz3Xv/vuO3d379q1qy9fvvyw49u5c6efeeaZvmzZMnd3f/zxxx3wFStWFFruWL3ZvLw879ChQ6Rd7u7PPvusn3HGGV63bl0/99xzff369YXWIcYeju7DESnD7r//ftq3b88tt9wS13r510eaNWvG3r17I5/T09PZsGFDZLlKlSpx4403AtC2bVt++tOfsm7dOpYuXcrGjRtp06ZNZNnc3Fy++eYbABo1akSrVq2OuO9FixbRrVs3ateuDcCvfvUrUlNT42r/HXfcQWJiIoMHDy5UPnfuXJYtW8aYMWMA2Lt3L3Xq1GH37t2sXbuWX/7ylwBkZGSQkpISWW/FihWMHj2ab7/9lnLlyvHJJ5/E1I7MzEwGDRrEwIEDWbBgAYmJiSQkJDB//nw2bdpE165dI8uaGRs2bCAjI4P58+cfcXvVqlVj5syZDB48mH379tG1a1eqV69OxYoVY/7eDBgwgDPOOIPf/va3QKjX9+STT/L+++/TpEkT/va3v3HVVVexevVqzCzm7YJu/Dyp0odPK+kmyClmxcM3lXQTCmnSpAndunXj0UcfLVReoUKFQgMK9u3bV6j+tNNOA6B8+fKHfc7NzT3q/twdM8Pd6dKlC9OmHf5/5KOPPuKMM84ochsFxfuL78wzz2TAgAGMGjXqsG2//PLLNGzYsFD5rl27MLMj7ufAgQP07NmTJUuW0KxZM7Zu3cq5554bUzsuvfRScnJyWLNmDVOmTCEzMzPSjpSUFJYsWRLXcQF07NiRjh07AvDNN9/w8MMPH3Y8RzNs2DDWr1/PvHnzKFcudMXl9ddfp3r16jRp0gSAa665hszMTLZv387ZZxc5uUAhuoYjUsaNGjWKJ598MnKOHuC8885j+fLlAPzzn/+M9DzideDAAZ5//nkA3nrrLfbt20eTJk3o3Lkz//jHP/jPf/4TWTZ/f0Xp0KED8+fP5+uvvwZg0qRJkV+w8Rg8eDCvvfYaGzdujJRdeeWVPPDAA5HrNtu3b2fTpk1Uq1aNCy+8kBdeeAGAlStXsmbNGiAUxrm5uZFrI+PHjy+0nypVqrBr166jtuOmm25izJgxLFmyhB49egChaz7r169n0aJFkeWWL18euZ5yLPnfl0OHDvGHP/yB/v37c/rppxe53p133smKFSt4+eWX+clPfhIpb9CgAR988AHZ2dlAqIdZtWrV4xqBqMARKePq1KlD7969+fbbbyNl999/P2PGjKFly5bMnz+fevXqHde2a9asyfr167n44ou5/fbbeeGFF6hUqRKNGjXi2Wef5ZZbbiE1NZXExESeeuqpmLZ50UUX8ac//YlOnTqRkpLCqlWr+POf/xx3204//XTuuOMOvvjii0jZ2LFjKV++PKmpqSQnJ9OlSxe+/PJLIDRQYezYsaSnpzNhwgRSU1OpVq0aVatW5d5776V58+a0adPmsF/uQ4cO5bLLLosMGojWp08fpk+fTvfu3alcuTIANWrUYO7cudxzzz2R78+oUaMigdOtW7ejTrs1cuRIEhMTadSoEZUqVeKBBx6I1A0cOJA6derwxRdf0LFjRy666CIA/vOf/zB69Gi2bt0aGeBw1VVXAaHTpMOHD6dt27akpqby+9//npdeeinuXiWAxZKYZVVGRoafyFxqOqUm0U61U2oSu++//57KlStjZnz44Ye0a9eOdevWUaNGjZJuWokzsxXunlHUcrqGIyISg3//+98MHz480suYNGmSwiZOChwRkRh07tyZzp07l3QzftR0DUekDCrLU9s0bNiQtLQ0LrjgguO69pPv1ltvjdzI+vLLL7Ns2bJI3fvvv88NN9xw3NsuyjPPPENKSgppaWkkJyfz+OOPR+q+/vprunfvTkpKComJiTz77LORuuzsbP73f/+XlJQULrjgAm6//fbIqMJRo0ZRq1Yt0tLSSEtLi9y0WpzUwxEpo/bs2cP06dPp06dPSTflmPLy8iLDr4vyzTffMGvWLHbu3BkZ1hvt8ccf54orruDzzz8nKSmJdu3axX0fD8DkyZMjX7/88stkZGTQokULIHSfznPPPRf3NmPVo0cPMjMzMTNycnIix5GSksKQIUPIyMhgzpw5bNu2jfT0dNq2bUvdunUZPXo0iYmJvPrqqxw8eJDWrVsze/ZsrrnmGiA0Yu6RRx45ae1WD0ekjCqrU9vkq1u3Lk2aNIncpPnggw+SlJREUlISffv2jUzwOWfOnMjElUlJSSxevBj476Sfr732GnPnzuWBBx4gLS2NadOmsXjxYjIyQtfQb7nllkI9qbVr19KwYUPc/ZhT6RxL1apVI6PE9u7dy8GDByOfV61aRZcuXQA4++yzSUtL429/+xtAJKAOHTrE/v37OXDgQMz3DBUHBY5IGZWRkUFGRgZ/+ctf4l53//79vPPOO8yaNYt+/fpRsWJFli1bxujRo7njjjsiy+3YsYOUlBSWLVvGE088wfXXX8/+/fvZuHEj9913HwsWLGDFihVMnjw58lc2wJo1a/jlL3/Ju+++yxVXXFFo32vXrmXEiBG8/vrrrF69mqSkJAYMGECVKlWYP38+1atXJysr67BZBKJ9+OGHfPzxx6SkpLBgwQKmT5/O22+/zZo1a8jLy+O+++4DQrM7jx8/nqysLFatWkWzZs0Kbefyyy/nyiuvZMSIEWRlZXHTTYVHImZmZjJ16tTI52eeeSbSOxkyZAht27Zl2bJlZGVlkZ2dzdNPPw3AhAkTuPvuu4/a/rlz53LRRRdRv359hg8fTnJyMhAaxjxjxgzcnU2bNvH2229H5kW76667+OSTT6hduzbnnHMOl19+OZdccklkmzNmzCAlJYXOnTvzzjvvHPP7dzx0Sk2kDCuLU9sMHDiQkSNHctppp/HUU0/RpEkTJk6cyHXXXUfVqlUBuO222xg0aBAAl112GUOHDqVXr1507dqVpKSkmPcF/51NYPXq1ZGbR/N/mR9tKh2A/v37H3O7V155JVdeeSVbtmzhF7/4ReTxAmPGjGHw4MGkpaVRr149LrvsssjUNi+++CIpKSn885//JCcnh65du/LSSy/Rs2dP+vfvz5133knFihV544036N69Ox999BE1a9aM63iPRYEjUoaVxalt8q/hxLrNxx57jDVr1vDmm2/Sq1cvhgwZQr9+/WLeH4SujUydOpV27dqRmJhI/fr1I/s90lQ68ahXrx4tWrTglVdeoUmTJpx99tmFBgp069aNxMREAMaNG8fTTz9NuXLlqFatGt27d2fRokX07NmTc845J7JOp06dqFu3LmvXrqVt27bH3bZoOqUmUsaV1altCurUqRMzZswgJycHd2fy5MmRba5bt47k5GQGDRrEjTfeeMR2Vq1a9ZjT1/Tp04cXXniByZMn07dv30j50abSKcrHH38c+Xr79u0sWrQockptx44dkdB/8803I6cnITRNzT/+8Q8g9G+zcOHCSI8tf0YFgKysLDZv3hyZP624qIcjUsblT22Tf1oHQqfa+vTpw6RJk7jkkkuKZWqbvXv3HnFqmx9++IEDBw5wySWX0Lx58yK3WXBqGzOjYcOGMU+LczRdu3Zl9erVkdN4GRkZjBw5EoARI0awfv16KlSoQPXq1fnrX/962Pq9e/cmMzOTF198kSFDhhz2/apXrx4XXnghixcvjszHBqGpdH73u9+RmpqKmfGTn/yEsWPH0qBBAyZMmMDWrVu59957D9vfU089xeuvv07FihVxd377299G7hFatmwZAwcOpHz58px11lnMmzcvMmXO2LFj6d+/P8nJyeTl5dG+fftIb+0Pf/gDK1asoHz58lSqVInp06cX6vUUB01tcwya2kaKm6a2kdIo1qltdEpNREQCocAREZFAKHBEyqCEhAQuuOACUlNTSUpKYsaMGce9rW7dukWeKTNlypRCT7ucO3cuw4cPP+H2Hq/oG1vvvvtuZs6ceULbzMvL4ze/+Q3nnXce559/fqEZBwr66quvaN68eWT6mV69evHdd99F6ufNm8cFF1zA+eefz7XXXsvevXsLre/udOjQoUSmBzpZdA3nGHQNR4rbqXINJyEhgVdeeYWkpCQ++OADfv7zn/P555+f8C+3du3aMWzYsMOGHZ8sRU17k39n/bGGWcdr2rRpPPfccyxYsIAdO3bQtGlTli5dSkJCQqHlDh48yMGDByMX7AcPHoyZ8eijj7Jnz57IrAyNGjXi1ltvpV69eoVu9Bw3bhxZWVnMmTOH7du3F1v7TwZdwxGRmDRt2pQqVaqwadMm8vLyGDZsWGSKl2HDhkWG7E6cOJHExETS0tJISUmJDM3Nn/bmmWee4f3332fgwIGkpaWxcOFCpkyZQs+ePYHQcOY5c+ZE9jtv3jzat28PhHoDPXv2jEyBM3r06CO2dcqUKXTp0oXevXuTnp7OmjVrGDNmDM2bN6dp06a0atWKrKwsgMjkk/kPFNu5cyeZmZk88cQTQGguub59+0aO9cEHH4zp+zVz5kz69etHuXLlOPvss/nFL37Biy++eNhyFStWjIRNXl4ee/bsiczvtmDBAjIyMmjUqBEQusmzYM9r/fr1zJgxgxEjRsTUph8LDYsWKeMWLVrEvn37aNSoERMnTiQrK4uVK1cCoeHCEydO5Ne//jXDhw9n7dq11K1bl/379x8251ffvn2ZOnVqoR7OlClTIvX5U7x07949Upd/T8pNN93EXXfdRZs2bThw4AAdOnSgefPmdOrU6bD2Ll26lFWrVnHeeecBcO655zJ06FAAFi5cSP/+/Xn33Xd58sknGT9+PG+//fYRezj33Xcfhw4dYs2aNeTk5NCqVStSUlLo2rXrMYckb9myJXLjJoSGPH/++edH/f6mpaWxZcsWUlJSmDt3bpHbOHToEP369ePJJ5+MzBBQWgTawzGzc8xsppltM7PvzOxNM0stUH+TmW00s71m9p6ZpUetn2Fmy8L1G83sxqj6WmY228xywvt40MzUixM5gp49e5KWlsYf//hHZs2aRfXq1Vm4cCGZmZlUqlSJSpUq0bdvXxYuXAiEpnjp27cv48aN48svv4z89R6rHj16sGTJErZv386OHTv417/+RY8ePfj+++9ZvHhxpGfUokULtm7dykcffXTE7bRu3ToSNgArVqygTZs2JCUlMWTIkEgPpygLFy6kX79+mBlVq1bl+uuvjxxr//79jxg2xyMrK4tvvvmGxMREJkyYUOTyjzzyCG3atCEtLa1Y9n8qCbqHMx6oAjQB9gD3A6+YWT3gEuAvwFXAv4BBwHwza+Tuu82sGrAAeAS4FGgD/N3MNrp7/ixzzwE5QB2gJvAP4Fsgtr6ySBny0ksvHTYv2LGmeJk9ezbLly/nzTffpH379kyYMIGuXbvGvL/KlSvTvXv3yI2P3bt35/TTTycnJwczY/ny5TH9RV+wt3LgwAF69uzJkiVLaNasGVu3bo159uPjnSKnXr16fPbZZ5GbVKN7K0dSsWJF+vTpQ79+/fjd735HvXr1WLRoUaR+y5Yt1K1bF4AlS5awevVqpk2bRm5uLt999x0JCQmsXr06Mtfbj1XQf/2fD7zo7t+6+wHgr/w3HPoBs939dXffDzwM7CcUQABXAz8AD7n7fnd/A/g7cBuAmTUAOgLD3X2Xu39KKGiOPQNeFDOraWaNzazxseaEEimNOnXqxJQpUyIXvKdOnUrHjh3Jzc3l008/pUWLFowYMYLOnTvzwQcfHLZ+UVO8ZGZmMmXKlEKn06pUqcKll17KAw88EFnu888/j0xdcyz79u0jNzc38st6/PjxheqrVKly1PZ06tSJyZMn4+7k5OQwY8aMmKbI6dWrF5MmTeLQoUNs27aNl19+mR49ehy23Oeffx55xMGhQ4eYNWtWZPqZLl26sHz5ctavXw+EZobOny37lVdeYcuWLWzevJmlS5dSo0YNNm/e/KMPGwg+cB4GepjZWWZ2GqGwWOru24FUYEX+gh4aPvdBuJzw+0ovPKxuZVT9LnffGFWfYGbx/EsNANYB67Kzs+NYTeTH77bbbiMlJYWmTZvStGlTUlJS6NevH3l5eWRmZpKcnExqaipfffUVv/rVr464/n333UfTpk0jp6cKuvTSS9m9eze7d++mdevWkfLnnnuODz/8kOTkZJKTk7n22mvZuXNnke2tWrUq9957L82bN6dNmzacfvrpheqHDh3KZZddFhk0UNBdd92Fu5OcnEyrVq3o3bt35Dkyx3o0QO/evWnYsCGNGjWiZcuW3H333ZHJNwuut27dOlq3bk1KSgopKSl89dVXkSdzVqlShYkTJ3LFFVdw/vnns2vXLoYNG1bk8f7YBTos2swaAhOBDkAe8DnQ1d0/NrONwP3u/kyB5acCB939VjP7K1DB3fsUqO8L3Onu55tZ7/D69QvUNwA+Beq6+xcxtrEmoR4Xqamp62I9H3wkGhYt0U6VYdEixemUGxYdvni/EPgEqAZUBv5/4C0z+xmhay/VolarDuwOf3289fl1MXH3He7+ibt/UqGCBvGJiBSXIE+pnQk0AMa5+253P+Duk8NtaAmsAiKP0rPQ1bu0cDnh96ZR22waVV8t3IsqWL/Z3Y9+UllERAIRWOCEr9N8AtxuZqebWQUzu5nQqLU1wCTgajPrYGaVgKHAaYQGBhB+r2xmw82skpl1IDSQYGJ4+5sI9aAeMrOq4dNpvwdObN5yEREpFkEPGvgFoV7OZ8AO4DdAL3f/1N2XArcTCp5dwDVAN3ffDeDuO4FuQK9w/SSgf4Eh0QA3EDqmL4HlwBzgoQCOS0REihDoRQp3/wg46iRL7j4NOOqVdndfDrQ4Rn02oV6PiIicYnQXvoiIBEKBIyIigVDgiIhIIBQ4IiISCAWOiIgEQoEjIiKBUOCIiEggFDgiIhIIBY6IiARCgSMiIoFQ4IiISCAUOCIiEggFjoiIBEKBIyIigVDgiIhIIBQ4IiISCAWOiIgEQoEjIiKBUOCIiEggFDgiIhIIBY6IiARCgSMiIoFQ4IiISCAUOCIiEggFjoiIBEKBIyIigVDgiIhIIBQ4IiISCAWOiIgEQoEjIiKBUOCIiEggFDgiIhIIBY6IiAQi8MAxs45m9q6Z7TGz7WY2vkDdTWa20cz2mtl7ZpYetW6GmS0L1280sxuj6muZ2WwzyzGzbWb2oJkpVEVETgGB/jI2s3bAS8AjQE2gDjA5XNca+Avwa6AGMAuYb2ZVw/XVgAXh8hpAf2CCmbUqsIvnwu91gIuBq4DhJ/WgREQkJkH/9f8nYIK7v+Tu+919n7uvDNf1A2a7++vuvh94GNhPKDQArgZ+AB4Kr/sG8HfgNgAzawB0BIa7+y53/xR4kFAwxczMappZYzNrnJube4KHKyIi+QILHDM7HWgB7DOzleHTaYvNLCO8SCqwIn95d3fgg3B5fv3KcHm+lVH1u9x9Y1R9Qn4vKUYDgHXAuuzs7DhWExGRYwmyh1MjvL9+QCbwP8DrhE6bVQeqALui1tkJ5IfF8dZTYJlYjAOaAE1q1aoVx2oiInIsQQZOTvj9GXdf7e4HCJ1iqwj8PFxfLWqd6sDuAusfT33BfRfJ3Xe4+yfu/kmFChViXU1ERIoQWOC4+y5gM+BHqgZWAc3yC8zMgLRwOeH3plHrNY2qr2ZmDaPqN4f3LSIiJSjoQQPjgb5mdqGZVSA0gmwf8DYwCbjazDqYWSVgKHAaoYEBhN8rm9lwM6tkZh0IDSSYCODum4CFwENmVjU8iOD3wFMBHp+IiBxF0OeMHiF0reVNQmHyAdA13ANZama3Ewqe2sAaoJu77wZw951m1g14ErgX+Aro7+7vFNj+DcAE4EtCI9yeBh4K4sBEROTYAg2c8Aizu8OvI9VPA6YdY/3lhEa6Ha0+m1CvR0RETjG6C19ERAKhwBERkUDEHDhmlmdmh92YEr4zP694myUiIqVNPD0cO0p5JeBgMbRFRERKsSIHDZjZTeEvHbjGzHYXqC4PtAU2nIS2iYhIKRLLKLW/Fvj6sai6A8CnwOBia5GIiJRKRQaOu1cEMLNNQHN3337SWyUiIqVOzPfhuHuDk9kQEREp3eK68TM8XUw74GdEDThw99HF1ywRESltYg4cM7sBeIbQiLRtFJ6E0wEFjoiIHFU8PZx7gLHAH9xdj8IUEZG4xHMfTm1Cj4dW2IiISNziCZxFhJ5PIyIiErd4TqlNI/SsmbpAFlGzC7j728XZMBERKV3iCZwZ4ffomz8hNGig/Ik3R0RESqt4Akf34YiIyHGL58bPz05mQ0REpHSL5z6cXx6r3t2fP/HmiIhIaRXPKbVnj1KefwOoAkdERI4q5mHR7l6u4IvQc3BaAv8GWp+sBoqISOlw3I+Ydvdcd18G3Ak8WXxNEhGR0ui4A6eAbKBJMWxHRERKsXgGDfxPdBHwP8Ao4MNibJOIiJRC8Qwa+ILCM0RDKHQ+A64pthaJiEipFE/gtI/6fIjQ6bQN7p5XfE0SEZHSKJ4bP/91MhsiIiKlW7xP/Dwb+C1wYbhoLTDe3bcVd8NERKR0iXmUmpm1BDYAfQsU3wysN7MWxd0wEREpXeLp4TwCvAzckv8QNjMrD/wVGANcWvzNExGR0iKewEkH+hV84qe755nZQ8D7xd4yEREpVeK58XMPcM4RymsB3xdPc0REpLSKJ3DmApPMrKOZ/TT86gBMIHSqTURE5KjiOaU2GJgCvE7hG0D/DgwtxjaJiEgpFM9s0bvd/WqgMfCL8Kuxu/d0993x7NTMypnZ22bmZlanQPlNZrbRzPaa2Xtmlh61XoaZLQvXbzSzG6Pqa5nZbDPLMbNtZvagmRXHfHEiInKC4hkW/bSZDXH3De4+L/zaaGZDzGxynPsdDOyN2n5r4C/Ar4EawCxgvplVDddXAxaEy2sA/YEJZtaqwGaeC7/XAS4GrgKGx9k2ERE5CeL5678L8M8jlC8Cusa6ETNrDNwODIuq6gfMdvfX3X0/8DCwn1BoAFwN/AA85O773f0NQqfzbgtvtwHQERju7rvc/VPgQULBJCIiJSyewDmT0Ei1aLuBmrFsIHx662lCvY6dUdWpwIr8D+7uwAfh8vz6leHyfCuj6ne5+8ao+oT8XlKMbaxpZo3NrHFubm7RK4iISEziGTTwKXAZsDGq/DJCM0bHYhDwtbvPNrOEqLoqwK6osp1A1ROsJ7xMrNeZBgB/BMjOzo5xFZEfjy33Jpd0E+QUUu/uNYHtK57AmQA8YmaVgYXhsg7AvcA9Ra1sZucTGs2WcZRFcoBqUWXV+W/A5QAJR6jfXaD+SOvn18VqHPA8QK1atdbFsZ6IiBxDPLNFP25mtYA/AY+Giw8Aj7r7YzFsojVwNrDWzOC/p/P+9xdcAAAKqklEQVRWm9lIYBXQLH9hCy2UBswOF63iv9dz8jUNl+fXVzOzhuHrN/n1m909uudzVO6+A9gBkJFxtGwUEZF4xTVk2N1HEgqNluHXWe5+Z4yr/w04j1CIpAHdwuWdgWnAJOBqM+tgZpUI9YZOIzQwgPB7ZTMbbmaVwjedXg1MDLdtE6Ge10NmVjU8iOD3wFPxHKOIiJwccT2eAMDdvweWH8d6eykwFNrM8vf9tbvvAZaa2e2Egqc2sAboln+Pj7vvNLNuwJOETuN9BfR393cK7OYGQqf+viQ0wu1p4KF42yoiIsUv7sApLu6+mdAjqguWTSPU2znaOsuBoz4Kwd2zCfV6RETkFKO78EVEJBAKHBERCYQCR0REAqHAERGRQChwREQkEAocEREJhAJHREQCocAREZFAKHBERCQQChwREQmEAkdERAKhwBERkUAocEREJBAKHBERCYQCR0REAqHAERGRQChwREQkEAocEREJhAJHREQCocAREZFAKHBERCQQChwREQmEAkdERAKhwBERkUAocEREJBAKHBERCYQCR0REAqHAERGRQChwREQkEAocEREJhAJHREQCocAREZFAKHBERCQQChwREQlEYIFjZg+a2X/MbLeZbTWzSWZ2ZtQyN5nZRjPba2bvmVl6VH2GmS0L1280sxuj6muZ2WwzyzGzbeF9KlRFRE4BQf4yzgNuBGoCqUAd4Jn8SjNrDfwF+DVQA5gFzDezquH6asCCcHkNoD8wwcxaFdjHc+H3OsDFwFXA8JN3SCIiEqvAAsfd/+DuH7j7QXffBjwBtCuwSD9gtru/7u77gYeB/YRCA+Bq4AfgIXff7+5vAH8HbgMwswZAR2C4u+9y90+BBwkFU8zMrKaZNTazxrm5ucd9vCIiUlhJnm7qAKwu8DkVWJH/wd0d+CBcnl+/Mlyeb2VU/S533xhVn5DfS4rRAGAdsC47OzuO1URE5FhKJHDMrAehHs2gAsVVgF1Ri+4Eqp5gPQWWicU4oAnQpFatWnGsJiIixxJ44JhZL2AScKW7ryxQlQNUi1q8OrD7BOvz62Li7jvc/RN3/6RChQqxriYiIkUINHDMrC/wFPD/ufuiqOpVQLMCyxqQFi7Pr28atU7TqPpqZtYwqn6zu0f3fEREJGBBDoseCDwCXO7u/z7CIpOAq82sg5lVAoYCpxEaGED4vbKZDTezSmbWgdBAgokA7r4JWAg8ZGZVw4MIfk8o4EREpIQF2cP5M6FrKYvMbE/+K7/S3ZcCtxMKnl3ANUA3d98drt8JdAN6hesnAf3d/Z0C+7iB0DF9CSwH5gAPnewDExGRogV2kcLdLYZlpgHTjlG/HGhxjPpsQr0eERE5xegufBERCYQCR0REAqHAERGRQChwREQkEAocEREJhAJHREQCocAREZFAKHBERCQQChwREQmEAkdERAKhwBERkUAocEREJBAKHBERCYQCR0REAqHAERGRQChwREQkEAocEREJhAJHREQCocAREZFAKHBERCQQChwREQmEAkdERAKhwBERkUAocEREJBAKHBERCYQCR0REAqHAERGRQChwREQkEAocEREJhAJHREQCocAREZFAKHBERCQQChwREQlEqQscMytvZg+b2TYzyzGzWWZ2Vkm3S0SkrCt1gQOMALoDFwN1wmXTS645IiICpTNwbgMedPdP3X0X8Dugi5klxLKymdU0s8Zm1jg3N/ckNlNEpGwxdy/pNhQbM6sG7ASauntWgfJdQG93nxvDNkYBfwx/3At8dBKaWtaUB34GfAPklXBbREA/k8WtvrufXdRCFYJoSYCqht93RZXvLFBXlHHA8+Gvd7j7juJoWFlmZo2BdUA7d/+kpNsjop/JklHaAicn/F4tqrw6sDuWDYQDRiEjIlLMStU1HHffCWwBmuWXmVlDQr2b1SXVLhERKWWBEzYR+L2ZNTCzqsCDwGvuvrlkm1Wm7QDuQT1HOXXoZ7IElKpBAxC6D4dQyGQCPwHeAG5z9+0l2S4RkbKu1AWOiIicmkrjKTURETkFKXBERCQQChwREQmEAkdERAKhwBERkUAocEREJBAKHBERCYQCR0REAqHAkRMW71NWzayLmf3HzH4ws7Vm1jnI9krpZ2bXmdlbZrbbzIp8sJWZZZjZMjPba2YbzezGINpZ1ihwpDjE/JTV8GSqs4E/EZrV+0/A32N9QJ5IjL4DxgP/V9SC4edoLQBmATWA/sAEM2t1UltYBmlqGzlhZvYZcK+7/zX8+TxgA9AgetJUM7sHuMzdLy1Q9haw0N3vCa7VUhaYWTtCP1tHfRSLmfUlNJFnfQ//QjSz6UCuu/cNpKFlhHo4ckLCfx3WA1bkl7n7RkLPH0o5wiqpBZcNWxkuFykJqcBKL/zXt34mTwIFjpyoeJ+yWiWOZUWCoJ/JgChw5ETF+5TVnDiWFQmCfiYDosCRE3IcT1ldVXDZsKbhcpGSsIrQz2BB+pk8CRQ4UhziecrqNCDDzK43s4pmdj2QDkwNrrlS2oWH6p8GVAp/Pi38siMs/negspkNN7NKZtYBuJrQz7UUIwWOFIcHgHnAcuBLoDxwI4CZ3WBme/IXDA8ouBoYSeiUxUjgKj0CXIpZb+AH4DVCP48/hF/1zexSM9tjZvUg0kvvBvQidC1nEtDf3d8pkZaXYhoWLSIigVAPR0REAqHAERGRQChwREQkEAocEREJhAJHREQCocAREZFAKHBERCQQChyRYmZmXsRrc0m3EcDM7jezj0u6HVJ2HPUZESJy3GoX+PrnhB7s1Qz4KlyWd7wbNrOfuPv+E2ibSIlRD0ekmLn71/kv4Ntw8bYC5dsAzKyPmS0PPwZ5u5nNM7NG+dsxswvCPaLrzOwNM9sLDA/XXWFmH5vZPjN7x8yuCi/bssD6F5rZK+Htbws/+rtuuK4/cCfQpEDPa0RA3yIpoxQ4IiWnEvBHQjMTX07ojMMcM4s+8/AgMBm4CJhW4DHdrwNphB7T/XDBFcysDrAU+BhoCbQj1LN6w8wqEZosdSyhJ7PWDr/GFfsRihSgU2oiJcTdJxX8bGY3A1s5/Kmo49x9ZoHlHgU2AYPCT6n8ONxzeaLAOgOALHcfVmC9mwhNTtnZ3V8xs++BvHBPTOSkUw9HpISYWVMz+7uZbTazHGB9uKp+1KLLoj4nAu9FPRL53ahlMoD8WZH3hGfs3g5UBBohUgLUwxEpAWZWDVgYfvUBviF0im1V+L2gvcexi3LAfGDoEeq2H8f2RE6YAkekZCQBZwIj3H0TgJldFuO6HwHdzMwK9HJaRC2zArgK+MzdDx5lOwcIPStGJBA6pSZSMjYBB4GBZtbQzDoDj8S47hNAQ+AxM2tiZlcAg8N1+QE0ltBjvl8ys1bhp7G2M7M/m1n+KbtPgTpmlm5mZ5nZT4vlyESOQoEjUgLcfSuhU2lXAh8SGmk2JMZ1PwV6AF2B1YSGN/8xXL0vvMwXQCtCvZhXCfWKJgM/JTRwAOBFYA7wBrANGHSChyVyTHrip0gpYGZ9CT0auYa755R0e0SORNdwRH6EzOw3wPtANpAOjAb+prCRU5kCR+TH6XzgDuBs4EvgeeCuEm2RSBF0Sk1ERAKhQQMiIhIIBY6IiARCgSMiIoFQ4IiISCAUOCIiEoj/Bxufc0HADzs3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns # data visualization library \n",
    "ax = sns.countplot(dfall.Target,label=\"Count\")       \n",
    "N, P = dfall.Target.value_counts()\n",
    "ax.text(0.6, 9000,'Number of Negative: 9128', fontsize=11)\n",
    "ax.text(0.6, 8500,'Number of Positive: 3985', fontsize=11)\n",
    "ax.text(0.6,8000,'Positive ratio: 0.304',fontsize = 11)\n",
    "print('Number of Negative: ',N)\n",
    "print('Number of Positive : ',P)\n",
    "print('Positive ratio: ',P/(P+N) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10490, 354)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucslr = xValSVM(dataset,'Target',10,'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucsrf = xValSVM(dataset,'Target',10,'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613853\n",
      "[2]\ttraining's binary_logloss: 0.612751\n",
      "[3]\ttraining's binary_logloss: 0.611694\n",
      "[4]\ttraining's binary_logloss: 0.610743\n",
      "[5]\ttraining's binary_logloss: 0.609774\n",
      "[6]\ttraining's binary_logloss: 0.608829\n",
      "[7]\ttraining's binary_logloss: 0.607922\n",
      "[8]\ttraining's binary_logloss: 0.607112\n",
      "[9]\ttraining's binary_logloss: 0.606234\n",
      "[10]\ttraining's binary_logloss: 0.605415\n",
      "[11]\ttraining's binary_logloss: 0.604601\n",
      "[12]\ttraining's binary_logloss: 0.60382\n",
      "[13]\ttraining's binary_logloss: 0.603087\n",
      "[14]\ttraining's binary_logloss: 0.602383\n",
      "[15]\ttraining's binary_logloss: 0.601686\n",
      "[16]\ttraining's binary_logloss: 0.601035\n",
      "[17]\ttraining's binary_logloss: 0.600402\n",
      "[18]\ttraining's binary_logloss: 0.599927\n",
      "[19]\ttraining's binary_logloss: 0.599321\n",
      "[20]\ttraining's binary_logloss: 0.598761\n",
      "[21]\ttraining's binary_logloss: 0.598142\n",
      "[22]\ttraining's binary_logloss: 0.597677\n",
      "[23]\ttraining's binary_logloss: 0.597192\n",
      "[24]\ttraining's binary_logloss: 0.596695\n",
      "[25]\ttraining's binary_logloss: 0.596234\n",
      "[26]\ttraining's binary_logloss: 0.595772\n",
      "[27]\ttraining's binary_logloss: 0.595307\n",
      "[28]\ttraining's binary_logloss: 0.594866\n",
      "[29]\ttraining's binary_logloss: 0.594507\n",
      "[30]\ttraining's binary_logloss: 0.594133\n",
      "[31]\ttraining's binary_logloss: 0.593746\n",
      "[32]\ttraining's binary_logloss: 0.593379\n",
      "[33]\ttraining's binary_logloss: 0.593052\n",
      "[34]\ttraining's binary_logloss: 0.59272\n",
      "[35]\ttraining's binary_logloss: 0.592405\n",
      "[36]\ttraining's binary_logloss: 0.59212\n",
      "[37]\ttraining's binary_logloss: 0.591882\n",
      "[38]\ttraining's binary_logloss: 0.591634\n",
      "[39]\ttraining's binary_logloss: 0.591419\n",
      "[40]\ttraining's binary_logloss: 0.591213\n",
      "[41]\ttraining's binary_logloss: 0.590895\n",
      "[42]\ttraining's binary_logloss: 0.590642\n",
      "[43]\ttraining's binary_logloss: 0.590352\n",
      "[44]\ttraining's binary_logloss: 0.590072\n",
      "[45]\ttraining's binary_logloss: 0.589808\n",
      "[46]\ttraining's binary_logloss: 0.58959\n",
      "[47]\ttraining's binary_logloss: 0.589391\n",
      "[48]\ttraining's binary_logloss: 0.589165\n",
      "[49]\ttraining's binary_logloss: 0.588952\n",
      "[50]\ttraining's binary_logloss: 0.588803\n",
      "[51]\ttraining's binary_logloss: 0.588608\n",
      "[52]\ttraining's binary_logloss: 0.588464\n",
      "[53]\ttraining's binary_logloss: 0.588289\n",
      "[54]\ttraining's binary_logloss: 0.588168\n",
      "[55]\ttraining's binary_logloss: 0.588015\n",
      "[56]\ttraining's binary_logloss: 0.587877\n",
      "[57]\ttraining's binary_logloss: 0.587738\n",
      "[58]\ttraining's binary_logloss: 0.587581\n",
      "[59]\ttraining's binary_logloss: 0.587436\n",
      "[60]\ttraining's binary_logloss: 0.587312\n",
      "[61]\ttraining's binary_logloss: 0.587171\n",
      "[62]\ttraining's binary_logloss: 0.58707\n",
      "[63]\ttraining's binary_logloss: 0.586958\n",
      "[64]\ttraining's binary_logloss: 0.586824\n",
      "[65]\ttraining's binary_logloss: 0.586705\n",
      "[66]\ttraining's binary_logloss: 0.586633\n",
      "[67]\ttraining's binary_logloss: 0.586575\n",
      "[68]\ttraining's binary_logloss: 0.586513\n",
      "[69]\ttraining's binary_logloss: 0.586513\n",
      "[70]\ttraining's binary_logloss: 0.586514\n",
      "[71]\ttraining's binary_logloss: 0.586485\n",
      "[72]\ttraining's binary_logloss: 0.586395\n",
      "[73]\ttraining's binary_logloss: 0.586304\n",
      "[74]\ttraining's binary_logloss: 0.58624\n",
      "[75]\ttraining's binary_logloss: 0.5862\n",
      "[76]\ttraining's binary_logloss: 0.586132\n",
      "[77]\ttraining's binary_logloss: 0.586075\n",
      "[78]\ttraining's binary_logloss: 0.58605\n",
      "[79]\ttraining's binary_logloss: 0.58601\n",
      "[80]\ttraining's binary_logloss: 0.585964\n",
      "[81]\ttraining's binary_logloss: 0.585929\n",
      "[82]\ttraining's binary_logloss: 0.585903\n",
      "[83]\ttraining's binary_logloss: 0.585877\n",
      "[84]\ttraining's binary_logloss: 0.585917\n",
      "[85]\ttraining's binary_logloss: 0.585906\n",
      "[86]\ttraining's binary_logloss: 0.58589\n",
      "[87]\ttraining's binary_logloss: 0.585911\n",
      "[88]\ttraining's binary_logloss: 0.585925\n",
      "[89]\ttraining's binary_logloss: 0.585926\n",
      "[90]\ttraining's binary_logloss: 0.585945\n",
      "[91]\ttraining's binary_logloss: 0.585931\n",
      "[92]\ttraining's binary_logloss: 0.585932\n",
      "[93]\ttraining's binary_logloss: 0.585935\n",
      "[94]\ttraining's binary_logloss: 0.585951\n",
      "[95]\ttraining's binary_logloss: 0.585962\n",
      "[96]\ttraining's binary_logloss: 0.585918\n",
      "[97]\ttraining's binary_logloss: 0.585874\n",
      "[98]\ttraining's binary_logloss: 0.585789\n",
      "[99]\ttraining's binary_logloss: 0.58572\n",
      "[100]\ttraining's binary_logloss: 0.585689\n",
      "[101]\ttraining's binary_logloss: 0.585729\n",
      "[102]\ttraining's binary_logloss: 0.585724\n",
      "[103]\ttraining's binary_logloss: 0.585724\n",
      "[104]\ttraining's binary_logloss: 0.585727\n",
      "[105]\ttraining's binary_logloss: 0.585747\n",
      "[106]\ttraining's binary_logloss: 0.585731\n",
      "[107]\ttraining's binary_logloss: 0.585723\n",
      "[108]\ttraining's binary_logloss: 0.585714\n",
      "[109]\ttraining's binary_logloss: 0.585714\n",
      "[110]\ttraining's binary_logloss: 0.585747\n",
      "[111]\ttraining's binary_logloss: 0.585739\n",
      "[112]\ttraining's binary_logloss: 0.585799\n",
      "[113]\ttraining's binary_logloss: 0.585832\n",
      "[114]\ttraining's binary_logloss: 0.58587\n",
      "[115]\ttraining's binary_logloss: 0.585905\n",
      "[116]\ttraining's binary_logloss: 0.585954\n",
      "[117]\ttraining's binary_logloss: 0.586016\n",
      "[118]\ttraining's binary_logloss: 0.586057\n",
      "[119]\ttraining's binary_logloss: 0.586071\n",
      "[120]\ttraining's binary_logloss: 0.586094\n",
      "[121]\ttraining's binary_logloss: 0.586106\n",
      "[122]\ttraining's binary_logloss: 0.586154\n",
      "[123]\ttraining's binary_logloss: 0.58617\n",
      "[124]\ttraining's binary_logloss: 0.586196\n",
      "[125]\ttraining's binary_logloss: 0.586218\n",
      "[126]\ttraining's binary_logloss: 0.586258\n",
      "[127]\ttraining's binary_logloss: 0.586305\n",
      "[128]\ttraining's binary_logloss: 0.586311\n",
      "[129]\ttraining's binary_logloss: 0.586356\n",
      "[130]\ttraining's binary_logloss: 0.586349\n",
      "[131]\ttraining's binary_logloss: 0.586341\n",
      "[132]\ttraining's binary_logloss: 0.586342\n",
      "[133]\ttraining's binary_logloss: 0.586344\n",
      "[134]\ttraining's binary_logloss: 0.586323\n",
      "[135]\ttraining's binary_logloss: 0.586331\n",
      "[136]\ttraining's binary_logloss: 0.586378\n",
      "[137]\ttraining's binary_logloss: 0.586377\n",
      "[138]\ttraining's binary_logloss: 0.586424\n",
      "[139]\ttraining's binary_logloss: 0.586426\n",
      "[140]\ttraining's binary_logloss: 0.586431\n",
      "[141]\ttraining's binary_logloss: 0.586459\n",
      "[142]\ttraining's binary_logloss: 0.58646\n",
      "[143]\ttraining's binary_logloss: 0.586462\n",
      "[144]\ttraining's binary_logloss: 0.586495\n",
      "[145]\ttraining's binary_logloss: 0.58651\n",
      "[146]\ttraining's binary_logloss: 0.586536\n",
      "[147]\ttraining's binary_logloss: 0.586573\n",
      "[148]\ttraining's binary_logloss: 0.586597\n",
      "[149]\ttraining's binary_logloss: 0.586651\n",
      "[150]\ttraining's binary_logloss: 0.586674\n",
      "[151]\ttraining's binary_logloss: 0.586699\n",
      "[152]\ttraining's binary_logloss: 0.586744\n",
      "[153]\ttraining's binary_logloss: 0.586759\n",
      "[154]\ttraining's binary_logloss: 0.586777\n",
      "[155]\ttraining's binary_logloss: 0.586778\n",
      "[156]\ttraining's binary_logloss: 0.586801\n",
      "[157]\ttraining's binary_logloss: 0.586841\n",
      "[158]\ttraining's binary_logloss: 0.586841\n",
      "[159]\ttraining's binary_logloss: 0.586864\n",
      "[160]\ttraining's binary_logloss: 0.586901\n",
      "[161]\ttraining's binary_logloss: 0.586902\n",
      "[162]\ttraining's binary_logloss: 0.586897\n",
      "[163]\ttraining's binary_logloss: 0.586892\n",
      "[164]\ttraining's binary_logloss: 0.586896\n",
      "[165]\ttraining's binary_logloss: 0.586894\n",
      "[166]\ttraining's binary_logloss: 0.586917\n",
      "[167]\ttraining's binary_logloss: 0.586929\n",
      "[168]\ttraining's binary_logloss: 0.586934\n",
      "[169]\ttraining's binary_logloss: 0.586942\n",
      "[170]\ttraining's binary_logloss: 0.586953\n",
      "[171]\ttraining's binary_logloss: 0.58697\n",
      "[172]\ttraining's binary_logloss: 0.586989\n",
      "[173]\ttraining's binary_logloss: 0.587049\n",
      "[174]\ttraining's binary_logloss: 0.587107\n",
      "[175]\ttraining's binary_logloss: 0.587132\n",
      "[176]\ttraining's binary_logloss: 0.587156\n",
      "[177]\ttraining's binary_logloss: 0.587139\n",
      "[178]\ttraining's binary_logloss: 0.587125\n",
      "[179]\ttraining's binary_logloss: 0.58711\n",
      "[180]\ttraining's binary_logloss: 0.587101\n",
      "[181]\ttraining's binary_logloss: 0.587117\n",
      "[182]\ttraining's binary_logloss: 0.587146\n",
      "[183]\ttraining's binary_logloss: 0.587168\n",
      "[184]\ttraining's binary_logloss: 0.587183\n",
      "[185]\ttraining's binary_logloss: 0.587203\n",
      "[186]\ttraining's binary_logloss: 0.587192\n",
      "[187]\ttraining's binary_logloss: 0.587164\n",
      "[188]\ttraining's binary_logloss: 0.587134\n",
      "[189]\ttraining's binary_logloss: 0.587109\n",
      "[190]\ttraining's binary_logloss: 0.587093\n",
      "[191]\ttraining's binary_logloss: 0.587116\n",
      "[192]\ttraining's binary_logloss: 0.587145\n",
      "[193]\ttraining's binary_logloss: 0.587152\n",
      "[194]\ttraining's binary_logloss: 0.587184\n",
      "[195]\ttraining's binary_logloss: 0.587217\n",
      "[196]\ttraining's binary_logloss: 0.587222\n",
      "[197]\ttraining's binary_logloss: 0.587218\n",
      "[198]\ttraining's binary_logloss: 0.587215\n",
      "[199]\ttraining's binary_logloss: 0.587222\n",
      "[200]\ttraining's binary_logloss: 0.587225\n",
      "[201]\ttraining's binary_logloss: 0.587219\n",
      "[202]\ttraining's binary_logloss: 0.587207\n",
      "[203]\ttraining's binary_logloss: 0.5872\n",
      "[204]\ttraining's binary_logloss: 0.58719\n",
      "[205]\ttraining's binary_logloss: 0.587185\n",
      "[206]\ttraining's binary_logloss: 0.58718\n",
      "[207]\ttraining's binary_logloss: 0.587188\n",
      "[208]\ttraining's binary_logloss: 0.587209\n",
      "[209]\ttraining's binary_logloss: 0.587236\n",
      "[210]\ttraining's binary_logloss: 0.587253\n",
      "[211]\ttraining's binary_logloss: 0.58724\n",
      "[212]\ttraining's binary_logloss: 0.587219\n",
      "[213]\ttraining's binary_logloss: 0.587209\n",
      "[214]\ttraining's binary_logloss: 0.587189\n",
      "[215]\ttraining's binary_logloss: 0.587172\n",
      "[216]\ttraining's binary_logloss: 0.5872\n",
      "[217]\ttraining's binary_logloss: 0.587207\n",
      "[218]\ttraining's binary_logloss: 0.587214\n",
      "[219]\ttraining's binary_logloss: 0.58722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[220]\ttraining's binary_logloss: 0.587219\n",
      "[221]\ttraining's binary_logloss: 0.58719\n",
      "[222]\ttraining's binary_logloss: 0.587157\n",
      "[223]\ttraining's binary_logloss: 0.587132\n",
      "[224]\ttraining's binary_logloss: 0.587096\n",
      "[225]\ttraining's binary_logloss: 0.587072\n",
      "[226]\ttraining's binary_logloss: 0.587076\n",
      "[227]\ttraining's binary_logloss: 0.587081\n",
      "[228]\ttraining's binary_logloss: 0.587088\n",
      "[229]\ttraining's binary_logloss: 0.587093\n",
      "[230]\ttraining's binary_logloss: 0.587101\n",
      "[231]\ttraining's binary_logloss: 0.587073\n",
      "[232]\ttraining's binary_logloss: 0.587046\n",
      "[233]\ttraining's binary_logloss: 0.587022\n",
      "[234]\ttraining's binary_logloss: 0.586992\n",
      "[235]\ttraining's binary_logloss: 0.58696\n",
      "[236]\ttraining's binary_logloss: 0.586924\n",
      "[237]\ttraining's binary_logloss: 0.586896\n",
      "[238]\ttraining's binary_logloss: 0.586866\n",
      "[239]\ttraining's binary_logloss: 0.586837\n",
      "[240]\ttraining's binary_logloss: 0.586804\n",
      "[241]\ttraining's binary_logloss: 0.586791\n",
      "[242]\ttraining's binary_logloss: 0.586773\n",
      "[243]\ttraining's binary_logloss: 0.586759\n",
      "[244]\ttraining's binary_logloss: 0.586729\n",
      "[245]\ttraining's binary_logloss: 0.586719\n",
      "[246]\ttraining's binary_logloss: 0.586684\n",
      "[247]\ttraining's binary_logloss: 0.586651\n",
      "[248]\ttraining's binary_logloss: 0.586613\n",
      "[249]\ttraining's binary_logloss: 0.58658\n",
      "[250]\ttraining's binary_logloss: 0.58656\n",
      "[251]\ttraining's binary_logloss: 0.586515\n",
      "[252]\ttraining's binary_logloss: 0.586477\n",
      "[253]\ttraining's binary_logloss: 0.586433\n",
      "[254]\ttraining's binary_logloss: 0.586385\n",
      "[255]\ttraining's binary_logloss: 0.586343\n",
      "[256]\ttraining's binary_logloss: 0.586318\n",
      "[257]\ttraining's binary_logloss: 0.586311\n",
      "[258]\ttraining's binary_logloss: 0.58629\n",
      "[259]\ttraining's binary_logloss: 0.586246\n",
      "[260]\ttraining's binary_logloss: 0.586228\n",
      "[261]\ttraining's binary_logloss: 0.586174\n",
      "[262]\ttraining's binary_logloss: 0.58612\n",
      "[263]\ttraining's binary_logloss: 0.586074\n",
      "[264]\ttraining's binary_logloss: 0.586011\n",
      "[265]\ttraining's binary_logloss: 0.585982\n",
      "[266]\ttraining's binary_logloss: 0.585904\n",
      "[267]\ttraining's binary_logloss: 0.585827\n",
      "[268]\ttraining's binary_logloss: 0.585752\n",
      "[269]\ttraining's binary_logloss: 0.585671\n",
      "[270]\ttraining's binary_logloss: 0.585582\n",
      "[271]\ttraining's binary_logloss: 0.585542\n",
      "[272]\ttraining's binary_logloss: 0.585512\n",
      "[273]\ttraining's binary_logloss: 0.585475\n",
      "[274]\ttraining's binary_logloss: 0.585445\n",
      "[275]\ttraining's binary_logloss: 0.585417\n",
      "[276]\ttraining's binary_logloss: 0.5854\n",
      "[277]\ttraining's binary_logloss: 0.5854\n",
      "[278]\ttraining's binary_logloss: 0.58539\n",
      "[279]\ttraining's binary_logloss: 0.58538\n",
      "[280]\ttraining's binary_logloss: 0.585374\n",
      "[281]\ttraining's binary_logloss: 0.585328\n",
      "[282]\ttraining's binary_logloss: 0.585286\n",
      "[283]\ttraining's binary_logloss: 0.58524\n",
      "[284]\ttraining's binary_logloss: 0.585185\n",
      "[285]\ttraining's binary_logloss: 0.585148\n",
      "[286]\ttraining's binary_logloss: 0.585072\n",
      "[287]\ttraining's binary_logloss: 0.584999\n",
      "[288]\ttraining's binary_logloss: 0.584949\n",
      "[289]\ttraining's binary_logloss: 0.584873\n",
      "[290]\ttraining's binary_logloss: 0.584804\n",
      "[291]\ttraining's binary_logloss: 0.584751\n",
      "[292]\ttraining's binary_logloss: 0.584699\n",
      "[293]\ttraining's binary_logloss: 0.584647\n",
      "[294]\ttraining's binary_logloss: 0.584597\n",
      "[295]\ttraining's binary_logloss: 0.584547\n",
      "[296]\ttraining's binary_logloss: 0.584476\n",
      "[297]\ttraining's binary_logloss: 0.584413\n",
      "[298]\ttraining's binary_logloss: 0.584353\n",
      "[299]\ttraining's binary_logloss: 0.58429\n",
      "[300]\ttraining's binary_logloss: 0.584221\n",
      "[301]\ttraining's binary_logloss: 0.584196\n",
      "[302]\ttraining's binary_logloss: 0.584176\n",
      "[303]\ttraining's binary_logloss: 0.584159\n",
      "[304]\ttraining's binary_logloss: 0.584142\n",
      "[305]\ttraining's binary_logloss: 0.584141\n",
      "[306]\ttraining's binary_logloss: 0.584072\n",
      "[307]\ttraining's binary_logloss: 0.584013\n",
      "[308]\ttraining's binary_logloss: 0.583952\n",
      "[309]\ttraining's binary_logloss: 0.583895\n",
      "[310]\ttraining's binary_logloss: 0.583833\n",
      "[311]\ttraining's binary_logloss: 0.583813\n",
      "[312]\ttraining's binary_logloss: 0.58378\n",
      "[313]\ttraining's binary_logloss: 0.583738\n",
      "[314]\ttraining's binary_logloss: 0.583702\n",
      "[315]\ttraining's binary_logloss: 0.583673\n",
      "[316]\ttraining's binary_logloss: 0.583601\n",
      "[317]\ttraining's binary_logloss: 0.583524\n",
      "[318]\ttraining's binary_logloss: 0.583459\n",
      "[319]\ttraining's binary_logloss: 0.583385\n",
      "[320]\ttraining's binary_logloss: 0.583313\n",
      "[321]\ttraining's binary_logloss: 0.583234\n",
      "[322]\ttraining's binary_logloss: 0.583145\n",
      "[323]\ttraining's binary_logloss: 0.583071\n",
      "[324]\ttraining's binary_logloss: 0.582988\n",
      "[325]\ttraining's binary_logloss: 0.582938\n",
      "[326]\ttraining's binary_logloss: 0.582847\n",
      "[327]\ttraining's binary_logloss: 0.582759\n",
      "[328]\ttraining's binary_logloss: 0.582674\n",
      "[329]\ttraining's binary_logloss: 0.58259\n",
      "[330]\ttraining's binary_logloss: 0.582499\n",
      "[331]\ttraining's binary_logloss: 0.582432\n",
      "[332]\ttraining's binary_logloss: 0.582379\n",
      "[333]\ttraining's binary_logloss: 0.582328\n",
      "[334]\ttraining's binary_logloss: 0.582265\n",
      "[335]\ttraining's binary_logloss: 0.582198\n",
      "[336]\ttraining's binary_logloss: 0.582151\n",
      "[337]\ttraining's binary_logloss: 0.582104\n",
      "[338]\ttraining's binary_logloss: 0.582063\n",
      "[339]\ttraining's binary_logloss: 0.582008\n",
      "[340]\ttraining's binary_logloss: 0.581968\n",
      "[341]\ttraining's binary_logloss: 0.581864\n",
      "[342]\ttraining's binary_logloss: 0.58176\n",
      "[343]\ttraining's binary_logloss: 0.581658\n",
      "[344]\ttraining's binary_logloss: 0.581561\n",
      "[345]\ttraining's binary_logloss: 0.581452\n",
      "[346]\ttraining's binary_logloss: 0.581386\n",
      "[347]\ttraining's binary_logloss: 0.581338\n",
      "[348]\ttraining's binary_logloss: 0.581274\n",
      "[349]\ttraining's binary_logloss: 0.581215\n",
      "[350]\ttraining's binary_logloss: 0.581171\n",
      "[351]\ttraining's binary_logloss: 0.581081\n",
      "[352]\ttraining's binary_logloss: 0.580999\n",
      "[353]\ttraining's binary_logloss: 0.58092\n",
      "[354]\ttraining's binary_logloss: 0.580843\n",
      "[355]\ttraining's binary_logloss: 0.580757\n",
      "[356]\ttraining's binary_logloss: 0.580688\n",
      "[357]\ttraining's binary_logloss: 0.580622\n",
      "[358]\ttraining's binary_logloss: 0.580555\n",
      "[359]\ttraining's binary_logloss: 0.580484\n",
      "[360]\ttraining's binary_logloss: 0.580419\n",
      "[361]\ttraining's binary_logloss: 0.580335\n",
      "[362]\ttraining's binary_logloss: 0.580251\n",
      "[363]\ttraining's binary_logloss: 0.580181\n",
      "[364]\ttraining's binary_logloss: 0.580098\n",
      "[365]\ttraining's binary_logloss: 0.580023\n",
      "[366]\ttraining's binary_logloss: 0.579947\n",
      "[367]\ttraining's binary_logloss: 0.579874\n",
      "[368]\ttraining's binary_logloss: 0.579806\n",
      "[369]\ttraining's binary_logloss: 0.57974\n",
      "[370]\ttraining's binary_logloss: 0.579679\n",
      "[371]\ttraining's binary_logloss: 0.579598\n",
      "[372]\ttraining's binary_logloss: 0.579523\n",
      "[373]\ttraining's binary_logloss: 0.579452\n",
      "[374]\ttraining's binary_logloss: 0.579376\n",
      "[375]\ttraining's binary_logloss: 0.579306\n",
      "[376]\ttraining's binary_logloss: 0.579229\n",
      "[377]\ttraining's binary_logloss: 0.579155\n",
      "[378]\ttraining's binary_logloss: 0.579085\n",
      "[379]\ttraining's binary_logloss: 0.579005\n",
      "[380]\ttraining's binary_logloss: 0.578914\n",
      "[381]\ttraining's binary_logloss: 0.57883\n",
      "[382]\ttraining's binary_logloss: 0.578748\n",
      "[383]\ttraining's binary_logloss: 0.578657\n",
      "[384]\ttraining's binary_logloss: 0.578573\n",
      "[385]\ttraining's binary_logloss: 0.578501\n",
      "[386]\ttraining's binary_logloss: 0.578459\n",
      "[387]\ttraining's binary_logloss: 0.578394\n",
      "[388]\ttraining's binary_logloss: 0.578332\n",
      "[389]\ttraining's binary_logloss: 0.578268\n",
      "[390]\ttraining's binary_logloss: 0.578226\n",
      "[391]\ttraining's binary_logloss: 0.578132\n",
      "[392]\ttraining's binary_logloss: 0.57806\n",
      "[393]\ttraining's binary_logloss: 0.577963\n",
      "[394]\ttraining's binary_logloss: 0.577893\n",
      "[395]\ttraining's binary_logloss: 0.577798\n",
      "[396]\ttraining's binary_logloss: 0.577733\n",
      "[397]\ttraining's binary_logloss: 0.577656\n",
      "[398]\ttraining's binary_logloss: 0.577586\n",
      "[399]\ttraining's binary_logloss: 0.577525\n",
      "[400]\ttraining's binary_logloss: 0.577457\n",
      "[401]\ttraining's binary_logloss: 0.577403\n",
      "[402]\ttraining's binary_logloss: 0.577346\n",
      "[403]\ttraining's binary_logloss: 0.577293\n",
      "[404]\ttraining's binary_logloss: 0.577231\n",
      "[405]\ttraining's binary_logloss: 0.577174\n",
      "[406]\ttraining's binary_logloss: 0.577114\n",
      "[407]\ttraining's binary_logloss: 0.577061\n",
      "[408]\ttraining's binary_logloss: 0.577004\n",
      "[409]\ttraining's binary_logloss: 0.576923\n",
      "[410]\ttraining's binary_logloss: 0.576871\n",
      "[411]\ttraining's binary_logloss: 0.576803\n",
      "[412]\ttraining's binary_logloss: 0.576724\n",
      "[413]\ttraining's binary_logloss: 0.576652\n",
      "[414]\ttraining's binary_logloss: 0.576582\n",
      "[415]\ttraining's binary_logloss: 0.576519\n",
      "[416]\ttraining's binary_logloss: 0.576431\n",
      "[417]\ttraining's binary_logloss: 0.576374\n",
      "[418]\ttraining's binary_logloss: 0.576319\n",
      "[419]\ttraining's binary_logloss: 0.576251\n",
      "[420]\ttraining's binary_logloss: 0.5762\n",
      "[421]\ttraining's binary_logloss: 0.576135\n",
      "[422]\ttraining's binary_logloss: 0.576078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[423]\ttraining's binary_logloss: 0.576018\n",
      "[424]\ttraining's binary_logloss: 0.575973\n",
      "[425]\ttraining's binary_logloss: 0.575914\n",
      "[426]\ttraining's binary_logloss: 0.575874\n",
      "[427]\ttraining's binary_logloss: 0.575838\n",
      "[428]\ttraining's binary_logloss: 0.575803\n",
      "[429]\ttraining's binary_logloss: 0.575766\n",
      "[430]\ttraining's binary_logloss: 0.575739\n",
      "[431]\ttraining's binary_logloss: 0.575712\n",
      "[432]\ttraining's binary_logloss: 0.575653\n",
      "[433]\ttraining's binary_logloss: 0.575591\n",
      "[434]\ttraining's binary_logloss: 0.575538\n",
      "[435]\ttraining's binary_logloss: 0.575483\n",
      "[436]\ttraining's binary_logloss: 0.575371\n",
      "[437]\ttraining's binary_logloss: 0.575256\n",
      "[438]\ttraining's binary_logloss: 0.57515\n",
      "[439]\ttraining's binary_logloss: 0.575046\n",
      "[440]\ttraining's binary_logloss: 0.574943\n",
      "[441]\ttraining's binary_logloss: 0.574872\n",
      "[442]\ttraining's binary_logloss: 0.574807\n",
      "[443]\ttraining's binary_logloss: 0.574739\n",
      "[444]\ttraining's binary_logloss: 0.574678\n",
      "[445]\ttraining's binary_logloss: 0.574609\n",
      "[446]\ttraining's binary_logloss: 0.574518\n",
      "[447]\ttraining's binary_logloss: 0.574432\n",
      "[448]\ttraining's binary_logloss: 0.574328\n",
      "[449]\ttraining's binary_logloss: 0.574238\n",
      "[450]\ttraining's binary_logloss: 0.574138\n",
      "[451]\ttraining's binary_logloss: 0.574068\n",
      "[452]\ttraining's binary_logloss: 0.574001\n",
      "[453]\ttraining's binary_logloss: 0.573931\n",
      "[454]\ttraining's binary_logloss: 0.573863\n",
      "[455]\ttraining's binary_logloss: 0.573802\n",
      "[456]\ttraining's binary_logloss: 0.573712\n",
      "[457]\ttraining's binary_logloss: 0.573598\n",
      "[458]\ttraining's binary_logloss: 0.573486\n",
      "[459]\ttraining's binary_logloss: 0.573391\n",
      "[460]\ttraining's binary_logloss: 0.573286\n",
      "[461]\ttraining's binary_logloss: 0.573186\n",
      "[462]\ttraining's binary_logloss: 0.573075\n",
      "[463]\ttraining's binary_logloss: 0.572966\n",
      "[464]\ttraining's binary_logloss: 0.572874\n",
      "[465]\ttraining's binary_logloss: 0.572773\n",
      "[466]\ttraining's binary_logloss: 0.572671\n",
      "[467]\ttraining's binary_logloss: 0.572567\n",
      "[468]\ttraining's binary_logloss: 0.572465\n",
      "[469]\ttraining's binary_logloss: 0.572364\n",
      "[470]\ttraining's binary_logloss: 0.572268\n",
      "[471]\ttraining's binary_logloss: 0.572149\n",
      "[472]\ttraining's binary_logloss: 0.572042\n",
      "[473]\ttraining's binary_logloss: 0.571935\n",
      "[474]\ttraining's binary_logloss: 0.571826\n",
      "[475]\ttraining's binary_logloss: 0.57171\n",
      "[476]\ttraining's binary_logloss: 0.571632\n",
      "[477]\ttraining's binary_logloss: 0.571563\n",
      "[478]\ttraining's binary_logloss: 0.571498\n",
      "[479]\ttraining's binary_logloss: 0.571431\n",
      "[480]\ttraining's binary_logloss: 0.571352\n",
      "[481]\ttraining's binary_logloss: 0.571296\n",
      "[482]\ttraining's binary_logloss: 0.571245\n",
      "[483]\ttraining's binary_logloss: 0.571189\n",
      "[484]\ttraining's binary_logloss: 0.571137\n",
      "[485]\ttraining's binary_logloss: 0.571097\n",
      "[486]\ttraining's binary_logloss: 0.570996\n",
      "[487]\ttraining's binary_logloss: 0.570909\n",
      "[488]\ttraining's binary_logloss: 0.570817\n",
      "[489]\ttraining's binary_logloss: 0.570706\n",
      "[490]\ttraining's binary_logloss: 0.570591\n",
      "[491]\ttraining's binary_logloss: 0.570511\n",
      "[492]\ttraining's binary_logloss: 0.570433\n",
      "[493]\ttraining's binary_logloss: 0.570357\n",
      "[494]\ttraining's binary_logloss: 0.570287\n",
      "[495]\ttraining's binary_logloss: 0.570213\n",
      "[496]\ttraining's binary_logloss: 0.570148\n",
      "[497]\ttraining's binary_logloss: 0.570086\n",
      "[498]\ttraining's binary_logloss: 0.570022\n",
      "[499]\ttraining's binary_logloss: 0.569963\n",
      "[500]\ttraining's binary_logloss: 0.569898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.615244\n",
      "[2]\ttraining's binary_logloss: 0.614252\n",
      "[3]\ttraining's binary_logloss: 0.613134\n",
      "[4]\ttraining's binary_logloss: 0.612145\n",
      "[5]\ttraining's binary_logloss: 0.611241\n",
      "[6]\ttraining's binary_logloss: 0.610279\n",
      "[7]\ttraining's binary_logloss: 0.609355\n",
      "[8]\ttraining's binary_logloss: 0.608513\n",
      "[9]\ttraining's binary_logloss: 0.607655\n",
      "[10]\ttraining's binary_logloss: 0.606852\n",
      "[11]\ttraining's binary_logloss: 0.605992\n",
      "[12]\ttraining's binary_logloss: 0.605172\n",
      "[13]\ttraining's binary_logloss: 0.604382\n",
      "[14]\ttraining's binary_logloss: 0.603624\n",
      "[15]\ttraining's binary_logloss: 0.602875\n",
      "[16]\ttraining's binary_logloss: 0.6022\n",
      "[17]\ttraining's binary_logloss: 0.60155\n",
      "[18]\ttraining's binary_logloss: 0.601006\n",
      "[19]\ttraining's binary_logloss: 0.600479\n",
      "[20]\ttraining's binary_logloss: 0.599904\n",
      "[21]\ttraining's binary_logloss: 0.59927\n",
      "[22]\ttraining's binary_logloss: 0.59871\n",
      "[23]\ttraining's binary_logloss: 0.598169\n",
      "[24]\ttraining's binary_logloss: 0.597651\n",
      "[25]\ttraining's binary_logloss: 0.597142\n",
      "[26]\ttraining's binary_logloss: 0.596579\n",
      "[27]\ttraining's binary_logloss: 0.59604\n",
      "[28]\ttraining's binary_logloss: 0.59553\n",
      "[29]\ttraining's binary_logloss: 0.595036\n",
      "[30]\ttraining's binary_logloss: 0.59456\n",
      "[31]\ttraining's binary_logloss: 0.594135\n",
      "[32]\ttraining's binary_logloss: 0.593728\n",
      "[33]\ttraining's binary_logloss: 0.593353\n",
      "[34]\ttraining's binary_logloss: 0.593043\n",
      "[35]\ttraining's binary_logloss: 0.592696\n",
      "[36]\ttraining's binary_logloss: 0.592372\n",
      "[37]\ttraining's binary_logloss: 0.592074\n",
      "[38]\ttraining's binary_logloss: 0.591833\n",
      "[39]\ttraining's binary_logloss: 0.591609\n",
      "[40]\ttraining's binary_logloss: 0.591397\n",
      "[41]\ttraining's binary_logloss: 0.591064\n",
      "[42]\ttraining's binary_logloss: 0.590766\n",
      "[43]\ttraining's binary_logloss: 0.590453\n",
      "[44]\ttraining's binary_logloss: 0.590158\n",
      "[45]\ttraining's binary_logloss: 0.589881\n",
      "[46]\ttraining's binary_logloss: 0.589633\n",
      "[47]\ttraining's binary_logloss: 0.589385\n",
      "[48]\ttraining's binary_logloss: 0.589189\n",
      "[49]\ttraining's binary_logloss: 0.589001\n",
      "[50]\ttraining's binary_logloss: 0.588886\n",
      "[51]\ttraining's binary_logloss: 0.588668\n",
      "[52]\ttraining's binary_logloss: 0.588454\n",
      "[53]\ttraining's binary_logloss: 0.588254\n",
      "[54]\ttraining's binary_logloss: 0.58806\n",
      "[55]\ttraining's binary_logloss: 0.587873\n",
      "[56]\ttraining's binary_logloss: 0.587701\n",
      "[57]\ttraining's binary_logloss: 0.587592\n",
      "[58]\ttraining's binary_logloss: 0.58747\n",
      "[59]\ttraining's binary_logloss: 0.587358\n",
      "[60]\ttraining's binary_logloss: 0.587271\n",
      "[61]\ttraining's binary_logloss: 0.587143\n",
      "[62]\ttraining's binary_logloss: 0.587015\n",
      "[63]\ttraining's binary_logloss: 0.586898\n",
      "[64]\ttraining's binary_logloss: 0.58679\n",
      "[65]\ttraining's binary_logloss: 0.586691\n",
      "[66]\ttraining's binary_logloss: 0.586598\n",
      "[67]\ttraining's binary_logloss: 0.586524\n",
      "[68]\ttraining's binary_logloss: 0.586518\n",
      "[69]\ttraining's binary_logloss: 0.586455\n",
      "[70]\ttraining's binary_logloss: 0.586461\n",
      "[71]\ttraining's binary_logloss: 0.586345\n",
      "[72]\ttraining's binary_logloss: 0.586308\n",
      "[73]\ttraining's binary_logloss: 0.586226\n",
      "[74]\ttraining's binary_logloss: 0.586127\n",
      "[75]\ttraining's binary_logloss: 0.586103\n",
      "[76]\ttraining's binary_logloss: 0.58604\n",
      "[77]\ttraining's binary_logloss: 0.586019\n",
      "[78]\ttraining's binary_logloss: 0.585935\n",
      "[79]\ttraining's binary_logloss: 0.585918\n",
      "[80]\ttraining's binary_logloss: 0.585868\n",
      "[81]\ttraining's binary_logloss: 0.585915\n",
      "[82]\ttraining's binary_logloss: 0.585827\n",
      "[83]\ttraining's binary_logloss: 0.585753\n",
      "[84]\ttraining's binary_logloss: 0.585673\n",
      "[85]\ttraining's binary_logloss: 0.585621\n",
      "[86]\ttraining's binary_logloss: 0.585632\n",
      "[87]\ttraining's binary_logloss: 0.585609\n",
      "[88]\ttraining's binary_logloss: 0.585591\n",
      "[89]\ttraining's binary_logloss: 0.585591\n",
      "[90]\ttraining's binary_logloss: 0.585581\n",
      "[91]\ttraining's binary_logloss: 0.585574\n",
      "[92]\ttraining's binary_logloss: 0.585571\n",
      "[93]\ttraining's binary_logloss: 0.585571\n",
      "[94]\ttraining's binary_logloss: 0.585564\n",
      "[95]\ttraining's binary_logloss: 0.585571\n",
      "[96]\ttraining's binary_logloss: 0.585505\n",
      "[97]\ttraining's binary_logloss: 0.585444\n",
      "[98]\ttraining's binary_logloss: 0.585366\n",
      "[99]\ttraining's binary_logloss: 0.585292\n",
      "[100]\ttraining's binary_logloss: 0.58524\n",
      "[101]\ttraining's binary_logloss: 0.585275\n",
      "[102]\ttraining's binary_logloss: 0.585289\n",
      "[103]\ttraining's binary_logloss: 0.585307\n",
      "[104]\ttraining's binary_logloss: 0.585334\n",
      "[105]\ttraining's binary_logloss: 0.585352\n",
      "[106]\ttraining's binary_logloss: 0.585336\n",
      "[107]\ttraining's binary_logloss: 0.585307\n",
      "[108]\ttraining's binary_logloss: 0.585296\n",
      "[109]\ttraining's binary_logloss: 0.585274\n",
      "[110]\ttraining's binary_logloss: 0.585265\n",
      "[111]\ttraining's binary_logloss: 0.585328\n",
      "[112]\ttraining's binary_logloss: 0.585393\n",
      "[113]\ttraining's binary_logloss: 0.585405\n",
      "[114]\ttraining's binary_logloss: 0.5854\n",
      "[115]\ttraining's binary_logloss: 0.585393\n",
      "[116]\ttraining's binary_logloss: 0.585425\n",
      "[117]\ttraining's binary_logloss: 0.585499\n",
      "[118]\ttraining's binary_logloss: 0.585549\n",
      "[119]\ttraining's binary_logloss: 0.585586\n",
      "[120]\ttraining's binary_logloss: 0.585638\n",
      "[121]\ttraining's binary_logloss: 0.585654\n",
      "[122]\ttraining's binary_logloss: 0.585711\n",
      "[123]\ttraining's binary_logloss: 0.585677\n",
      "[124]\ttraining's binary_logloss: 0.585646\n",
      "[125]\ttraining's binary_logloss: 0.585623\n",
      "[126]\ttraining's binary_logloss: 0.58562\n",
      "[127]\ttraining's binary_logloss: 0.585628\n",
      "[128]\ttraining's binary_logloss: 0.585635\n",
      "[129]\ttraining's binary_logloss: 0.585641\n",
      "[130]\ttraining's binary_logloss: 0.585651\n",
      "[131]\ttraining's binary_logloss: 0.585645\n",
      "[132]\ttraining's binary_logloss: 0.585638\n",
      "[133]\ttraining's binary_logloss: 0.585633\n",
      "[134]\ttraining's binary_logloss: 0.585635\n",
      "[135]\ttraining's binary_logloss: 0.585615\n",
      "[136]\ttraining's binary_logloss: 0.585623\n",
      "[137]\ttraining's binary_logloss: 0.585636\n",
      "[138]\ttraining's binary_logloss: 0.585651\n",
      "[139]\ttraining's binary_logloss: 0.585682\n",
      "[140]\ttraining's binary_logloss: 0.5857\n",
      "[141]\ttraining's binary_logloss: 0.585692\n",
      "[142]\ttraining's binary_logloss: 0.585684\n",
      "[143]\ttraining's binary_logloss: 0.585682\n",
      "[144]\ttraining's binary_logloss: 0.585687\n",
      "[145]\ttraining's binary_logloss: 0.585735\n",
      "[146]\ttraining's binary_logloss: 0.58573\n",
      "[147]\ttraining's binary_logloss: 0.585729\n",
      "[148]\ttraining's binary_logloss: 0.58571\n",
      "[149]\ttraining's binary_logloss: 0.585735\n",
      "[150]\ttraining's binary_logloss: 0.585738\n",
      "[151]\ttraining's binary_logloss: 0.585728\n",
      "[152]\ttraining's binary_logloss: 0.585749\n",
      "[153]\ttraining's binary_logloss: 0.58574\n",
      "[154]\ttraining's binary_logloss: 0.585768\n",
      "[155]\ttraining's binary_logloss: 0.58576\n",
      "[156]\ttraining's binary_logloss: 0.585815\n",
      "[157]\ttraining's binary_logloss: 0.585858\n",
      "[158]\ttraining's binary_logloss: 0.585897\n",
      "[159]\ttraining's binary_logloss: 0.585931\n",
      "[160]\ttraining's binary_logloss: 0.585981\n",
      "[161]\ttraining's binary_logloss: 0.585965\n",
      "[162]\ttraining's binary_logloss: 0.585976\n",
      "[163]\ttraining's binary_logloss: 0.585956\n",
      "[164]\ttraining's binary_logloss: 0.585929\n",
      "[165]\ttraining's binary_logloss: 0.585907\n",
      "[166]\ttraining's binary_logloss: 0.585908\n",
      "[167]\ttraining's binary_logloss: 0.585901\n",
      "[168]\ttraining's binary_logloss: 0.585893\n",
      "[169]\ttraining's binary_logloss: 0.585897\n",
      "[170]\ttraining's binary_logloss: 0.585893\n",
      "[171]\ttraining's binary_logloss: 0.585918\n",
      "[172]\ttraining's binary_logloss: 0.585963\n",
      "[173]\ttraining's binary_logloss: 0.586022\n",
      "[174]\ttraining's binary_logloss: 0.586081\n",
      "[175]\ttraining's binary_logloss: 0.586109\n",
      "[176]\ttraining's binary_logloss: 0.586093\n",
      "[177]\ttraining's binary_logloss: 0.58608\n",
      "[178]\ttraining's binary_logloss: 0.586069\n",
      "[179]\ttraining's binary_logloss: 0.586073\n",
      "[180]\ttraining's binary_logloss: 0.586079\n",
      "[181]\ttraining's binary_logloss: 0.586088\n",
      "[182]\ttraining's binary_logloss: 0.586099\n",
      "[183]\ttraining's binary_logloss: 0.586099\n",
      "[184]\ttraining's binary_logloss: 0.586112\n",
      "[185]\ttraining's binary_logloss: 0.5861\n",
      "[186]\ttraining's binary_logloss: 0.586108\n",
      "[187]\ttraining's binary_logloss: 0.586118\n",
      "[188]\ttraining's binary_logloss: 0.586121\n",
      "[189]\ttraining's binary_logloss: 0.586128\n",
      "[190]\ttraining's binary_logloss: 0.586133\n",
      "[191]\ttraining's binary_logloss: 0.586145\n",
      "[192]\ttraining's binary_logloss: 0.586173\n",
      "[193]\ttraining's binary_logloss: 0.586196\n",
      "[194]\ttraining's binary_logloss: 0.586213\n",
      "[195]\ttraining's binary_logloss: 0.586228\n",
      "[196]\ttraining's binary_logloss: 0.586237\n",
      "[197]\ttraining's binary_logloss: 0.586247\n",
      "[198]\ttraining's binary_logloss: 0.586265\n",
      "[199]\ttraining's binary_logloss: 0.58625\n",
      "[200]\ttraining's binary_logloss: 0.58626\n",
      "[201]\ttraining's binary_logloss: 0.586249\n",
      "[202]\ttraining's binary_logloss: 0.586245\n",
      "[203]\ttraining's binary_logloss: 0.586248\n",
      "[204]\ttraining's binary_logloss: 0.586246\n",
      "[205]\ttraining's binary_logloss: 0.586241\n",
      "[206]\ttraining's binary_logloss: 0.586238\n",
      "[207]\ttraining's binary_logloss: 0.586233\n",
      "[208]\ttraining's binary_logloss: 0.586234\n",
      "[209]\ttraining's binary_logloss: 0.586234\n",
      "[210]\ttraining's binary_logloss: 0.586256\n",
      "[211]\ttraining's binary_logloss: 0.586225\n",
      "[212]\ttraining's binary_logloss: 0.586219\n",
      "[213]\ttraining's binary_logloss: 0.586206\n",
      "[214]\ttraining's binary_logloss: 0.586183\n",
      "[215]\ttraining's binary_logloss: 0.586171\n",
      "[216]\ttraining's binary_logloss: 0.586165\n",
      "[217]\ttraining's binary_logloss: 0.586129\n",
      "[218]\ttraining's binary_logloss: 0.586112\n",
      "[219]\ttraining's binary_logloss: 0.586081\n",
      "[220]\ttraining's binary_logloss: 0.586059\n",
      "[221]\ttraining's binary_logloss: 0.586016\n",
      "[222]\ttraining's binary_logloss: 0.586002\n",
      "[223]\ttraining's binary_logloss: 0.585962\n",
      "[224]\ttraining's binary_logloss: 0.585929\n",
      "[225]\ttraining's binary_logloss: 0.585894\n",
      "[226]\ttraining's binary_logloss: 0.5859\n",
      "[227]\ttraining's binary_logloss: 0.585907\n",
      "[228]\ttraining's binary_logloss: 0.585917\n",
      "[229]\ttraining's binary_logloss: 0.585927\n",
      "[230]\ttraining's binary_logloss: 0.585925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[231]\ttraining's binary_logloss: 0.585881\n",
      "[232]\ttraining's binary_logloss: 0.585841\n",
      "[233]\ttraining's binary_logloss: 0.585823\n",
      "[234]\ttraining's binary_logloss: 0.585773\n",
      "[235]\ttraining's binary_logloss: 0.585727\n",
      "[236]\ttraining's binary_logloss: 0.585703\n",
      "[237]\ttraining's binary_logloss: 0.585666\n",
      "[238]\ttraining's binary_logloss: 0.585649\n",
      "[239]\ttraining's binary_logloss: 0.585627\n",
      "[240]\ttraining's binary_logloss: 0.585606\n",
      "[241]\ttraining's binary_logloss: 0.585574\n",
      "[242]\ttraining's binary_logloss: 0.585535\n",
      "[243]\ttraining's binary_logloss: 0.585489\n",
      "[244]\ttraining's binary_logloss: 0.58546\n",
      "[245]\ttraining's binary_logloss: 0.585426\n",
      "[246]\ttraining's binary_logloss: 0.585373\n",
      "[247]\ttraining's binary_logloss: 0.58533\n",
      "[248]\ttraining's binary_logloss: 0.585279\n",
      "[249]\ttraining's binary_logloss: 0.585239\n",
      "[250]\ttraining's binary_logloss: 0.585173\n",
      "[251]\ttraining's binary_logloss: 0.585123\n",
      "[252]\ttraining's binary_logloss: 0.585089\n",
      "[253]\ttraining's binary_logloss: 0.585044\n",
      "[254]\ttraining's binary_logloss: 0.585023\n",
      "[255]\ttraining's binary_logloss: 0.584982\n",
      "[256]\ttraining's binary_logloss: 0.584986\n",
      "[257]\ttraining's binary_logloss: 0.584973\n",
      "[258]\ttraining's binary_logloss: 0.584966\n",
      "[259]\ttraining's binary_logloss: 0.584945\n",
      "[260]\ttraining's binary_logloss: 0.58494\n",
      "[261]\ttraining's binary_logloss: 0.584879\n",
      "[262]\ttraining's binary_logloss: 0.584815\n",
      "[263]\ttraining's binary_logloss: 0.584753\n",
      "[264]\ttraining's binary_logloss: 0.584665\n",
      "[265]\ttraining's binary_logloss: 0.584617\n",
      "[266]\ttraining's binary_logloss: 0.584548\n",
      "[267]\ttraining's binary_logloss: 0.584474\n",
      "[268]\ttraining's binary_logloss: 0.58441\n",
      "[269]\ttraining's binary_logloss: 0.584331\n",
      "[270]\ttraining's binary_logloss: 0.584249\n",
      "[271]\ttraining's binary_logloss: 0.584217\n",
      "[272]\ttraining's binary_logloss: 0.584191\n",
      "[273]\ttraining's binary_logloss: 0.58416\n",
      "[274]\ttraining's binary_logloss: 0.584134\n",
      "[275]\ttraining's binary_logloss: 0.584107\n",
      "[276]\ttraining's binary_logloss: 0.584103\n",
      "[277]\ttraining's binary_logloss: 0.584101\n",
      "[278]\ttraining's binary_logloss: 0.584074\n",
      "[279]\ttraining's binary_logloss: 0.584082\n",
      "[280]\ttraining's binary_logloss: 0.584071\n",
      "[281]\ttraining's binary_logloss: 0.58401\n",
      "[282]\ttraining's binary_logloss: 0.583952\n",
      "[283]\ttraining's binary_logloss: 0.583894\n",
      "[284]\ttraining's binary_logloss: 0.583836\n",
      "[285]\ttraining's binary_logloss: 0.583782\n",
      "[286]\ttraining's binary_logloss: 0.583698\n",
      "[287]\ttraining's binary_logloss: 0.583621\n",
      "[288]\ttraining's binary_logloss: 0.583544\n",
      "[289]\ttraining's binary_logloss: 0.583469\n",
      "[290]\ttraining's binary_logloss: 0.583395\n",
      "[291]\ttraining's binary_logloss: 0.583339\n",
      "[292]\ttraining's binary_logloss: 0.583298\n",
      "[293]\ttraining's binary_logloss: 0.583243\n",
      "[294]\ttraining's binary_logloss: 0.583189\n",
      "[295]\ttraining's binary_logloss: 0.583138\n",
      "[296]\ttraining's binary_logloss: 0.583086\n",
      "[297]\ttraining's binary_logloss: 0.583031\n",
      "[298]\ttraining's binary_logloss: 0.582982\n",
      "[299]\ttraining's binary_logloss: 0.582939\n",
      "[300]\ttraining's binary_logloss: 0.582885\n",
      "[301]\ttraining's binary_logloss: 0.582881\n",
      "[302]\ttraining's binary_logloss: 0.582879\n",
      "[303]\ttraining's binary_logloss: 0.582877\n",
      "[304]\ttraining's binary_logloss: 0.582877\n",
      "[305]\ttraining's binary_logloss: 0.582846\n",
      "[306]\ttraining's binary_logloss: 0.582801\n",
      "[307]\ttraining's binary_logloss: 0.582764\n",
      "[308]\ttraining's binary_logloss: 0.582731\n",
      "[309]\ttraining's binary_logloss: 0.58269\n",
      "[310]\ttraining's binary_logloss: 0.582658\n",
      "[311]\ttraining's binary_logloss: 0.582613\n",
      "[312]\ttraining's binary_logloss: 0.582578\n",
      "[313]\ttraining's binary_logloss: 0.582543\n",
      "[314]\ttraining's binary_logloss: 0.582504\n",
      "[315]\ttraining's binary_logloss: 0.58248\n",
      "[316]\ttraining's binary_logloss: 0.582381\n",
      "[317]\ttraining's binary_logloss: 0.582286\n",
      "[318]\ttraining's binary_logloss: 0.582194\n",
      "[319]\ttraining's binary_logloss: 0.582109\n",
      "[320]\ttraining's binary_logloss: 0.582025\n",
      "[321]\ttraining's binary_logloss: 0.581946\n",
      "[322]\ttraining's binary_logloss: 0.581869\n",
      "[323]\ttraining's binary_logloss: 0.581799\n",
      "[324]\ttraining's binary_logloss: 0.581731\n",
      "[325]\ttraining's binary_logloss: 0.581668\n",
      "[326]\ttraining's binary_logloss: 0.581585\n",
      "[327]\ttraining's binary_logloss: 0.581493\n",
      "[328]\ttraining's binary_logloss: 0.581418\n",
      "[329]\ttraining's binary_logloss: 0.581346\n",
      "[330]\ttraining's binary_logloss: 0.581279\n",
      "[331]\ttraining's binary_logloss: 0.581215\n",
      "[332]\ttraining's binary_logloss: 0.581155\n",
      "[333]\ttraining's binary_logloss: 0.581096\n",
      "[334]\ttraining's binary_logloss: 0.581027\n",
      "[335]\ttraining's binary_logloss: 0.580975\n",
      "[336]\ttraining's binary_logloss: 0.58092\n",
      "[337]\ttraining's binary_logloss: 0.580866\n",
      "[338]\ttraining's binary_logloss: 0.580812\n",
      "[339]\ttraining's binary_logloss: 0.580761\n",
      "[340]\ttraining's binary_logloss: 0.580707\n",
      "[341]\ttraining's binary_logloss: 0.58063\n",
      "[342]\ttraining's binary_logloss: 0.580555\n",
      "[343]\ttraining's binary_logloss: 0.580486\n",
      "[344]\ttraining's binary_logloss: 0.580416\n",
      "[345]\ttraining's binary_logloss: 0.580351\n",
      "[346]\ttraining's binary_logloss: 0.580281\n",
      "[347]\ttraining's binary_logloss: 0.580227\n",
      "[348]\ttraining's binary_logloss: 0.580163\n",
      "[349]\ttraining's binary_logloss: 0.580105\n",
      "[350]\ttraining's binary_logloss: 0.580058\n",
      "[351]\ttraining's binary_logloss: 0.579975\n",
      "[352]\ttraining's binary_logloss: 0.579889\n",
      "[353]\ttraining's binary_logloss: 0.579811\n",
      "[354]\ttraining's binary_logloss: 0.579731\n",
      "[355]\ttraining's binary_logloss: 0.579658\n",
      "[356]\ttraining's binary_logloss: 0.579593\n",
      "[357]\ttraining's binary_logloss: 0.579521\n",
      "[358]\ttraining's binary_logloss: 0.579466\n",
      "[359]\ttraining's binary_logloss: 0.579406\n",
      "[360]\ttraining's binary_logloss: 0.579345\n",
      "[361]\ttraining's binary_logloss: 0.579274\n",
      "[362]\ttraining's binary_logloss: 0.579208\n",
      "[363]\ttraining's binary_logloss: 0.579143\n",
      "[364]\ttraining's binary_logloss: 0.57908\n",
      "[365]\ttraining's binary_logloss: 0.579016\n",
      "[366]\ttraining's binary_logloss: 0.578956\n",
      "[367]\ttraining's binary_logloss: 0.578892\n",
      "[368]\ttraining's binary_logloss: 0.578824\n",
      "[369]\ttraining's binary_logloss: 0.578767\n",
      "[370]\ttraining's binary_logloss: 0.578715\n",
      "[371]\ttraining's binary_logloss: 0.578617\n",
      "[372]\ttraining's binary_logloss: 0.578528\n",
      "[373]\ttraining's binary_logloss: 0.57843\n",
      "[374]\ttraining's binary_logloss: 0.578334\n",
      "[375]\ttraining's binary_logloss: 0.578241\n",
      "[376]\ttraining's binary_logloss: 0.578167\n",
      "[377]\ttraining's binary_logloss: 0.578078\n",
      "[378]\ttraining's binary_logloss: 0.578004\n",
      "[379]\ttraining's binary_logloss: 0.577916\n",
      "[380]\ttraining's binary_logloss: 0.577835\n",
      "[381]\ttraining's binary_logloss: 0.577732\n",
      "[382]\ttraining's binary_logloss: 0.57764\n",
      "[383]\ttraining's binary_logloss: 0.57755\n",
      "[384]\ttraining's binary_logloss: 0.577456\n",
      "[385]\ttraining's binary_logloss: 0.577367\n",
      "[386]\ttraining's binary_logloss: 0.577315\n",
      "[387]\ttraining's binary_logloss: 0.577259\n",
      "[388]\ttraining's binary_logloss: 0.577209\n",
      "[389]\ttraining's binary_logloss: 0.577165\n",
      "[390]\ttraining's binary_logloss: 0.577109\n",
      "[391]\ttraining's binary_logloss: 0.57703\n",
      "[392]\ttraining's binary_logloss: 0.576937\n",
      "[393]\ttraining's binary_logloss: 0.576846\n",
      "[394]\ttraining's binary_logloss: 0.576744\n",
      "[395]\ttraining's binary_logloss: 0.576648\n",
      "[396]\ttraining's binary_logloss: 0.576566\n",
      "[397]\ttraining's binary_logloss: 0.576486\n",
      "[398]\ttraining's binary_logloss: 0.576401\n",
      "[399]\ttraining's binary_logloss: 0.576326\n",
      "[400]\ttraining's binary_logloss: 0.576248\n",
      "[401]\ttraining's binary_logloss: 0.57616\n",
      "[402]\ttraining's binary_logloss: 0.57607\n",
      "[403]\ttraining's binary_logloss: 0.576021\n",
      "[404]\ttraining's binary_logloss: 0.575936\n",
      "[405]\ttraining's binary_logloss: 0.575876\n",
      "[406]\ttraining's binary_logloss: 0.57579\n",
      "[407]\ttraining's binary_logloss: 0.575714\n",
      "[408]\ttraining's binary_logloss: 0.575637\n",
      "[409]\ttraining's binary_logloss: 0.575565\n",
      "[410]\ttraining's binary_logloss: 0.575477\n",
      "[411]\ttraining's binary_logloss: 0.575422\n",
      "[412]\ttraining's binary_logloss: 0.575371\n",
      "[413]\ttraining's binary_logloss: 0.575317\n",
      "[414]\ttraining's binary_logloss: 0.575253\n",
      "[415]\ttraining's binary_logloss: 0.575187\n",
      "[416]\ttraining's binary_logloss: 0.575107\n",
      "[417]\ttraining's binary_logloss: 0.575026\n",
      "[418]\ttraining's binary_logloss: 0.57495\n",
      "[419]\ttraining's binary_logloss: 0.574879\n",
      "[420]\ttraining's binary_logloss: 0.574804\n",
      "[421]\ttraining's binary_logloss: 0.574753\n",
      "[422]\ttraining's binary_logloss: 0.57469\n",
      "[423]\ttraining's binary_logloss: 0.574637\n",
      "[424]\ttraining's binary_logloss: 0.574597\n",
      "[425]\ttraining's binary_logloss: 0.574534\n",
      "[426]\ttraining's binary_logloss: 0.574448\n",
      "[427]\ttraining's binary_logloss: 0.574367\n",
      "[428]\ttraining's binary_logloss: 0.574291\n",
      "[429]\ttraining's binary_logloss: 0.574219\n",
      "[430]\ttraining's binary_logloss: 0.574156\n",
      "[431]\ttraining's binary_logloss: 0.574125\n",
      "[432]\ttraining's binary_logloss: 0.574082\n",
      "[433]\ttraining's binary_logloss: 0.574042\n",
      "[434]\ttraining's binary_logloss: 0.574001\n",
      "[435]\ttraining's binary_logloss: 0.573955\n",
      "[436]\ttraining's binary_logloss: 0.573827\n",
      "[437]\ttraining's binary_logloss: 0.573708\n",
      "[438]\ttraining's binary_logloss: 0.573587\n",
      "[439]\ttraining's binary_logloss: 0.573467\n",
      "[440]\ttraining's binary_logloss: 0.573349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[441]\ttraining's binary_logloss: 0.573271\n",
      "[442]\ttraining's binary_logloss: 0.573176\n",
      "[443]\ttraining's binary_logloss: 0.573094\n",
      "[444]\ttraining's binary_logloss: 0.573027\n",
      "[445]\ttraining's binary_logloss: 0.572961\n",
      "[446]\ttraining's binary_logloss: 0.57289\n",
      "[447]\ttraining's binary_logloss: 0.572825\n",
      "[448]\ttraining's binary_logloss: 0.572753\n",
      "[449]\ttraining's binary_logloss: 0.572691\n",
      "[450]\ttraining's binary_logloss: 0.572629\n",
      "[451]\ttraining's binary_logloss: 0.572549\n",
      "[452]\ttraining's binary_logloss: 0.572471\n",
      "[453]\ttraining's binary_logloss: 0.572402\n",
      "[454]\ttraining's binary_logloss: 0.572327\n",
      "[455]\ttraining's binary_logloss: 0.572269\n",
      "[456]\ttraining's binary_logloss: 0.572196\n",
      "[457]\ttraining's binary_logloss: 0.572122\n",
      "[458]\ttraining's binary_logloss: 0.572049\n",
      "[459]\ttraining's binary_logloss: 0.571981\n",
      "[460]\ttraining's binary_logloss: 0.571911\n",
      "[461]\ttraining's binary_logloss: 0.571808\n",
      "[462]\ttraining's binary_logloss: 0.571711\n",
      "[463]\ttraining's binary_logloss: 0.571619\n",
      "[464]\ttraining's binary_logloss: 0.571521\n",
      "[465]\ttraining's binary_logloss: 0.571417\n",
      "[466]\ttraining's binary_logloss: 0.571325\n",
      "[467]\ttraining's binary_logloss: 0.571232\n",
      "[468]\ttraining's binary_logloss: 0.571139\n",
      "[469]\ttraining's binary_logloss: 0.571043\n",
      "[470]\ttraining's binary_logloss: 0.57095\n",
      "[471]\ttraining's binary_logloss: 0.570857\n",
      "[472]\ttraining's binary_logloss: 0.570762\n",
      "[473]\ttraining's binary_logloss: 0.570667\n",
      "[474]\ttraining's binary_logloss: 0.570573\n",
      "[475]\ttraining's binary_logloss: 0.570492\n",
      "[476]\ttraining's binary_logloss: 0.57042\n",
      "[477]\ttraining's binary_logloss: 0.570362\n",
      "[478]\ttraining's binary_logloss: 0.570295\n",
      "[479]\ttraining's binary_logloss: 0.570237\n",
      "[480]\ttraining's binary_logloss: 0.570168\n",
      "[481]\ttraining's binary_logloss: 0.570104\n",
      "[482]\ttraining's binary_logloss: 0.570042\n",
      "[483]\ttraining's binary_logloss: 0.569982\n",
      "[484]\ttraining's binary_logloss: 0.569915\n",
      "[485]\ttraining's binary_logloss: 0.56986\n",
      "[486]\ttraining's binary_logloss: 0.569803\n",
      "[487]\ttraining's binary_logloss: 0.569721\n",
      "[488]\ttraining's binary_logloss: 0.569645\n",
      "[489]\ttraining's binary_logloss: 0.569558\n",
      "[490]\ttraining's binary_logloss: 0.5695\n",
      "[491]\ttraining's binary_logloss: 0.569413\n",
      "[492]\ttraining's binary_logloss: 0.56932\n",
      "[493]\ttraining's binary_logloss: 0.569243\n",
      "[494]\ttraining's binary_logloss: 0.569165\n",
      "[495]\ttraining's binary_logloss: 0.569091\n",
      "[496]\ttraining's binary_logloss: 0.569011\n",
      "[497]\ttraining's binary_logloss: 0.568923\n",
      "[498]\ttraining's binary_logloss: 0.568864\n",
      "[499]\ttraining's binary_logloss: 0.568793\n",
      "[500]\ttraining's binary_logloss: 0.568723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613243\n",
      "[2]\ttraining's binary_logloss: 0.612095\n",
      "[3]\ttraining's binary_logloss: 0.610991\n",
      "[4]\ttraining's binary_logloss: 0.609988\n",
      "[5]\ttraining's binary_logloss: 0.609047\n",
      "[6]\ttraining's binary_logloss: 0.608066\n",
      "[7]\ttraining's binary_logloss: 0.607095\n",
      "[8]\ttraining's binary_logloss: 0.606282\n",
      "[9]\ttraining's binary_logloss: 0.605407\n",
      "[10]\ttraining's binary_logloss: 0.604572\n",
      "[11]\ttraining's binary_logloss: 0.603733\n",
      "[12]\ttraining's binary_logloss: 0.602929\n",
      "[13]\ttraining's binary_logloss: 0.602164\n",
      "[14]\ttraining's binary_logloss: 0.601425\n",
      "[15]\ttraining's binary_logloss: 0.600727\n",
      "[16]\ttraining's binary_logloss: 0.599977\n",
      "[17]\ttraining's binary_logloss: 0.599258\n",
      "[18]\ttraining's binary_logloss: 0.598705\n",
      "[19]\ttraining's binary_logloss: 0.598128\n",
      "[20]\ttraining's binary_logloss: 0.597478\n",
      "[21]\ttraining's binary_logloss: 0.596858\n",
      "[22]\ttraining's binary_logloss: 0.596348\n",
      "[23]\ttraining's binary_logloss: 0.59578\n",
      "[24]\ttraining's binary_logloss: 0.59522\n",
      "[25]\ttraining's binary_logloss: 0.594687\n",
      "[26]\ttraining's binary_logloss: 0.594186\n",
      "[27]\ttraining's binary_logloss: 0.593699\n",
      "[28]\ttraining's binary_logloss: 0.593294\n",
      "[29]\ttraining's binary_logloss: 0.592846\n",
      "[30]\ttraining's binary_logloss: 0.592475\n",
      "[31]\ttraining's binary_logloss: 0.592052\n",
      "[32]\ttraining's binary_logloss: 0.591643\n",
      "[33]\ttraining's binary_logloss: 0.591238\n",
      "[34]\ttraining's binary_logloss: 0.590855\n",
      "[35]\ttraining's binary_logloss: 0.590499\n",
      "[36]\ttraining's binary_logloss: 0.5902\n",
      "[37]\ttraining's binary_logloss: 0.589919\n",
      "[38]\ttraining's binary_logloss: 0.58964\n",
      "[39]\ttraining's binary_logloss: 0.5894\n",
      "[40]\ttraining's binary_logloss: 0.589168\n",
      "[41]\ttraining's binary_logloss: 0.588835\n",
      "[42]\ttraining's binary_logloss: 0.588504\n",
      "[43]\ttraining's binary_logloss: 0.588197\n",
      "[44]\ttraining's binary_logloss: 0.587909\n",
      "[45]\ttraining's binary_logloss: 0.587633\n",
      "[46]\ttraining's binary_logloss: 0.587377\n",
      "[47]\ttraining's binary_logloss: 0.587159\n",
      "[48]\ttraining's binary_logloss: 0.586941\n",
      "[49]\ttraining's binary_logloss: 0.586735\n",
      "[50]\ttraining's binary_logloss: 0.586609\n",
      "[51]\ttraining's binary_logloss: 0.586398\n",
      "[52]\ttraining's binary_logloss: 0.586224\n",
      "[53]\ttraining's binary_logloss: 0.58603\n",
      "[54]\ttraining's binary_logloss: 0.585855\n",
      "[55]\ttraining's binary_logloss: 0.585712\n",
      "[56]\ttraining's binary_logloss: 0.585577\n",
      "[57]\ttraining's binary_logloss: 0.585455\n",
      "[58]\ttraining's binary_logloss: 0.585344\n",
      "[59]\ttraining's binary_logloss: 0.585247\n",
      "[60]\ttraining's binary_logloss: 0.585109\n",
      "[61]\ttraining's binary_logloss: 0.58502\n",
      "[62]\ttraining's binary_logloss: 0.58494\n",
      "[63]\ttraining's binary_logloss: 0.584819\n",
      "[64]\ttraining's binary_logloss: 0.584786\n",
      "[65]\ttraining's binary_logloss: 0.584713\n",
      "[66]\ttraining's binary_logloss: 0.584692\n",
      "[67]\ttraining's binary_logloss: 0.584689\n",
      "[68]\ttraining's binary_logloss: 0.584691\n",
      "[69]\ttraining's binary_logloss: 0.584688\n",
      "[70]\ttraining's binary_logloss: 0.58469\n",
      "[71]\ttraining's binary_logloss: 0.584602\n",
      "[72]\ttraining's binary_logloss: 0.584519\n",
      "[73]\ttraining's binary_logloss: 0.58444\n",
      "[74]\ttraining's binary_logloss: 0.584366\n",
      "[75]\ttraining's binary_logloss: 0.584291\n",
      "[76]\ttraining's binary_logloss: 0.584207\n",
      "[77]\ttraining's binary_logloss: 0.584174\n",
      "[78]\ttraining's binary_logloss: 0.58414\n",
      "[79]\ttraining's binary_logloss: 0.584089\n",
      "[80]\ttraining's binary_logloss: 0.584008\n",
      "[81]\ttraining's binary_logloss: 0.584063\n",
      "[82]\ttraining's binary_logloss: 0.583965\n",
      "[83]\ttraining's binary_logloss: 0.583878\n",
      "[84]\ttraining's binary_logloss: 0.583794\n",
      "[85]\ttraining's binary_logloss: 0.583725\n",
      "[86]\ttraining's binary_logloss: 0.583696\n",
      "[87]\ttraining's binary_logloss: 0.583682\n",
      "[88]\ttraining's binary_logloss: 0.583648\n",
      "[89]\ttraining's binary_logloss: 0.583618\n",
      "[90]\ttraining's binary_logloss: 0.583596\n",
      "[91]\ttraining's binary_logloss: 0.583598\n",
      "[92]\ttraining's binary_logloss: 0.583544\n",
      "[93]\ttraining's binary_logloss: 0.583567\n",
      "[94]\ttraining's binary_logloss: 0.583592\n",
      "[95]\ttraining's binary_logloss: 0.583606\n",
      "[96]\ttraining's binary_logloss: 0.583562\n",
      "[97]\ttraining's binary_logloss: 0.583524\n",
      "[98]\ttraining's binary_logloss: 0.583487\n",
      "[99]\ttraining's binary_logloss: 0.583451\n",
      "[100]\ttraining's binary_logloss: 0.583416\n",
      "[101]\ttraining's binary_logloss: 0.583417\n",
      "[102]\ttraining's binary_logloss: 0.5834\n",
      "[103]\ttraining's binary_logloss: 0.583386\n",
      "[104]\ttraining's binary_logloss: 0.583382\n",
      "[105]\ttraining's binary_logloss: 0.583392\n",
      "[106]\ttraining's binary_logloss: 0.583363\n",
      "[107]\ttraining's binary_logloss: 0.583338\n",
      "[108]\ttraining's binary_logloss: 0.583319\n",
      "[109]\ttraining's binary_logloss: 0.583303\n",
      "[110]\ttraining's binary_logloss: 0.583331\n",
      "[111]\ttraining's binary_logloss: 0.583342\n",
      "[112]\ttraining's binary_logloss: 0.583376\n",
      "[113]\ttraining's binary_logloss: 0.583368\n",
      "[114]\ttraining's binary_logloss: 0.58336\n",
      "[115]\ttraining's binary_logloss: 0.583396\n",
      "[116]\ttraining's binary_logloss: 0.583397\n",
      "[117]\ttraining's binary_logloss: 0.583399\n",
      "[118]\ttraining's binary_logloss: 0.583374\n",
      "[119]\ttraining's binary_logloss: 0.583381\n",
      "[120]\ttraining's binary_logloss: 0.583423\n",
      "[121]\ttraining's binary_logloss: 0.583416\n",
      "[122]\ttraining's binary_logloss: 0.583449\n",
      "[123]\ttraining's binary_logloss: 0.58341\n",
      "[124]\ttraining's binary_logloss: 0.583374\n",
      "[125]\ttraining's binary_logloss: 0.583343\n",
      "[126]\ttraining's binary_logloss: 0.583359\n",
      "[127]\ttraining's binary_logloss: 0.58336\n",
      "[128]\ttraining's binary_logloss: 0.583375\n",
      "[129]\ttraining's binary_logloss: 0.583398\n",
      "[130]\ttraining's binary_logloss: 0.58342\n",
      "[131]\ttraining's binary_logloss: 0.58341\n",
      "[132]\ttraining's binary_logloss: 0.583395\n",
      "[133]\ttraining's binary_logloss: 0.583386\n",
      "[134]\ttraining's binary_logloss: 0.583377\n",
      "[135]\ttraining's binary_logloss: 0.583368\n",
      "[136]\ttraining's binary_logloss: 0.583372\n",
      "[137]\ttraining's binary_logloss: 0.583361\n",
      "[138]\ttraining's binary_logloss: 0.583353\n",
      "[139]\ttraining's binary_logloss: 0.58338\n",
      "[140]\ttraining's binary_logloss: 0.583375\n",
      "[141]\ttraining's binary_logloss: 0.583361\n",
      "[142]\ttraining's binary_logloss: 0.583361\n",
      "[143]\ttraining's binary_logloss: 0.583365\n",
      "[144]\ttraining's binary_logloss: 0.583372\n",
      "[145]\ttraining's binary_logloss: 0.583382\n",
      "[146]\ttraining's binary_logloss: 0.583413\n",
      "[147]\ttraining's binary_logloss: 0.583412\n",
      "[148]\ttraining's binary_logloss: 0.583441\n",
      "[149]\ttraining's binary_logloss: 0.583461\n",
      "[150]\ttraining's binary_logloss: 0.583487\n",
      "[151]\ttraining's binary_logloss: 0.583502\n",
      "[152]\ttraining's binary_logloss: 0.583519\n",
      "[153]\ttraining's binary_logloss: 0.583536\n",
      "[154]\ttraining's binary_logloss: 0.583556\n",
      "[155]\ttraining's binary_logloss: 0.583582\n",
      "[156]\ttraining's binary_logloss: 0.583605\n",
      "[157]\ttraining's binary_logloss: 0.583638\n",
      "[158]\ttraining's binary_logloss: 0.583656\n",
      "[159]\ttraining's binary_logloss: 0.58368\n",
      "[160]\ttraining's binary_logloss: 0.583682\n",
      "[161]\ttraining's binary_logloss: 0.583655\n",
      "[162]\ttraining's binary_logloss: 0.583677\n",
      "[163]\ttraining's binary_logloss: 0.583649\n",
      "[164]\ttraining's binary_logloss: 0.583615\n",
      "[165]\ttraining's binary_logloss: 0.583584\n",
      "[166]\ttraining's binary_logloss: 0.583593\n",
      "[167]\ttraining's binary_logloss: 0.583617\n",
      "[168]\ttraining's binary_logloss: 0.583629\n",
      "[169]\ttraining's binary_logloss: 0.583657\n",
      "[170]\ttraining's binary_logloss: 0.583686\n",
      "[171]\ttraining's binary_logloss: 0.583696\n",
      "[172]\ttraining's binary_logloss: 0.583713\n",
      "[173]\ttraining's binary_logloss: 0.583731\n",
      "[174]\ttraining's binary_logloss: 0.583752\n",
      "[175]\ttraining's binary_logloss: 0.583774\n",
      "[176]\ttraining's binary_logloss: 0.583754\n",
      "[177]\ttraining's binary_logloss: 0.583736\n",
      "[178]\ttraining's binary_logloss: 0.583721\n",
      "[179]\ttraining's binary_logloss: 0.5837\n",
      "[180]\ttraining's binary_logloss: 0.583674\n",
      "[181]\ttraining's binary_logloss: 0.583691\n",
      "[182]\ttraining's binary_logloss: 0.583711\n",
      "[183]\ttraining's binary_logloss: 0.583732\n",
      "[184]\ttraining's binary_logloss: 0.583758\n",
      "[185]\ttraining's binary_logloss: 0.583774\n",
      "[186]\ttraining's binary_logloss: 0.583743\n",
      "[187]\ttraining's binary_logloss: 0.583714\n",
      "[188]\ttraining's binary_logloss: 0.583687\n",
      "[189]\ttraining's binary_logloss: 0.583657\n",
      "[190]\ttraining's binary_logloss: 0.583641\n",
      "[191]\ttraining's binary_logloss: 0.583655\n",
      "[192]\ttraining's binary_logloss: 0.583671\n",
      "[193]\ttraining's binary_logloss: 0.583684\n",
      "[194]\ttraining's binary_logloss: 0.583695\n",
      "[195]\ttraining's binary_logloss: 0.58371\n",
      "[196]\ttraining's binary_logloss: 0.583711\n",
      "[197]\ttraining's binary_logloss: 0.583695\n",
      "[198]\ttraining's binary_logloss: 0.583695\n",
      "[199]\ttraining's binary_logloss: 0.583687\n",
      "[200]\ttraining's binary_logloss: 0.583675\n",
      "[201]\ttraining's binary_logloss: 0.583647\n",
      "[202]\ttraining's binary_logloss: 0.583623\n",
      "[203]\ttraining's binary_logloss: 0.583599\n",
      "[204]\ttraining's binary_logloss: 0.583582\n",
      "[205]\ttraining's binary_logloss: 0.583562\n",
      "[206]\ttraining's binary_logloss: 0.583574\n",
      "[207]\ttraining's binary_logloss: 0.583588\n",
      "[208]\ttraining's binary_logloss: 0.583601\n",
      "[209]\ttraining's binary_logloss: 0.583582\n",
      "[210]\ttraining's binary_logloss: 0.58359\n",
      "[211]\ttraining's binary_logloss: 0.583571\n",
      "[212]\ttraining's binary_logloss: 0.583569\n",
      "[213]\ttraining's binary_logloss: 0.583566\n",
      "[214]\ttraining's binary_logloss: 0.583557\n",
      "[215]\ttraining's binary_logloss: 0.583544\n",
      "[216]\ttraining's binary_logloss: 0.583515\n",
      "[217]\ttraining's binary_logloss: 0.583497\n",
      "[218]\ttraining's binary_logloss: 0.583501\n",
      "[219]\ttraining's binary_logloss: 0.583485\n",
      "[220]\ttraining's binary_logloss: 0.583469\n",
      "[221]\ttraining's binary_logloss: 0.583405\n",
      "[222]\ttraining's binary_logloss: 0.583352\n",
      "[223]\ttraining's binary_logloss: 0.583289\n",
      "[224]\ttraining's binary_logloss: 0.58323\n",
      "[225]\ttraining's binary_logloss: 0.583163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[226]\ttraining's binary_logloss: 0.583159\n",
      "[227]\ttraining's binary_logloss: 0.583156\n",
      "[228]\ttraining's binary_logloss: 0.583144\n",
      "[229]\ttraining's binary_logloss: 0.583135\n",
      "[230]\ttraining's binary_logloss: 0.583119\n",
      "[231]\ttraining's binary_logloss: 0.583101\n",
      "[232]\ttraining's binary_logloss: 0.583083\n",
      "[233]\ttraining's binary_logloss: 0.583088\n",
      "[234]\ttraining's binary_logloss: 0.583072\n",
      "[235]\ttraining's binary_logloss: 0.583063\n",
      "[236]\ttraining's binary_logloss: 0.58305\n",
      "[237]\ttraining's binary_logloss: 0.583052\n",
      "[238]\ttraining's binary_logloss: 0.583037\n",
      "[239]\ttraining's binary_logloss: 0.583026\n",
      "[240]\ttraining's binary_logloss: 0.583008\n",
      "[241]\ttraining's binary_logloss: 0.582964\n",
      "[242]\ttraining's binary_logloss: 0.582932\n",
      "[243]\ttraining's binary_logloss: 0.582895\n",
      "[244]\ttraining's binary_logloss: 0.582847\n",
      "[245]\ttraining's binary_logloss: 0.582819\n",
      "[246]\ttraining's binary_logloss: 0.582766\n",
      "[247]\ttraining's binary_logloss: 0.582712\n",
      "[248]\ttraining's binary_logloss: 0.58269\n",
      "[249]\ttraining's binary_logloss: 0.58264\n",
      "[250]\ttraining's binary_logloss: 0.582592\n",
      "[251]\ttraining's binary_logloss: 0.582556\n",
      "[252]\ttraining's binary_logloss: 0.58253\n",
      "[253]\ttraining's binary_logloss: 0.582507\n",
      "[254]\ttraining's binary_logloss: 0.58249\n",
      "[255]\ttraining's binary_logloss: 0.58247\n",
      "[256]\ttraining's binary_logloss: 0.582445\n",
      "[257]\ttraining's binary_logloss: 0.582423\n",
      "[258]\ttraining's binary_logloss: 0.582395\n",
      "[259]\ttraining's binary_logloss: 0.58235\n",
      "[260]\ttraining's binary_logloss: 0.58233\n",
      "[261]\ttraining's binary_logloss: 0.582292\n",
      "[262]\ttraining's binary_logloss: 0.582256\n",
      "[263]\ttraining's binary_logloss: 0.582225\n",
      "[264]\ttraining's binary_logloss: 0.58217\n",
      "[265]\ttraining's binary_logloss: 0.582153\n",
      "[266]\ttraining's binary_logloss: 0.582083\n",
      "[267]\ttraining's binary_logloss: 0.582007\n",
      "[268]\ttraining's binary_logloss: 0.581942\n",
      "[269]\ttraining's binary_logloss: 0.581867\n",
      "[270]\ttraining's binary_logloss: 0.581792\n",
      "[271]\ttraining's binary_logloss: 0.581733\n",
      "[272]\ttraining's binary_logloss: 0.581676\n",
      "[273]\ttraining's binary_logloss: 0.581618\n",
      "[274]\ttraining's binary_logloss: 0.581563\n",
      "[275]\ttraining's binary_logloss: 0.581533\n",
      "[276]\ttraining's binary_logloss: 0.5815\n",
      "[277]\ttraining's binary_logloss: 0.581474\n",
      "[278]\ttraining's binary_logloss: 0.581446\n",
      "[279]\ttraining's binary_logloss: 0.581417\n",
      "[280]\ttraining's binary_logloss: 0.581392\n",
      "[281]\ttraining's binary_logloss: 0.581334\n",
      "[282]\ttraining's binary_logloss: 0.581276\n",
      "[283]\ttraining's binary_logloss: 0.581221\n",
      "[284]\ttraining's binary_logloss: 0.581166\n",
      "[285]\ttraining's binary_logloss: 0.581115\n",
      "[286]\ttraining's binary_logloss: 0.581031\n",
      "[287]\ttraining's binary_logloss: 0.580956\n",
      "[288]\ttraining's binary_logloss: 0.580876\n",
      "[289]\ttraining's binary_logloss: 0.580807\n",
      "[290]\ttraining's binary_logloss: 0.580732\n",
      "[291]\ttraining's binary_logloss: 0.580678\n",
      "[292]\ttraining's binary_logloss: 0.580619\n",
      "[293]\ttraining's binary_logloss: 0.580559\n",
      "[294]\ttraining's binary_logloss: 0.580482\n",
      "[295]\ttraining's binary_logloss: 0.580409\n",
      "[296]\ttraining's binary_logloss: 0.580306\n",
      "[297]\ttraining's binary_logloss: 0.580205\n",
      "[298]\ttraining's binary_logloss: 0.580106\n",
      "[299]\ttraining's binary_logloss: 0.580013\n",
      "[300]\ttraining's binary_logloss: 0.579937\n",
      "[301]\ttraining's binary_logloss: 0.579936\n",
      "[302]\ttraining's binary_logloss: 0.579941\n",
      "[303]\ttraining's binary_logloss: 0.579948\n",
      "[304]\ttraining's binary_logloss: 0.579947\n",
      "[305]\ttraining's binary_logloss: 0.579949\n",
      "[306]\ttraining's binary_logloss: 0.579911\n",
      "[307]\ttraining's binary_logloss: 0.579853\n",
      "[308]\ttraining's binary_logloss: 0.579794\n",
      "[309]\ttraining's binary_logloss: 0.579728\n",
      "[310]\ttraining's binary_logloss: 0.579682\n",
      "[311]\ttraining's binary_logloss: 0.579648\n",
      "[312]\ttraining's binary_logloss: 0.579614\n",
      "[313]\ttraining's binary_logloss: 0.579581\n",
      "[314]\ttraining's binary_logloss: 0.57955\n",
      "[315]\ttraining's binary_logloss: 0.57952\n",
      "[316]\ttraining's binary_logloss: 0.579446\n",
      "[317]\ttraining's binary_logloss: 0.579373\n",
      "[318]\ttraining's binary_logloss: 0.579282\n",
      "[319]\ttraining's binary_logloss: 0.579206\n",
      "[320]\ttraining's binary_logloss: 0.579125\n",
      "[321]\ttraining's binary_logloss: 0.579069\n",
      "[322]\ttraining's binary_logloss: 0.579012\n",
      "[323]\ttraining's binary_logloss: 0.578959\n",
      "[324]\ttraining's binary_logloss: 0.578909\n",
      "[325]\ttraining's binary_logloss: 0.57886\n",
      "[326]\ttraining's binary_logloss: 0.578771\n",
      "[327]\ttraining's binary_logloss: 0.578678\n",
      "[328]\ttraining's binary_logloss: 0.578584\n",
      "[329]\ttraining's binary_logloss: 0.578489\n",
      "[330]\ttraining's binary_logloss: 0.578369\n",
      "[331]\ttraining's binary_logloss: 0.5783\n",
      "[332]\ttraining's binary_logloss: 0.578233\n",
      "[333]\ttraining's binary_logloss: 0.578155\n",
      "[334]\ttraining's binary_logloss: 0.578092\n",
      "[335]\ttraining's binary_logloss: 0.578003\n",
      "[336]\ttraining's binary_logloss: 0.577934\n",
      "[337]\ttraining's binary_logloss: 0.577859\n",
      "[338]\ttraining's binary_logloss: 0.577798\n",
      "[339]\ttraining's binary_logloss: 0.577723\n",
      "[340]\ttraining's binary_logloss: 0.577664\n",
      "[341]\ttraining's binary_logloss: 0.577598\n",
      "[342]\ttraining's binary_logloss: 0.577532\n",
      "[343]\ttraining's binary_logloss: 0.577473\n",
      "[344]\ttraining's binary_logloss: 0.577409\n",
      "[345]\ttraining's binary_logloss: 0.577344\n",
      "[346]\ttraining's binary_logloss: 0.577321\n",
      "[347]\ttraining's binary_logloss: 0.577297\n",
      "[348]\ttraining's binary_logloss: 0.577274\n",
      "[349]\ttraining's binary_logloss: 0.577245\n",
      "[350]\ttraining's binary_logloss: 0.577182\n",
      "[351]\ttraining's binary_logloss: 0.577098\n",
      "[352]\ttraining's binary_logloss: 0.577004\n",
      "[353]\ttraining's binary_logloss: 0.576909\n",
      "[354]\ttraining's binary_logloss: 0.576837\n",
      "[355]\ttraining's binary_logloss: 0.576753\n",
      "[356]\ttraining's binary_logloss: 0.576705\n",
      "[357]\ttraining's binary_logloss: 0.576623\n",
      "[358]\ttraining's binary_logloss: 0.576574\n",
      "[359]\ttraining's binary_logloss: 0.5765\n",
      "[360]\ttraining's binary_logloss: 0.576431\n",
      "[361]\ttraining's binary_logloss: 0.576331\n",
      "[362]\ttraining's binary_logloss: 0.576259\n",
      "[363]\ttraining's binary_logloss: 0.576165\n",
      "[364]\ttraining's binary_logloss: 0.576096\n",
      "[365]\ttraining's binary_logloss: 0.576019\n",
      "[366]\ttraining's binary_logloss: 0.575955\n",
      "[367]\ttraining's binary_logloss: 0.575875\n",
      "[368]\ttraining's binary_logloss: 0.575807\n",
      "[369]\ttraining's binary_logloss: 0.575744\n",
      "[370]\ttraining's binary_logloss: 0.575676\n",
      "[371]\ttraining's binary_logloss: 0.575614\n",
      "[372]\ttraining's binary_logloss: 0.575551\n",
      "[373]\ttraining's binary_logloss: 0.575483\n",
      "[374]\ttraining's binary_logloss: 0.575414\n",
      "[375]\ttraining's binary_logloss: 0.575352\n",
      "[376]\ttraining's binary_logloss: 0.57528\n",
      "[377]\ttraining's binary_logloss: 0.575209\n",
      "[378]\ttraining's binary_logloss: 0.575136\n",
      "[379]\ttraining's binary_logloss: 0.575065\n",
      "[380]\ttraining's binary_logloss: 0.575001\n",
      "[381]\ttraining's binary_logloss: 0.574917\n",
      "[382]\ttraining's binary_logloss: 0.574802\n",
      "[383]\ttraining's binary_logloss: 0.574715\n",
      "[384]\ttraining's binary_logloss: 0.574636\n",
      "[385]\ttraining's binary_logloss: 0.574559\n",
      "[386]\ttraining's binary_logloss: 0.57451\n",
      "[387]\ttraining's binary_logloss: 0.574464\n",
      "[388]\ttraining's binary_logloss: 0.574405\n",
      "[389]\ttraining's binary_logloss: 0.574346\n",
      "[390]\ttraining's binary_logloss: 0.574305\n",
      "[391]\ttraining's binary_logloss: 0.574206\n",
      "[392]\ttraining's binary_logloss: 0.574114\n",
      "[393]\ttraining's binary_logloss: 0.574021\n",
      "[394]\ttraining's binary_logloss: 0.573929\n",
      "[395]\ttraining's binary_logloss: 0.573845\n",
      "[396]\ttraining's binary_logloss: 0.573772\n",
      "[397]\ttraining's binary_logloss: 0.5737\n",
      "[398]\ttraining's binary_logloss: 0.573622\n",
      "[399]\ttraining's binary_logloss: 0.573566\n",
      "[400]\ttraining's binary_logloss: 0.573489\n",
      "[401]\ttraining's binary_logloss: 0.573419\n",
      "[402]\ttraining's binary_logloss: 0.573341\n",
      "[403]\ttraining's binary_logloss: 0.573268\n",
      "[404]\ttraining's binary_logloss: 0.573186\n",
      "[405]\ttraining's binary_logloss: 0.573101\n",
      "[406]\ttraining's binary_logloss: 0.573031\n",
      "[407]\ttraining's binary_logloss: 0.572948\n",
      "[408]\ttraining's binary_logloss: 0.572877\n",
      "[409]\ttraining's binary_logloss: 0.572781\n",
      "[410]\ttraining's binary_logloss: 0.572698\n",
      "[411]\ttraining's binary_logloss: 0.572648\n",
      "[412]\ttraining's binary_logloss: 0.572579\n",
      "[413]\ttraining's binary_logloss: 0.572512\n",
      "[414]\ttraining's binary_logloss: 0.572451\n",
      "[415]\ttraining's binary_logloss: 0.572376\n",
      "[416]\ttraining's binary_logloss: 0.572301\n",
      "[417]\ttraining's binary_logloss: 0.572205\n",
      "[418]\ttraining's binary_logloss: 0.572131\n",
      "[419]\ttraining's binary_logloss: 0.57204\n",
      "[420]\ttraining's binary_logloss: 0.571968\n",
      "[421]\ttraining's binary_logloss: 0.571919\n",
      "[422]\ttraining's binary_logloss: 0.571846\n",
      "[423]\ttraining's binary_logloss: 0.571802\n",
      "[424]\ttraining's binary_logloss: 0.571744\n",
      "[425]\ttraining's binary_logloss: 0.571673\n",
      "[426]\ttraining's binary_logloss: 0.571616\n",
      "[427]\ttraining's binary_logloss: 0.571544\n",
      "[428]\ttraining's binary_logloss: 0.571492\n",
      "[429]\ttraining's binary_logloss: 0.571446\n",
      "[430]\ttraining's binary_logloss: 0.571394\n",
      "[431]\ttraining's binary_logloss: 0.571373\n",
      "[432]\ttraining's binary_logloss: 0.571333\n",
      "[433]\ttraining's binary_logloss: 0.571292\n",
      "[434]\ttraining's binary_logloss: 0.571244\n",
      "[435]\ttraining's binary_logloss: 0.5712\n",
      "[436]\ttraining's binary_logloss: 0.571064\n",
      "[437]\ttraining's binary_logloss: 0.570933\n",
      "[438]\ttraining's binary_logloss: 0.570809\n",
      "[439]\ttraining's binary_logloss: 0.57068\n",
      "[440]\ttraining's binary_logloss: 0.570557\n",
      "[441]\ttraining's binary_logloss: 0.570475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[442]\ttraining's binary_logloss: 0.570396\n",
      "[443]\ttraining's binary_logloss: 0.570318\n",
      "[444]\ttraining's binary_logloss: 0.570231\n",
      "[445]\ttraining's binary_logloss: 0.570132\n",
      "[446]\ttraining's binary_logloss: 0.570052\n",
      "[447]\ttraining's binary_logloss: 0.569979\n",
      "[448]\ttraining's binary_logloss: 0.569903\n",
      "[449]\ttraining's binary_logloss: 0.569827\n",
      "[450]\ttraining's binary_logloss: 0.569768\n",
      "[451]\ttraining's binary_logloss: 0.569709\n",
      "[452]\ttraining's binary_logloss: 0.569661\n",
      "[453]\ttraining's binary_logloss: 0.569602\n",
      "[454]\ttraining's binary_logloss: 0.56953\n",
      "[455]\ttraining's binary_logloss: 0.569483\n",
      "[456]\ttraining's binary_logloss: 0.569399\n",
      "[457]\ttraining's binary_logloss: 0.569329\n",
      "[458]\ttraining's binary_logloss: 0.569247\n",
      "[459]\ttraining's binary_logloss: 0.569172\n",
      "[460]\ttraining's binary_logloss: 0.569107\n",
      "[461]\ttraining's binary_logloss: 0.569015\n",
      "[462]\ttraining's binary_logloss: 0.568907\n",
      "[463]\ttraining's binary_logloss: 0.568814\n",
      "[464]\ttraining's binary_logloss: 0.568727\n",
      "[465]\ttraining's binary_logloss: 0.568614\n",
      "[466]\ttraining's binary_logloss: 0.56852\n",
      "[467]\ttraining's binary_logloss: 0.568446\n",
      "[468]\ttraining's binary_logloss: 0.568347\n",
      "[469]\ttraining's binary_logloss: 0.568266\n",
      "[470]\ttraining's binary_logloss: 0.568159\n",
      "[471]\ttraining's binary_logloss: 0.568093\n",
      "[472]\ttraining's binary_logloss: 0.567998\n",
      "[473]\ttraining's binary_logloss: 0.567932\n",
      "[474]\ttraining's binary_logloss: 0.567861\n",
      "[475]\ttraining's binary_logloss: 0.5678\n",
      "[476]\ttraining's binary_logloss: 0.567719\n",
      "[477]\ttraining's binary_logloss: 0.567651\n",
      "[478]\ttraining's binary_logloss: 0.567574\n",
      "[479]\ttraining's binary_logloss: 0.567504\n",
      "[480]\ttraining's binary_logloss: 0.567447\n",
      "[481]\ttraining's binary_logloss: 0.567379\n",
      "[482]\ttraining's binary_logloss: 0.567305\n",
      "[483]\ttraining's binary_logloss: 0.567234\n",
      "[484]\ttraining's binary_logloss: 0.567168\n",
      "[485]\ttraining's binary_logloss: 0.567106\n",
      "[486]\ttraining's binary_logloss: 0.567006\n",
      "[487]\ttraining's binary_logloss: 0.56691\n",
      "[488]\ttraining's binary_logloss: 0.566823\n",
      "[489]\ttraining's binary_logloss: 0.566724\n",
      "[490]\ttraining's binary_logloss: 0.566628\n",
      "[491]\ttraining's binary_logloss: 0.566533\n",
      "[492]\ttraining's binary_logloss: 0.566446\n",
      "[493]\ttraining's binary_logloss: 0.566362\n",
      "[494]\ttraining's binary_logloss: 0.566277\n",
      "[495]\ttraining's binary_logloss: 0.566187\n",
      "[496]\ttraining's binary_logloss: 0.566109\n",
      "[497]\ttraining's binary_logloss: 0.56605\n",
      "[498]\ttraining's binary_logloss: 0.565979\n",
      "[499]\ttraining's binary_logloss: 0.56591\n",
      "[500]\ttraining's binary_logloss: 0.565836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.61551\n",
      "[2]\ttraining's binary_logloss: 0.61451\n",
      "[3]\ttraining's binary_logloss: 0.613525\n",
      "[4]\ttraining's binary_logloss: 0.612447\n",
      "[5]\ttraining's binary_logloss: 0.611445\n",
      "[6]\ttraining's binary_logloss: 0.610449\n",
      "[7]\ttraining's binary_logloss: 0.609609\n",
      "[8]\ttraining's binary_logloss: 0.608687\n",
      "[9]\ttraining's binary_logloss: 0.607791\n",
      "[10]\ttraining's binary_logloss: 0.606927\n",
      "[11]\ttraining's binary_logloss: 0.606118\n",
      "[12]\ttraining's binary_logloss: 0.605259\n",
      "[13]\ttraining's binary_logloss: 0.604435\n",
      "[14]\ttraining's binary_logloss: 0.603662\n",
      "[15]\ttraining's binary_logloss: 0.602926\n",
      "[16]\ttraining's binary_logloss: 0.602111\n",
      "[17]\ttraining's binary_logloss: 0.601444\n",
      "[18]\ttraining's binary_logloss: 0.600757\n",
      "[19]\ttraining's binary_logloss: 0.600099\n",
      "[20]\ttraining's binary_logloss: 0.599475\n",
      "[21]\ttraining's binary_logloss: 0.598823\n",
      "[22]\ttraining's binary_logloss: 0.598274\n",
      "[23]\ttraining's binary_logloss: 0.597666\n",
      "[24]\ttraining's binary_logloss: 0.597158\n",
      "[25]\ttraining's binary_logloss: 0.596591\n",
      "[26]\ttraining's binary_logloss: 0.596157\n",
      "[27]\ttraining's binary_logloss: 0.595698\n",
      "[28]\ttraining's binary_logloss: 0.595256\n",
      "[29]\ttraining's binary_logloss: 0.594833\n",
      "[30]\ttraining's binary_logloss: 0.594506\n",
      "[31]\ttraining's binary_logloss: 0.594054\n",
      "[32]\ttraining's binary_logloss: 0.593587\n",
      "[33]\ttraining's binary_logloss: 0.593173\n",
      "[34]\ttraining's binary_logloss: 0.59269\n",
      "[35]\ttraining's binary_logloss: 0.592219\n",
      "[36]\ttraining's binary_logloss: 0.591963\n",
      "[37]\ttraining's binary_logloss: 0.591625\n",
      "[38]\ttraining's binary_logloss: 0.591404\n",
      "[39]\ttraining's binary_logloss: 0.591097\n",
      "[40]\ttraining's binary_logloss: 0.590834\n",
      "[41]\ttraining's binary_logloss: 0.590496\n",
      "[42]\ttraining's binary_logloss: 0.590191\n",
      "[43]\ttraining's binary_logloss: 0.589896\n",
      "[44]\ttraining's binary_logloss: 0.589615\n",
      "[45]\ttraining's binary_logloss: 0.58933\n",
      "[46]\ttraining's binary_logloss: 0.589038\n",
      "[47]\ttraining's binary_logloss: 0.588761\n",
      "[48]\ttraining's binary_logloss: 0.588497\n",
      "[49]\ttraining's binary_logloss: 0.588242\n",
      "[50]\ttraining's binary_logloss: 0.588011\n",
      "[51]\ttraining's binary_logloss: 0.587789\n",
      "[52]\ttraining's binary_logloss: 0.58758\n",
      "[53]\ttraining's binary_logloss: 0.587384\n",
      "[54]\ttraining's binary_logloss: 0.587247\n",
      "[55]\ttraining's binary_logloss: 0.587157\n",
      "[56]\ttraining's binary_logloss: 0.586976\n",
      "[57]\ttraining's binary_logloss: 0.586813\n",
      "[58]\ttraining's binary_logloss: 0.586658\n",
      "[59]\ttraining's binary_logloss: 0.586513\n",
      "[60]\ttraining's binary_logloss: 0.586375\n",
      "[61]\ttraining's binary_logloss: 0.586215\n",
      "[62]\ttraining's binary_logloss: 0.586064\n",
      "[63]\ttraining's binary_logloss: 0.58593\n",
      "[64]\ttraining's binary_logloss: 0.585862\n",
      "[65]\ttraining's binary_logloss: 0.585747\n",
      "[66]\ttraining's binary_logloss: 0.585672\n",
      "[67]\ttraining's binary_logloss: 0.585599\n",
      "[68]\ttraining's binary_logloss: 0.585539\n",
      "[69]\ttraining's binary_logloss: 0.58547\n",
      "[70]\ttraining's binary_logloss: 0.585424\n",
      "[71]\ttraining's binary_logloss: 0.585301\n",
      "[72]\ttraining's binary_logloss: 0.585181\n",
      "[73]\ttraining's binary_logloss: 0.585079\n",
      "[74]\ttraining's binary_logloss: 0.585015\n",
      "[75]\ttraining's binary_logloss: 0.584954\n",
      "[76]\ttraining's binary_logloss: 0.584957\n",
      "[77]\ttraining's binary_logloss: 0.584871\n",
      "[78]\ttraining's binary_logloss: 0.584793\n",
      "[79]\ttraining's binary_logloss: 0.584717\n",
      "[80]\ttraining's binary_logloss: 0.584657\n",
      "[81]\ttraining's binary_logloss: 0.584574\n",
      "[82]\ttraining's binary_logloss: 0.584499\n",
      "[83]\ttraining's binary_logloss: 0.58443\n",
      "[84]\ttraining's binary_logloss: 0.584372\n",
      "[85]\ttraining's binary_logloss: 0.584311\n",
      "[86]\ttraining's binary_logloss: 0.584279\n",
      "[87]\ttraining's binary_logloss: 0.584257\n",
      "[88]\ttraining's binary_logloss: 0.584237\n",
      "[89]\ttraining's binary_logloss: 0.584242\n",
      "[90]\ttraining's binary_logloss: 0.584226\n",
      "[91]\ttraining's binary_logloss: 0.584237\n",
      "[92]\ttraining's binary_logloss: 0.584253\n",
      "[93]\ttraining's binary_logloss: 0.584257\n",
      "[94]\ttraining's binary_logloss: 0.584232\n",
      "[95]\ttraining's binary_logloss: 0.584293\n",
      "[96]\ttraining's binary_logloss: 0.584242\n",
      "[97]\ttraining's binary_logloss: 0.584137\n",
      "[98]\ttraining's binary_logloss: 0.5841\n",
      "[99]\ttraining's binary_logloss: 0.584082\n",
      "[100]\ttraining's binary_logloss: 0.584053\n",
      "[101]\ttraining's binary_logloss: 0.584104\n",
      "[102]\ttraining's binary_logloss: 0.584113\n",
      "[103]\ttraining's binary_logloss: 0.584141\n",
      "[104]\ttraining's binary_logloss: 0.584147\n",
      "[105]\ttraining's binary_logloss: 0.584148\n",
      "[106]\ttraining's binary_logloss: 0.584146\n",
      "[107]\ttraining's binary_logloss: 0.584144\n",
      "[108]\ttraining's binary_logloss: 0.584148\n",
      "[109]\ttraining's binary_logloss: 0.584153\n",
      "[110]\ttraining's binary_logloss: 0.584194\n",
      "[111]\ttraining's binary_logloss: 0.584161\n",
      "[112]\ttraining's binary_logloss: 0.584133\n",
      "[113]\ttraining's binary_logloss: 0.584109\n",
      "[114]\ttraining's binary_logloss: 0.584094\n",
      "[115]\ttraining's binary_logloss: 0.584078\n",
      "[116]\ttraining's binary_logloss: 0.584057\n",
      "[117]\ttraining's binary_logloss: 0.584045\n",
      "[118]\ttraining's binary_logloss: 0.584036\n",
      "[119]\ttraining's binary_logloss: 0.584015\n",
      "[120]\ttraining's binary_logloss: 0.584001\n",
      "[121]\ttraining's binary_logloss: 0.583977\n",
      "[122]\ttraining's binary_logloss: 0.583965\n",
      "[123]\ttraining's binary_logloss: 0.583949\n",
      "[124]\ttraining's binary_logloss: 0.583931\n",
      "[125]\ttraining's binary_logloss: 0.583932\n",
      "[126]\ttraining's binary_logloss: 0.583921\n",
      "[127]\ttraining's binary_logloss: 0.583916\n",
      "[128]\ttraining's binary_logloss: 0.583951\n",
      "[129]\ttraining's binary_logloss: 0.583945\n",
      "[130]\ttraining's binary_logloss: 0.583945\n",
      "[131]\ttraining's binary_logloss: 0.583935\n",
      "[132]\ttraining's binary_logloss: 0.583929\n",
      "[133]\ttraining's binary_logloss: 0.583901\n",
      "[134]\ttraining's binary_logloss: 0.583899\n",
      "[135]\ttraining's binary_logloss: 0.583897\n",
      "[136]\ttraining's binary_logloss: 0.583914\n",
      "[137]\ttraining's binary_logloss: 0.583922\n",
      "[138]\ttraining's binary_logloss: 0.583918\n",
      "[139]\ttraining's binary_logloss: 0.583956\n",
      "[140]\ttraining's binary_logloss: 0.583952\n",
      "[141]\ttraining's binary_logloss: 0.583952\n",
      "[142]\ttraining's binary_logloss: 0.583973\n",
      "[143]\ttraining's binary_logloss: 0.583984\n",
      "[144]\ttraining's binary_logloss: 0.584013\n",
      "[145]\ttraining's binary_logloss: 0.584013\n",
      "[146]\ttraining's binary_logloss: 0.58398\n",
      "[147]\ttraining's binary_logloss: 0.583945\n",
      "[148]\ttraining's binary_logloss: 0.583919\n",
      "[149]\ttraining's binary_logloss: 0.583891\n",
      "[150]\ttraining's binary_logloss: 0.583943\n",
      "[151]\ttraining's binary_logloss: 0.583979\n",
      "[152]\ttraining's binary_logloss: 0.584006\n",
      "[153]\ttraining's binary_logloss: 0.584011\n",
      "[154]\ttraining's binary_logloss: 0.584049\n",
      "[155]\ttraining's binary_logloss: 0.584099\n",
      "[156]\ttraining's binary_logloss: 0.584082\n",
      "[157]\ttraining's binary_logloss: 0.584068\n",
      "[158]\ttraining's binary_logloss: 0.584058\n",
      "[159]\ttraining's binary_logloss: 0.584032\n",
      "[160]\ttraining's binary_logloss: 0.584054\n",
      "[161]\ttraining's binary_logloss: 0.584009\n",
      "[162]\ttraining's binary_logloss: 0.583965\n",
      "[163]\ttraining's binary_logloss: 0.583932\n",
      "[164]\ttraining's binary_logloss: 0.583894\n",
      "[165]\ttraining's binary_logloss: 0.58387\n",
      "[166]\ttraining's binary_logloss: 0.583902\n",
      "[167]\ttraining's binary_logloss: 0.583935\n",
      "[168]\ttraining's binary_logloss: 0.583929\n",
      "[169]\ttraining's binary_logloss: 0.583969\n",
      "[170]\ttraining's binary_logloss: 0.583949\n",
      "[171]\ttraining's binary_logloss: 0.583993\n",
      "[172]\ttraining's binary_logloss: 0.584008\n",
      "[173]\ttraining's binary_logloss: 0.584016\n",
      "[174]\ttraining's binary_logloss: 0.584063\n",
      "[175]\ttraining's binary_logloss: 0.584103\n",
      "[176]\ttraining's binary_logloss: 0.584061\n",
      "[177]\ttraining's binary_logloss: 0.584078\n",
      "[178]\ttraining's binary_logloss: 0.58404\n",
      "[179]\ttraining's binary_logloss: 0.584003\n",
      "[180]\ttraining's binary_logloss: 0.583963\n",
      "[181]\ttraining's binary_logloss: 0.58397\n",
      "[182]\ttraining's binary_logloss: 0.583979\n",
      "[183]\ttraining's binary_logloss: 0.583985\n",
      "[184]\ttraining's binary_logloss: 0.584008\n",
      "[185]\ttraining's binary_logloss: 0.584004\n",
      "[186]\ttraining's binary_logloss: 0.583981\n",
      "[187]\ttraining's binary_logloss: 0.583961\n",
      "[188]\ttraining's binary_logloss: 0.583945\n",
      "[189]\ttraining's binary_logloss: 0.58394\n",
      "[190]\ttraining's binary_logloss: 0.583924\n",
      "[191]\ttraining's binary_logloss: 0.583923\n",
      "[192]\ttraining's binary_logloss: 0.583913\n",
      "[193]\ttraining's binary_logloss: 0.583906\n",
      "[194]\ttraining's binary_logloss: 0.583902\n",
      "[195]\ttraining's binary_logloss: 0.5839\n",
      "[196]\ttraining's binary_logloss: 0.583925\n",
      "[197]\ttraining's binary_logloss: 0.583944\n",
      "[198]\ttraining's binary_logloss: 0.583967\n",
      "[199]\ttraining's binary_logloss: 0.583995\n",
      "[200]\ttraining's binary_logloss: 0.58402\n",
      "[201]\ttraining's binary_logloss: 0.584006\n",
      "[202]\ttraining's binary_logloss: 0.583992\n",
      "[203]\ttraining's binary_logloss: 0.583972\n",
      "[204]\ttraining's binary_logloss: 0.583963\n",
      "[205]\ttraining's binary_logloss: 0.583941\n",
      "[206]\ttraining's binary_logloss: 0.583936\n",
      "[207]\ttraining's binary_logloss: 0.583934\n",
      "[208]\ttraining's binary_logloss: 0.583934\n",
      "[209]\ttraining's binary_logloss: 0.583933\n",
      "[210]\ttraining's binary_logloss: 0.583931\n",
      "[211]\ttraining's binary_logloss: 0.583903\n",
      "[212]\ttraining's binary_logloss: 0.583892\n",
      "[213]\ttraining's binary_logloss: 0.583887\n",
      "[214]\ttraining's binary_logloss: 0.583879\n",
      "[215]\ttraining's binary_logloss: 0.583889\n",
      "[216]\ttraining's binary_logloss: 0.583888\n",
      "[217]\ttraining's binary_logloss: 0.583897\n",
      "[218]\ttraining's binary_logloss: 0.583899\n",
      "[219]\ttraining's binary_logloss: 0.583902\n",
      "[220]\ttraining's binary_logloss: 0.583904\n",
      "[221]\ttraining's binary_logloss: 0.583822\n",
      "[222]\ttraining's binary_logloss: 0.583771\n",
      "[223]\ttraining's binary_logloss: 0.583717\n",
      "[224]\ttraining's binary_logloss: 0.583663\n",
      "[225]\ttraining's binary_logloss: 0.5836\n",
      "[226]\ttraining's binary_logloss: 0.583548\n",
      "[227]\ttraining's binary_logloss: 0.583503\n",
      "[228]\ttraining's binary_logloss: 0.583458\n",
      "[229]\ttraining's binary_logloss: 0.583433\n",
      "[230]\ttraining's binary_logloss: 0.583399\n",
      "[231]\ttraining's binary_logloss: 0.583368\n",
      "[232]\ttraining's binary_logloss: 0.583339\n",
      "[233]\ttraining's binary_logloss: 0.58331\n",
      "[234]\ttraining's binary_logloss: 0.583297\n",
      "[235]\ttraining's binary_logloss: 0.583266\n",
      "[236]\ttraining's binary_logloss: 0.583247\n",
      "[237]\ttraining's binary_logloss: 0.583235\n",
      "[238]\ttraining's binary_logloss: 0.583225\n",
      "[239]\ttraining's binary_logloss: 0.583216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[240]\ttraining's binary_logloss: 0.583207\n",
      "[241]\ttraining's binary_logloss: 0.583127\n",
      "[242]\ttraining's binary_logloss: 0.583083\n",
      "[243]\ttraining's binary_logloss: 0.583042\n",
      "[244]\ttraining's binary_logloss: 0.582967\n",
      "[245]\ttraining's binary_logloss: 0.582926\n",
      "[246]\ttraining's binary_logloss: 0.582856\n",
      "[247]\ttraining's binary_logloss: 0.582813\n",
      "[248]\ttraining's binary_logloss: 0.582775\n",
      "[249]\ttraining's binary_logloss: 0.582723\n",
      "[250]\ttraining's binary_logloss: 0.582658\n",
      "[251]\ttraining's binary_logloss: 0.582612\n",
      "[252]\ttraining's binary_logloss: 0.582566\n",
      "[253]\ttraining's binary_logloss: 0.582531\n",
      "[254]\ttraining's binary_logloss: 0.58249\n",
      "[255]\ttraining's binary_logloss: 0.582454\n",
      "[256]\ttraining's binary_logloss: 0.58242\n",
      "[257]\ttraining's binary_logloss: 0.582395\n",
      "[258]\ttraining's binary_logloss: 0.582357\n",
      "[259]\ttraining's binary_logloss: 0.582335\n",
      "[260]\ttraining's binary_logloss: 0.582314\n",
      "[261]\ttraining's binary_logloss: 0.582268\n",
      "[262]\ttraining's binary_logloss: 0.582252\n",
      "[263]\ttraining's binary_logloss: 0.582216\n",
      "[264]\ttraining's binary_logloss: 0.582201\n",
      "[265]\ttraining's binary_logloss: 0.58216\n",
      "[266]\ttraining's binary_logloss: 0.58209\n",
      "[267]\ttraining's binary_logloss: 0.582039\n",
      "[268]\ttraining's binary_logloss: 0.581993\n",
      "[269]\ttraining's binary_logloss: 0.581944\n",
      "[270]\ttraining's binary_logloss: 0.581881\n",
      "[271]\ttraining's binary_logloss: 0.581839\n",
      "[272]\ttraining's binary_logloss: 0.5818\n",
      "[273]\ttraining's binary_logloss: 0.581745\n",
      "[274]\ttraining's binary_logloss: 0.581686\n",
      "[275]\ttraining's binary_logloss: 0.58166\n",
      "[276]\ttraining's binary_logloss: 0.581633\n",
      "[277]\ttraining's binary_logloss: 0.581614\n",
      "[278]\ttraining's binary_logloss: 0.581596\n",
      "[279]\ttraining's binary_logloss: 0.581582\n",
      "[280]\ttraining's binary_logloss: 0.581571\n",
      "[281]\ttraining's binary_logloss: 0.581486\n",
      "[282]\ttraining's binary_logloss: 0.581407\n",
      "[283]\ttraining's binary_logloss: 0.581326\n",
      "[284]\ttraining's binary_logloss: 0.581252\n",
      "[285]\ttraining's binary_logloss: 0.581158\n",
      "[286]\ttraining's binary_logloss: 0.581087\n",
      "[287]\ttraining's binary_logloss: 0.581044\n",
      "[288]\ttraining's binary_logloss: 0.580992\n",
      "[289]\ttraining's binary_logloss: 0.580952\n",
      "[290]\ttraining's binary_logloss: 0.580881\n",
      "[291]\ttraining's binary_logloss: 0.580806\n",
      "[292]\ttraining's binary_logloss: 0.580746\n",
      "[293]\ttraining's binary_logloss: 0.580666\n",
      "[294]\ttraining's binary_logloss: 0.580606\n",
      "[295]\ttraining's binary_logloss: 0.580556\n",
      "[296]\ttraining's binary_logloss: 0.580487\n",
      "[297]\ttraining's binary_logloss: 0.580408\n",
      "[298]\ttraining's binary_logloss: 0.580341\n",
      "[299]\ttraining's binary_logloss: 0.580265\n",
      "[300]\ttraining's binary_logloss: 0.580198\n",
      "[301]\ttraining's binary_logloss: 0.580186\n",
      "[302]\ttraining's binary_logloss: 0.580167\n",
      "[303]\ttraining's binary_logloss: 0.580158\n",
      "[304]\ttraining's binary_logloss: 0.580123\n",
      "[305]\ttraining's binary_logloss: 0.580126\n",
      "[306]\ttraining's binary_logloss: 0.580089\n",
      "[307]\ttraining's binary_logloss: 0.580038\n",
      "[308]\ttraining's binary_logloss: 0.579972\n",
      "[309]\ttraining's binary_logloss: 0.579925\n",
      "[310]\ttraining's binary_logloss: 0.579891\n",
      "[311]\ttraining's binary_logloss: 0.579861\n",
      "[312]\ttraining's binary_logloss: 0.579836\n",
      "[313]\ttraining's binary_logloss: 0.579803\n",
      "[314]\ttraining's binary_logloss: 0.579767\n",
      "[315]\ttraining's binary_logloss: 0.579746\n",
      "[316]\ttraining's binary_logloss: 0.579662\n",
      "[317]\ttraining's binary_logloss: 0.579584\n",
      "[318]\ttraining's binary_logloss: 0.57951\n",
      "[319]\ttraining's binary_logloss: 0.579436\n",
      "[320]\ttraining's binary_logloss: 0.57938\n",
      "[321]\ttraining's binary_logloss: 0.579306\n",
      "[322]\ttraining's binary_logloss: 0.579247\n",
      "[323]\ttraining's binary_logloss: 0.579171\n",
      "[324]\ttraining's binary_logloss: 0.579096\n",
      "[325]\ttraining's binary_logloss: 0.579025\n",
      "[326]\ttraining's binary_logloss: 0.578941\n",
      "[327]\ttraining's binary_logloss: 0.578837\n",
      "[328]\ttraining's binary_logloss: 0.578749\n",
      "[329]\ttraining's binary_logloss: 0.578637\n",
      "[330]\ttraining's binary_logloss: 0.578555\n",
      "[331]\ttraining's binary_logloss: 0.578478\n",
      "[332]\ttraining's binary_logloss: 0.578406\n",
      "[333]\ttraining's binary_logloss: 0.57834\n",
      "[334]\ttraining's binary_logloss: 0.578274\n",
      "[335]\ttraining's binary_logloss: 0.578206\n",
      "[336]\ttraining's binary_logloss: 0.578169\n",
      "[337]\ttraining's binary_logloss: 0.578118\n",
      "[338]\ttraining's binary_logloss: 0.578078\n",
      "[339]\ttraining's binary_logloss: 0.578044\n",
      "[340]\ttraining's binary_logloss: 0.578014\n",
      "[341]\ttraining's binary_logloss: 0.577948\n",
      "[342]\ttraining's binary_logloss: 0.577877\n",
      "[343]\ttraining's binary_logloss: 0.577814\n",
      "[344]\ttraining's binary_logloss: 0.577749\n",
      "[345]\ttraining's binary_logloss: 0.57768\n",
      "[346]\ttraining's binary_logloss: 0.577628\n",
      "[347]\ttraining's binary_logloss: 0.577574\n",
      "[348]\ttraining's binary_logloss: 0.577504\n",
      "[349]\ttraining's binary_logloss: 0.577463\n",
      "[350]\ttraining's binary_logloss: 0.577408\n",
      "[351]\ttraining's binary_logloss: 0.577317\n",
      "[352]\ttraining's binary_logloss: 0.577237\n",
      "[353]\ttraining's binary_logloss: 0.577149\n",
      "[354]\ttraining's binary_logloss: 0.577072\n",
      "[355]\ttraining's binary_logloss: 0.576999\n",
      "[356]\ttraining's binary_logloss: 0.576904\n",
      "[357]\ttraining's binary_logloss: 0.576827\n",
      "[358]\ttraining's binary_logloss: 0.576769\n",
      "[359]\ttraining's binary_logloss: 0.576702\n",
      "[360]\ttraining's binary_logloss: 0.576639\n",
      "[361]\ttraining's binary_logloss: 0.576517\n",
      "[362]\ttraining's binary_logloss: 0.576411\n",
      "[363]\ttraining's binary_logloss: 0.576299\n",
      "[364]\ttraining's binary_logloss: 0.576198\n",
      "[365]\ttraining's binary_logloss: 0.5761\n",
      "[366]\ttraining's binary_logloss: 0.576\n",
      "[367]\ttraining's binary_logloss: 0.575902\n",
      "[368]\ttraining's binary_logloss: 0.575789\n",
      "[369]\ttraining's binary_logloss: 0.575698\n",
      "[370]\ttraining's binary_logloss: 0.575603\n",
      "[371]\ttraining's binary_logloss: 0.575534\n",
      "[372]\ttraining's binary_logloss: 0.575473\n",
      "[373]\ttraining's binary_logloss: 0.575407\n",
      "[374]\ttraining's binary_logloss: 0.575345\n",
      "[375]\ttraining's binary_logloss: 0.57528\n",
      "[376]\ttraining's binary_logloss: 0.575185\n",
      "[377]\ttraining's binary_logloss: 0.575096\n",
      "[378]\ttraining's binary_logloss: 0.575008\n",
      "[379]\ttraining's binary_logloss: 0.574931\n",
      "[380]\ttraining's binary_logloss: 0.574847\n",
      "[381]\ttraining's binary_logloss: 0.574741\n",
      "[382]\ttraining's binary_logloss: 0.574643\n",
      "[383]\ttraining's binary_logloss: 0.574541\n",
      "[384]\ttraining's binary_logloss: 0.574446\n",
      "[385]\ttraining's binary_logloss: 0.574349\n",
      "[386]\ttraining's binary_logloss: 0.574292\n",
      "[387]\ttraining's binary_logloss: 0.574235\n",
      "[388]\ttraining's binary_logloss: 0.574175\n",
      "[389]\ttraining's binary_logloss: 0.574114\n",
      "[390]\ttraining's binary_logloss: 0.57405\n",
      "[391]\ttraining's binary_logloss: 0.573954\n",
      "[392]\ttraining's binary_logloss: 0.573872\n",
      "[393]\ttraining's binary_logloss: 0.573794\n",
      "[394]\ttraining's binary_logloss: 0.573701\n",
      "[395]\ttraining's binary_logloss: 0.573623\n",
      "[396]\ttraining's binary_logloss: 0.573558\n",
      "[397]\ttraining's binary_logloss: 0.573477\n",
      "[398]\ttraining's binary_logloss: 0.573417\n",
      "[399]\ttraining's binary_logloss: 0.573355\n",
      "[400]\ttraining's binary_logloss: 0.573296\n",
      "[401]\ttraining's binary_logloss: 0.573217\n",
      "[402]\ttraining's binary_logloss: 0.573135\n",
      "[403]\ttraining's binary_logloss: 0.57305\n",
      "[404]\ttraining's binary_logloss: 0.572968\n",
      "[405]\ttraining's binary_logloss: 0.572877\n",
      "[406]\ttraining's binary_logloss: 0.57277\n",
      "[407]\ttraining's binary_logloss: 0.572651\n",
      "[408]\ttraining's binary_logloss: 0.572555\n",
      "[409]\ttraining's binary_logloss: 0.572457\n",
      "[410]\ttraining's binary_logloss: 0.572353\n",
      "[411]\ttraining's binary_logloss: 0.572299\n",
      "[412]\ttraining's binary_logloss: 0.572244\n",
      "[413]\ttraining's binary_logloss: 0.572203\n",
      "[414]\ttraining's binary_logloss: 0.572152\n",
      "[415]\ttraining's binary_logloss: 0.572107\n",
      "[416]\ttraining's binary_logloss: 0.572032\n",
      "[417]\ttraining's binary_logloss: 0.571968\n",
      "[418]\ttraining's binary_logloss: 0.571886\n",
      "[419]\ttraining's binary_logloss: 0.571813\n",
      "[420]\ttraining's binary_logloss: 0.57175\n",
      "[421]\ttraining's binary_logloss: 0.571698\n",
      "[422]\ttraining's binary_logloss: 0.571654\n",
      "[423]\ttraining's binary_logloss: 0.571607\n",
      "[424]\ttraining's binary_logloss: 0.571575\n",
      "[425]\ttraining's binary_logloss: 0.571532\n",
      "[426]\ttraining's binary_logloss: 0.571482\n",
      "[427]\ttraining's binary_logloss: 0.571433\n",
      "[428]\ttraining's binary_logloss: 0.571388\n",
      "[429]\ttraining's binary_logloss: 0.571329\n",
      "[430]\ttraining's binary_logloss: 0.571286\n",
      "[431]\ttraining's binary_logloss: 0.571248\n",
      "[432]\ttraining's binary_logloss: 0.571205\n",
      "[433]\ttraining's binary_logloss: 0.57115\n",
      "[434]\ttraining's binary_logloss: 0.571096\n",
      "[435]\ttraining's binary_logloss: 0.571049\n",
      "[436]\ttraining's binary_logloss: 0.570932\n",
      "[437]\ttraining's binary_logloss: 0.570818\n",
      "[438]\ttraining's binary_logloss: 0.570698\n",
      "[439]\ttraining's binary_logloss: 0.570598\n",
      "[440]\ttraining's binary_logloss: 0.570488\n",
      "[441]\ttraining's binary_logloss: 0.570392\n",
      "[442]\ttraining's binary_logloss: 0.570295\n",
      "[443]\ttraining's binary_logloss: 0.570199\n",
      "[444]\ttraining's binary_logloss: 0.57011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[445]\ttraining's binary_logloss: 0.570029\n",
      "[446]\ttraining's binary_logloss: 0.569974\n",
      "[447]\ttraining's binary_logloss: 0.569921\n",
      "[448]\ttraining's binary_logloss: 0.569875\n",
      "[449]\ttraining's binary_logloss: 0.569828\n",
      "[450]\ttraining's binary_logloss: 0.569782\n",
      "[451]\ttraining's binary_logloss: 0.569723\n",
      "[452]\ttraining's binary_logloss: 0.569666\n",
      "[453]\ttraining's binary_logloss: 0.569612\n",
      "[454]\ttraining's binary_logloss: 0.569546\n",
      "[455]\ttraining's binary_logloss: 0.569495\n",
      "[456]\ttraining's binary_logloss: 0.569414\n",
      "[457]\ttraining's binary_logloss: 0.569325\n",
      "[458]\ttraining's binary_logloss: 0.569241\n",
      "[459]\ttraining's binary_logloss: 0.569158\n",
      "[460]\ttraining's binary_logloss: 0.56908\n",
      "[461]\ttraining's binary_logloss: 0.568995\n",
      "[462]\ttraining's binary_logloss: 0.568908\n",
      "[463]\ttraining's binary_logloss: 0.568843\n",
      "[464]\ttraining's binary_logloss: 0.568763\n",
      "[465]\ttraining's binary_logloss: 0.568677\n",
      "[466]\ttraining's binary_logloss: 0.568576\n",
      "[467]\ttraining's binary_logloss: 0.568466\n",
      "[468]\ttraining's binary_logloss: 0.56836\n",
      "[469]\ttraining's binary_logloss: 0.568255\n",
      "[470]\ttraining's binary_logloss: 0.568148\n",
      "[471]\ttraining's binary_logloss: 0.568082\n",
      "[472]\ttraining's binary_logloss: 0.568003\n",
      "[473]\ttraining's binary_logloss: 0.567933\n",
      "[474]\ttraining's binary_logloss: 0.567854\n",
      "[475]\ttraining's binary_logloss: 0.567779\n",
      "[476]\ttraining's binary_logloss: 0.567705\n",
      "[477]\ttraining's binary_logloss: 0.567626\n",
      "[478]\ttraining's binary_logloss: 0.567558\n",
      "[479]\ttraining's binary_logloss: 0.567483\n",
      "[480]\ttraining's binary_logloss: 0.567414\n",
      "[481]\ttraining's binary_logloss: 0.567319\n",
      "[482]\ttraining's binary_logloss: 0.567226\n",
      "[483]\ttraining's binary_logloss: 0.567129\n",
      "[484]\ttraining's binary_logloss: 0.567031\n",
      "[485]\ttraining's binary_logloss: 0.566949\n",
      "[486]\ttraining's binary_logloss: 0.566839\n",
      "[487]\ttraining's binary_logloss: 0.566731\n",
      "[488]\ttraining's binary_logloss: 0.566632\n",
      "[489]\ttraining's binary_logloss: 0.566528\n",
      "[490]\ttraining's binary_logloss: 0.566428\n",
      "[491]\ttraining's binary_logloss: 0.566324\n",
      "[492]\ttraining's binary_logloss: 0.566228\n",
      "[493]\ttraining's binary_logloss: 0.566139\n",
      "[494]\ttraining's binary_logloss: 0.566035\n",
      "[495]\ttraining's binary_logloss: 0.565935\n",
      "[496]\ttraining's binary_logloss: 0.565888\n",
      "[497]\ttraining's binary_logloss: 0.565813\n",
      "[498]\ttraining's binary_logloss: 0.565768\n",
      "[499]\ttraining's binary_logloss: 0.565707\n",
      "[500]\ttraining's binary_logloss: 0.565667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.61404\n",
      "[2]\ttraining's binary_logloss: 0.613027\n",
      "[3]\ttraining's binary_logloss: 0.612032\n",
      "[4]\ttraining's binary_logloss: 0.610959\n",
      "[5]\ttraining's binary_logloss: 0.60995\n",
      "[6]\ttraining's binary_logloss: 0.609008\n",
      "[7]\ttraining's binary_logloss: 0.608176\n",
      "[8]\ttraining's binary_logloss: 0.607283\n",
      "[9]\ttraining's binary_logloss: 0.606415\n",
      "[10]\ttraining's binary_logloss: 0.605549\n",
      "[11]\ttraining's binary_logloss: 0.604651\n",
      "[12]\ttraining's binary_logloss: 0.603798\n",
      "[13]\ttraining's binary_logloss: 0.602975\n",
      "[14]\ttraining's binary_logloss: 0.602169\n",
      "[15]\ttraining's binary_logloss: 0.601386\n",
      "[16]\ttraining's binary_logloss: 0.600661\n",
      "[17]\ttraining's binary_logloss: 0.600024\n",
      "[18]\ttraining's binary_logloss: 0.599326\n",
      "[19]\ttraining's binary_logloss: 0.598735\n",
      "[20]\ttraining's binary_logloss: 0.598149\n",
      "[21]\ttraining's binary_logloss: 0.597552\n",
      "[22]\ttraining's binary_logloss: 0.59707\n",
      "[23]\ttraining's binary_logloss: 0.596514\n",
      "[24]\ttraining's binary_logloss: 0.596071\n",
      "[25]\ttraining's binary_logloss: 0.59559\n",
      "[26]\ttraining's binary_logloss: 0.59513\n",
      "[27]\ttraining's binary_logloss: 0.594697\n",
      "[28]\ttraining's binary_logloss: 0.594278\n",
      "[29]\ttraining's binary_logloss: 0.59394\n",
      "[30]\ttraining's binary_logloss: 0.593578\n",
      "[31]\ttraining's binary_logloss: 0.593154\n",
      "[32]\ttraining's binary_logloss: 0.592769\n",
      "[33]\ttraining's binary_logloss: 0.592332\n",
      "[34]\ttraining's binary_logloss: 0.59195\n",
      "[35]\ttraining's binary_logloss: 0.591593\n",
      "[36]\ttraining's binary_logloss: 0.591207\n",
      "[37]\ttraining's binary_logloss: 0.590899\n",
      "[38]\ttraining's binary_logloss: 0.590589\n",
      "[39]\ttraining's binary_logloss: 0.590277\n",
      "[40]\ttraining's binary_logloss: 0.589976\n",
      "[41]\ttraining's binary_logloss: 0.589614\n",
      "[42]\ttraining's binary_logloss: 0.589262\n",
      "[43]\ttraining's binary_logloss: 0.588924\n",
      "[44]\ttraining's binary_logloss: 0.5886\n",
      "[45]\ttraining's binary_logloss: 0.588289\n",
      "[46]\ttraining's binary_logloss: 0.587996\n",
      "[47]\ttraining's binary_logloss: 0.587731\n",
      "[48]\ttraining's binary_logloss: 0.587457\n",
      "[49]\ttraining's binary_logloss: 0.587198\n",
      "[50]\ttraining's binary_logloss: 0.586966\n",
      "[51]\ttraining's binary_logloss: 0.586766\n",
      "[52]\ttraining's binary_logloss: 0.586556\n",
      "[53]\ttraining's binary_logloss: 0.586359\n",
      "[54]\ttraining's binary_logloss: 0.586215\n",
      "[55]\ttraining's binary_logloss: 0.586098\n",
      "[56]\ttraining's binary_logloss: 0.585918\n",
      "[57]\ttraining's binary_logloss: 0.585749\n",
      "[58]\ttraining's binary_logloss: 0.585659\n",
      "[59]\ttraining's binary_logloss: 0.585508\n",
      "[60]\ttraining's binary_logloss: 0.585352\n",
      "[61]\ttraining's binary_logloss: 0.58523\n",
      "[62]\ttraining's binary_logloss: 0.585091\n",
      "[63]\ttraining's binary_logloss: 0.584964\n",
      "[64]\ttraining's binary_logloss: 0.584906\n",
      "[65]\ttraining's binary_logloss: 0.584803\n",
      "[66]\ttraining's binary_logloss: 0.584742\n",
      "[67]\ttraining's binary_logloss: 0.584693\n",
      "[68]\ttraining's binary_logloss: 0.584641\n",
      "[69]\ttraining's binary_logloss: 0.584597\n",
      "[70]\ttraining's binary_logloss: 0.584567\n",
      "[71]\ttraining's binary_logloss: 0.584443\n",
      "[72]\ttraining's binary_logloss: 0.584364\n",
      "[73]\ttraining's binary_logloss: 0.584295\n",
      "[74]\ttraining's binary_logloss: 0.584244\n",
      "[75]\ttraining's binary_logloss: 0.584199\n",
      "[76]\ttraining's binary_logloss: 0.584152\n",
      "[77]\ttraining's binary_logloss: 0.584072\n",
      "[78]\ttraining's binary_logloss: 0.584036\n",
      "[79]\ttraining's binary_logloss: 0.584006\n",
      "[80]\ttraining's binary_logloss: 0.584003\n",
      "[81]\ttraining's binary_logloss: 0.583893\n",
      "[82]\ttraining's binary_logloss: 0.583789\n",
      "[83]\ttraining's binary_logloss: 0.583693\n",
      "[84]\ttraining's binary_logloss: 0.583601\n",
      "[85]\ttraining's binary_logloss: 0.583516\n",
      "[86]\ttraining's binary_logloss: 0.58347\n",
      "[87]\ttraining's binary_logloss: 0.583426\n",
      "[88]\ttraining's binary_logloss: 0.58343\n",
      "[89]\ttraining's binary_logloss: 0.583383\n",
      "[90]\ttraining's binary_logloss: 0.583375\n",
      "[91]\ttraining's binary_logloss: 0.58341\n",
      "[92]\ttraining's binary_logloss: 0.583406\n",
      "[93]\ttraining's binary_logloss: 0.583435\n",
      "[94]\ttraining's binary_logloss: 0.583384\n",
      "[95]\ttraining's binary_logloss: 0.583454\n",
      "[96]\ttraining's binary_logloss: 0.583406\n",
      "[97]\ttraining's binary_logloss: 0.583334\n",
      "[98]\ttraining's binary_logloss: 0.58334\n",
      "[99]\ttraining's binary_logloss: 0.583325\n",
      "[100]\ttraining's binary_logloss: 0.583297\n",
      "[101]\ttraining's binary_logloss: 0.583338\n",
      "[102]\ttraining's binary_logloss: 0.583329\n",
      "[103]\ttraining's binary_logloss: 0.58341\n",
      "[104]\ttraining's binary_logloss: 0.583407\n",
      "[105]\ttraining's binary_logloss: 0.583421\n",
      "[106]\ttraining's binary_logloss: 0.583433\n",
      "[107]\ttraining's binary_logloss: 0.583449\n",
      "[108]\ttraining's binary_logloss: 0.583469\n",
      "[109]\ttraining's binary_logloss: 0.583483\n",
      "[110]\ttraining's binary_logloss: 0.583532\n",
      "[111]\ttraining's binary_logloss: 0.583517\n",
      "[112]\ttraining's binary_logloss: 0.583514\n",
      "[113]\ttraining's binary_logloss: 0.583506\n",
      "[114]\ttraining's binary_logloss: 0.583539\n",
      "[115]\ttraining's binary_logloss: 0.583561\n",
      "[116]\ttraining's binary_logloss: 0.583512\n",
      "[117]\ttraining's binary_logloss: 0.583466\n",
      "[118]\ttraining's binary_logloss: 0.583425\n",
      "[119]\ttraining's binary_logloss: 0.583388\n",
      "[120]\ttraining's binary_logloss: 0.583356\n",
      "[121]\ttraining's binary_logloss: 0.583344\n",
      "[122]\ttraining's binary_logloss: 0.583336\n",
      "[123]\ttraining's binary_logloss: 0.58333\n",
      "[124]\ttraining's binary_logloss: 0.583328\n",
      "[125]\ttraining's binary_logloss: 0.583336\n",
      "[126]\ttraining's binary_logloss: 0.583326\n",
      "[127]\ttraining's binary_logloss: 0.583326\n",
      "[128]\ttraining's binary_logloss: 0.58339\n",
      "[129]\ttraining's binary_logloss: 0.583393\n",
      "[130]\ttraining's binary_logloss: 0.583404\n",
      "[131]\ttraining's binary_logloss: 0.583433\n",
      "[132]\ttraining's binary_logloss: 0.583458\n",
      "[133]\ttraining's binary_logloss: 0.583473\n",
      "[134]\ttraining's binary_logloss: 0.583514\n",
      "[135]\ttraining's binary_logloss: 0.583551\n",
      "[136]\ttraining's binary_logloss: 0.583554\n",
      "[137]\ttraining's binary_logloss: 0.58355\n",
      "[138]\ttraining's binary_logloss: 0.583554\n",
      "[139]\ttraining's binary_logloss: 0.583592\n",
      "[140]\ttraining's binary_logloss: 0.583616\n",
      "[141]\ttraining's binary_logloss: 0.583619\n",
      "[142]\ttraining's binary_logloss: 0.583598\n",
      "[143]\ttraining's binary_logloss: 0.583593\n",
      "[144]\ttraining's binary_logloss: 0.583579\n",
      "[145]\ttraining's binary_logloss: 0.583589\n",
      "[146]\ttraining's binary_logloss: 0.583562\n",
      "[147]\ttraining's binary_logloss: 0.583542\n",
      "[148]\ttraining's binary_logloss: 0.583524\n",
      "[149]\ttraining's binary_logloss: 0.583506\n",
      "[150]\ttraining's binary_logloss: 0.5835\n",
      "[151]\ttraining's binary_logloss: 0.583513\n",
      "[152]\ttraining's binary_logloss: 0.58353\n",
      "[153]\ttraining's binary_logloss: 0.583551\n",
      "[154]\ttraining's binary_logloss: 0.583572\n",
      "[155]\ttraining's binary_logloss: 0.583597\n",
      "[156]\ttraining's binary_logloss: 0.583611\n",
      "[157]\ttraining's binary_logloss: 0.583621\n",
      "[158]\ttraining's binary_logloss: 0.583633\n",
      "[159]\ttraining's binary_logloss: 0.58365\n",
      "[160]\ttraining's binary_logloss: 0.58369\n",
      "[161]\ttraining's binary_logloss: 0.583669\n",
      "[162]\ttraining's binary_logloss: 0.58365\n",
      "[163]\ttraining's binary_logloss: 0.583634\n",
      "[164]\ttraining's binary_logloss: 0.583619\n",
      "[165]\ttraining's binary_logloss: 0.583598\n",
      "[166]\ttraining's binary_logloss: 0.583657\n",
      "[167]\ttraining's binary_logloss: 0.583695\n",
      "[168]\ttraining's binary_logloss: 0.583738\n",
      "[169]\ttraining's binary_logloss: 0.583749\n",
      "[170]\ttraining's binary_logloss: 0.583796\n",
      "[171]\ttraining's binary_logloss: 0.583801\n",
      "[172]\ttraining's binary_logloss: 0.583811\n",
      "[173]\ttraining's binary_logloss: 0.583844\n",
      "[174]\ttraining's binary_logloss: 0.583862\n",
      "[175]\ttraining's binary_logloss: 0.583873\n",
      "[176]\ttraining's binary_logloss: 0.583896\n",
      "[177]\ttraining's binary_logloss: 0.583876\n",
      "[178]\ttraining's binary_logloss: 0.583901\n",
      "[179]\ttraining's binary_logloss: 0.583918\n",
      "[180]\ttraining's binary_logloss: 0.583945\n",
      "[181]\ttraining's binary_logloss: 0.583962\n",
      "[182]\ttraining's binary_logloss: 0.583976\n",
      "[183]\ttraining's binary_logloss: 0.583992\n",
      "[184]\ttraining's binary_logloss: 0.584017\n",
      "[185]\ttraining's binary_logloss: 0.584028\n",
      "[186]\ttraining's binary_logloss: 0.584023\n",
      "[187]\ttraining's binary_logloss: 0.584026\n",
      "[188]\ttraining's binary_logloss: 0.584015\n",
      "[189]\ttraining's binary_logloss: 0.584018\n",
      "[190]\ttraining's binary_logloss: 0.58402\n",
      "[191]\ttraining's binary_logloss: 0.584022\n",
      "[192]\ttraining's binary_logloss: 0.584033\n",
      "[193]\ttraining's binary_logloss: 0.584023\n",
      "[194]\ttraining's binary_logloss: 0.584037\n",
      "[195]\ttraining's binary_logloss: 0.584028\n",
      "[196]\ttraining's binary_logloss: 0.584028\n",
      "[197]\ttraining's binary_logloss: 0.584031\n",
      "[198]\ttraining's binary_logloss: 0.584033\n",
      "[199]\ttraining's binary_logloss: 0.584037\n",
      "[200]\ttraining's binary_logloss: 0.584051\n",
      "[201]\ttraining's binary_logloss: 0.584034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[202]\ttraining's binary_logloss: 0.584016\n",
      "[203]\ttraining's binary_logloss: 0.583983\n",
      "[204]\ttraining's binary_logloss: 0.583965\n",
      "[205]\ttraining's binary_logloss: 0.583947\n",
      "[206]\ttraining's binary_logloss: 0.583945\n",
      "[207]\ttraining's binary_logloss: 0.583952\n",
      "[208]\ttraining's binary_logloss: 0.583944\n",
      "[209]\ttraining's binary_logloss: 0.583929\n",
      "[210]\ttraining's binary_logloss: 0.583935\n",
      "[211]\ttraining's binary_logloss: 0.58393\n",
      "[212]\ttraining's binary_logloss: 0.583913\n",
      "[213]\ttraining's binary_logloss: 0.583897\n",
      "[214]\ttraining's binary_logloss: 0.583872\n",
      "[215]\ttraining's binary_logloss: 0.583852\n",
      "[216]\ttraining's binary_logloss: 0.583858\n",
      "[217]\ttraining's binary_logloss: 0.583875\n",
      "[218]\ttraining's binary_logloss: 0.583889\n",
      "[219]\ttraining's binary_logloss: 0.583905\n",
      "[220]\ttraining's binary_logloss: 0.583923\n",
      "[221]\ttraining's binary_logloss: 0.583857\n",
      "[222]\ttraining's binary_logloss: 0.58379\n",
      "[223]\ttraining's binary_logloss: 0.583724\n",
      "[224]\ttraining's binary_logloss: 0.583663\n",
      "[225]\ttraining's binary_logloss: 0.583616\n",
      "[226]\ttraining's binary_logloss: 0.583578\n",
      "[227]\ttraining's binary_logloss: 0.583523\n",
      "[228]\ttraining's binary_logloss: 0.583474\n",
      "[229]\ttraining's binary_logloss: 0.58347\n",
      "[230]\ttraining's binary_logloss: 0.583424\n",
      "[231]\ttraining's binary_logloss: 0.583403\n",
      "[232]\ttraining's binary_logloss: 0.583353\n",
      "[233]\ttraining's binary_logloss: 0.583336\n",
      "[234]\ttraining's binary_logloss: 0.5833\n",
      "[235]\ttraining's binary_logloss: 0.583267\n",
      "[236]\ttraining's binary_logloss: 0.583252\n",
      "[237]\ttraining's binary_logloss: 0.583221\n",
      "[238]\ttraining's binary_logloss: 0.583203\n",
      "[239]\ttraining's binary_logloss: 0.583173\n",
      "[240]\ttraining's binary_logloss: 0.583163\n",
      "[241]\ttraining's binary_logloss: 0.583107\n",
      "[242]\ttraining's binary_logloss: 0.583053\n",
      "[243]\ttraining's binary_logloss: 0.583001\n",
      "[244]\ttraining's binary_logloss: 0.582951\n",
      "[245]\ttraining's binary_logloss: 0.5829\n",
      "[246]\ttraining's binary_logloss: 0.582873\n",
      "[247]\ttraining's binary_logloss: 0.582819\n",
      "[248]\ttraining's binary_logloss: 0.582797\n",
      "[249]\ttraining's binary_logloss: 0.58277\n",
      "[250]\ttraining's binary_logloss: 0.582748\n",
      "[251]\ttraining's binary_logloss: 0.582712\n",
      "[252]\ttraining's binary_logloss: 0.582671\n",
      "[253]\ttraining's binary_logloss: 0.582634\n",
      "[254]\ttraining's binary_logloss: 0.582602\n",
      "[255]\ttraining's binary_logloss: 0.582577\n",
      "[256]\ttraining's binary_logloss: 0.582548\n",
      "[257]\ttraining's binary_logloss: 0.582485\n",
      "[258]\ttraining's binary_logloss: 0.58244\n",
      "[259]\ttraining's binary_logloss: 0.582409\n",
      "[260]\ttraining's binary_logloss: 0.582378\n",
      "[261]\ttraining's binary_logloss: 0.582338\n",
      "[262]\ttraining's binary_logloss: 0.5823\n",
      "[263]\ttraining's binary_logloss: 0.582264\n",
      "[264]\ttraining's binary_logloss: 0.582242\n",
      "[265]\ttraining's binary_logloss: 0.582213\n",
      "[266]\ttraining's binary_logloss: 0.582184\n",
      "[267]\ttraining's binary_logloss: 0.582158\n",
      "[268]\ttraining's binary_logloss: 0.582124\n",
      "[269]\ttraining's binary_logloss: 0.582082\n",
      "[270]\ttraining's binary_logloss: 0.58204\n",
      "[271]\ttraining's binary_logloss: 0.582002\n",
      "[272]\ttraining's binary_logloss: 0.581951\n",
      "[273]\ttraining's binary_logloss: 0.581919\n",
      "[274]\ttraining's binary_logloss: 0.581878\n",
      "[275]\ttraining's binary_logloss: 0.581841\n",
      "[276]\ttraining's binary_logloss: 0.581834\n",
      "[277]\ttraining's binary_logloss: 0.581834\n",
      "[278]\ttraining's binary_logloss: 0.581831\n",
      "[279]\ttraining's binary_logloss: 0.581812\n",
      "[280]\ttraining's binary_logloss: 0.58181\n",
      "[281]\ttraining's binary_logloss: 0.581732\n",
      "[282]\ttraining's binary_logloss: 0.581665\n",
      "[283]\ttraining's binary_logloss: 0.581563\n",
      "[284]\ttraining's binary_logloss: 0.581488\n",
      "[285]\ttraining's binary_logloss: 0.581406\n",
      "[286]\ttraining's binary_logloss: 0.581345\n",
      "[287]\ttraining's binary_logloss: 0.581262\n",
      "[288]\ttraining's binary_logloss: 0.581182\n",
      "[289]\ttraining's binary_logloss: 0.581105\n",
      "[290]\ttraining's binary_logloss: 0.581032\n",
      "[291]\ttraining's binary_logloss: 0.580945\n",
      "[292]\ttraining's binary_logloss: 0.580886\n",
      "[293]\ttraining's binary_logloss: 0.580805\n",
      "[294]\ttraining's binary_logloss: 0.580701\n",
      "[295]\ttraining's binary_logloss: 0.580614\n",
      "[296]\ttraining's binary_logloss: 0.580524\n",
      "[297]\ttraining's binary_logloss: 0.580431\n",
      "[298]\ttraining's binary_logloss: 0.580335\n",
      "[299]\ttraining's binary_logloss: 0.580262\n",
      "[300]\ttraining's binary_logloss: 0.580175\n",
      "[301]\ttraining's binary_logloss: 0.580152\n",
      "[302]\ttraining's binary_logloss: 0.580115\n",
      "[303]\ttraining's binary_logloss: 0.580099\n",
      "[304]\ttraining's binary_logloss: 0.580069\n",
      "[305]\ttraining's binary_logloss: 0.580051\n",
      "[306]\ttraining's binary_logloss: 0.579999\n",
      "[307]\ttraining's binary_logloss: 0.579955\n",
      "[308]\ttraining's binary_logloss: 0.579913\n",
      "[309]\ttraining's binary_logloss: 0.57987\n",
      "[310]\ttraining's binary_logloss: 0.579834\n",
      "[311]\ttraining's binary_logloss: 0.579767\n",
      "[312]\ttraining's binary_logloss: 0.579714\n",
      "[313]\ttraining's binary_logloss: 0.579673\n",
      "[314]\ttraining's binary_logloss: 0.579608\n",
      "[315]\ttraining's binary_logloss: 0.579556\n",
      "[316]\ttraining's binary_logloss: 0.579481\n",
      "[317]\ttraining's binary_logloss: 0.579406\n",
      "[318]\ttraining's binary_logloss: 0.579335\n",
      "[319]\ttraining's binary_logloss: 0.579266\n",
      "[320]\ttraining's binary_logloss: 0.5792\n",
      "[321]\ttraining's binary_logloss: 0.579147\n",
      "[322]\ttraining's binary_logloss: 0.579076\n",
      "[323]\ttraining's binary_logloss: 0.579023\n",
      "[324]\ttraining's binary_logloss: 0.578975\n",
      "[325]\ttraining's binary_logloss: 0.57891\n",
      "[326]\ttraining's binary_logloss: 0.578852\n",
      "[327]\ttraining's binary_logloss: 0.578753\n",
      "[328]\ttraining's binary_logloss: 0.578665\n",
      "[329]\ttraining's binary_logloss: 0.578574\n",
      "[330]\ttraining's binary_logloss: 0.578481\n",
      "[331]\ttraining's binary_logloss: 0.578422\n",
      "[332]\ttraining's binary_logloss: 0.578365\n",
      "[333]\ttraining's binary_logloss: 0.578307\n",
      "[334]\ttraining's binary_logloss: 0.578262\n",
      "[335]\ttraining's binary_logloss: 0.578228\n",
      "[336]\ttraining's binary_logloss: 0.578181\n",
      "[337]\ttraining's binary_logloss: 0.578143\n",
      "[338]\ttraining's binary_logloss: 0.578099\n",
      "[339]\ttraining's binary_logloss: 0.578065\n",
      "[340]\ttraining's binary_logloss: 0.578024\n",
      "[341]\ttraining's binary_logloss: 0.577927\n",
      "[342]\ttraining's binary_logloss: 0.577837\n",
      "[343]\ttraining's binary_logloss: 0.577735\n",
      "[344]\ttraining's binary_logloss: 0.577669\n",
      "[345]\ttraining's binary_logloss: 0.577577\n",
      "[346]\ttraining's binary_logloss: 0.577511\n",
      "[347]\ttraining's binary_logloss: 0.577455\n",
      "[348]\ttraining's binary_logloss: 0.577392\n",
      "[349]\ttraining's binary_logloss: 0.577329\n",
      "[350]\ttraining's binary_logloss: 0.577265\n",
      "[351]\ttraining's binary_logloss: 0.57717\n",
      "[352]\ttraining's binary_logloss: 0.577079\n",
      "[353]\ttraining's binary_logloss: 0.576994\n",
      "[354]\ttraining's binary_logloss: 0.576915\n",
      "[355]\ttraining's binary_logloss: 0.576822\n",
      "[356]\ttraining's binary_logloss: 0.576747\n",
      "[357]\ttraining's binary_logloss: 0.576669\n",
      "[358]\ttraining's binary_logloss: 0.576596\n",
      "[359]\ttraining's binary_logloss: 0.576522\n",
      "[360]\ttraining's binary_logloss: 0.576448\n",
      "[361]\ttraining's binary_logloss: 0.57636\n",
      "[362]\ttraining's binary_logloss: 0.576293\n",
      "[363]\ttraining's binary_logloss: 0.576211\n",
      "[364]\ttraining's binary_logloss: 0.576148\n",
      "[365]\ttraining's binary_logloss: 0.576082\n",
      "[366]\ttraining's binary_logloss: 0.575975\n",
      "[367]\ttraining's binary_logloss: 0.575867\n",
      "[368]\ttraining's binary_logloss: 0.57576\n",
      "[369]\ttraining's binary_logloss: 0.575652\n",
      "[370]\ttraining's binary_logloss: 0.575555\n",
      "[371]\ttraining's binary_logloss: 0.575488\n",
      "[372]\ttraining's binary_logloss: 0.575427\n",
      "[373]\ttraining's binary_logloss: 0.575367\n",
      "[374]\ttraining's binary_logloss: 0.575307\n",
      "[375]\ttraining's binary_logloss: 0.575251\n",
      "[376]\ttraining's binary_logloss: 0.575184\n",
      "[377]\ttraining's binary_logloss: 0.575116\n",
      "[378]\ttraining's binary_logloss: 0.575054\n",
      "[379]\ttraining's binary_logloss: 0.574979\n",
      "[380]\ttraining's binary_logloss: 0.574901\n",
      "[381]\ttraining's binary_logloss: 0.574836\n",
      "[382]\ttraining's binary_logloss: 0.574765\n",
      "[383]\ttraining's binary_logloss: 0.574684\n",
      "[384]\ttraining's binary_logloss: 0.574603\n",
      "[385]\ttraining's binary_logloss: 0.57453\n",
      "[386]\ttraining's binary_logloss: 0.574468\n",
      "[387]\ttraining's binary_logloss: 0.574403\n",
      "[388]\ttraining's binary_logloss: 0.574338\n",
      "[389]\ttraining's binary_logloss: 0.574272\n",
      "[390]\ttraining's binary_logloss: 0.574175\n",
      "[391]\ttraining's binary_logloss: 0.57409\n",
      "[392]\ttraining's binary_logloss: 0.574007\n",
      "[393]\ttraining's binary_logloss: 0.573942\n",
      "[394]\ttraining's binary_logloss: 0.573864\n",
      "[395]\ttraining's binary_logloss: 0.573783\n",
      "[396]\ttraining's binary_logloss: 0.573685\n",
      "[397]\ttraining's binary_logloss: 0.573609\n",
      "[398]\ttraining's binary_logloss: 0.573519\n",
      "[399]\ttraining's binary_logloss: 0.573435\n",
      "[400]\ttraining's binary_logloss: 0.573354\n",
      "[401]\ttraining's binary_logloss: 0.573271\n",
      "[402]\ttraining's binary_logloss: 0.573214\n",
      "[403]\ttraining's binary_logloss: 0.573135\n",
      "[404]\ttraining's binary_logloss: 0.57304\n",
      "[405]\ttraining's binary_logloss: 0.572968\n",
      "[406]\ttraining's binary_logloss: 0.572867\n",
      "[407]\ttraining's binary_logloss: 0.572768\n",
      "[408]\ttraining's binary_logloss: 0.572684\n",
      "[409]\ttraining's binary_logloss: 0.572588\n",
      "[410]\ttraining's binary_logloss: 0.572503\n",
      "[411]\ttraining's binary_logloss: 0.572442\n",
      "[412]\ttraining's binary_logloss: 0.572371\n",
      "[413]\ttraining's binary_logloss: 0.572302\n",
      "[414]\ttraining's binary_logloss: 0.572234\n",
      "[415]\ttraining's binary_logloss: 0.572163\n",
      "[416]\ttraining's binary_logloss: 0.572091\n",
      "[417]\ttraining's binary_logloss: 0.572012\n",
      "[418]\ttraining's binary_logloss: 0.57194\n",
      "[419]\ttraining's binary_logloss: 0.571863\n",
      "[420]\ttraining's binary_logloss: 0.571787\n",
      "[421]\ttraining's binary_logloss: 0.571751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[422]\ttraining's binary_logloss: 0.571717\n",
      "[423]\ttraining's binary_logloss: 0.571676\n",
      "[424]\ttraining's binary_logloss: 0.57164\n",
      "[425]\ttraining's binary_logloss: 0.571603\n",
      "[426]\ttraining's binary_logloss: 0.57152\n",
      "[427]\ttraining's binary_logloss: 0.571453\n",
      "[428]\ttraining's binary_logloss: 0.571381\n",
      "[429]\ttraining's binary_logloss: 0.57131\n",
      "[430]\ttraining's binary_logloss: 0.571232\n",
      "[431]\ttraining's binary_logloss: 0.571203\n",
      "[432]\ttraining's binary_logloss: 0.57117\n",
      "[433]\ttraining's binary_logloss: 0.571135\n",
      "[434]\ttraining's binary_logloss: 0.571103\n",
      "[435]\ttraining's binary_logloss: 0.571076\n",
      "[436]\ttraining's binary_logloss: 0.570987\n",
      "[437]\ttraining's binary_logloss: 0.570891\n",
      "[438]\ttraining's binary_logloss: 0.570811\n",
      "[439]\ttraining's binary_logloss: 0.570746\n",
      "[440]\ttraining's binary_logloss: 0.570658\n",
      "[441]\ttraining's binary_logloss: 0.570577\n",
      "[442]\ttraining's binary_logloss: 0.570491\n",
      "[443]\ttraining's binary_logloss: 0.570402\n",
      "[444]\ttraining's binary_logloss: 0.570323\n",
      "[445]\ttraining's binary_logloss: 0.570251\n",
      "[446]\ttraining's binary_logloss: 0.570174\n",
      "[447]\ttraining's binary_logloss: 0.570101\n",
      "[448]\ttraining's binary_logloss: 0.570032\n",
      "[449]\ttraining's binary_logloss: 0.569962\n",
      "[450]\ttraining's binary_logloss: 0.569894\n",
      "[451]\ttraining's binary_logloss: 0.569809\n",
      "[452]\ttraining's binary_logloss: 0.569729\n",
      "[453]\ttraining's binary_logloss: 0.569648\n",
      "[454]\ttraining's binary_logloss: 0.569575\n",
      "[455]\ttraining's binary_logloss: 0.569498\n",
      "[456]\ttraining's binary_logloss: 0.569423\n",
      "[457]\ttraining's binary_logloss: 0.569342\n",
      "[458]\ttraining's binary_logloss: 0.569258\n",
      "[459]\ttraining's binary_logloss: 0.56917\n",
      "[460]\ttraining's binary_logloss: 0.569089\n",
      "[461]\ttraining's binary_logloss: 0.569009\n",
      "[462]\ttraining's binary_logloss: 0.568914\n",
      "[463]\ttraining's binary_logloss: 0.568838\n",
      "[464]\ttraining's binary_logloss: 0.568771\n",
      "[465]\ttraining's binary_logloss: 0.568696\n",
      "[466]\ttraining's binary_logloss: 0.568593\n",
      "[467]\ttraining's binary_logloss: 0.568475\n",
      "[468]\ttraining's binary_logloss: 0.568366\n",
      "[469]\ttraining's binary_logloss: 0.568252\n",
      "[470]\ttraining's binary_logloss: 0.568149\n",
      "[471]\ttraining's binary_logloss: 0.568063\n",
      "[472]\ttraining's binary_logloss: 0.567991\n",
      "[473]\ttraining's binary_logloss: 0.567928\n",
      "[474]\ttraining's binary_logloss: 0.56785\n",
      "[475]\ttraining's binary_logloss: 0.567767\n",
      "[476]\ttraining's binary_logloss: 0.567701\n",
      "[477]\ttraining's binary_logloss: 0.567636\n",
      "[478]\ttraining's binary_logloss: 0.567576\n",
      "[479]\ttraining's binary_logloss: 0.567521\n",
      "[480]\ttraining's binary_logloss: 0.567448\n",
      "[481]\ttraining's binary_logloss: 0.567348\n",
      "[482]\ttraining's binary_logloss: 0.567277\n",
      "[483]\ttraining's binary_logloss: 0.567182\n",
      "[484]\ttraining's binary_logloss: 0.567102\n",
      "[485]\ttraining's binary_logloss: 0.567035\n",
      "[486]\ttraining's binary_logloss: 0.56691\n",
      "[487]\ttraining's binary_logloss: 0.566799\n",
      "[488]\ttraining's binary_logloss: 0.566693\n",
      "[489]\ttraining's binary_logloss: 0.566572\n",
      "[490]\ttraining's binary_logloss: 0.566473\n",
      "[491]\ttraining's binary_logloss: 0.566395\n",
      "[492]\ttraining's binary_logloss: 0.566303\n",
      "[493]\ttraining's binary_logloss: 0.566209\n",
      "[494]\ttraining's binary_logloss: 0.566119\n",
      "[495]\ttraining's binary_logloss: 0.566028\n",
      "[496]\ttraining's binary_logloss: 0.565965\n",
      "[497]\ttraining's binary_logloss: 0.5659\n",
      "[498]\ttraining's binary_logloss: 0.565839\n",
      "[499]\ttraining's binary_logloss: 0.565781\n",
      "[500]\ttraining's binary_logloss: 0.565722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.613947\n",
      "[2]\ttraining's binary_logloss: 0.612838\n",
      "[3]\ttraining's binary_logloss: 0.611823\n",
      "[4]\ttraining's binary_logloss: 0.610777\n",
      "[5]\ttraining's binary_logloss: 0.609833\n",
      "[6]\ttraining's binary_logloss: 0.608897\n",
      "[7]\ttraining's binary_logloss: 0.607985\n",
      "[8]\ttraining's binary_logloss: 0.607114\n",
      "[9]\ttraining's binary_logloss: 0.606356\n",
      "[10]\ttraining's binary_logloss: 0.605548\n",
      "[11]\ttraining's binary_logloss: 0.604695\n",
      "[12]\ttraining's binary_logloss: 0.603878\n",
      "[13]\ttraining's binary_logloss: 0.603168\n",
      "[14]\ttraining's binary_logloss: 0.602485\n",
      "[15]\ttraining's binary_logloss: 0.601758\n",
      "[16]\ttraining's binary_logloss: 0.601027\n",
      "[17]\ttraining's binary_logloss: 0.600465\n",
      "[18]\ttraining's binary_logloss: 0.599789\n",
      "[19]\ttraining's binary_logloss: 0.599216\n",
      "[20]\ttraining's binary_logloss: 0.59865\n",
      "[21]\ttraining's binary_logloss: 0.598086\n",
      "[22]\ttraining's binary_logloss: 0.597522\n",
      "[23]\ttraining's binary_logloss: 0.596949\n",
      "[24]\ttraining's binary_logloss: 0.596432\n",
      "[25]\ttraining's binary_logloss: 0.595934\n",
      "[26]\ttraining's binary_logloss: 0.595454\n",
      "[27]\ttraining's binary_logloss: 0.595028\n",
      "[28]\ttraining's binary_logloss: 0.594604\n",
      "[29]\ttraining's binary_logloss: 0.594211\n",
      "[30]\ttraining's binary_logloss: 0.593806\n",
      "[31]\ttraining's binary_logloss: 0.593341\n",
      "[32]\ttraining's binary_logloss: 0.592929\n",
      "[33]\ttraining's binary_logloss: 0.592503\n",
      "[34]\ttraining's binary_logloss: 0.592137\n",
      "[35]\ttraining's binary_logloss: 0.591725\n",
      "[36]\ttraining's binary_logloss: 0.591448\n",
      "[37]\ttraining's binary_logloss: 0.591124\n",
      "[38]\ttraining's binary_logloss: 0.590822\n",
      "[39]\ttraining's binary_logloss: 0.59053\n",
      "[40]\ttraining's binary_logloss: 0.590259\n",
      "[41]\ttraining's binary_logloss: 0.589907\n",
      "[42]\ttraining's binary_logloss: 0.589669\n",
      "[43]\ttraining's binary_logloss: 0.589426\n",
      "[44]\ttraining's binary_logloss: 0.58912\n",
      "[45]\ttraining's binary_logloss: 0.588821\n",
      "[46]\ttraining's binary_logloss: 0.58854\n",
      "[47]\ttraining's binary_logloss: 0.588302\n",
      "[48]\ttraining's binary_logloss: 0.588079\n",
      "[49]\ttraining's binary_logloss: 0.587925\n",
      "[50]\ttraining's binary_logloss: 0.587658\n",
      "[51]\ttraining's binary_logloss: 0.587372\n",
      "[52]\ttraining's binary_logloss: 0.587183\n",
      "[53]\ttraining's binary_logloss: 0.586998\n",
      "[54]\ttraining's binary_logloss: 0.586802\n",
      "[55]\ttraining's binary_logloss: 0.586573\n",
      "[56]\ttraining's binary_logloss: 0.586425\n",
      "[57]\ttraining's binary_logloss: 0.586266\n",
      "[58]\ttraining's binary_logloss: 0.586117\n",
      "[59]\ttraining's binary_logloss: 0.586006\n",
      "[60]\ttraining's binary_logloss: 0.58588\n",
      "[61]\ttraining's binary_logloss: 0.585746\n",
      "[62]\ttraining's binary_logloss: 0.585594\n",
      "[63]\ttraining's binary_logloss: 0.585487\n",
      "[64]\ttraining's binary_logloss: 0.58535\n",
      "[65]\ttraining's binary_logloss: 0.585234\n",
      "[66]\ttraining's binary_logloss: 0.585147\n",
      "[67]\ttraining's binary_logloss: 0.585083\n",
      "[68]\ttraining's binary_logloss: 0.585002\n",
      "[69]\ttraining's binary_logloss: 0.584941\n",
      "[70]\ttraining's binary_logloss: 0.584886\n",
      "[71]\ttraining's binary_logloss: 0.58484\n",
      "[72]\ttraining's binary_logloss: 0.584799\n",
      "[73]\ttraining's binary_logloss: 0.584766\n",
      "[74]\ttraining's binary_logloss: 0.584668\n",
      "[75]\ttraining's binary_logloss: 0.584577\n",
      "[76]\ttraining's binary_logloss: 0.584515\n",
      "[77]\ttraining's binary_logloss: 0.584439\n",
      "[78]\ttraining's binary_logloss: 0.584396\n",
      "[79]\ttraining's binary_logloss: 0.584334\n",
      "[80]\ttraining's binary_logloss: 0.584289\n",
      "[81]\ttraining's binary_logloss: 0.584204\n",
      "[82]\ttraining's binary_logloss: 0.58413\n",
      "[83]\ttraining's binary_logloss: 0.584061\n",
      "[84]\ttraining's binary_logloss: 0.584021\n",
      "[85]\ttraining's binary_logloss: 0.584003\n",
      "[86]\ttraining's binary_logloss: 0.583953\n",
      "[87]\ttraining's binary_logloss: 0.583934\n",
      "[88]\ttraining's binary_logloss: 0.583895\n",
      "[89]\ttraining's binary_logloss: 0.583867\n",
      "[90]\ttraining's binary_logloss: 0.583856\n",
      "[91]\ttraining's binary_logloss: 0.583856\n",
      "[92]\ttraining's binary_logloss: 0.583843\n",
      "[93]\ttraining's binary_logloss: 0.583839\n",
      "[94]\ttraining's binary_logloss: 0.583856\n",
      "[95]\ttraining's binary_logloss: 0.583908\n",
      "[96]\ttraining's binary_logloss: 0.583898\n",
      "[97]\ttraining's binary_logloss: 0.583929\n",
      "[98]\ttraining's binary_logloss: 0.583874\n",
      "[99]\ttraining's binary_logloss: 0.583825\n",
      "[100]\ttraining's binary_logloss: 0.583807\n",
      "[101]\ttraining's binary_logloss: 0.583792\n",
      "[102]\ttraining's binary_logloss: 0.583774\n",
      "[103]\ttraining's binary_logloss: 0.583815\n",
      "[104]\ttraining's binary_logloss: 0.583786\n",
      "[105]\ttraining's binary_logloss: 0.583777\n",
      "[106]\ttraining's binary_logloss: 0.583807\n",
      "[107]\ttraining's binary_logloss: 0.583831\n",
      "[108]\ttraining's binary_logloss: 0.583859\n",
      "[109]\ttraining's binary_logloss: 0.583893\n",
      "[110]\ttraining's binary_logloss: 0.583927\n",
      "[111]\ttraining's binary_logloss: 0.583943\n",
      "[112]\ttraining's binary_logloss: 0.583944\n",
      "[113]\ttraining's binary_logloss: 0.583945\n",
      "[114]\ttraining's binary_logloss: 0.583952\n",
      "[115]\ttraining's binary_logloss: 0.583991\n",
      "[116]\ttraining's binary_logloss: 0.583975\n",
      "[117]\ttraining's binary_logloss: 0.583958\n",
      "[118]\ttraining's binary_logloss: 0.583979\n",
      "[119]\ttraining's binary_logloss: 0.583973\n",
      "[120]\ttraining's binary_logloss: 0.583974\n",
      "[121]\ttraining's binary_logloss: 0.583979\n",
      "[122]\ttraining's binary_logloss: 0.583987\n",
      "[123]\ttraining's binary_logloss: 0.583993\n",
      "[124]\ttraining's binary_logloss: 0.583968\n",
      "[125]\ttraining's binary_logloss: 0.583947\n",
      "[126]\ttraining's binary_logloss: 0.583957\n",
      "[127]\ttraining's binary_logloss: 0.583961\n",
      "[128]\ttraining's binary_logloss: 0.583952\n",
      "[129]\ttraining's binary_logloss: 0.583962\n",
      "[130]\ttraining's binary_logloss: 0.58402\n",
      "[131]\ttraining's binary_logloss: 0.584023\n",
      "[132]\ttraining's binary_logloss: 0.584042\n",
      "[133]\ttraining's binary_logloss: 0.584077\n",
      "[134]\ttraining's binary_logloss: 0.584075\n",
      "[135]\ttraining's binary_logloss: 0.584097\n",
      "[136]\ttraining's binary_logloss: 0.584167\n",
      "[137]\ttraining's binary_logloss: 0.584194\n",
      "[138]\ttraining's binary_logloss: 0.584223\n",
      "[139]\ttraining's binary_logloss: 0.584255\n",
      "[140]\ttraining's binary_logloss: 0.584314\n",
      "[141]\ttraining's binary_logloss: 0.584307\n",
      "[142]\ttraining's binary_logloss: 0.584312\n",
      "[143]\ttraining's binary_logloss: 0.584311\n",
      "[144]\ttraining's binary_logloss: 0.584302\n",
      "[145]\ttraining's binary_logloss: 0.584309\n",
      "[146]\ttraining's binary_logloss: 0.584317\n",
      "[147]\ttraining's binary_logloss: 0.584296\n",
      "[148]\ttraining's binary_logloss: 0.584278\n",
      "[149]\ttraining's binary_logloss: 0.584268\n",
      "[150]\ttraining's binary_logloss: 0.584261\n",
      "[151]\ttraining's binary_logloss: 0.584278\n",
      "[152]\ttraining's binary_logloss: 0.584332\n",
      "[153]\ttraining's binary_logloss: 0.58435\n",
      "[154]\ttraining's binary_logloss: 0.584395\n",
      "[155]\ttraining's binary_logloss: 0.584448\n",
      "[156]\ttraining's binary_logloss: 0.584494\n",
      "[157]\ttraining's binary_logloss: 0.584533\n",
      "[158]\ttraining's binary_logloss: 0.584531\n",
      "[159]\ttraining's binary_logloss: 0.584561\n",
      "[160]\ttraining's binary_logloss: 0.584605\n",
      "[161]\ttraining's binary_logloss: 0.584569\n",
      "[162]\ttraining's binary_logloss: 0.584538\n",
      "[163]\ttraining's binary_logloss: 0.584528\n",
      "[164]\ttraining's binary_logloss: 0.584505\n",
      "[165]\ttraining's binary_logloss: 0.584479\n",
      "[166]\ttraining's binary_logloss: 0.584495\n",
      "[167]\ttraining's binary_logloss: 0.584525\n",
      "[168]\ttraining's binary_logloss: 0.584537\n",
      "[169]\ttraining's binary_logloss: 0.584555\n",
      "[170]\ttraining's binary_logloss: 0.584573\n",
      "[171]\ttraining's binary_logloss: 0.584559\n",
      "[172]\ttraining's binary_logloss: 0.58455\n",
      "[173]\ttraining's binary_logloss: 0.584565\n",
      "[174]\ttraining's binary_logloss: 0.584556\n",
      "[175]\ttraining's binary_logloss: 0.584598\n",
      "[176]\ttraining's binary_logloss: 0.584568\n",
      "[177]\ttraining's binary_logloss: 0.584573\n",
      "[178]\ttraining's binary_logloss: 0.584563\n",
      "[179]\ttraining's binary_logloss: 0.584565\n",
      "[180]\ttraining's binary_logloss: 0.584563\n",
      "[181]\ttraining's binary_logloss: 0.584564\n",
      "[182]\ttraining's binary_logloss: 0.584568\n",
      "[183]\ttraining's binary_logloss: 0.584599\n",
      "[184]\ttraining's binary_logloss: 0.584605\n",
      "[185]\ttraining's binary_logloss: 0.584613\n",
      "[186]\ttraining's binary_logloss: 0.584606\n",
      "[187]\ttraining's binary_logloss: 0.58462\n",
      "[188]\ttraining's binary_logloss: 0.584652\n",
      "[189]\ttraining's binary_logloss: 0.584648\n",
      "[190]\ttraining's binary_logloss: 0.58466\n",
      "[191]\ttraining's binary_logloss: 0.584689\n",
      "[192]\ttraining's binary_logloss: 0.584707\n",
      "[193]\ttraining's binary_logloss: 0.584728\n",
      "[194]\ttraining's binary_logloss: 0.584748\n",
      "[195]\ttraining's binary_logloss: 0.58477\n",
      "[196]\ttraining's binary_logloss: 0.584752\n",
      "[197]\ttraining's binary_logloss: 0.584759\n",
      "[198]\ttraining's binary_logloss: 0.584769\n",
      "[199]\ttraining's binary_logloss: 0.584774\n",
      "[200]\ttraining's binary_logloss: 0.584795\n",
      "[201]\ttraining's binary_logloss: 0.584773\n",
      "[202]\ttraining's binary_logloss: 0.584743\n",
      "[203]\ttraining's binary_logloss: 0.58471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[204]\ttraining's binary_logloss: 0.584679\n",
      "[205]\ttraining's binary_logloss: 0.584665\n",
      "[206]\ttraining's binary_logloss: 0.584663\n",
      "[207]\ttraining's binary_logloss: 0.584664\n",
      "[208]\ttraining's binary_logloss: 0.584662\n",
      "[209]\ttraining's binary_logloss: 0.58464\n",
      "[210]\ttraining's binary_logloss: 0.584638\n",
      "[211]\ttraining's binary_logloss: 0.584624\n",
      "[212]\ttraining's binary_logloss: 0.584626\n",
      "[213]\ttraining's binary_logloss: 0.584619\n",
      "[214]\ttraining's binary_logloss: 0.5846\n",
      "[215]\ttraining's binary_logloss: 0.584585\n",
      "[216]\ttraining's binary_logloss: 0.584562\n",
      "[217]\ttraining's binary_logloss: 0.584525\n",
      "[218]\ttraining's binary_logloss: 0.5845\n",
      "[219]\ttraining's binary_logloss: 0.584466\n",
      "[220]\ttraining's binary_logloss: 0.584439\n",
      "[221]\ttraining's binary_logloss: 0.584379\n",
      "[222]\ttraining's binary_logloss: 0.584304\n",
      "[223]\ttraining's binary_logloss: 0.58429\n",
      "[224]\ttraining's binary_logloss: 0.58426\n",
      "[225]\ttraining's binary_logloss: 0.584188\n",
      "[226]\ttraining's binary_logloss: 0.584167\n",
      "[227]\ttraining's binary_logloss: 0.584155\n",
      "[228]\ttraining's binary_logloss: 0.584142\n",
      "[229]\ttraining's binary_logloss: 0.584123\n",
      "[230]\ttraining's binary_logloss: 0.584107\n",
      "[231]\ttraining's binary_logloss: 0.584092\n",
      "[232]\ttraining's binary_logloss: 0.584038\n",
      "[233]\ttraining's binary_logloss: 0.58399\n",
      "[234]\ttraining's binary_logloss: 0.583957\n",
      "[235]\ttraining's binary_logloss: 0.583907\n",
      "[236]\ttraining's binary_logloss: 0.583902\n",
      "[237]\ttraining's binary_logloss: 0.583891\n",
      "[238]\ttraining's binary_logloss: 0.583868\n",
      "[239]\ttraining's binary_logloss: 0.583831\n",
      "[240]\ttraining's binary_logloss: 0.583826\n",
      "[241]\ttraining's binary_logloss: 0.583781\n",
      "[242]\ttraining's binary_logloss: 0.583728\n",
      "[243]\ttraining's binary_logloss: 0.583677\n",
      "[244]\ttraining's binary_logloss: 0.583621\n",
      "[245]\ttraining's binary_logloss: 0.58357\n",
      "[246]\ttraining's binary_logloss: 0.583523\n",
      "[247]\ttraining's binary_logloss: 0.583477\n",
      "[248]\ttraining's binary_logloss: 0.583452\n",
      "[249]\ttraining's binary_logloss: 0.583409\n",
      "[250]\ttraining's binary_logloss: 0.583374\n",
      "[251]\ttraining's binary_logloss: 0.583356\n",
      "[252]\ttraining's binary_logloss: 0.583321\n",
      "[253]\ttraining's binary_logloss: 0.583292\n",
      "[254]\ttraining's binary_logloss: 0.58326\n",
      "[255]\ttraining's binary_logloss: 0.583228\n",
      "[256]\ttraining's binary_logloss: 0.583176\n",
      "[257]\ttraining's binary_logloss: 0.583124\n",
      "[258]\ttraining's binary_logloss: 0.583069\n",
      "[259]\ttraining's binary_logloss: 0.583016\n",
      "[260]\ttraining's binary_logloss: 0.582956\n",
      "[261]\ttraining's binary_logloss: 0.582931\n",
      "[262]\ttraining's binary_logloss: 0.582922\n",
      "[263]\ttraining's binary_logloss: 0.582897\n",
      "[264]\ttraining's binary_logloss: 0.58287\n",
      "[265]\ttraining's binary_logloss: 0.582848\n",
      "[266]\ttraining's binary_logloss: 0.582796\n",
      "[267]\ttraining's binary_logloss: 0.582768\n",
      "[268]\ttraining's binary_logloss: 0.582747\n",
      "[269]\ttraining's binary_logloss: 0.582728\n",
      "[270]\ttraining's binary_logloss: 0.582718\n",
      "[271]\ttraining's binary_logloss: 0.582685\n",
      "[272]\ttraining's binary_logloss: 0.582646\n",
      "[273]\ttraining's binary_logloss: 0.582609\n",
      "[274]\ttraining's binary_logloss: 0.582579\n",
      "[275]\ttraining's binary_logloss: 0.582549\n",
      "[276]\ttraining's binary_logloss: 0.582527\n",
      "[277]\ttraining's binary_logloss: 0.582503\n",
      "[278]\ttraining's binary_logloss: 0.582478\n",
      "[279]\ttraining's binary_logloss: 0.582444\n",
      "[280]\ttraining's binary_logloss: 0.582409\n",
      "[281]\ttraining's binary_logloss: 0.582345\n",
      "[282]\ttraining's binary_logloss: 0.582293\n",
      "[283]\ttraining's binary_logloss: 0.582241\n",
      "[284]\ttraining's binary_logloss: 0.582191\n",
      "[285]\ttraining's binary_logloss: 0.582103\n",
      "[286]\ttraining's binary_logloss: 0.582058\n",
      "[287]\ttraining's binary_logloss: 0.581994\n",
      "[288]\ttraining's binary_logloss: 0.581935\n",
      "[289]\ttraining's binary_logloss: 0.581895\n",
      "[290]\ttraining's binary_logloss: 0.581836\n",
      "[291]\ttraining's binary_logloss: 0.58176\n",
      "[292]\ttraining's binary_logloss: 0.581687\n",
      "[293]\ttraining's binary_logloss: 0.581601\n",
      "[294]\ttraining's binary_logloss: 0.58153\n",
      "[295]\ttraining's binary_logloss: 0.581466\n",
      "[296]\ttraining's binary_logloss: 0.581418\n",
      "[297]\ttraining's binary_logloss: 0.581379\n",
      "[298]\ttraining's binary_logloss: 0.581341\n",
      "[299]\ttraining's binary_logloss: 0.581288\n",
      "[300]\ttraining's binary_logloss: 0.581235\n",
      "[301]\ttraining's binary_logloss: 0.581191\n",
      "[302]\ttraining's binary_logloss: 0.581174\n",
      "[303]\ttraining's binary_logloss: 0.581133\n",
      "[304]\ttraining's binary_logloss: 0.581112\n",
      "[305]\ttraining's binary_logloss: 0.581075\n",
      "[306]\ttraining's binary_logloss: 0.581041\n",
      "[307]\ttraining's binary_logloss: 0.580977\n",
      "[308]\ttraining's binary_logloss: 0.580932\n",
      "[309]\ttraining's binary_logloss: 0.580872\n",
      "[310]\ttraining's binary_logloss: 0.580834\n",
      "[311]\ttraining's binary_logloss: 0.580778\n",
      "[312]\ttraining's binary_logloss: 0.580732\n",
      "[313]\ttraining's binary_logloss: 0.580677\n",
      "[314]\ttraining's binary_logloss: 0.580642\n",
      "[315]\ttraining's binary_logloss: 0.58059\n",
      "[316]\ttraining's binary_logloss: 0.580524\n",
      "[317]\ttraining's binary_logloss: 0.580459\n",
      "[318]\ttraining's binary_logloss: 0.580397\n",
      "[319]\ttraining's binary_logloss: 0.580308\n",
      "[320]\ttraining's binary_logloss: 0.580234\n",
      "[321]\ttraining's binary_logloss: 0.580177\n",
      "[322]\ttraining's binary_logloss: 0.58012\n",
      "[323]\ttraining's binary_logloss: 0.580045\n",
      "[324]\ttraining's binary_logloss: 0.57999\n",
      "[325]\ttraining's binary_logloss: 0.579914\n",
      "[326]\ttraining's binary_logloss: 0.579837\n",
      "[327]\ttraining's binary_logloss: 0.579777\n",
      "[328]\ttraining's binary_logloss: 0.579734\n",
      "[329]\ttraining's binary_logloss: 0.579684\n",
      "[330]\ttraining's binary_logloss: 0.579629\n",
      "[331]\ttraining's binary_logloss: 0.579573\n",
      "[332]\ttraining's binary_logloss: 0.579513\n",
      "[333]\ttraining's binary_logloss: 0.579459\n",
      "[334]\ttraining's binary_logloss: 0.579401\n",
      "[335]\ttraining's binary_logloss: 0.579343\n",
      "[336]\ttraining's binary_logloss: 0.579268\n",
      "[337]\ttraining's binary_logloss: 0.579199\n",
      "[338]\ttraining's binary_logloss: 0.579128\n",
      "[339]\ttraining's binary_logloss: 0.579053\n",
      "[340]\ttraining's binary_logloss: 0.578978\n",
      "[341]\ttraining's binary_logloss: 0.57889\n",
      "[342]\ttraining's binary_logloss: 0.578804\n",
      "[343]\ttraining's binary_logloss: 0.578742\n",
      "[344]\ttraining's binary_logloss: 0.578632\n",
      "[345]\ttraining's binary_logloss: 0.57853\n",
      "[346]\ttraining's binary_logloss: 0.578489\n",
      "[347]\ttraining's binary_logloss: 0.578449\n",
      "[348]\ttraining's binary_logloss: 0.578403\n",
      "[349]\ttraining's binary_logloss: 0.57835\n",
      "[350]\ttraining's binary_logloss: 0.578294\n",
      "[351]\ttraining's binary_logloss: 0.578214\n",
      "[352]\ttraining's binary_logloss: 0.578128\n",
      "[353]\ttraining's binary_logloss: 0.578048\n",
      "[354]\ttraining's binary_logloss: 0.577965\n",
      "[355]\ttraining's binary_logloss: 0.577889\n",
      "[356]\ttraining's binary_logloss: 0.577815\n",
      "[357]\ttraining's binary_logloss: 0.577751\n",
      "[358]\ttraining's binary_logloss: 0.577685\n",
      "[359]\ttraining's binary_logloss: 0.577622\n",
      "[360]\ttraining's binary_logloss: 0.577561\n",
      "[361]\ttraining's binary_logloss: 0.577435\n",
      "[362]\ttraining's binary_logloss: 0.577318\n",
      "[363]\ttraining's binary_logloss: 0.57721\n",
      "[364]\ttraining's binary_logloss: 0.577126\n",
      "[365]\ttraining's binary_logloss: 0.577018\n",
      "[366]\ttraining's binary_logloss: 0.576921\n",
      "[367]\ttraining's binary_logloss: 0.576828\n",
      "[368]\ttraining's binary_logloss: 0.576702\n",
      "[369]\ttraining's binary_logloss: 0.576589\n",
      "[370]\ttraining's binary_logloss: 0.576467\n",
      "[371]\ttraining's binary_logloss: 0.576397\n",
      "[372]\ttraining's binary_logloss: 0.576294\n",
      "[373]\ttraining's binary_logloss: 0.576204\n",
      "[374]\ttraining's binary_logloss: 0.576103\n",
      "[375]\ttraining's binary_logloss: 0.575999\n",
      "[376]\ttraining's binary_logloss: 0.575925\n",
      "[377]\ttraining's binary_logloss: 0.575851\n",
      "[378]\ttraining's binary_logloss: 0.575754\n",
      "[379]\ttraining's binary_logloss: 0.575657\n",
      "[380]\ttraining's binary_logloss: 0.575562\n",
      "[381]\ttraining's binary_logloss: 0.5755\n",
      "[382]\ttraining's binary_logloss: 0.575415\n",
      "[383]\ttraining's binary_logloss: 0.575335\n",
      "[384]\ttraining's binary_logloss: 0.575261\n",
      "[385]\ttraining's binary_logloss: 0.575184\n",
      "[386]\ttraining's binary_logloss: 0.575093\n",
      "[387]\ttraining's binary_logloss: 0.575008\n",
      "[388]\ttraining's binary_logloss: 0.574916\n",
      "[389]\ttraining's binary_logloss: 0.574833\n",
      "[390]\ttraining's binary_logloss: 0.574757\n",
      "[391]\ttraining's binary_logloss: 0.574664\n",
      "[392]\ttraining's binary_logloss: 0.574573\n",
      "[393]\ttraining's binary_logloss: 0.574486\n",
      "[394]\ttraining's binary_logloss: 0.574396\n",
      "[395]\ttraining's binary_logloss: 0.57431\n",
      "[396]\ttraining's binary_logloss: 0.57423\n",
      "[397]\ttraining's binary_logloss: 0.574157\n",
      "[398]\ttraining's binary_logloss: 0.574084\n",
      "[399]\ttraining's binary_logloss: 0.573999\n",
      "[400]\ttraining's binary_logloss: 0.573922\n",
      "[401]\ttraining's binary_logloss: 0.573857\n",
      "[402]\ttraining's binary_logloss: 0.573793\n",
      "[403]\ttraining's binary_logloss: 0.573731\n",
      "[404]\ttraining's binary_logloss: 0.573682\n",
      "[405]\ttraining's binary_logloss: 0.573624\n",
      "[406]\ttraining's binary_logloss: 0.573568\n",
      "[407]\ttraining's binary_logloss: 0.573501\n",
      "[408]\ttraining's binary_logloss: 0.573449\n",
      "[409]\ttraining's binary_logloss: 0.573391\n",
      "[410]\ttraining's binary_logloss: 0.573318\n",
      "[411]\ttraining's binary_logloss: 0.573254\n",
      "[412]\ttraining's binary_logloss: 0.573197\n",
      "[413]\ttraining's binary_logloss: 0.573136\n",
      "[414]\ttraining's binary_logloss: 0.573081\n",
      "[415]\ttraining's binary_logloss: 0.573023\n",
      "[416]\ttraining's binary_logloss: 0.572921\n",
      "[417]\ttraining's binary_logloss: 0.572823\n",
      "[418]\ttraining's binary_logloss: 0.572726\n",
      "[419]\ttraining's binary_logloss: 0.572632\n",
      "[420]\ttraining's binary_logloss: 0.572544\n",
      "[421]\ttraining's binary_logloss: 0.572498\n",
      "[422]\ttraining's binary_logloss: 0.572453\n",
      "[423]\ttraining's binary_logloss: 0.572411\n",
      "[424]\ttraining's binary_logloss: 0.572366\n",
      "[425]\ttraining's binary_logloss: 0.572324\n",
      "[426]\ttraining's binary_logloss: 0.572242\n",
      "[427]\ttraining's binary_logloss: 0.57216\n",
      "[428]\ttraining's binary_logloss: 0.57208\n",
      "[429]\ttraining's binary_logloss: 0.571998\n",
      "[430]\ttraining's binary_logloss: 0.571916\n",
      "[431]\ttraining's binary_logloss: 0.571863\n",
      "[432]\ttraining's binary_logloss: 0.571816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[433]\ttraining's binary_logloss: 0.571774\n",
      "[434]\ttraining's binary_logloss: 0.57171\n",
      "[435]\ttraining's binary_logloss: 0.571664\n",
      "[436]\ttraining's binary_logloss: 0.571582\n",
      "[437]\ttraining's binary_logloss: 0.571502\n",
      "[438]\ttraining's binary_logloss: 0.571421\n",
      "[439]\ttraining's binary_logloss: 0.571345\n",
      "[440]\ttraining's binary_logloss: 0.571285\n",
      "[441]\ttraining's binary_logloss: 0.571176\n",
      "[442]\ttraining's binary_logloss: 0.571064\n",
      "[443]\ttraining's binary_logloss: 0.570957\n",
      "[444]\ttraining's binary_logloss: 0.570855\n",
      "[445]\ttraining's binary_logloss: 0.570745\n",
      "[446]\ttraining's binary_logloss: 0.570639\n",
      "[447]\ttraining's binary_logloss: 0.57057\n",
      "[448]\ttraining's binary_logloss: 0.570504\n",
      "[449]\ttraining's binary_logloss: 0.570398\n",
      "[450]\ttraining's binary_logloss: 0.570333\n",
      "[451]\ttraining's binary_logloss: 0.570242\n",
      "[452]\ttraining's binary_logloss: 0.570177\n",
      "[453]\ttraining's binary_logloss: 0.570095\n",
      "[454]\ttraining's binary_logloss: 0.57001\n",
      "[455]\ttraining's binary_logloss: 0.569922\n",
      "[456]\ttraining's binary_logloss: 0.569849\n",
      "[457]\ttraining's binary_logloss: 0.569791\n",
      "[458]\ttraining's binary_logloss: 0.569731\n",
      "[459]\ttraining's binary_logloss: 0.569691\n",
      "[460]\ttraining's binary_logloss: 0.569634\n",
      "[461]\ttraining's binary_logloss: 0.569557\n",
      "[462]\ttraining's binary_logloss: 0.569482\n",
      "[463]\ttraining's binary_logloss: 0.569417\n",
      "[464]\ttraining's binary_logloss: 0.56934\n",
      "[465]\ttraining's binary_logloss: 0.56926\n",
      "[466]\ttraining's binary_logloss: 0.569154\n",
      "[467]\ttraining's binary_logloss: 0.569054\n",
      "[468]\ttraining's binary_logloss: 0.568955\n",
      "[469]\ttraining's binary_logloss: 0.568858\n",
      "[470]\ttraining's binary_logloss: 0.568763\n",
      "[471]\ttraining's binary_logloss: 0.568696\n",
      "[472]\ttraining's binary_logloss: 0.568627\n",
      "[473]\ttraining's binary_logloss: 0.568563\n",
      "[474]\ttraining's binary_logloss: 0.568506\n",
      "[475]\ttraining's binary_logloss: 0.568446\n",
      "[476]\ttraining's binary_logloss: 0.568366\n",
      "[477]\ttraining's binary_logloss: 0.568302\n",
      "[478]\ttraining's binary_logloss: 0.568222\n",
      "[479]\ttraining's binary_logloss: 0.568144\n",
      "[480]\ttraining's binary_logloss: 0.568067\n",
      "[481]\ttraining's binary_logloss: 0.567974\n",
      "[482]\ttraining's binary_logloss: 0.56788\n",
      "[483]\ttraining's binary_logloss: 0.567779\n",
      "[484]\ttraining's binary_logloss: 0.567684\n",
      "[485]\ttraining's binary_logloss: 0.567594\n",
      "[486]\ttraining's binary_logloss: 0.567493\n",
      "[487]\ttraining's binary_logloss: 0.567387\n",
      "[488]\ttraining's binary_logloss: 0.567312\n",
      "[489]\ttraining's binary_logloss: 0.567236\n",
      "[490]\ttraining's binary_logloss: 0.567132\n",
      "[491]\ttraining's binary_logloss: 0.567021\n",
      "[492]\ttraining's binary_logloss: 0.566911\n",
      "[493]\ttraining's binary_logloss: 0.56682\n",
      "[494]\ttraining's binary_logloss: 0.566712\n",
      "[495]\ttraining's binary_logloss: 0.566631\n",
      "[496]\ttraining's binary_logloss: 0.566571\n",
      "[497]\ttraining's binary_logloss: 0.566503\n",
      "[498]\ttraining's binary_logloss: 0.566441\n",
      "[499]\ttraining's binary_logloss: 0.566377\n",
      "[500]\ttraining's binary_logloss: 0.56632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614528\n",
      "[2]\ttraining's binary_logloss: 0.613409\n",
      "[3]\ttraining's binary_logloss: 0.612308\n",
      "[4]\ttraining's binary_logloss: 0.611273\n",
      "[5]\ttraining's binary_logloss: 0.610434\n",
      "[6]\ttraining's binary_logloss: 0.609441\n",
      "[7]\ttraining's binary_logloss: 0.608565\n",
      "[8]\ttraining's binary_logloss: 0.607725\n",
      "[9]\ttraining's binary_logloss: 0.606877\n",
      "[10]\ttraining's binary_logloss: 0.606073\n",
      "[11]\ttraining's binary_logloss: 0.605356\n",
      "[12]\ttraining's binary_logloss: 0.604533\n",
      "[13]\ttraining's binary_logloss: 0.603783\n",
      "[14]\ttraining's binary_logloss: 0.603021\n",
      "[15]\ttraining's binary_logloss: 0.602329\n",
      "[16]\ttraining's binary_logloss: 0.601659\n",
      "[17]\ttraining's binary_logloss: 0.600997\n",
      "[18]\ttraining's binary_logloss: 0.600364\n",
      "[19]\ttraining's binary_logloss: 0.599757\n",
      "[20]\ttraining's binary_logloss: 0.599096\n",
      "[21]\ttraining's binary_logloss: 0.59857\n",
      "[22]\ttraining's binary_logloss: 0.598047\n",
      "[23]\ttraining's binary_logloss: 0.597517\n",
      "[24]\ttraining's binary_logloss: 0.597056\n",
      "[25]\ttraining's binary_logloss: 0.596518\n",
      "[26]\ttraining's binary_logloss: 0.596024\n",
      "[27]\ttraining's binary_logloss: 0.595553\n",
      "[28]\ttraining's binary_logloss: 0.595101\n",
      "[29]\ttraining's binary_logloss: 0.594667\n",
      "[30]\ttraining's binary_logloss: 0.594273\n",
      "[31]\ttraining's binary_logloss: 0.593811\n",
      "[32]\ttraining's binary_logloss: 0.593418\n",
      "[33]\ttraining's binary_logloss: 0.59302\n",
      "[34]\ttraining's binary_logloss: 0.592538\n",
      "[35]\ttraining's binary_logloss: 0.592161\n",
      "[36]\ttraining's binary_logloss: 0.591829\n",
      "[37]\ttraining's binary_logloss: 0.591491\n",
      "[38]\ttraining's binary_logloss: 0.591216\n",
      "[39]\ttraining's binary_logloss: 0.5909\n",
      "[40]\ttraining's binary_logloss: 0.59062\n",
      "[41]\ttraining's binary_logloss: 0.590321\n",
      "[42]\ttraining's binary_logloss: 0.589961\n",
      "[43]\ttraining's binary_logloss: 0.589613\n",
      "[44]\ttraining's binary_logloss: 0.58928\n",
      "[45]\ttraining's binary_logloss: 0.588962\n",
      "[46]\ttraining's binary_logloss: 0.588669\n",
      "[47]\ttraining's binary_logloss: 0.588402\n",
      "[48]\ttraining's binary_logloss: 0.588146\n",
      "[49]\ttraining's binary_logloss: 0.587904\n",
      "[50]\ttraining's binary_logloss: 0.58765\n",
      "[51]\ttraining's binary_logloss: 0.587488\n",
      "[52]\ttraining's binary_logloss: 0.587265\n",
      "[53]\ttraining's binary_logloss: 0.587038\n",
      "[54]\ttraining's binary_logloss: 0.58686\n",
      "[55]\ttraining's binary_logloss: 0.586657\n",
      "[56]\ttraining's binary_logloss: 0.586467\n",
      "[57]\ttraining's binary_logloss: 0.586287\n",
      "[58]\ttraining's binary_logloss: 0.586111\n",
      "[59]\ttraining's binary_logloss: 0.58594\n",
      "[60]\ttraining's binary_logloss: 0.58579\n",
      "[61]\ttraining's binary_logloss: 0.585658\n",
      "[62]\ttraining's binary_logloss: 0.585533\n",
      "[63]\ttraining's binary_logloss: 0.585416\n",
      "[64]\ttraining's binary_logloss: 0.585329\n",
      "[65]\ttraining's binary_logloss: 0.585255\n",
      "[66]\ttraining's binary_logloss: 0.585182\n",
      "[67]\ttraining's binary_logloss: 0.585067\n",
      "[68]\ttraining's binary_logloss: 0.585004\n",
      "[69]\ttraining's binary_logloss: 0.584903\n",
      "[70]\ttraining's binary_logloss: 0.584805\n",
      "[71]\ttraining's binary_logloss: 0.584755\n",
      "[72]\ttraining's binary_logloss: 0.584649\n",
      "[73]\ttraining's binary_logloss: 0.584555\n",
      "[74]\ttraining's binary_logloss: 0.58451\n",
      "[75]\ttraining's binary_logloss: 0.584433\n",
      "[76]\ttraining's binary_logloss: 0.584362\n",
      "[77]\ttraining's binary_logloss: 0.584317\n",
      "[78]\ttraining's binary_logloss: 0.584285\n",
      "[79]\ttraining's binary_logloss: 0.584234\n",
      "[80]\ttraining's binary_logloss: 0.584189\n",
      "[81]\ttraining's binary_logloss: 0.584098\n",
      "[82]\ttraining's binary_logloss: 0.58406\n",
      "[83]\ttraining's binary_logloss: 0.584058\n",
      "[84]\ttraining's binary_logloss: 0.583972\n",
      "[85]\ttraining's binary_logloss: 0.58397\n",
      "[86]\ttraining's binary_logloss: 0.583925\n",
      "[87]\ttraining's binary_logloss: 0.583893\n",
      "[88]\ttraining's binary_logloss: 0.583865\n",
      "[89]\ttraining's binary_logloss: 0.58381\n",
      "[90]\ttraining's binary_logloss: 0.583782\n",
      "[91]\ttraining's binary_logloss: 0.583783\n",
      "[92]\ttraining's binary_logloss: 0.583805\n",
      "[93]\ttraining's binary_logloss: 0.583818\n",
      "[94]\ttraining's binary_logloss: 0.583789\n",
      "[95]\ttraining's binary_logloss: 0.583815\n",
      "[96]\ttraining's binary_logloss: 0.583818\n",
      "[97]\ttraining's binary_logloss: 0.583843\n",
      "[98]\ttraining's binary_logloss: 0.583879\n",
      "[99]\ttraining's binary_logloss: 0.583904\n",
      "[100]\ttraining's binary_logloss: 0.583934\n",
      "[101]\ttraining's binary_logloss: 0.583951\n",
      "[102]\ttraining's binary_logloss: 0.583949\n",
      "[103]\ttraining's binary_logloss: 0.583957\n",
      "[104]\ttraining's binary_logloss: 0.583973\n",
      "[105]\ttraining's binary_logloss: 0.583981\n",
      "[106]\ttraining's binary_logloss: 0.583975\n",
      "[107]\ttraining's binary_logloss: 0.583953\n",
      "[108]\ttraining's binary_logloss: 0.583942\n",
      "[109]\ttraining's binary_logloss: 0.583939\n",
      "[110]\ttraining's binary_logloss: 0.583939\n",
      "[111]\ttraining's binary_logloss: 0.583934\n",
      "[112]\ttraining's binary_logloss: 0.58394\n",
      "[113]\ttraining's binary_logloss: 0.58401\n",
      "[114]\ttraining's binary_logloss: 0.584068\n",
      "[115]\ttraining's binary_logloss: 0.584137\n",
      "[116]\ttraining's binary_logloss: 0.584101\n",
      "[117]\ttraining's binary_logloss: 0.584086\n",
      "[118]\ttraining's binary_logloss: 0.584058\n",
      "[119]\ttraining's binary_logloss: 0.58403\n",
      "[120]\ttraining's binary_logloss: 0.58401\n",
      "[121]\ttraining's binary_logloss: 0.58403\n",
      "[122]\ttraining's binary_logloss: 0.58401\n",
      "[123]\ttraining's binary_logloss: 0.583997\n",
      "[124]\ttraining's binary_logloss: 0.583969\n",
      "[125]\ttraining's binary_logloss: 0.583957\n",
      "[126]\ttraining's binary_logloss: 0.583936\n",
      "[127]\ttraining's binary_logloss: 0.583922\n",
      "[128]\ttraining's binary_logloss: 0.583908\n",
      "[129]\ttraining's binary_logloss: 0.583917\n",
      "[130]\ttraining's binary_logloss: 0.583908\n",
      "[131]\ttraining's binary_logloss: 0.583936\n",
      "[132]\ttraining's binary_logloss: 0.58397\n",
      "[133]\ttraining's binary_logloss: 0.584\n",
      "[134]\ttraining's binary_logloss: 0.584031\n",
      "[135]\ttraining's binary_logloss: 0.584071\n",
      "[136]\ttraining's binary_logloss: 0.584101\n",
      "[137]\ttraining's binary_logloss: 0.584144\n",
      "[138]\ttraining's binary_logloss: 0.584174\n",
      "[139]\ttraining's binary_logloss: 0.584212\n",
      "[140]\ttraining's binary_logloss: 0.584253\n",
      "[141]\ttraining's binary_logloss: 0.584244\n",
      "[142]\ttraining's binary_logloss: 0.584282\n",
      "[143]\ttraining's binary_logloss: 0.584274\n",
      "[144]\ttraining's binary_logloss: 0.584272\n",
      "[145]\ttraining's binary_logloss: 0.584254\n",
      "[146]\ttraining's binary_logloss: 0.584244\n",
      "[147]\ttraining's binary_logloss: 0.584258\n",
      "[148]\ttraining's binary_logloss: 0.584254\n",
      "[149]\ttraining's binary_logloss: 0.58428\n",
      "[150]\ttraining's binary_logloss: 0.58429\n",
      "[151]\ttraining's binary_logloss: 0.584314\n",
      "[152]\ttraining's binary_logloss: 0.584337\n",
      "[153]\ttraining's binary_logloss: 0.584387\n",
      "[154]\ttraining's binary_logloss: 0.584452\n",
      "[155]\ttraining's binary_logloss: 0.584476\n",
      "[156]\ttraining's binary_logloss: 0.584484\n",
      "[157]\ttraining's binary_logloss: 0.584511\n",
      "[158]\ttraining's binary_logloss: 0.584525\n",
      "[159]\ttraining's binary_logloss: 0.584562\n",
      "[160]\ttraining's binary_logloss: 0.584588\n",
      "[161]\ttraining's binary_logloss: 0.584563\n",
      "[162]\ttraining's binary_logloss: 0.584549\n",
      "[163]\ttraining's binary_logloss: 0.58454\n",
      "[164]\ttraining's binary_logloss: 0.58454\n",
      "[165]\ttraining's binary_logloss: 0.584528\n",
      "[166]\ttraining's binary_logloss: 0.584551\n",
      "[167]\ttraining's binary_logloss: 0.584575\n",
      "[168]\ttraining's binary_logloss: 0.584597\n",
      "[169]\ttraining's binary_logloss: 0.584652\n",
      "[170]\ttraining's binary_logloss: 0.584676\n",
      "[171]\ttraining's binary_logloss: 0.584718\n",
      "[172]\ttraining's binary_logloss: 0.584708\n",
      "[173]\ttraining's binary_logloss: 0.584701\n",
      "[174]\ttraining's binary_logloss: 0.584696\n",
      "[175]\ttraining's binary_logloss: 0.584718\n",
      "[176]\ttraining's binary_logloss: 0.584724\n",
      "[177]\ttraining's binary_logloss: 0.584725\n",
      "[178]\ttraining's binary_logloss: 0.58473\n",
      "[179]\ttraining's binary_logloss: 0.584734\n",
      "[180]\ttraining's binary_logloss: 0.584747\n",
      "[181]\ttraining's binary_logloss: 0.584781\n",
      "[182]\ttraining's binary_logloss: 0.584792\n",
      "[183]\ttraining's binary_logloss: 0.584794\n",
      "[184]\ttraining's binary_logloss: 0.584828\n",
      "[185]\ttraining's binary_logloss: 0.584858\n",
      "[186]\ttraining's binary_logloss: 0.584851\n",
      "[187]\ttraining's binary_logloss: 0.584838\n",
      "[188]\ttraining's binary_logloss: 0.584818\n",
      "[189]\ttraining's binary_logloss: 0.584799\n",
      "[190]\ttraining's binary_logloss: 0.584787\n",
      "[191]\ttraining's binary_logloss: 0.584783\n",
      "[192]\ttraining's binary_logloss: 0.584779\n",
      "[193]\ttraining's binary_logloss: 0.584777\n",
      "[194]\ttraining's binary_logloss: 0.584775\n",
      "[195]\ttraining's binary_logloss: 0.584758\n",
      "[196]\ttraining's binary_logloss: 0.584752\n",
      "[197]\ttraining's binary_logloss: 0.584742\n",
      "[198]\ttraining's binary_logloss: 0.584718\n",
      "[199]\ttraining's binary_logloss: 0.584705\n",
      "[200]\ttraining's binary_logloss: 0.584698\n",
      "[201]\ttraining's binary_logloss: 0.58468\n",
      "[202]\ttraining's binary_logloss: 0.584657\n",
      "[203]\ttraining's binary_logloss: 0.584644\n",
      "[204]\ttraining's binary_logloss: 0.584623\n",
      "[205]\ttraining's binary_logloss: 0.58461\n",
      "[206]\ttraining's binary_logloss: 0.584596\n",
      "[207]\ttraining's binary_logloss: 0.584584\n",
      "[208]\ttraining's binary_logloss: 0.584579\n",
      "[209]\ttraining's binary_logloss: 0.584577\n",
      "[210]\ttraining's binary_logloss: 0.584578\n",
      "[211]\ttraining's binary_logloss: 0.584556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[212]\ttraining's binary_logloss: 0.584536\n",
      "[213]\ttraining's binary_logloss: 0.584512\n",
      "[214]\ttraining's binary_logloss: 0.5845\n",
      "[215]\ttraining's binary_logloss: 0.584481\n",
      "[216]\ttraining's binary_logloss: 0.584463\n",
      "[217]\ttraining's binary_logloss: 0.58445\n",
      "[218]\ttraining's binary_logloss: 0.584437\n",
      "[219]\ttraining's binary_logloss: 0.584425\n",
      "[220]\ttraining's binary_logloss: 0.584412\n",
      "[221]\ttraining's binary_logloss: 0.584385\n",
      "[222]\ttraining's binary_logloss: 0.584347\n",
      "[223]\ttraining's binary_logloss: 0.584323\n",
      "[224]\ttraining's binary_logloss: 0.584297\n",
      "[225]\ttraining's binary_logloss: 0.584285\n",
      "[226]\ttraining's binary_logloss: 0.584287\n",
      "[227]\ttraining's binary_logloss: 0.584264\n",
      "[228]\ttraining's binary_logloss: 0.584245\n",
      "[229]\ttraining's binary_logloss: 0.584211\n",
      "[230]\ttraining's binary_logloss: 0.584199\n",
      "[231]\ttraining's binary_logloss: 0.584215\n",
      "[232]\ttraining's binary_logloss: 0.584199\n",
      "[233]\ttraining's binary_logloss: 0.584191\n",
      "[234]\ttraining's binary_logloss: 0.584176\n",
      "[235]\ttraining's binary_logloss: 0.584164\n",
      "[236]\ttraining's binary_logloss: 0.584179\n",
      "[237]\ttraining's binary_logloss: 0.584187\n",
      "[238]\ttraining's binary_logloss: 0.584145\n",
      "[239]\ttraining's binary_logloss: 0.584159\n",
      "[240]\ttraining's binary_logloss: 0.584129\n",
      "[241]\ttraining's binary_logloss: 0.584078\n",
      "[242]\ttraining's binary_logloss: 0.584046\n",
      "[243]\ttraining's binary_logloss: 0.584014\n",
      "[244]\ttraining's binary_logloss: 0.583967\n",
      "[245]\ttraining's binary_logloss: 0.583924\n",
      "[246]\ttraining's binary_logloss: 0.583862\n",
      "[247]\ttraining's binary_logloss: 0.583806\n",
      "[248]\ttraining's binary_logloss: 0.583743\n",
      "[249]\ttraining's binary_logloss: 0.583708\n",
      "[250]\ttraining's binary_logloss: 0.583657\n",
      "[251]\ttraining's binary_logloss: 0.583633\n",
      "[252]\ttraining's binary_logloss: 0.583623\n",
      "[253]\ttraining's binary_logloss: 0.583601\n",
      "[254]\ttraining's binary_logloss: 0.583588\n",
      "[255]\ttraining's binary_logloss: 0.583563\n",
      "[256]\ttraining's binary_logloss: 0.583523\n",
      "[257]\ttraining's binary_logloss: 0.583483\n",
      "[258]\ttraining's binary_logloss: 0.583444\n",
      "[259]\ttraining's binary_logloss: 0.583402\n",
      "[260]\ttraining's binary_logloss: 0.583365\n",
      "[261]\ttraining's binary_logloss: 0.583296\n",
      "[262]\ttraining's binary_logloss: 0.583222\n",
      "[263]\ttraining's binary_logloss: 0.583166\n",
      "[264]\ttraining's binary_logloss: 0.583102\n",
      "[265]\ttraining's binary_logloss: 0.583048\n",
      "[266]\ttraining's binary_logloss: 0.583001\n",
      "[267]\ttraining's binary_logloss: 0.582955\n",
      "[268]\ttraining's binary_logloss: 0.582913\n",
      "[269]\ttraining's binary_logloss: 0.582877\n",
      "[270]\ttraining's binary_logloss: 0.582854\n",
      "[271]\ttraining's binary_logloss: 0.582818\n",
      "[272]\ttraining's binary_logloss: 0.582783\n",
      "[273]\ttraining's binary_logloss: 0.582754\n",
      "[274]\ttraining's binary_logloss: 0.582727\n",
      "[275]\ttraining's binary_logloss: 0.58269\n",
      "[276]\ttraining's binary_logloss: 0.582658\n",
      "[277]\ttraining's binary_logloss: 0.582617\n",
      "[278]\ttraining's binary_logloss: 0.582586\n",
      "[279]\ttraining's binary_logloss: 0.582559\n",
      "[280]\ttraining's binary_logloss: 0.582513\n",
      "[281]\ttraining's binary_logloss: 0.582447\n",
      "[282]\ttraining's binary_logloss: 0.582381\n",
      "[283]\ttraining's binary_logloss: 0.582323\n",
      "[284]\ttraining's binary_logloss: 0.582263\n",
      "[285]\ttraining's binary_logloss: 0.582199\n",
      "[286]\ttraining's binary_logloss: 0.582191\n",
      "[287]\ttraining's binary_logloss: 0.582184\n",
      "[288]\ttraining's binary_logloss: 0.582166\n",
      "[289]\ttraining's binary_logloss: 0.582148\n",
      "[290]\ttraining's binary_logloss: 0.582123\n",
      "[291]\ttraining's binary_logloss: 0.582034\n",
      "[292]\ttraining's binary_logloss: 0.581951\n",
      "[293]\ttraining's binary_logloss: 0.581866\n",
      "[294]\ttraining's binary_logloss: 0.58178\n",
      "[295]\ttraining's binary_logloss: 0.581692\n",
      "[296]\ttraining's binary_logloss: 0.581618\n",
      "[297]\ttraining's binary_logloss: 0.581559\n",
      "[298]\ttraining's binary_logloss: 0.581516\n",
      "[299]\ttraining's binary_logloss: 0.581473\n",
      "[300]\ttraining's binary_logloss: 0.581418\n",
      "[301]\ttraining's binary_logloss: 0.581355\n",
      "[302]\ttraining's binary_logloss: 0.58129\n",
      "[303]\ttraining's binary_logloss: 0.581225\n",
      "[304]\ttraining's binary_logloss: 0.581163\n",
      "[305]\ttraining's binary_logloss: 0.581121\n",
      "[306]\ttraining's binary_logloss: 0.581055\n",
      "[307]\ttraining's binary_logloss: 0.580994\n",
      "[308]\ttraining's binary_logloss: 0.580932\n",
      "[309]\ttraining's binary_logloss: 0.580876\n",
      "[310]\ttraining's binary_logloss: 0.580826\n",
      "[311]\ttraining's binary_logloss: 0.580778\n",
      "[312]\ttraining's binary_logloss: 0.580711\n",
      "[313]\ttraining's binary_logloss: 0.580657\n",
      "[314]\ttraining's binary_logloss: 0.580594\n",
      "[315]\ttraining's binary_logloss: 0.580519\n",
      "[316]\ttraining's binary_logloss: 0.580463\n",
      "[317]\ttraining's binary_logloss: 0.580403\n",
      "[318]\ttraining's binary_logloss: 0.58034\n",
      "[319]\ttraining's binary_logloss: 0.580272\n",
      "[320]\ttraining's binary_logloss: 0.580206\n",
      "[321]\ttraining's binary_logloss: 0.580118\n",
      "[322]\ttraining's binary_logloss: 0.580041\n",
      "[323]\ttraining's binary_logloss: 0.579956\n",
      "[324]\ttraining's binary_logloss: 0.579868\n",
      "[325]\ttraining's binary_logloss: 0.579804\n",
      "[326]\ttraining's binary_logloss: 0.579751\n",
      "[327]\ttraining's binary_logloss: 0.579699\n",
      "[328]\ttraining's binary_logloss: 0.579652\n",
      "[329]\ttraining's binary_logloss: 0.579599\n",
      "[330]\ttraining's binary_logloss: 0.579552\n",
      "[331]\ttraining's binary_logloss: 0.579481\n",
      "[332]\ttraining's binary_logloss: 0.579413\n",
      "[333]\ttraining's binary_logloss: 0.579356\n",
      "[334]\ttraining's binary_logloss: 0.579311\n",
      "[335]\ttraining's binary_logloss: 0.579246\n",
      "[336]\ttraining's binary_logloss: 0.579192\n",
      "[337]\ttraining's binary_logloss: 0.579115\n",
      "[338]\ttraining's binary_logloss: 0.579054\n",
      "[339]\ttraining's binary_logloss: 0.579003\n",
      "[340]\ttraining's binary_logloss: 0.578955\n",
      "[341]\ttraining's binary_logloss: 0.578863\n",
      "[342]\ttraining's binary_logloss: 0.578773\n",
      "[343]\ttraining's binary_logloss: 0.57868\n",
      "[344]\ttraining's binary_logloss: 0.578596\n",
      "[345]\ttraining's binary_logloss: 0.578508\n",
      "[346]\ttraining's binary_logloss: 0.578444\n",
      "[347]\ttraining's binary_logloss: 0.578402\n",
      "[348]\ttraining's binary_logloss: 0.578356\n",
      "[349]\ttraining's binary_logloss: 0.578315\n",
      "[350]\ttraining's binary_logloss: 0.57827\n",
      "[351]\ttraining's binary_logloss: 0.578179\n",
      "[352]\ttraining's binary_logloss: 0.578101\n",
      "[353]\ttraining's binary_logloss: 0.57803\n",
      "[354]\ttraining's binary_logloss: 0.577968\n",
      "[355]\ttraining's binary_logloss: 0.57788\n",
      "[356]\ttraining's binary_logloss: 0.577799\n",
      "[357]\ttraining's binary_logloss: 0.577723\n",
      "[358]\ttraining's binary_logloss: 0.577646\n",
      "[359]\ttraining's binary_logloss: 0.577573\n",
      "[360]\ttraining's binary_logloss: 0.577505\n",
      "[361]\ttraining's binary_logloss: 0.577395\n",
      "[362]\ttraining's binary_logloss: 0.577283\n",
      "[363]\ttraining's binary_logloss: 0.577189\n",
      "[364]\ttraining's binary_logloss: 0.57709\n",
      "[365]\ttraining's binary_logloss: 0.576986\n",
      "[366]\ttraining's binary_logloss: 0.57688\n",
      "[367]\ttraining's binary_logloss: 0.576783\n",
      "[368]\ttraining's binary_logloss: 0.576692\n",
      "[369]\ttraining's binary_logloss: 0.5766\n",
      "[370]\ttraining's binary_logloss: 0.576515\n",
      "[371]\ttraining's binary_logloss: 0.576446\n",
      "[372]\ttraining's binary_logloss: 0.57636\n",
      "[373]\ttraining's binary_logloss: 0.576275\n",
      "[374]\ttraining's binary_logloss: 0.576195\n",
      "[375]\ttraining's binary_logloss: 0.576113\n",
      "[376]\ttraining's binary_logloss: 0.576044\n",
      "[377]\ttraining's binary_logloss: 0.575957\n",
      "[378]\ttraining's binary_logloss: 0.575871\n",
      "[379]\ttraining's binary_logloss: 0.575783\n",
      "[380]\ttraining's binary_logloss: 0.575702\n",
      "[381]\ttraining's binary_logloss: 0.575635\n",
      "[382]\ttraining's binary_logloss: 0.575578\n",
      "[383]\ttraining's binary_logloss: 0.575513\n",
      "[384]\ttraining's binary_logloss: 0.575449\n",
      "[385]\ttraining's binary_logloss: 0.57539\n",
      "[386]\ttraining's binary_logloss: 0.575294\n",
      "[387]\ttraining's binary_logloss: 0.575198\n",
      "[388]\ttraining's binary_logloss: 0.575108\n",
      "[389]\ttraining's binary_logloss: 0.575016\n",
      "[390]\ttraining's binary_logloss: 0.574908\n",
      "[391]\ttraining's binary_logloss: 0.57484\n",
      "[392]\ttraining's binary_logloss: 0.574769\n",
      "[393]\ttraining's binary_logloss: 0.574718\n",
      "[394]\ttraining's binary_logloss: 0.574655\n",
      "[395]\ttraining's binary_logloss: 0.574606\n",
      "[396]\ttraining's binary_logloss: 0.574514\n",
      "[397]\ttraining's binary_logloss: 0.574418\n",
      "[398]\ttraining's binary_logloss: 0.574304\n",
      "[399]\ttraining's binary_logloss: 0.57421\n",
      "[400]\ttraining's binary_logloss: 0.574113\n",
      "[401]\ttraining's binary_logloss: 0.574049\n",
      "[402]\ttraining's binary_logloss: 0.574006\n",
      "[403]\ttraining's binary_logloss: 0.573964\n",
      "[404]\ttraining's binary_logloss: 0.573926\n",
      "[405]\ttraining's binary_logloss: 0.573885\n",
      "[406]\ttraining's binary_logloss: 0.573775\n",
      "[407]\ttraining's binary_logloss: 0.573672\n",
      "[408]\ttraining's binary_logloss: 0.573569\n",
      "[409]\ttraining's binary_logloss: 0.573469\n",
      "[410]\ttraining's binary_logloss: 0.573366\n",
      "[411]\ttraining's binary_logloss: 0.573281\n",
      "[412]\ttraining's binary_logloss: 0.573204\n",
      "[413]\ttraining's binary_logloss: 0.573118\n",
      "[414]\ttraining's binary_logloss: 0.573038\n",
      "[415]\ttraining's binary_logloss: 0.57295\n",
      "[416]\ttraining's binary_logloss: 0.572852\n",
      "[417]\ttraining's binary_logloss: 0.572755\n",
      "[418]\ttraining's binary_logloss: 0.572686\n",
      "[419]\ttraining's binary_logloss: 0.572595\n",
      "[420]\ttraining's binary_logloss: 0.572512\n",
      "[421]\ttraining's binary_logloss: 0.572461\n",
      "[422]\ttraining's binary_logloss: 0.572413\n",
      "[423]\ttraining's binary_logloss: 0.572355\n",
      "[424]\ttraining's binary_logloss: 0.572308\n",
      "[425]\ttraining's binary_logloss: 0.572258\n",
      "[426]\ttraining's binary_logloss: 0.572209\n",
      "[427]\ttraining's binary_logloss: 0.572163\n",
      "[428]\ttraining's binary_logloss: 0.572117\n",
      "[429]\ttraining's binary_logloss: 0.572075\n",
      "[430]\ttraining's binary_logloss: 0.57204\n",
      "[431]\ttraining's binary_logloss: 0.571963\n",
      "[432]\ttraining's binary_logloss: 0.571857\n",
      "[433]\ttraining's binary_logloss: 0.57175\n",
      "[434]\ttraining's binary_logloss: 0.571656\n",
      "[435]\ttraining's binary_logloss: 0.571544\n",
      "[436]\ttraining's binary_logloss: 0.571448\n",
      "[437]\ttraining's binary_logloss: 0.571374\n",
      "[438]\ttraining's binary_logloss: 0.57128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[439]\ttraining's binary_logloss: 0.571211\n",
      "[440]\ttraining's binary_logloss: 0.571136\n",
      "[441]\ttraining's binary_logloss: 0.571047\n",
      "[442]\ttraining's binary_logloss: 0.570971\n",
      "[443]\ttraining's binary_logloss: 0.570885\n",
      "[444]\ttraining's binary_logloss: 0.570803\n",
      "[445]\ttraining's binary_logloss: 0.570717\n",
      "[446]\ttraining's binary_logloss: 0.570634\n",
      "[447]\ttraining's binary_logloss: 0.570577\n",
      "[448]\ttraining's binary_logloss: 0.570508\n",
      "[449]\ttraining's binary_logloss: 0.570431\n",
      "[450]\ttraining's binary_logloss: 0.57038\n",
      "[451]\ttraining's binary_logloss: 0.570296\n",
      "[452]\ttraining's binary_logloss: 0.5702\n",
      "[453]\ttraining's binary_logloss: 0.570119\n",
      "[454]\ttraining's binary_logloss: 0.570021\n",
      "[455]\ttraining's binary_logloss: 0.569936\n",
      "[456]\ttraining's binary_logloss: 0.569874\n",
      "[457]\ttraining's binary_logloss: 0.569802\n",
      "[458]\ttraining's binary_logloss: 0.569731\n",
      "[459]\ttraining's binary_logloss: 0.569662\n",
      "[460]\ttraining's binary_logloss: 0.569606\n",
      "[461]\ttraining's binary_logloss: 0.569538\n",
      "[462]\ttraining's binary_logloss: 0.569469\n",
      "[463]\ttraining's binary_logloss: 0.569397\n",
      "[464]\ttraining's binary_logloss: 0.569335\n",
      "[465]\ttraining's binary_logloss: 0.569277\n",
      "[466]\ttraining's binary_logloss: 0.569223\n",
      "[467]\ttraining's binary_logloss: 0.569163\n",
      "[468]\ttraining's binary_logloss: 0.569103\n",
      "[469]\ttraining's binary_logloss: 0.569036\n",
      "[470]\ttraining's binary_logloss: 0.568969\n",
      "[471]\ttraining's binary_logloss: 0.568908\n",
      "[472]\ttraining's binary_logloss: 0.56885\n",
      "[473]\ttraining's binary_logloss: 0.568784\n",
      "[474]\ttraining's binary_logloss: 0.568709\n",
      "[475]\ttraining's binary_logloss: 0.568649\n",
      "[476]\ttraining's binary_logloss: 0.568601\n",
      "[477]\ttraining's binary_logloss: 0.568543\n",
      "[478]\ttraining's binary_logloss: 0.5685\n",
      "[479]\ttraining's binary_logloss: 0.568455\n",
      "[480]\ttraining's binary_logloss: 0.568408\n",
      "[481]\ttraining's binary_logloss: 0.568307\n",
      "[482]\ttraining's binary_logloss: 0.568211\n",
      "[483]\ttraining's binary_logloss: 0.568121\n",
      "[484]\ttraining's binary_logloss: 0.568028\n",
      "[485]\ttraining's binary_logloss: 0.567936\n",
      "[486]\ttraining's binary_logloss: 0.567854\n",
      "[487]\ttraining's binary_logloss: 0.567771\n",
      "[488]\ttraining's binary_logloss: 0.567691\n",
      "[489]\ttraining's binary_logloss: 0.567605\n",
      "[490]\ttraining's binary_logloss: 0.567484\n",
      "[491]\ttraining's binary_logloss: 0.567368\n",
      "[492]\ttraining's binary_logloss: 0.567256\n",
      "[493]\ttraining's binary_logloss: 0.567148\n",
      "[494]\ttraining's binary_logloss: 0.567043\n",
      "[495]\ttraining's binary_logloss: 0.566943\n",
      "[496]\ttraining's binary_logloss: 0.56686\n",
      "[497]\ttraining's binary_logloss: 0.566778\n",
      "[498]\ttraining's binary_logloss: 0.566712\n",
      "[499]\ttraining's binary_logloss: 0.566636\n",
      "[500]\ttraining's binary_logloss: 0.566563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.617535\n",
      "[2]\ttraining's binary_logloss: 0.616437\n",
      "[3]\ttraining's binary_logloss: 0.615347\n",
      "[4]\ttraining's binary_logloss: 0.614336\n",
      "[5]\ttraining's binary_logloss: 0.613364\n",
      "[6]\ttraining's binary_logloss: 0.612388\n",
      "[7]\ttraining's binary_logloss: 0.611511\n",
      "[8]\ttraining's binary_logloss: 0.610701\n",
      "[9]\ttraining's binary_logloss: 0.609829\n",
      "[10]\ttraining's binary_logloss: 0.60912\n",
      "[11]\ttraining's binary_logloss: 0.608313\n",
      "[12]\ttraining's binary_logloss: 0.6075\n",
      "[13]\ttraining's binary_logloss: 0.606803\n",
      "[14]\ttraining's binary_logloss: 0.606027\n",
      "[15]\ttraining's binary_logloss: 0.605334\n",
      "[16]\ttraining's binary_logloss: 0.604621\n",
      "[17]\ttraining's binary_logloss: 0.60402\n",
      "[18]\ttraining's binary_logloss: 0.603372\n",
      "[19]\ttraining's binary_logloss: 0.602839\n",
      "[20]\ttraining's binary_logloss: 0.602233\n",
      "[21]\ttraining's binary_logloss: 0.60176\n",
      "[22]\ttraining's binary_logloss: 0.601314\n",
      "[23]\ttraining's binary_logloss: 0.600781\n",
      "[24]\ttraining's binary_logloss: 0.600269\n",
      "[25]\ttraining's binary_logloss: 0.599877\n",
      "[26]\ttraining's binary_logloss: 0.5994\n",
      "[27]\ttraining's binary_logloss: 0.599027\n",
      "[28]\ttraining's binary_logloss: 0.59859\n",
      "[29]\ttraining's binary_logloss: 0.598172\n",
      "[30]\ttraining's binary_logloss: 0.597772\n",
      "[31]\ttraining's binary_logloss: 0.597357\n",
      "[32]\ttraining's binary_logloss: 0.596921\n",
      "[33]\ttraining's binary_logloss: 0.596444\n",
      "[34]\ttraining's binary_logloss: 0.59609\n",
      "[35]\ttraining's binary_logloss: 0.595712\n",
      "[36]\ttraining's binary_logloss: 0.595352\n",
      "[37]\ttraining's binary_logloss: 0.595067\n",
      "[38]\ttraining's binary_logloss: 0.594733\n",
      "[39]\ttraining's binary_logloss: 0.594436\n",
      "[40]\ttraining's binary_logloss: 0.594187\n",
      "[41]\ttraining's binary_logloss: 0.593903\n",
      "[42]\ttraining's binary_logloss: 0.593619\n",
      "[43]\ttraining's binary_logloss: 0.593324\n",
      "[44]\ttraining's binary_logloss: 0.593067\n",
      "[45]\ttraining's binary_logloss: 0.592824\n",
      "[46]\ttraining's binary_logloss: 0.592514\n",
      "[47]\ttraining's binary_logloss: 0.592225\n",
      "[48]\ttraining's binary_logloss: 0.591953\n",
      "[49]\ttraining's binary_logloss: 0.591729\n",
      "[50]\ttraining's binary_logloss: 0.591473\n",
      "[51]\ttraining's binary_logloss: 0.591246\n",
      "[52]\ttraining's binary_logloss: 0.591049\n",
      "[53]\ttraining's binary_logloss: 0.590863\n",
      "[54]\ttraining's binary_logloss: 0.590665\n",
      "[55]\ttraining's binary_logloss: 0.590484\n",
      "[56]\ttraining's binary_logloss: 0.590332\n",
      "[57]\ttraining's binary_logloss: 0.590162\n",
      "[58]\ttraining's binary_logloss: 0.590001\n",
      "[59]\ttraining's binary_logloss: 0.589856\n",
      "[60]\ttraining's binary_logloss: 0.589754\n",
      "[61]\ttraining's binary_logloss: 0.589618\n",
      "[62]\ttraining's binary_logloss: 0.5895\n",
      "[63]\ttraining's binary_logloss: 0.589374\n",
      "[64]\ttraining's binary_logloss: 0.589282\n",
      "[65]\ttraining's binary_logloss: 0.589157\n",
      "[66]\ttraining's binary_logloss: 0.589074\n",
      "[67]\ttraining's binary_logloss: 0.588973\n",
      "[68]\ttraining's binary_logloss: 0.588867\n",
      "[69]\ttraining's binary_logloss: 0.588763\n",
      "[70]\ttraining's binary_logloss: 0.588699\n",
      "[71]\ttraining's binary_logloss: 0.588649\n",
      "[72]\ttraining's binary_logloss: 0.588575\n",
      "[73]\ttraining's binary_logloss: 0.588512\n",
      "[74]\ttraining's binary_logloss: 0.588439\n",
      "[75]\ttraining's binary_logloss: 0.588369\n",
      "[76]\ttraining's binary_logloss: 0.58828\n",
      "[77]\ttraining's binary_logloss: 0.5882\n",
      "[78]\ttraining's binary_logloss: 0.588126\n",
      "[79]\ttraining's binary_logloss: 0.588115\n",
      "[80]\ttraining's binary_logloss: 0.588057\n",
      "[81]\ttraining's binary_logloss: 0.587931\n",
      "[82]\ttraining's binary_logloss: 0.587872\n",
      "[83]\ttraining's binary_logloss: 0.587767\n",
      "[84]\ttraining's binary_logloss: 0.587762\n",
      "[85]\ttraining's binary_logloss: 0.587661\n",
      "[86]\ttraining's binary_logloss: 0.587578\n",
      "[87]\ttraining's binary_logloss: 0.587522\n",
      "[88]\ttraining's binary_logloss: 0.58748\n",
      "[89]\ttraining's binary_logloss: 0.587414\n",
      "[90]\ttraining's binary_logloss: 0.587374\n",
      "[91]\ttraining's binary_logloss: 0.587303\n",
      "[92]\ttraining's binary_logloss: 0.587359\n",
      "[93]\ttraining's binary_logloss: 0.587326\n",
      "[94]\ttraining's binary_logloss: 0.587295\n",
      "[95]\ttraining's binary_logloss: 0.587242\n",
      "[96]\ttraining's binary_logloss: 0.587177\n",
      "[97]\ttraining's binary_logloss: 0.58717\n",
      "[98]\ttraining's binary_logloss: 0.587155\n",
      "[99]\ttraining's binary_logloss: 0.587151\n",
      "[100]\ttraining's binary_logloss: 0.587144\n",
      "[101]\ttraining's binary_logloss: 0.587159\n",
      "[102]\ttraining's binary_logloss: 0.587164\n",
      "[103]\ttraining's binary_logloss: 0.58715\n",
      "[104]\ttraining's binary_logloss: 0.587146\n",
      "[105]\ttraining's binary_logloss: 0.587132\n",
      "[106]\ttraining's binary_logloss: 0.587145\n",
      "[107]\ttraining's binary_logloss: 0.587149\n",
      "[108]\ttraining's binary_logloss: 0.587151\n",
      "[109]\ttraining's binary_logloss: 0.587156\n",
      "[110]\ttraining's binary_logloss: 0.587192\n",
      "[111]\ttraining's binary_logloss: 0.587164\n",
      "[112]\ttraining's binary_logloss: 0.587138\n",
      "[113]\ttraining's binary_logloss: 0.587117\n",
      "[114]\ttraining's binary_logloss: 0.5871\n",
      "[115]\ttraining's binary_logloss: 0.587156\n",
      "[116]\ttraining's binary_logloss: 0.58718\n",
      "[117]\ttraining's binary_logloss: 0.587136\n",
      "[118]\ttraining's binary_logloss: 0.587131\n",
      "[119]\ttraining's binary_logloss: 0.587142\n",
      "[120]\ttraining's binary_logloss: 0.587106\n",
      "[121]\ttraining's binary_logloss: 0.587065\n",
      "[122]\ttraining's binary_logloss: 0.587028\n",
      "[123]\ttraining's binary_logloss: 0.587004\n",
      "[124]\ttraining's binary_logloss: 0.586972\n",
      "[125]\ttraining's binary_logloss: 0.586951\n",
      "[126]\ttraining's binary_logloss: 0.586946\n",
      "[127]\ttraining's binary_logloss: 0.586956\n",
      "[128]\ttraining's binary_logloss: 0.58695\n",
      "[129]\ttraining's binary_logloss: 0.586954\n",
      "[130]\ttraining's binary_logloss: 0.586943\n",
      "[131]\ttraining's binary_logloss: 0.586985\n",
      "[132]\ttraining's binary_logloss: 0.587025\n",
      "[133]\ttraining's binary_logloss: 0.587062\n",
      "[134]\ttraining's binary_logloss: 0.587104\n",
      "[135]\ttraining's binary_logloss: 0.587122\n",
      "[136]\ttraining's binary_logloss: 0.587164\n",
      "[137]\ttraining's binary_logloss: 0.587171\n",
      "[138]\ttraining's binary_logloss: 0.587181\n",
      "[139]\ttraining's binary_logloss: 0.587213\n",
      "[140]\ttraining's binary_logloss: 0.587261\n",
      "[141]\ttraining's binary_logloss: 0.587242\n",
      "[142]\ttraining's binary_logloss: 0.587277\n",
      "[143]\ttraining's binary_logloss: 0.587268\n",
      "[144]\ttraining's binary_logloss: 0.587241\n",
      "[145]\ttraining's binary_logloss: 0.587224\n",
      "[146]\ttraining's binary_logloss: 0.587209\n",
      "[147]\ttraining's binary_logloss: 0.587206\n",
      "[148]\ttraining's binary_logloss: 0.587209\n",
      "[149]\ttraining's binary_logloss: 0.587202\n",
      "[150]\ttraining's binary_logloss: 0.587202\n",
      "[151]\ttraining's binary_logloss: 0.587258\n",
      "[152]\ttraining's binary_logloss: 0.587279\n",
      "[153]\ttraining's binary_logloss: 0.587345\n",
      "[154]\ttraining's binary_logloss: 0.587369\n",
      "[155]\ttraining's binary_logloss: 0.587396\n",
      "[156]\ttraining's binary_logloss: 0.587402\n",
      "[157]\ttraining's binary_logloss: 0.587417\n",
      "[158]\ttraining's binary_logloss: 0.587427\n",
      "[159]\ttraining's binary_logloss: 0.587437\n",
      "[160]\ttraining's binary_logloss: 0.587456\n",
      "[161]\ttraining's binary_logloss: 0.587479\n",
      "[162]\ttraining's binary_logloss: 0.587504\n",
      "[163]\ttraining's binary_logloss: 0.587526\n",
      "[164]\ttraining's binary_logloss: 0.587547\n",
      "[165]\ttraining's binary_logloss: 0.587571\n",
      "[166]\ttraining's binary_logloss: 0.587591\n",
      "[167]\ttraining's binary_logloss: 0.587583\n",
      "[168]\ttraining's binary_logloss: 0.5876\n",
      "[169]\ttraining's binary_logloss: 0.587618\n",
      "[170]\ttraining's binary_logloss: 0.587644\n",
      "[171]\ttraining's binary_logloss: 0.587622\n",
      "[172]\ttraining's binary_logloss: 0.587595\n",
      "[173]\ttraining's binary_logloss: 0.587572\n",
      "[174]\ttraining's binary_logloss: 0.587556\n",
      "[175]\ttraining's binary_logloss: 0.58754\n",
      "[176]\ttraining's binary_logloss: 0.587511\n",
      "[177]\ttraining's binary_logloss: 0.587479\n",
      "[178]\ttraining's binary_logloss: 0.587486\n",
      "[179]\ttraining's binary_logloss: 0.587464\n",
      "[180]\ttraining's binary_logloss: 0.587467\n",
      "[181]\ttraining's binary_logloss: 0.587464\n",
      "[182]\ttraining's binary_logloss: 0.587478\n",
      "[183]\ttraining's binary_logloss: 0.58749\n",
      "[184]\ttraining's binary_logloss: 0.587471\n",
      "[185]\ttraining's binary_logloss: 0.587474\n",
      "[186]\ttraining's binary_logloss: 0.587467\n",
      "[187]\ttraining's binary_logloss: 0.587448\n",
      "[188]\ttraining's binary_logloss: 0.587438\n",
      "[189]\ttraining's binary_logloss: 0.587424\n",
      "[190]\ttraining's binary_logloss: 0.587433\n",
      "[191]\ttraining's binary_logloss: 0.587403\n",
      "[192]\ttraining's binary_logloss: 0.587372\n",
      "[193]\ttraining's binary_logloss: 0.587359\n",
      "[194]\ttraining's binary_logloss: 0.587331\n",
      "[195]\ttraining's binary_logloss: 0.587327\n",
      "[196]\ttraining's binary_logloss: 0.587323\n",
      "[197]\ttraining's binary_logloss: 0.58731\n",
      "[198]\ttraining's binary_logloss: 0.587299\n",
      "[199]\ttraining's binary_logloss: 0.587285\n",
      "[200]\ttraining's binary_logloss: 0.58727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[201]\ttraining's binary_logloss: 0.587251\n",
      "[202]\ttraining's binary_logloss: 0.587232\n",
      "[203]\ttraining's binary_logloss: 0.587234\n",
      "[204]\ttraining's binary_logloss: 0.587213\n",
      "[205]\ttraining's binary_logloss: 0.587199\n",
      "[206]\ttraining's binary_logloss: 0.587184\n",
      "[207]\ttraining's binary_logloss: 0.587172\n",
      "[208]\ttraining's binary_logloss: 0.587166\n",
      "[209]\ttraining's binary_logloss: 0.587177\n",
      "[210]\ttraining's binary_logloss: 0.587164\n",
      "[211]\ttraining's binary_logloss: 0.587152\n",
      "[212]\ttraining's binary_logloss: 0.587132\n",
      "[213]\ttraining's binary_logloss: 0.587103\n",
      "[214]\ttraining's binary_logloss: 0.587087\n",
      "[215]\ttraining's binary_logloss: 0.587059\n",
      "[216]\ttraining's binary_logloss: 0.587044\n",
      "[217]\ttraining's binary_logloss: 0.587019\n",
      "[218]\ttraining's binary_logloss: 0.586984\n",
      "[219]\ttraining's binary_logloss: 0.586976\n",
      "[220]\ttraining's binary_logloss: 0.586948\n",
      "[221]\ttraining's binary_logloss: 0.586914\n",
      "[222]\ttraining's binary_logloss: 0.586889\n",
      "[223]\ttraining's binary_logloss: 0.586857\n",
      "[224]\ttraining's binary_logloss: 0.586841\n",
      "[225]\ttraining's binary_logloss: 0.586818\n",
      "[226]\ttraining's binary_logloss: 0.586806\n",
      "[227]\ttraining's binary_logloss: 0.586785\n",
      "[228]\ttraining's binary_logloss: 0.586768\n",
      "[229]\ttraining's binary_logloss: 0.586754\n",
      "[230]\ttraining's binary_logloss: 0.586729\n",
      "[231]\ttraining's binary_logloss: 0.586724\n",
      "[232]\ttraining's binary_logloss: 0.586724\n",
      "[233]\ttraining's binary_logloss: 0.586708\n",
      "[234]\ttraining's binary_logloss: 0.586698\n",
      "[235]\ttraining's binary_logloss: 0.586698\n",
      "[236]\ttraining's binary_logloss: 0.586708\n",
      "[237]\ttraining's binary_logloss: 0.586691\n",
      "[238]\ttraining's binary_logloss: 0.586704\n",
      "[239]\ttraining's binary_logloss: 0.586705\n",
      "[240]\ttraining's binary_logloss: 0.586706\n",
      "[241]\ttraining's binary_logloss: 0.586638\n",
      "[242]\ttraining's binary_logloss: 0.586587\n",
      "[243]\ttraining's binary_logloss: 0.586536\n",
      "[244]\ttraining's binary_logloss: 0.58648\n",
      "[245]\ttraining's binary_logloss: 0.586429\n",
      "[246]\ttraining's binary_logloss: 0.586367\n",
      "[247]\ttraining's binary_logloss: 0.586319\n",
      "[248]\ttraining's binary_logloss: 0.586262\n",
      "[249]\ttraining's binary_logloss: 0.58621\n",
      "[250]\ttraining's binary_logloss: 0.586159\n",
      "[251]\ttraining's binary_logloss: 0.58611\n",
      "[252]\ttraining's binary_logloss: 0.586075\n",
      "[253]\ttraining's binary_logloss: 0.586035\n",
      "[254]\ttraining's binary_logloss: 0.586004\n",
      "[255]\ttraining's binary_logloss: 0.585968\n",
      "[256]\ttraining's binary_logloss: 0.585905\n",
      "[257]\ttraining's binary_logloss: 0.585836\n",
      "[258]\ttraining's binary_logloss: 0.585769\n",
      "[259]\ttraining's binary_logloss: 0.5857\n",
      "[260]\ttraining's binary_logloss: 0.58563\n",
      "[261]\ttraining's binary_logloss: 0.585544\n",
      "[262]\ttraining's binary_logloss: 0.585466\n",
      "[263]\ttraining's binary_logloss: 0.585389\n",
      "[264]\ttraining's binary_logloss: 0.585315\n",
      "[265]\ttraining's binary_logloss: 0.585248\n",
      "[266]\ttraining's binary_logloss: 0.585203\n",
      "[267]\ttraining's binary_logloss: 0.585166\n",
      "[268]\ttraining's binary_logloss: 0.585128\n",
      "[269]\ttraining's binary_logloss: 0.585105\n",
      "[270]\ttraining's binary_logloss: 0.585057\n",
      "[271]\ttraining's binary_logloss: 0.585031\n",
      "[272]\ttraining's binary_logloss: 0.585002\n",
      "[273]\ttraining's binary_logloss: 0.584987\n",
      "[274]\ttraining's binary_logloss: 0.584968\n",
      "[275]\ttraining's binary_logloss: 0.584944\n",
      "[276]\ttraining's binary_logloss: 0.584894\n",
      "[277]\ttraining's binary_logloss: 0.58485\n",
      "[278]\ttraining's binary_logloss: 0.584819\n",
      "[279]\ttraining's binary_logloss: 0.584771\n",
      "[280]\ttraining's binary_logloss: 0.584742\n",
      "[281]\ttraining's binary_logloss: 0.584653\n",
      "[282]\ttraining's binary_logloss: 0.58457\n",
      "[283]\ttraining's binary_logloss: 0.584477\n",
      "[284]\ttraining's binary_logloss: 0.584388\n",
      "[285]\ttraining's binary_logloss: 0.584323\n",
      "[286]\ttraining's binary_logloss: 0.584305\n",
      "[287]\ttraining's binary_logloss: 0.584284\n",
      "[288]\ttraining's binary_logloss: 0.584258\n",
      "[289]\ttraining's binary_logloss: 0.584243\n",
      "[290]\ttraining's binary_logloss: 0.584228\n",
      "[291]\ttraining's binary_logloss: 0.584143\n",
      "[292]\ttraining's binary_logloss: 0.584059\n",
      "[293]\ttraining's binary_logloss: 0.583976\n",
      "[294]\ttraining's binary_logloss: 0.583902\n",
      "[295]\ttraining's binary_logloss: 0.58381\n",
      "[296]\ttraining's binary_logloss: 0.58374\n",
      "[297]\ttraining's binary_logloss: 0.583661\n",
      "[298]\ttraining's binary_logloss: 0.583599\n",
      "[299]\ttraining's binary_logloss: 0.583547\n",
      "[300]\ttraining's binary_logloss: 0.583494\n",
      "[301]\ttraining's binary_logloss: 0.583417\n",
      "[302]\ttraining's binary_logloss: 0.583343\n",
      "[303]\ttraining's binary_logloss: 0.583269\n",
      "[304]\ttraining's binary_logloss: 0.5832\n",
      "[305]\ttraining's binary_logloss: 0.58313\n",
      "[306]\ttraining's binary_logloss: 0.583059\n",
      "[307]\ttraining's binary_logloss: 0.582997\n",
      "[308]\ttraining's binary_logloss: 0.582934\n",
      "[309]\ttraining's binary_logloss: 0.582873\n",
      "[310]\ttraining's binary_logloss: 0.582808\n",
      "[311]\ttraining's binary_logloss: 0.582728\n",
      "[312]\ttraining's binary_logloss: 0.582663\n",
      "[313]\ttraining's binary_logloss: 0.582602\n",
      "[314]\ttraining's binary_logloss: 0.582538\n",
      "[315]\ttraining's binary_logloss: 0.582473\n",
      "[316]\ttraining's binary_logloss: 0.582386\n",
      "[317]\ttraining's binary_logloss: 0.582305\n",
      "[318]\ttraining's binary_logloss: 0.582232\n",
      "[319]\ttraining's binary_logloss: 0.582152\n",
      "[320]\ttraining's binary_logloss: 0.582083\n",
      "[321]\ttraining's binary_logloss: 0.582009\n",
      "[322]\ttraining's binary_logloss: 0.581937\n",
      "[323]\ttraining's binary_logloss: 0.581868\n",
      "[324]\ttraining's binary_logloss: 0.5818\n",
      "[325]\ttraining's binary_logloss: 0.581738\n",
      "[326]\ttraining's binary_logloss: 0.581684\n",
      "[327]\ttraining's binary_logloss: 0.58163\n",
      "[328]\ttraining's binary_logloss: 0.581581\n",
      "[329]\ttraining's binary_logloss: 0.581516\n",
      "[330]\ttraining's binary_logloss: 0.581468\n",
      "[331]\ttraining's binary_logloss: 0.5814\n",
      "[332]\ttraining's binary_logloss: 0.581346\n",
      "[333]\ttraining's binary_logloss: 0.581303\n",
      "[334]\ttraining's binary_logloss: 0.581241\n",
      "[335]\ttraining's binary_logloss: 0.581155\n",
      "[336]\ttraining's binary_logloss: 0.581064\n",
      "[337]\ttraining's binary_logloss: 0.580982\n",
      "[338]\ttraining's binary_logloss: 0.580894\n",
      "[339]\ttraining's binary_logloss: 0.580809\n",
      "[340]\ttraining's binary_logloss: 0.580744\n",
      "[341]\ttraining's binary_logloss: 0.580655\n",
      "[342]\ttraining's binary_logloss: 0.580562\n",
      "[343]\ttraining's binary_logloss: 0.580477\n",
      "[344]\ttraining's binary_logloss: 0.580392\n",
      "[345]\ttraining's binary_logloss: 0.580302\n",
      "[346]\ttraining's binary_logloss: 0.58022\n",
      "[347]\ttraining's binary_logloss: 0.580148\n",
      "[348]\ttraining's binary_logloss: 0.580075\n",
      "[349]\ttraining's binary_logloss: 0.580005\n",
      "[350]\ttraining's binary_logloss: 0.579943\n",
      "[351]\ttraining's binary_logloss: 0.579875\n",
      "[352]\ttraining's binary_logloss: 0.579811\n",
      "[353]\ttraining's binary_logloss: 0.579722\n",
      "[354]\ttraining's binary_logloss: 0.579647\n",
      "[355]\ttraining's binary_logloss: 0.579587\n",
      "[356]\ttraining's binary_logloss: 0.579505\n",
      "[357]\ttraining's binary_logloss: 0.579426\n",
      "[358]\ttraining's binary_logloss: 0.57935\n",
      "[359]\ttraining's binary_logloss: 0.579275\n",
      "[360]\ttraining's binary_logloss: 0.579203\n",
      "[361]\ttraining's binary_logloss: 0.579126\n",
      "[362]\ttraining's binary_logloss: 0.579059\n",
      "[363]\ttraining's binary_logloss: 0.578966\n",
      "[364]\ttraining's binary_logloss: 0.578893\n",
      "[365]\ttraining's binary_logloss: 0.578824\n",
      "[366]\ttraining's binary_logloss: 0.578735\n",
      "[367]\ttraining's binary_logloss: 0.578631\n",
      "[368]\ttraining's binary_logloss: 0.578537\n",
      "[369]\ttraining's binary_logloss: 0.578444\n",
      "[370]\ttraining's binary_logloss: 0.578355\n",
      "[371]\ttraining's binary_logloss: 0.578275\n",
      "[372]\ttraining's binary_logloss: 0.578197\n",
      "[373]\ttraining's binary_logloss: 0.578121\n",
      "[374]\ttraining's binary_logloss: 0.578054\n",
      "[375]\ttraining's binary_logloss: 0.577975\n",
      "[376]\ttraining's binary_logloss: 0.577896\n",
      "[377]\ttraining's binary_logloss: 0.577796\n",
      "[378]\ttraining's binary_logloss: 0.577703\n",
      "[379]\ttraining's binary_logloss: 0.577611\n",
      "[380]\ttraining's binary_logloss: 0.577518\n",
      "[381]\ttraining's binary_logloss: 0.577439\n",
      "[382]\ttraining's binary_logloss: 0.577361\n",
      "[383]\ttraining's binary_logloss: 0.577288\n",
      "[384]\ttraining's binary_logloss: 0.577215\n",
      "[385]\ttraining's binary_logloss: 0.577128\n",
      "[386]\ttraining's binary_logloss: 0.577032\n",
      "[387]\ttraining's binary_logloss: 0.57694\n",
      "[388]\ttraining's binary_logloss: 0.57685\n",
      "[389]\ttraining's binary_logloss: 0.576775\n",
      "[390]\ttraining's binary_logloss: 0.57667\n",
      "[391]\ttraining's binary_logloss: 0.576635\n",
      "[392]\ttraining's binary_logloss: 0.57657\n",
      "[393]\ttraining's binary_logloss: 0.576513\n",
      "[394]\ttraining's binary_logloss: 0.576448\n",
      "[395]\ttraining's binary_logloss: 0.576384\n",
      "[396]\ttraining's binary_logloss: 0.576307\n",
      "[397]\ttraining's binary_logloss: 0.576234\n",
      "[398]\ttraining's binary_logloss: 0.576166\n",
      "[399]\ttraining's binary_logloss: 0.576081\n",
      "[400]\ttraining's binary_logloss: 0.576015\n",
      "[401]\ttraining's binary_logloss: 0.57593\n",
      "[402]\ttraining's binary_logloss: 0.575847\n",
      "[403]\ttraining's binary_logloss: 0.57577\n",
      "[404]\ttraining's binary_logloss: 0.575693\n",
      "[405]\ttraining's binary_logloss: 0.575617\n",
      "[406]\ttraining's binary_logloss: 0.575485\n",
      "[407]\ttraining's binary_logloss: 0.575366\n",
      "[408]\ttraining's binary_logloss: 0.575244\n",
      "[409]\ttraining's binary_logloss: 0.575129\n",
      "[410]\ttraining's binary_logloss: 0.575011\n",
      "[411]\ttraining's binary_logloss: 0.574915\n",
      "[412]\ttraining's binary_logloss: 0.574827\n",
      "[413]\ttraining's binary_logloss: 0.574734\n",
      "[414]\ttraining's binary_logloss: 0.574638\n",
      "[415]\ttraining's binary_logloss: 0.574545\n",
      "[416]\ttraining's binary_logloss: 0.574437\n",
      "[417]\ttraining's binary_logloss: 0.574337\n",
      "[418]\ttraining's binary_logloss: 0.574229\n",
      "[419]\ttraining's binary_logloss: 0.574132\n",
      "[420]\ttraining's binary_logloss: 0.574044\n",
      "[421]\ttraining's binary_logloss: 0.573999\n",
      "[422]\ttraining's binary_logloss: 0.573947\n",
      "[423]\ttraining's binary_logloss: 0.573903\n",
      "[424]\ttraining's binary_logloss: 0.573854\n",
      "[425]\ttraining's binary_logloss: 0.573795\n",
      "[426]\ttraining's binary_logloss: 0.573731\n",
      "[427]\ttraining's binary_logloss: 0.573676\n",
      "[428]\ttraining's binary_logloss: 0.573602\n",
      "[429]\ttraining's binary_logloss: 0.57355\n",
      "[430]\ttraining's binary_logloss: 0.573517\n",
      "[431]\ttraining's binary_logloss: 0.573447\n",
      "[432]\ttraining's binary_logloss: 0.573386\n",
      "[433]\ttraining's binary_logloss: 0.573319\n",
      "[434]\ttraining's binary_logloss: 0.573255\n",
      "[435]\ttraining's binary_logloss: 0.573185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[436]\ttraining's binary_logloss: 0.573095\n",
      "[437]\ttraining's binary_logloss: 0.573015\n",
      "[438]\ttraining's binary_logloss: 0.572934\n",
      "[439]\ttraining's binary_logloss: 0.572846\n",
      "[440]\ttraining's binary_logloss: 0.572767\n",
      "[441]\ttraining's binary_logloss: 0.572674\n",
      "[442]\ttraining's binary_logloss: 0.572583\n",
      "[443]\ttraining's binary_logloss: 0.5725\n",
      "[444]\ttraining's binary_logloss: 0.572418\n",
      "[445]\ttraining's binary_logloss: 0.572345\n",
      "[446]\ttraining's binary_logloss: 0.572251\n",
      "[447]\ttraining's binary_logloss: 0.572158\n",
      "[448]\ttraining's binary_logloss: 0.572077\n",
      "[449]\ttraining's binary_logloss: 0.571996\n",
      "[450]\ttraining's binary_logloss: 0.571914\n",
      "[451]\ttraining's binary_logloss: 0.571821\n",
      "[452]\ttraining's binary_logloss: 0.571737\n",
      "[453]\ttraining's binary_logloss: 0.571653\n",
      "[454]\ttraining's binary_logloss: 0.571565\n",
      "[455]\ttraining's binary_logloss: 0.571482\n",
      "[456]\ttraining's binary_logloss: 0.571398\n",
      "[457]\ttraining's binary_logloss: 0.571318\n",
      "[458]\ttraining's binary_logloss: 0.57123\n",
      "[459]\ttraining's binary_logloss: 0.571181\n",
      "[460]\ttraining's binary_logloss: 0.571096\n",
      "[461]\ttraining's binary_logloss: 0.571007\n",
      "[462]\ttraining's binary_logloss: 0.570923\n",
      "[463]\ttraining's binary_logloss: 0.570839\n",
      "[464]\ttraining's binary_logloss: 0.570751\n",
      "[465]\ttraining's binary_logloss: 0.570667\n",
      "[466]\ttraining's binary_logloss: 0.570599\n",
      "[467]\ttraining's binary_logloss: 0.57054\n",
      "[468]\ttraining's binary_logloss: 0.57047\n",
      "[469]\ttraining's binary_logloss: 0.570404\n",
      "[470]\ttraining's binary_logloss: 0.570338\n",
      "[471]\ttraining's binary_logloss: 0.57026\n",
      "[472]\ttraining's binary_logloss: 0.570184\n",
      "[473]\ttraining's binary_logloss: 0.570119\n",
      "[474]\ttraining's binary_logloss: 0.570049\n",
      "[475]\ttraining's binary_logloss: 0.569988\n",
      "[476]\ttraining's binary_logloss: 0.569926\n",
      "[477]\ttraining's binary_logloss: 0.569868\n",
      "[478]\ttraining's binary_logloss: 0.569815\n",
      "[479]\ttraining's binary_logloss: 0.569758\n",
      "[480]\ttraining's binary_logloss: 0.569706\n",
      "[481]\ttraining's binary_logloss: 0.569623\n",
      "[482]\ttraining's binary_logloss: 0.569546\n",
      "[483]\ttraining's binary_logloss: 0.569463\n",
      "[484]\ttraining's binary_logloss: 0.569384\n",
      "[485]\ttraining's binary_logloss: 0.569299\n",
      "[486]\ttraining's binary_logloss: 0.569219\n",
      "[487]\ttraining's binary_logloss: 0.569145\n",
      "[488]\ttraining's binary_logloss: 0.569063\n",
      "[489]\ttraining's binary_logloss: 0.568991\n",
      "[490]\ttraining's binary_logloss: 0.568887\n",
      "[491]\ttraining's binary_logloss: 0.568806\n",
      "[492]\ttraining's binary_logloss: 0.568726\n",
      "[493]\ttraining's binary_logloss: 0.568652\n",
      "[494]\ttraining's binary_logloss: 0.568578\n",
      "[495]\ttraining's binary_logloss: 0.568488\n",
      "[496]\ttraining's binary_logloss: 0.568409\n",
      "[497]\ttraining's binary_logloss: 0.568324\n",
      "[498]\ttraining's binary_logloss: 0.568235\n",
      "[499]\ttraining's binary_logloss: 0.568153\n",
      "[500]\ttraining's binary_logloss: 0.568063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614074\n",
      "[2]\ttraining's binary_logloss: 0.61295\n",
      "[3]\ttraining's binary_logloss: 0.611871\n",
      "[4]\ttraining's binary_logloss: 0.610883\n",
      "[5]\ttraining's binary_logloss: 0.609941\n",
      "[6]\ttraining's binary_logloss: 0.608953\n",
      "[7]\ttraining's binary_logloss: 0.607992\n",
      "[8]\ttraining's binary_logloss: 0.607195\n",
      "[9]\ttraining's binary_logloss: 0.606304\n",
      "[10]\ttraining's binary_logloss: 0.60546\n",
      "[11]\ttraining's binary_logloss: 0.604648\n",
      "[12]\ttraining's binary_logloss: 0.603871\n",
      "[13]\ttraining's binary_logloss: 0.603125\n",
      "[14]\ttraining's binary_logloss: 0.602411\n",
      "[15]\ttraining's binary_logloss: 0.601747\n",
      "[16]\ttraining's binary_logloss: 0.601031\n",
      "[17]\ttraining's binary_logloss: 0.600348\n",
      "[18]\ttraining's binary_logloss: 0.59977\n",
      "[19]\ttraining's binary_logloss: 0.599253\n",
      "[20]\ttraining's binary_logloss: 0.598644\n",
      "[21]\ttraining's binary_logloss: 0.598069\n",
      "[22]\ttraining's binary_logloss: 0.597519\n",
      "[23]\ttraining's binary_logloss: 0.597002\n",
      "[24]\ttraining's binary_logloss: 0.596514\n",
      "[25]\ttraining's binary_logloss: 0.596034\n",
      "[26]\ttraining's binary_logloss: 0.595534\n",
      "[27]\ttraining's binary_logloss: 0.595056\n",
      "[28]\ttraining's binary_logloss: 0.594601\n",
      "[29]\ttraining's binary_logloss: 0.594229\n",
      "[30]\ttraining's binary_logloss: 0.593793\n",
      "[31]\ttraining's binary_logloss: 0.593381\n",
      "[32]\ttraining's binary_logloss: 0.592988\n",
      "[33]\ttraining's binary_logloss: 0.592602\n",
      "[34]\ttraining's binary_logloss: 0.592289\n",
      "[35]\ttraining's binary_logloss: 0.59194\n",
      "[36]\ttraining's binary_logloss: 0.591641\n",
      "[37]\ttraining's binary_logloss: 0.59132\n",
      "[38]\ttraining's binary_logloss: 0.591031\n",
      "[39]\ttraining's binary_logloss: 0.590766\n",
      "[40]\ttraining's binary_logloss: 0.590505\n",
      "[41]\ttraining's binary_logloss: 0.590225\n",
      "[42]\ttraining's binary_logloss: 0.589979\n",
      "[43]\ttraining's binary_logloss: 0.589735\n",
      "[44]\ttraining's binary_logloss: 0.5895\n",
      "[45]\ttraining's binary_logloss: 0.589278\n",
      "[46]\ttraining's binary_logloss: 0.589026\n",
      "[47]\ttraining's binary_logloss: 0.588729\n",
      "[48]\ttraining's binary_logloss: 0.588462\n",
      "[49]\ttraining's binary_logloss: 0.588206\n",
      "[50]\ttraining's binary_logloss: 0.588038\n",
      "[51]\ttraining's binary_logloss: 0.587836\n",
      "[52]\ttraining's binary_logloss: 0.587679\n",
      "[53]\ttraining's binary_logloss: 0.587492\n",
      "[54]\ttraining's binary_logloss: 0.587301\n",
      "[55]\ttraining's binary_logloss: 0.587152\n",
      "[56]\ttraining's binary_logloss: 0.586949\n",
      "[57]\ttraining's binary_logloss: 0.58678\n",
      "[58]\ttraining's binary_logloss: 0.586594\n",
      "[59]\ttraining's binary_logloss: 0.58638\n",
      "[60]\ttraining's binary_logloss: 0.586206\n",
      "[61]\ttraining's binary_logloss: 0.586075\n",
      "[62]\ttraining's binary_logloss: 0.585935\n",
      "[63]\ttraining's binary_logloss: 0.585804\n",
      "[64]\ttraining's binary_logloss: 0.585702\n",
      "[65]\ttraining's binary_logloss: 0.585591\n",
      "[66]\ttraining's binary_logloss: 0.585463\n",
      "[67]\ttraining's binary_logloss: 0.585394\n",
      "[68]\ttraining's binary_logloss: 0.585331\n",
      "[69]\ttraining's binary_logloss: 0.585244\n",
      "[70]\ttraining's binary_logloss: 0.585243\n",
      "[71]\ttraining's binary_logloss: 0.585171\n",
      "[72]\ttraining's binary_logloss: 0.585115\n",
      "[73]\ttraining's binary_logloss: 0.584995\n",
      "[74]\ttraining's binary_logloss: 0.584884\n",
      "[75]\ttraining's binary_logloss: 0.584829\n",
      "[76]\ttraining's binary_logloss: 0.584812\n",
      "[77]\ttraining's binary_logloss: 0.584791\n",
      "[78]\ttraining's binary_logloss: 0.584681\n",
      "[79]\ttraining's binary_logloss: 0.584674\n",
      "[80]\ttraining's binary_logloss: 0.584562\n",
      "[81]\ttraining's binary_logloss: 0.584562\n",
      "[82]\ttraining's binary_logloss: 0.584435\n",
      "[83]\ttraining's binary_logloss: 0.584328\n",
      "[84]\ttraining's binary_logloss: 0.584216\n",
      "[85]\ttraining's binary_logloss: 0.584115\n",
      "[86]\ttraining's binary_logloss: 0.5841\n",
      "[87]\ttraining's binary_logloss: 0.584108\n",
      "[88]\ttraining's binary_logloss: 0.584089\n",
      "[89]\ttraining's binary_logloss: 0.584081\n",
      "[90]\ttraining's binary_logloss: 0.584091\n",
      "[91]\ttraining's binary_logloss: 0.58405\n",
      "[92]\ttraining's binary_logloss: 0.584021\n",
      "[93]\ttraining's binary_logloss: 0.584069\n",
      "[94]\ttraining's binary_logloss: 0.584114\n",
      "[95]\ttraining's binary_logloss: 0.584101\n",
      "[96]\ttraining's binary_logloss: 0.584127\n",
      "[97]\ttraining's binary_logloss: 0.584161\n",
      "[98]\ttraining's binary_logloss: 0.5842\n",
      "[99]\ttraining's binary_logloss: 0.584232\n",
      "[100]\ttraining's binary_logloss: 0.584202\n",
      "[101]\ttraining's binary_logloss: 0.584241\n",
      "[102]\ttraining's binary_logloss: 0.584276\n",
      "[103]\ttraining's binary_logloss: 0.584317\n",
      "[104]\ttraining's binary_logloss: 0.584351\n",
      "[105]\ttraining's binary_logloss: 0.584381\n",
      "[106]\ttraining's binary_logloss: 0.584392\n",
      "[107]\ttraining's binary_logloss: 0.5844\n",
      "[108]\ttraining's binary_logloss: 0.584414\n",
      "[109]\ttraining's binary_logloss: 0.584429\n",
      "[110]\ttraining's binary_logloss: 0.584475\n",
      "[111]\ttraining's binary_logloss: 0.584497\n",
      "[112]\ttraining's binary_logloss: 0.584559\n",
      "[113]\ttraining's binary_logloss: 0.584542\n",
      "[114]\ttraining's binary_logloss: 0.58453\n",
      "[115]\ttraining's binary_logloss: 0.584522\n",
      "[116]\ttraining's binary_logloss: 0.584531\n",
      "[117]\ttraining's binary_logloss: 0.58458\n",
      "[118]\ttraining's binary_logloss: 0.584573\n",
      "[119]\ttraining's binary_logloss: 0.584574\n",
      "[120]\ttraining's binary_logloss: 0.584563\n",
      "[121]\ttraining's binary_logloss: 0.58458\n",
      "[122]\ttraining's binary_logloss: 0.58458\n",
      "[123]\ttraining's binary_logloss: 0.584547\n",
      "[124]\ttraining's binary_logloss: 0.584521\n",
      "[125]\ttraining's binary_logloss: 0.5845\n",
      "[126]\ttraining's binary_logloss: 0.584498\n",
      "[127]\ttraining's binary_logloss: 0.584485\n",
      "[128]\ttraining's binary_logloss: 0.584508\n",
      "[129]\ttraining's binary_logloss: 0.584516\n",
      "[130]\ttraining's binary_logloss: 0.584524\n",
      "[131]\ttraining's binary_logloss: 0.584563\n",
      "[132]\ttraining's binary_logloss: 0.584608\n",
      "[133]\ttraining's binary_logloss: 0.584652\n",
      "[134]\ttraining's binary_logloss: 0.584679\n",
      "[135]\ttraining's binary_logloss: 0.584718\n",
      "[136]\ttraining's binary_logloss: 0.584739\n",
      "[137]\ttraining's binary_logloss: 0.584757\n",
      "[138]\ttraining's binary_logloss: 0.584778\n",
      "[139]\ttraining's binary_logloss: 0.584807\n",
      "[140]\ttraining's binary_logloss: 0.584846\n",
      "[141]\ttraining's binary_logloss: 0.584808\n",
      "[142]\ttraining's binary_logloss: 0.584789\n",
      "[143]\ttraining's binary_logloss: 0.584772\n",
      "[144]\ttraining's binary_logloss: 0.584761\n",
      "[145]\ttraining's binary_logloss: 0.584784\n",
      "[146]\ttraining's binary_logloss: 0.584787\n",
      "[147]\ttraining's binary_logloss: 0.584815\n",
      "[148]\ttraining's binary_logloss: 0.584823\n",
      "[149]\ttraining's binary_logloss: 0.584847\n",
      "[150]\ttraining's binary_logloss: 0.584858\n",
      "[151]\ttraining's binary_logloss: 0.584868\n",
      "[152]\ttraining's binary_logloss: 0.584928\n",
      "[153]\ttraining's binary_logloss: 0.584944\n",
      "[154]\ttraining's binary_logloss: 0.584967\n",
      "[155]\ttraining's binary_logloss: 0.584989\n",
      "[156]\ttraining's binary_logloss: 0.585013\n",
      "[157]\ttraining's binary_logloss: 0.585054\n",
      "[158]\ttraining's binary_logloss: 0.585077\n",
      "[159]\ttraining's binary_logloss: 0.585099\n",
      "[160]\ttraining's binary_logloss: 0.585125\n",
      "[161]\ttraining's binary_logloss: 0.585105\n",
      "[162]\ttraining's binary_logloss: 0.585116\n",
      "[163]\ttraining's binary_logloss: 0.585086\n",
      "[164]\ttraining's binary_logloss: 0.585069\n",
      "[165]\ttraining's binary_logloss: 0.585076\n",
      "[166]\ttraining's binary_logloss: 0.585089\n",
      "[167]\ttraining's binary_logloss: 0.585104\n",
      "[168]\ttraining's binary_logloss: 0.585121\n",
      "[169]\ttraining's binary_logloss: 0.585148\n",
      "[170]\ttraining's binary_logloss: 0.585159\n",
      "[171]\ttraining's binary_logloss: 0.585176\n",
      "[172]\ttraining's binary_logloss: 0.585182\n",
      "[173]\ttraining's binary_logloss: 0.58519\n",
      "[174]\ttraining's binary_logloss: 0.585214\n",
      "[175]\ttraining's binary_logloss: 0.585236\n",
      "[176]\ttraining's binary_logloss: 0.585202\n",
      "[177]\ttraining's binary_logloss: 0.585171\n",
      "[178]\ttraining's binary_logloss: 0.585142\n",
      "[179]\ttraining's binary_logloss: 0.585146\n",
      "[180]\ttraining's binary_logloss: 0.585157\n",
      "[181]\ttraining's binary_logloss: 0.585136\n",
      "[182]\ttraining's binary_logloss: 0.585119\n",
      "[183]\ttraining's binary_logloss: 0.585105\n",
      "[184]\ttraining's binary_logloss: 0.585101\n",
      "[185]\ttraining's binary_logloss: 0.5851\n",
      "[186]\ttraining's binary_logloss: 0.585088\n",
      "[187]\ttraining's binary_logloss: 0.585113\n",
      "[188]\ttraining's binary_logloss: 0.585146\n",
      "[189]\ttraining's binary_logloss: 0.58513\n",
      "[190]\ttraining's binary_logloss: 0.585148\n",
      "[191]\ttraining's binary_logloss: 0.585132\n",
      "[192]\ttraining's binary_logloss: 0.585131\n",
      "[193]\ttraining's binary_logloss: 0.585109\n",
      "[194]\ttraining's binary_logloss: 0.585087\n",
      "[195]\ttraining's binary_logloss: 0.585084\n",
      "[196]\ttraining's binary_logloss: 0.58511\n",
      "[197]\ttraining's binary_logloss: 0.585115\n",
      "[198]\ttraining's binary_logloss: 0.585136\n",
      "[199]\ttraining's binary_logloss: 0.585131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's binary_logloss: 0.585143\n",
      "[201]\ttraining's binary_logloss: 0.585146\n",
      "[202]\ttraining's binary_logloss: 0.585143\n",
      "[203]\ttraining's binary_logloss: 0.585161\n",
      "[204]\ttraining's binary_logloss: 0.585163\n",
      "[205]\ttraining's binary_logloss: 0.585167\n",
      "[206]\ttraining's binary_logloss: 0.585148\n",
      "[207]\ttraining's binary_logloss: 0.585108\n",
      "[208]\ttraining's binary_logloss: 0.585081\n",
      "[209]\ttraining's binary_logloss: 0.585054\n",
      "[210]\ttraining's binary_logloss: 0.585029\n",
      "[211]\ttraining's binary_logloss: 0.585012\n",
      "[212]\ttraining's binary_logloss: 0.584998\n",
      "[213]\ttraining's binary_logloss: 0.584975\n",
      "[214]\ttraining's binary_logloss: 0.584965\n",
      "[215]\ttraining's binary_logloss: 0.584956\n",
      "[216]\ttraining's binary_logloss: 0.584956\n",
      "[217]\ttraining's binary_logloss: 0.584938\n",
      "[218]\ttraining's binary_logloss: 0.584918\n",
      "[219]\ttraining's binary_logloss: 0.584913\n",
      "[220]\ttraining's binary_logloss: 0.584896\n",
      "[221]\ttraining's binary_logloss: 0.584882\n",
      "[222]\ttraining's binary_logloss: 0.584872\n",
      "[223]\ttraining's binary_logloss: 0.584849\n",
      "[224]\ttraining's binary_logloss: 0.584811\n",
      "[225]\ttraining's binary_logloss: 0.584812\n",
      "[226]\ttraining's binary_logloss: 0.584798\n",
      "[227]\ttraining's binary_logloss: 0.584753\n",
      "[228]\ttraining's binary_logloss: 0.584719\n",
      "[229]\ttraining's binary_logloss: 0.584684\n",
      "[230]\ttraining's binary_logloss: 0.58465\n",
      "[231]\ttraining's binary_logloss: 0.584626\n",
      "[232]\ttraining's binary_logloss: 0.584617\n",
      "[233]\ttraining's binary_logloss: 0.58459\n",
      "[234]\ttraining's binary_logloss: 0.584587\n",
      "[235]\ttraining's binary_logloss: 0.584575\n",
      "[236]\ttraining's binary_logloss: 0.584574\n",
      "[237]\ttraining's binary_logloss: 0.584565\n",
      "[238]\ttraining's binary_logloss: 0.584542\n",
      "[239]\ttraining's binary_logloss: 0.584534\n",
      "[240]\ttraining's binary_logloss: 0.584555\n",
      "[241]\ttraining's binary_logloss: 0.584509\n",
      "[242]\ttraining's binary_logloss: 0.584468\n",
      "[243]\ttraining's binary_logloss: 0.58444\n",
      "[244]\ttraining's binary_logloss: 0.584392\n",
      "[245]\ttraining's binary_logloss: 0.584356\n",
      "[246]\ttraining's binary_logloss: 0.584294\n",
      "[247]\ttraining's binary_logloss: 0.584232\n",
      "[248]\ttraining's binary_logloss: 0.584194\n",
      "[249]\ttraining's binary_logloss: 0.584129\n",
      "[250]\ttraining's binary_logloss: 0.584084\n",
      "[251]\ttraining's binary_logloss: 0.584038\n",
      "[252]\ttraining's binary_logloss: 0.583986\n",
      "[253]\ttraining's binary_logloss: 0.583941\n",
      "[254]\ttraining's binary_logloss: 0.583905\n",
      "[255]\ttraining's binary_logloss: 0.583856\n",
      "[256]\ttraining's binary_logloss: 0.583813\n",
      "[257]\ttraining's binary_logloss: 0.583767\n",
      "[258]\ttraining's binary_logloss: 0.583726\n",
      "[259]\ttraining's binary_logloss: 0.583692\n",
      "[260]\ttraining's binary_logloss: 0.583655\n",
      "[261]\ttraining's binary_logloss: 0.583585\n",
      "[262]\ttraining's binary_logloss: 0.583535\n",
      "[263]\ttraining's binary_logloss: 0.583493\n",
      "[264]\ttraining's binary_logloss: 0.583435\n",
      "[265]\ttraining's binary_logloss: 0.583395\n",
      "[266]\ttraining's binary_logloss: 0.583386\n",
      "[267]\ttraining's binary_logloss: 0.583385\n",
      "[268]\ttraining's binary_logloss: 0.583372\n",
      "[269]\ttraining's binary_logloss: 0.58335\n",
      "[270]\ttraining's binary_logloss: 0.58335\n",
      "[271]\ttraining's binary_logloss: 0.583345\n",
      "[272]\ttraining's binary_logloss: 0.58333\n",
      "[273]\ttraining's binary_logloss: 0.58332\n",
      "[274]\ttraining's binary_logloss: 0.583303\n",
      "[275]\ttraining's binary_logloss: 0.583295\n",
      "[276]\ttraining's binary_logloss: 0.583241\n",
      "[277]\ttraining's binary_logloss: 0.583185\n",
      "[278]\ttraining's binary_logloss: 0.58314\n",
      "[279]\ttraining's binary_logloss: 0.583075\n",
      "[280]\ttraining's binary_logloss: 0.583021\n",
      "[281]\ttraining's binary_logloss: 0.582945\n",
      "[282]\ttraining's binary_logloss: 0.582895\n",
      "[283]\ttraining's binary_logloss: 0.582821\n",
      "[284]\ttraining's binary_logloss: 0.58277\n",
      "[285]\ttraining's binary_logloss: 0.582704\n",
      "[286]\ttraining's binary_logloss: 0.582687\n",
      "[287]\ttraining's binary_logloss: 0.58269\n",
      "[288]\ttraining's binary_logloss: 0.582677\n",
      "[289]\ttraining's binary_logloss: 0.582654\n",
      "[290]\ttraining's binary_logloss: 0.58265\n",
      "[291]\ttraining's binary_logloss: 0.582591\n",
      "[292]\ttraining's binary_logloss: 0.582506\n",
      "[293]\ttraining's binary_logloss: 0.58244\n",
      "[294]\ttraining's binary_logloss: 0.582358\n",
      "[295]\ttraining's binary_logloss: 0.582271\n",
      "[296]\ttraining's binary_logloss: 0.582193\n",
      "[297]\ttraining's binary_logloss: 0.582095\n",
      "[298]\ttraining's binary_logloss: 0.582068\n",
      "[299]\ttraining's binary_logloss: 0.581983\n",
      "[300]\ttraining's binary_logloss: 0.581906\n",
      "[301]\ttraining's binary_logloss: 0.581826\n",
      "[302]\ttraining's binary_logloss: 0.581732\n",
      "[303]\ttraining's binary_logloss: 0.581642\n",
      "[304]\ttraining's binary_logloss: 0.581566\n",
      "[305]\ttraining's binary_logloss: 0.581471\n",
      "[306]\ttraining's binary_logloss: 0.581419\n",
      "[307]\ttraining's binary_logloss: 0.581367\n",
      "[308]\ttraining's binary_logloss: 0.581311\n",
      "[309]\ttraining's binary_logloss: 0.581257\n",
      "[310]\ttraining's binary_logloss: 0.5812\n",
      "[311]\ttraining's binary_logloss: 0.581159\n",
      "[312]\ttraining's binary_logloss: 0.581081\n",
      "[313]\ttraining's binary_logloss: 0.581003\n",
      "[314]\ttraining's binary_logloss: 0.580926\n",
      "[315]\ttraining's binary_logloss: 0.58086\n",
      "[316]\ttraining's binary_logloss: 0.580781\n",
      "[317]\ttraining's binary_logloss: 0.580702\n",
      "[318]\ttraining's binary_logloss: 0.580625\n",
      "[319]\ttraining's binary_logloss: 0.580547\n",
      "[320]\ttraining's binary_logloss: 0.580474\n",
      "[321]\ttraining's binary_logloss: 0.580429\n",
      "[322]\ttraining's binary_logloss: 0.580389\n",
      "[323]\ttraining's binary_logloss: 0.580342\n",
      "[324]\ttraining's binary_logloss: 0.580298\n",
      "[325]\ttraining's binary_logloss: 0.580241\n",
      "[326]\ttraining's binary_logloss: 0.580188\n",
      "[327]\ttraining's binary_logloss: 0.580136\n",
      "[328]\ttraining's binary_logloss: 0.580081\n",
      "[329]\ttraining's binary_logloss: 0.580023\n",
      "[330]\ttraining's binary_logloss: 0.579962\n",
      "[331]\ttraining's binary_logloss: 0.57992\n",
      "[332]\ttraining's binary_logloss: 0.579852\n",
      "[333]\ttraining's binary_logloss: 0.579791\n",
      "[334]\ttraining's binary_logloss: 0.579721\n",
      "[335]\ttraining's binary_logloss: 0.579655\n",
      "[336]\ttraining's binary_logloss: 0.579574\n",
      "[337]\ttraining's binary_logloss: 0.579497\n",
      "[338]\ttraining's binary_logloss: 0.579421\n",
      "[339]\ttraining's binary_logloss: 0.579345\n",
      "[340]\ttraining's binary_logloss: 0.579277\n",
      "[341]\ttraining's binary_logloss: 0.579206\n",
      "[342]\ttraining's binary_logloss: 0.57912\n",
      "[343]\ttraining's binary_logloss: 0.579047\n",
      "[344]\ttraining's binary_logloss: 0.578974\n",
      "[345]\ttraining's binary_logloss: 0.578907\n",
      "[346]\ttraining's binary_logloss: 0.578844\n",
      "[347]\ttraining's binary_logloss: 0.578793\n",
      "[348]\ttraining's binary_logloss: 0.578724\n",
      "[349]\ttraining's binary_logloss: 0.578666\n",
      "[350]\ttraining's binary_logloss: 0.578619\n",
      "[351]\ttraining's binary_logloss: 0.57855\n",
      "[352]\ttraining's binary_logloss: 0.578464\n",
      "[353]\ttraining's binary_logloss: 0.578412\n",
      "[354]\ttraining's binary_logloss: 0.57835\n",
      "[355]\ttraining's binary_logloss: 0.578271\n",
      "[356]\ttraining's binary_logloss: 0.578191\n",
      "[357]\ttraining's binary_logloss: 0.578113\n",
      "[358]\ttraining's binary_logloss: 0.578038\n",
      "[359]\ttraining's binary_logloss: 0.57796\n",
      "[360]\ttraining's binary_logloss: 0.577886\n",
      "[361]\ttraining's binary_logloss: 0.577791\n",
      "[362]\ttraining's binary_logloss: 0.577698\n",
      "[363]\ttraining's binary_logloss: 0.577595\n",
      "[364]\ttraining's binary_logloss: 0.577505\n",
      "[365]\ttraining's binary_logloss: 0.577418\n",
      "[366]\ttraining's binary_logloss: 0.577337\n",
      "[367]\ttraining's binary_logloss: 0.577259\n",
      "[368]\ttraining's binary_logloss: 0.577183\n",
      "[369]\ttraining's binary_logloss: 0.577109\n",
      "[370]\ttraining's binary_logloss: 0.577038\n",
      "[371]\ttraining's binary_logloss: 0.576996\n",
      "[372]\ttraining's binary_logloss: 0.576937\n",
      "[373]\ttraining's binary_logloss: 0.576877\n",
      "[374]\ttraining's binary_logloss: 0.576809\n",
      "[375]\ttraining's binary_logloss: 0.576734\n",
      "[376]\ttraining's binary_logloss: 0.576645\n",
      "[377]\ttraining's binary_logloss: 0.576543\n",
      "[378]\ttraining's binary_logloss: 0.576453\n",
      "[379]\ttraining's binary_logloss: 0.576339\n",
      "[380]\ttraining's binary_logloss: 0.576236\n",
      "[381]\ttraining's binary_logloss: 0.576169\n",
      "[382]\ttraining's binary_logloss: 0.576092\n",
      "[383]\ttraining's binary_logloss: 0.576012\n",
      "[384]\ttraining's binary_logloss: 0.575956\n",
      "[385]\ttraining's binary_logloss: 0.575897\n",
      "[386]\ttraining's binary_logloss: 0.575805\n",
      "[387]\ttraining's binary_logloss: 0.575714\n",
      "[388]\ttraining's binary_logloss: 0.575622\n",
      "[389]\ttraining's binary_logloss: 0.575534\n",
      "[390]\ttraining's binary_logloss: 0.575439\n",
      "[391]\ttraining's binary_logloss: 0.575376\n",
      "[392]\ttraining's binary_logloss: 0.575321\n",
      "[393]\ttraining's binary_logloss: 0.575272\n",
      "[394]\ttraining's binary_logloss: 0.575229\n",
      "[395]\ttraining's binary_logloss: 0.57518\n",
      "[396]\ttraining's binary_logloss: 0.575104\n",
      "[397]\ttraining's binary_logloss: 0.575035\n",
      "[398]\ttraining's binary_logloss: 0.57496\n",
      "[399]\ttraining's binary_logloss: 0.574884\n",
      "[400]\ttraining's binary_logloss: 0.574813\n",
      "[401]\ttraining's binary_logloss: 0.574712\n",
      "[402]\ttraining's binary_logloss: 0.574623\n",
      "[403]\ttraining's binary_logloss: 0.57454\n",
      "[404]\ttraining's binary_logloss: 0.574458\n",
      "[405]\ttraining's binary_logloss: 0.574379\n",
      "[406]\ttraining's binary_logloss: 0.574285\n",
      "[407]\ttraining's binary_logloss: 0.57419\n",
      "[408]\ttraining's binary_logloss: 0.574103\n",
      "[409]\ttraining's binary_logloss: 0.574017\n",
      "[410]\ttraining's binary_logloss: 0.573933\n",
      "[411]\ttraining's binary_logloss: 0.573828\n",
      "[412]\ttraining's binary_logloss: 0.573741\n",
      "[413]\ttraining's binary_logloss: 0.573642\n",
      "[414]\ttraining's binary_logloss: 0.57353\n",
      "[415]\ttraining's binary_logloss: 0.573431\n",
      "[416]\ttraining's binary_logloss: 0.573343\n",
      "[417]\ttraining's binary_logloss: 0.573257\n",
      "[418]\ttraining's binary_logloss: 0.57317\n",
      "[419]\ttraining's binary_logloss: 0.573087\n",
      "[420]\ttraining's binary_logloss: 0.573008\n",
      "[421]\ttraining's binary_logloss: 0.572958\n",
      "[422]\ttraining's binary_logloss: 0.572904\n",
      "[423]\ttraining's binary_logloss: 0.572853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[424]\ttraining's binary_logloss: 0.572806\n",
      "[425]\ttraining's binary_logloss: 0.572763\n",
      "[426]\ttraining's binary_logloss: 0.572707\n",
      "[427]\ttraining's binary_logloss: 0.572665\n",
      "[428]\ttraining's binary_logloss: 0.57263\n",
      "[429]\ttraining's binary_logloss: 0.572579\n",
      "[430]\ttraining's binary_logloss: 0.572524\n",
      "[431]\ttraining's binary_logloss: 0.572439\n",
      "[432]\ttraining's binary_logloss: 0.572362\n",
      "[433]\ttraining's binary_logloss: 0.572283\n",
      "[434]\ttraining's binary_logloss: 0.572211\n",
      "[435]\ttraining's binary_logloss: 0.572141\n",
      "[436]\ttraining's binary_logloss: 0.572061\n",
      "[437]\ttraining's binary_logloss: 0.571985\n",
      "[438]\ttraining's binary_logloss: 0.571919\n",
      "[439]\ttraining's binary_logloss: 0.57185\n",
      "[440]\ttraining's binary_logloss: 0.571777\n",
      "[441]\ttraining's binary_logloss: 0.571688\n",
      "[442]\ttraining's binary_logloss: 0.571599\n",
      "[443]\ttraining's binary_logloss: 0.571512\n",
      "[444]\ttraining's binary_logloss: 0.571435\n",
      "[445]\ttraining's binary_logloss: 0.571338\n",
      "[446]\ttraining's binary_logloss: 0.571257\n",
      "[447]\ttraining's binary_logloss: 0.57119\n",
      "[448]\ttraining's binary_logloss: 0.571112\n",
      "[449]\ttraining's binary_logloss: 0.57103\n",
      "[450]\ttraining's binary_logloss: 0.570949\n",
      "[451]\ttraining's binary_logloss: 0.570882\n",
      "[452]\ttraining's binary_logloss: 0.570817\n",
      "[453]\ttraining's binary_logloss: 0.570766\n",
      "[454]\ttraining's binary_logloss: 0.570703\n",
      "[455]\ttraining's binary_logloss: 0.57064\n",
      "[456]\ttraining's binary_logloss: 0.570543\n",
      "[457]\ttraining's binary_logloss: 0.570469\n",
      "[458]\ttraining's binary_logloss: 0.570399\n",
      "[459]\ttraining's binary_logloss: 0.570318\n",
      "[460]\ttraining's binary_logloss: 0.570245\n",
      "[461]\ttraining's binary_logloss: 0.570148\n",
      "[462]\ttraining's binary_logloss: 0.570057\n",
      "[463]\ttraining's binary_logloss: 0.569961\n",
      "[464]\ttraining's binary_logloss: 0.569881\n",
      "[465]\ttraining's binary_logloss: 0.569792\n",
      "[466]\ttraining's binary_logloss: 0.569718\n",
      "[467]\ttraining's binary_logloss: 0.569642\n",
      "[468]\ttraining's binary_logloss: 0.569581\n",
      "[469]\ttraining's binary_logloss: 0.569506\n",
      "[470]\ttraining's binary_logloss: 0.569455\n",
      "[471]\ttraining's binary_logloss: 0.569389\n",
      "[472]\ttraining's binary_logloss: 0.569318\n",
      "[473]\ttraining's binary_logloss: 0.569257\n",
      "[474]\ttraining's binary_logloss: 0.5692\n",
      "[475]\ttraining's binary_logloss: 0.569141\n",
      "[476]\ttraining's binary_logloss: 0.569037\n",
      "[477]\ttraining's binary_logloss: 0.568937\n",
      "[478]\ttraining's binary_logloss: 0.568837\n",
      "[479]\ttraining's binary_logloss: 0.568769\n",
      "[480]\ttraining's binary_logloss: 0.568671\n",
      "[481]\ttraining's binary_logloss: 0.568571\n",
      "[482]\ttraining's binary_logloss: 0.568484\n",
      "[483]\ttraining's binary_logloss: 0.568391\n",
      "[484]\ttraining's binary_logloss: 0.568304\n",
      "[485]\ttraining's binary_logloss: 0.568208\n",
      "[486]\ttraining's binary_logloss: 0.568142\n",
      "[487]\ttraining's binary_logloss: 0.568078\n",
      "[488]\ttraining's binary_logloss: 0.567998\n",
      "[489]\ttraining's binary_logloss: 0.567927\n",
      "[490]\ttraining's binary_logloss: 0.567858\n",
      "[491]\ttraining's binary_logloss: 0.567782\n",
      "[492]\ttraining's binary_logloss: 0.567714\n",
      "[493]\ttraining's binary_logloss: 0.567648\n",
      "[494]\ttraining's binary_logloss: 0.567585\n",
      "[495]\ttraining's binary_logloss: 0.567517\n",
      "[496]\ttraining's binary_logloss: 0.567423\n",
      "[497]\ttraining's binary_logloss: 0.567339\n",
      "[498]\ttraining's binary_logloss: 0.567254\n",
      "[499]\ttraining's binary_logloss: 0.567165\n",
      "[500]\ttraining's binary_logloss: 0.567088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.614476\n",
      "[2]\ttraining's binary_logloss: 0.613349\n",
      "[3]\ttraining's binary_logloss: 0.612322\n",
      "[4]\ttraining's binary_logloss: 0.611286\n",
      "[5]\ttraining's binary_logloss: 0.61042\n",
      "[6]\ttraining's binary_logloss: 0.609489\n",
      "[7]\ttraining's binary_logloss: 0.608633\n",
      "[8]\ttraining's binary_logloss: 0.607839\n",
      "[9]\ttraining's binary_logloss: 0.60703\n",
      "[10]\ttraining's binary_logloss: 0.606246\n",
      "[11]\ttraining's binary_logloss: 0.605402\n",
      "[12]\ttraining's binary_logloss: 0.6046\n",
      "[13]\ttraining's binary_logloss: 0.603894\n",
      "[14]\ttraining's binary_logloss: 0.603152\n",
      "[15]\ttraining's binary_logloss: 0.602448\n",
      "[16]\ttraining's binary_logloss: 0.601669\n",
      "[17]\ttraining's binary_logloss: 0.600998\n",
      "[18]\ttraining's binary_logloss: 0.600282\n",
      "[19]\ttraining's binary_logloss: 0.599729\n",
      "[20]\ttraining's binary_logloss: 0.599108\n",
      "[21]\ttraining's binary_logloss: 0.598632\n",
      "[22]\ttraining's binary_logloss: 0.598177\n",
      "[23]\ttraining's binary_logloss: 0.597596\n",
      "[24]\ttraining's binary_logloss: 0.597042\n",
      "[25]\ttraining's binary_logloss: 0.596637\n",
      "[26]\ttraining's binary_logloss: 0.596172\n",
      "[27]\ttraining's binary_logloss: 0.595821\n",
      "[28]\ttraining's binary_logloss: 0.595394\n",
      "[29]\ttraining's binary_logloss: 0.594976\n",
      "[30]\ttraining's binary_logloss: 0.594584\n",
      "[31]\ttraining's binary_logloss: 0.59413\n",
      "[32]\ttraining's binary_logloss: 0.593695\n",
      "[33]\ttraining's binary_logloss: 0.59317\n",
      "[34]\ttraining's binary_logloss: 0.592822\n",
      "[35]\ttraining's binary_logloss: 0.592415\n",
      "[36]\ttraining's binary_logloss: 0.59212\n",
      "[37]\ttraining's binary_logloss: 0.591852\n",
      "[38]\ttraining's binary_logloss: 0.591576\n",
      "[39]\ttraining's binary_logloss: 0.591316\n",
      "[40]\ttraining's binary_logloss: 0.591073\n",
      "[41]\ttraining's binary_logloss: 0.590757\n",
      "[42]\ttraining's binary_logloss: 0.590456\n",
      "[43]\ttraining's binary_logloss: 0.590231\n",
      "[44]\ttraining's binary_logloss: 0.589999\n",
      "[45]\ttraining's binary_logloss: 0.589812\n",
      "[46]\ttraining's binary_logloss: 0.589601\n",
      "[47]\ttraining's binary_logloss: 0.589275\n",
      "[48]\ttraining's binary_logloss: 0.588985\n",
      "[49]\ttraining's binary_logloss: 0.588701\n",
      "[50]\ttraining's binary_logloss: 0.588504\n",
      "[51]\ttraining's binary_logloss: 0.588278\n",
      "[52]\ttraining's binary_logloss: 0.588125\n",
      "[53]\ttraining's binary_logloss: 0.587989\n",
      "[54]\ttraining's binary_logloss: 0.587771\n",
      "[55]\ttraining's binary_logloss: 0.587565\n",
      "[56]\ttraining's binary_logloss: 0.587404\n",
      "[57]\ttraining's binary_logloss: 0.587229\n",
      "[58]\ttraining's binary_logloss: 0.587045\n",
      "[59]\ttraining's binary_logloss: 0.586899\n",
      "[60]\ttraining's binary_logloss: 0.586712\n",
      "[61]\ttraining's binary_logloss: 0.586599\n",
      "[62]\ttraining's binary_logloss: 0.586495\n",
      "[63]\ttraining's binary_logloss: 0.586438\n",
      "[64]\ttraining's binary_logloss: 0.586363\n",
      "[65]\ttraining's binary_logloss: 0.586284\n",
      "[66]\ttraining's binary_logloss: 0.586255\n",
      "[67]\ttraining's binary_logloss: 0.586193\n",
      "[68]\ttraining's binary_logloss: 0.586074\n",
      "[69]\ttraining's binary_logloss: 0.585961\n",
      "[70]\ttraining's binary_logloss: 0.585861\n",
      "[71]\ttraining's binary_logloss: 0.585816\n",
      "[72]\ttraining's binary_logloss: 0.585745\n",
      "[73]\ttraining's binary_logloss: 0.585624\n",
      "[74]\ttraining's binary_logloss: 0.585568\n",
      "[75]\ttraining's binary_logloss: 0.585518\n",
      "[76]\ttraining's binary_logloss: 0.585522\n",
      "[77]\ttraining's binary_logloss: 0.585418\n",
      "[78]\ttraining's binary_logloss: 0.585314\n",
      "[79]\ttraining's binary_logloss: 0.585276\n",
      "[80]\ttraining's binary_logloss: 0.585189\n",
      "[81]\ttraining's binary_logloss: 0.585176\n",
      "[82]\ttraining's binary_logloss: 0.585184\n",
      "[83]\ttraining's binary_logloss: 0.585188\n",
      "[84]\ttraining's binary_logloss: 0.585195\n",
      "[85]\ttraining's binary_logloss: 0.585205\n",
      "[86]\ttraining's binary_logloss: 0.585131\n",
      "[87]\ttraining's binary_logloss: 0.585058\n",
      "[88]\ttraining's binary_logloss: 0.585002\n",
      "[89]\ttraining's binary_logloss: 0.584955\n",
      "[90]\ttraining's binary_logloss: 0.584905\n",
      "[91]\ttraining's binary_logloss: 0.58485\n",
      "[92]\ttraining's binary_logloss: 0.584891\n",
      "[93]\ttraining's binary_logloss: 0.584845\n",
      "[94]\ttraining's binary_logloss: 0.584817\n",
      "[95]\ttraining's binary_logloss: 0.584885\n",
      "[96]\ttraining's binary_logloss: 0.58482\n",
      "[97]\ttraining's binary_logloss: 0.584845\n",
      "[98]\ttraining's binary_logloss: 0.58486\n",
      "[99]\ttraining's binary_logloss: 0.584871\n",
      "[100]\ttraining's binary_logloss: 0.58489\n",
      "[101]\ttraining's binary_logloss: 0.584936\n",
      "[102]\ttraining's binary_logloss: 0.584982\n",
      "[103]\ttraining's binary_logloss: 0.585033\n",
      "[104]\ttraining's binary_logloss: 0.585089\n",
      "[105]\ttraining's binary_logloss: 0.585135\n",
      "[106]\ttraining's binary_logloss: 0.585177\n",
      "[107]\ttraining's binary_logloss: 0.585223\n",
      "[108]\ttraining's binary_logloss: 0.58526\n",
      "[109]\ttraining's binary_logloss: 0.585312\n",
      "[110]\ttraining's binary_logloss: 0.585356\n",
      "[111]\ttraining's binary_logloss: 0.585338\n",
      "[112]\ttraining's binary_logloss: 0.585317\n",
      "[113]\ttraining's binary_logloss: 0.585288\n",
      "[114]\ttraining's binary_logloss: 0.585306\n",
      "[115]\ttraining's binary_logloss: 0.585284\n",
      "[116]\ttraining's binary_logloss: 0.585306\n",
      "[117]\ttraining's binary_logloss: 0.585301\n",
      "[118]\ttraining's binary_logloss: 0.585278\n",
      "[119]\ttraining's binary_logloss: 0.585277\n",
      "[120]\ttraining's binary_logloss: 0.585261\n",
      "[121]\ttraining's binary_logloss: 0.585255\n",
      "[122]\ttraining's binary_logloss: 0.585246\n",
      "[123]\ttraining's binary_logloss: 0.58524\n",
      "[124]\ttraining's binary_logloss: 0.585238\n",
      "[125]\ttraining's binary_logloss: 0.585237\n",
      "[126]\ttraining's binary_logloss: 0.585237\n",
      "[127]\ttraining's binary_logloss: 0.58523\n",
      "[128]\ttraining's binary_logloss: 0.585224\n",
      "[129]\ttraining's binary_logloss: 0.585215\n",
      "[130]\ttraining's binary_logloss: 0.585215\n",
      "[131]\ttraining's binary_logloss: 0.585237\n",
      "[132]\ttraining's binary_logloss: 0.58528\n",
      "[133]\ttraining's binary_logloss: 0.58533\n",
      "[134]\ttraining's binary_logloss: 0.585364\n",
      "[135]\ttraining's binary_logloss: 0.585373\n",
      "[136]\ttraining's binary_logloss: 0.585386\n",
      "[137]\ttraining's binary_logloss: 0.585397\n",
      "[138]\ttraining's binary_logloss: 0.58541\n",
      "[139]\ttraining's binary_logloss: 0.585427\n",
      "[140]\ttraining's binary_logloss: 0.585454\n",
      "[141]\ttraining's binary_logloss: 0.585428\n",
      "[142]\ttraining's binary_logloss: 0.585447\n",
      "[143]\ttraining's binary_logloss: 0.585428\n",
      "[144]\ttraining's binary_logloss: 0.58541\n",
      "[145]\ttraining's binary_logloss: 0.585387\n",
      "[146]\ttraining's binary_logloss: 0.585382\n",
      "[147]\ttraining's binary_logloss: 0.585429\n",
      "[148]\ttraining's binary_logloss: 0.585428\n",
      "[149]\ttraining's binary_logloss: 0.585425\n",
      "[150]\ttraining's binary_logloss: 0.585471\n",
      "[151]\ttraining's binary_logloss: 0.585511\n",
      "[152]\ttraining's binary_logloss: 0.585536\n",
      "[153]\ttraining's binary_logloss: 0.58558\n",
      "[154]\ttraining's binary_logloss: 0.585597\n",
      "[155]\ttraining's binary_logloss: 0.585641\n",
      "[156]\ttraining's binary_logloss: 0.585668\n",
      "[157]\ttraining's binary_logloss: 0.585706\n",
      "[158]\ttraining's binary_logloss: 0.585737\n",
      "[159]\ttraining's binary_logloss: 0.585772\n",
      "[160]\ttraining's binary_logloss: 0.585805\n",
      "[161]\ttraining's binary_logloss: 0.585826\n",
      "[162]\ttraining's binary_logloss: 0.585809\n",
      "[163]\ttraining's binary_logloss: 0.585793\n",
      "[164]\ttraining's binary_logloss: 0.585815\n",
      "[165]\ttraining's binary_logloss: 0.585838\n",
      "[166]\ttraining's binary_logloss: 0.585845\n",
      "[167]\ttraining's binary_logloss: 0.585844\n",
      "[168]\ttraining's binary_logloss: 0.585857\n",
      "[169]\ttraining's binary_logloss: 0.58585\n",
      "[170]\ttraining's binary_logloss: 0.58584\n",
      "[171]\ttraining's binary_logloss: 0.585881\n",
      "[172]\ttraining's binary_logloss: 0.585902\n",
      "[173]\ttraining's binary_logloss: 0.585926\n",
      "[174]\ttraining's binary_logloss: 0.585964\n",
      "[175]\ttraining's binary_logloss: 0.58599\n",
      "[176]\ttraining's binary_logloss: 0.585986\n",
      "[177]\ttraining's binary_logloss: 0.585974\n",
      "[178]\ttraining's binary_logloss: 0.585969\n",
      "[179]\ttraining's binary_logloss: 0.585966\n",
      "[180]\ttraining's binary_logloss: 0.585959\n",
      "[181]\ttraining's binary_logloss: 0.585974\n",
      "[182]\ttraining's binary_logloss: 0.585959\n",
      "[183]\ttraining's binary_logloss: 0.585947\n",
      "[184]\ttraining's binary_logloss: 0.585937\n",
      "[185]\ttraining's binary_logloss: 0.585925\n",
      "[186]\ttraining's binary_logloss: 0.585943\n",
      "[187]\ttraining's binary_logloss: 0.585946\n",
      "[188]\ttraining's binary_logloss: 0.585958\n",
      "[189]\ttraining's binary_logloss: 0.585965\n",
      "[190]\ttraining's binary_logloss: 0.586003\n",
      "[191]\ttraining's binary_logloss: 0.58599\n",
      "[192]\ttraining's binary_logloss: 0.585973\n",
      "[193]\ttraining's binary_logloss: 0.585965\n",
      "[194]\ttraining's binary_logloss: 0.585949\n",
      "[195]\ttraining's binary_logloss: 0.585913\n",
      "[196]\ttraining's binary_logloss: 0.585915\n",
      "[197]\ttraining's binary_logloss: 0.585921\n",
      "[198]\ttraining's binary_logloss: 0.585922\n",
      "[199]\ttraining's binary_logloss: 0.585935\n",
      "[200]\ttraining's binary_logloss: 0.58594\n",
      "[201]\ttraining's binary_logloss: 0.585928\n",
      "[202]\ttraining's binary_logloss: 0.585928\n",
      "[203]\ttraining's binary_logloss: 0.585931\n",
      "[204]\ttraining's binary_logloss: 0.585914\n",
      "[205]\ttraining's binary_logloss: 0.585905\n",
      "[206]\ttraining's binary_logloss: 0.585902\n",
      "[207]\ttraining's binary_logloss: 0.585878\n",
      "[208]\ttraining's binary_logloss: 0.585875\n",
      "[209]\ttraining's binary_logloss: 0.585833\n",
      "[210]\ttraining's binary_logloss: 0.585802\n",
      "[211]\ttraining's binary_logloss: 0.585785\n",
      "[212]\ttraining's binary_logloss: 0.585768\n",
      "[213]\ttraining's binary_logloss: 0.585738\n",
      "[214]\ttraining's binary_logloss: 0.585712\n",
      "[215]\ttraining's binary_logloss: 0.58569\n",
      "[216]\ttraining's binary_logloss: 0.585675\n",
      "[217]\ttraining's binary_logloss: 0.585674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[218]\ttraining's binary_logloss: 0.585675\n",
      "[219]\ttraining's binary_logloss: 0.585677\n",
      "[220]\ttraining's binary_logloss: 0.585664\n",
      "[221]\ttraining's binary_logloss: 0.585627\n",
      "[222]\ttraining's binary_logloss: 0.585592\n",
      "[223]\ttraining's binary_logloss: 0.585552\n",
      "[224]\ttraining's binary_logloss: 0.585504\n",
      "[225]\ttraining's binary_logloss: 0.585461\n",
      "[226]\ttraining's binary_logloss: 0.585449\n",
      "[227]\ttraining's binary_logloss: 0.585441\n",
      "[228]\ttraining's binary_logloss: 0.585439\n",
      "[229]\ttraining's binary_logloss: 0.585431\n",
      "[230]\ttraining's binary_logloss: 0.585414\n",
      "[231]\ttraining's binary_logloss: 0.585427\n",
      "[232]\ttraining's binary_logloss: 0.58542\n",
      "[233]\ttraining's binary_logloss: 0.585405\n",
      "[234]\ttraining's binary_logloss: 0.585412\n",
      "[235]\ttraining's binary_logloss: 0.585422\n",
      "[236]\ttraining's binary_logloss: 0.585403\n",
      "[237]\ttraining's binary_logloss: 0.585402\n",
      "[238]\ttraining's binary_logloss: 0.585394\n",
      "[239]\ttraining's binary_logloss: 0.585397\n",
      "[240]\ttraining's binary_logloss: 0.585392\n",
      "[241]\ttraining's binary_logloss: 0.585334\n",
      "[242]\ttraining's binary_logloss: 0.585283\n",
      "[243]\ttraining's binary_logloss: 0.585251\n",
      "[244]\ttraining's binary_logloss: 0.585202\n",
      "[245]\ttraining's binary_logloss: 0.585173\n",
      "[246]\ttraining's binary_logloss: 0.585109\n",
      "[247]\ttraining's binary_logloss: 0.585046\n",
      "[248]\ttraining's binary_logloss: 0.584986\n",
      "[249]\ttraining's binary_logloss: 0.584941\n",
      "[250]\ttraining's binary_logloss: 0.584885\n",
      "[251]\ttraining's binary_logloss: 0.584853\n",
      "[252]\ttraining's binary_logloss: 0.584816\n",
      "[253]\ttraining's binary_logloss: 0.58478\n",
      "[254]\ttraining's binary_logloss: 0.584738\n",
      "[255]\ttraining's binary_logloss: 0.58467\n",
      "[256]\ttraining's binary_logloss: 0.584643\n",
      "[257]\ttraining's binary_logloss: 0.584632\n",
      "[258]\ttraining's binary_logloss: 0.584597\n",
      "[259]\ttraining's binary_logloss: 0.584559\n",
      "[260]\ttraining's binary_logloss: 0.584534\n",
      "[261]\ttraining's binary_logloss: 0.584473\n",
      "[262]\ttraining's binary_logloss: 0.584404\n",
      "[263]\ttraining's binary_logloss: 0.584336\n",
      "[264]\ttraining's binary_logloss: 0.584259\n",
      "[265]\ttraining's binary_logloss: 0.58419\n",
      "[266]\ttraining's binary_logloss: 0.58417\n",
      "[267]\ttraining's binary_logloss: 0.584148\n",
      "[268]\ttraining's binary_logloss: 0.584126\n",
      "[269]\ttraining's binary_logloss: 0.584115\n",
      "[270]\ttraining's binary_logloss: 0.584091\n",
      "[271]\ttraining's binary_logloss: 0.584077\n",
      "[272]\ttraining's binary_logloss: 0.584077\n",
      "[273]\ttraining's binary_logloss: 0.584067\n",
      "[274]\ttraining's binary_logloss: 0.584039\n",
      "[275]\ttraining's binary_logloss: 0.58404\n",
      "[276]\ttraining's binary_logloss: 0.583989\n",
      "[277]\ttraining's binary_logloss: 0.583918\n",
      "[278]\ttraining's binary_logloss: 0.583837\n",
      "[279]\ttraining's binary_logloss: 0.583758\n",
      "[280]\ttraining's binary_logloss: 0.583699\n",
      "[281]\ttraining's binary_logloss: 0.583632\n",
      "[282]\ttraining's binary_logloss: 0.583572\n",
      "[283]\ttraining's binary_logloss: 0.583513\n",
      "[284]\ttraining's binary_logloss: 0.583441\n",
      "[285]\ttraining's binary_logloss: 0.583372\n",
      "[286]\ttraining's binary_logloss: 0.58333\n",
      "[287]\ttraining's binary_logloss: 0.583279\n",
      "[288]\ttraining's binary_logloss: 0.583226\n",
      "[289]\ttraining's binary_logloss: 0.583183\n",
      "[290]\ttraining's binary_logloss: 0.583143\n",
      "[291]\ttraining's binary_logloss: 0.583055\n",
      "[292]\ttraining's binary_logloss: 0.582971\n",
      "[293]\ttraining's binary_logloss: 0.582888\n",
      "[294]\ttraining's binary_logloss: 0.582807\n",
      "[295]\ttraining's binary_logloss: 0.582725\n",
      "[296]\ttraining's binary_logloss: 0.582684\n",
      "[297]\ttraining's binary_logloss: 0.582655\n",
      "[298]\ttraining's binary_logloss: 0.582632\n",
      "[299]\ttraining's binary_logloss: 0.582605\n",
      "[300]\ttraining's binary_logloss: 0.582568\n",
      "[301]\ttraining's binary_logloss: 0.582477\n",
      "[302]\ttraining's binary_logloss: 0.582373\n",
      "[303]\ttraining's binary_logloss: 0.582274\n",
      "[304]\ttraining's binary_logloss: 0.582181\n",
      "[305]\ttraining's binary_logloss: 0.58209\n",
      "[306]\ttraining's binary_logloss: 0.58202\n",
      "[307]\ttraining's binary_logloss: 0.581956\n",
      "[308]\ttraining's binary_logloss: 0.581889\n",
      "[309]\ttraining's binary_logloss: 0.581841\n",
      "[310]\ttraining's binary_logloss: 0.581774\n",
      "[311]\ttraining's binary_logloss: 0.58169\n",
      "[312]\ttraining's binary_logloss: 0.581623\n",
      "[313]\ttraining's binary_logloss: 0.581544\n",
      "[314]\ttraining's binary_logloss: 0.581466\n",
      "[315]\ttraining's binary_logloss: 0.581394\n",
      "[316]\ttraining's binary_logloss: 0.581298\n",
      "[317]\ttraining's binary_logloss: 0.581225\n",
      "[318]\ttraining's binary_logloss: 0.581147\n",
      "[319]\ttraining's binary_logloss: 0.581077\n",
      "[320]\ttraining's binary_logloss: 0.581008\n",
      "[321]\ttraining's binary_logloss: 0.580946\n",
      "[322]\ttraining's binary_logloss: 0.580886\n",
      "[323]\ttraining's binary_logloss: 0.580815\n",
      "[324]\ttraining's binary_logloss: 0.580762\n",
      "[325]\ttraining's binary_logloss: 0.580696\n",
      "[326]\ttraining's binary_logloss: 0.580627\n",
      "[327]\ttraining's binary_logloss: 0.580556\n",
      "[328]\ttraining's binary_logloss: 0.580492\n",
      "[329]\ttraining's binary_logloss: 0.580451\n",
      "[330]\ttraining's binary_logloss: 0.580382\n",
      "[331]\ttraining's binary_logloss: 0.580334\n",
      "[332]\ttraining's binary_logloss: 0.580282\n",
      "[333]\ttraining's binary_logloss: 0.580228\n",
      "[334]\ttraining's binary_logloss: 0.580174\n",
      "[335]\ttraining's binary_logloss: 0.580119\n",
      "[336]\ttraining's binary_logloss: 0.58008\n",
      "[337]\ttraining's binary_logloss: 0.580037\n",
      "[338]\ttraining's binary_logloss: 0.579997\n",
      "[339]\ttraining's binary_logloss: 0.579954\n",
      "[340]\ttraining's binary_logloss: 0.5799\n",
      "[341]\ttraining's binary_logloss: 0.579815\n",
      "[342]\ttraining's binary_logloss: 0.579752\n",
      "[343]\ttraining's binary_logloss: 0.579669\n",
      "[344]\ttraining's binary_logloss: 0.579604\n",
      "[345]\ttraining's binary_logloss: 0.579532\n",
      "[346]\ttraining's binary_logloss: 0.579467\n",
      "[347]\ttraining's binary_logloss: 0.579428\n",
      "[348]\ttraining's binary_logloss: 0.579363\n",
      "[349]\ttraining's binary_logloss: 0.579325\n",
      "[350]\ttraining's binary_logloss: 0.579276\n",
      "[351]\ttraining's binary_logloss: 0.579193\n",
      "[352]\ttraining's binary_logloss: 0.579111\n",
      "[353]\ttraining's binary_logloss: 0.57903\n",
      "[354]\ttraining's binary_logloss: 0.578965\n",
      "[355]\ttraining's binary_logloss: 0.578895\n",
      "[356]\ttraining's binary_logloss: 0.578813\n",
      "[357]\ttraining's binary_logloss: 0.578731\n",
      "[358]\ttraining's binary_logloss: 0.578655\n",
      "[359]\ttraining's binary_logloss: 0.578573\n",
      "[360]\ttraining's binary_logloss: 0.578499\n",
      "[361]\ttraining's binary_logloss: 0.578415\n",
      "[362]\ttraining's binary_logloss: 0.578329\n",
      "[363]\ttraining's binary_logloss: 0.57824\n",
      "[364]\ttraining's binary_logloss: 0.578128\n",
      "[365]\ttraining's binary_logloss: 0.578044\n",
      "[366]\ttraining's binary_logloss: 0.577933\n",
      "[367]\ttraining's binary_logloss: 0.577828\n",
      "[368]\ttraining's binary_logloss: 0.577727\n",
      "[369]\ttraining's binary_logloss: 0.577629\n",
      "[370]\ttraining's binary_logloss: 0.577524\n",
      "[371]\ttraining's binary_logloss: 0.577459\n",
      "[372]\ttraining's binary_logloss: 0.577393\n",
      "[373]\ttraining's binary_logloss: 0.577325\n",
      "[374]\ttraining's binary_logloss: 0.577255\n",
      "[375]\ttraining's binary_logloss: 0.577193\n",
      "[376]\ttraining's binary_logloss: 0.577093\n",
      "[377]\ttraining's binary_logloss: 0.576989\n",
      "[378]\ttraining's binary_logloss: 0.576882\n",
      "[379]\ttraining's binary_logloss: 0.576783\n",
      "[380]\ttraining's binary_logloss: 0.576685\n",
      "[381]\ttraining's binary_logloss: 0.576606\n",
      "[382]\ttraining's binary_logloss: 0.576534\n",
      "[383]\ttraining's binary_logloss: 0.576469\n",
      "[384]\ttraining's binary_logloss: 0.576393\n",
      "[385]\ttraining's binary_logloss: 0.576331\n",
      "[386]\ttraining's binary_logloss: 0.576236\n",
      "[387]\ttraining's binary_logloss: 0.576152\n",
      "[388]\ttraining's binary_logloss: 0.576076\n",
      "[389]\ttraining's binary_logloss: 0.575998\n",
      "[390]\ttraining's binary_logloss: 0.57591\n",
      "[391]\ttraining's binary_logloss: 0.575863\n",
      "[392]\ttraining's binary_logloss: 0.57581\n",
      "[393]\ttraining's binary_logloss: 0.575759\n",
      "[394]\ttraining's binary_logloss: 0.57572\n",
      "[395]\ttraining's binary_logloss: 0.575681\n",
      "[396]\ttraining's binary_logloss: 0.575593\n",
      "[397]\ttraining's binary_logloss: 0.575506\n",
      "[398]\ttraining's binary_logloss: 0.575456\n",
      "[399]\ttraining's binary_logloss: 0.575364\n",
      "[400]\ttraining's binary_logloss: 0.575273\n",
      "[401]\ttraining's binary_logloss: 0.575185\n",
      "[402]\ttraining's binary_logloss: 0.575076\n",
      "[403]\ttraining's binary_logloss: 0.574974\n",
      "[404]\ttraining's binary_logloss: 0.57488\n",
      "[405]\ttraining's binary_logloss: 0.57479\n",
      "[406]\ttraining's binary_logloss: 0.574687\n",
      "[407]\ttraining's binary_logloss: 0.574583\n",
      "[408]\ttraining's binary_logloss: 0.574496\n",
      "[409]\ttraining's binary_logloss: 0.574397\n",
      "[410]\ttraining's binary_logloss: 0.574301\n",
      "[411]\ttraining's binary_logloss: 0.574188\n",
      "[412]\ttraining's binary_logloss: 0.57408\n",
      "[413]\ttraining's binary_logloss: 0.573971\n",
      "[414]\ttraining's binary_logloss: 0.57387\n",
      "[415]\ttraining's binary_logloss: 0.573766\n",
      "[416]\ttraining's binary_logloss: 0.573721\n",
      "[417]\ttraining's binary_logloss: 0.57368\n",
      "[418]\ttraining's binary_logloss: 0.573623\n",
      "[419]\ttraining's binary_logloss: 0.57357\n",
      "[420]\ttraining's binary_logloss: 0.573528\n",
      "[421]\ttraining's binary_logloss: 0.573445\n",
      "[422]\ttraining's binary_logloss: 0.573378\n",
      "[423]\ttraining's binary_logloss: 0.5733\n",
      "[424]\ttraining's binary_logloss: 0.573222\n",
      "[425]\ttraining's binary_logloss: 0.57315\n",
      "[426]\ttraining's binary_logloss: 0.573091\n",
      "[427]\ttraining's binary_logloss: 0.573034\n",
      "[428]\ttraining's binary_logloss: 0.572985\n",
      "[429]\ttraining's binary_logloss: 0.572922\n",
      "[430]\ttraining's binary_logloss: 0.572858\n",
      "[431]\ttraining's binary_logloss: 0.572778\n",
      "[432]\ttraining's binary_logloss: 0.572687\n",
      "[433]\ttraining's binary_logloss: 0.57261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[434]\ttraining's binary_logloss: 0.572533\n",
      "[435]\ttraining's binary_logloss: 0.572454\n",
      "[436]\ttraining's binary_logloss: 0.572375\n",
      "[437]\ttraining's binary_logloss: 0.572294\n",
      "[438]\ttraining's binary_logloss: 0.57223\n",
      "[439]\ttraining's binary_logloss: 0.572163\n",
      "[440]\ttraining's binary_logloss: 0.572092\n",
      "[441]\ttraining's binary_logloss: 0.572\n",
      "[442]\ttraining's binary_logloss: 0.571915\n",
      "[443]\ttraining's binary_logloss: 0.571834\n",
      "[444]\ttraining's binary_logloss: 0.571761\n",
      "[445]\ttraining's binary_logloss: 0.571688\n",
      "[446]\ttraining's binary_logloss: 0.571601\n",
      "[447]\ttraining's binary_logloss: 0.571523\n",
      "[448]\ttraining's binary_logloss: 0.57143\n",
      "[449]\ttraining's binary_logloss: 0.57135\n",
      "[450]\ttraining's binary_logloss: 0.571266\n",
      "[451]\ttraining's binary_logloss: 0.571202\n",
      "[452]\ttraining's binary_logloss: 0.571127\n",
      "[453]\ttraining's binary_logloss: 0.571061\n",
      "[454]\ttraining's binary_logloss: 0.570998\n",
      "[455]\ttraining's binary_logloss: 0.570935\n",
      "[456]\ttraining's binary_logloss: 0.570875\n",
      "[457]\ttraining's binary_logloss: 0.570813\n",
      "[458]\ttraining's binary_logloss: 0.57076\n",
      "[459]\ttraining's binary_logloss: 0.570706\n",
      "[460]\ttraining's binary_logloss: 0.570655\n",
      "[461]\ttraining's binary_logloss: 0.570558\n",
      "[462]\ttraining's binary_logloss: 0.570462\n",
      "[463]\ttraining's binary_logloss: 0.570369\n",
      "[464]\ttraining's binary_logloss: 0.570273\n",
      "[465]\ttraining's binary_logloss: 0.570159\n",
      "[466]\ttraining's binary_logloss: 0.570109\n",
      "[467]\ttraining's binary_logloss: 0.570037\n",
      "[468]\ttraining's binary_logloss: 0.569991\n",
      "[469]\ttraining's binary_logloss: 0.569933\n",
      "[470]\ttraining's binary_logloss: 0.569863\n",
      "[471]\ttraining's binary_logloss: 0.569778\n",
      "[472]\ttraining's binary_logloss: 0.569698\n",
      "[473]\ttraining's binary_logloss: 0.569614\n",
      "[474]\ttraining's binary_logloss: 0.569523\n",
      "[475]\ttraining's binary_logloss: 0.56943\n",
      "[476]\ttraining's binary_logloss: 0.569349\n",
      "[477]\ttraining's binary_logloss: 0.569272\n",
      "[478]\ttraining's binary_logloss: 0.569183\n",
      "[479]\ttraining's binary_logloss: 0.569103\n",
      "[480]\ttraining's binary_logloss: 0.56902\n",
      "[481]\ttraining's binary_logloss: 0.568937\n",
      "[482]\ttraining's binary_logloss: 0.568827\n",
      "[483]\ttraining's binary_logloss: 0.568739\n",
      "[484]\ttraining's binary_logloss: 0.568643\n",
      "[485]\ttraining's binary_logloss: 0.568555\n",
      "[486]\ttraining's binary_logloss: 0.56846\n",
      "[487]\ttraining's binary_logloss: 0.568366\n",
      "[488]\ttraining's binary_logloss: 0.568285\n",
      "[489]\ttraining's binary_logloss: 0.568209\n",
      "[490]\ttraining's binary_logloss: 0.568115\n",
      "[491]\ttraining's binary_logloss: 0.568047\n",
      "[492]\ttraining's binary_logloss: 0.567956\n",
      "[493]\ttraining's binary_logloss: 0.567858\n",
      "[494]\ttraining's binary_logloss: 0.567767\n",
      "[495]\ttraining's binary_logloss: 0.567676\n",
      "[496]\ttraining's binary_logloss: 0.567584\n",
      "[497]\ttraining's binary_logloss: 0.567491\n",
      "[498]\ttraining's binary_logloss: 0.567408\n",
      "[499]\ttraining's binary_logloss: 0.567311\n",
      "[500]\ttraining's binary_logloss: 0.567224\n"
     ]
    }
   ],
   "source": [
    "aucslgm = xValSVM(dataset,'Target',10,'lgm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aucslr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00020021294265729168"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(aucslr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00026850282596599167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Fold AUC for LightGBM ')"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py:2267: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgmmean = np.mean(aucslgm)\n",
    "print(np.var(aucslgm))\n",
    "plt.bar(np.arange(1,11),aucslgm)\n",
    "plt.plot(np.ones(12)*lrmean,'r')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Fold AUC')\n",
    "plt.ylim([0.5,0.76])\n",
    "plt.text(6.8, 0.74, 'variance = 2.7e-4', bbox=dict(facecolor='r', alpha=0.5))\n",
    "plt.title('Fold AUC for LightGBM ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00018471454437789134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Fold AUC for Random Forest ')"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py:2267: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rfmean = np.mean(aucsrf)\n",
    "print(np.var(aucsrf))\n",
    "plt.bar(np.arange(1,11),aucsrf)\n",
    "plt.plot(np.ones(12)*lrmean,'r')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Fold AUC')\n",
    "plt.ylim([0.5,0.75])\n",
    "plt.text(6.8, 0.73, 'variance = 1.8e-4', bbox=dict(facecolor='r', alpha=0.5))\n",
    "plt.title('Fold AUC for Random Forest ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Fold AUC for Logistic Regression ')"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py:2267: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrmean = np.mean(aucslr)\n",
    "\n",
    "plt.bar(np.arange(1,11),aucslr)\n",
    "plt.plot(np.ones(12)*lrmean,'r')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Fold AUC')\n",
    "plt.ylim([0.5,0.75])\n",
    "plt.text(6.8, 0.72, 'variance = 2e-4', bbox=dict(facecolor='r', alpha=0.5))\n",
    "plt.title('Fold AUC for Logistic Regression ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xValSVM(dataset, lab, k , model):\n",
    "    '''\n",
    "    Perform k-fold cross validation on SVM across a range of C,\n",
    "    returns mean and var of auc avg.\n",
    "    '''\n",
    "    n_samp = dataset.shape[0]\n",
    "    cv = KFold(n = n_samp, n_folds = k)\n",
    "    aucs = [] #record auc for each fold return a list\n",
    "\n",
    "    for train_index, test_index in cv:\n",
    "        tr_k = dataset.iloc[train_index]\n",
    "        va_k = dataset.iloc[test_index]\n",
    "        \n",
    "        test_p = getprediction(model,tr_k.drop(lab,1),tr_k[lab],va_k.drop(lab,1))[0]\n",
    "        met = metrics.roc_auc_score(va_k[lab], test_p)\n",
    "        \n",
    "        aucs.append(met)\n",
    "    \n",
    "    return aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getprediction(model,trainx,trainy,testx):\n",
    "    if model == 'lgm':\n",
    "        scalar = MinMaxScaler()\n",
    "        scalar.fit(trainx)\n",
    "        trainx = scalar.transform(trainx)\n",
    "        testx = scalar.transform(testx)\n",
    "        \n",
    "        #created dataset for lightgbm\n",
    "        lgb_train = lgb.Dataset(trainx, trainy)\n",
    "        \n",
    "    # specify your configurations as a dict\n",
    "        params = {\n",
    "            'colsample_bytree':0.4,\n",
    "            \n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'is_unbalance': 'true',         # base rate: 0.30\n",
    "            'num_leaves': 12,\n",
    "            \"num_threads\": 4,\n",
    "            'learning_rate': 0.01,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'n_estimators': 500,\n",
    "            'verbose': 0\n",
    "        }\n",
    "\n",
    "    # train\n",
    "        \n",
    "        gbm = lgb.train(params,\n",
    "                        lgb_train,\n",
    "                        num_boost_round=10,\n",
    "                        valid_sets=lgb_train,  # eval training data\n",
    "                        categorical_feature = 'auto')\n",
    "# predict\n",
    "        y_pred = gbm.predict(testx, num_iteration=gbm.best_iteration)\n",
    "        trained = gbm\n",
    "    \n",
    "    elif model == 'lr':\n",
    "        LRC = LogisticRegression(C= 0.1, penalty = 'l1').fit(trainx,trainy)\n",
    "        y_pred = LRC.predict_proba(testx)[:,1]\n",
    "        trained = LRC\n",
    "        \n",
    "    elif model == 'rf':\n",
    "        RF = RandomForestClassifier(criterion='entropy', bootstrap=True, max_depth=30, n_estimators=1200, max_features=0.2, min_samples_split=20, min_samples_leaf=10, n_jobs = -1, oob_score=True).fit(trainx,trainy)\n",
    "        y_pred = RF.predict_proba(testx)[:,1]\n",
    "        trained = RF\n",
    "        \n",
    "    return y_pred,trained\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
